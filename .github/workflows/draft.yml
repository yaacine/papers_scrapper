name: Scrap Authors

on:
  push:
    branches: [gh-actions-scrapper]
    
  schedule:
    # * is a special character in YAML so you have to quote this string
    - cron:  '0 */2 * * *'

jobs:
  Scrap:
    runs-on: ubuntu-latest
    if: "!contains(github.event.head_commit.message, 'Automated scrapping')"
    steps:

      - name: Notify slack Start
        if: success()
        id: slack
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@v1
        with:
          channel_id: C01KUCG5820
          status: Scrapping started
          color: warning

      - name: Check out source repository
        uses: actions/checkout@v2
        with:
          token: ${{secrets.GH_ACCESS_TOKEN}}
          ref: gh-actions-scrapper


      - name: install tor proxy
        run: sudo apt install tor

      - name: run tor
        run: |
          ss -nlt


      - name: Set up Python environment
        uses: actions/setup-python@v1
        with:
          python-version: "3.8"

        

      - name: install dependencies 
        run: |
          python3 -m pip install scholarly
          python3 -m pip install pandas
          python3 -m pip install configparser

          

      - name: scrap 
        run: |
          python3 scripts/V1.0.2/main.py publication
        continue-on-error: true
        timeout-minutes: 350
        

     
      - name: Upload to Google Drive
        uses: satackey/action-google-drive@v1
        with:
          skicka-tokencache-json: ${{ secrets.SKICKA_TOKENCACHE_JSON }}
          upload-from: scripts/V1.0.2/datasets
          upload-to: /PFE/datasets/genetared_from_gh_actions
          # For those who set up Google Drive API client ID and secret themselves
          google-client-id: ${{ secrets.GOOGLE_CLIENT_ID }}
          google-client-secret: ${{ secrets.GOOGLE_CLIENT_SECRET }}
        continue-on-error: true

      - uses: actions/upload-artifact@v2
        with:
          name: my-artifact
          path: scripts/V1.0.2/datasets/articles/
        continue-on-error: true

        
      # push the formatting changes to the PR itself
      - name: Commit changes
        run: |
          git config --global user.name 'Mehyac Scrapper'
          git config --global user.email 'mehyac_scrapper@users.noreply.github.com'
          git add .
          git commit -am "Automated scrapping"
          git push origin gh-actions-scrapper

        continue-on-error: true

      
      - name: Notify slack success
        if: success()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@v1
        with:
          message_id: ${{ steps.slack.outputs.message_id }}
          channel_id: C01KUCG5820
          status: Staging PR_Review Succeeded
          color: good

      - name: Notify slack fail
        if: failure()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@v1
        with:
          message_id: ${{ steps.slack.outputs.message_id }}
          channel_id: C01KUCG5820
          status: Scrapping Failed
          color: danger
      
      - name: Notify slack cancelled 
        if: cancelled()
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        uses: voxmedia/github-action-slack-notify-build@v1
        with:
          message_id: ${{ steps.slack.outputs.message_id }}
          channel_id: C01KUCG5820
          status: Scrapping Cancelled
          color: "#FFFFFF"

