,title,pub_year,author,volume,journal,number,pages,publisher,abstract,filled,author_pub_id,num_citations,pub_url,cites_id,citedby_url,gsrank,author_id,eprint_url,got_citations,got_author_ids,author_ids
1278018,The FLARE™ intraoperative near-infrared fluorescence imaging system: a first-in-human clinical trial in breast cancer sentinel lymph node mapping,2009,Susan L Troyan and Vida Kianzad and Summer L Gibbs-Strauss and Sylvain Gioux and Aya Matsui and Rafiou Oketokoun and Long Ngo and Ali Khamene and Fred Azar and John V Frangioni,16,Annals of Surgical Oncology,10,2943-2952,Springer New York,Invisible NIR fluorescent light can provide high sensitivity. high-resolution. and real-time image-guidance during oncologic surgery. but imaging systems that are presently available do not display this invisible light in the context of surgical anatomy. The FLARE™ imaging system overcomes this major obstacle.Color video was acquired simultaneously. and in real-time. along with two independent channels of NIR fluorescence. Grayscale NIR fluorescence images were converted to visible “pseudo-colors” and overlaid onto the color video image. Yorkshire pigs weighing 35 kg (n = 5) were used for final preclinical validation of the imaging system. A six-patient pilot study was conducted in women undergoing sentinel lymph node (SLN) mapping for breast cancer. Subjects received 99mTc-sulfur colloid lymphoscintigraphy. In addition …,True,j41ocikAAAAJ:u-x6o8ySG0sC,691,https://link.springer.com/article/10.1245/s10434-009-0594-2,16604290576264846668,/scholar?cites=16604290576264846668,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2772055/,0,0,0
1278019,Automatic CT-ultrasound registration for diagnostic imaging and image-guided intervention,2008,Wolfgang Wein and Shelby Brunke and Ali Khamene and Matthew R Callstrom and Nassir Navab,12,Medical Image Analysis,5,577-585,Elsevier,The fusion of tracked ultrasound with CT has benefits for a variety of clinical applications. however extensive manual effort is usually required for correct registration. We developed new methods that allow one to simulate medical ultrasound from CT in real-time. reproducing the majority of ultrasonic imaging effects. They are combined with a robust similarity measure that assesses the correlation of a combination of signals extracted from CT with ultrasound. without knowing the influence of each signal. This serves as the foundation of a fully automatic registration. that aligns a 3D ultrasound sweep with the corresponding tomographic modality using a rigid or an affine transformation model. without any manual interaction.These techniques were evaluated in a study involving 25 patients with indeterminate lesions in liver and kidney. The clinical setup. acquisition and registration workflow is described. along with the …,True,j41ocikAAAAJ:9yKSN-GCB0IC,470,https://www.sciencedirect.com/science/article/pii/S1361841508000637,16782031562727993010,/scholar?cites=16782031562727993010,,,https://www.researchgate.net/profile/Ali_Kamen/publication/272352969_wein2008ctusfusion/links/54e26ef30cf2edaea092ea91/wein2008ctusfusion.pdf,0,0,0
1278020,A new method for the extraction of fetal ECG from the composite abdominal signal,2000,Ali Khamene and Shahriar Negahdaripour,47,IEEE Transactions on Biomedical Engineering,4,507-516,IEEE,We developed a wavelet transform-based method to extract the fetal electrocardiogram (ECG) from the composite abdominal signal. This is based on the detection of the singularities obtained from the composite abdominal signal. using the modulus maxima in the wavelet domain. Modulus maxima locations of the abdominal signal are used to discriminate between maternal and fetal ECG signals. Two different approaches have been considered. In the first approach. at least one thoracic signal is used as the a prior to perform the classification whereas in the second approach no thoracic signal is needed. A reconstruction method is utilized to obtain the fetal ECG signal from the detected fetal modulus maxima. The proposed technique is different from the classical time-domain methods. in that we exploit the most distinct features of the signal. leading to more robustness with respect to signal perturbations. Results of …,True,j41ocikAAAAJ:u5HHmVD_uO8C,255,https://ieeexplore.ieee.org/abstract/document/828150/,14309528410263199158,/scholar?cites=14309528410263199158,,,,0,0,0
1278021,Method and apparatus for ultrasound guidance of needle biopsies,2004,Frank Sauer and Gianluca Paladini and Ali Khamene,,,,,,An ultrasound scanning system having an ultrasound transducer (10) which provides ultrasound images (33). a computer to process the ultrasound information and to render the ultrasound image (33) correctly positioned and scaled for display on a flat panel monitor (29) which has a display size similar to the actual physical size of the ultrasound image (33). A half silvered mirror (30) redirects the image (33) so that the user (32) perceives the image (33) as if it occupied the actual physical location of the structures (34. 35) appearing in the image (33). An illumination (22) unit projects onto a patient (13) a line of light (3) that is within the imaging plane (4) projected by the ultrasound transducer (10) into the patient (13). Alternatively a video camera may be used to display a guide line (15) that is coplanar with the imaging plane (4). A mechanical mount (16) combines the transducer (10). monitor (29). mirror (30). and …,True,j41ocikAAAAJ:PZE8UkGerEcC,182,https://patents.google.com/patent/US6689067B2/en,14302400050318200263,/scholar?cites=14302400050318200263,,,https://patentimages.storage.googleapis.com/77/45/46/e95c73c328bda3/US6689067B2.pdf,0,0,0
1278022,Automatic registration of portal images and volumetric CT for patient positioning in radiation therapy,2006,Ali Khamene and Peter Bloch and Wolfgang Wein and Michelle Svatos and Frank Sauer,10,Medical Image Analysis,1,96-112,Elsevier,The efficacy of radiation therapy treatment depends on the patient setup accuracy at each daily fraction. A significant problem is reproducing the patient position during treatment planning for every fraction of the treatment process. We propose and evaluate an intensity based automatic registration method using multiple portal images and the pre-treatment CT volume. We perform both geometric and radiometric calibrations to generate high quality digitally reconstructed radiographs (DRRs) that can be compared against portal images acquired right before treatment dose delivery. We use a graphics processing unit (GPU) to generate the DRRs in order to gain computational efficiency. We also perform a comparative study on various similarity measures and optimization procedures. Simple similarity measure such as local normalized correlation (LNC) performs best as long as the radiometric calibration is carefully …,True,j41ocikAAAAJ:3BvdIg-l-ZAC,176,https://www.sciencedirect.com/science/article/pii/S1361841505000678,13057669431817763733,/scholar?cites=13057669431817763733,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.205.4506&rep=rep1&type=pdf,0,0,0
1278023,System and method for augmented reality navigation in a medical intervention procedure,2010,Frank Sauer and Ali Khamene and Sebastian Vogt,,,,,,A method for augmented reality navigation of a medical intervention includes providing a stereoscopic head mounted display. the display including a pair of stereo viewing cameras. at least one tracking camera. and a stereoscopic guidance display. During a medical intervention on a patient. the patient's body pose is determined from a rigid body transformation between the tracking camera and frame markers on the scanning table. and the pose of an intervention instrument with respect to the table is determined. A visual representation of the patient overlaid with an image of the intervention target. the instrument. and a path for guiding the instrument to perform said medical intervention is displayed in the stereoscopic guidance display.,True,j41ocikAAAAJ:1xBWf43XMUgC,147,https://patents.google.com/patent/US7774044B2/en,16907489873381176067,/scholar?cites=16907489873381176067,,,https://patentimages.storage.googleapis.com/a9/c2/47/9facf399b51262/US7774044.pdf,0,0,0
1278024,An Augmented Reality System for MR Image–guided Needle Biopsy: Initial Results in a Swine Model1,2006,Frank K Wacker and Sebastian Vogt and Ali Khamene and John A Jesberger and Sherif G Nour and Daniel R Elgort and Frank Sauer and Jeffrey L Duerk and Jonathan S Lewin,238,Radiology,2,497-504,Radiological Society of North America,Purpose: To evaluate an augmented reality (AR) system in combination with a 1.5-T closed-bore magnetic resonance (MR) imager as a navigation tool for needle biopsies.Materials and Methods: The experimental protocol had institutional animal care and use committee approval. Seventy biopsies were performed in phantoms by using 20 tube targets. each with a diameter of 6 mm. and 50 virtual targets. The position of the needle tip in AR and MR space was compared in multiple imaging planes. and virtual and real needle tip localization errors were calculated. Ten AR-guided biopsies were performed in three pigs. and the duration of each procedure was determined. After successful puncture. the distance to the target was measured on MR images. The confidence limits for the achieved in-plane hit rate and for lateral deviation were calculated. A repeated measures analysis of variance was used to determine …,True,j41ocikAAAAJ:MGPUR4WVBMEC,138,https://pubs.rsna.org/doi/abs/10.1148/radiol.2382041441,15047803332825271729,/scholar?cites=15047803332825271729,,,,0,0,0
1278025,An artificial agent for robust image registration,2017,Rui Liao and Shun Miao and Pierre de Tournemire and Sasa Grbic and Ali Kamen and Tommaso Mansi and Dorin Comaniciu,,,,,,"3-D image registration. which involves aligning two or more images. is a critical step in a variety of medical applications from diagnosis to therapy. Image registration is commonly performed by optimizing an image matching metric as a cost function. However this task is challenging due to the non-convex nature of the matching metric over the plausible registration parameter space and insufficient approches for a robust optimization. As a result. current approaches are often customized to a specific problem and sensitive to image quality and artifacts. In this paper. we propose a completely different approach to image registration. inspired by how experts perform the task. We first cast the image registration problem as a"" strategic learning"" process. where the goal is to find the best sequence of motion actions (eg up. down. etc) that yields image alignment. Within this approach. an artificial agent is learned. modeled using deep convolutional neural networks. with 3D raw image data as the input. and the next optimal action as the output. To copy with the dimensionality of the problem. we propose a greedy supervised approach for an end-to-end training. coupled with attention-driven hierarchical strategy. The resulting registration approach inherently encodes both a data-driven matching metric and an optimal registration strategy (policy). We demonstrate on two 3-D/3-D medical image registration examples with drastically different nature of challenges. that the artificial agent outperforms several state-of-the-art registration methods by a large margin in terms of both accuracy and robustness.",True,j41ocikAAAAJ:T_0gP6tLVL0C,133,https://ojs.aaai.org/index.php/AAAI/article/view/11230,13789426669412137738,/scholar?cites=13789426669412137738,,,https://ojs.aaai.org/index.php/AAAI/article/download/11230/11089,0,0,0
1278026,Robust non-rigid registration through agent-based action learning,2017,Julian Krebs and Tommaso Mansi and Hervé Delingette and Li Zhang and Florin C Ghesu and Shun Miao and Andreas K Maier and Nicholas Ayache and Rui Liao and Ali Kamen,,,,344-352,Springer. Cham,Robust image registration in medical imaging is essential for comparison or fusion of images. acquired from various perspectives. modalities or at different times. Typically. an objective function needs to be minimized assuming specific a priori deformation models and predefined or learned similarity measures. However. these approaches have difficulties to cope with large deformations or a large variability in appearance. Using modern deep learning (DL) methods with automated feature design. these limitations could be resolved by learning the intrinsic mapping solely from experience. We investigate in this paper how DL could help organ-specific (ROI-specific) deformable registration. to solve motion compensation or atlas-based segmentation problems for instance in prostate diagnosis. An artificial agent is trained to solve the task of non-rigid registration by exploring the parametric space of a statistical …,True,j41ocikAAAAJ:Dmoar05iI2YC,120,https://link.springer.com/chapter/10.1007/978-3-319-66182-7_40,6297155798520631821,/scholar?cites=6297155798520631821,,,https://hal.inria.fr/hal-01569447/document,0,0,0
1278027,System and method for patient positioning for radiotherapy in the presence of respiratory motion,2010,Frank Sauer and Ali Khamene,,,,,,A system and method for positioning a patient for radiotherapy is provided. The method comprises: acquiring a first x-ray image sequence of a target inside the patient at a first angle; acquiring first respiratory signals of the patient while acquiring the first x-ray image sequence; acquiring a second x-ray image sequence of the target at a second angle; acquiring second respiratory signals of the patient while acquiring the second x-ray image sequence; synchronizing the first and second x-ray image sequences with the first and second respiratory signals to form synchronized first and second x-ray image sequences; identifying the target in the synchronized first and second x-ray image sequences; and determining three-dimensional (3D) positions of the target through time in the synchronized first and second x-ray image sequences.,True,j41ocikAAAAJ:VjBpw8Hezy4C,113,https://patents.google.com/patent/US7853308B2/en,1491842018390446951,/scholar?cites=1491842018390446951,,,https://patentimages.storage.googleapis.com/a2/d1/f5/d87aebab200264/US7853308.pdf,0,0,0
1278028,A survey of medical image registration on graphics hardware,2011,O Fluck and C Vetter and W Wein and A Kamen and B Preim and R Westermann,104,Computer Methods and Programs in Biomedicine,3,45-57,Elsevier,The rapidly increasing performance of graphics processors. improving programming support and excellent performance-price ratio make graphics processing units (GPUs) a good option for a variety of computationally intensive tasks. Within this survey. we give an overview of GPU accelerated image registration. We address both. GPU experienced readers with an interest in accelerated image registration. as well as registration experts who are interested in using GPUs. We survey programming models and interfaces and analyze different approaches to programming on the GPU. We furthermore discuss the inherent advantages and challenges of current hardware architectures. which leads to a description of the details of the important building blocks for successful implementations.,True,j41ocikAAAAJ:M0j1y4EgrScC,109,https://www.sciencedirect.com/science/article/pii/S0169260710002713,18193700807429056957,/scholar?cites=18193700807429056957,,,https://www.researchgate.net/profile/Bernhard_Preim/publication/49639970_A_survey_of_medical_image_registration_on_graphics_hardware/links/5a13008f0f7e9b1e572c2525/A-survey-of-medical-image-registration-on-graphics-hardware.pdf,0,0,0
1278029,Diffusion kernels on graphs and other discrete structures,2002,Risi Imre Kondor and John Lafferty,2002,Proceedings of the 19th international conference on machine learning,,315-322,,The application of kernel-based learning algorithms has. so far. largely been confined to realvalued data and a few special data types. such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures. based on the matrix exponentiation idea. In particular. we focus on generating kernels on graphs. for which we propose a special class of exponential kernels. based on the heat equation. called diffusion kernels. and show that these can be regarded as the discretisation of the familiar Gaussian kernel of Euclidean space.,True,v12-jLUAAAAJ:u5HHmVD_uO8C,1429,http://people.cs.uchicago.edu/~risi/papers/diffusion-kernels.pdf,6737969268261813970,/scholar?cites=6737969268261813970,,,http://people.cs.uchicago.edu/~risi/papers/diffusion-kernels.pdf,0,0,0
1278030,Gaussian approximation potentials: The accuracy of quantum mechanics. without the electrons,2010,Albert P Bartók and Mike C Payne and Risi Kondor and Gábor Csányi,104,Physical review letters,13,136403,American Physical Society,We introduce a class of interatomic potential models that can be automatically generated from data consisting of the energies and forces experienced by atoms. as derived from quantum mechanical calculations. The models do not have a fixed functional form and hence are capable of modeling complex potential energy landscapes. They are systematically improvable with more data. We apply the method to bulk crystals. and test it by calculating properties at high temperatures. Using the interatomic potential to generate the long molecular dynamics trajectories required for such calculations saves orders of magnitude in computational cost.,True,v12-jLUAAAAJ:UeHWp8X0CEIC,1134,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.104.136403,4745823905145029648,/scholar?cites=4745823905145029648,,,https://arxiv.org/pdf/0910.1019,0,0,0
1278031,Graph kernels,2010,S Vichy N Vishwanathan and Nicol N Schraudolph and Risi Kondor and Karsten M Borgwardt,11,Journal of Machine Learning Research,,1201-1242,MIT Press,We present a unified framework to study graph kernels. special cases of which include the random walk (Gärtner et al.. 2003; Borgwardt et al.. 2005) and marginalized (Kashima et al.. 2003. 2004; Mahé et al.. 2004) graph kernels. Through reduction to a Sylvester equation we improve the time complexity of kernel computation between unlabeled graphs with n vertices from O(n^6) to O(n^3). We find a spectral decomposition approach even more efficient when computing entire kernel matrices. For labeled graphs we develop conjugate gradient and fixed-point methods that take O(dn^3) time per iteration. where d is the size of the label set. By extending the necessary linear algebra to Reproducing Kernel Hilbert Spaces (RKHS) we obtain the same result for d-dimensional edge kernels. and O(n^4) in the infinite-dimensional case; on sparse graphs these algorithms only take O(n^2) time per iteration in all cases. Experiments on graphs from bioinformatics and other application domains show that these techniques can speed up computation of the kernel by an order of magnitude or more. We also show that certain rational kernels (Cortes et al.. 2002. 2003. 2004) when specialized to graphs reduce to our random walk graph kernel. Finally. we relate our framework to R-convolution kernels (Haussler. 1999) and provide a kernel that is close to the optimal assignment kernel of Fröhlich et al. (2006) yet provably positive semi-definite.,True,v12-jLUAAAAJ:2osOgNQ5qMEC,968,https://authors.library.caltech.edu/20528,11932573160154031862,/scholar?cites=11932573160154031862,,,https://authors.library.caltech.edu/20528/1/Vishwanathan2010p11646J_Mach_Learn_Res.pdf,0,0,0
1278032,Kernels and regularization on graphs,2003,Alexander J Smola and Risi Kondor,,,,144-158,Springer. Berlin. Heidelberg,We introduce a family of kernels on graphs based on the notion of regularization operators. This generalizes in a natural way the notion of regularization and Greens functions. as commonly used for real valued functions. to graphs. It turns out that diffusion kernels can be found as a special case of our reasoning. We show that the class of positive. monotonically decreasing functions on the unit interval leads to kernels and corresponding regularization operators.,True,v12-jLUAAAAJ:u-x6o8ySG0sC,937,https://link.springer.com/chapter/10.1007/978-3-540-45167-9_12,10853394597336247098,/scholar?cites=10853394597336247098,,,https://www.shivani-agarwal.net/Teaching/E0371/Papers/colt03-kernels-regularization-graphs.pdf,0,0,0
1278033,On representing chemical environments,2013,Albert P Bartók and Risi Kondor and Gábor Csányi,87,Physical Review B,18,184115,American Physical Society,We review some recently published methods to represent atomic neighborhood environments. and analyze their relative merits in terms of their faithfulness and suitability for fitting potential energy surfaces. The crucial properties that such representations (sometimes called descriptors) must have are differentiability with respect to moving the atoms and invariance to the basic symmetries of physics: rotation. reflection. translation. and permutation of atoms of the same species. We demonstrate that certain widely used descriptors that initially look quite different are specific cases of a general approach. in which a finite set of basis functions with increasing angular wave numbers are used to expand the atomic neighborhood density function. Using the example system of small clusters. we quantitatively show that this expansion needs to be carried to higher and higher wave numbers as the number of neighbors …,True,v12-jLUAAAAJ:Y0pCki6q_DkC,873,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.87.184115,3134398014064745426,/scholar?cites=3134398014064745426,,,https://arxiv.org/pdf/1209.3140.pdf;,0,0,0
1278034,Probability product kernels,2004,Tony Jebara and Risi Kondor and Andrew Howard,5,The Journal of Machine Learning Research,,819-844,JMLR. org,The advantages of discriminative learning algorithms and kernel machines are combined with generative modeling using a novel kernel between distributions. In the probability product kernel. data points in the input space are mapped to distributions over the sample space and a general inner product is then evaluated as the integral of the product of pairs of distributions. The kernel is straightforward to evaluate for all exponential family models such as multinomials and Gaussians and yields interesting nonlinear kernels. Furthermore. the kernel is computable in closed form for latent distributions such as mixture models. hidden Markov models and linear dynamical systems. For intractable models. such as switching linear dynamical systems. structured mean-field approximations can be brought to bear on the kernel evaluation. For general distributions. even if an analytic expression for the kernel is not feasible. we show a straightforward sampling method to evaluate it. Thus. the kernel permits discriminative learning methods. including support vector machines. to exploit the properties. metrics and invariances of the generative models we infer from each datum. Experiments are shown using multinomial models for text. hidden Markov models for biological data sets and linear dynamical systems for time series data.,True,v12-jLUAAAAJ:d1gkVwhDpl0C,613,https://www.jmlr.org/papers/volume5/jebara04a/jebara04a.pdf,3848151407572273068,/scholar?cites=3848151407572273068,,,https://www.jmlr.org/papers/volume5/jebara04a/jebara04a.pdf,0,0,0
1278035,A kernel between sets of vectors,2003,Risi Kondor and Tony Jebara,,,,361-368,,In various application domains. including image recognition. it is natural to represent each example as a set of vectors. With a base kernel we can implicitly map these vectors to a Hilbert space and fit a Gaussian distribution to the whole set using Kernel PCA. We define our kernel between examples as Bhattacharyya’s measure of affinity between such Gaussians. The resulting kernel is computable in closed form and enjoys many favorable properties. including graceful behavior under transformations. potentially justifying the vector set representation even in cases when more conventional representations also exist.,True,v12-jLUAAAAJ:9yKSN-GCB0IC,339,https://www.aaai.org/Papers/ICML/2003/ICML03-049.pdf,10184135545233010818,/scholar?cites=10184135545233010818,,,https://www.aaai.org/Papers/ICML/2003/ICML03-049.pdf,0,0,0
1278036,On the generalization of equivariance and convolution in neural networks to the action of compact groups,2018,Risi Kondor and Shubhendu Trivedi,,,,2747-2755,PMLR,Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance with respect to translations. There have been many recent attempts to generalize this framework to other domains. including graphs and data lying on manifolds. In this paper we give a rigorous. theoretical treatment of convolution and equivariance in neural networks with respect to not just translations. but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient. but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.,True,v12-jLUAAAAJ:TFP_iSt0sucC,170,http://proceedings.mlr.press/v80/kondor18a.html,9202958939197040845,/scholar?cites=9202958939197040845,,,http://proceedings.mlr.press/v80/kondor18a/kondor18a.pdf,0,0,0
1278037,Bhattacharyya and expected likelihood kernels,2003,Tony Jebara and Risi Kondor,,,,57-71,Springer. Berlin. Heidelberg,We introduce a new class of kernels between distributions. These induce a kernel on the input space between data points by associating to each datum a generative model fit to the data point individually. The kernel is then computed by integrating the product of the two generative models corresponding to two data points. This kernel permits discriminative estimation via. for instance. support vector machines. while exploiting the properties. assumptions. and invariances inherent in the choice of generative model. It satisfies Mercer’s condition and can be computed in closed form for a large class of models. including exponential family models. mixtures. hidden Markov models and Bayesian networks. For other models the kernel can be approximated by sampling methods. Experiments are shown for multinomial models in text classification and for hidden Markov models for protein sequence classification.,True,v12-jLUAAAAJ:qjMakFHDy7sC,162,https://link.springer.com/chapter/10.1007/978-3-540-45167-9_6,18436797459594014855,/scholar?cites=18436797459594014855,,,http://www.gatsby.ucl.ac.uk/~risi/papers/bhatta.pdf,0,0,0
1278038,Solving the multi-way matching problem by permutation synchronization,2013,Deepti Pachauri and Risi Kondor and Vikas Singh,,,,1860-1868,,The problem of matching not just two. but m different sets of objects to each other arises in many contexts. including finding the correspondence between feature points across multiple images in computer vision. At present it is usually solved by matching the sets pairwise. in series. In contrast. we propose a new method. Permutation Synchronization. which finds all the matchings jointly. in one shot. via a relaxation to eigenvector decomposition. The resulting algorithm is both computationally efficient. and. as we demonstrate with theoretical arguments as well as experimental results. much more stable to noise than previous methods.,True,v12-jLUAAAAJ:_FxGoFyzp5QC,146,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.724.487&rep=rep1&type=pdf,12845926242523497045,/scholar?cites=12845926242523497045,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.724.487&rep=rep1&type=pdf,0,0,0
1278039,The multiscale laplacian graph kernel,2016,Risi Kondor and Horace Pan,,arXiv preprint arXiv:1603.06186,,,,Many real world graphs. such as the graphs of molecules. exhibit structure at multiple different scales. but most existing kernels between graphs are either purely local or purely global in character. In contrast. by building a hierarchy of nested subgraphs. the Multiscale Laplacian Graph kernels (MLG kernels) that we define in this paper can account for structure at a range of different scales. At the heart of the MLG construction is another new graph kernel. called the Feature Space Laplacian Graph kernel (FLG kernel). which has the property that it can lift a base kernel defined on the vertices of two graphs to a kernel between the graphs. The MLG kernel applies such FLG kernels to subgraphs recursively. To make the MLG kernel computationally feasible. we also introduce a randomized projection procedure. similar to the Nyström method. but for RKHS operators.,True,v12-jLUAAAAJ:7PzlFSSx8tAC,112,https://arxiv.org/abs/1603.06186,16878982718407030522,/scholar?cites=16878982718407030522,,,https://arxiv.org/pdf/1603.06186,0,0,0
1278040,Neural style transfer: A review,2019,Yongcheng Jing and Yezhou Yang and Zunlei Feng and Jingwen Ye and Yizhou Yu and Mingli Song,26,,11,3365-3385,IEEE,The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then. NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper. we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then. we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future …,True,7oLbhAwAAAAJ:H_6PQ7K5Sg8C,264,https://ieeexplore.ieee.org/abstract/document/8732370/,4434701562780805395,/scholar?cites=4434701562780805395,,,https://arxiv.org/pdf/1705.04058.pdf%20http://arxiv.org/abs/1705.04058,0,0,0
1278041,Semi-supervised coupled dictionary learning for person re-identification,2014,Xiao Liu and Mingli Song and Dacheng Tao and Xingchen Zhou and Chun Chen and Jiajun Bu,,,,3550-3557,,The desirability of being able to search for specific persons in surveillance videos captured by different cameras has increasingly motivated interest in the problem of person re-identification. which is a critical yet under-addressed challenge in multi-camera tracking systems. The main difficulty of person re-identification arises from the variations in human appearances from different camera views. In this paper. to bridge the human appearance variations across cameras. two coupled dictionaries that relate to the gallery and probe cameras are jointly learned in the training phase from both labeled and unlabeled images. The labeled training images carry the relationship between features from different cameras. and the abundant unlabeled training images are introduced to exploit the geometry of the marginal distribution for obtaining robust sparse representation. In the testing phase. the feature of each target image from the probe camera is first encoded by the sparse representation and then recovered in the feature space spanned by the images from the gallery camera. The features of the same person from different cameras are similar following the above transformation. Experimental results on publicly available datasets demonstrate the superiority of our method.,True,7oLbhAwAAAAJ:MRFs4rWx_PcC,223,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Liu_Semi-Supervised_Coupled_Dictionary_2014_CVPR_paper.html,14992023929562555237,/scholar?cites=14992023929562555237,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Liu_Semi-Supervised_Coupled_Dictionary_2014_CVPR_paper.pdf,0,0,0
1278042,Discovering discriminative graphlets for aerial image categories recognition,2013,Luming Zhang and Yahong Han and Yi Yang and Mingli Song and Shuicheng Yan and Qi Tian,22,IEEE Transactions on Image Processing,12,5071-5084,IEEE,Recognizing aerial image categories is useful for scene annotation and surveillance. Local features have been demonstrated to be robust to image transformations. including occlusions and clutters. However. the geometric property of an aerial image (i.e.. the topology and relative displacement of local features). which is key to discriminating aerial image categories. cannot be effectively represented by state-of-the-art generic visual descriptors. To solve this problem. we propose a recognition model that mines graphlets from aerial images. where graphlets are small connected subgraphs reflecting both the geometric property and color/texture distribution of an aerial image. More specifically. each aerial image is decomposed into a set of basic components (e.g.. road and playground) and a region adjacency graph (RAG) is accordingly constructed to model their spatial interactions. Aerial image categories recognition …,True,7oLbhAwAAAAJ:P5F9QuxV20EC,171,https://ieeexplore.ieee.org/abstract/document/6578546/,10344000150395602485,/scholar?cites=10344000150395602485,,,https://www.researchgate.net/profile/Yahong_Han/publication/255976223_Discovering_Discriminative_Graphlets_for_Aerial_Image_Category_Recognition/links/54d24ef30cf28e069723d6a4/Discovering-Discriminative-Graphlets-for-Aerial-Image-Category-Recognition.pdf,0,0,0
1278043,Probabilistic graphlet transfer for photo cropping,2012,Luming Zhang and Mingli Song and Qi Zhao and Xiao Liu and Jiajun Bu and Chun Chen,22,IEEE Transactions on Image Processing,2,802-815,IEEE,As one of the most basic photo manipulation processes. photo cropping is widely used in the printing. graphic design. and photography industries. In this paper. we introduce graphlets (i.e.. small connected subgraphs) to represent a photo's aesthetic features. and propose a probabilistic model to transfer aesthetic features from the training photo onto the cropped photo. In particular. by segmenting each photo into a set of regions. we construct a region adjacency graph (RAG) to represent the global aesthetic feature of each photo. Graphlets are then extracted from the RAGs. and these graphlets capture the local aesthetic features of the photos. Finally. we cast photo cropping as a candidate-searching procedure on the basis of a probabilistic model. and infer the parameters of the cropped photos using Gibbs sampling. The proposed method is fully automatic. Subjective evaluations have shown that it is preferred over …,True,7oLbhAwAAAAJ:BqipwSGYUEgC,170,https://ieeexplore.ieee.org/abstract/document/6327366/,10708815325600403267,/scholar?cites=10708815325600403267,,,https://www.comp.nus.edu.sg/~cs5248/1415S1/l10/tip2013.pdf,0,0,0
1278044,Audio-visual based emotion recognition-a new approach,2004,Mingli Song and Jiajun Bu and Chun Chen and Nan Li,2,,,II-II,IEEE,Emotion recognition is one of the latest challenges in intelligent human/computer communication. Most of the previous work on emotion recognition focused on extracting emotions from visual or audio information separately. A novel approach is presented in this paper. including both visual and audio from video clips. to recognize the human emotion. The facial animation parameters (FAPs) compliant facial feature tracking based on active appearance model is performed on the video to generate two vector stream which represent the expression feature and the visual speech one. Combined with the visual vectors. the audio vector is extracted in terms of low level features. Then. a tripled hidden Markov model is introduced to perform the recognition which allows the state asynchrony of the audio and visual observation sequences while preserving their natural correlation over time. The experimental results show that …,True,7oLbhAwAAAAJ:u5HHmVD_uO8C,156,https://ieeexplore.ieee.org/abstract/document/1315276/,12678269764684482408,/scholar?cites=12678269764684482408,,,,0,0,0
1278045,Probabilistic graphlet cut: Exploiting spatial structure cue for weakly supervised image segmentation,2013,Luming Zhang and Mingli Song and Zicheng Liu and Xiao Liu and Jiajun Bu and Chun Chen,,,,1908-1915,,Weakly supervised image segmentation is a challenging problem in computer vision field. In this paper. we present a new weakly supervised image segmentation algorithm by learning the distribution of spatially structured superpixel sets from image-level labels. Specifically. we first extract graphlets from each image where a graphlet is a smallsized graph consisting of superpixels as its nodes and it encapsulates the spatial structure of those superpixels. Then. a manifold embedding algorithm is proposed to transform graphlets of different sizes into equal-length feature vectors. Thereafter. we use GMM to learn the distribution of the post-embedding graphlets. Finally. we propose a novel image segmentation algorithm. called graphlet cut. that leverages the learned graphlet distribution in measuring the homogeneity of a set of spatially structured superpixels. Experimental results show that the proposed approach outperforms state-of-the-art weakly supervised image segmentation methods. and its performance is comparable to those of the fully supervised segmentation models.,True,7oLbhAwAAAAJ:NhqRSupF_l8C,152,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Zhang_Probabilistic_Graphlet_Cut_2013_CVPR_paper.html,7003727931529566612,/scholar?cites=7003727931529566612,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhang_Probabilistic_Graphlet_Cut_2013_CVPR_paper.pdf,0,0,0
1278046,Probabilistic exposure fusion,2011,Mingli Song and Dacheng Tao and Chun Chen and Jiajun Bu and Jiebo Luo and Chengqi Zhang,21,IEEE Transactions on Image Processing,1,341-357,IEEE,The luminance of a natural scene is often of high dynamic range (HDR). In this paper. we propose a new scheme to handle HDR scenes by integrating locally adaptive scene detail capture and suppressing gradient reversals introduced by the local adaptation. The proposed scheme is novel for capturing an HDR scene by using a standard dynamic range (SDR) device and synthesizing an image suitable for SDR displays. In particular. we use an SDR capture device to record scene details (i.e.. the visible contrasts and the scene gradients) in a series of SDR images with different exposure levels. Each SDR image responds to a fraction of the HDR and partially records scene details. With the captured SDR image series. we first calculate the image luminance levels. which maximize the visible contrasts. and then the scene gradients embedded in these images. Next. we synthesize an SDR image by using a …,True,7oLbhAwAAAAJ:8k81kl-MbHgC,148,https://ieeexplore.ieee.org/abstract/document/5773085/,10946735759235352712,/scholar?cites=10946735759235352712,,,,0,0,0
1278047,Bayesian tensor approach for 3-D face modeling,2008,Dacheng Tao and Mingli Song and Xuelong Li and Jialie Shen and Jimeng Sun and Xindong Wu and Christos Faloutsos and Stephen J Maybank,18,IEEE Transactions on Circuits and Systems for Video Technology,10,1397-1410,IEEE,Effectively modeling a collection of three-dimensional (3-D) faces is an important task in various applications. especially facial expression-driven ones. e.g.. expression generation. retargeting. and synthesis. These 3-D faces naturally form a set of second-order tensors-one modality for identity and the other for expression. The number of these second-order tensors is three times of that of the vertices for 3-D face modeling. As for algorithms. Bayesian data modeling. which is a natural data analysis tool. has been widely applied with great success; however. it works only for vector data. Therefore. there is a gap between tensor-based representation and vector-based data analysis tools. Aiming at bridging this gap and generalizing conventional statistical tools over tensors. this paper proposes a decoupled probabilistic algorithm. which is named Bayesian tensor analysis (BTA). Theoretically. BTA can automatically and …,True,7oLbhAwAAAAJ:u-x6o8ySG0sC,120,https://ieeexplore.ieee.org/abstract/document/4633660/,15208304029207262603,/scholar?cites=15208304029207262603,,,http://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=1770&context=sis_research,0,0,0
1278048,Person re-identification by dual-regularized kiss metric learning,2016,Dapeng Tao and Yanan Guo and Mingli Song and Yaotang Li and Zhengtao Yu and Yuan Yan Tang,25,IEEE Transactions on Image Processing,6,2726-2738,IEEE,Person re-identification aims to match the images of pedestrians across different camera views from different locations. This is a challenging intelligent video surveillance problem that remains an active area of research due to the need for performance improvement. Person re-identification involves two main steps: feature representation and metric learning. Although the keep it simple and straightforward (KISS) metric learning method for discriminative distance metric learning has been shown to be effective for the person re-identification. the estimation of the inverse of a covariance matrix is unstable and indeed may not exist when the training set is small. resulting in poor performance. Here. we present dual-regularized KISS (DR-KISS) metric learning. By regularizing the two covariance matrices. DR-KISS improves on KISS by reducing overestimation of large eigenvalues of the two estimated covariance matrices …,True,7oLbhAwAAAAJ:NzUpm4bhSXQC,117,https://ieeexplore.ieee.org/abstract/document/7451215/,16001816367369005578,/scholar?cites=16001816367369005578,,,,0,0,0
1278049,Weakly supervised photo cropping,2013,Luming Zhang and Mingli Song and Yi Yang and Qi Zhao and Chen Zhao and Nicu Sebe,16,IEEE Transactions on Multimedia,1,94-107,IEEE,Photo cropping is widely used in the printing industry. photography. and cinematography. Conventional photo cropping methods suffer from three drawbacks: 1) the semantics used to describe photo aesthetics are determined by the experience of model designers and specific data sets. 2) image global configurations. an essential cue to capture photos aesthetics. are not well preserved in the cropped photo. and 3) multi-channel visual features from an image region contribute differently to human aesthetics. but state-of-the-art photo cropping methods cannot automatically weight them. Owing to the recent progress in image retrieval community. image-level semantics. i.e.. photo labels obtained without much human supervision. can be efficiently and effectively acquired. Thus. we propose weakly supervised photo cropping. where a manifold embedding algorithm is developed to incorporate image-level semantics …,True,7oLbhAwAAAAJ:p2g8aNsByqUC,116,https://ieeexplore.ieee.org/abstract/document/6644258/,14280459729788574952,/scholar?cites=14280459729788574952,,,http://disi.unitn.it/~sebe/publications/TMM-Jan14.pdf,0,0,0
1278050,Transductive unbiased embedding for zero-shot learning,2018,Jie Song and Chengchao Shen and Yezhou Yang and Yang Liu and Mingli Song,,,,1024-1033,,Most existing Zero-Shot Learning (ZSL) methods have the strong bias problem. in which instances of unseen (target) classes tend to be categorized as one of the seen (source) classes. So they yield poor performance after being deployed in the generalized ZSL settings. In this paper. we propose a straightforward yet effective method named Quasi-Fully Supervised Learning (QFSL) to alleviate the bias problem. Our method follows the way of transductive learning. which assumes that both the labeled source images and unlabeled target images are available for training. In the semantic embedding space. the labeled source images are mapped to several fixed points specified by the source categories. and the unlabeled target images are forced to be mapped to other points specified by the target categories. Experiments conducted on AwA2. CUB and SUN datasets demonstrate that our method outperforms existing state-of-the-art approaches by a huge margin of 9.3~ 24.5% following generalized ZSL settings. and by a large margin of 0.2~ 16.2% following conventional ZSL settings.,True,7oLbhAwAAAAJ:suENJ97mPqEC,115,http://openaccess.thecvf.com/content_cvpr_2018/html/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.html,5260697667959057370,/scholar?cites=5260697667959057370,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.pdf,0,0,0
1278051,Deep speech 2: End-to-end speech recognition in english and mandarin,2016,Dario Amodei and Sundaram Ananthanarayanan and Rishita Anubhai and Jingliang Bai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Qiang Cheng and Guoliang Chen and Jie Chen and Jingdong Chen and Zhijie Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Ke Ding and Niandong Du and Erich Elsen and Jesse Engel and Weiwei Fang and Linxi Fan and Christopher Fougner and Liang Gao and Caixia Gong and Awni Hannun and Tony Han and Lappi Johannes and Bing Jiang and Cai Ju and Billy Jun and Patrick LeGresley and Libby Lin and Junjie Liu and Yang Liu and Weigao Li and Xiangang Li and Dongpeng Ma and Sharan Narang and Andrew Ng and Sherjil Ozair and Yiping Peng and Ryan Prenger and Sheng Qian and Zongfeng Quan and Jonathan Raiman and Vinay Rao and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Kavya Srinet and Anuroop Sriram and Haiyuan Tang and Liliang Tang and Chong Wang and Jidong Wang and Kaifu Wang and Yi Wang and Zhijian Wang and Zhiqian Wang and Shuang Wu and Likai Wei and Bo Xiao and Wen Xie and Yan Xie and Dani Yogatama and Bin Yuan and Jun Zhan and Zhenyao Zhu,,,,173-182,PMLR,We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks. end-to-end learning allows us to handle a diverse variety of speech including noisy environments. accents and different languages. Key to our approach is our application of HPC techniques. enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result. in several cases. our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally. using a technique called Batch Dispatch with GPUs in the data center. we show that our system can be inexpensively deployed in an online setting. delivering low latency when serving users at scale.,True,pTvhQDQAAAAJ:ULOm3_A8WrAC,2028,http://proceedings.mlr.press/v48/amodei16.html,16030706496972570658,/scholar?cites=16030706496972570658,,,http://proceedings.mlr.press/v48/amodei16.html,0,0,0
1278052,Deep speech: Scaling up end-to-end speech recognition,2014,Awni Hannun and Carl Case and Jared Casper and Bryan Catanzaro and Greg Diamos and Erich Elsen and Ryan Prenger and Sanjeev Satheesh and Shubho Sengupta and Adam Coates and Andrew Y Ng,,arXiv preprint arXiv:1412.5567,,,,"We present a state-of-the-art speech recognition system developed using end-to-end deep learning. Our architecture is significantly simpler than traditional speech systems. which rely on laboriously engineered processing pipelines; these traditional systems also tend to perform poorly when used in noisy environments. In contrast. our system does not need hand-designed components to model background noise. reverberation. or speaker variation. but instead directly learns a function that is robust to such effects. We do not need a phoneme dictionary. nor even the concept of a"" phoneme."" Key to our approach is a well-optimized RNN training system that uses multiple GPUs. as well as a set of novel data synthesis techniques that allow us to efficiently obtain a large amount of varied data for training. Our system. called Deep Speech. outperforms previously published results on the widely studied Switchboard Hub5'00. achieving 16.0% error on the full test set. Deep Speech also handles challenging noisy environments better than widely used. state-of-the-art commercial speech systems.",True,pTvhQDQAAAAJ:Zph67rFs4hoC,1422,https://arxiv.org/abs/1412.5567,13646243124343983110,/scholar?cites=13646243124343983110,,,https://arxiv.org/pdf/1412.5567,0,0,0
1278053,Parallel prefix sum (scan) with CUDA,2007,Mark Harris and Shubhabrata Sengupta and John D Owens,3,GPU gems,39,851-876,,Parallel prefix sum. also known as parallel Scan. is a useful building block for many parallel algorithms including sorting and building data structures. In this document we introduce Scan and describe step-by-step how it can be implemented efficiently in NVIDIA CUDA. We start with a basic naïve algorithm and proceed through more advanced techniques to obtain best performance. We then explain how to scan arrays of arbitrary size that cannot be processed with a single block of threads.,True,pTvhQDQAAAAJ:u-x6o8ySG0sC,944,http://developer.download.nvidia.com/compute/cuda/2_2/sdk/website/projects/scan/doc/scan.pdf,6099036942573679152,/scholar?cites=6099036942573679152,,,http://developer.download.nvidia.com/compute/cuda/2_2/sdk/website/projects/scan/doc/scan.pdf,0,0,0
1278054,Scan primitives for GPU computing,2007,Shubhabrata Sengupta and Mark Harris and Yao Zhang and John D Owens,,,,,,The scan primitives are powerful. general-purpose data-parallel primitives that are building blocks for a broad range of applications. We describe GPU implementations of these primitives. specifically an efficient formulation and implementation of segmented scan. on NVIDIA GPUs using the CUDA API. Using the scan primitives. we show novel GPU implementations of quicksort and sparse matrix-vector multiply. and analyze the performance of the scan primitives. several sort algorithms that use the scan primitives. and a graphical shallow-water fluid simulation using the scan framework for a tridiagonal matrix solver.,True,pTvhQDQAAAAJ:u5HHmVD_uO8C,787,https://escholarship.org/uc/item/8051p6nd,18098657636247979535,/scholar?cites=18098657636247979535,,,https://escholarship.org/content/qt8051p6nd/qt8051p6nd.pdf,0,0,0
1278055,Fast BVH construction on GPUs,2009,Christian Lauterbach and Michael Garland and Shubhabrata Sengupta and David Luebke and Dinesh Manocha,28,Computer Graphics Forum,2,375-384,Blackwell Publishing Ltd,We present two novel parallel algorithms for rapidly constructing bounding volume hierarchies on manycore GPUs. The first uses a linear ordering derived from spatial Morton codes to build hierarchies extremely quickly and with high parallel scalability. The second is a top‐down approach that uses the surface area heuristic (SAH) to build hierarchies optimized for fast ray tracing. Both algorithms are combined into a hybrid algorithm that removes existing bottlenecks in the algorithm for GPU construction performance and scalability leading to significantly decreased build time. The resulting hierarchies are close in to optimized SAH hierarchies. but the construction process is substantially faster. leading to a significant net benefit when both construction and traversal cost are accounted for. Our preliminary results show that current GPU architectures can compete with CPU implementations of hierarchy construction …,True,pTvhQDQAAAAJ:9yKSN-GCB0IC,505,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01377.x,1405947048116619674,/scholar?cites=1405947048116619674,,,http://gamma-web.iacs.umd.edu/papers/documents/articles/2009/lauterbach09.pdf,0,0,0
1278056,Deep voice: Real-time neural text-to-speech,2017,Sercan Ö Arık and Mike Chrzanowski and Adam Coates and Gregory Diamos and Andrew Gibiansky and Yongguo Kang and Xian Li and John Miller and Andrew Ng and Jonathan Raiman and Shubho Sengupta and Mohammad Shoeybi,,,,195-204,PMLR,We present Deep Voice. a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries. a grapheme-to-phoneme conversion model. a phoneme duration prediction model. a fundamental frequency prediction model. and an audio synthesis model. For the segmentation model. we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model. we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component. our system is simpler and more flexible than traditional text-to-speech systems. where each component requires laborious feature engineering and extensive domain expertise. Finally. we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.,True,pTvhQDQAAAAJ:4DMP91E08xMC,387,http://proceedings.mlr.press/v70/arik17a.html,18296399576126585694,/scholar?cites=18296399576126585694,,,http://proceedings.mlr.press/v70/arik17a/arik17a.pdf,0,0,0
1278057,Glift: Generic. efficient. random-access GPU data structures,2006,Aaron E Lefohn and Shubhabrata Sengupta and Joe Kniss and Robert Strzodka and John D Owens,25,ACM Transactions on Graphics (TOG),1,60-99,ACM,This article presents Glift. an abstraction and generic template library for defining complex. random-access graphics processor (GPU) data structures. Like modern CPU data structure libraries. Glift enables GPU programmers to separate algorithms from data structure definitions; thereby greatly simplifying algorithmic development and enabling reusable and interchangeable data structures. We characterize a large body of previously published GPU data structures in terms of our abstraction and present several new GPU data structures. The structures. a stack. quadtree. and octree. are explained using simple Glift concepts and implemented using reusable Glift components. We also describe two applications of these structures not previously demonstrated on GPUs: adaptive shadow maps and octree three-dimensional paint. Last. we show that our example Glift data structures perform comparably to handwritten …,True,pTvhQDQAAAAJ:d1gkVwhDpl0C,221,https://dl.acm.org/doi/abs/10.1145/1122501.1122505,8783832016438181139,/scholar?cites=8783832016438181139,,,https://escholarship.org/content/qt6gc3x9w1/qt6gc3x9w1.pdf,0,0,0
1278058,Real-time parallel hashing on the GPU,2009,Dan A Alcantara and Andrei Sharf and Fatemeh Abbasinejad and Shubhabrata Sengupta and Michael Mitzenmacher and John D Owens and Nina Amenta,,,,1-9,,We demonstrate an efficient data-parallel algorithm for building large hash tables of millions of elements in real-time. We consider two parallel algorithms for the construction: a classical sparse perfect hashing approach. and cuckoo hashing. which packs elements densely by allowing an element to be stored in one of multiple possible locations. Our construction is a hybrid approach that uses both algorithms. We measure the construction time. access time. and memory usage of our implementations and demonstrate real-time performance on large datasets: for 5 million key-value pairs. we construct a hash table in 35.7 ms using 1.42 times as much memory as the input data itself. and we can access all the elements in that hash table in 15.3 ms. For comparison. sorting the same data requires 36.6 ms. but accessing all the elements via binary search requires 79.5 ms. Furthermore. we show how our hashing methods …,True,pTvhQDQAAAAJ:UeHWp8X0CEIC,220,https://dl.acm.org/doi/abs/10.1145/1661412.1618500,5136371726643231794,/scholar?cites=5136371726643231794,,,https://escholarship.org/content/qt445536d6/qt445536d6.pdf,0,0,0
1278059,Navigating the maze of graph analytics frameworks using massive graph datasets,2014,Nadathur Satish and Narayanan Sundaram and Md Mostofa Ali Patwary and Jiwon Seo and Jongsoo Park and M Amber Hassaan and Shubho Sengupta and Zhaoming Yin and Pradeep Dubey,,,,979-990,,"Graph algorithms are becoming increasingly important for analyzing large datasets in many fields. Real-world graph data follows a pattern of sparsity. that is not uniform but highly skewed towards a few items. Implementing graph traversal. statistics and machine learning algorithms on such data in a scalable manner is quite challenging. As a result. several graph analytics frameworks (GraphLab. CombBLAS. Giraph. SociaLite and Galois among others) have been developed. each offering a solution with different programming models and targeted at different users. Unfortunately. the"" Ninja performance gap"" between optimized code and most of these frameworks is very large (2-30X for most frameworks and up to 560X for Giraph) for common graph algorithms. and moreover varies widely with algorithms. This makes the end-users' choice of graph framework dependent not only on ease of use but also on …",True,pTvhQDQAAAAJ:_kc_bZDykSQC,207,https://dl.acm.org/doi/abs/10.1145/2588555.2610518,8082533910910124902,/scholar?cites=8082533910910124902,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.727.5426&rep=rep1&type=pdf,0,0,0
1278060,Efficient parallel scan algorithms for GPUs,2008,Shubhabrata Sengupta and Mark Harris and Michael Garland,1,"NVIDIA, Santa Clara, CA, Tech. Rep. NVR-2008-003",1,1-17,,Scan and segmented scan algorithms are crucial building blocks for a great many data-parallel algorithms. Segmented scan and related primitives also provide the necessary support for the flattening transform. which allows for nested data-parallel programs to be compiled into flat data-parallel languages. In this paper. we describe the design of efficient scan and segmented scan parallel primitives in CUDA for execution on GPUs. Our algorithms are designed using a divide-and-conquer approach that builds all scan primitives on top of a set of primitive intra-warp scan routines. We demonstrate that this design methodology results in routines that are simple. highly efficient. and free of irregular access patterns that lead to memory bank conflicts. These algorithms form the basis for current and upcoming releases of the widely used CUDPP library.,True,pTvhQDQAAAAJ:2osOgNQ5qMEC,183,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.163.847&rep=rep1&type=pdf,17681433241865929281,/scholar?cites=17681433241865929281,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.163.847&rep=rep1&type=pdf,0,0,0
1278061,Exploring sparsity in recurrent neural networks,2017,Sharan Narang and Erich Elsen and Gregory Diamos and Shubho Sengupta,,arXiv preprint arXiv:1704.05119,,,,Recurrent Neural Networks (RNN) are widely used to solve a variety of problems and as the quantity of data and the amount of available compute have increased. so have model sizes. The number of parameters in recent state-of-the-art networks makes them hard to deploy. especially on mobile phones and embedded devices. The challenge is due to both the size of the model and the time it takes to evaluate it. In order to deploy these RNNs efficiently. we propose a technique to reduce the parameters of a network by pruning weights during the initial training of the network. At the end of training. the parameters of the network are sparse while accuracy is still close to the original dense neural network. The network size is reduced by 8x and the time required to train the model remains constant. Additionally. we can prune a larger dense network to achieve better than baseline performance while still reducing the total number of parameters significantly. Pruning RNNs reduces the size of the model and can also help achieve significant inference time speed-up using sparse matrix multiply. Benchmarks show that using our technique model size can be reduced by 90% and speed-up is around 2x to 7x.,True,pTvhQDQAAAAJ:mVmsd5A6BfQC,182,https://arxiv.org/abs/1704.05119,15665014708787597981,/scholar?cites=15665014708787597981,,,https://arxiv.org/pdf/1704.05119,0,0,0
1278062,ZDOCK: An initial‐stage protein‐docking algorithm,2003,Rong Chen and Li Li and Zhiping Weng,52,"Proteins: Structure, Function, and Bioinformatics",1,80-87,Wiley Subscription Services. Inc.. A Wiley Company,The development of scoring functions is of great importance to protein docking. Here we present a new scoring function for the initial stage of unbound docking. It combines our recently developed pairwise shape complementarity with desolvation and electrostatics. We compare this scoring function with three other functions on a large benchmark of 49 nonredundant test cases and show its superior performance. especially for the antibody‐antigen category of test cases. For 44 test cases (90% of the benchmark). we can retain at least one near‐native structure within the top 2000 predictions at the 6° rotational sampling density. with an average of 52 near‐native structures per test case. The remaining five difficult test cases can be explained by a combination of poor binding affinity. large backbone conformational changes. and our algorithm's strong tendency for identifying large concave binding pockets. All four …,True,rSMPsx4AAAAJ:qUcmZB5y_30C,1362,https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.10389,9807787162184178409,/scholar?cites=9807787162184178409,,,https://www.academia.edu/download/48371800/zdock2.3.pdf,0,0,0
1278063,Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records.,2016,R Miotto and L Li and BA Kidd and JT. Dudley,6,Sci Rep.,,,,Secondary use of electronic health records (EHRs) promises to advance clinical research and better inform clinical decision making. Challenges in summarizing and representing patient data prevent widespread practice of predictive modeling using EHRs. Here we present a novel unsupervised deep feature learning method to derive a general-purpose patient representation from EHR data that facilitates clinical predictive modeling. In particular. a three-layer stack of denoising autoencoders was used to capture hierarchical regularities and dependencies in the aggregated EHRs of about 700.000 patients from the Mount Sinai data warehouse. The result is a representation we name “deep patient”. We evaluated this representation as broadly predictive of health states by assessing the probability of patients to develop various diseases. We performed evaluation using 76.214 test patients comprising 78 diseases …,True,rSMPsx4AAAAJ:anDooRL1HQEC,949,https://www.nature.com/articles/srep26094,7817832429417121675,/scholar?cites=7817832429417121675,,,https://www.nature.com/articles/srep26094,0,0,0
1278064,The MicroArray Quality Control (MAQC)-II study of common practices for the development and validation of microarray-based predictive models.,2010,Leming Shi and Gregory Campbell and Wendell D Jones and Fabien Campagne and Zhining Wen and Stephen J Walker and Zhenqiang Su and Tzu-Ming Chu and Federico M Goodsaid and Lajos Pusztai and JD Shaughnessy Jr and André Oberthuer and Russell S Thomas and Richard S Paules and Mark Fielden and Bart Barlogie and Weijie Chen and Pan Du and Matthias Fischer and Cesare Furlanello and Brandon D Gallas and Xijin Ge and Dalila B Megherbi and W Fraser Symmans and May D Wang and John Zhang and Hans Bitter and Benedikt Brors and Pierre R Bushel and Max Bylesjo and Minjun Chen and Jie Cheng and J Chou and TS Davison and M Delorenzi and Y Deng and V Devanarayan and DJ Dix and J Dopazo and KC Dorff and F Elloumi and J Fan and S Fan and X Fan and H Fang and N Gonzaludo and KR Hess and H Hong and J Huan and RA Irizarry and R Judson and D Juraeva and S Lababidi and CG Lambert and L Li and Y Li and Z Li and SM Lin and G Liu and EK Lobenhofer and J Luo and W Luo and MN McCall and Y Nikolsky and GA Pennello and RG Perkins and R Philip and V Popovici and ND Price and F Qian and A Scherer and T Shi and W Shi and J Sung and D Thierry-Mieg and J Thierry-Mieg and V Thodima and J Trygg and L Vishnuvajjala and SJ Wang and J Wu and Y Wu and Q Xie and WA Yousef and L Zhang and X Zhang and S Zhong and Y Zhou and S Zhu and D Arasappan and W Bao and AB Lucas and F Berthold and RJ Brennan and A Buness and JG Catalano and C Chang and R Chen and Y Cheng and J Cui and W Czika and F Demichelis and X Deng and D Dosymbekov and R Eils and Y Feng and J Fostel and S Fulmer-Smentek and JC Fuscoe and L Gatto and W Ge and DR Goldstein and L Guo and DN Halbert and J Han and SC Harris and C Hatzis and D Herman and J Huang and RV Jensen and R Jiang and CD Johnson and G Jurman and Y Kahlert and SA Khuder and M Kohl and J Li and M Li and QZ Li and S Li and J Liu and Y Liu and Z Liu and L Meng and M Madera and F Martinez-Murillo and I Medina and J Meehan and K Miclaus and RA Moffitt and D Montaner and P Mukherjee and GJ Mulligan and P Neville and T Nikolskaya and B Ning and GP Page and J Parker and RM Parry and X Peng,28,Nature biotechnology,8,827,,Gene expression data from microarrays are being applied to predict preclinical and clinical endpoints. but the reliability of these predictions has not been established. In the MAQC-II project. 36 independent teams analyzed six microarray data sets to generate predictive models for classifying a sample with respect to one of 13 endpoints indicative of lung or liver toxicity in rodents. or of breast cancer. multiple myeloma or neuroblastoma in humans. In total.> 30.000 models were built using many combinations of analytical methods. The teams generated predictive models without knowing the biological meaning of some of the endpoints and. to mimic clinical reality. tested the models on data that had not been used for training. We found that model performance depended largely on the endpoint and team proficiency and that different approaches generated models of similar performance. The conclusions and …,True,rSMPsx4AAAAJ:hFOr9nPyWt4C,700,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3315840/,1036758183145455714,/scholar?cites=1036758183145455714,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3315840/,0,0,0
1278065,A comprehensive assessment of RNA-seq accuracy. reproducibility and information content by the Sequencing Quality Control Consortium.,2014,SEQC/MAQC-III Consortium,32,Nat Biotechnol,9,903-914,,We present primary results from the Sequencing Quality Control (SEQC) project. coordinated by the United States Food and Drug Administration. Examining Illumina HiSeq. Life Technologies SOLiD and Roche 454 platforms at multiple laboratory sites using reference RNA samples with built-in controls. we assess RNA sequencing (RNA-seq) performance for junction discovery and differential expression profiling and compare it to microarray and quantitative PCR (qPCR) data using complementary metrics. At all sequencing depths. we discover unannotated exon-exon junctions. with> 80% validated by qPCR. We find that measurements of relative expression are accurate and reproducible across sites and platforms if specific filters are used. In contrast. RNA-seq and microarrays do not provide accurate absolute measurements. and gene-specific biases are observed. for these and qPCR. Measurement performance …,True,rSMPsx4AAAAJ:RJujIP1NYNUC,592,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321899/,11361128396247762313,/scholar?cites=11361128396247762313,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321899/,0,0,0
1278066,Identification of type 2 diabetes subgroups through topological analysis of patient similarity.,2015,Li Li and Cheng Wei-Yi and Ben Glicksberg and Gottesman Omri and Ronald Tamler and Rong Chen and Erwin Bottinger and Joel. Dudley,7,Sci Transl Med,311,,,Type 2 diabetes (T2D) is a heterogeneous complex disease affecting more than 29 million Americans alone with a rising prevalence trending toward steady increases in the coming decades. Thus. there is a pressing clinical need to improve early prevention and clinical management of T2D and its complications. Clinicians have understood that patients who carry the T2D diagnosis have a variety of phenotypes and susceptibilities to diabetes-related complications. We used a precision medicine approach to characterize the complexity of T2D patient populations based on high-dimensional electronic medical records (EMRs) and genotype data from 11.210 individuals. We successfully identified three distinct subgroups of T2D from topology-based patient-patient networks. Subtype 1 was characterized by T2D complications diabetic nephropathy and diabetic retinopathy; subtype 2 was enriched for cancer malignancy …,True,rSMPsx4AAAAJ:aNch6Af-aFkC,375,https://stm.sciencemag.org/content/7/311/311ra174.short,378358030854080492,/scholar?cites=378358030854080492,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4780757/,0,0,0
1278067,Identification of a peripheral blood transcriptional biomarker panel associated with operational renal allograft tolerance,2007,Sophie Brouard and Elaine Mansfield and Christophe Braud and Li Li and Magali Giral and Szu-chuan Hsieh and Dominique Baeten and Meixia Zhang and Joanna Ashton-Chess and Cécile Braudeau and Frank Hsieh and Alexandre Dupont and Annaik Pallier and Anne Moreau and Stéphanie Louis and Catherine Ruiz and Oscar Salvatierra and Jean-Paul Soulillou and Minnie Sarwal,104,Proceedings of the National Academy of Sciences,39,15448-15453,National Acad Sciences,Long-term allograft survival generally requires lifelong immunosuppression (IS). Rarely. recipients display spontaneous “operational tolerance” with stable graft function in the absence of IS. The lack of biological markers of this phenomenon precludes identification of potentially tolerant patients in which IS could be tapered and hinders the development of new tolerance-inducing strategies. The objective of this study was to identify minimally invasive blood biomarkers for operational tolerance and use these biomarkers to determine the frequency of this state in immunosuppressed patients with stable graft function. Blood gene expression profiles from 75 renal-transplant patient cohorts (operational tolerance/acute and chronic rejection/stable graft function on IS) and 16 healthy individuals were analyzed. A subset of samples was used for microarray analysis where three-class comparison of the different groups of …,True,rSMPsx4AAAAJ:u5HHmVD_uO8C,366,https://www.pnas.org/content/104/39/15448.short,14760182595980183675,/scholar?cites=14760182595980183675,,,https://www.pnas.org/content/pnas/104/39/15448.full.pdf,0,0,0
1278068,RDOCK: Refinement of rigid‐body protein docking predictions,2003,Li Li and Rong Chen and Zhiping Weng,53,"Proteins: Structure, Function, and Bioinformatics",3,693-707,Wiley Subscription Services. Inc.. A Wiley Company,We present a simple and effective algorithm RDOCK for refining unbound predictions generated by a rigid‐body docking algorithm ZDOCK. which has been developed earlier by our group. The main component of RDOCK is a three‐stage energy minimization scheme. followed by the evaluation of electrostatic and desolvation energies. Ionic side chains are kept neutral in the first two stages of minimization. and reverted to their full charge states in the last stage of brief minimization. Without side chain conformational search or filtering/clustering of resulting structures. RDOCK represents the simplest approach toward refining unbound docking predictions. Despite its simplicity. RDOCK makes substantial improvement upon the top predictions by ZDOCK with all three scoring functions and the improvement is observed across all three categories of test cases in a large benchmark of 49 non‐redundant unbound test …,True,rSMPsx4AAAAJ:hC7cP41nSMkC,332,https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.10460,6672810355174505816,/scholar?cites=6672810355174505816,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.547.1749&rep=rep1&type=pdf,0,0,0
1278069,A randomized. prospective trial of rituximab for acute rejection in pediatric renal transplantation,2008,V Zarkhin and L Li and N Kambham and T Sigdel and O Salvatierra and MM Sarwal,8,American Journal of Transplantation,12,2607-2617,Blackwell Publishing Inc, We report 1‐year outcomes of a randomized study of Rituximab versus standard‐of‐care immunosuppression (Thymoglobulin and/or pulse steroids) for treatment of biopsy confirmed. acute transplant rejection with B‐cell infiltrates. in 20 consecutive recipients (2–23 years). Graft biopsies. with Banff and CADI scores. CD20 and C4d stains. were performed at rejection and 1 and 6 months later. Peripheral blood CMV. EBV and BK viral loads. graft function. DSA. immunoglobulins. serum humanized antichimeric antibody (HACA) and Rituximab. and lymphocyte counts were monitored until 1 year posttreatment. Rituximab infusions were given with a high index of safety without HACA development and increased infections complications. Rituximab therapy resulted in complete tissue B‐cell depletion and rapid peripheral B‐cell depletion. Peripheral CD19 cells recovered at a mean time of ∼12 months. There were some …,True,rSMPsx4AAAAJ:9yKSN-GCB0IC,139,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1600-6143.2008.02411.x,16015713664015789526,/scholar?cites=16015713664015789526,,,https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1600-6143.2008.02411.x,0,0,0
1278070,Expression of complement components differs between kidney allografts from living and deceased donors,2009,Maarten Naesens and Li Li and Lihua Ying and Poonam Sansanwal and Tara K Sigdel and Szu-Chuan Hsieh and Neeraja Kambham and Evelyne Lerut and Oscar Salvatierra and Atul J Butte and Minnie M Sarwal,20,Journal of the American Society of Nephrology,8,1839-1851,American Society of Nephrology,A disparity remains between graft survival of renal allografts from deceased donors and from living donors. A better understanding of the molecular mechanisms that underlie this disparity may allow the development of targeted therapies to enhance graft survival. Here. we used microarrays to examine whole genome expression profiles using tissue from 53 human renal allograft protocol biopsies obtained both at implantation and after transplantation. The gene expression profiles of living-donor kidneys and pristine deceased-donor kidneys (normal histology. young age) were significantly different before reperfusion at implantation. Deceased-donor kidneys exhibited a significant increase in renal expression of complement genes; posttransplantation biopsies from well-functioning. nonrejecting kidneys. regardless of donor source. also demonstrated a significant increase in complement expression …,True,rSMPsx4AAAAJ:Y0pCki6q_DkC,134,https://jasn.asnjournals.org/content/20/8/1839.short,4405608577803590291,/scholar?cites=4405608577803590291,,,https://jasn.asnjournals.org/content/jnephrol/20/8/1839.full.pdf,0,0,0
1278071,Characterization of intra-graft B cells during renal allograft rejection,2008,Valeriya Zarkhin and Neeraja Kambham and Li Li and Shirley Kwok and Szu-Chuan Hsieh and Oscar Salvatierra and Minnie M Sarwal,74,Kidney international,5,664-673,Nature Publishing Group,Intra-graft CD20+ B-cell clusters are found during acute rejection of renal allografts and correlate with graft recovery following rejection injury. Here using archived kidney tissue we conducted immunohistochemical studies to measure specific subsets of pathogenic B cells during graft rejection. Cluster-forming CD20+ B cells in the rejected graft are likely derived from the recipient and are composed of mature B cells. These cells are activated (CD79a+). and present MHC Class II antigen (HLADR+) to CD4+ T cells. Some of these clusters contained memory B cells (CD27+) and they did not correlate with intra-graft C4d deposition or with detection of donor-specific antibody. Further. several non-cluster forming CD20− B-lineage CD38+ plasmablasts and plasma cells were found to infiltrate the rejected grafts and these cells strongly correlated with circulating donor-specific antibody. and to a lesser extent with intra-graft …,True,rSMPsx4AAAAJ:d1gkVwhDpl0C,133,https://www.sciencedirect.com/science/article/pii/S0085253815533723,15132549886183340979,/scholar?cites=15132549886183340979,,,https://www.sciencedirect.com/science/article/pii/S0085253815533723,0,0,0
1278072,AKI in hospitalized patients with COVID-19,2021,Lili Chan and Kumardeep Chaudhary and Aparna Saha and Kinsuk Chauhan and Akhil Vaid and Shan Zhao and Ishan Paranjpe and Sulaiman Somani and Felix Richter and Riccardo Miotto and Anuradha Lala and Arash Kia and Prem Timsina and Li Li and Robert Freeman and Rong Chen and Jagat Narula and Allan C Just and Carol Horowitz and Zahi Fayad and Carlos Cordon-Cardo and Eric Schadt and Matthew A Levin and David L Reich and Valentin Fuster and Barbara Murphy and John C He and Alexander W Charney and Erwin P Böttinger and Benjamin S Glicksberg and Steven G Coca and Girish N Nadkarni,32,Journal of the American Society of Nephrology,1,151-160,American Society of Nephrology,Early reports indicate that AKI is common among patients with coronavirus disease 2019 (COVID-19) and associated with worse outcomes. However. AKI among hospitalized patients with COVID-19 in the United States is not well described.This retrospective. observational study involved a review of data from electronic health records of patients aged ≥18 years with laboratory-confirmed COVID-19 admitted to the Mount Sinai Health System from February 27 to May 30. 2020. We describe the frequency of AKI and dialysis requirement. AKI recovery. and adjusted odds ratios (aORs) with mortality.Of 3993 hospitalized patients with COVID-19. AKI occurred in 1835 (46%) patients; 347 (19%) of the patients with AKI required dialysis. The proportions with stages 1. 2. or 3 AKI were 39%. 19%. and 42%. respectively. A total of 976 (24%) patients were admitted to intensive care. and 745 (76 …,True,rSMPsx4AAAAJ:AubyX3KqGToC,126,https://jasn.asnjournals.org/content/32/1/151.abstract,3834149631321160307,/scholar?cites=3834149631321160307,,,https://jasn.asnjournals.org/content/32/1/151.abstract,0,0,0
1278073,On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix,1985,Erkki Oja and Juha Karhunen,106,Journal of mathematical analysis and applications,1,69-84,Academic Press,In applications of signal processing and pattern recognition. eigenvectors and eigenvalues of the statistical mean of a random matrix sequence are needed. Iterative methods are suggested and analyzed. in which no sample moments are used. Convergence is shown by stochastic approximation theory.,True,Mu_v3sQAAAAJ:u-x6o8ySG0sC,667,https://www.sciencedirect.com/science/article/pii/0022247X85901313,16635234693347026971,/scholar?cites=16635234693347026971,,,https://www.sciencedirect.com/science/article/pii/0022247X85901313/pdf?md5=cca6f401b066164fa48ce04800abcd5c&pid=1-s2.0-0022247X85901313-main.pdf&_valck=1,0,0,0
1278074,A class of neural networks for independent component analysis,1997,Juha Karhunen and Erkki Oja and Liuyue Wang and Ricardo Vigario and Jyrki Joutsensalo,8,IEEE Transactions on neural networks,3,486-504,IEEE,Independent component analysis (ICA) is a recently developed. useful extension of standard principal component analysis (PCA). The ICA model is utilized mainly in blind separation of unknown source signals from their linear mixtures. In this application only the source signals which correspond to the coefficients of the ICA expansion are of interest. In this paper. we propose neural structures related to multilayer feedforward networks for performing complete ICA. The basic ICA network consists of whitening. separation. and basis vector estimation layers. It can be used for both blind source separation and estimation of the basis vectors of ICA. We consider learning algorithms for each layer. and modify our previous nonlinear PCA type algorithms so that their separation capabilities are greatly improved. The proposed class of networks yields good results in test examples with both artificial and real-world data.,True,Mu_v3sQAAAAJ:u5HHmVD_uO8C,610,https://ieeexplore.ieee.org/abstract/document/572090/,4099231783230964724,/scholar?cites=4099231783230964724,,,http://users.ics.aalto.fi/~juha/papers/Class_IEEETrNN-1997.pdf,0,0,0
1278075,Representation and separation of signals using nonlinear PCA type learning,1994,Juha Karhunen and Jyrki Joutsensalo,7,Neural networks,1,113-127,Pergamon,A class of nonlinear PCA (principal component analysis) type learning algorithms is derived by minimizing a general statistical signal representation error. Another related algorithm is derived from a nonlinear feature extraction criterion. Several known algorithms emerge as special cases of these optimization approaches that provide useful information on the properties of the algorithms. By taking into account higher-order statistics. nonlinear algorithms are often able to separate component signals from their mixture. This is not possible with linear principal component subspace estimation algorithms. A suitably chosen nonlinearity makes the results more robust against various types of noise. Estimation of noisy sinusoids is used as a demonstration example.,True,Mu_v3sQAAAAJ:d1gkVwhDpl0C,512,https://www.sciencedirect.com/science/article/pii/0893608094900604,16207038959297915118,/scholar?cites=16207038959297915118,,,http://users.ics.aalto.fi/~juha/papers/Representation_NN1994.pdf,0,0,0
1278076,Generalizations of principal component analysis. optimization problems. and neural networks,1995,Juha Karhunen and Jyrki Joutsensalo,8,Neural Networks,4,549-562,Pergamon,We derive and discuss various generalizations of neural PCA (Principal Component Analysis)-type learning algorithms containing nonlinearities using optimization-based approach. Standard PCA arises as an optimal solution to several different information representation problems. We justify that this is essentially due to the fact that the solution is based on the second-order statistics only. If the respective optimization problems are generalized for nonquadratic criteria so that higher-order statistics are taken into account. their solutions will in general be different. The solutions define in a natural way several meaningful extensions of PCA and give a solid foundation for them. In this framework. we study more closely generalizations of the problems of variance maximization and mean-square error minimization. For these problems. we derive gradient-type neural learning algorithms both for symmetric and hierarchic …,True,Mu_v3sQAAAAJ:9yKSN-GCB0IC,380,https://www.sciencedirect.com/science/article/pii/0893608094000987,11811611920224044192,/scholar?cites=11811611920224044192,,,https://users.ics.aalto.fi/juha/papers/Generalizations_NN_1995.pdf,0,0,0
1278077,Independent component analysis,2004,James V Stone,,A Bradford Book,,,,Finally. my intention has been to cut through the distracting issues that inevitably accompany any new method (eg. variants of independent component analysis methods that are smaller. faster. or cheaper). and to describe the essential core of independent component analysis in relation to a few intuitive examples. However. it must be acknowledged that there are a small number of variants of independent component analysis which. while not essential for understanding the principles of the method. are of considerable interest. and these are described briefly.,True,Mu_v3sQAAAAJ:0N-VGjzr574C,312,http://pzs.dstu.dp.ua/DataMining/ica/bibl/Stone.pdf,2931976008531929281,/scholar?cites=2931976008531929281,,,http://pzs.dstu.dp.ua/DataMining/ica/bibl/Stone.pdf,0,0,0
1278078,Advances in nonlinear blind source separation,2003,Christian Jutten and Juha Karhunen,,Proc. of the 4th Int. Symp. on Independent Component Analysis and Blind Signal Separation (ICA2003),,245-256,,In this paper. we briefly review recent advances in blind source separation (BSS) for nonlinear mixing models. After a general introduction to the nonlinear BSS and ICA (independent Component Analysis) problems. we discuss in more detail uniqueness issues. presenting some new results. A fundamental difficulty in the nonlinear BSS problem and even more so in the nonlinear ICA problem is that they are nonunique without extra constraints. which are often implemented by using a suitable regularization. Post-nonlinear mixtures are an important special case. where a nonlinearity is applied to linear mixtures. For such mixtures. the ambiguities are essentially the same as for the linear ICA or BSS problems. In the later part of this paper. various separation techniques proposed for post-nonlinear mixtures and general nonlinear mixtures are reviewed.,True,Mu_v3sQAAAAJ:IjCSPb-OGe4C,211,https://www.academia.edu/download/44633816/Advances_in_blind_source_separation_BSS20160411-3090-5yvccn.pdf,14174205138272608091,/scholar?cites=14174205138272608091,,,https://www.academia.edu/download/44633816/Advances_in_blind_source_separation_BSS20160411-3090-5yvccn.pdf,0,0,0
1278079,Nonlinear blind source separation by self-organizing maps,1996,Petteri Pajunen and Aapo Hyvärinen and Juha Karhunen,,,,,,In neural blind source separation most approaches have considered the linear source separation problem where the input data consist of unknown linear mixtures of unknown independent source signals. The solution is a linear transformation which makes the output vector components statistically independent. More generally we can consider nonlinear mixtures of sources. Then we can try to separate the sources by constructing mappings that make the components of the output vectors independent. We show that such a mapping can be approximately realized using self-organizing maps with rectangular map topology. We apply these mappings to the separation of nonlinear mixtures of sub-Gaussian sources.,True,Mu_v3sQAAAAJ:qjMakFHDy7sC,209,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.49.1069,17096972065778642110,/scholar?cites=17096972065778642110,,,,0,0,0
1278080,Neural approaches to independent component analysis and source separation.,1996,Juha Karhunen,96,ESANN,,249-266,,Independent Component Analysis (ICA) is a recently developed technique that in many cases characterizes the data in a natural way. The main application area of the linear ICA model is blind source separation. Here. unknown source signals are estimated from their unknown linear mixtures using the strong assumption that the sources are mutually independent. In practice. separation can be achieved by using suitable higher-order statistics or nonlinearities. Various neural approaches have recently been proposed for blind source separation and ICA. In this paper. these approaches and the respective learning algorithms are brie y reviewed. and some extensions of the basic ICA model are discussed.,True,Mu_v3sQAAAAJ:2osOgNQ5qMEC,207,https://www.researchgate.net/profile/Juha_Karhunen2/publication/2423880_Neural_Approaches_to_Independent_Component_Analysis_and_Source_Separation/links/0c96052133cae17507000000/Neural-Approaches-to-Independent-Component-Analysis-and-Source-Separation.pdf,11413485229949296198,/scholar?cites=11413485229949296198,,,https://www.researchgate.net/profile/Juha_Karhunen2/publication/2423880_Neural_Approaches_to_Independent_Component_Analysis_and_Source_Separation/links/0c96052133cae17507000000/Neural-Approaches-to-Independent-Component-Analysis-and-Source-Separation.pdf,0,0,0
1278081,An unsupervised ensemble learning method for nonlinear dynamic state-space models,2002,Harri Valpola and Juha Karhunen,14,Neural computation,11,2647-2692,MIT Press,A Bayesian ensemble learning method is introduced for unsupervised extraction of dynamic processes from noisy data. The data are assumed to be generated by an unknown nonlinear mapping from unknown factors. The dynamics of the factors are modeled using a nonlinear state-space model. The nonlinear mappings in the model are represented using multilayer perceptron networks. The proposed method is computationally demanding. but it allows the use of higher-dimensional nonlinear latent variable models than other existing approaches. Experiments with chaotic data show that the new method is able to blindly estimate the factors and the dynamic process that generated the data. It clearly outperforms currently available nonlinear prediction techniques in this very difficult test problem.,True,Mu_v3sQAAAAJ:Tyk-4Ss8FVUC,173,https://www.mitpressjournals.org/doi/abs/10.1162/089976602760408017,12225904767396553441,/scholar?cites=12225904767396553441,,,http://cis.legacy.ics.tkk.fi/projects/bayes/papers/files/Valpola02NC.pdf,0,0,0
1278082,Independent component analysis,2009,Aapo Hyvärinen and Jarmo Hurri and Patrik O Hoyer,,,,151-175,Springer. London,In this chapter. we discuss a statistical generative model called independent component analysis. It is basically a proper probabilistic formulation of the ideas underpinning sparse coding. It shows how sparse coding can be interpreted as providing a Bayesian prior. and answers some questions which were not properly answered in the sparse coding framework.,True,Mu_v3sQAAAAJ:Ri6SYOTghG4C,166,https://link.springer.com/chapter/10.1007/978-1-84882-491-1_7,920130877927565164,/scholar?cites=920130877927565164,,,http://videolectures.net/site/normal_dl/tag=30619/mlss05au_hyvarinen_ica_02.pdf,0,0,0
1278083,Applications of neural blind separation to signal and image processing,1997,Juha Karhunen and Aapo Hyvarinen and Ricardo Vigário and Jarmo Hurri and Erkki Oja,1,,,131-134,IEEE,In blind source separation one tries to separate statistically independent unknown source signals from their linear mixtures without knowing the mixing coefficients. Such techniques are currently studied actively both in statistical signal processing and unsupervised neural learning. We apply neural blind separation techniques developed in our laboratory to the extraction of features from natural images and to the separation of medical EEG signals. The new analysis method yields features that describe the underlying data better than for example classical principal component analysis. We discuss difficulties related with real-world applications of blind signal processing. too.,True,Mu_v3sQAAAAJ:Y0pCki6q_DkC,164,https://ieeexplore.ieee.org/abstract/document/599569/,13945287315615333640,/scholar?cites=13945287315615333640,,,https://www.academia.edu/download/44543596/Applications_of_neural_blind_separation_20160408-27347-1be20ld.pdf,0,0,0
1278084,Character-level convolutional networks for text classification,2015,Xiang Zhang and Junbo Zhao and Yann LeCun,,arXiv preprint arXiv:1509.01626,,,,This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words. n-grams and their TFIDF variants. and deep learning models such as word-based ConvNets and recurrent neural networks.,True,8ipao8MAAAAJ:u5HHmVD_uO8C,3163,https://arxiv.org/abs/1509.01626,5819400392657163601,/scholar?cites=5819400392657163601,,,https://arxiv.org/pdf/1509.01626.pdf?source=post_page---------------------------,0,0,0
1278085,End to end learning for self-driving cars,2016,A (All equal contribution) and Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba,,,,,,,True,8ipao8MAAAAJ:d1gkVwhDpl0C,2597,,9841425441326142274,/scholar?cites=9841425441326142274,,,,0,0,0
1278086,Energy-based generative adversarial network,2016,Junbo Zhao and Michael Mathieu and Yann LeCun,,,,,,"We introduce the"" Energy-based Generative Adversarial Network"" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs. a generator is seen as being trained to produce contrastive samples with minimal energies. while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them. we show one instantiation of EBGAN framework as using an auto-encoder architecture. with the energy being the reconstruction error. in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.",True,8ipao8MAAAAJ:2osOgNQ5qMEC,950,https://arxiv.org/abs/1609.03126,15426746467469595309,/scholar?cites=15426746467469595309,,,https://arxiv.org/pdf/1609.03126.pdf?source=post_page---------------------------,0,0,0
1278087,Disentangling factors of variation in deep representation using adversarial training,2016,Michael F Mathieu and Junbo Zhao and Aditya Ramesh and Pablo Sprechmann and Yann LeCun,,,,5041-5049,,We introduce a conditional generative model for learning to disentangle the hidden factors of variation within a set of labeled observations. and separate them into complementary codes. One code summarizes the specified factors of variation associated with the labels. The other summarizes the remaining unspecified variability. During training. the only available source of supervision comes from our ability to distinguish among different observations belonging to the same class. Examples of such observations include images of a set of labeled objects captured at different viewpoints. or recordings of set of speakers dictating multiple phrases. In both instances. the intra-class diversity is the source of the unspecified factors of variation: each object is observed at multiple viewpoints. and each speaker dictates multiple phrases. Learning to disentangle the specified factors from the unspecified ones becomes easier when strong supervision is possible. Suppose that during training. we have access to pairs of images. where each pair shows two different objects captured from the same viewpoint. This source of alignment allows us to solve our task using existing methods. However. labels for the unspecified factors are usually unavailable in realistic scenarios where data acquisition is not strictly controlled. We address the problem of disentanglement in this more general setting by combining deep convolutional autoencoders with a form of adversarial training. Both factors of variation are implicitly captured in the organization of the learned embedding space. and can be used for solving single-image analogies. Experimental results on synthetic and real …,True,8ipao8MAAAAJ:UeHWp8X0CEIC,353,https://arxiv.org/abs/1611.03383,9681778665663063227,/scholar?cites=9681778665663063227,,,https://arxiv.org/pdf/1611.03383,0,0,0
1278088,Stacked What-Where Auto-encoders,2016,Yann LeCun Junbo Zhao and Michael Mathieu and Ross Goroshin,,,,,,,True,8ipao8MAAAAJ:Y0pCki6q_DkC,265,,4259489367047739374,/scholar?cites=4259489367047739374,,,,0,0,0
1278089,Deep graph library: Towards efficient and scalable deep learning on graphs,2019,Minjie Wang and Lingfan Yu and Da Zheng and Quan Gan and Yu Gai and Zihao Ye and Mufei Li and Jinjing Zhou and Qi Huang and Chao Ma and Ziyue Huang and Qipeng Guo and Hao Zhang and Haibin Lin and Jake Zhao and Jinyang Li and Alexander Smola and Zheng Zhang,,,,,,Accelerating research in the emerging field of deep graph learning requires new tools. Such systems should support graph as the core abstraction and take care to maintain both forward (ie supporting new research ideas) and backward (ie integration with existing components) compatibility. In this paper. we present Deep Graph Library (DGL). DGL enables arbitrary message handling and mutation operators. flexible propagation rules. and is framework agnostic so as to leverage high-performance tensor. autograd operations. and other feature extraction modules already available in existing frameworks. DGL carefully handles the sparse and irregular graph structure. deals with graphs big and small which may change dynamically. fuses operations. and performs auto-batching. all to take advantages of modern hardware. DGL has been tested on a variety of models. including but not limited to the popular Graph …,True,8ipao8MAAAAJ:Zph67rFs4hoC,199,https://openreview.net/forum?id=q9RwOO-Ci5_,16907004441404067104,/scholar?cites=16907004441404067104,,,,0,0,0
1278090,Adversarially Regularized Autoencoders,2017,Junbo Zhao and Yoon Kim and Kelly Zhang and Alexander M Rush and Yann LeCun,,,,,,Deep latent variable models. trained using variational autoencoders or generative adversarial networks. are now a key technique for representation learning of continuous structures. However. applying similar methods to discrete structures. such as text sequences or discretized images. has proven to be more challenging. In this work. we propose a more flexible method for training deep latent variable models of discrete structures. Our approach is based on the recently proposed Wasserstein Autoencoder (WAE) which formalizes adversarial autoencoders as an optimal transport problem. We first extend this framework to model discrete sequences. and then further explore different learned priors targeting a controllable representation. Unlike many other latent variable generative models for text. this adversarially regularized autoencoder (ARAE) allows us to generate fluent textual outputs as well as perform manipulations in the latent space to induce change in the output space. Finally we show that the latent representation can be trained to perform unaligned textual style transfer. giving improvements both in automatic measures and human evaluation.,True,8ipao8MAAAAJ:Tyk-4Ss8FVUC,172,http://proceedings.mlr.press/v80/zhao18b.html,5024716526871945774,/scholar?cites=5024716526871945774,,,http://proceedings.mlr.press/v80/zhao18b/zhao18b.pdf,0,0,0
1278091,BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer,2019,Fei Sun and Jun Liu and Jian Wu and Changhua Pei and Xiao Lin and Wenwu Ou and Peng Jiang,,,,1441-1450,,Modeling users' dynamic preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks to encode users' historical interactions from left to right into hidden representations for making recommendations. Despite their effectiveness. we argue that such left-to-right unidirectional models are sub-optimal due to the limitations including:\begin enumerate*[label= series\itshape\alph*\upshape)]\item unidirectional architectures restrict the power of hidden representation in users' behavior sequences;\item they often assume a rigidly ordered sequence which is not always practical.\end enumerate* To address these limitations. we proposed a sequential recommendation model called BERT4Rec. which employs the deep bidirectional self-attention to model user behavior sequences. To avoid the information leakage and efficiently train …,True,8ipao8MAAAAJ:roLk4NBRz8UC,163,https://dl.acm.org/doi/abs/10.1145/3357384.3357895,12445250694030130078,/scholar?cites=12445250694030130078,,,https://arxiv.org/pdf/1904.06690,0,0,0
1278092,End to end learning for self-driving cars. arXiv 2016,2016,Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao,103,arXiv preprint arXiv:1604.07316,,,,,True,8ipao8MAAAAJ:8k81kl-MbHgC,94,http://scholar.google.com/scholar?cluster=437137459044025045&hl=en&oi=scholarr,437137459044025045,/scholar?cites=437137459044025045,,,,0,0,0
1278093,Levenshtein transformer,2019,Jiatao Gu and Changhan Wang and Jake Zhao,,arXiv preprint arXiv:1905.11006,,,,Modern neural sequence generation models are built to either generate tokens step-by-step from scratch or (iteratively) modify a sequence of tokens bounded by a fixed length. In this work. we develop Levenshtein Transformer. a new partially autoregressive model devised for more flexible and amenable sequence generation. Unlike previous approaches. the atomic operations of our model are insertion and deletion. The combination of them facilitates not only generation but also sequence refinement allowing dynamic length changes. We also propose a set of new training techniques dedicated at them. effectively exploiting one as the other's learning signal thanks to their complementary nature. Experiments applying the proposed model achieve comparable performance but much-improved efficiency on both generation (eg machine translation. text summarization) and refinement tasks (eg automatic post-editing). We further confirm the flexibility of our model by showing a Levenshtein Transformer trained by machine translation can straightforwardly be used for automatic post-editing.,True,8ipao8MAAAAJ:UebtZRa9Y70C,91,https://arxiv.org/abs/1905.11006,6969695107747166842,/scholar?cites=6969695107747166842,,,https://arxiv.org/pdf/1905.11006,0,0,0
1278094,Glomo: Unsupervised learning of transferable relational graphs,2018,Zhilin Yang and Jake Junbo Zhao and Bhuwan Dhingra and Kaiming He and William W Cohen and Ruslan Salakhutdinov and Yann LeCun,,,,8964-8975,,Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks. such as word embeddings in language and pretrained convolutional features in vision. However. these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (eg. words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering. natural language inference. sentiment analysis. and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings. ELMo embeddings. and task-specific RNN hidden units). or embedding-free units such as image pixels.,True,8ipao8MAAAAJ:LkGwnXOMwfcC,40,https://research.fb.com/wp-content/uploads/2019/06/GLoMo-Unsupervised-Learning-of-Transferable-Relational-Graphs.pdf,958782425356507244,/scholar?cites=958782425356507244,,,https://research.fb.com/wp-content/uploads/2019/06/GLoMo-Unsupervised-Learning-of-Transferable-Relational-Graphs.pdf,0,0,0
1278095,Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora,2009,Daniel Ramage and David Hall and Ramesh Nallapati and Christopher D Manning,,,,248-256,,A significant portion of the world’s text is tagged by readers on social bookmarking websites. Credit attribution is an inherent problem in these corpora because most pages have multiple tags. but the tags do not always apply with equal specificity across the whole document. Solving the credit attribution problem requires associating each word in a document with the most appropriate tags and vice versa. This paper introduces Labeled LDA. a topic model that constrains Latent Dirichlet Allocation by defining a one-to-one correspondence between LDA’s latent topics and user tags. This allows Labeled LDA to directly learn word-tag correspondences. We demonstrate Labeled LDA’s improved expressiveness over traditional LDA with visualizations of a corpus of tagged web pages from del. icio. us. Labeled LDA outperforms SVMs by more than 3 to 1 when extracting tag-specific document snippets. As a multi-label text classifier. our model is competitive with a discriminative baseline on a variety of datasets.,True,mZcPPW4AAAAJ:9yKSN-GCB0IC,1515,https://www.aclweb.org/anthology/D09-1026.pdf,7810445113832013291,/scholar?cites=7810445113832013291,,,https://www.aclweb.org/anthology/D09-1026.pdf,0,0,0
1278096,Abstractive text summarization using sequence-to-sequence rnns and beyond,2016,Ramesh Nallapati and Bowen Zhou and Caglar Gulcehre and Bing Xiang,,arXiv preprint arXiv:1602.06023,,,,In this work. we model abstractive text summarization using Attentional Encoder-Decoder Recurrent Neural Networks. and show that they achieve state-of-the-art performance on two different corpora. We propose several novel models that address critical problems in summarization that are not adequately modeled by the basic architecture. such as modeling key-words. capturing the hierarchy of sentence-to-word structure. and emitting words that are rare or unseen at training time. Our work shows that many of our proposed models contribute to further improvement in performance. We also propose a new dataset consisting of multi-sentence summaries. and establish performance benchmarks for further research.,True,mZcPPW4AAAAJ:r0BpntZqJG4C,1247,https://arxiv.org/abs/1602.06023,17503002498462524081,/scholar?cites=17503002498462524081,,,"https://arxiv.org/pdf/1602.06023.pdf,",0,0,0
1278097,Multi-instance multi-label learning for relation extraction,2012,Mihai Surdeanu and Julie Tibshirani and Ramesh Nallapati and Christopher D Manning,,,,455-465,,Distant supervision for relation extraction (RE)–gathering training data by aligning a database of facts with text–is an efficient approach to scale RE to thousands of different relations. However. this introduces a challenging learning scenario where the relation expressed by a pair of entities found in a sentence is unknown. For example. a sentence containing Balzac and France may express BornIn or Died. an unknown relation. or no relation at all. Because of this. traditional supervised learning. which assumes that each example is explicitly mapped to a label. is not appropriate. We propose a novel approach to multi-instance multi-label learning for RE. which jointly models all the instances of a pair of entities in text and all their labels using a graphical model with latent variables. Our model performs competitively on two difficult domains.,True,mZcPPW4AAAAJ:7PzlFSSx8tAC,691,https://www.aclweb.org/anthology/D12-1042.pdf,15564046182984763532,/scholar?cites=15564046182984763532,,,https://www.aclweb.org/anthology/D12-1042.pdf,0,0,0
1278098,Summarunner: A recurrent neural network based sequence model for extractive summarization of documents,2017,Ramesh Nallapati and Feifei Zhai and Bowen Zhou,31,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,We present SummaRuNNer. a Recurrent Neural Network (RNN) based sequence model for extractive summarization of documents and show that it achieves performance better than or comparable to state-of-the-art. Our model has the additional advantage of being very interpretable. since it allows visualization of its predictions broken up by abstract features such as information content. salience and novelty. Another novel contribution of our work is abstractive training of our extractive model that can train on human generated reference summaries alone. eliminating the need for sentence-level extractive labels.,True,mZcPPW4AAAAJ:iH-uZ7U-co4C,647,https://ojs.aaai.org/index.php/AAAI/article/view/10958,15743603261336170924,/scholar?cites=15743603261336170924,,,https://ojs.aaai.org/index.php/AAAI/article/download/10958/10817,0,0,0
1278099,Joint latent topic models for text and citations,2008,Ramesh M Nallapati and Amr Ahmed and Eric P Xing and William W Cohen,,,,542-550,,In this work. we address the problem of joint modeling of text and citations in the topic modeling framework. We present two different models called the Pairwise-Link-LDA and the Link-PLSA-LDA models.,True,mZcPPW4AAAAJ:d1gkVwhDpl0C,483,https://dl.acm.org/doi/abs/10.1145/1401890.1401957,4691435010373970274,/scholar?cites=4691435010373970274,,,http://www.cs.cmu.edu/~nmramesh/kdd.pdf,0,0,0
1278100,Pointing the unknown words,2016,Caglar Gulcehre and Sungjin Ahn and Ramesh Nallapati and Bowen Zhou and Yoshua Bengio,,arXiv preprint arXiv:1603.08148,,,,The problem of rare and unknown words is an important issue that can potentially influence the performance of many NLP systems. including both the traditional count-based and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence. and the other predicts a word in the shortlist vocabulary. At each time-step. the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context.~ We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known.~ We observe improvements on two tasks. neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model.,True,mZcPPW4AAAAJ:j3f4tGmQtD8C,447,https://arxiv.org/abs/1603.08148,8939912433163056499,/scholar?cites=8939912433163056499,,,https://arxiv.org/pdf/1603.08148,0,0,0
1278101,Discriminative models for information retrieval,2004,Ramesh Nallapati,,,,64-71,,Discriminative models have been preferred over generative models in many machine learning problems in the recent past owing to some of their attractive theoretical properties. In this paper. we explore the applicability of discriminative classifiers for IR. We have compared the performance of two popular discriminative models. namely the maximum entropy model and support vector machines with that of language modeling. the state-of-the-art generative model for IR. Our experiments on ad-hoc retrieval indicate that although maximum entropy is significantly worse than language models. support vector machines are on par with language models. We argue that the main reason to prefer SVMs over language models is their ability to learn arbitrary features automatically as demonstrated by our experiments on the home-page finding task of TREC-10.,True,mZcPPW4AAAAJ:u5HHmVD_uO8C,369,https://dl.acm.org/doi/abs/10.1145/1008992.1009006,11635503154850814424,/scholar?cites=11635503154850814424,,,https://core.ac.uk/download/pdf/206718416.pdf,0,0,0
1278102,Event threading within news topics,2004,Ramesh Nallapati and Ao Feng and Fuchun Peng and James Allan,,,,446-453,,With the overwhelming volume of online news available today. there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner. Previous research focused only on organizing news stories by their topics into a flat hierarchy. We believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly.,True,mZcPPW4AAAAJ:u-x6o8ySG0sC,312,https://dl.acm.org/doi/abs/10.1145/1031171.1031258,11435666706506209412,/scholar?cites=11435666706506209412,,,https://www.academia.edu/download/30740748/88.pdf,0,0,0
1278103,Conservation properties of unstructured staggered mesh schemes,2000,Blair Perot,159,Journal of Computational Physics,1,58-89,Academic Press,Classic Cartesian staggered mesh schemes have a number of attractive properties. They do not display spurious pressure modes and they have been shown to locally conserve. mass. momentum. kinetic energy. and circulation to machine precision. Recently. a number of generalizations of the staggered mesh approach have been proposed for unstructured (triangular or tetrahedral) meshes. These unstructured staggered mesh methods have been created to retain the attractive pressure aspects and mass conservation properties of the classic Cartesian mesh method. This work addresses the momentum. kinetic energy. and circulation conservation properties of unstructured staggered mesh methods. It is shown that with certain choices of the velocity interpolation. unstructured staggered mesh discretizations of the divergence form of the Navier–Stokes equations can conserve kinetic energy and momentum both …,True,mZcPPW4AAAAJ:Wp0gIr-vW9MC,297,https://www.sciencedirect.com/science/article/pii/S0021999100964246,2079584686333627117,/scholar?cites=2079584686333627117,,,https://pdfs.semanticscholar.org/28a4/5338e328179a3b684d1ab687b482ed56b36f.pdf,0,0,0
1278104,A comparative study of methods for transductive transfer learning,2007,Andrew Arnold and Ramesh Nallapati and William W Cohen,,,,77-82,IEEE,The problem of transfer learning. where information gained in one learning task is used to improve performance in another related task. is an important new area of research. While previous work has studied the supervised version of this problem. we study the more challenging case of unsupervised transductive transfer learning. where no labeled data from the target domain are available at training. We describe some current state-of-the-art inductive and transductive approaches and then adapt these models to the problem of transfer learning for protein name extraction. In the process. we introduce a novel maximum entropy based technique. iterative feature transformation (IFT). and show that it achieves comparable performance with state-of-the-art transductive SVMs. We also show how simple relaxations. such as providing additional information like the proportion of positive examples in the test data. can …,True,mZcPPW4AAAAJ:zYLM7Y9cAGgC,272,https://ieeexplore.ieee.org/abstract/document/4476649/,2216495401090174755,/scholar?cites=2216495401090174755,,,https://www.andrewoarnold.com/arnolda-transfer-icdm-long.pdf,0,0,0
1278105,Link-PLSA-LDA: A New Unsupervised Model for Topics and Influence of Blogs.,2008,Ramesh Nallapati and William W Cohen,,,,84-92,,In this work. we address the twin problems of unsupervised topic discovery and estimation of topic specific influence of blogs. We propose a new model that can be used to provide a user with highly influential blog postings on the topic of the user’s interest.We adopt the framework of an unsupervised model called Latent Dirichlet Allocation (Blei. Ng. & Jordan 2003). known for its effectiveness in topic discovery. An extension of this model. which we call Link-LDA (Erosheva. Fienberg. & Lafferty 2004). defines a generative model for hyperlinks and thereby models topic specific influence of documents. the problem of our interest. However. this model does not exploit the topical relationship between the documents on either side of a hyperlink. ie. the notion that documents tend to link to other documents on the same topic. We propose a new model. called Link-PLSA-LDA. that combines PLSA (Hoffman 1999) and LDA (Blei. Ng. & Jordan 2003) into a single framework. and explicitly models the topical relationship between the linking and the linked document. The output of the new model on blog data reveals very interesting visualizations of topics and influential blogs on each topic. We also perform quantitative evaluation of the model using log-likelihood of unseen data and on the task of link prediction. Both experiments show that that the new model performs better. suggesting its superiority over Link-LDA in modeling topics and topic specific influence of blogs.,True,mZcPPW4AAAAJ:UeHWp8X0CEIC,171,https://www.aaai.org/Papers/ICWSM/2008/ICWSM08-018.pdf,6865852857073220648,/scholar?cites=6865852857073220648,,,https://www.aaai.org/Papers/ICWSM/2008/ICWSM08-018.pdf,0,0,0
1278106,Convolutional neural network architectures for matching natural language sentences,2014,Baotian Hu and Zhengdong Lu and Hang Li and Qingcai Chen,,,,2042-2050,,Semantic matching is of central importance to many natural language tasks\cite {bordes2014semantic. RetrievalQA}. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal. we propose convolutional neural network models for matching two sentences. by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layer-by-layer composition and pooling. but also capture the rich matching patterns at different levels. Our models are rather generic. requiring no prior knowledge on language. and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demonstrates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models.,True,x5lXo2YAAAAJ:9yKSN-GCB0IC,1133,http://papers.nips.cc/paper/5550-distance-based-network-recovery-under-feature-correlation.pdf,14879863982425897304,/scholar?cites=14879863982425897304,,,http://papers.nips.cc/paper/5550-distance-based-network-recovery-under-feature-correlation.pdf,0,0,0
1278107,Incorporating copying mechanism in sequence-to-sequence learning,2016,Jiatao Gu and Zhengdong Lu and Hang Li and Victor OK Li,,arXiv preprint arXiv:1603.06393,,,,We address an important problem in sequence-to-sequence (Seq2Seq) learning referred to as copying. in which certain segments in the input sequence are selectively replicated in the output sequence. A similar phenomenon is observable in human language communication. For example. humans tend to repeat entity names or even long phrases in conversation. The challenge with regard to copying in Seq2Seq is that new machinery is needed to decide when to perform the operation. In this paper. we incorporate copying into neural network-based Seq2Seq learning and propose a new model called CopyNet with encoder-decoder structure. CopyNet can nicely integrate the regular way of word generation in the decoder with the new copying mechanism which can choose sub-sequences in the input sequence and put them at proper places in the output sequence. Our empirical study on both synthetic data sets and real world data sets demonstrates the efficacy of CopyNet. For example. CopyNet can outperform regular RNN-based model with remarkable margins on text summarization tasks.,True,x5lXo2YAAAAJ:4DMP91E08xMC,1019,https://arxiv.org/abs/1603.06393,6836221883265474919,/scholar?cites=6836221883265474919,,,https://arxiv.org/pdf/1603.06393,0,0,0
1278108,Neural responding machine for short-text conversation,2015,Lifeng Shang and Zhengdong Lu and Hang Li,,arXiv preprint arXiv:1503.02364,,,,We propose Neural Responding Machine (NRM). a neural network-based response generator for Short-Text Conversation. NRM takes the general encoder-decoder framework: it formalizes the generation of response as a decoding process based on the latent representation of the input text. while both encoding and decoding are realized with recurrent neural networks (RNN). The NRM is trained with a large amount of one-round conversation data collected from a microblogging service. Empirical study shows that NRM can generate grammatically correct and content-wise appropriate responses to over 75% of the input text. outperforming state-of-the-arts in the same setting. including retrieval-based and SMT-based models.,True,x5lXo2YAAAAJ:Y0pCki6q_DkC,935,https://arxiv.org/abs/1503.02364,5059354282047966578,/scholar?cites=5059354282047966578,,,https://arxiv.org/pdf/1503.02364,0,0,0
1278109,Modeling coverage for neural machine translation,2016,Zhaopeng Tu and Zhengdong Lu and Yang Liu and Xiaohua Liu and Hang Li,,arXiv preprint arXiv:1601.04811,,,,Attention mechanism has enhanced state-of-the-art Neural Machine Translation (NMT) by jointly learning to align and translate. It tends to ignore past alignment information. however. which often leads to over-translation and under-translation. To address this problem. we propose coverage-based NMT in this paper. We maintain a coverage vector to keep track of the attention history. The coverage vector is fed to the attention model to help adjust future attention. which lets NMT system to consider more about untranslated source words. Experiments show that the proposed approach significantly improves both translation quality and alignment quality over standard attention-based NMT.,True,x5lXo2YAAAAJ:aqlVkmm33-oC,546,https://arxiv.org/abs/1601.04811,894656013823838967,/scholar?cites=894656013823838967,,,https://arxiv.org/pdf/1601.04811,0,0,0
1278110,Multimodal convolutional neural networks for matching image and sentence,2015,Lin Ma and Zhengdong Lu and Lifeng Shang and Hang Li,,,,2623-2631,,In this paper. we propose multimodal convolutional neural networks (m-CNNs) for matching image and sentence. Our m-CNN provides an end-to-end framework with convolutional architectures to exploit image representation. word composition. and the matching relations between the two modalities. More specifically. it consists of one image CNN encoding the image content and one matching CNN modeling the joint representation of image and sentence. The matching CNN composes different semantic fragments from words and learns the inter-modal relations between image and the composed fragments at different levels. thus fully exploit the matching relations between image and sentence. Experimental results demonstrate that the proposed m-CNNs can effectively capture the information necessary for image and sentence matching. More specifically. our proposed m-CNNs significantly outperform the state-of-the-art approaches for bidirectional image and sentence retrieval on the Flickr8K and Flickr30K datasets.,True,x5lXo2YAAAAJ:hqOjcs7Dif8C,305,http://openaccess.thecvf.com/content_iccv_2015/html/Ma_Multimodal_Convolutional_Neural_ICCV_2015_paper.html,8242855245788745193,/scholar?cites=8242855245788745193,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Ma_Multimodal_Convolutional_Neural_ICCV_2015_paper.pdf,0,0,0
1278111,Clustering with multiple graphs,2009,Wei Tang and Zhengdong Lu and Inderjit S Dhillon,,,,1016-1021,IEEE,In graph-based learning models. entities are often represented as vertices in an undirected graph with weighted edges describing the relationships between entities. In many real-world applications. however. entities are often associated with relations of different types and/or from different sources. which can be well captured by multiple undirected graphs over the same set of vertices. How to exploit such multiple sources of information to make better inferences on entities remains an interesting open problem. In this paper. we focus on the problem of clustering the vertices based on multiple graphs in both unsupervised and semi-supervised settings. As one of our contributions. we propose Linked Matrix Factorization (LMF) as a novel way of fusing information from multiple graph sources. In LMF. each graph is approximated by matrix factorization with a graph-specific factor and a factor common to all graphs. where …,True,x5lXo2YAAAAJ:u-x6o8ySG0sC,295,https://ieeexplore.ieee.org/abstract/document/5360349/,2612989421770182529,/scholar?cites=2612989421770182529,,,https://core.ac.uk/download/pdf/190637215.pdf,0,0,0
1278112,Learning to answer questions from image using convolutional neural network,2016,Lin Ma and Zhengdong Lu and Hang Li,30,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,In this paper. we propose to employ the convolutional neural network (CNN) for the image question answering (QA) task. Our proposed CNN provides an end-to-end framework with convolutional architectures for learning not only the image and question representations. but also their inter-modal interactions to produce the answer. More specifically. our model consists of three CNNs: one image CNN to encode the image content. one sentence CNN to compose the words of the question. and one multimodal convolution layer to learn their joint representation for the classification in the space of candidate answer words. We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA datasets. which are two benchmark datasets for image QA. with the performances significantly outperforming the state-of-the-art.,True,x5lXo2YAAAAJ:ufrVoPGSRksC,262,https://ojs.aaai.org/index.php/AAAI/article/view/10442,15810845386202392485,/scholar?cites=15810845386202392485,,,https://ojs.aaai.org/index.php/AAAI/article/download/10442/10301,0,0,0
1278113,A deep architecture for matching short texts,2013,Zhengdong Lu and Hang Li,26,Advances in neural information processing systems,,1367-1375,,Many machine learning problems can be interpreted as learning for matching two types of objects (eg. images and captions. users and products. queries and documents. etc.). The matching level of two objects is usually measured as the inner product in a certain feature space. while the modeling effort focuses on mapping of objects from the original space to the feature space. This schema. although proven successful on a range of matching tasks. is insufficient for capturing the rich structure in the matching process of more complicated objects. In this paper. we propose a new deep architecture to more effectively model the complicated matching relations between two objects from heterogeneous domains. More specifically. we apply this model to matching tasks in natural language. eg. finding sensible responses for a tweet. or relevant answers to a given question. This new architecture naturally combines the localness and hierarchy intrinsic to the natural language problems. and therefore greatly improves upon the state-of-the-art models.,True,x5lXo2YAAAAJ:eQOLeE2rZwMC,222,http://hangli-hl.com/uploads/3/1/6/8/3168008/nips_2013.pdf,9706401483814083653,/scholar?cites=9706401483814083653,,,http://hangli-hl.com/uploads/3/1/6/8/3168008/nips_2013.pdf,0,0,0
1278114,An information retrieval approach to short text conversation,2014,Zongcheng Ji and Zhengdong Lu and Hang Li,,arXiv preprint arXiv:1408.6988,,,,"Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper. we address one of its key sub-problems. referred to as short text conversation. in which given a message from human. the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step. and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather"" intelligently"". when combined with a huge repository of conversation data from social media.",True,x5lXo2YAAAAJ:Zph67rFs4hoC,211,https://arxiv.org/abs/1408.6988,690543487409622269,/scholar?cites=690543487409622269,,,https://arxiv.org/pdf/1408.6988,0,0,0
1278115,Constrained spectral clustering through affinity propagation,2008,Zhengdong Lu and Miguel A Carreira-Perpinan,,,,1-8,IEEE,Pairwise constraints specify whether or not two samples should be in one cluster. Although it has been successful to incorporate them into traditional clustering methods. such as K-means. little progress has been made in combining them with spectral clustering. The major challenge in designing an effective constrained spectral clustering is a sensible combination of the scarce pairwise constraints with the original affinity matrix. We propose to combine the two sources of affinity by propagating the pairwise constraints information over the original affinity matrix. Our method has a Gaussian process interpretation and results in a closed-form expression for the new affinity matrix. Experiments show it outperforms state-of-the-art constrained clustering methods in getting good clusterings with fewer constraints. and yields good image segmentation with user-specified pairwise constraints.,True,x5lXo2YAAAAJ:u5HHmVD_uO8C,199,https://ieeexplore.ieee.org/abstract/document/4587451/,16477327230063693048,/scholar?cites=16477327230063693048,,,http://engr.case.edu/ray_soumya/mlrg/constrained_spectral_clustering_lu.cvpr08.pdf,0,0,0
1278116,Self-adaptive hierarchical sentence model,2015,Han Zhao and Zhengdong Lu and Pascal Poupart,,arXiv preprint arXiv:1504.05070,,,,The ability to accurately model a sentence at varying stages (eg. word-phrase-sentence) plays a central role in natural language processing. As an effort towards this goal we propose a self-adaptive hierarchical sentence model (AdaSent). AdaSent effectively forms a hierarchy of representations from words to phrases and then to sentences through recursive gated local composition of adjacent segments. We design a competitive mechanism (through gating networks) to allow the representations of the same sentence to be engaged in a particular learning task (eg. classification). therefore effectively mitigating the gradient vanishing problem persistent in other recursive models. Both qualitative and quantitative analysis shows that AdaSent can automatically form and select the representations suitable for the task at hand during training. yielding superior classification performance over competitor models on 5 benchmark data sets.,True,x5lXo2YAAAAJ:Se3iqnhoufwC,196,https://arxiv.org/abs/1504.05070,17759270433860780143,/scholar?cites=17759270433860780143,,,https://arxiv.org/pdf/1504.05070,0,0,0
1278117,Multi-messenger observations of a binary neutron star merger,2017,Benjamin P Abbott and S Bloemen and P Canizares and H Falcke and RP Fender and S Ghosh and P Groot and T Hinderer and JR Hörandel and PG Jonker and Z Kostrzewa-Rutkowska and G Nelemans and D Nichols and S Nissanke and P Schmidt and C Timmermans and AR van Vliet and AR Williamson,,,,,,On 2017 August 17 a binary neutron star coalescence candidate (later designated GW170817) with merger time 12: 41: 04 UTC was observed through gravitational waves by the Advanced LIGO and Advanced Virgo detectors. The Fermi Gamma-ray Burst Monitor independently detected a gamma-ray burst (GRB 170817A) with a time delay of 1.7 s~ with respect to the merger time. From the gravitational-wave signal. the source was initially localized to a sky region of 31 deg2 at a luminosity distance of 40 8 8-+ Mpc and with component masses consistent with neutron stars. The component masses were later measured to be in the range 0.86 to 2.26 M. An extensive observing campaign was launched across the electromagnetic spectrum leading to the discovery of a bright optical transient (SSS17a. now with the IAU identification of AT 2017gfo) in NGC 4993 (at 40 Mpc~) less than 11 hours after the merger by the …,True,SAzirToAAAAJ:p2g8aNsByqUC,2389,https://iopscience.iop.org/article/10.3847/2041-8213/aa91c9/meta,2461611103499596342,/scholar?cites=2461611103499596342,,,https://arxiv.org/pdf/1710.05833,0,0,0
1278118,Depth of maximum of air-shower profiles at the Pierre Auger Observatory. I. Measurements at energies above ,2014,Alexander Aab and P Abreu and MARCO Aglietta and EJ Ahn and I Al Samarai and Ivone Freire da Mota Albuquerque and I Allekotte and J Allen and P Allison and A Almela and J Alvarez Castillo and J Alvarez-Muniz and R Alves Batista and M Ambrosio and A Aminaei and L Anchordoqui and S Andringa and C Aramo and VM Aranda and F Arqueros and H Asorey and P Assis and J Aublin and M Ave and M Avenier and G Avila and N Awal and AM Badescu and KB Barber and J Baeuml and C Baus and JJ Beatty and KH Becker and JA Bellido and C Berat and Mario Edoardo Bertaina and X Bertou and PL Biermann and P Billoir and S Blaess and M Blanco and C Bleve and H Bluemer and M Boháčová and D Boncioli and C Bonifazi and Raffaella Bonino and N Borodai and J Brack and I Brancus and A Bridgeman and P Brogueira and WC Brown and P Buchholz and A Bueno and S Buitink and M Buscemi and KS Caballero-Mora and B Caccianiga and L Caccianiga and M Candusso and L Caramete and R Caruso and ANTONELLA Castellina and G Cataldi and L Cazon and Rosanna Cester and AG Chavez and Andrea Chiavassa and JA Chinellato and J Chudoba and M Cilmo and RW Clay and G Cocciolo and R Colalillo and A Coleman and L Collica and MR Coluccia and R Conceicao and F Contreras and MJ Cooper and A Cordier and S Coutu and CE Covault and J Cronin and A Curutiu and R Dallier and B Daniel and S Dasso and K Daumiller and BR Dawson and RM De Almeida and M De Domenico and SJ De Jong and JRT de Mello Neto and I De Mitri and J De Oliveira and V De Souza and L Del Peral and O Deligny and H Dembinski and N Dhital and C Di Giulio and A Di Matteo and JC Diaz and ML Díaz Castro and F Diogo and C Dobrigkeit and W Docters and JC D’Olivo and A Dorofeev and Q Dorosti Hasankiadeh and MT Dova and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and P Facal San Luis and H Falcke and K Fang and G Farrar and AC Fauth and N Fazzini and AP Ferguson and M Fernandes and B Fick and JM Figueira and A Filevich and A Filipčič and BD Fox and O Fratu and U Fröhlich and B Fuchs and T Fujii and R Gaior and B García and ST Garcia Roca and D Garcia-Gamez and D Garcia-Pinto and G Garilli and A Gascon Bravo and F Gate and H Gemmeke and PL Ghia and U Giaccari and M Giammarchi and M Giller,90,Physical Review D,12,122005,American Physical Society,We report a study of the distributions of the depth of maximum. X max. of extensive air-shower profiles with energies above 1 0 17.8 eV as observed with the fluorescence telescopes of the Pierre Auger Observatory. The analysis method for selecting a data sample with minimal sampling bias is described in detail as well as the experimental cross-checks and systematic uncertainties. Furthermore. we discuss the detector acceptance and the resolution of the X max measurement and provide parametrizations thereof as a function of energy. The energy dependence of the mean and standard deviation of the X max distributions are compared to air-shower simulations for different nuclear primaries and interpreted in terms of the mean and variance of the logarithmic mass distribution at the top of the atmosphere.,True,SAzirToAAAAJ:u-x6o8ySG0sC,429,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.90.122005,428436654746512107,/scholar?cites=428436654746512107,,,https://arxiv.org/pdf/1409.4809,0,0,0
1278119,Measurement of the Proton-Air Cross Section at  with the Pierre Auger Observatory,2012,Pedro Abreu and M Aglietta and EJ Ahn and Ivone Freire da Mota Albuquerque and D Allard and I Allekotte and J Allen and P Allison and A Almeda and J Alvarez Castillo and J Alvarez-Muñiz and M Ambrosio and A Aminaei and L Anchordoqui and S Andringa and T Antičić and C Aramo and E Arganda and F Arqueros and H Asorey and P Assis and J Aublin and M Ave and M Avenier and G Avila and T Bäcker and M Balzer and KB Barber and AF Barbosa and R Bardenet and SLC Barroso and B Baughman and J Bäuml and JJ Beatty and BR Becker and KH Becker and A Bellétoile and JA Bellido and S BenZvi and C Berat and X Bertou and PL Biermann and P Billoir and F Blanco and M Blanco and C Bleve and H Blümer and M Boháčová and D Boncioli and C Bonifazi and R Bonino and N Borodai and J Brack and P Brogueira and WC Brown and R Bruijn and P Buchholz and A Bueno and RE Burton and KS Caballero-Mora and L Caramete and R Caruso and A Castellina and O Catalano and G Cataldi and L Cazon and R Cester and J Chauvin and SH Cheng and A Chiavassa and JA Chinellato and J Chirinos Diaz and J Chudoba and RW Clay and MR Coluccia and R Conceição and F Contreras and H Cook and MJ Cooper and J Coppens and A Cordier and S Coutu and CE Covault and A Creusot and A Criss and J Cronin and A Curutiu and S Dagoret-Campagne and R Dallier and S Dasso and K Daumiller and BR Dawson and RM De Almeida and M De Domenico and C De Donato and SJ De Jong and G De La Vega and WJM de Mello Junior and JRT de Mello Neto and I De Mitri and V De Souza and KD De Vries and G Decerprit and L Del Peral and M Del Río and O Deligny and H Dembinski and N Dhital and C Di Giulio and ML Díaz Castro and PN Diep and C Dobrigkeit and W Docters and JC D’Olivo and PN Dong and A Dorofeev and JC Dos Anjos and MT Dova and D D’Urso and I Dutan and J Ebr and R Engel and M Erdmann and CO Escobar and J Espadanal and A Etchegoyen and P Facal San Luis and I Fajardo Tapia and H Falcke and G Farrar and AC Fauth and N Fazzini and AP Ferguson and A Ferrero and B Fick and A Filevich and A Filipčič and S Fliescher and CE Fracchiolla and ED Fraenkel and U Fröhlich and B Fuchs and R Gaior and RF Gamarra and S Gambetta and B García and D Garcia-Gamez and D Garcia-Pinto and A Gascon and H Gemmeke,109,Physical review letters,6,062002,American Physical Society,We report a measurement of the proton-air cross section for particle production at the center-of-mass energy per nucleon of 57 TeV. This is derived from the distribution of the depths of shower maxima observed with the Pierre Auger Observatory: systematic uncertainties are studied in detail. Analyzing the tail of the distribution of the shower maxima. a proton-air cross section of [505±22 (stat)− 36+ 28 (syst)] mb is found.,True,SAzirToAAAAJ:LkGwnXOMwfcC,328,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.109.062002,2202905696621146860,/scholar?cites=2202905696621146860,,,https://arxiv.org/pdf/1208.1520,0,0,0
1278120,Depth of maximum of air-shower profiles at the Pierre Auger Observatory. II. Composition implications,2014,A Aab and P Abreu and MARCO Aglietta and EJ Ahn and I Al Samarai and IFM Albuquerque and I Allekotte and J Allen and P Allison and A Almela and J Alvarez Castillo and J Alvarez-Muñiz and R Alves Batista and M Ambrosio and A Aminaei and L Anchordoqui and S Andringa and C Aramo and VM Aranda and F Arqueros and H Asorey and P Assis and J Aublin and M Ave and M Avenier and G Avila and N Awal and AM Badescu and KB Barber and J Bäuml and C Baus and JJ Beatty and KH Becker and JA Bellido and C Berat and ME Bertania and X Bertou and PL Biermann and P Billoir and S Blaess and M Blanco and C Bleve and H Blümer and M Boháčová and D Boncioli and C Bonifazi and Raffaella Bonino and N Borodai and J Brack and I Brancus and A Bridgeman and P Brogueira and WC Brown and P Buchholz and A Bueno and S Buitink and M Buscemi and KS Caballero-Mora and B Caccianiga and L Caccianiga and M Candusso and L Caramete and R Caruso and ANTONELLA Castellina and G Cataldi and L Cazon and Rosanna Cester and AG Chavez and Andrea Chiavassa and JA Chinellato and J Chudoba and M Cilmo and RW Clay and G Cocciolo and R Colalillo and A Coleman and L Collica and MR Coluccia and R Conceição and F Contreras and MJ Cooper and A Cordier and S Coutu and CE Covault and J Cronin and A Curutiu and R Dallier and B Daniel and S Dasso and K Daumiller and BR Dawson and RM De Almeida and M De Domenico and SJ De Jong and JRT de Mello Neto and I De Mitri and J De Oliveira and V De Souza and L Del Peral and O Deligny and H Dembinski and N Dhital and C Di Giulio and A Di Matteo and JC Diaz and ML Díaz Castro and F Diogo and C Dobrigkeit and W Docters and JC D’Olivo and A Dorofeev and Q Dorosti Hasankiadeh and MT Dova and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and P Facal San Luis and H Falcke and K Fang and G Farrar and AC Fauth and N Fazzini and AP Ferguson and M Fernandes and B Fick and JM Figueira and A Filevich and A Filipčič and BD Fox and O Fratu and U Fröhlich and B Fuchs and T Fuji and R Gaior and B García and ST Garcia Roca and D Garcia-Gamez and D Garcia-Pinto and G Garilli and A Gascon Bravo and F Gate and H Gemmeke and PL Ghia and U Giaccari and M Giammarchi and M Giller,90,Physical Review D,12,122006,American Physical Society,Using the data taken at the Pierre Auger Observatory between December 2004 and December 2012. we have examined the implications of the distributions of depths of atmospheric shower maximum (X max). using a hybrid technique. for composition and hadronic interaction models. We do this by fitting the distributions with predictions from a variety of hadronic interaction models for variations in the composition of the primary cosmic rays and examining the quality of the fit. Regardless of what interaction model is assumed. we find that our data are not well described by a mix of protons and iron nuclei over most of the energy range. Acceptable fits can be obtained when intermediate masses are included. and when this is done consistent results for the proton and iron-nuclei contributions can be found using the available models. We observe a strong energy dependence of the resulting proton fractions. and find no …,True,SAzirToAAAAJ:a0OBvERweLwC,326,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.90.122006,723801533738185668,/scholar?cites=723801533738185668,,,https://arxiv.org/pdf/1409.5083,0,0,0
1278121,Observation of a large-scale anisotropy in the arrival directions of cosmic rays above 8× 1018 eV,2017,Alexander Aab and Pedro Abreu and Marco Aglietta and Imen Al Samarai and IFM Albuquerque and Ingomar Allekotte and Alejandro Almela and J Alvarez Castillo and Jaime Alvarez-Muñiz and Gioacchino Alex Anastasi and Luis Anchordoqui and Belén Andrada and Sofia Andringa and Carla Aramo and Fernando Arqueros and Nicusor Arsene and H Asorey and Pedro Assis and Julien Aublin and Gualberto Avila and Alina Mihaela Badescu and Alexandru Balaceanu and Felicia Barbato and RJ Barreira Luz and JJ Beatty and Karl-Heinz Becker and Jose A Bellido and Corinne Berat and Mario Edoardo Bertaina and Xavier Bertou and PL Biermann and Pierre Billoir and Jonathan Biteau and Simon G Blaess and Alberto Blanco and Jiri Blazek and Carla Bleve and Martina Boháčová and Denise Boncioli and Carla Bonifazi and Nataliia Borodai and Ana Martina Botti and Jeffrey Brack and Iliana Brancus and Thomas Bretz and Ariel Bridgeman and Florian Lukas Briechle and Peter Buchholz and Antonio Bueno and Stijn Buitink and Mario Buscemi and Karen S Caballero-Mora and Lorenzo Caccianiga and A Cancio and Fabrizia Canfora and Laurentiu Caramete and Rossella Caruso and Antonella Castellina and Gabriella Cataldi and Lorenzo Cazon and Alan G Chavez and Jose Augusto Chinellato and Jiri Chudoba and Roger W Clay and Agustín Cobos and Roberta Colalillo and Alan Coleman and Laura Collica and Maria Rita Coluccia and Ruben Conceição and Giovanni Consolati and Fernando Contreras and Mathew J Cooper and Stephane Coutu and CE Covault and James Cronin and Stefano D’Amico and Bruno Daniel and Sergio Dasso and Kai Daumiller and Bruce R Dawson and Rogerio M de Almeida and Sijbrand J de Jong and Giuseppe De Mauro and JRT de Mello Neto and Ivan De Mitri and Jaime de Oliveira and Vitor de Souza and Joachim Debatin and Olivier Deligny and Claudio Di Giulio and Armando Di Matteo and ML Díaz Castro and Francisco Diogo and Carola Dobrigkeit and Juan Carlos D’Olivo and Qader Dorosti and RC Dos Anjos and Maria Teresa Dova and Andrej Dundovic and Jan Ebr and Ralph Engel and Martin Erdmann and Mona Erfani and Carlos O Escobar and João Espadanal and Alberto Etchegoyen and Heino Falcke and Glennys Farrar and AC Fauth and Norberto Fazzini and Francesco Fenu and Brian Fick and Juan Manuel Figueira and Andrej Filipčič and Octavian Fratu and Martín Miguel Freire and Toshihiro Fujii and Alan Fuster and Romain Gaior and Beatriz García and Diego Garcia-Pinto and Florian Gaté and Hartmut Gemmeke and Alexandru Gherghel-Lascu and Piera Luisa Ghia and Ugo Giaccari and Marco Giammarchi and Maria Giller and Dariusz Głas and Christian Glaser and Geraldina Golup and M Gómez Berisso and PF Gómez Vitale and Nicolás González and Alessio Gorgi and Peter Gorham and AF Grillo and Trent D Grubb and Fausto Guarino and GP Guedes and Matías Rolf Hampel and Patricia Hansen and Diego Harari and Thomas A Harrison and JL Harton and Andreas Haungs and Thomas Hebbeker and Dieter Heck and Philipp Heimann,357,Science,6357,1266-1270,American Association for the Advancement of Science,Cosmic rays are atomic nuclei arriving from outer space that reach the highest energies observed in nature. Clues to their origin come from studying the distribution of their arrival directions. Using 3 × 104 cosmic rays with energies above 8 × 1018 electron volts. recorded with the Pierre Auger Observatory from a total exposure of 76.800 km2 sr year. we determined the existence of anisotropy in arrival directions. The anisotropy. detected at more than a 5.2σ level of significance. can be described by a dipole with an amplitude of 6.5−0.9+1.3 percent toward right ascension αd = 100 ± 10 degrees and declination δd = −24−13+12 degrees. That direction indicates an extragalactic origin for these ultrahigh-energy particles.,True,SAzirToAAAAJ:7PzlFSSx8tAC,284,https://science.sciencemag.org/content/357/6357/1266.abstract,10673236251651763112,/scholar?cites=10673236251651763112,,,https://arxiv.org/pdf/1709.07321,0,0,0
1278122,Muons in air showers at the Pierre Auger Observatory: Mean number in highly inclined events,2015,Alexander Aab and P Abreu and MARCO Aglietta and EJ Ahn and I Al Samarai and IFM Albuquerque and I Allekotte and J Allen and P Allison and A Almela and J Alvarez Castillo and J Alvarez-Muñiz and R Alves Batista and M Ambrosio and A Aminaei and L Anchordoqui and S Andringa and C Aramo and VM Aranda and F Arqueros and H Asorey and P Assis and J Aublin and M Ave and M Avenier and G Avila and AM Badescu and KB Barber and J Bäuml and C Baus and JJ Beatty and KH Becker and JA Bellido and C Berat and Mario Edoardo Bertaina and X Bertou and PL Biermann and P Billoir and M Blanco and C Bleve and H Blümer and M Boháčová and D Boncioli and C Bonifazi and Raffaella Bonino and N Borodai and J Brack and I Brancus and P Brogueira and WC Brown and P Buchholz and A Bueno and S Buitink and M Buscemi and KS Caballero-Mora and B Caccianiga and L Caccianiga and M Candusso and L Caramete and R Caruso and ANTONELLA Castellina and G Cataldi and L Cazon and R Cester and AG Chavez and Andrea Chiavassa and JA Chinellato and J Chudoba and M Cilmo and RW Clay and G Cocciolo and R Colalillo and A Coleman and L Collica and MR Coluccia and R Conceição and F Contreras and MJ Cooper and A Cordier and S Coutu and CE Covault and J Cronin and A Curutiu and R Dallier and B Daniel and S Dasso and K Daumiller and BR Dawson and RM De Almeida and M De Domenico and SJ De Jong and JRT de Mello Neto and I De Mitri and J De Oliveira and V De Souza and L Del Peral and O Deligny and H Dembinski and N Dhital and C Di Giulio and A Di Matteo and JC Diaz and ML Díaz Castro and F Diogo and C Dobrigkeit and W Docters and JC D’Olivo and A Dorofeev and Q Dorosti Hasankiadeh and MT Dova and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and P Facal San Luis and H Falcke and K Fang and G Farrar and AC Fauth and N Fazzini and AP Ferguson and M Fernandes and B Fick and JM Figueira and A Filevich and A Filipčič and BD Fox and O Fratu and U Fröhlich and B Fuchs and T Fujii and R Gaior and B García and ST Garcia Roca and D Garcia-Gamez and D Garcia-Pinto and G Garilli and A Gascon Bravo and F Gate and H Gemmeke and PL Ghia and U Giaccari and M Giammarchi and M Giller and C Glaser and H Glass and M Gómez Berisso,91,Physical Review D,3,032003,American Physical Society,We present the first hybrid measurement of the average muon number in air showers at ultrahigh energies. initiated by cosmic rays with zenith angles between 62 and 80. The measurement is based on 174 hybrid events recorded simultaneously with the surface detector array and the fluorescence detector of the Pierre Auger Observatory. The muon number for each shower is derived by scaling a simulated reference profile of the lateral muon density distribution at the ground until it fits the data. A 10 19 eV shower with a zenith angle of 67. which arrives at the surface detector array at an altitude of 1450 m above sea level. contains on average (2.68±0.04±0.48 (sys))× 10 7 muons with energies larger than 0.3 GeV. The logarithmic gain d ln N μ/d ln E of muons with increasing energy between 4× 10 18 eV and 5× 10 19 eV is measured to be (1.029±0.024±0.030 (sys)).,True,SAzirToAAAAJ:pyW8ca7W8N0C,264,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.91.032003,3324830671523810657,/scholar?cites=3324830671523810657,,,https://arxiv.org/pdf/1408.1421,0,0,0
1278123,Searches for anisotropies in the arrival directions of the highest energy cosmic rays detected by the Pierre Auger Observatory,2015,Alexander Aab and P Abreu and MARCO Aglietta and EJ Ahn and I Al Samarai and IFM Albuquerque and I Allekotte and J Allen and P Allison and A Almela and J Alvarez Castillo and J Alvarez-Muniz and R Alves Batista and M Ambrosio and A Aminaei and L Anchordoqui and S Andringa and C Aramo and VM Aranda and F Arqueros and H Asorey and P Assis and J Aublin and M Ave and M Avenier and G Avila and N Awal and AM Badescu and KB Barber and J Bäuml and C Baus and JJ Beatty and KH Becker and JA Bellido and C Berat and Mario Edoardo Bertaina and X Bertou and PL Biermann and P Billoir and SG Blaess and M Blanco and C Bleve and H Blümer and M Boháčová and D Boncioli and C Bonifazi and Raffaella Bonino and N Borodai and J Brack and I Brancus and A Bridgeman and P Brogueira and WC Brown and P Buchholz and A Bueno and S Buitink and M Buscemi and KS Caballero-Mora and B Caccianiga and L Caccianiga and M Candusso and L Caramete and R Caruso and ANTONELLA Castellina and G Cataldi and L Cazon and R Cester and AG Chavez and Andrea Chiavassa and JA Chinellato and J Chudoba and M Cilmo and RW Clay and G Cocciolo and R Colalillo and A Coleman and L Collica and MR Coluccia and R Conceição and F Contreras and MJ Cooper and A Cordier and S Coutu and CE Covault and J Cronin and A Curutiu and R Dallier and B Daniel and S Dasso and K Daumiller and BR Dawson and RM De Almeida and M De Domenico and SJ De Jong and JRT de Mello Neto and I De Mitri and J De Oliveira and V De Souza and L Del Peral and O Deligny and H Dembinski and N Dhital and C Di Giulio and A Di Matteo and JC Diaz and ML Díaz Castro and F Diogo and C Dobrigkeit and W Docters and JC D’Olivo and A Dorofeev and Q Dorosti Hasankiadeh and MT Dova and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and P Facal San Luis and H Falcke and K Fang and G Farrar and AC Fauth and N Fazzini and AP Ferguson and M Fernandes and B Fick and JM Figueira and A Filevich and A Filipčič and BD Fox and O Fratu and MM Freire and U Fröhlich and B Fuchs and T Fujii and R Gaior and B García and D Garcia-Gamez and D Garcia-Pinto and G Garilli and A Gascon Bravo and F Gate and H Gemmeke and PL Ghia and U Giaccari and M Giammarchi and M Giller,804,The Astrophysical Journal,1,15,IOP Publishing,The American Astronomical Society (AAS). established in 1899 and based in Washington. DC. is the major organization of professional astronomers in North America. Its membership of about 7.000 individuals also includes physicists. mathematicians. geologists. engineers. and others whose research and educational interests lie within the broad spectrum of subjects comprising contemporary astronomy. The mission of the AAS is to enhance and share humanity's scientific understanding of the universe.,True,SAzirToAAAAJ:ufrVoPGSRksC,247,https://iopscience.iop.org/article/10.1088/0004-637X/804/1/15/meta,1933030099878153116,/scholar?cites=1933030099878153116,,,https://iopscience.iop.org/article/10.1088/0004-637X/804/1/15/pdf,0,0,0
1278124,Improved limit to the diffuse flux of ultrahigh energy neutrinos from the Pierre Auger Observatory,2015,Alexander Aab and Pedro Abreu and Marco Aglietta and Eun-Joo Ahn and I Al Samarai and IFM Albuquerque and Ingomar Allekotte and Patrick Allison and Alejandro Almela and J Alvarez Castillo and Jaime Alvarez-Muñiz and R Alves Batista and Michelangelo Ambrosio and Amin Aminaei and Luis Anchordoqui and Sofia Andringa and Carla Aramo and Victor Manuel Aranda and Fernando Arqueros and Nicusor Arsene and H Asorey and Pedro Assis and Julien Aublin and Maximo Ave and Michel Avenier and Gualberto Avila and Nafiun Awal and Alina Mihaela Badescu and Kerri B Barber and Julia Bäuml and Colin Baus and JJ Beatty and Karl Heinz Becker and Jose A Bellido and Corinne Berat and Mario Edoardo Bertaina and Xavier Bertou and PL Biermann and Pierre Billoir and Simon G Blaess and Alberto Blanco and Miguel Blanco and Carla Bleve and Hans Blümer and Martina Boháčová and Denise Boncioli and Carla Bonifazi and Nataliia Borodai and Jeffrey Brack and Iliana Brancus and Ariel Bridgeman and Pedro Brogueira and William C Brown and Peter Buchholz and Antonio Bueno and Stijn Buitink and Mario Buscemi and Karen S Caballero-Mora and Barbara Caccianiga and Lorenzo Caccianiga and Marina Candusso and Laurentiu Caramete and Rossella Caruso and Antonella Castellina and Gabriella Cataldi and Lorenzo Cazon and Rosanna Cester and Alan G Chavez and Andrea Chiavassa and Jose Augusto Chinellato and Jiri Chudoba and Marco Cilmo and Roger W Clay and Giuseppe Cocciolo and Roberta Colalillo and Alan Coleman and Laura Collica and Maria Rita Coluccia and Ruben Conceição and Fernando Contreras and Mathew J Cooper and Alain Cordier and Stephane Coutu and CE Covault and James Cronin and Richard Dallier and Bruno Daniel and Sergio Dasso and Kai Daumiller and Bruce R Dawson and Rogerio M de Almeida and Sijbrand J de Jong and Giuseppe De Mauro and JRT de Mello Neto and Ivan De Mitri and Jaime de Oliveira and Vitor de Souza and Luis del Peral and Olivier Deligny and H Dembinski and N Dhital and C Di Giulio and A Di Matteo and Johana Chirinos Diaz and ML Díaz Castro and F Diogo and C Dobrigkeit and W Docters and JC D’Olivo and A Dorofeev and Q Dorosti Hasankiadeh and MT Dova and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and H Falcke and K Fang and G Farrar and AC Fauth and N Fazzini and AP Ferguson and M Fernandes and B Fick and JM Figueira and A Filevich and A Filipčič and BD Fox and O Fratu and MM Freire and B Fuchs and T Fujii and B García and D Garcia-Pinto and F Gate and H Gemmeke and A Gherghel-Lascu and PL Ghia and U Giaccari and M Giammarchi and M Giller and D Głas and C Glaser and H Glass and G Golup and M Gómez Berisso and PF Gómez Vitale,91,Physical Review D,9,092008,American Physical Society,Neutrinos in the cosmic ray flux with energies near 1 EeV and above are detectable with the Surface Detector array (SD) of the Pierre Auger Observatory. We report here on searches through Auger data from 1 January 2004 until 20 June 2013. No neutrino candidates were found. yielding a limit to the diffuse flux of ultrahigh energy neutrinos that challenges the Waxman-Bahcall bound predictions. Neutrino identification is attempted using the broad time structure of the signals expected in the SD stations. and is efficiently done for neutrinos of all flavors interacting in the atmosphere at large zenith angles. as well as for “Earth-skimming” neutrino interactions in the case of tau neutrinos. In this paper the searches for downward-going neutrinos in the zenith angle bins 60–75 and 75–90 as well as for upward-going neutrinos. are combined to give a single limit. The 90% CL single-flavor limit to the diffuse flux of ultrahigh …,True,SAzirToAAAAJ:f2IySw72cVMC,222,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.91.092008,6221358303287359596,/scholar?cites=6221358303287359596,,,https://link.aps.org/pdf/10.1103/PhysRevD.91.092008,0,0,0
1278125,CRPropa 3—a public astrophysical simulation framework for propagating extraterrestrial ultra-high energy particles,2016,Rafael Alves Batista and Andrej Dundovic and Martin Erdmann and Karl-Heinz Kampert and Daniel Kuempel and Gero Mueller and Guenter Sigl and Arjen van Vliet and David Walz and Tobias Winchen,2016,Journal of Cosmology and Astroparticle Physics,05,038,IOP Publishing,We present the simulation framework CRPropa version 3 designed for efficient development of astrophysical predictions for ultra-high energy particles. Users can assemble modules of the most relevant propagation effects in galactic and extragalactic space. include their own physics modules with new features. and receive on output primary and secondary cosmic messengers including nuclei. neutrinos and photons. In extension to the propagation physics contained in a previous CRPropa version. the new version facilitates high-performance computing and comprises new physical features such as an interface for galactic propagation using lensing techniques. an improved photonuclear interaction calculation. and propagation in time dependent environments to take into account cosmic evolution effects in anisotropy studies and variable sources. First applications using highlighted features are presented as well.,True,SAzirToAAAAJ:3fE2CSJIrl8C,202,https://iopscience.iop.org/article/10.1088/1475-7516/2016/05/038/meta,5247964289493027520,/scholar?cites=5247964289493027520,,,https://iopscience.iop.org/article/10.1088/1475-7516/2016/05/038/pdf,0,0,0
1278126,Combined fit of spectrum and composition data as measured by the Pierre Auger Observatory,2017,Alexander Aab and P Abreu and MARCO Aglietta and Imen Al Samarai and IFM Albuquerque and I Allekotte and A Almela and J Alvarez Castillo and J Alvarez-Muñiz and GA Anastasi and L Anchordoqui and B Andrada and S Andringa and C Aramo and F Arqueros and N Arsene and H Asorey and P Assis and J Aublin and G Avila and AM Badescu and A Balaceanu and RJ Barreira Luz and JJ Beatty and KH Becker and JA Bellido and C Berat and ME Bertaina and X Bertou and PL Biermann and P Billoir and J Biteau and SG Blaess and A Blanco and J Blazek and C Bleve and M Boháčová and D Boncioli and C Bonifazi and N Borodai and AM Botti and J Brack and I Brancus and T Bretz and A Bridgeman and FL Briechle and P Buchholz and A Bueno and S Buitink and M Buscemi and KS Caballero-Mora and L Caccianiga and A Cancio and F Canfora and L Caramete and R Caruso and ANTONELLA Castellina and G Cataldi and L Cazon and AG Chavez and JA Chinellato and J Chudoba and RW Clay and R Colalillo and A Coleman and L Collica and MR Coluccia and R Conceição and F Contreras and MJ Cooper and S Coutu and CE Covault and J Cronin and S d'Amico and B Daniel and S Dasso and K Daumiller and BR Dawson and RM De Almeida and SJ De Jong and G De Mauro and JRT de Mello Neto and I De Mitri and J De Oliveira and V De Souza and J Debatin and O Deligny and C Di Giulio and A Di Matteo and ML Díaz Castro and F Diogo and C Dobrigkeit and JC d'Olivo and Q Dorosti and RC Dos Anjos and MT Dova and A Dundovic and J Ebr and R Engel and M Erdmann and M Erfani and CO Escobar and J Espadanal and A Etchegoyen and H Falcke and G Farrar and AC Fauth and N Fazzini and B Fick and JM Figueira and A Filipčič and O Fratu and MM Freire and T Fujii and A Fuster and R Gaior and B García and D Garcia-Pinto and F Gaté and H Gemmeke and A Gherghel-Lascu and PL Ghia and U Giaccari and M Giammarchi and M Giller and D Głas and C Glaser and G Golup and M Gómez Berisso and PF Gómez Vitale and N González and Alessio Gorgi and P Gorham and AF Grillo and TD Grubb and F Guarino and GP Guedes and MR Hampel and P Hansen and D Harari and TA Harrison and JL Harton and A Haungs and T Hebbeker and D Heck and P Heimann and AE Herve and GC Hill and C Hojvat and E Holt,2017,Journal of Cosmology and Astroparticle Physics,04,038,IOP Publishing,We present a combined fit of a simple astrophysical model of UHECR sources to both the energy spectrum and mass composition data measured by the Pierre Auger Observatory. The fit has been performed for energies above 5· 1018 eV. ie the region of the all-particle spectrum above the so-called “ankle” feature. The astrophysical model we adopted consists of identical sources uniformly distributed in a comoving volume. where nuclei are accelerated through a rigidity-dependent mechanism. The fit results suggest sources characterized by relatively low maximum injection energies. hard spectra and heavy chemical composition. We also show that uncertainties about physical quantities relevant to UHECR propagation and shower development have a non-negligible impact on the fit results.,True,SAzirToAAAAJ:hC7cP41nSMkC,191,https://iopscience.iop.org/article/10.1088/1475-7516/2017/04/038/meta,9710325157901199745,/scholar?cites=9710325157901199745,,,https://arxiv.org/pdf/1612.07155,0,0,0
1278127,An Indication of anisotropy in arrival directions of ultra-high-energy cosmic rays through comparison to the flux pattern of extragalactic gamma-ray sources,2018,Alexander Aab and Pedro Abreu and Marco Aglietta and IFM Albuquerque and Ingomar Allekotte and Alejandro Almela and J Alvarez Castillo and Jaime Alvarez-Muñiz and Gioacchino Alex Anastasi and Luis Anchordoqui and Belén Andrada and Sofia Andringa and Carla Aramo and Nicusor Arsene and H Asorey and Pedro Assis and Gualberto Avila and Alina Mihaela Badescu and Alexandru Balaceanu and Felicia Barbato and RJ Barreira Luz and JJ Beatty and Karl-Heinz Becker and Jose A Bellido and Corinne Berat and Mario Edoardo Bertaina and Xavier Bertou and PL Biermann and Jonathan Biteau and Simon G Blaess and Alberto Blanco and Jiri Blazek and Carla Bleve and Martina Boháčová and Carla Bonifazi and Nataliia Borodai and Ana Martina Botti and Jeffrey Brack and Iliana Brancus and Thomas Bretz and Ariel Bridgeman and Florian Lukas Briechle and Peter Buchholz and Antonio Bueno and Stijn Buitink and Mario Buscemi and Karen S Caballero-Mora and Lorenzo Caccianiga and A Cancio and Fabrizia Canfora and Rossella Caruso and Antonella Castellina and Fernando Catalani and Gabriella Cataldi and Lorenzo Cazon and Alan G Chavez and Jose Augusto Chinellato and Jiri Chudoba and Roger W Clay and AC Cobos Cerutti and Roberta Colalillo and Alan Coleman and Laura Collica and Maria Rita Coluccia and Ruben Conceição and Giovanni Consolati and Fernando Contreras and Mathew J Cooper and Stephane Coutu and CE Covault and James Cronin and Stefano D’Amico and Bruno Daniel and Sergio Dasso and Kai Daumiller and Bruce R Dawson and Rogerio M de Almeida and Sijbrand J de Jong and Giuseppe De Mauro and JRT de Mello Neto and Ivan De Mitri and Jaime de Oliveira and Vitor de Souza and Joachim Debatin and Olivier Deligny and ML Díaz Castro and Francisco Diogo and Carola Dobrigkeit and Juan Carlos D’Olivo and Qader Dorosti and RC Dos Anjos and Maria Teresa Dova and Andrej Dundovic and Jan Ebr and Ralph Engel and Martin Erdmann and Mona Erfani and Carlos O Escobar and João Espadanal and Alberto Etchegoyen and Heino Falcke and John Farmer and Glennys Farrar and AC Fauth and Norberto Fazzini and Francesco Fenu and Brian Fick and Juan Manuel Figueira and Andrej Filipčič and Martín Miguel Freire and Toshihiro Fujii and Alan Fuster and Romain Gaïor and Beatriz García and F Gaté and H Gemmeke and A Gherghel-Lascu and PL Ghia and U Giaccari and M Giammarchi and M Giller and D Głas and C Glaser and G Golup and M Gómez Berisso and PF Gómez Vitale and N González and Alessio Gorgi and AF Grillo and TD Grubb and F Guarino and GP Guedes and R Halliday and MR Hampel and P Hansen and D Harari and TA Harrison and A Haungs and T Hebbeker and D Heck and P Heimann and AE Herve and GC Hill and C Hojvat and E Holt and P Homola and JR Hörandel and P Horvath and M Hrabovský and T Huege,853,The Astrophysical Journal Letters,2,L29,IOP Publishing,A new analysis of the data set from the Pierre Auger Observatory provides evidence for anisotropy in the arrival directions of ultra-high-energy cosmic rays on an intermediate angular scale. which is indicative of excess arrivals from strong. nearby sources. The data consist of 5514 events above 20 EeV with zenith angles up to 80 recorded before 2017 April 30. Sky models have been created for two distinct populations of extragalactic gamma-ray emitters: active galactic nuclei from the second catalog of hard Fermi-LAT sources (2FHL) and starburst galaxies from a sample that was examined with Fermi-LAT. Flux-limited samples. which include all types of galaxies from the Swift-BAT and 2MASS surveys. have been investigated for comparison. The sky model of cosmic-ray density constructed using each catalog has two free parameters. the fraction of events correlating with astrophysical objects. and an angular …,True,SAzirToAAAAJ:M3NEmzRMIkIC,145,https://iopscience.iop.org/article/10.3847/2041-8213/aaa66d/meta,15430386398318332178,/scholar?cites=15430386398318332178,,,https://iopscience.iop.org/article/10.3847/2041-8213/aaa66d/pdf,0,0,0
1278128,Galileo magnetometer measurements: A stronger case for a subsurface ocean at Europa,2000,Margaret G Kivelson and Krishan K Khurana and Christopher T Russell and Martin Volwerk and Raymond J Walker and Christophe Zimmer,289,Science,5483,1340-1343,American Association for the Advancement of Science,On 3 January 2000. the Galileo spacecraft passed close to Europa when it was located far south of Jupiter9s magnetic equator in a region where the radial component of the magnetospheric magnetic field points inward toward Jupiter. This pass with a previously unexamined orientation of the external forcing field distinguished between an induced and a permanent magnetic dipole moment model of Europa9s internal field. The Galileo magnetometer measured changes in the magnetic field predicted if a current-carrying outer shell. such as a planet-scale liquid ocean. is present beneath the icy surface. The evidence that Europa9s field varies temporally strengthens the argument that a liquid ocean exists beneath the present-day surface.,True,cPAja4UAAAAJ:u5HHmVD_uO8C,568,https://science.sciencemag.org/content/289/5483/1340.abstract,12329863168891639361,/scholar?cites=12329863168891639361,,,https://pdfs.semanticscholar.org/c959/3eef8efb22f44976dfe9a832caef1dcb9ae5.pdf,0,0,0
1278129,SAGA interacting factors confine sub-diffusion of transcribed genes to the nuclear envelope,2006,Ghislain G Cabal and Auguste Genovesio and Susana Rodriguez-Navarro and Christophe Zimmer and Olivier Gadal and Annick Lesne and Henri Buc and Frank Feuerbach-Fournier and Jean-Christophe Olivo-Marin and Eduard C Hurt and Ulf Nehrbass,441,Nature,7094,770-773,Nature Publishing Group,Changes in the transcriptional state of genes have been correlated with their repositioning within the nuclear space 1. Tethering reporter genes to the nuclear envelope alone can impose repression 2 and recent reports have shown that. after activation. certain genes can also be found closer to the nuclear periphery 3. 4. 5. 6. The molecular mechanisms underlying these phenomena have remained elusive. Here. with the use of dynamic three-dimensional tracking of a single locus in live yeast (Saccharomyces cerevisiae) cells. we show that the activation of GAL genes (GAL7. GAL10 and GAL1) leads to a confinement in dynamic motility. We demonstrate that the GAL locus is subject to sub-diffusive movement. which after activation can become constrained to a two-dimensional sliding motion along the nuclear envelope. RNA-fluorescence in situ hybridization analysis after activation reveals a higher transcriptional …,True,cPAja4UAAAAJ:u-x6o8ySG0sC,470,https://www.nature.com/articles/nature04752,1262135480491611933,/scholar?cites=1262135480491611933,,,https://www.researchgate.net/profile/Susana_Rodriguez-Navarro/publication/7022230_SAGA_interacting_factors_confine_sub-diffusion_of_transcribed_genes_to_the_nuclear_envelope/links/0912f5089a07fca4bf000000.pdf,0,0,0
1278130,Richardson–Lucy algorithm with total variation regularization for 3D confocal microscope deconvolution,2006,Nicolas Dey and Laure Blanc‐Feraud and Christophe Zimmer and Pascal Roux and Zvi Kam and Jean‐Christophe Olivo‐Marin and Josiane Zerubia,69,Microscopy research and technique,4,260-266,Wiley Subscription Services. Inc.. A Wiley Company,Confocal laser scanning microscopy is a powerful and popular technique for 3D imaging of biological specimens. Although confocal microscopy images are much sharper than standard epifluorescence ones. they are still degraded by residual out‐of‐focus light and by Poisson noise due to photon‐limited detection. Several deconvolution methods have been proposed to reduce these degradations. including the Richardson–Lucy iterative algorithm. which computes maximum likelihood estimation adapted to Poisson statistics. As this algorithm tends to amplify noise. regularization constraints based on some prior knowledge on the data have to be applied to stabilize the solution. Here. we propose to combine the Richardson–Lucy algorithm with a regularization constraint based on Total Variation. which suppresses unstable oscillations while preserving object edges. We show on simulated and real images that this …,True,cPAja4UAAAAJ:qjMakFHDy7sC,419,https://onlinelibrary.wiley.com/doi/abs/10.1002/jemt.20294,17979853337572302552,/scholar?cites=17979853337572302552,,,https://www.academia.edu/download/47558581/Richardson-Lucy_algorithm_with_total_var20160727-27439-1mtnljf.pdf,0,0,0
1278131,QuickPALM: 3D real-time photoactivation nanoscopy image processing in ImageJ,2010,Ricardo Henriques and Mickael Lelek and Eugenio F Fornasiero and Flavia Valtorta and Christophe Zimmer and Musa M Mhlanga,7,Nature methods,5,339-340,Nature Publishing Group,To the Editor: Although conventional microscopes have a resolution limited by diffraction to about half the wavelength of light. several recent advances have led to microscopy methods that achieve roughly tenfold improvements in resolution. Among them. photoactivated light microscopy (PALM) and stochastic optical resolution microscopy (STORM) have become particularly popular. as they only require relatively simple and affordable modifications to a standard total internal reflection fluorescence (TIRF) microscope1–3 and have been extended to three-dimensional (3D) super-resolution and multicolor imaging4. 5. PALM and STORM achieve super-resolution by sequentially imaging sparse subsets of photoswitchable molecules. Positions of individual molecules are computed from individual low-resolution images with subdiffraction accuracy. These positions are then corrected for drifts and subsequently …,True,cPAja4UAAAAJ:0EnyYjriUFMC,412,https://www.nature.com/articles/nmeth0510-339,1412682450072191801,/scholar?cites=1412682450072191801,,,,0,0,0
1278132,Segmentation and tracking of migrating cells in videomicroscopy with parametric active contours: A tool for cell-based drug testing,2002,Christophe Zimmer and Elisabeth Labruyere and Vannary Meas-Yedid and Nancy Guillén and J-C Olivo-Marin,21,IEEE transactions on medical imaging,10,1212-1221,IEEE,This paper presents a segmentation and tracking method for quantitative analysis of cell dynamics from in vitro videomicroscopy data. The method is based on parametric active contours and includes several adaptations that address important difficulties of cellular imaging. particularly the presence of low-contrast boundary deformations known as pseudopods. and the occurence of multiple contacts between cells. First. we use an edge map based on the average intensity dispersion that takes advantage of relative background homogeneity to facilitate the detection of both pseudopods and interfaces between adjacent cells. Second. we introduce a repulsive interaction between contours that allows correct segmentation of objects in contact and overcomes the shortcomings of previously reported techniques to enforce contour separation. Our tracking technique was validated on a realistic data set by comparison with …,True,cPAja4UAAAAJ:d1gkVwhDpl0C,369,https://ieeexplore.ieee.org/abstract/document/1174099/,335261733792042795,/scholar?cites=335261733792042795,,,https://www.researchgate.net/profile/Elisabeth_Labruyere2/publication/10900776_Segmentation_and_tracking_of_migrating_cells_in_Videomirco-scopy_with_parametric_active_controus_a_tool_for_cell-based_drug_testing/links/0046352a0462c467e7000000.pdf,0,0,0
1278133,Segmenting and tracking fluorescent cells in dynamic 3-D microscopy with coupled active surfaces,2005,Alexandre Dufour and Vasily Shinin and Shahragim Tajbakhsh and Nancy Guillén-Aghion and J-C Olivo-Marin and Christophe Zimmer,14,IEEE Transactions on Image Processing,9,1396-1410,IEEE,Cell migrations and deformations play essential roles in biological processes. such as parasite invasion. immune response. embryonic development. and cancer. We describe a fully automatic segmentation and tracking method designed to enable quantitative analyses of cellular shape and motion from dynamic three-dimensional microscopy data. The method uses multiple active surfaces with or without edges. coupled by a penalty for overlaps. and a volume conservation constraint that improves outlining of cell/cell boundaries. Its main advantages are robustness to low signal-to-noise ratios and the ability to handle multiple cells that may touch. divide. enter. or leave the observation volume. We give quantitative validation results based on synthetic images and show two examples of applications to real biological data.,True,cPAja4UAAAAJ:2osOgNQ5qMEC,361,https://ieeexplore.ieee.org/abstract/document/1495511/,17344912779336409001,/scholar?cites=17344912779336409001,,,https://www.researchgate.net/profile/Alexandre_Dufour/publication/7575006_Segmenting_and_tracking_fluorescent_cells_in_dynamic_3-D_microscopy_with_coupled_active_surfaces/links/0912f5097d85bc10a9000000.pdf,0,0,0
1278134,Subsurface oceans on Europa and Callisto: Constraints from Galileo magnetometer observations,2000,Christophe Zimmer and Krishan K Khurana and Margaret G Kivelson,147,Icarus,2,329-347,Academic Press,Magnetic field perturbations measured during Galileo flybys of Europa and Callisto are consistent with dipole fields induced by the temporal variations of the ambient jovian magnetospheric field. These fields are close to those expected for perfectly conducting moons. We investigate the implications of these observations for the electrical structure of the moon's interiors using a simple shell model. It is found that Europa and Callisto must possess regions where the conductivity exceeds 0.06 and 0.02 S/m at a depth of less than 200 and 300 km below the surface. respectively. This conductivity is unattainable in ice or silicates. unless the ice layer is at least partially molten or very large temperature gradients can be maintained below the ice. An ionosphere or a cloud of pick-up ions are probably also insufficiently conductive. Global Earth-like oceans under the surface of both moons could account for the observations …,True,cPAja4UAAAAJ:9yKSN-GCB0IC,352,https://www.sciencedirect.com/science/article/pii/S001910350096456X,7486090746417714724,/scholar?cites=7486090746417714724,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.981.3478&rep=rep1&type=pdf,0,0,0
1278135,Deep learning massively accelerates super-resolution localization microscopy,2018,Wei Ouyang and Andrey Aristov and Mickaël Lelek and Xian Hao and Christophe Zimmer,36,Nature biotechnology,5,460,Nature Publishing Group,The speed of super-resolution microscopy methods based on single-molecule localization. for example. PALM and STORM. is limited by the need to record many thousands of frames with a small number of observed molecules in each. Here. we present ANNA-PALM. a computational strategy that uses artificial neural networks to reconstruct super-resolution views from sparse. rapidly acquired localization images and/or widefield images. Simulations and experimental imaging of microtubules. nuclear pores. and mitochondria show that high-quality. super-resolution images can be reconstructed from up to two orders of magnitude fewer frames than usually needed. without compromising spatial resolution. Super-resolution reconstructions are even possible from widefield images alone. though adding localization data improves image quality. We demonstrate super-resolution imaging of> 1.000 fields of view …,True,cPAja4UAAAAJ:b0M2c_1WBrUC,225,https://www.nature.com/articles/nbt.4106,11250262882944031814,/scholar?cites=11250262882944031814,,,https://hal.archives-ouvertes.fr/pasteur-02074397/file/51139_2_merged_1518367653.pdf,0,0,0
1278136,FISH-quant: automatic counting of transcripts in 3D FISH images,2013,Florian Mueller and Adrien Senecal and Katjana Tantale and Hervé Marie-Nelly and Nathalie Ly and Olivier Collin and Eugenia Basyuk and Edouard Bertrand and Xavier Darzacq and Christophe Zimmer,10,Nature methods,4,277-278,Nature Publishing Group,Transcription is inherently stochastic even in clonal cell populations 1. Studies at the single-cell. single-molecule level enable a quantitative understanding of the underlying regulatory mechanisms 2. 3. A widely used technique is single-molecule RNA fluorescence in situ hybridization (FISH). in which fluorescent probes target the mRNA of interest. and individual molecules appear as bright. diffraction-limited spots (Fig. 1a) 3. Recent experimental progress has made FISH easy to use 4. but a dedicated image analysis tool is currently lacking. Available methods allow counting of isolated mature mRNAs but cannot reliably quantify the dense mRNA aggregates at transcription sites in three dimensions. particularly those of highly transcribed genes. We developed FISH-quant to close this gap (Supplementary Note 1).,True,cPAja4UAAAAJ:maZDTaKrznsC,225,https://www.nature.com/articles/nmeth.2406,10621981543253894745,/scholar?cites=10621981543253894745,,,https://cyberleninka.org/article/n/1235968.pdf,0,0,0
1278137,Entrapment of intracytosolic bacteria by septin cage-like structures,2010,Serge Mostowy and Matteo Bonazzi and Mélanie Anne Hamon and To Nam Tham and Adeline Mallet and Mickaël Lelek and Edith Gouin and Caroline Demangel and Roland Brosch and Christophe Zimmer and Anna Sartori and Makoto Kinoshita and Marc Lecuit and Pascale Cossart,8,Cell host & microbe,5,433-444,Cell Press,Actin-based motility is used by various pathogens for dissemination within and between cells. Yet host factors restricting this process have not been identified. Septins are GTP-binding proteins that assemble as filaments and are essential for cell division. However. their role during interphase has remained elusive. Here. we report that septin assemblies are recruited to different bacteria that polymerize actin. We observed that intracytosolic Shigella either become compartmentalized in septin cage-like structures or form actin tails. Inactivation of septin caging increases the number of Shigella with actin tails and enhances cell-to-cell spread. TNF-α. a host cytokine produced upon Shigella infection. stimulates septin caging and restricts actin tail formation and cell-to-cell spread. Finally. we show that septin cages entrap bacteria targeted to autophagy. Together. these results reveal an unsuspected mechanism of host …,True,cPAja4UAAAAJ:TQgYirikUcIC,222,https://www.sciencedirect.com/science/article/pii/S193131281000346X,15858611693833977531,/scholar?cites=15858611693833977531,,,https://www.sciencedirect.com/science/article/pii/S193131281000346X,0,0,0
1278138,Imaging movement of malaria parasites during transmission by Anopheles mosquitoes,2004,Friedrich Frischknecht and Patricia Baldacci and Béatrice Martin and Christophe Zimmer and Sabine Thiberge and Jean‐Christophe Olivo‐Marin and Spencer L Shorte and Robert Ménard,6,Cellular microbiology,7,687-694,Blackwell Science Ltd,Malaria is contracted when Plasmodium sporozoites are inoculated into the vertebrate host during the blood meal of a mosquito. In infected mosquitoes. sporozoites are present in large numbers in the secretory cavities of the salivary glands at the most distal site of the salivary system. However. how sporozoites move through the salivary system of the mosquito. both in resting and feeding mosquitoes. is unknown. Here. we observed fluorescent Plasmodium berghei sporozoites within live Anopheles stephensi mosquitoes and their salivary glands and ducts. We show that sporozoites move in the mosquito by gliding. a type of motility associated with their capacity to invade host cells. Unlike in vitro. sporozoite gliding inside salivary cavities and ducts is modulated in speed and motion pattern. Imaging of sporozoite discharge through the proboscis of salivating mosquitoes indicates that sporozoites need to locomote …,True,cPAja4UAAAAJ:IjCSPb-OGe4C,214,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1462-5822.2004.00395.x,6558588623442039258,/scholar?cites=6558588623442039258,,,https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1462-5822.2004.00395.x,0,0,0
1278139,Four-chamber heart modeling and automatic segmentation for 3-D cardiac CT volumes using marginal space learning and steerable features,2008,Yefeng Zheng and Adrian Barbu and Bogdan Georgescu and Michael Scheuering and Dorin Comaniciu,27,IEEE transactions on medical imaging,11,1668-1681,IEEE,We propose an automatic four-chamber heart segmentation system for the quantitative functional analysis of the heart from cardiac computed tomography (CT) volumes. Two topics are discussed: heart modeling and automatic model fitting to an unseen volume. Heart modeling is a nontrivial task since the heart is a complex nonrigid organ. The model must be anatomically accurate. allow manual editing. and provide sufficient information to guide automatic detection and segmentation. Unlike previous work. we explicitly represent important landmarks (such as the valves and the ventricular septum cusps) among the control points of the model. The control points can be detected reliably to guide the automatic model fitting process. Using this model. we develop an efficient and robust approach for automatic heart chamber segmentation in 3D CT volumes. We formulate the segmentation as a two-step learning problem …,True,vAIECxgAAAAJ:u5HHmVD_uO8C,689,https://ieeexplore.ieee.org/abstract/document/4601463/,11620924174299954534,/scholar?cites=11620924174299954534,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.142.3884&rep=rep1&type=pdf,0,0,0
1278140,Robust point matching for nonrigid shapes by preserving local neighborhood structures,2006,Yefeng Zheng and David Doermann,28,IEEE transactions on pattern analysis and machine intelligence,4,643-649,IEEE,In previous work on point matching. a set of points is often treated as an instance of a joint distribution to exploit global relationships in the point set. For nonrigid shapes. however. the local relationship among neighboring points is stronger and more stable than the global one. In this paper. we introduce the notion of a neighborhood structure for the general point matching problem. We formulate point matching as an optimization problem to preserve local neighborhood structures during matching. Our approach has a simple graph matching interpretation. where each point is a node in the graph. and two nodes are connected by an edge if they are neighbors. The optimal match between two graphs is the one that maximizes the number of matched edges. Existing techniques are leveraged to search for an optimal solution with the shape context distance used to initialize the graph matching. followed by relaxation …,True,vAIECxgAAAAJ:9yKSN-GCB0IC,351,https://ieeexplore.ieee.org/abstract/document/1597120/,14130918865540294374,/scholar?cites=14130918865540294374,,,https://www.researchgate.net/profile/Yefeng_Zheng/publication/7211798_Robust_point_matching_for_nonrigid_shapes_by_preserving_local_neighborhood_structures/links/0deec527101e1d3269000000/Robust-point-matching-for-nonrigid-shapes-by-preserving-local-neighborhood-structures.pdf,0,0,0
1278141,Machine printed text and handwriting identification in noisy document images,2004,Yefeng Zheng and Huiping Li and David Doermann,26,IEEE transactions on pattern analysis and machine intelligence,3,337-353,IEEE,In this paper. we address the problem of the identification of text in noisy document images. We are especially focused on segmenting and identifying between handwriting and machine printed text because: 1) Handwriting in a document often indicates corrections. additions. or other supplemental information that should be treated differently from the main content and 2) the segmentation and recognition techniques requested for machine printed and handwritten text are significantly different. A novel aspect of our approach is that we treat noise as a separate class and model noise based on selected features. Trained Fisher classifiers are used to identify machine printed text and handwriting from noise and we further exploit context to refine the classification. A Markov Random Field-based (MRF) approach is used to model the geometrical structure of the printed text. handwriting. and noise to rectify misclassifications …,True,vAIECxgAAAAJ:u-x6o8ySG0sC,252,https://ieeexplore.ieee.org/abstract/document/1262324/,7496969388694677544,/scholar?cites=7496969388694677544,,,https://apps.dtic.mil/sti/pdfs/ADA459230.pdf,0,0,0
1278142,Script-independent text line segmentation in freestyle handwritten documents,2008,Yi Li and Yefeng Zheng and David Doermann and Stefan Jaeger,30,IEEE Transactions on Pattern Analysis and Machine Intelligence,8,1313-1329,IEEE,Text line segmentation in freestyle handwritten documents remains an open document analysis problem. Curvilinear text lines and small gaps between neighboring text lines present a challenge to algorithms developed for machine printed or hand-printed documents. In this paper. we propose a novel approach based on density estimation and a state-of-the-art image segmentation technique. the level set method. From an input document image. we estimate a probability map. where each element represents the probability that the underlying pixel belongs to a text line. The level set method is then exploited to determine the boundary of neighboring text lines by evolving an initial estimate. Unlike connected component based methods ( [1]. [2] for example). the proposed algorithm does not use any script-specific knowledge. Extensive quantitative experiments on freestyle handwritten documents with diverse scripts …,True,vAIECxgAAAAJ:2osOgNQ5qMEC,251,https://ieeexplore.ieee.org/abstract/document/4359385/,5158788969418054585,/scholar?cites=5158788969418054585,,,https://apps.dtic.mil/sti/pdfs/ADA460371.pdf,0,0,0
1278143,Fast automatic heart chamber segmentation from 3D CT data using marginal space learning and steerable features,2007,Yefeng Zheng and Adrian Barbu and Bogdan Georgescu and Michael Scheuering and Dorin Comaniciu,,,,1-8,IEEE,Multi-chamber heart segmentation is a prerequisite for global quantification of the cardiac function. The complexity of cardiac anatomy. poor contrast. noise or motion artifacts makes this segmentation problem a challenging task. In this paper. we present an efficient. robust. and fully automatic segmentation method for 3D cardiac computed tomography (CT) volumes. Our approach is based on recent advances in learning discriminative object models and we exploit a large database of annotated CT volumes. We formulate the segmentation as a two step learning problem: anatomical structure localization and boundary delineation. A novel algorithm. marginal space learning (MSL). is introduced to solve the 9-dimensional similarity search problem for localizing the heart chambers. MSL reduces the number of testing hypotheses by about six orders of magnitude. We also propose to use steerable image features. which …,True,vAIECxgAAAAJ:nOKOSwxqtg8C,213,https://ieeexplore.ieee.org/abstract/document/4408925/,4467871872897096292,/scholar?cites=4467871872897096292,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.1943&rep=rep1&type=pdf,0,0,0
1278144,Translating and segmenting multimodal medical volumes with cycle-and shapeconsistency generative adversarial network,2018,Zizhao Zhang and Lin Yang and Yefeng Zheng,,,,9242-9251,,Synthesized medical images have several important applications. eg. as an intermedium in cross-modality image registration and as supplementary training samples to boost the generalization capability of a classifier. Especially. synthesized CT data can provide X-ray attenuation map for radiation therapy planning. In this work. we propose a generic cross-modality synthesis approach with the following targets: 1) synthesizing realistic looking 3D images using unpaired training data. 2) ensuring consistent anatomical structures. which could changed by geometric distortion in cross-modality synthesis and 3) improving volume segmentation by using synthetic data for modalities with limited training samples. We show that these goals can be achieved with an end-to-end 3D convolutional neural network (CNN) composed of mutually-beneficial generators and segmentors for image synthesis and segmentation tasks. The generators are trained with an adversarial loss. a cycle-consistency loss. and also a shape-consistency loss. which is supervised by segmentors. to reduce the geometric distortion. From the segmentation view. the segmentors are boosted by synthetic data from generators in an online manner. Generators and segmentors prompt each other alternatively in an end-to-end training fashion. With extensive experiments on a dataset including a total of 4.496 CT and MRI cardiovascular volumes. we show both tasks are beneficial to each other and coupling these two tasks results in better performance than solving them exclusively.,True,vAIECxgAAAAJ:0Tn0GYh_KFEC,193,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Translating_and_Segmenting_CVPR_2018_paper.html,16727094656283669463,/scholar?cites=16727094656283669463,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Translating_and_Segmenting_CVPR_2018_paper.pdf,0,0,0
1278145,Hierarchical. learning-based automatic liver segmentation,2008,Haibin Ling and S Kevin Zhou and Yefeng Zheng and Bogdan Georgescu and Michael Suehling and Dorin Comaniciu,,,,1-8,IEEE,In this paper we present a hierarchical. learning-based approach for automatic and accurate liver segmentation from 3D CT volumes. We target CT volumes that come from largely diverse sources (e.g.. diseased in six different organs) and are generated by different scanning protocols (e.g.. contrast and non-contrast. various resolution and position). Three key ingredients are combined to solve the segmentation problem. First. a hierarchical framework is used to efficiently and effectively monitor the accuracy propagation in a coarse-to-fine fashion. Second. two new learning techniques. marginal space learning and steerable features. are applied for robust boundary inference. This enables handling of highly heterogeneous texture pattern. Third. a novel shape space initialization is proposed to improve traditional methods that are limited to similarity transformation. The proposed approach is tested on a challenging …,True,vAIECxgAAAAJ:UeHWp8X0CEIC,188,https://ieeexplore.ieee.org/abstract/document/4587393/,9690884041901502689,/scholar?cites=9690884041901502689,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.204.809&rep=rep1&type=pdf,0,0,0
1278146,Method and system for comprehensive patient-specific modeling of the heart,2014,Razvan Ioan Ionasec and Ingmar Voigt and Viorel Mihalef and Sasa Grbic and Dime Vitanovski and Yang Wang and Yefeng Zheng and Bogdan Georgescu and Dorin Comaniciu and Puneet Sharma and Tommaso Mansi,,,,,,A method and system for patient-specific modeling of the whole heart anatomy. dynamics. hemodynamics. and fluid structure interaction from 4D medical image data is disclosed. The anatomy and dynamics of the heart are determined by estimating patient-specific parameters of a physiological model of the heart from the 4D medical image data for a patient. The patient-specific anatomy and dynamics are used as input to a 3D Navier-Stokes solver that derives realistic hemodynamics. constrained by the local anatomy. along the entire heart cycle. Fluid structure interactions are determined iteratively over the heart cycle by simulating the blood flow at a given time step and calculating the deformation of the heart structure based on the simulated blood flow. such that the deformation of the heart structure is used in the simulation of the blood flow at the next time step. The comprehensive patient-specific model of the …,True,vAIECxgAAAAJ:tuHXwOkdijsC,137,https://patents.google.com/patent/US8682626B2/en,10037804130297789029,/scholar?cites=10037804130297789029,,,https://patentimages.storage.googleapis.com/4c/13/7b/6977c5c9e9e070/US8682626.pdf,0,0,0
1278147,Multi-scale deep reinforcement learning for real-time 3D-landmark detection in CT scans,2017,Florin-Cristian Ghesu and Bogdan Georgescu and Yefeng Zheng and Sasa Grbic and Andreas Maier and Joachim Hornegger and Dorin Comaniciu,41,IEEE transactions on pattern analysis and machine intelligence,1,176-189,IEEE,Robust and fast detection of anatomical structures is a prerequisite for both diagnostic and interventional medical image analysis. Current solutions for anatomy detection are typically based on machine learning techniques that exploit large annotated image databases in order to learn the appearance of the captured anatomy. These solutions are subject to several limitations. including the use of suboptimal feature engineering techniques and most importantly the use of computationally suboptimal search-schemes for anatomy detection. To address these issues. we propose a method that follows a new paradigm by reformulating the detection problem as a behavior learning task for an artificial agent. We couple the modeling of the anatomy appearance and the object search in a unified behavioral framework. using the capabilities of deep reinforcement learning and multi-scale image analysis. In other words. an …,True,vAIECxgAAAAJ:XyWThvt29VcC,134,https://ieeexplore.ieee.org/abstract/document/8187667/,4628977264663626491,/scholar?cites=4628977264663626491,,,,0,0,0
1278148,3D Deep Learning for Efficient and Robust Landmark Detection in Volumetric Data,2015,Y. Zheng and D. Liu and B. Georgescu and H. Nguyen and D. Comaniciu,,,,,Springer,Recently. deep learning has demonstrated great success in computer vision with the capability to learn powerful image features from a large training set. However. most of the published work has been confined to solving 2D problems. with a few limited exceptions that treated the 3D space as a composition of 2D orthogonal planes. The challenge of 3D deep learning is due to a much larger input vector. compared to 2D. which dramatically increases the computation time and the chance of over-fitting. especially when combined with limited training samples (hundreds to thousands). typical for medical imaging applications. To address this challenge. we propose an efficient and robust deep learning algorithm capable of full 3D detection in volumetric data. A two-step approach is exploited for efficient detection. A shallow network (with one hidden layer) is used for the initial testing of all voxels to obtain a small …,True,vAIECxgAAAAJ:QSG1pgF8pGAC,134,https://link.springer.com/chapter/10.1007/978-3-319-24553-9_69,6261382727857014395,/scholar?cites=6261382727857014395,,,https://www.comaniciu.net/Papers/3D_DeepLearningLandmark_MICCAI15.pdf,0,0,0
1278149,Deep similarity learning for multimodal medical images,2018,Xi Cheng and Li Zhang and Yefeng Zheng,6,Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization,3,248-252,Taylor & Francis,An effective similarity measure for multi-modal images is crucial for medical image fusion in many clinical applications. The underlining correlation across modalities is usually too complex to be modelled by intensity-based statistical metrics. Therefore. approaches of learning a similarity metric are proposed in recent years. In this work. we propose a novel deep similarity learning method that trains a binary classifier to learn the correspondence of two image patches. The classification output is transformed to a continuous probability value. then used as the similarity score. Moreover. we propose to utilise multi-modal stacked denoising autoencoder to effectively pre-train the deep neural network. We train and test the proposed metric using sampled corresponding/non-corresponding computed tomography and magnetic resonance head image patches from a same subject. Comparison is made with two commonly …,True,vAIECxgAAAAJ:GWiaReNCd0YC,120,https://www.tandfonline.com/doi/abs/10.1080/21681163.2015.1135299,10985599784362716781,/scholar?cites=10985599784362716781,,,,0,0,0
1278150,A novel connectionist system for unconstrained handwriting recognition,2008,Alex Graves and Marcus Liwicki and Santiago Fernández and Roman Bertolami and Horst Bunke and Jürgen Schmidhuber,31,IEEE transactions on pattern analysis and machine intelligence,5,855-868,IEEE,Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters. combined with the need to exploit surrounding context. has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed. most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition. despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network. specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large …,True,n1Y4zq4AAAAJ:u-x6o8ySG0sC,1829,https://ieeexplore.ieee.org/abstract/document/4531750/,3713186694765030515,/scholar?cites=3713186694765030515,,,https://mediatum.ub.tum.de/doc/1289308/file.pdf,0,0,0
1278151,Scene labeling with lstm recurrent neural networks,2015,Wonmin Byeon and Thomas M Breuel and Federico Raue and Marcus Liwicki,,,,3547-3555,,This paper addresses the problem of pixel-level segmentation and classification of scene images with an entirely learning-based approach using Long Short Term Memory (LSTM) recurrent neural networks. which are commonly used for sequence classification. We investigate two-dimensional (2D) LSTM networks for natural scene images taking into account the complex spatial dependencies of labels. Prior methods generally have required separate classification and image segmentation stages and/or pre-and post-processing. In our approach. classification. segmentation. and context integration are all carried out by 2D LSTM networks. allowing texture and spatial model parameters to be learned within a single model. The networks efficiently capture local and global contextual information over raw RGB values and adapt well for complex scene images. Our approach. which has a much lower computational complexity than prior methods. achieved state-of-the-art performance over the Stanford Background and the SIFT Flow datasets. In fact. if no pre-or post-processing is applied. LSTM networks outperform other state-of-the-art approaches. Hence. only with a single-core Central Processing Unit (CPU). the running time of our approach is equivalent or better than the compared state-of-the-art approaches which use a Graphics Processing Unit (GPU). Finally. our networks' ability to visualize feature maps from each layer supports the hypothesis that LSTM networks are overall suited for image processing tasks.,True,n1Y4zq4AAAAJ:WqliGbK-hY8C,349,http://openaccess.thecvf.com/content_cvpr_2015/html/Byeon_Scene_Labeling_With_2015_CVPR_paper.html,14243878442330676532,/scholar?cites=14243878442330676532,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Byeon_Scene_Labeling_With_2015_CVPR_paper.pdf,0,0,0
1278152,Unconstrained online handwriting recognition with recurrent neural networks,2008,Alex Graves and Santiago Fernández and Marcus Liwicki and Horst Bunke and Jürgen Schmidhuber,,,,,,In online handwriting recognition the trajectory of the pen is recorded during writing. Although the trajectory provides a compact and complete representation of the written output. it is hard to transcribe directly. because each letter is spread over many pen locations. Most recognition systems therefore employ sophisticated preprocessing techniques to put the inputs into a more localised form. However these techniques require considerable human effort. and are specific to particular languages and alphabets. This paper describes a system capable of directly transcribing raw online handwriting data. The system consists of an advanced recurrent neural network with an output layer designed for sequence labelling. combined with a probabilistic language model. In experiments on an unconstrained online database. we record excellent results using either raw or preprocessed data. well outperforming a state-of-the-art HMM based system in both cases.,True,n1Y4zq4AAAAJ:qjMakFHDy7sC,298,https://mediatum.ub.tum.de/doc/1289307/file.pdf,295581017747117445,/scholar?cites=295581017747117445,,,https://mediatum.ub.tum.de/doc/1289307/file.pdf,0,0,0
1278153,Parallel multi-dimensional lstm. with application to fast biomedical volumetric image segmentation,2015,Marijn F Stollenga and Wonmin Byeon and Marcus Liwicki and Juergen Schmidhuber,,arXiv preprint arXiv:1506.07452,,,,Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast. Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels. especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages. however. unlike CNNs. previous MD-LSTM variants were hard to parallelize on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelize. especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).,True,n1Y4zq4AAAAJ:hkOj_22Ku90C,273,https://arxiv.org/abs/1506.07452,3236346698623785406,/scholar?cites=3236346698623785406,,,https://arxiv.org/pdf/1506.07452,0,0,0
1278154,A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks,2007,Marcus Liwicki and Alex Graves and Santiago Fernàndez and Horst Bunke and Jürgen Schmidhuber,,,,,,In this paper we introduce a new connectionist approach to on-line handwriting recognition and address in particular the problem of recognizing handwritten whiteboard notes. The approach uses a bidirectional recurrent neural network with long short-term memory blocks. We use a recently introduced objective function. known as Connectionist Temporal Classification (CTC). that directly trains the network to label unsegmented sequence data. Our new system achieves a word recognition rate of 74.0%. compared with 65.4% using a previously developed HMM-based recognition system.,True,n1Y4zq4AAAAJ:Y0pCki6q_DkC,241,https://mediatum.ub.tum.de/doc/1289961/file.pdf,2789465280243096739,/scholar?cites=2789465280243096739,,,https://mediatum.ub.tum.de/doc/1289961/file.pdf,0,0,0
1278155,IAM-OnDB-an on-line English sentence database acquired from handwritten text on a whiteboard,2005,Marcus Liwicki and Horst Bunke,,,,956-961,IEEE,In this paper we present IAM-OnDB - a new large online handwritten sentences database. It is publicly available and consists of text acquired via an electronic interface from a whiteboard. The database contains about 86 K word instances from an 11 K dictionary written by more than 200 writers. We also describe a recognizer for unconstrained English text that was trained and tested using this database. This recognizer is based on hidden Markov models (HMMs). In our experiments we show that by using larger training sets we can significantly increase the word recognition rate. This recognizer may serve as a benchmark reference for future research.,True,n1Y4zq4AAAAJ:u5HHmVD_uO8C,199,https://ieeexplore.ieee.org/abstract/document/1575685/,16359889263892690217,/scholar?cites=16359889263892690217,,,https://www.researchgate.net/profile/Marcus_Liwicki/publication/224626482_IAM-OnDB_-_An_on-line_English_sentence_database_acquired_from_handwritten_text_on_a_whiteboard/links/0c9605327ee2f9aba5000000/IAM-OnDB-An-on-line-English-sentence-database-acquired-from-handwritten-text-on-a-whiteboard.pdf,0,0,0
1278156,Signature verification competition for online and offline skilled forgeries (sigcomp2011),2011,Marcus Liwicki and Muhammad Imran Malik and C Elisa Van Den Heuvel and Xiaohong Chen and Charles Berger and Reinoud Stoel and Michael Blumenstein and Bryan Found,,,,1480-1484,IEEE,The Netherlands Forensic Institute and the Institute for Forensic Science in Shanghai are in search of a signature verification system that can be implemented in forensic casework and research to objectify results. We want to bridge the gap between recent technological developments and forensic casework. In collaboration with the German Research Center for Artificial Intelligence we have organized a signature verification competition on datasets with two scripts (Dutch and Chinese) in which we asked to compare questioned signatures against a set of reference signatures. We have received 12 systems from 5 institutes and performed experiments on online and offline Dutch and Chinese signatures. For evaluation. we applied methods used by Forensic Handwriting Examiners (FHEs) to assess the value of the evidence. i.e.. we took the likelihood ratios more into account than in previous competitions. The data set …,True,n1Y4zq4AAAAJ:HDshCWvjkbEC,130,https://ieeexplore.ieee.org/abstract/document/6065554/,13396842309717085724,/scholar?cites=13396842309717085724,,,https://www.xyzmo.com/downloads/documents/en/Signature_Verification_Competition_2011_en.pdf,0,0,0
1278157,Dexpression: Deep convolutional neural network for expression recognition,2015,Peter Burkert and Felix Trier and Muhammad Zeshan Afzal and Andreas Dengel and Marcus Liwicki,,arXiv preprint arXiv:1509.05371,,,,We propose a convolutional neural network (CNN) architecture for facial expression recognition. The proposed architecture is independent of any hand-crafted feature extraction and performs better than the earlier proposed convolutional neural network based approaches. We visualize the automatically extracted features which have been learned by the network in order to provide a better understanding. The standard datasets. ie Extended Cohn-Kanade (CKP) and MMI Facial Expression Databse are used for the quantitative evaluation. On the CKP set the current state of the art approach. using CNNs. achieves an accuracy of 99.2%. For the MMI dataset. currently the best accuracy for emotion recognition is 93.33%. The proposed architecture achieves 99.6% for CKP and 98.63% for MMI. therefore performing better than the state of the art using CNNs. Automatic facial expression recognition has a broad spectrum of applications such as human-computer interaction and safety systems. This is due to the fact that non-verbal cues are important forms of communication and play a pivotal role in interpersonal communication. The performance of the proposed architecture endorses the efficacy and reliable usage of the proposed work for real world applications.,True,n1Y4zq4AAAAJ:NJ774b8OgUMC,124,https://arxiv.org/abs/1509.05371,12905263877370168167,/scholar?cites=12905263877370168167,,,https://arxiv.org/pdf/1509.05371,0,0,0
1278158,A writer identification system for on-line whiteboard data,2008,Andreas Schlapbach and Marcus Liwicki and Horst Bunke,41,Pattern recognition,7,2381-2397,Pergamon,In this paper we address the task of writer identification of on-line handwriting captured from a whiteboard. Different sets of features are extracted from the recorded data and used to train a text and language independent on-line writer identification system. The system is based on Gaussian mixture models (GMMs) which provide a powerful yet simple means of representing the distribution of the features extracted from the handwritten text. The training data of all writers are used to train a universal background model (UBM) from which a client specific model is obtained by adaptation. Different sets of features are described and evaluated in this work. The system is tested using text from 200 different writers. A writer identification rate of 98.56% on the paragraph and of 88.96% on the text line level is achieved.,True,n1Y4zq4AAAAJ:2osOgNQ5qMEC,115,https://www.sciencedirect.com/science/article/pii/S0031320308000083,319881650810611147,/scholar?cites=319881650810611147,,,,0,0,0
1278159,HMM-based on-line recognition of handwritten whiteboard notes,2006,Marcus Liwicki and Horst Bunke,,,,,Suvisoft,In this paper we present an on-line recognition system for handwritten texts acquired from a whiteboard. This input modality has received relatively little attention in the handwriting recognition community in the past. The system proposed in this paper uses state-of-the-art normalization and feature extraction strategies to transform a handwritten text line into a sequence of feature vectors. Additional preprocessing techniques are introduced. which significantly increase the word recognition rate. For classification. Hidden Markov Models are used together with a statistical language model. In writer independent experiments we achieved word recognition rates of 67.3% on the test set when no language model is used. and 70.8% by including a language model.,True,n1Y4zq4AAAAJ:d1gkVwhDpl0C,110,https://hal.inria.fr/inria-00108307/,9186775349194641660,/scholar?cites=9186775349194641660,,,https://hal.inria.fr/inria-00108307/document,0,0,0
1278160,Tac-gan-text conditioned auxiliary classifier generative adversarial network,2017,Ayushman Dash and John Cristian Borges Gamboa and Sheraz Ahmed and Marcus Liwicki and Muhammad Zeshan Afzal,,arXiv preprint arXiv:1703.06412,,,,In this work. we present the Text Conditioned Auxiliary Classifier Generative Adversarial Network.(TAC-GAN) a text to image Generative Adversarial Network (GAN) for synthesizing images from their text descriptions. Former approaches have tried to condition the generative process on the textual data; but allying it to the usage of class information. known to diversify the generated samples and improve their structural coherence. has not been explored. We trained the presented TAC-GAN model on the Oxford-102 dataset of flowers. and evaluated the discriminability of the generated images with Inception-Score. as well as their diversity using the Multi-Scale Structural Similarity Index (MS-SSIM). Our approach outperforms the state-of-the-art models. ie. its inception score is 3.45. corresponding to a relative increase of 7.8% compared to the recently introduced StackGan. A comparison of the mean MS-SSIM scores of the training and generated samples per class shows that our approach is able to generate highly diverse images with an average MS-SSIM of 0.14 over all generated classes.,True,n1Y4zq4AAAAJ:xtoqd-5pKcoC,96,https://arxiv.org/abs/1703.06412,8629167258335551493,/scholar?cites=8629167258335551493,,,https://arxiv.org/pdf/1703.06412,0,0,0
1278161,MPEG‐7 homogeneous texture descriptor,2001,Yong Man Ro and Munchurl Kim and Ho Kyung Kang and BS Manjunath and Jinwoong Kim,23,ETRI journal,2,41-51,,MPEG‐7 standardization work has started with the aims of providing fundamental tools for describing multimedia contents. MPEG‐7 defines the syntax and semantics of descriptors and description schemes so that they may be used as fundamental tools for multimedia content description. In this paper. we introduce a texture based image description and retrieval method. which is adopted as the homogeneous texture descriptor in the visual part of the MPEG‐7 final committee draft. The current MPEG‐7 homogeneous texture descriptor consists of the mean. the standard deviation value of an image. energy. and energy deviation values of Fourier transform of the image. These are extracted from partitioned frequency channels based on the human visual system (HVS). For reliable extraction of the texture descriptor. Radon transformation is employed. This is suitable for HVS behavior. We also introduce various …,True,IPzfF7cAAAAJ:u-x6o8ySG0sC,218,https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.01.0101.0201,15932355650912561043,/scholar?cites=15932355650912561043,,,https://onlinelibrary.wiley.com/doi/pdf/10.4218/etrij.01.0101.0201,0,0,0
1278162,Reduction of susceptibility artifact in gradient‐echo imaging,1992,ZH Cho and YongMan Ro,23,Magnetic resonance in medicine,1,193-200,Wiley Subscription Services. Inc.. A Wiley Company,A new technique with which susceptibility artifact in gradient‐echo imaging can be reduced substantially by use of a tailored RF pulse is described. The proposed technique can ideally be applied to the case where high local magnetic field inhomogeneity is dominated by the susceptibility. The signal loss and void phenomena due to susceptibility in a voxel are studied and a correction method is also proposed. The description of the tailored RF pulse and its proposed application are given and experimental results obtained using a human volunteer with a 2.0‐T KAIS NMR system are presented. © 1992 Academic Press. Inc.,True,IPzfF7cAAAAJ:u5HHmVD_uO8C,199,https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910230120,1328270244325547760,/scholar?cites=1328270244325547760,,,,0,0,0
1278163,Color local texture features for color face recognition,2011,Jae Young Choi and Yong Man Ro and Konstantinos N Plataniotis,21,IEEE transactions on image processing,3,1366-1380,IEEE,This paper proposes new color local texture features. i.e.. color local Gabor wavelets (CLGWs) and color local binary pattern (CLBP). for the purpose of face recognition (FR). The proposed color local texture features are able to exploit the discriminative information derived from spatiochromatic texture patterns of different spectral channels within a certain local face region. Furthermore. in order to maximize a complementary effect taken by using both color and texture information. the opponent color texture features that capture the texture patterns of spatial interactions between spectral channels are also incorporated into the generation of CLGW and CLBP. In addition. to perform the final classification. multiple color local texture features (each corresponding to the associated color band) are combined within a feature-level fusion framework. Extensive and comparative experiments have been conducted to evaluate …,True,IPzfF7cAAAAJ:7T2F9Uy0os0C,178,https://ieeexplore.ieee.org/abstract/document/6020798/,2673163602096109697,/scholar?cites=2673163602096109697,,,https://www.researchgate.net/profile/Konstantinos_Plataniotis/publication/220502398_Color_Local_Texture_Features_for_Color_Face_Recognition/links/00463513f25f18b56c000000/Color-Local-Texture-Features-for-Color-Face-Recognition.pdf,0,0,0
1278164,Method. system. and computer program for identification and sharing of digital images with face signatures,2014,Ray Ganong and Donald Waugh and Yong Man Ro and Konstantinos Plataniotis and Chris Studholme,,,,,,The present invention solves the problem of automatically recognizing multiple known faces in photos or videos on a local computer storage device (on a home computer). It further allows for sophisticated organization and presentation of the photos or videos based on the graphical selection of known faces (by selecting thumbnail images of people). It also solves the problem of sharing or distributing photos or videos in an automated fashion between ‘friends’ who are also using the same software that enables the invention. It further solves the problem of allowing a user of the invention to review the results of the automatic face detection. eye detection. and face recognition methods and to correct any errors resulting from the automated process.,True,IPzfF7cAAAAJ:uLbwQdceFCQC,176,https://patents.google.com/patent/US8750574B2/en,12767248582671969881,/scholar?cites=12767248582671969881,,,https://patentimages.storage.googleapis.com/dc/d2/d5/18cf2fb43cd7fb/US8750574.pdf,0,0,0
1278165,An evaluation of bitrate adaptation methods for HTTP live streaming,2014,Truong Cong Thang and Hung T Le and Anh T Pham and Yong Man Ro,32,IEEE Journal on Selected Areas in Communications,4,693-705,IEEE,HTTP streaming has become a cost-effective means for multimedia delivery nowadays. For adaptivity to networks and terminals. a provider should generate multiple representations of an original video as well as the related metadata. Recently. there have been various adaptation methods to support adaptive HTTP streaming. In this paper. we investigate typical adaptation methods in the context of live video streaming. We first discuss the trade-off among typical adaptation methods. The evaluation and comparison are then carried out not only in terms of bitrate and buffer behaviors but also in terms of the perceptual impact on end users. It is found that the perceptual impact depends not only on adaptation method but also on the content itself. We also show that the preparation of representation sets may affect the behaviors of some adaptation methods.,True,IPzfF7cAAAAJ:CoqsOaBEKcQC,152,https://ieeexplore.ieee.org/abstract/document/6774590/,14583896971388299367,/scholar?cites=14583896971388299367,,,https://www.researchgate.net/profile/Truong_Cong_Thang/publication/260945728_An_Evaluation_of_Bitrate_Adaptation_Methods_for_HTTP_Live_Streaming/links/59b0a3160f7e9b3743466a86/An-Evaluation-of-Bitrate-Adaptation-Methods-for-HTTP-Live-Streaming.pdf,0,0,0
1278166,Local color vector binary patterns from multichannel face images for face recognition,2011,Seung Ho Lee and Jae Young Choi and Yong Man Ro and Konstantinos N Plataniotis,21,IEEE Transactions on Image Processing,4,2347-2353,IEEE,This paper proposes a novel face descriptor based on color information. i.e.. so-called local color vector binary patterns (LCVBPs). for face recognition (FR). The proposed LCVBP consists of two discriminative patterns: color norm patterns and color angular patterns. In particular. we have designed a method for extracting color angular patterns. which enables to encode the discriminating texture patterns derived from spatial interactions among different spectral-band images. In order to perform FR tasks. the proposed LCVBP feature is generated by combining multiple features extracted from both color norm patterns and color angular patterns. Extensive and comparative experiments have been conducted to evaluate the proposed LCVBP feature on five public databases. Experimental results show that the proposed LCVBP feature is able to yield excellent FR performance for challenging face images. In addition. the …,True,IPzfF7cAAAAJ:a3BOlSfXSfwC,141,https://ieeexplore.ieee.org/abstract/document/6112223/,16546858526513102373,/scholar?cites=16546858526513102373,,,https://www.researchgate.net/profile/Konstantinos_Plataniotis/publication/51895875_Local_Color_Vector_Binary_Patterns_From_Multichannel_Face_Images_for_Face_Recognition/links/0fcfd5148c780b118d000000/Local-Color-Vector-Binary-Patterns-From-Multichannel-Face-Images-for-Face-Recognition.pdf,0,0,0
1278167,Color face recognition for degraded face images,2009,Jae Young Choi and Yong Man Ro and Konstantinos N Plataniotis,39,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",5,1217-1230,IEEE,In many current face-recognition (FR) applications. such as video surveillance security and content annotation in a Web environment. low-resolution faces are commonly encountered and negatively impact on reliable recognition performance. In particular. the recognition accuracy of current intensity-based FR systems can significantly drop off if the resolution of facial images is smaller than a certain level (e.g.. less than 20 times 20 pixels). To cope with low-resolution faces. we demonstrate that facial color cue can significantly improve recognition performance compared with intensity-based features. The contribution of this paper is twofold. First. a new metric called ldquovariation ratio gainrdquo (VRG) is proposed to prove theoretically the significance of color effect on low-resolution faces within well-known subspace FR frameworks; VRG quantitatively characterizes how color features affect the recognition …,True,IPzfF7cAAAAJ:qjMakFHDy7sC,133,https://ieeexplore.ieee.org/abstract/document/4804691/,649125355777346560,/scholar?cites=649125355777346560,,,https://koasas.kaist.ac.kr/bitstream/10203/21044/1/000267865400011.pdf,0,0,0
1278168,Collaborative face recognition for improved face annotation in personal photo collections shared on online social networks,2010,Jae Young Choi and Wesley De Neve and Konstantinos N Plataniotis and Yong Man Ro,13,IEEE Transactions on Multimedia,1,14-28,IEEE,Using face annotation for effective management of personal photos in online social networks (OSNs) is currently of considerable practical interest. In this paper. we propose a novel collaborative face recognition (FR) framework. improving the accuracy of face annotation by effectively making use of multiple FR engines available in an OSN. Our collaborative FR framework consists of two major parts: selection of FR engines and merging (or fusion) of multiple FR results. The selection of FR engines aims at determining a set of personalized FR engines that are suitable for recognizing query face images belonging to a particular member of the OSN. For this purpose. we exploit both social network context in an OSN and social context in personal photo collections. In addition. to take advantage of the availability of multiple FR results retrieved from the selected FR engines. we devise two effective solutions for merging …,True,IPzfF7cAAAAJ:QIV2ME_5wuYC,128,https://ieeexplore.ieee.org/abstract/document/5601785/,15273953266296176372,/scholar?cites=15273953266296176372,,,https://koasas.kaist.ac.kr/bitstream/10203/22860/1/000286386900003.pdf,0,0,0
1278169,Method and apparatus for category-based photo clustering in digital photo album,2005,Sangkyun Kim and Jiyeun Kim and Youngsu Moon and Yongman Ro and Seungji Yang and Samsung Electronics Co. and Ltd. and Industrial Cooperation Group,,,,,,A method of category-based clustering of a digital photo album and a system thereof. the method includes: generating photo information by extracting at least one of camera information of a camera used to take a photo. photographing information. and a content-based feature value including at least one of color. texture. and shape feature values. and a speech feature value; generating a predetermined parameter including at least one of user preference indicating the personal preference of the user. photo semantic information generated by using the content-based feature value of the photo. and photo syntactic information generated by at least one of the camera information. the photographing information. and interaction with the user; generating photo group information categorizing photos by using the photo information and the parameter; and generating a photo album by using the photo information and the …,True,IPzfF7cAAAAJ:O3NaXMp0MMsC,124,https://patents.google.com/patent/US20060074771A1/en,7649200111934517891,/scholar?cites=7649200111934517891,,,https://patentimages.storage.googleapis.com/d2/0c/e6/4702efbac244d7/US20060074771A1.pdf,0,0,0
1278170,Intra-class variation reduction using training expression images for sparse representation based facial expression recognition,2014,Seung Ho Lee and Konstantinos N Plataniotis and Yong Man Ro,5,IEEE Transactions on Affective Computing,3,340-351,IEEE,Automatic facial expression recognition (FER) is becoming increasingly important in the area of affective computing systems because of its various emerging applications such as human-machine interface and human emotion analysis. Recently. sparse representation based FER has become popular and has shown an impressive performance. However. sparse representation could often produce less meaningful sparse solution for FER due to intra-class variation such as variation in identity or illumination. This paper proposes a new sparse representation based FER method. aiming to reduce the intra-class variation while emphasizing the facial expression in a query face image. To that end. we present a new method for generating an intra-class variation image of each expression by using training expression images. The appearance of each intra-class variation image could be close to the appearance of the …,True,IPzfF7cAAAAJ:qE25ZKhNtbAC,103,https://ieeexplore.ieee.org/abstract/document/6874505/,17815368995022000352,/scholar?cites=17815368995022000352,,,,0,0,0
1278171,Privacy protection in video surveillance systems: Analysis of subband-adaptive scrambling in JPEG XR,2011,Hosik Sohn and Wesley De Neve and Yong Man Ro,21,IEEE Transactions on Circuits and Systems for Video Technology,2,170-177,IEEE,This paper discusses a privacy-protected video surveillance system that makes use of JPEG extended range (JPEG XR). JPEG XR offers a low-complexity solution for the scalable coding of high-resolution images. To address privacy concerns. face regions are detected and scrambled in the transform domain. taking into account the quality and spatial scalability features of JPEG XR. Experiments were conducted to investigate the performance of our surveillance system. considering visual distortion. bit stream overhead. and security aspects. Our results demonstrate that subband-adaptive scrambling is able to conceal privacy-sensitive face regions with a feasible level of protection. In addition. our results show that subband-adaptive scrambling of face regions outperforms subband-adaptive scrambling of frames in terms of coding efficiency. except when low video bit rates are in use.,True,IPzfF7cAAAAJ:hC7cP41nSMkC,99,https://ieeexplore.ieee.org/abstract/document/5688306/,15774707058281374282,/scholar?cites=15774707058281374282,,,https://www.researchgate.net/profile/Wesley_De_Neve/publication/224212024_Privacy_Protection_in_Video_Surveillance_Systems_Analysis_of_Subband-Adaptive_Scrambling_in_JPEG_XR/links/02bfe51200efd215e3000000.pdf,0,0,0
1278172,Enet: A deep neural network architecture for real-time semantic segmentation,2016,Adam Paszke and Abhishek Chaurasia and Sangpil Kim and Eugenio Culurciello,,arXiv preprint arXiv:1606.02147,,,,The ability to perform pixel-wise semantic segmentation in real-time is of paramount importance in mobile applications. Recent deep neural networks aimed at this task have the disadvantage of requiring a large number of floating point operations and have long run-times that hinder their usability. In this paper. we propose a novel deep neural network architecture named ENet (efficient neural network). created specifically for tasks requiring low latency operation. ENet is up to 18 faster. requires 75 less FLOPs. has 79 less parameters. and provides similar or better accuracy to existing models. We have tested it on CamVid. Cityscapes and SUN datasets and report on comparisons with existing state-of-the-art methods. and the trade-offs between accuracy and processing time of a network. We present performance measurements of the proposed architecture on embedded systems and suggest possible software improvements that could make ENet even faster.,True,SeGmqkIAAAAJ:SdhP9T11ey4C,1018,https://arxiv.org/abs/1606.02147,10064611961321647849,/scholar?cites=10064611961321647849,,,https://arxiv.org/pdf/1606.02147.pdf)%C3%AC%20%E2%82%AC,0,0,0
1278173,An analysis of deep neural network models for practical applications,2016,Alfredo Canziani and Adam Paszke and Eugenio Culurciello,,arXiv preprint arXiv:1605.07678,,,,Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision. the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased. the resource utilisation of winning models has not been properly taken into account. In this work. we present a comprehensive analysis of important metrics in practical applications: accuracy. memory footprint. parameters. operations count. inference time and power consumption. Key findings are:(1) power consumption is independent of batch size and architecture;(2) accuracy and inference time are in a hyperbolic relationship;(3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity;(4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.,True,SeGmqkIAAAAJ:9vf0nzSNQJEC,779,https://arxiv.org/abs/1605.07678,7120878747763061713,/scholar?cites=7120878747763061713,,,https://arxiv.org/pdf/1605.07678.pdf?source=post_page---------------------------,0,0,0
1278174,Neuflow: A runtime reconfigurable dataflow processor for vision,2011,Clément Farabet and Berin Martini and Benoit Corda and Polina Akselrod and Eugenio Culurciello and Yann LeCun,,,,109-116,IEEE,In this paper we present a scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms - neuFlow - and a dataflow compiler - luaFlow - that transforms high-level flow-graph representations of these algorithms into machine code for neuFlow. This system was designed with the goal of providing real-time detection. categorization and localization of objects in complex scenes. while consuming 10 Watts when implemented on a Xilinx Virtex 6 FPGA platform. or about ten times less than a laptop computer. and producing speedups of up to 100 times in real-world applications. We present an application of the system on street scene analysis. segmenting 20 categories on 500 × 375 frames at 12 frames per second on our custom hardware neuFlow.,True,SeGmqkIAAAAJ:maZDTaKrznsC,423,https://ieeexplore.ieee.org/abstract/document/5981829/,17206820744442464968,/scholar?cites=17206820744442464968,,,http://ww.w.robertdick.org/iesr/papers/farabet11jun.pdf,0,0,0
1278175,Linknet: Exploiting encoder representations for efficient semantic segmentation,2017,Abhishek Chaurasia and Eugenio Culurciello,,,,1-4,IEEE,Pixel-wise semantic segmentation for visual scene understanding not only needs to be accurate. but also efficient in order to find any use in real-time application. Existing algorithms even though are accurate but they do not focus on utilizing the parameters of neural network efficiently. As a result they are huge in terms of parameters and number of operations; hence slow too. In this paper. we propose a novel deep neural network architecture which allows it to learn without any significant increase in number of parameters. Our network uses only 11.5 million parameters and 21.2 GFLOPs for processing an image of resolution 3 × 640 × 360. It gives state-of-the-art performance on CamVid and comparable results on Cityscapes dataset. We also compare our networks processing time on NVIDIA GPU and embedded system device with existing state-of-the-art architectures for different image resolutions.,True,SeGmqkIAAAAJ:JQOojiI6XY0C,399,https://ieeexplore.ieee.org/abstract/document/8305148/,36680124474753890,/scholar?cites=36680124474753890,,,https://arxiv.org/pdf/1707.03718.pdf%5D,0,0,0
1278176,A biomorphic digital image sensor,2003,Eugenio Culurciello and Ralph Etienne-Cummings and Kwabena A Boahen,38,IEEE Journal of Solid-State Circuits,2,281-294,IEEE,An arbitrated address-event imager has been designed and fabricated in a 0.6-μm CMOS process. The imager is composed of 80 × 60 pixels of 32 × 30 μm. The value of the light intensity collected by each photosensitive element is inversely proportional to the pixel's interspike time interval. The readout of each spike is initiated by the individual pixel; therefore. the available output bandwidth is allocated according to pixel output demand. This encoding of light intensities favors brighter pixels. equalizes the number of integrated photons across light intensity. and minimizes power consumption. Tests conducted on the imager showed a large output dynamic range of 180 dB (under bright local illumination) for an individual pixel. The array. on the other hand. produced a dynamic range of 120 dB (under uniform bright illumination and when no lower bound was placed on the update rate per pixel). The dynamic range is …,True,SeGmqkIAAAAJ:u5HHmVD_uO8C,379,https://ieeexplore.ieee.org/abstract/document/1175509/,1946787689839092899,/scholar?cites=1946787689839092899,,,https://repository.upenn.edu/cgi/viewcontent.cgi?article=1027&context=be_papers,0,0,0
1278177,Hardware accelerated convolutional neural networks for synthetic vision systems,2010,Clément Farabet and Berin Martini and Polina Akselrod and Selçuk Talay and Yann LeCun and Eugenio Culurciello,,,,257-260,IEEE,In this paper we present a scalable hardware architecture to implement large-scale convolutional neural networks and state-of-the-art multi-layered artificial vision systems. This system is fully digital and is a modular vision engine with the goal of performing real-time detection. recognition and segmentation of mega-pixel images. We present a performance comparison between a software. FPGA and ASIC implementation that shows a speed up in custom hardware implementations.,True,SeGmqkIAAAAJ:8k81kl-MbHgC,310,https://ieeexplore.ieee.org/abstract/document/5537908/,13108728441784567062,/scholar?cites=13108728441784567062,,,https://www.academia.edu/download/51056100/Hardware_Accelerated_Convolutional_Neura20161225-5441-np1m88.pdf,0,0,0
1278178,A 240 g-ops/s mobile coprocessor for deep neural networks,2014,Vinayak Gokhale and Jonghoon Jin and Aysegul Dundar and Berin Martini and Eugenio Culurciello,,,,682-687,,Deep networks are state-of-the-art models used for understanding the content of images. videos. audio and raw input data. Current computing systems are not able to run deep network models in real-time with low power consumption. In this paper we present nn-X: a scalable. low-power coprocessor for enabling real-time execution of deep neural networks. nn-X is implemented on programmable logic devices and comprises an array of configurable processing elements called collections. These collections perform the most common operations in deep networks: convolution. subsampling and non-linear functions. The nn-X system includes 4 high-speed direct memory access interfaces to DDR3 memory and two ARM Cortex-A9 processors. Each port is capable of a sustained throughput of 950 MB/s in full duplex. nn-X is able to achieve a peak performance of 227 G-ops/s. a measured performance in deep learning applications of up to 200 G-ops/s while consuming less than 4 watts of power. This translates to a performance per power improvement of 10 to 100 times that of conventional mobile and desktop processors.,True,SeGmqkIAAAAJ:kRWSkSYxWN8C,302,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W17/html/Gokhale_A_240_G-opss_2014_CVPR_paper.html,14257947925461129718,/scholar?cites=14257947925461129718,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W17/papers/Gokhale_A_240_G-opss_2014_CVPR_paper.pdf,0,0,0
1278179,Activity-driven. event-based vision sensors,2010,Tobi Delbrück and Bernabe Linares-Barranco and Eugenio Culurciello and Christoph Posch,,,,2426-2429,IEEE,"The four chips presented in the special session on ""Activity-driven. event-based vision sensors"" quickly output compressed digital data in the form of events. These sensors reduce redundancy and latency and increase dynamic range compared with conventional imagers. The digital sensor output is easily interfaced to conventional digital post processing. where it reduces the latency and cost of post processing compared to imagers. The asynchronous data could spawn a new area of DSP that breaks from conventional Nyquist rate signal processing. This paper reviews the rationale and history of this event-based approach. introduces sensor functionalities. and gives an overview of the papers in this session. The paper concludes with a brief discussion on open questions.",True,SeGmqkIAAAAJ:_kc_bZDykSQC,195,https://ieeexplore.ieee.org/abstract/document/5537149/,12448519096296577172,/scholar?cites=12448519096296577172,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.192.1551&rep=rep1&type=pdf,0,0,0
1278180,Spatially compact neural clusters in the dorsal striatum encode locomotion relevant information,2016,Giovanni Barbera and Bo Liang and Lifeng Zhang and Charles R Gerfen and Eugenio Culurciello and Rong Chen and Yun Li and Da-Ting Lin,92,Neuron,1,202-213,Cell Press,An influential striatal model postulates that neural activities in the striatal direct and indirect pathways promote and inhibit movement. respectively. Normal behavior requires coordinated activity in the direct pathway to facilitate intended locomotion and indirect pathway to inhibit unwanted locomotion. In this striatal model. neuronal population activity is assumed to encode locomotion relevant information. Here. we propose a novel encoding mechanism for the dorsal striatum. We identified spatially compact neural clusters in both the direct and indirect pathways. Detailed characterization revealed similar cluster organization between the direct and indirect pathways. and cluster activities from both pathways were correlated with mouse locomotion velocities. Using machine-learning algorithms. cluster activities could be used to decode locomotion relevant behavioral states and locomotion velocity. We propose that …,True,SeGmqkIAAAAJ:5awf1xo2G04C,174,https://www.sciencedirect.com/science/article/pii/S089662731630530X,5078727646050123924,/scholar?cites=5078727646050123924,,,https://www.sciencedirect.com/science/article/pii/S089662731630530X,0,0,0
1278181,Flattened convolutional neural networks for feedforward acceleration,2014,Jonghoon Jin and Aysegul Dundar and Eugenio Culurciello,,arXiv preprint arXiv:1412.5474,,,,We present flattened convolutional neural networks that are designed for fast feedforward execution. The redundancy of the parameters. especially weights of the convolutional filters in convolutional neural networks has been extensively studied and different heuristics have been proposed to construct a low rank basis of the filters after training. In this work. we train flattened networks that consist of consecutive sequence of one-dimensional filters across all directions in 3D space to obtain comparable performance as conventional convolutional networks. We tested flattened model on different datasets and found that the flattened layer can effectively substitute for the 3D filters without loss of accuracy. The flattened convolution pipelines provide around two times speed-up during feedforward pass compared to the baseline model due to the significant reduction of learning parameters. Furthermore. the proposed method does not require efforts in manual tuning or post processing once the model is trained.,True,SeGmqkIAAAAJ:bnK-pcrLprsC,173,https://arxiv.org/abs/1412.5474,7847245353859028508,/scholar?cites=7847245353859028508,,,https://arxiv.org/pdf/1412.5474,0,0,0
1278182,Capacitive inter-chip data and power transfer for 3-D VLSI,2006,Eugenio Culurciello and Andreas G Andreou,53,IEEE Transactions on Circuits and Systems II: Express Briefs,12,1348-1352,IEEE,We report on inter-chip bidirectional communication and power transfer between two stacked chips. The experimental prototype system components were fabricated in a 0.5-mum silicon-on-sapphire CMOS technology. Bi-directional communication between the two chips is experimentally measured at 1Hz-15 MHz. The circuits on the floating top chip are powered with capacitively coupled energy using a charge pump. This is the first demonstration of simultaneous nongalvanic power and data transfer between chips in a stack. The potential use in 3-D VLSI is aimed at reducing costs and complexity that are associated with galvanic inter-chip vias in 3-D integration,True,SeGmqkIAAAAJ:UeHWp8X0CEIC,123,https://ieeexplore.ieee.org/abstract/document/4033147/,8464071480641407644,/scholar?cites=8464071480641407644,,,,0,0,0
1278183,A no-reference objective image sharpness metric based on the notion of just noticeable blur (JNB),2009,Rony Ferzli and Lina J Karam,18,IEEE transactions on image processing,4,717-728,IEEE,This work presents a perceptual-based no-reference objective image sharpness/blurriness metric by integrating the concept of just noticeable blur into a probability summation model. Unlike existing objective no-reference image sharpness/blurriness metrics. the proposed metric is able to predict the relative amount of blurriness in images with different content. Results are provided to illustrate the performance of the proposed perceptual-based sharpness metric. These results show that the proposed sharpness metric correlates well with the perceived sharpness being able to predict with high accuracy the relative amount of blurriness in images with different content.,True,VPaETnoAAAAJ:u5HHmVD_uO8C,816,https://ieeexplore.ieee.org/abstract/document/4799375/,17032134277705541693,/scholar?cites=17032134277705541693,,,https://imaging.utk.edu/research/wcho/references/2009%20TIP%20JNBM.pdf,0,0,0
1278184,Objective video quality assessment methods: A classification. review. and performance comparison,2011,Shyamprasad Chikkerur and Vijay Sundaram and Martin Reisslein and Lina J Karam,57,IEEE transactions on broadcasting,2,165-182,IEEE,With the increasing demand for video-based applications. the reliable prediction of video quality has increased in importance. Numerous video quality assessment methods and metrics have been proposed over the past years with varying computational complexity and accuracy. In this paper. we introduce a classification scheme for full-reference and reduced-reference media-layer objective video quality assessment methods. Our classification scheme first classifies a method according to whether natural visual characteristics or perceptual (human visual system) characteristics are considered. We further subclassify natural visual characteristics methods into methods based on natural visual statistics or natural visual features. We subclassify perceptual characteristics methods into frequency or pixel-domain methods. According to our classification scheme. we comprehensively review and compare the media-layer …,True,VPaETnoAAAAJ:u-x6o8ySG0sC,664,https://ieeexplore.ieee.org/abstract/document/5710601/,17077831798081041320,/scholar?cites=17077831798081041320,,,https://www.researchgate.net/profile/Vijay_Sundaram4/publication/224217861_Objective_Video_Quality_Assessment_Methods_A_Classification_Review_and_Performance_Comparison/links/53ea624c0cf28f342f41a1fb/Objective-Video-Quality-Assessment-Methods-A-Classification-Review-and-Performance-Comparison.pdf,0,0,0
1278185,A no-reference image blur metric based on the cumulative probability of blur detection (CPBD),2011,Niranjan D Narvekar and Lina J Karam,20,IEEE Transactions on Image Processing,9,2678-2683,IEEE,This paper presents a no-reference image blur metric that is based on the study of human blur perception for varying contrast values. The metric utilizes a probabilistic model to estimate the probability of detecting blur at each edge in the image. and then the information is pooled by computing the cumulative probability of blur detection (CPBD). The performance of the metric is demonstated by comparing it with existing no-reference sharpness/blurriness metrics for various publicly available image databases.,True,VPaETnoAAAAJ:2osOgNQ5qMEC,458,https://ieeexplore.ieee.org/abstract/document/5739529/,16505549643508126543,/scholar?cites=16505549643508126543,,,https://imaging.utk.edu/research/wcho/references/2011%20TIP%20CPBM.pdf,0,0,0
1278186,Understanding how image quality affects deep neural networks,2016,Samuel Dodge and Lina Karam,,,,1-6,IEEE,Image quality is an important practical challenge that is often overlooked in the design of machine vision systems. Commonly. machine vision systems are trained and tested on high quality image datasets. yet in practical applications the input images can not be assumed to be of high quality. Recently. deep neural networks have obtained state-of-the-art performance on many machine vision tasks. In this paper we provide an evaluation of 4 state-of-the-art deep neural network models for image classification under quality distortions. We consider five types of quality distortions: blur. noise. contrast. JPEG. and JPEG2000 compression. We show that the existing networks are susceptible to these quality distortions. particularly to blur and noise. These results enable future work in developing deep neural networks that are more invariant to quality distortions.,True,VPaETnoAAAAJ:a9-T7VOCCH8C,409,https://ieeexplore.ieee.org/abstract/document/7498955/,7843123208178714020,/scholar?cites=7843123208178714020,,,https://arxiv.org/pdf/1604.04004.pdf%C3%A6%C5%93%E2%80%B0%C3%A7%E2%80%9A%C2%B9%C3%A5%E2%84%A2%C2%AA%C3%A9%C5%B8%C2%B3%C3%A6%CB%86%E2%80%93%C3%A6%C2%A8%C2%A1%C3%A7%C2%B3%C5%A0%C3%A4%C2%BC%C5%A1%C3%A5%C2%AF%C2%BC%C3%A8%E2%80%A1%C2%B4DNN%C3%A6%E2%82%AC%C2%A7%C3%A8%C6%92%C2%BD%C3%A6%CB%9C%C2%BE%C3%A7%20%E2%82%AC%C3%A4%C2%B8%E2%80%B9%C3%A9%E2%84%A2%20%C3%A3%E2%82%AC%E2%80%9A,0,0,0
1278187,Morphological text extraction from images,2000,Yassin MY Hasan and Lina J Karam,9,IEEE Transactions on Image Processing,11,1978-1983,IEEE,This paper presents a morphological technique for text extraction from images. The proposed morphological technique is insensitive to noise. skew and text orientation. It is also free from artifacts that are usually introduced by both fixed/optimal global thresholding and fixed-size block-based local thresholding. Examples are presented to illustrate the performance of the proposed method.,True,VPaETnoAAAAJ:9yKSN-GCB0IC,241,https://ieeexplore.ieee.org/abstract/document/877220/,7010159450684564655,/scholar?cites=7010159450684564655,,,,0,0,0
1278188,A study and comparison of human and deep learning recognition performance under visual distortions,2017,Samuel Dodge and Lina Karam,,,,1-7,IEEE,Deep neural networks (DNNs) achieve excellent performance on standard classification tasks. However. under image quality distortions such as blur and noise. classification accuracy becomes poor. In this work. we compare the performance of DNNs with human subjects on distorted images. We show that. although DNNs perform better than or on par with humans on good quality images. DNN performance is still much lower than human performance on distorted images. We additionally find that there is little correlation in errors between DNNs and human subjects. This could be an indication that the internal representation of images are different between DNNs and the human visual system. These comparisons with human performance could be used to guide future development of more robust DNNs.,True,VPaETnoAAAAJ:yxmsSjX2EkcC,234,https://ieeexplore.ieee.org/abstract/document/8038465/,16818468554786551038,/scholar?cites=16818468554786551038,,,https://arxiv.org/pdf/1705.02498,0,0,0
1278189,Complex Chebyshev approximation for FIR filter design,1995,Lina J Karam and James H McClellan,42,IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing,3,207-216,IEEE,The alternation theorem is at the core of efficient real Chebyshev approximation algorithms. In this paper. the alternation theorem is extended from the real-only to the complex case. The complex FIR filter design problem is reformulated so that it clearly satisfies the Haar condition of Chebyshev approximation. An efficient exchange algorithm is derived for designing complex FIR filters in the Chebyshev sense. By transforming the complex error function. the Remez exchange algorithm can be used to compute the optimal complex Chebyshev approximation. The algorithm converges to the optimal solution whenever the complex Chebyshev error alternates; in all other cases. the algorithm converges to the optimal Chebyshev approximation over a subset of the desired bands. The new algorithm is a generalization of the Parks-McClellan algorithm. so that arbitrary magnitude and phase responses can be approximated …,True,VPaETnoAAAAJ:d1gkVwhDpl0C,234,https://ieeexplore.ieee.org/abstract/document/372870/,18006085733073489068,/scholar?cites=18006085733073489068,,,,0,0,0
1278190,JPEG2000 encoding with perceptual distortion control,2006,Zhen Liu and Lina J Karam and Andrew B Watson,15,IEEE transactions on image processing,7,1763-1778,IEEE,In this paper. a new encoding approach is proposed to control the JPEG2000 encoding in order to reach a desired perceptual quality. The new method is based on a vision model that incorporates various masking effects of human visual perception and a perceptual distortion metric that takes spatial and spectral summation of individual quantization errors into account. Compared with the conventional rate-based distortion minimization JPEG2000 encoding. the new method provides a way to generate consistent quality images at a lower bit rate.,True,VPaETnoAAAAJ:qjMakFHDy7sC,194,https://ieeexplore.ieee.org/abstract/document/1643687/,7770015800464563222,/scholar?cites=7770015800464563222,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.374.5045&rep=rep1&type=pdf,0,0,0
1278191,Adaptive image coding with perceptual distortion control,2002,Ingo Hontsch and Lina J Karam,11,IEEE transactions on image processing,3,213-222,IEEE,This paper presents a discrete cosine transform (DCT)-based locally adaptive perceptual image coder. which discriminates between image components based on their perceptual relevance for achieving increased performance in terms of quality and bit rate. The new coder uses a locally adaptive perceptual quantization scheme based on a tractable perceptual distortion metric. Our strategy is to exploit human visual masking properties by deriving visual masking thresholds in a locally adaptive fashion. The derived masking thresholds are used in controlling the quantization stage by adapting the quantizer reconstruction levels in order to meet the desired target perceptual distortion. The proposed coding scheme is flexible in that it can be easily extended to work with any subband-based decomposition in addition to block-based transform methods. Compared to existing perceptual coding methods. the proposed …,True,VPaETnoAAAAJ:IjCSPb-OGe4C,185,https://ieeexplore.ieee.org/abstract/document/988955/,10128986196907480120,/scholar?cites=10128986196907480120,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.7099&rep=rep1&type=pdf,0,0,0
1278192,Trends in multicore DSP platforms,2009,Lina Karam and Ismail AlKamal and Alan Gatherer and Gene A Frantz and David V Anderson and Brian L Evans,26,IEEE signal processing magazine,6,38-49,IEEE,In the last two years. the embedded DSP market has been swept up by the general increase in interest in multicore that has been driven by companies such as Intel and Sun. One reason for this is that there is now a lot of focus on tooling in academia and also a willingness on the part of users to accept new programming paradigms. This industry-wide effort will have an effect on the way multicore DSPs are programmed and perhaps architected. But it is too early to say in what way this will occur. Programming multicore DSPs remains very challenging. The problem of how to take a piece of sequential code and optimally partition it across multiple cores remains unsolved. Hence. there will naturally be a lot of variations in the approaches taken. Equally important is the issue of debugging and visibility. Developing effective and easy-to-use code development and real-time debug tools is tremendously important as the …,True,VPaETnoAAAAJ:zYLM7Y9cAGgC,173,https://ieeexplore.ieee.org/abstract/document/5230802/,12820422876066386993,/scholar?cites=12820422876066386993,,,https://www.ece.ucdavis.edu/~bbaas/281/papers/TrendsInMulticoreDSP.Gatherer.pdf,0,0,0
1278193,Locally adaptive perceptual image coding,2000,Ingo Hontsch and Lina J Karam,9,IEEE Transactions on Image Processing,9,1472-1483,IEEE,Most existing efforts in image and video compression have focused on developing methods to minimize not perceptual but rather mathematically tractable. easy to measure. distortion metrics. While nonperceptual distortion measures were found to be reasonably reliable for higher bit rates (high-quality applications). they do not correlate well with the perceived quality at lower bit rates and they fail to guarantee preservation of important perceptual qualities in the reconstructed images despite the potential for a good signal-to-noise ratio (SNR). This paper presents a perceptual-based image coder. which discriminates between image components based on their perceptual relevance for achieving increased performance in terms of quality and bit rate. The new coder is based on a locally adaptive perceptual quantization scheme for compressing the visual data. Our strategy is to exploit human visual masking properties …,True,VPaETnoAAAAJ:UeHWp8X0CEIC,164,https://ieeexplore.ieee.org/abstract/document/862622/,4671959054004500297,/scholar?cites=4671959054004500297,,,,0,0,0
1278194,Hotspot mutations in H3F3A and IDH1 define distinct epigenetic and biological subgroups of glioblastoma,2012,Dominik Sturm and Hendrik Witt and Volker Hovestadt and Dong-Anh Khuong-Quang and David TW Jones and Carolin Konermann and Elke Pfaff and Martje Tönjes and Martin Sill and Sebastian Bender and Marcel Kool and Marc Zapatka and Natalia Becker and Manuela Zucknick and Thomas Hielscher and Xiao-Yang Liu and Adam M Fontebasso and Marina Ryzhova and Steffen Albrecht and Karine Jacob and Marietta Wolter and Martin Ebinger and Martin U Schuhmann and Timothy van Meter and Michael C Frühwald and Holger Hauch and Arnulf Pekrun and Bernhard Radlwimmer and Tim Niehues and Gregor Von Komorowski and Matthias Dürken and Andreas E Kulozik and Jenny Madden and Andrew Donson and Nicholas K Foreman and Rachid Drissi and Maryam Fouladi and Wolfram Scheurlen and Andreas von Deimling and Camelia Monoranu and Wolfgang Roggendorf and Christel Herold-Mende and Andreas Unterberg and Christof M Kramm and Jörg Felsberg and Christian Hartmann and Benedikt Wiestler and Wolfgang Wick and Till Milde and Olaf Witt and Anders M Lindroth and Jeremy Schwartzentruber and Damien Faury and Adam Fleming and Magdalena Zakrzewska and Pawel P Liberski and Krzysztof Zakrzewski and Peter Hauser and Miklos Garami and Almos Klekner and Laszlo Bognar and Sorana Morrissy and Florence Cavalli and Michael D Taylor and Peter van Sluis and Jan Koster and Rogier Versteeg and Richard Volckmann and Tom Mikkelsen and Kenneth Aldape and Guido Reifenberger and V Peter Collins and Jacek Majewski and Andrey Korshunov and Peter Lichter and Christoph Plass and Nada Jabado and Stefan M Pfister,22,Cancer cell,4,425-437,Cell Press,Glioblastoma (GBM) is a brain tumor that carries a dismal prognosis and displays considerable heterogeneity. We have recently identified recurrent H3F3A mutations affecting two critical amino acids (K27 and G34) of histone H3.3 in one-third of pediatric GBM. Here. we show that each H3F3A mutation defines an epigenetic subgroup of GBM with a distinct global methylation pattern. and that they are mutually exclusive with IDH1 mutations. which characterize a third mutation-defined subgroup. Three further epigenetic subgroups were enriched for hallmark genetic events of adult GBM and/or established transcriptomic signatures. We also demonstrate that the two H3F3A mutations give rise to GBMs in separate anatomic compartments. with differential regulation of transcription factors OLIG1. OLIG2. and FOXG1. possibly reflecting different cellular origins.,True,-EEm-_MAAAAJ:yB1At4FlUx8C,1400,https://www.sciencedirect.com/science/article/pii/S1535610812003649,11353818512397085728,/scholar?cites=11353818512397085728,,,https://www.sciencedirect.com/science/article/pii/S1535610812003649,0,0,0
1278195,A vaccine targeting mutant IDH1 induces antitumour immunity,2014,Theresa Schumacher and Lukas Bunse and Stefan Pusch and Felix Sahm and Benedikt Wiestler and Jasmin Quandt and Oliver Menn and Matthias Osswald and Iris Oezen and Martina Ott and Melanie Keil and Jörg Balß and Katharina Rauschenbach and Agnieszka K Grabowska and Isabel Vogler and Jan Diekmann and Nico Trautwein and Stefan B Eichmüller and Jürgen Okun and Stefan Stevanović and Angelika B Riemer and Ugur Sahin and Manuel A Friese and Philipp Beckhove and Andreas von Deimling and Wolfgang Wick and Michael Platten,512,Nature,7514,324-327,Nature Publishing Group,Monoallelic point mutations of isocitrate dehydrogenase type 1 (IDH1) are an early and defining event in the development of a subgroup of gliomas 1. 2. 3 and other types of tumour 4. 5. 6. They almost uniformly occur in the critical arginine residue (Arg 132) in the catalytic pocket. resulting in a neomorphic enzymatic function. production of the oncometabolite 2-hydroxyglutarate (2-HG) 7. 8. genomic hypermethylation 9. 10. 11. genetic instability and malignant transformation 12. More than 70% of diffuse grade II and grade III gliomas carry the most frequent mutation. IDH1 (R132H)(ref. 3). From an immunological perspective. IDH1 (R132H) represents a potential target for immunotherapy as it is a tumour-specific potential neoantigen with high uniformity and penetrance expressed in all tumour cells 13. 14. Here we demonstrate that IDH1 (R132H) contains an immunogenic epitope suitable for mutation-specific …,True,-EEm-_MAAAAJ:HbR8gkJAVGIC,506,https://www.nature.com/articles/nature13387,16005576618138197653,/scholar?cites=16005576618138197653,,,,0,0,0
1278196,Identifying the best machine learning algorithms for brain tumor segmentation. progression assessment. and overall survival prediction in the BRATS challenge,2018,Spyridon Bakas and Mauricio Reyes and Andras Jakab and Stefan Bauer and Markus Rempfler and Alessandro Crimi and Russell Takeshi Shinohara and Christoph Berger and Sung Min Ha and Martin Rozycki and Marcel Prastawa and Esther Alberts and Jana Lipkova and John Freymann and Justin Kirby and Michel Bilello and Hassan Fathallah-Shaykh and Roland Wiest and Jan Kirschke and Benedikt Wiestler and Rivka Colen and Aikaterini Kotrotsou and Pamela Lamontagne and Daniel Marcus and Mikhail Milchenko and Arash Nazeri and Marc-Andre Weber and Abhishek Mahajan and Ujjwal Baid and Elizabeth Gerstner and Dongjin Kwon and Gagan Acharya and Manu Agarwal and Mahbubul Alam and Alberto Albiol and Antonio Albiol and Francisco J Albiol and Varghese Alex and Nigel Allinson and Pedro HA Amorim and Abhijit Amrutkar and Ganesh Anand and Simon Andermatt and Tal Arbel and Pablo Arbelaez and Aaron Avery and Muneeza Azmat and W Bai and Subhashis Banerjee and Bill Barth and Thomas Batchelder and Kayhan Batmanghelich and Enzo Battistella and Andrew Beers and Mikhail Belyaev and Martin Bendszus and Eze Benson and Jose Bernal and Halandur Nagaraja Bharath and George Biros and Sotirios Bisdas and James Brown and Mariano Cabezas and Shilei Cao and Jorge M Cardoso and Eric N Carver and Adrià Casamitjana and Laura Silvana Castillo and Marcel Catà and Philippe Cattin and Albert Cerigues and Vinicius S Chagas and Siddhartha Chandra and Yi-Ju Chang and Shiyu Chang and Ken Chang and Joseph Chazalon and Shengcong Chen and Wei Chen and Jefferson W Chen and Zhaolin Chen and Kun Cheng and Ahana Roy Choudhury and Roger Chylla and Albert Clérigues and Steven Colleman and Ramiro German Rodriguez Colmeiro and Marc Combalia and Anthony Costa and Xiaomeng Cui and Zhenzhen Dai and Lutao Dai and Laura Alexandra Daza and Eric Deutsch and Changxing Ding and Chao Dong and Shidu Dong and Wojciech Dudzik and Zach Eaton-Rosen,,arXiv preprint arXiv:1811.02629,,,,Gliomas are the most common primary brain malignancies. with different degrees of aggressiveness. variable prognosis and various heterogeneous histologic sub-regions. ie. peritumoral edematous/invaded tissue. necrotic core. active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype. as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans. reflecting varying biological properties. Their heterogeneous shape. extent. and location are some of the factors that make these tumors difficult to resect. and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans. when evaluating the apparent tumor for potential diagnosis of progression. Furthermore. there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans. during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge. ie. 2012-2018. Specifically. we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans. ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions. beyond use of the RECIST/RANO criteria. and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally. we investigate the challenge …,True,-EEm-_MAAAAJ:ZuybSZzF8UAC,487,https://arxiv.org/abs/1811.02629,7713865873909162489,/scholar?cites=7713865873909162489,,,https://arxiv.org/pdf/1811.02629,0,0,0
1278197,Brain tumour cells interconnect to a functional and resistant network,2015,Matthias Osswald and Erik Jung and Felix Sahm and Gergely Solecki and Varun Venkataramani and Jonas Blaes and Sophie Weil and Heinz Horstmann and Benedikt Wiestler and Mustafa Syed and Lulu Huang and Miriam Ratliff and Kianush Karimian Jazi and Felix T Kurz and Torsten Schmenger and Dieter Lemke and Miriam Gömmel and Martin Pauli and Yunxiang Liao and Peter Häring and Stefan Pusch and Verena Herl and Christian Steinhäuser and Damir Krunic and Mostafa Jarahian and Hrvoje Miletic and Anna S Berghoff and Oliver Griesbeck and Georgios Kalamakis and Olga Garaschuk and Matthias Preusser and Samuel Weiss and Haikun Liu and Sabine Heiland and Michael Platten and Peter E Huber and Thomas Kuner and Andreas von Deimling and Wolfgang Wick and Frank Winkler,528,Nature,7580,93-98,Nature Publishing Group,Astrocytic brain tumours. including glioblastomas. are incurable neoplasms characterized by diffusely infiltrative growth. Here we show that many tumour cells in astrocytomas extend ultra-long membrane protrusions. and use these distinct tumour microtubes as routes for brain invasion. proliferation. and to interconnect over long distances. The resulting network allows multicellular communication through microtube-associated gap junctions. When damage to the network occurred. tumour microtubes were used for repair. Moreover. the microtube-connected astrocytoma cells. but not those remaining unconnected throughout tumour progression. were protected from cell death inflicted by radiotherapy. The neuronal growth-associated protein 43 was important for microtube formation and function. and drove microtube-dependent tumour cell invasion. proliferation. interconnection. and radioresistance. Oligodendroglial …,True,-EEm-_MAAAAJ:tKAzc9rXhukC,473,https://www.nature.com/articles/nature16071,9468427307091946790,/scholar?cites=9468427307091946790,,,,0,0,0
1278198,ATRX and IDH1-R132H immunohistochemistry with subsequent copy number analysis and IDH sequencing as a basis for an “integrated” diagnostic approach for …,2015,David E Reuss and Felix Sahm and Daniel Schrimpf and Benedikt Wiestler and David Capper and Christian Koelsche and Leonille Schweizer and Andrey Korshunov and David TW Jones and Volker Hovestadt and Michel Mittelbronn and Jens Schittenhelm and Christel Herold-Mende and Andreas Unterberg and Michael Platten and Michael Weller and Wolfgang Wick and Stefan M Pfister and Andreas von Deimling,129,Acta neuropathologica,1,133-146,Springer Berlin Heidelberg,Diffuse gliomas are represented in the 2007 WHO classification as astrocytomas. oligoastrocytomas and oligodendrogliomas of grades II and III and glioblastomas WHO grade IV. Molecular data on these tumors have a major impact on prognosis and therapy of the patients. Consequently. the inclusion of molecular parameters in the WHO definition of brain tumors is being planned and has been forwarded as the “ISN-Haarlem” consensus. We. here. analyze markers of special interest including ATRX. IDH and 1p/19q codeletion in a series of 405 adult patients. Among the WHO 2007 classified tumors were 152 astrocytomas. 61 oligodendrogliomas. 63 oligoastrocytomas and 129 glioblastomas. Following the concepts of the “ISN-Haarlem”. we rediagnosed the series to obtain “integrated” diagnoses with 155 tumors being astrocytomas. 100 oligodendrogliomas and 150 glioblastomas. In a subset of 100 …,True,-EEm-_MAAAAJ:WbkHhVStYXYC,378,https://link.springer.com/content/pdf/10.1007/s00401-014-1370-3.pdf,161570053861975591,/scholar?cites=161570053861975591,,,https://www.zora.uzh.ch/id/eprint/104736/1/Reuss1%20ATRX.pdf,0,0,0
1278199,Yes and PI3K bind CD95 to signal invasion of glioblastoma,2008,Susanne Kleber and Ignacio Sancho-Martinez and Benedict Wiestler and Alexandra Beisel and Christian Gieffers and Oliver Hill and Meinolf Thiemann and Wolf Mueller and Jaromir Sykora and Andreas Kuhn and Nina Schreglmann and Elisabeth Letellier and Cecilia Zuliani and Stefan Klussmann and Marcin Teodorczyk and Hermann-Josef Gröne and Tom M Ganten and Holger Sültmann and Jochen Tüttenberg and Andreas von Deimling and Anne Regnier-Vigouroux and Christel Herold-Mende and Ana Martin-Villalba,13,Cancer cell,3,235-248,Cell Press,Invasion of surrounding brain tissue by isolated tumor cells represents one of the main obstacles to a curative therapy of glioblastoma multiforme. Here we unravel a mechanism regulating glioma infiltration. Tumor interaction with the surrounding brain tissue induces CD95 Ligand expression. Binding of CD95 Ligand to CD95 on glioblastoma cells recruits the Src family member Yes and the p85 subunit of phosphatidylinositol 3-kinase to CD95. which signal invasion via the glycogen synthase kinase 3-β pathway and subsequent expression of matrix metalloproteinases. In a murine syngeneic model of intracranial GBM. neutralization of CD95 activity dramatically reduced the number of invading cells. Our results uncover CD95 as an activator of PI3K and. most importantly. as a crucial trigger of basal invasion of glioblastoma in vivo.,True,-EEm-_MAAAAJ:_Re3VWB3Y0AC,304,https://www.sciencedirect.com/science/article/pii/S1535610808000433,9651432120481968013,/scholar?cites=9651432120481968013,,,https://www.sciencedirect.com/science/article/pii/S1535610808000433,0,0,0
1278200,ATRX loss refines the classification of anaplastic gliomas and identifies a subgroup of IDH mutant astrocytic tumors with better prognosis,2013,Benedikt Wiestler and David Capper and Tim Holland-Letz and Andrey Korshunov and Andreas von Deimling and Stefan Michael Pfister and Michael Platten and Michael Weller and Wolfgang Wick,126,Acta neuropathologica,3,443-451,Springer Berlin Heidelberg,Mutation/loss of alpha-thalassemia/mental retardation syndrome X-linked (ATRX) expression has been described in anaplastic gliomas. The present study explored the role of ATRX status in the molecular classification of anaplastic gliomas and its impact on survival in the biomarker cohort of the NOA-04 anaplastic glioma trial. Patients (n = 133) of the NOA-04 trial were analyzed for ATRX expression using immunohistochemistry. ATRX status was correlated with age. histology. isocitrate dehydrogenase (IDH). 1p/19q. alternative lengthening of telomeres (ALT) and O6-methylguanine-DNA methyltransferase (MGMT) status. and the trial efficacy endpoints. Loss of ATRX expression was detected in 45 % of anaplastic astrocytomas (AA). 27 % of anaplastic oligoastrocytomas (AOA) and 10 % of anaplastic oligodendrogliomas (AO). It was mostly restricted to IDH mutant tumors and almost mutually exclusive with …,True,-EEm-_MAAAAJ:bnK-pcrLprsC,303,https://link.springer.com/content/pdf/10.1007/s00401-013-1156-z.pdf,4116156621752379400,/scholar?cites=4116156621752379400,,,https://www.zora.uzh.ch/id/eprint/79916/1/ANP-D-13-00386_Revised.pdf,0,0,0
1278201,Distribution of TERT promoter mutations in pediatric and adult tumors of the nervous system,2013,Christian Koelsche and Felix Sahm and David Capper and David Reuss and Dominik Sturm and David TW Jones and Marcel Kool and Paul A Northcott and Benedikt Wiestler and Katja Böhmer and Jochen Meyer and Christian Mawrin and Christian Hartmann and Michel Mittelbronn and Michael Platten and Benjamin Brokinkel and Marcel Seiz and Christel Herold-Mende and Andreas Unterberg and Jens Schittenhelm and Michael Weller and Stefan Pfister and Wolfgang Wick and Andrey Korshunov and Andreas von Deimling,126,Acta neuropathologica,6,907-915,Springer Berlin Heidelberg,Hot spot mutations in the promoter region of telomerase reverse transcriptase (TERT) have recently been described in several human tumor entities. These mutations result in an upregulation of the telomerase complex activity and thus constitute a relevant mechanism for immortalization of tumor cells. Knowledge of the TERT promoter status in tumors is likely to be of interest for molecular classification and as a potential target for therapy. We. therefore. performed a systematic analysis of TERT promoter mutations in 1.515 tumors of the human nervous system and its coverings including 373 pediatric and 1.142 adult patients. We detected a total of 327 mutations. TERT promoter mutations were exceedingly rare in tumors typically encountered in pediatric patients. In entities typically encountered in adult patients TERT promoter mutations were strongly associated with older age (p < 0.0001). Highest mutation …,True,-EEm-_MAAAAJ:5awf1xo2G04C,235,https://link.springer.com/content/pdf/10.1007/s00401-013-1195-5.pdf,7145599795954756023,/scholar?cites=7145599795954756023,,,https://www.zora.uzh.ch/id/eprint/85416/1/TERT_mutations_in_tumors_of_the_central_nervous_system_-_Revision_inkl__figures.pdf,0,0,0
1278202,IDH mutation status is associated with a distinct hypoxia/angiogenesis transcriptome signature which is non-invasively predictable with rCBV imaging in human glioma,2015,Philipp Kickingereder and Felix Sahm and Alexander Radbruch and Wolfgang Wick and Sabine Heiland and Andreas Von Deimling and Martin Bendszus and Benedikt Wiestler,5,Scientific reports,1,1-9,Nature Publishing Group,The recent identification of IDH mutations in gliomas and several other cancers suggests that this pathway is involved in oncogenesis; however effector functions are complex and yet incompletely understood. To study the regulatory effects of IDH on hypoxia-inducible-factor 1-alpha (HIF1A). a driving force in hypoxia-initiated angiogenesis. we analyzed mRNA expression profiles of 288 glioma patients and show decreased expression of HIF1A targets on a single-gene and pathway level. strong inhibition of upstream regulators such as HIF1A and downstream biological functions such as angio-and vasculogenesis in IDH mutant tumors. Genotype/imaging phenotype correlation analysis with relative cerebral blood volume (rCBV) MRI–a robust and non-invasive estimate of tumor angiogenesis–in 73 treatment-naive patients with low-grade and anaplastic gliomas showed that a one-unit increase in rCBV …,True,-EEm-_MAAAAJ:5qfkUJPXOUwC,203,https://www.nature.com/articles/srep16238,17248520421420353005,/scholar?cites=17248520421420353005,,,https://www.nature.com/articles/srep16238,0,0,0
1278203,Prognostic or predictive value of MGMT promoter methylation in gliomas depends on IDH1 mutation,2013,Wolfgang Wick and Christoph Meisner and Bettina Hentschel and Michael Platten and Alissa Schilling and Benedikt Wiestler and Michael C Sabel and Susanne Koeppen and Ralf Ketter and Markus Weiler and Ghazaleh Tabatabai and Andreas von Deimling and Dorothee Gramatzki and Manfred Westphal and Gabriele Schackert and Markus Loeffler and Matthias Simon and Guido Reifenberger and Michael Weller,81,Neurology,17,1515-1522,Wolters Kluwer Health. Inc. on behalf of the American Academy of Neurology,To explore whether the isocitrate dehydrogenase 1 (IDH1) or 1p/19q status determines the prognostic vs predictive role of O6-methylguanine-DNA methyltransferase (MGMT) promoter methylation in the Neuro-Oncology Working Group of the German Cancer Society (NOA)-04 trial anaplastic glioma biomarker cohort.Patients (n = 183) of the NOA-04 trial with known MGMT and IDH1 status were analyzed for interdependency of the prognostic vs predictive role of MGMT promoter methylation from IDH1 or 1p/19q status and treatment. using progression-free survival (PFS) as an endpoint. An independent validation cohort of the German Glioma Network (n = 75) and the NOA-08 trial (n = 34) served as a confirmation cohort.In tumors with IDH1 mutation. MGMT promoter methylation was associated with prolonged PFS with chemotherapy ± radiotherapy (RT) or RT-only groups. and is thus …,True,-EEm-_MAAAAJ:AvfA0Oy_GE0C,195,https://n.neurology.org/content/81/17/1515.short,12315175884374077189,/scholar?cites=12315175884374077189,,,https://www.zora.uzh.ch/id/eprint/85421/1/Wick_2013.pdf,0,0,0
1278204,Integrated DNA methylation and copy-number profiling identify three clinically and biologically relevant groups of anaplastic glioma,2014,Benedikt Wiestler and David Capper and Martin Sill and David TW Jones and Volker Hovestadt and Dominik Sturm and Christian Koelsche and Anna Bertoni and Leonille Schweizer and Andrey Korshunov and Elisa K Weiß and Maximilian G Schliesser and Alexander Radbruch and Christel Herold-Mende and Patrick Roth and Andreas Unterberg and Christian Hartmann and Torsten Pietsch and Guido Reifenberger and Peter Lichter and Bernhard Radlwimmer and Michael Platten and Stefan M Pfister and Andreas von Deimling and Michael Weller and Wolfgang Wick,128,Acta neuropathologica,4,561-571,Springer Berlin Heidelberg, The outcome of patients with anaplastic gliomas varies considerably. Whether a molecular classification of anaplastic gliomas based on large-scale genomic or epigenomic analyses is superior to histopathology for reflecting distinct biological groups. predicting outcomes and guiding therapy decisions has yet to be determined. Epigenome-wide DNA methylation analysis. using a platform which also allows the detection of copy-number aberrations. was performed in a cohort of 228 patients with anaplastic gliomas (astrocytomas. oligoastrocytomas. and oligodendrogliomas). including 115 patients of the NOA-04 trial. We further compared these tumors with a group of 55 glioblastomas. Unsupervised clustering of DNA methylation patterns revealed two main groups correlated with IDH status: CpG island methylator phenotype (CIMP) positive (77.5 %) or negative (22.5 %). CIMPpos (IDH mutant) tumors …,True,-EEm-_MAAAAJ:ZfRJV9d4-WMC,185,https://link.springer.com/content/pdf/10.1007/s00401-014-1315-x.pdf,9580616673488322918,/scholar?cites=9580616673488322918,,,https://www.zora.uzh.ch/id/eprint/98106/1/Wiestler2.pdf,0,0,0
1278205,Laplacian surface editing,2004,Olga Sorkine and Daniel Cohen-Or and Yaron Lipman and Marc Alexa and Christian Rössl and H-P Seidel,,,,175-184,,Surface editing operations commonly require geometric details of the surface to be preserved as much as possible. We argue that geometric detail is an intrinsic property of a surface and that. consequently. surface editing is best performed by operating over an intrinsic surface representation. We provide such a representation of a surface. based on the Laplacian of the mesh. by encoding each vertex relative to its neighborhood. The Laplacian of the mesh is enhanced to be invariant to locally linearized rigid transformations and scaling. Based on this Laplacian representation. we develop useful editing operations: interactive free-form deformation in a region of interest based on the transformation of a handle. transfer and mixing of geometric details between two surfaces. and transplanting of a partial surface mesh onto another surface. The main computation involved in all operations is the solution of a sparse linear …,True,vyteiT4AAAAJ:u5HHmVD_uO8C,1254,https://dl.acm.org/doi/abs/10.1145/1057432.1057456,13421866874258505993,/scholar?cites=13421866874258505993,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.360.5276&rep=rep1&type=pdf,0,0,0
1278206,Blended intrinsic maps,2011,Vladimir G Kim and Yaron Lipman and Thomas Funkhouser,30,ACM transactions on graphics (TOG),4,1-12,ACM,"This paper describes a fully automatic pipeline for finding an intrinsic map between two non-isometric. genus zero surfaces. Our approach is based on the observation that efficient methods exist to search for nearly isometric maps (e.g.. Möbius Voting or Heat Kernel Maps). but no single solution found with these methods provides low-distortion everywhere for pairs of surfaces differing by large deformations. To address this problem. we suggest using a weighted combination of these maps to produce a ""blended map."" This approach enables algorithms that leverage efficient search procedures. yet can provide the flexibility to handle large deformations.The main challenges of this approach lie in finding a set of candidate maps {mi} and their associated blending weights {bi(p)} for every point p on the surface. We address these challenges specifically for conformal maps by making the following contributions. First. we …",True,vyteiT4AAAAJ:hqOjcs7Dif8C,431,https://dl.acm.org/doi/abs/10.1145/2010324.1964974,6067861833114072759,/scholar?cites=6067861833114072759,,,https://dl.acm.org/doi/pdf/10.1145/2010324.1964974,0,0,0
1278207,Linear rotation-invariant coordinates for meshes,2005,Yaron Lipman and Olga Sorkine and David Levin and Daniel Cohen-Or,24,ACM Transactions on Graphics (TOG),3,479-487,ACM,We introduce a rigid motion invariant mesh representation based on discrete forms defined on the mesh. The reconstruction of mesh geometry from this representation requires solving two sparse linear systems that arise from the discrete forms: the first system defines the relationship between local frames on the mesh. and the second encodes the position of the vertices via the local frames. The reconstructed geometry is unique up to a rigid transformation of the mesh. We define surface editing operations by placing user-defined constraints on the local frames and the vertex positions. These constraints are incorporated in the two linear reconstruction systems. and their solution produces a deformed surface geometry that preserves the local differential properties in the least-squares sense. Linear combination of shapes expressed with our representation enables linear shape interpolation that correctly handles …,True,vyteiT4AAAAJ:u-x6o8ySG0sC,403,https://dl.acm.org/doi/abs/10.1145/1073204.1073217,9189425928374353334,/scholar?cites=9189425928374353334,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.2912&rep=rep1&type=pdf,0,0,0
1278208,Möbius voting for surface correspondence,2009,Yaron Lipman and Thomas Funkhouser,28,ACM Transactions on Graphics (TOG),3,1-12,ACM,The goal of our work is to develop an efficient. automatic algorithm for discovering point correspondences between surfaces that are approximately and/or partially isometric.Our approach is based on three observations. First. isometries are a subset of the Möbius group. which has low-dimensionality -- six degrees of freedom for topological spheres. and three for topological discs. Second. computing the Möbius transformation that interpolates any three points can be computed in closed-form after a mid-edge flattening to the complex plane. Third. deviations from isometry can be modeled by a transportation-type distance between corresponding points in that plane.Motivated by these observations. we have developed a Möbius Voting algorithm that iteratively: 1) samples a triplet of three random points from each of two point sets. 2) uses the Möbius transformations defined by those triplets to map both point sets into …,True,vyteiT4AAAAJ:2osOgNQ5qMEC,390,https://dl.acm.org/doi/abs/10.1145/1531326.1531378,16581915968595622950,/scholar?cites=16581915968595622950,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.439.6282&rep=rep1&type=pdf,0,0,0
1278209,Green coordinates,2008,Yaron Lipman and David Levin and Daniel Cohen-Or,27,ACM Transactions on Graphics (TOG),3,1-10,ACM,We introduce Green Coordinates for closed polyhedral cages. The coordinates are motivated by Green's third integral identity and respect both the vertices position and faces orientation of the cage. We show that Green Coordinates lead to space deformations with a shape-preserving property. In particular. in 2D they induce conformal mappings. and extend naturally to quasi-conformal mappings in 3D. In both cases we derive closed-form expressions for the coordinates. yielding a simple and fast algorithm for cage-based space deformation. We compare the performance of Green Coordinates with those of Mean Value Coordinates and Harmonic Coordinates and show that the advantage of the shape-preserving property is not achieved at the expense of speed or simplicity. We also show that the new coordinates extend the mapping in a natural analytic manner to the exterior of the cage. allowing the employment …,True,vyteiT4AAAAJ:9yKSN-GCB0IC,372,https://dl.acm.org/doi/abs/10.1145/1360612.1360677,2873769660310073598,/scholar?cites=2873769660310073598,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.2116&rep=rep1&type=pdf,0,0,0
1278210,Differential coordinates for interactive mesh editing,2004,Yaron Lipman and Olga Sorkine and Daniel Cohen-Or and David Levin and Christian Rossi and Hans-Peter Seidel,,,,181-190,IEEE,One of the main challenges in editing a mesh is to retain the visual appearance of the surface after applying various modifications. In this paper we advocate the use of linear differential coordinates as means to preserve the high-frequency detail of the surface. The differential coordinates represent the details and are defined by a linear transformation of the mesh vertices. This allows the reconstruction of the edited surface by solving a linear system that satisfies the reconstruction of the local details in least squares sense. Since the differential coordinates are defined in a global coordinate system they are not rotation-invariant. To compensate for that. we rotate them to agree with the rotation of an approximated local frame. We show that the linear least squares system can be solved fast enough to guarantee interactive response time thanks to a precomputed factorization of the coefficient matrix. We demonstrate that …,True,vyteiT4AAAAJ:d1gkVwhDpl0C,353,https://ieeexplore.ieee.org/abstract/document/1314505/,11388892270702753309,/scholar?cites=11388892270702753309,,,http://www.cs.jhu.edu/~misha/Fall07/Papers/Lipman04.pdf,0,0,0
1278211,Coordinates for instant image cloning,2009,Zeev Farbman and Gil Hoffer and Yaron Lipman and Daniel Cohen-Or and Dani Lischinski,28,ACM Transactions on Graphics (TOG),3,1-9,ACM,Seamless cloning of a source image patch into a target image is an important and useful image editing operation. which has received considerable research attention in recent years. This operation is typically carried out by solving a Poisson equation with Dirichlet boundary conditions. which smoothly interpolates the discrepancies between the boundary of the source patch and the target across the entire cloned area. In this paper we introduce an alternative. coordinate-based approach. where rather than solving a large linear system to perform the aforementioned interpolation. the value of the interpolant at each interior pixel is given by a weighted combination of values along the boundary. More specifically. our approach is based on Mean-Value Coordinates (MVC). The use of coordinates is advantageous in terms of speed. ease of implementation. small memory footprint. and parallelizability. enabling real-time …,True,vyteiT4AAAAJ:UeHWp8X0CEIC,267,https://dl.acm.org/doi/abs/10.1145/1531326.1531373,6316467489984737800,/scholar?cites=6316467489984737800,,,https://www.researchgate.net/profile/Dani_Lischinski/publication/220183784_Coordinates_for_Instant_Image_Cloning/links/00b49524c4b5b304e4000000/Coordinates-for-Instant-Image-Cloning.pdf,0,0,0
1278212,Parameterization-free projection for geometry reconstruction,2007,Yaron Lipman and Daniel Cohen-Or and David Levin and Hillel Tal-Ezer,26,ACM Transactions on Graphics (TOG),3,22-es,ACM,We introduce a Locally Optimal Projection operator (LOP) for surface approximation from point-set data. The operator is parameterization free. in the sense that it does not rely on estimating a local normal. fitting a local plane. or using any other local parametric representation. Therefore. it can deal with noisy data which clutters the orientation of the points. The method performs well in cases of ambiguous orientation. e.g.. if two folds of a surface lie near each other. and other cases of complex geometry in which methods based upon local plane fitting may fail. Although defined by a global minimization problem. the method is effectively local. and it provides a second order approximation to smooth surfaces. Hence allowing good surface approximation without using any explicit or implicit approximation space. Furthermore. we show that LOP is highly robust to noise and outliers and demonstrate its effectiveness by …,True,vyteiT4AAAAJ:Y0pCki6q_DkC,233,https://dl.acm.org/doi/abs/10.1145/1276377.1276405,6187130887813550338,/scholar?cites=6187130887813550338,,,http://ztyiicos-1252101071.cosgz.myqcloud.com/2016/12/Parameterization-free-Projection-for-Geometry-Reconstruction.pdf,0,0,0
1278213,Point convolutional neural networks by extension operators,2018,Matan Atzmon and Haggai Maron and Yaron Lipman,,arXiv preprint arXiv:1803.10091,,,,This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction. mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism.The point cloud convolution is computationally efficient. invariant to the order of points in the point cloud. robust to different samplings and varying densities. and translation invariant. that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting.,True,vyteiT4AAAAJ:CRzUtm-VnGAC,187,https://arxiv.org/abs/1803.10091,6536237032480059688,/scholar?cites=6536237032480059688,,,https://arxiv.org/pdf/1803.10091,0,0,0
1278214,Context‐aware skeletal shape deformation,2007,Ofir Weber and Olga Sorkine and Yaron Lipman and Craig Gotsman,26,Computer Graphics Forum,3,265-274,Blackwell Publishing Ltd, We describe a system for the animation of a skeleton‐controlled articulated object that preserves the fine geometric details of the object skin and conforms to the characteristic shapes of the object specified through a set of examples. The system provides the animator with an intuitive user interface and produces compelling results even when presented with a very small set of examples. In addition it is able to generalize well by extrapolating far beyond the examples. ,True,vyteiT4AAAAJ:zYLM7Y9cAGgC,182,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01048.x,18184910353505457203,/scholar?cites=18184910353505457203,,,https://igl.ethz.ch/projects/skinning/context-aware-deformation/context-aware-skinning-def.pdf,0,0,0
1278215,Biharmonic distance,2010,Yaron Lipman and Raif M Rustamov and Thomas A Funkhouser,29,ACM Transactions on Graphics (TOG),3,1-11,ACM,Measuring distances between pairs of points on a 3D surface is a fundamental problem in computer graphics and geometric processing. For most applications. the important properties of a distance are that it is a metric. smooth. locally isotropic. globally “shape-aware.” isometry-invariant. insensitive to noise and small topology changes. parameter-free. and practical to compute on a discrete mesh. However. the basic methods currently popular in computer graphics (e.g.. geodesic and diffusion distances) do not have these basic properties. In this article. we propose a new distance measure based on the biharmonic differential operator that has all the desired properties. This new surface distance is related to the diffusion and commute-time distances. but applies different (inverse squared) weighting to the eigenvalues of the Laplace-Beltrami operator. which provides a nice trade-off between nearly geodesic …,True,vyteiT4AAAAJ:_FxGoFyzp5QC,181,https://dl.acm.org/doi/abs/10.1145/1805964.1805971,12762660351528551898,/scholar?cites=12762660351528551898,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.442.6406&rep=rep1&type=pdf,0,0,0
1278216,Out-of-sample extensions for lle. isomap. mds. eigenmaps. and spectral clustering,2004,Yoshua Bengio and Jean-François Paiement and Pascal Vincent and Olivier Delalleau and Nicolas Le Roux and Marie Ouimet,16,NIPS,,177-184,Cambridge. MA. USA: MIT Press,Several unsupervised learning algorithms based on an eigendecomposition provide either an embedding or a clustering only for given training points. with no straightforward extension for out-of-sample examples short of recomputing eigenvectors. This paper provides a unified framework for extending Local Linear Embedding (LLE). Isomap. Laplacian Eigenmaps. Multi-Dimensional Scaling (for dimensionality reduction) as well as for Spectral Clustering. This framework is based on seeing these algorithms as learning eigenfunctions of a data-dependent kernel. Numerical experiments show that the generalizations performed have a level of error comparable to the variability of the embedding algorithms due to the choice of training data.,True,LmKtwk8AAAAJ:u5HHmVD_uO8C,1250,http://papers.nips.cc/paper/2461-out-of-sample-extensions-for-lle-isomap-mds-eigenmaps-and-spectral-clustering.pdf,2681032414203026136,/scholar?cites=2681032414203026136,,,http://papers.nips.cc/paper/2461-out-of-sample-extensions-for-lle-isomap-mds-eigenmaps-and-spectral-clustering.pdf,0,0,0
1278217,Minimizing finite sums with the stochastic average gradient,2017,Mark Schmidt and Nicolas Le Roux and Francis Bach,162,Mathematical Programming,1-2,83-112,Springer Berlin Heidelberg,We analyze the stochastic average gradient (SAG) method for optimizing the sum of a finite number of smooth convex functions. Like stochastic gradient (SG) methods. the SAG method’s iteration cost is independent of the number of terms in the sum. However. by incorporating a memory of previous gradient values the SAG method achieves a faster convergence rate than black-box SG methods. The convergence rate is improved from  to O(1 / k) in general. and when the sum is strongly-convex the convergence rate is improved from the sub-linear O(1 / k) to a linear convergence rate of the form  for . Further. in many cases the convergence rate of the new method is also faster than black-box deterministic gradient methods. in terms of the number of gradient evaluations. This extends our earlier work Le Roux et al. (Adv Neural Inf Process Syst. 2012). which only lead to a faster rate for well …,True,LmKtwk8AAAAJ:X9ykpCP0fEIC,915,https://link.springer.com/content/pdf/10.1007/s10107-016-1030-6.pdf,8316752642523359382,/scholar?cites=8316752642523359382,,,https://arxiv.org/pdf/1309.2388,0,0,0
1278218,Representational power of restricted Boltzmann machines and deep belief networks,2008,Nicolas Le Roux and Yoshua Bengio,20,Neural Computation,6,1631-1649,MIT Press,Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors. recently introduced by Hinton. Osindero. and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM). used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power. while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs …,True,LmKtwk8AAAAJ:2osOgNQ5qMEC,765,https://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.04-07-510,16696969384440858898,/scholar?cites=16696969384440858898,,,https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/representational_power.pdf,0,0,0
1278219,A stochastic gradient method with an exponential convergence rate for finite training sets,2012,Nicolas Le Roux and Mark Schmidt and Francis Bach,,,,2663-2671,Curran Associates Inc.,We propose a new stochastic gradient method for optimizing the sum of a finite set of smooth functions. where the sum is strongly convex. While standard stochastic gradient methods converge at sublinear rates for this problem. the proposed method incorporates a memory of previous gradient values in order to achieve a linear convergence rate. In a machine learning context. numerical experiments indicate that the new algorithm can dramatically outperform standard algorithms. both in terms of optimizing the training error and reducing the test error quickly.Comments: The notable changes over the current version:-worked example of convergence rates showing SAG can be faster than first-order methods-pointing out that the storage cost is O (n) for linear models-the more-stable line-search-comparison to additional optimal SG methods-comparison to rates of coordinate descent methods in quadratic case,True,LmKtwk8AAAAJ:CYCckWUYoCcC,747,https://arxiv.org/abs/1202.6258,1209759207862565895,/scholar?cites=1209759207862565895,,,https://arxiv.org/pdf/1202.6258,0,0,0
1278220,Convergence rates of inexact proximal-gradient methods for convex optimization,2011,Mark Schmidt and Nicolas Le Roux and Francis Bach,,,,,,We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods. where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case. provided that the errors decrease at appropriate rates. Using these rates. we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems.,True,LmKtwk8AAAAJ:9ZlFYXVOiuMC,462,https://arxiv.org/abs/1109.2415,8936781430634437833,/scholar?cites=8936781430634437833,,,https://arxiv.org/pdf/1109.2415,0,0,0
1278221,A latent factor model for highly multi-relational data,2012,Rodolphe Jenatton and Nicolas Le Roux and Antoine Bordes and Guillaume R Obozinski,,,,3167-3175,,Many data such as social networks. movie preferences or knowledge bases are multi-relational. in that they describe multiple relations between entities. While there is a large body of work focused on modeling these data. modeling these multiple types of relations jointly remains challenging. Further. existing approaches tend to breakdown when the number of these types grows. In this paper. we propose a method for modeling large multi relational datasets. with possibly thousands of relations. Our model is based on a bilinear structure. which captures various orders of interaction of the data. and also shares sparse latent factors across different relations. We illustrate the performance of our approach on standard tensor-factorization datasets where we attain. or outperform. state-of-the-art results. Finally. a NLP application demonstrates our scalability and the ability of our model to learn efficient and semantically meaningful verb representations.,True,LmKtwk8AAAAJ:J_g5lzvAfSwC,399,https://hal.inria.fr/hal-00776335/,1447473044289475803,/scholar?cites=1447473044289475803,,,https://hal.inria.fr/hal-00776335/document,0,0,0
1278222,Label propagation and quadratic criterion,2006,Yoshua Bengio and Olivier Delalleau and Nicolas Le Roux,,Semi-supervised learning,,193-216,Cambridge. MA: MIT Press,Various graph-based algorithms for semi-supervised learning have been proposed in the recent literature. They rely on the idea of building a graph whose nodes are data points (labeled and unlabeled) and edges represent similarities between points. Known labels are used to propagate information through the graph in order to label all nodes. In this chapter. we show how these different algorithms can be cast into a common framework where one minimizes a quadratic cost criterion whose closedform solution is found by solving a linear system of size n (total number of data points). The cost criterion naturally leads to an extension of such algorithms to the inductive setting. where one obtains test samples one at a time: the derived induction formula can be evaluated in O (n) time. which is much more efficient than solving again exactly the linear system (which in general costs O (kn2) time for a sparse graph where each data point has k neighbors). We also use this inductive formula to show that when the similarity between points satisfies a locality property. then the algorithms are plagued by the curse of dimensionality. with respect to the dimensionality of an underlying manifold.,True,LmKtwk8AAAAJ:d1gkVwhDpl0C,349,https://www.researchgate.net/profile/Y_Bengio/publication/238675708_Label_Propagation_and_Quadratic_Criterion/links/0f3175320aae4ada34000000/Label-Propagation-and-Quadratic-Criterion.pdf,1630869818472058708,/scholar?cites=1630869818472058708,,,https://www.researchgate.net/profile/Y_Bengio/publication/238675708_Label_Propagation_and_Quadratic_Criterion/links/0f3175320aae4ada34000000/Label-Propagation-and-Quadratic-Criterion.pdf,0,0,0
1278223,Ask the locals: multi-way local pooling for image recognition,2011,Y-Lan Boureau and Nicolas Le Roux and Francis Bach and Jean Ponce and Yann LeCun,,,,,,Invariant representations in object recognition systems are generally obtained by pooling feature vectors over spatially local neighborhoods. But pooling is not local in the feature vector space. so that widely dissimilar features may be pooled together if they are in nearby locations. Recent approaches rely on sophisticated encoding methods and more specialized codebooks (or dictionaries). e.g.. learned on subsets of descriptors which are close in feature space. to circumvent this problem. In this work. we argue that a common trait found in much recent work in image recognition or retrieval is that it leverages locality in feature space on top of purely spatial locality. We propose to apply this idea in its simplest form to an object recognition system based on the spatial pyramid framework. to increase the performance of small dictionaries with very little added engineering. State-of-the-art results on several object …,True,LmKtwk8AAAAJ:3fE2CSJIrl8C,331,https://ieeexplore.ieee.org/abstract/document/6126555/,9896663533904213157,/scholar?cites=9896663533904213157,,,https://hal.inria.fr/hal-00646816/file/boureau-iccv-11.pdf,0,0,0
1278224,Learning eigenfunctions links spectral embedding and kernel PCA,2004,Yoshua Bengio and Olivier Delalleau and Nicolas Le Roux and Jean-François Paiement and Pascal Vincent and Marie Ouimet,16,Neural Computation,10,2197-2219,MIT Press,In this letter. we show a direct relation between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density. Whereas spectral embedding methods provided only coordinates for the training points. the analysis justifies a simple extension to out-of-sample examples (the Nyström formula) for multidimensional scaling (MDS). spectral clustering. Laplacian eigenmaps. locally linear embedding (LLE). and Isomap. The analysis provides. for all such spectral embedding methods. the definition of a loss function. whose empirical average is minimized by the traditional algorithms. The asymptotic expected value of that loss defines a generalization performance and clarifies what these algorithms are trying to learn. Experiments …,True,LmKtwk8AAAAJ:4DMP91E08xMC,310,https://www.mitpressjournals.org/doi/abs/10.1162/0899766041732396,2506178606788573263,/scholar?cites=2506178606788573263,,,http://www.iro.umontreal.ca/~vincentp/Publications/bengio_eigenfunctions_nc_2004.pdf,0,0,0
1278225,Efficient Non-Parametric Function Induction in Semi-Supervised Learning.,2005,Olivier Delalleau and Yoshua Bengio and Nicolas Le Roux,,,,,,There has been an increase of interest for semi-supervised learning recently. because of the many datasets with large amounts of unlabeled examples and only a few labeled ones. This paper follows up on proposed nonparametric algorithms which provide an estimated continuous label for the given unlabeled examples. First. it extends them to function induction algorithms that minimize a regularization criterion applied to an outof-sample example. and happen to have the form of Parzen windows regressors. This allows to predict test labels without solving again a linear system of dimension n (the number of unlabeled and labeled training examples). which can cost O (n3). Second. this function induction procedure gives rise to an efficient approximation of the training process. reducing the linear system to be solved to m «n unknowns. using only a subset of m examples. An improvement of O (n2/m2) in time can thus be obtained. Comparative experiments are presented. showing the good performance of the induction formula and approximation algorithm.,True,LmKtwk8AAAAJ:u-x6o8ySG0sC,220,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=105,98232010746411697,/scholar?cites=98232010746411697,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829&rep=rep1&type=pdf#page=105,0,0,0
1278226,The curse of highly variable functions for local kernel machines,2006,Yoshua Bengio and Olivier Delalleau and Nicolas Le Roux,18,NIPS,,107,MIT; 1998,We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior–with similarity between examples expressed with a local kernel–are sensitive to the curse of dimensionality. or more precisely to the variability of the target. Our discussion covers supervised. semisupervised and unsupervised learning algorithms. These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality. well studied for classical non-parametric statistical learning. We show in the case of the Gaussian kernel that when the function to be learned has many variations. these algorithms require a number of training examples proportional to the number of variations. which could be large even though there may exist short descriptions of the target function. ie their Kolmogorov complexity may be low. This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions (because locally they have many variations). while not using very specific prior domain knowledge.,True,LmKtwk8AAAAJ:9yKSN-GCB0IC,218,http://www.iro.umontreal.ca/~lisa/pointeurs/local_curse_nips2005.pdf,609153847578098786,/scholar?cites=609153847578098786,,,http://www.iro.umontreal.ca/~lisa/pointeurs/local_curse_nips2005.pdf,0,0,0
1278227,A novel four-step search algorithm for fast block motion estimation,1996,Lai-Man Po and Wing-Chung Ma,6,IEEE transactions on circuits and systems for video technology,3,313-317,IEEE,Based on the real world image sequence's characteristic of center-biased motion vector distribution. a new four-step search (4SS) algorithm with center-biased checking point pattern for fast block motion estimation is proposed in this paper. A halfway-stop technique is employed in the new algorithm with searching steps of 2 to 4 and the total number of checking points is varied from 17 to 27. Simulation results show that the proposed 4SS performs better than the well-known three-step search and has similar performance to the new three-step search (N3SS) in terms of motion compensation errors. In addition. the 4SS also reduces the worst-case computational requirement from 33 to 27 search points and the average computational requirement from 21 to 19 search points. as compared with N3SS.,True,H_0EvmkAAAAJ:u5HHmVD_uO8C,2265,https://ieeexplore.ieee.org/abstract/document/499840/,5946179056463480763,/scholar?cites=5946179056463480763,,,,0,0,0
1278228,A novel cross-diamond search algorithm for fast block motion estimation,2002,Chun-Ho Cheung and Lai-Man Po,12,IEEE transactions on Circuits and Systems for Video Technology,12,1168-1177,IEEE,In block motion estimation. search patterns with different shapes or sizes and the center-biased characteristics of motion-vector distribution have a large impact on the searching speed and quality of performance. We propose a novel algorithm using a cross-search pattern as the initial step and large/small diamond search (DS) patterns as the subsequent steps for fast block motion estimation. The initial cross-search pattern is designed to fit the cross-center-biased motion vector distribution characteristics of the real-world sequences by evaluating the nine relatively higher probable candidates located horizontally and vertically at the center of the search grid. The proposed cross-diamond search (CDS) algorithm employs the halfway-stop technique and finds small motion vectors with fewer search points than the DS algorithm while maintaining similar or even better search quality. The improvement of CDS over DS …,True,H_0EvmkAAAAJ:u-x6o8ySG0sC,562,https://ieeexplore.ieee.org/abstract/document/1175453/,6543206712269417233,/scholar?cites=6543206712269417233,,,http://www.ee.cityu.edu.hk/~lmpo/publications/2002_IEEE_TCSVT_CDS.pdf,0,0,0
1278229,Novel cross-diamond-hexagonal search algorithms for fast block motion estimation,2005,Chun-Ho Cheung and Lai-Man Po,7,IEEE Transactions on Multimedia,1,16-22,IEEE,We propose two cross-diamond-hexagonal search (CDHS) algorithms. which differ from each other by their sizes of hexagonal search patterns. These algorithms basically employ two cross-shaped search patterns consecutively in the very beginning steps and switch using diamond-shaped patterns. To further reduce the checking points. two pairs of hexagonal search patterns are proposed in conjunction with candidates found located at diamond corners. Experimental results show that the proposed CDHSs perform faster than the diamond search (DS) by about 144% and the cross-diamond search (CDS) by about 73%. whereas similar prediction quality is still maintained.,True,H_0EvmkAAAAJ:9yKSN-GCB0IC,261,https://ieeexplore.ieee.org/abstract/document/1386237/,8798326932761042046,/scholar?cites=8798326932761042046,,,https://www.researchgate.net/profile/Terence_Chun-Ho_Cheung/publication/3424261_Novel_cross-diamond-hexagonal_search_algorithms_for_fast_block_motion_estimation/links/00b4951f20d9180ff6000000/Novel-cross-diamond-hexagonal-search-algorithms-for-fast-block-motion-estimation.pdf,0,0,0
1278230,Normalized partial distortion search algorithm for block motion estimation,2000,Chok-Kwan Cheung and Lai-Man Po,10,IEEE Transactions on Circuits and Systems for Video Technology,3,417-422,IEEE,Many fast block-matching algorithms reduce computations by limiting the number of checking points. They can achieve high computation reduction. but often result in relatively higher matching error compared with the full-search algorithm. A novel fast block-matching algorithm named normalized partial distortion search is proposed. The proposed algorithm reduces computations by using a halfway-stop technique in the calculation of the block distortion measure. In order to increase the probability of early rejection of non-possible candidate motion vectors. the proposed algorithm normalized the accumulated partial distortion and the current minimum distortion before comparison. Experimental results show that the proposed algorithm can maintain its mean square error performance very close to the full-search algorithm while achieving an average computation reduction of 12-13 times. with respect to the full-search …,True,H_0EvmkAAAAJ:d1gkVwhDpl0C,248,https://ieeexplore.ieee.org/abstract/document/836286/,652718084362783860,/scholar?cites=652718084362783860,,,,0,0,0
1278231,Enhanced hexagonal search for fast block motion estimation,2004,Ce Zhu and Xiao Lin and Lappui Chau and Lai-Man Po,14,IEEE transactions on Circuits and Systems for Video Technology,10,1210-1214,IEEE,Fast block motion estimation normally consists of low-resolution coarse search and the following fine-resolution inner search. Most motion estimation algorithms developed attempt to speed up the coarse search without considering accelerating the focused inner search. On top of the hexagonal search method recently developed. an enhanced hexagonal search algorithm is proposed to further improve the performance in terms of reducing number of search points and distortion. where a novel fast inner search is employed by exploiting the distortion information of the evaluated points. Our experimental results substantially justify the merits of the proposed algorithm.,True,H_0EvmkAAAAJ:2osOgNQ5qMEC,225,https://ieeexplore.ieee.org/abstract/document/1336869/,2891166666057842478,/scholar?cites=2891166666057842478,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.515.8444&rep=rep1&type=pdf,0,0,0
1278232,Edge-based structural similarity for image quality assessment,2006,Guan-Hao Chen and Chun-Ling Yang and Lai-Man Po and Sheng-Li Xie,2,,,II-II,IEEE,Objective quality assessment has been widely used in image processing for decades and many researchers have been studying the objective quality assessment method based on human visual system (HVS). Recently the structural similarity (SSIM) is proposed. under the assumption that the HVS is highly adapted for extracting structural information from a scene. and simulation results have proved that it is better than PSNR (or MSE). By deeply studying the SSIM. we find it fails in measuring the badly blurred images. Based on this. we develop an improved method which is called edge-based structural similarity (ESSIM). Experiment results show that ESSIM is more consistent with HVS than SSIM and PSNR especially for the blurred images,True,H_0EvmkAAAAJ:1qzjygNMrQYC,173,https://ieeexplore.ieee.org/abstract/document/1660497/,3937484038755042706,/scholar?cites=3937484038755042706,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.461.7050&rep=rep1&type=pdf,0,0,0
1278233,Integration of image quality and motion cues for face anti-spoofing: A neural network approach,2016,Litong Feng and Lai-Man Po and Yuming Li and Xuyuan Xu and Fang Yuan and Terence Chun-Ho Cheung and Kwok-Wai Cheung,38,Journal of Visual Communication and Image Representation,,451-460,Academic Press,Many trait-specific countermeasures to face spoofing attacks have been developed for security of face authentication. However. there is no superior face anti-spoofing technique to deal with every kind of spoofing attack in varying scenarios. In order to improve the generalization ability of face anti-spoofing approaches. an extendable multi-cues integration framework for face anti-spoofing using a hierarchical neural network is proposed. which can fuse image quality cues and motion cues for liveness detection. Shearlet is utilized to develop an image quality-based liveness feature. Dense optical flow is utilized to extract motion-based liveness features. A bottleneck feature fusion strategy can integrate different liveness features effectively. The proposed approach was evaluated on three public face anti-spoofing databases. A half total error rate (HTER) of 0% and an equal error rate (EER) of 0% were achieved on both …,True,H_0EvmkAAAAJ:1yQoGdGgb4wC,155,https://www.sciencedirect.com/science/article/pii/S1047320316300244,5223547980813186246,/scholar?cites=5223547980813186246,,,http://www.ee.cityu.edu.hk/~lmpo/publications/2016_Jouranl_VCIR_Face_Liveness.pdf,0,0,0
1278234,Adaptive motion tracking block matching algorithms for video coding,1999,Jie-Bin Xu and Lai-Man Po and Chok-Kwan Cheung,9,IEEE Transactions on Circuits and Systems for Video Technology,7,1025-1029,IEEE,In most block-based video coding systems. the fast block matching algorithms (BMAs) use the origin as the initial search center. which may not track the motion very well. To improve the accuracy of the fast BMAs. a new adaptive motion tracking search algorithm is proposed. Based on the spatial correlation of motion blocks. a predicted starting search point. which reflects the motion trend of the current block. is adaptively chosen. This predicted search center is found closer to the global minimum. and thus the center-biased BMAs can be used to find the motion vector more efficiently. Experimental results show that the proposed algorithm enhances the accuracy of the fast center-biased BMAs. such as the new three-step search. the four-step search. and the block-based gradient descent search. as well as reduces their computational requirement.,True,H_0EvmkAAAAJ:qjMakFHDy7sC,147,https://ieeexplore.ieee.org/abstract/document/795056/,1411872152449262864,/scholar?cites=1411872152449262864,,,https://www.researchgate.net/profile/Mohamed_Ghoneim6/publication/224706107_Adaptive_Motion_Estimation_Block_Matching_Algorithms_for_Video_Coding/links/0deec53c5987f2231b000000.pdf,0,0,0
1278235,Adjustable partial distortion search algorithm for fast block motion estimation,2003,Chun-Ho Cheung and Lai-Man Po,13,IEEE Transactions on Circuits and Systems for Video Technology,1,100-110,IEEE,The quality control for video coding usually absents from many traditional fast block motion estimators. A novel block-matching algorithm for fast motion estimation named the adjustable partial distortion search algorithm (APDS) is proposed. It is a new normalized partial distortion comparison method capable of adjusting the prediction accuracy against searching speed by a quality factor k. With adjustability. APDS could act as the normalized partial distortion search algorithm (NPDS) when k is equal to 0. and the conventional partial distortion search algorithm (PDS) when k is equal to 1. In addition. it uses a halfway-stop technique with progressive partial distortions (PPD) to increase early rejection rate of impossible candidate motion vectors at very early stages. Simulations with PPD reduce computations up to 38 times with less than 0.50-dB degradation in PSNR performance. as compared to the full-search …,True,H_0EvmkAAAAJ:IjCSPb-OGe4C,116,https://ieeexplore.ieee.org/abstract/document/1180386/,16757290476328793671,/scholar?cites=16757290476328793671,,,https://pdfs.semanticscholar.org/a602/9caac5363df1ccc2d8d4b28e3dee0c63b3d3.pdf,0,0,0
1278236,Motion-resistant remote imaging photoplethysmography based on the optical properties of skin,2014,Litong Feng and Lai-Man Po and Xuyuan Xu and Yuming Li and Ruiyi Ma,25,IEEE Transactions on Circuits and Systems for Video Technology,5,879-891,IEEE,Remote imaging photoplethysmography (RIPPG) can achieve contactless monitoring of human vital signs. However. the robustness to a subject's motion is a challenging problem for RIPPG. especially in facial video-based RIPPG. The RIPPG signal originates from the radiant intensity variation of human skin with pulses of blood and motions can modulate the radiant intensity of the skin. Based on the optical properties of human skin. we build an optical RIPPG signal model in which the origins of the RIPPG signal and motion artifacts can be clearly described. The region of interest (ROI) of the skin is regarded as a Lambertian radiator and the effect of ROI tracking is analyzed from the perspective of radiometry. By considering a digital color camera as a simple spectrometer. we propose an adaptive color difference operation between the green and red channels to reduce motion artifacts. Based on the spectral …,True,H_0EvmkAAAAJ:WqliGbK-hY8C,114,https://ieeexplore.ieee.org/abstract/document/6933875/,3533721767549745128,/scholar?cites=3533721767549745128,,,http://www.ee.cityu.edu.hk/~lmpo/publications/2015_IEEE_TCSVT_rPPG.pdf,0,0,0
1278237,A fast H. 264 intra prediction algorithm using macroblock properties,2004,Chun-Ling Yang and Lai-Man Po and Wing-Hong Lam,1,,,461-464,IEEE,In the newest video coding standard of H.264. intra frame prediction is conducted in the spatial domain. There are two types of intra prediction for luma - Intra/spl I.bar/16/spl times/16 does prediction for the whole 16/spl times/16 luma macroblock and Intra/spl I.bar/4/spl times/4 does prediction for 4/spl times/4 block. Four and nine modes are supported by Intra/spl I.bar/16/spl times/16 and Intra/spl I.bar/4/spl times/4. respectively. The full search algorithm is used in the JVT reference software to choose the best modes. however it is very computationally expensive. In this paper. a new fast intra prediction algorithm using macroblock properties (FIPAMP) is proposed. Experimental results show that the proposed fast algorithm can achieve 10% to 40% computation reduction while maintaining similar PSNR and bit rate performance of H.264 codes.,True,H_0EvmkAAAAJ:UeHWp8X0CEIC,104,https://ieeexplore.ieee.org/abstract/document/1418790/,17813505905264592417,/scholar?cites=17813505905264592417,,,,0,0,0
1278238,Pyramid scene parsing network,2017,Hengshuang Zhao and Jianping Shi and Xiaojuan Qi and Xiaogang Wang and Jiaya Jia,,Conference on Computer Vision and Pattern Recognition (CVPR),,2881-2890,,Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper. we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network (PSPNet). Our global prior representation is effective to produce good quality results on the scene parsing task. while PSPNet provides a superior framework for pixel-level prediction. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge 2016. PASCAL VOC 2012 benchmark and Cityscapes benchmark. A single PSPNet yields the new record of mIoU accuracy 85.4% on PASCAL VOC 2012 and accuracy 80.2% on Cityscapes.,True,bGn0uacAAAAJ:u5HHmVD_uO8C,4428,http://openaccess.thecvf.com/content_cvpr_2017/html/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.html,14280592669518971589,/scholar?cites=14280592669518971589,,,https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.pdf,0,0,0
1278239,H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation from CT Volumes,2018,Xiaomeng Li and Hao Chen and Xiaojuan Qi and Qi Dou and Chi-Wing Fu and Pheng-Ann Heng,,IEEE Transactions on Medical Imaging (TMI),,,IEEE,Liver cancer is one of the leading causes of cancer death. To assist doctors in hepatocellular carcinoma diagnosis and treatment planning. an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice. Recently. fully convolutional neural networks (FCNs). including 2-D and 3-D FCNs. serve as the backbone in many volumetric image segmentation. However. 2-D convolutions cannot fully leverage the spatial information along the third dimension while 3-D convolutions suffer from high computational cost and GPU memory consumption. To address these issues. we propose a novel hybrid densely connected UNet (H-DenseUNet). which consists of a 2-D DenseUNet for efficiently extracting intra-slice features and a 3-D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation. We formulate …,True,bGn0uacAAAAJ:ufrVoPGSRksC,612,https://ieeexplore.ieee.org/abstract/document/8379359/,7248952072690335486,/scholar?cites=7248952072690335486,,,https://arxiv.org/pdf/1709.07330.pdf?source=post_page---------------------------,0,0,0
1278240,Icnet for real-time semantic segmentation on high-resolution images,2018,Hengshuang Zhao and Xiaojuan Qi and Xiaoyong Shen and Jianping Shi and Jiaya Jia,,European Conference on Computer Vision (ECCV),,,,We focus on the challenging task of real-time semantic segmentation in this paper. It finds many practical applications and yet is with fundamental difficulty of reducing a large portion of computation for pixel-wise label inference. We propose an image cascade network (ICNet) that incorporates multi-resolution branches under proper label guidance to address this challenge. We provide in-depth analysis of our framework and introduce the cascade feature fusion unit to quickly achieve high-quality segmentation. Our system yields real-time inference on a single GPU card with decent quality results evaluated on challenging datasets like Cityscapes. CamVid and COCO-Stuff.,True,bGn0uacAAAAJ:IjCSPb-OGe4C,586,http://openaccess.thecvf.com/content_ECCV_2018/html/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.html,4797791240153082941,/scholar?cites=4797791240153082941,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdf,0,0,0
1278241,DCAN: deep contour-aware networks for accurate gland segmentation,2016,Hao Chen and Xiaojuan Qi and Lequan Yu and Pheng-Ann Heng,,,,2487-2496,,The morphology of glands has been used routinely by pathologists to assess the malignancy degree of adenocarcinomas. Accurate segmentation of glands from histology images is a crucial step to obtain reliable morphological statistics for quantitative diagnosis. In this paper. we proposed an efficient deep contour-aware network (DCAN) to solve this challenging problem under a unified multi-task learning framework. In the proposed network. multi-level contextual features from the hierarchical architecture are explored with auxiliary supervision for accurate gland segmentation. When incorporated with multi-task regularization during the training. the discriminative capability of intermediate features can be further improved. Moreover. our network can not only output accurate probability maps of glands. but also depict clear contours simultaneously for separating clustered objects. which further boosts the gland segmentation performance. This unified framework can be efficient when applied to large-scale histopathological data without resorting to additional steps to generate contours based on low-level cues for post-separating. Our method won the 2015 MICCAI Gland Segmentation Challenge out of 13 competitive teams. surpassing all the other methods by a significant margin.,True,bGn0uacAAAAJ:u-x6o8ySG0sC,375,http://openaccess.thecvf.com/content_cvpr_2016/html/Chen_DCAN_Deep_Contour-Aware_CVPR_2016_paper.html,6985234319667339053,/scholar?cites=6985234319667339053,,,https://openaccess.thecvf.com/content_cvpr_2016/papers/Chen_DCAN_Deep_Contour-Aware_CVPR_2016_paper.pdf,0,0,0
1278242,Gland segmentation in colon histology images: The glas challenge contest,2017,Korsuk Sirinukunwattana and Josien PW Pluim and Hao Chen and Xiaojuan Qi and Pheng-Ann Heng and Yun Bo Guo and Li Yang Wang and Bogdan J Matuszewski and Elia Bruni and Urko Sanchez and Anton Böhm and Olaf Ronneberger and Bassem Ben Cheikh and Daniel Racoceanu and Philipp Kainz and Michael Pfeiffer and Martin Urschler and David RJ Snead and Nasir M Rajpoot,35,Medical Image Analysis (MedIA),,489-502,Elsevier,Colorectal adenocarcinoma originating in intestinal glandular structures is the most common form of colon cancer. In clinical practice. the morphology of intestinal glands. including architectural appearance and glandular formation. is used by pathologists to inform prognosis and plan the treatment of individual patients. However. achieving good inter-observer as well as intra-observer reproducibility of cancer grading is still a major challenge in modern pathology. An automated approach which quantifies the morphology of glands is a solution to the problem.This paper provides an overview to the Gland Segmentation in Colon Histology Images Challenge Contest (GlaS) held at MICCAI’2015. Details of the challenge. including organization. dataset and evaluation criteria. are presented. along with the method descriptions and evaluation results from the top performing methods.,True,bGn0uacAAAAJ:9yKSN-GCB0IC,296,https://www.sciencedirect.com/science/article/pii/S1361841516301542,8655089526173907291,/scholar?cites=8655089526173907291,,,https://arxiv.org/pdf/1603.00275,0,0,0
1278243,DCAN: Deep contour-aware networks for object instance segmentation from histology images,2017,Hao Chen and Xiaojuan Qi and Lequan Yu and Qi Dou and Jing Qin and Pheng-Ann Heng,36,Medical Image Analysis (MedIA),,135-146,Elsevier,In histopathological image analysis. the morphology of histological structures. such as glands and nuclei. has been routinely adopted by pathologists to assess the malignancy degree of adenocarcinomas. Accurate detection and segmentation of these objects of interest from histology images is an essential prerequisite to obtain reliable morphological statistics for quantitative diagnosis. While manual annotation is error-prone. time-consuming and operator-dependant. automated detection and segmentation of objects of interest from histology images can be very challenging due to the large appearance variation. existence of strong mimics. and serious degeneration of histological structures. In order to meet these challenges. we propose a novel deep contour-aware network (DCAN) under a unified multi-task learning framework for more accurate detection and segmentation. In the proposed network. multi-level …,True,bGn0uacAAAAJ:2osOgNQ5qMEC,260,https://www.sciencedirect.com/science/article/pii/S1361841516302043,10109194823949808147,/scholar?cites=10109194823949808147,,,http://www.cse.cuhk.edu.hk/~qdou/papers/2017/[2017][MedIA]DCAN--Deep%20contour-aware%20networks%20for%20object%20instance%20segmentation%20from%20histology%20images.pdf,0,0,0
1278244,3d graph neural networks for rgbd semantic segmentation,2017,Xiaojuan Qi and Renjie Liao and Jiaya Jia and Sanja Fidler and Raquel Urtasun,,International Conference on Computer Vision (ICCV),,5199-5208,,RGBD semantic segmentation requires joint reasoning about 2D appearance and 3D geometric information. In this paper we propose a 3D graph neural network (3DGNN) that builds a k-nearest neighbor graph on top of 3D point cloud. Each node in the graph corresponds to a set of points and is associated with a hidden representation vector initialized with an appearance feature extracted by a unary CNN from 2D images. Relying on recurrent functions. every node dynamically updates its hidden representation based on the current status and incoming messages from its neighbors. This propagation model is unrolled for a certain number of time steps and the final per-node representation is used for predicting the semantic class of each pixel. We use back-propagation through time to train the model. Extensive experiments on NYUD2 and SUN-RGBD datasets demonstrate the effectiveness of our approach.,True,bGn0uacAAAAJ:Tyk-4Ss8FVUC,240,http://openaccess.thecvf.com/content_iccv_2017/html/Qi_3D_Graph_Neural_ICCV_2017_paper.html,11151159786053391184,/scholar?cites=11151159786053391184,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf,0,0,0
1278245,The liver tumor segmentation benchmark (lits),2019,Patrick Bilic and Patrick Ferdinand Christ and Eugene Vorontsov and Grzegorz Chlebus and Hao Chen and Qi Dou and Chi-Wing Fu and Xiao Han and Pheng-Ann Heng and Jürgen Hesser and Samuel Kadoury and Tomasz Konopczynski and Miao Le and Chunming Li and Xiaomeng Li and Jana Lipkovà and John Lowengrub and Hans Meine and Jan Hendrik Moltz and Chris Pal and Marie Piraud and Xiaojuan Qi and Jin Qi and Markus Rempfler and Karsten Roth and Andrea Schenk and Anjany Sekuboyina and Ping Zhou and Christian Hülsemeyer and Marcel Beetz and Florian Ettlinger and Felix Grün and Georgios Kaissis and Fabian Lohöfer and Rickmer Braren and Julian Holch and Felix Hofmann and Wieland Sommer and Volker Heinemann and Colin Jacobs and Gabriel Efrain Humpire Mamani and Bram van Ginneken and Gabriel Chartrand and An Tang and Michal Drozdzal and Avi Ben-Cohen and Eyal Klang and Marianne M Amitai and Eli Konen and Hayit Greenspan and Johan Moreau and Alexandre Hostettler and Luc Soler and Refael Vivanti and Adi Szeskin and Naama Lev-Cohain and Jacob Sosna and Leo Joskowicz and Bjoern H Menze,,arXiv preprint arXiv:1901.04056,,,,In this work. we report the set-up and results of the Liver Tumor Segmentation Benchmark (LITS) organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2016 and International Conference On Medical Image Computing Computer Assisted Intervention (MICCAI) 2017. Twenty four valid state-of-the-art liver and liver tumor segmentation algorithms were applied to a set of 131 computed tomography (CT) volumes with different types of tumor contrast levels (hyper-/hypo-intense). abnormalities in tissues (metastasectomie) size and varying amount of lesions. The submitted algorithms have been tested on 70 undisclosed volumes. The dataset is created in collaboration with seven hospitals and research institutions and manually reviewed by independent three radiologists. We found that not a single algorithm performed best for liver and tumors. The best liver segmentation algorithm achieved a Dice score of 0.96 (MICCAI) whereas for tumor segmentation the best algorithm evaluated at 0.67 (ISBI) and 0.70 (MICCAI). The LITS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.,True,bGn0uacAAAAJ:mVmsd5A6BfQC,174,https://arxiv.org/abs/1901.04056,10996095861110041445,/scholar?cites=10996095861110041445,,,https://arxiv.org/pdf/1901.04056,0,0,0
1278246,GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation,2018,Xiaojuan Qi and Renjie Liao and Zhengzhe Liu and Raquel Urtasun and Jiaya Jia,,,,283-291,,In this paper. we propose Geometric Neural Network (GeoNet) to jointly predict depth and surface normal maps from a single image. Building on top of two-stream CNNs. our GeoNet incorporates geometric relation between depth and surface normal via the new depth-to-normal and normal-to-depth networks. Depth-to-normal network exploits the least square solution of surface normal from depth and im-proves its quality with a residual module. Normal-to-depth network. contrarily. refines the depth map based on the con-straints from the surface normal through a kernel regression module. which has no parameter to learn. These two net-works enforce the underlying model to efficiently predict depth and surface normal for high consistency and corre-sponding accuracy. Our experiments on NYU v2 dataset verify that our GeoNet is able to predict geometrically con-sistent depth and normal maps. It achieves top performance on surface normal estimation and is on par with state-of-the-art depth estimation methods.,True,bGn0uacAAAAJ:Se3iqnhoufwC,160,http://openaccess.thecvf.com/content_cvpr_2018/html/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.html,2144908127109091003,/scholar?cites=2144908127109091003,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.pdf,0,0,0
1278247,Deep Contextual Networks for Neuronal Structure Segmentation.,2016,Hao Chen* and Xiaojuan Qi* and Jie-Zhi Cheng and Pheng-Ann Heng,,,,1167-1173,,The goal of connectomics is to manifest the interconnections of neural system with the Electron Microscopy (EM) images. However. the formidable size of EM image data renders human annotation impractical. as it may take decades to fulfill the whole job. An alternative way to reconstruct the connectome can be attained with the computerized scheme that can automatically segment the neuronal structures. The segmentation of EM images is very challenging as the depicted structures can be very diverse. To address this difficult problem. a deep contextual network is proposed here by leveraging multi-level contextual information from the deep hierarchical structure to achieve better segmentation performance. To further improve the robustness against the vanishing gradients and strengthen the capability of the back-propagation of gradient flow. auxiliary classifiers are incorporated in the architecture of our deep neural network. It will be shown that our method can effectively parse the semantic meaning from the images with the underlying neural network and accurately delineate the structural boundaries with the reference of low-level contextual cues. Experimental results on the benchmark dataset of 2012 ISBI segmentation challenge of neuronal structures suggest that the proposed method can outperform the state-of-the-art methods by a large margin with respect to different evaluation measurements. Our method can potentially facilitate the automatic connectome analysis from EM images with less human intervention effort.,True,bGn0uacAAAAJ:d1gkVwhDpl0C,135,https://ojs.aaai.org/index.php/AAAI/article/view/10141,14292439319317398157,/scholar?cites=14292439319317398157,,,https://ojs.aaai.org/index.php/AAAI/article/download/10141/10000,0,0,0
1278248,Augmented feedback in semantic segmentation under image level supervision,2016,Xiaojuan Qi and Zhengzhe Liu and Jianping Shi and Hengshuang Zhao and Jiaya Jia,,,,90-105,Springer. Cham,Training neural networks for semantic segmentation is data hungry. Meanwhile annotating a large number of pixel-level segmentation masks needs enormous human effort. In this paper. we propose a framework with only image-level supervision. It unifies semantic segmentation and object localization with important proposal aggregation and selection modules. They greatly reduce the notorious error accumulation problem that commonly arises in weakly supervised learning. Our proposed training algorithm progressively improves segmentation performance with augmented feedback in iterations. Our method achieves decent results on the PASCAL VOC 2012 segmentation data. outperforming previous image-level supervised methods by a large margin.,True,bGn0uacAAAAJ:UeHWp8X0CEIC,111,https://link.springer.com/chapter/10.1007/978-3-319-46484-8_6,17361572888371043802,/scholar?cites=17361572888371043802,,,http://www.cs.cuhk.edu.hk/~leojia/papers/weakseg_eccv16.pdf,0,0,0
1278249,Metagenomic and functional analysis of hindgut microbiota of a wood-feeding higher termite,2007,Falk Warnecke and Peter Luginbühl and Natalia Ivanova and Majid Ghassemian and Toby H Richardson and Justin T Stege and Michelle Cayouette and Alice C McHardy and Gordana Djordjevic and Nahla Aboushadi and Rotem Sorek and Susannah G Tringe and Mircea Podar and Hector Garcia Martin and Victor Kunin and Daniel Dalevi and Julita Madejska and Edward Kirton and Darren Platt and Ernest Szeto and Asaf Salamov and Kerrie Barry and Natalia Mikhailova and Nikos C Kyrpides and Eric G Matson and Elizabeth A Ottesen and Xinning Zhang and Myriam Hernández and Catalina Murillo and Luis G Acosta and Isidore Rigoutsos and Giselle Tamayo and Brian D Green and Cathy Chang and Edward M Rubin and Eric J Mathur and Dan E Robertson and Philip Hugenholtz and Jared R Leadbetter,450,Nature,7169,560-565,Nature Publishing Group,From the standpoints of both basic research and biotechnology. there is considerable interest in reaching a clearer understanding of the diversity of biological mechanisms employed during lignocellulose degradation. Globally. termites are an extremely successful group of wood-degrading organisms 1 and are therefore important both for their roles in carbon turnover in the environment and as potential sources of biochemical catalysts for efforts aimed at converting wood into biofuels. Only recently have data supported any direct role for the symbiotic bacteria in the gut of the termite in cellulose and xylan hydrolysis 2. Here we use a metagenomic analysis of the bacterial community resident in the hindgut paunch of a wood-feeding ‘higher’Nasutitermes species (which do not contain cellulose-fermenting protozoa) to show the presence of a large. diverse set of bacterial genes for cellulose and xylan hydrolysis. Many …,True,A7rUODYAAAAJ:u5HHmVD_uO8C,1328,https://www.nature.com/articles/nature06269,18422919772922641307,/scholar?cites=18422919772922641307,,,https://authors.library.caltech.edu/37425/7/nature06269-s1.pdf,0,0,0
1278250,Genome streamlining in a cosmopolitan oceanic bacterium,2005,Stephen J Giovannoni and H James Tripp and Scott Givan and Mircea Podar and Kevin L Vergin and Damon Baptista and Lisa Bibbs and Jonathan Eads and Toby H Richardson and Michiel Noordewier and Michael S Rappé and Jay M Short and James C Carrington and Eric J Mathur,309,science,5738,1242-1245,American Association for the Advancement of Science,The SAR11 clade consists of very small. heterotrophic marine α-proteobacteria that are found throughout the oceans. where they account for about 25% of all microbial cells. Pelagibacter ubique. the first cultured member of this clade. has the smallest genome and encodes the smallest number of predicted open reading frames known for a free-living microorganism. In contrast to parasitic bacteria and archaea with small genomes. P. ubique has complete biosynthetic pathways for all 20 amino acids and all but a few cofactors. P. ubique has no pseudogenes. introns. transposons. extrachromosomal elements. or inteins; few paralogs; and the shortest intergenic spacers yet observed for any cell.,True,A7rUODYAAAAJ:u-x6o8ySG0sC,1031,https://science.sciencemag.org/content/309/5738/1242.abstract,11387297161222586750,/scholar?cites=11387297161222586750,,,https://hahana.soest.hawaii.edu/cmoreserver/summercourse/2015/documents/DeLong_06-01/giovannoni_Science_2005.pdf,0,0,0
1278251,The alternative nitrogenase of Azotobacter chroococcum is a vanadium enzyme,1986,Robert L Robson and Robert R Eady and Toby H Richardson and Richard W Miller and Marie Hawkins and John R Postgate,322,Nature,6077,388-390,Nature Publishing Group,The requirement for molybdenum in biological dinitrogen fixation. first reported by Bortels 1. is due to its involvement at or near the site of reduction of N 2 in conventional nitrogenase. To date. all nitrogenases which have been purified to homogeneity consist of an iron protein (component 2) and a molybdoprotein (component 1) 2. Azotobacter vinelandii. an obligately aerobic diazotrophic bacterium. has two systems for nitrogen fixation: a conventional nitrogenase involving molybdenum and an alternative system which functions under conditions of Mo deficiency and does not require the structural genes for conventional nitrogenase 3–6. The properties of the nitrogenase in extracts of comparable deletion strains of A. vinelandii are consistent with a two-component system 6. 7 in which the component 1-containing fraction has no detectable Mo (ref. 6). Recently. an alternative nitrogen fixation system has been …,True,A7rUODYAAAAJ:d1gkVwhDpl0C,585,https://www.nature.com/articles/322388a0,10680961342565980007,/scholar?cites=10680961342565980007,,,,0,0,0
1278252,The genome of Nanoarchaeum equitans: insights into early archaeal evolution and derived parasitism,2003,Elizabeth Waters and Michael J Hohn and Ivan Ahel and David E Graham and Mark D Adams and Mary Barnstead and Karen Y Beeson and Lisa Bibbs and Randall Bolanos and Martin Keller and Keith Kretz and Xiaoying Lin and Eric Mathur and Jingwei Ni and Mircea Podar and Toby Richardson and Granger G Sutton and Melvin Simon and Dieter Söll and Karl O Stetter and Jay M Short and Michiel Noordewier,100,Proceedings of the National Academy of Sciences,22,12984-12988,National Academy of Sciences,The hyperthermophile Nanoarchaeum equitans is an obligate symbiont growing in coculture with the crenarchaeon Ignicoccus. Ribosomal protein and rRNA-based phylogenies place its branching point early in the archaeal lineage. representing the new archaeal kingdom Nanoarchaeota. The N. equitans genome (490.885 base pairs) encodes the machinery for information processing and repair. but lacks genes for lipid. cofactor. amino acid. or nucleotide biosyntheses. It is the smallest microbial genome sequenced to date. and also one of the most compact. with 95% of the DNA predicted to encode proteins or stable RNAs. Its limited biosynthetic and catabolic capacity indicates that N. equitans9 symbiotic relationship to Ignicoccus is parasitic. making it the only known archaeal parasite. Unlike the small genomes of bacterial parasites that are undergoing reductive evolution. N. equitans has few pseudogenes or …,True,A7rUODYAAAAJ:9yKSN-GCB0IC,555,https://www.pnas.org/content/100/22/12984.short,8788279718605313226,/scholar?cites=8788279718605313226,,,https://www.pnas.org/content/pnas/100/22/12984.full.pdf,0,0,0
1278253,Domestication and divergence of Saccharomyces cerevisiae beer yeasts,2016,Brigida Gallone and Jan Steensels and Troels Prahl and Leah Soriaga and Veerle Saels and Beatriz Herrera-Malaver and Adriaan Merlevede and Miguel Roncoroni and Karin Voordeckers and Loren Miraglia and Clotilde Teiling and Brian Steffy and Maryann Taylor and Ariel Schwartz and Toby Richardson and Christopher White and Guy Baele and Steven Maere and Kevin J Verstrepen,166,Cell,6,1397-1410. e16,Cell Press,Whereas domestication of livestock. pets. and crops is well documented. it is still unclear to what extent microbes associated with the production of food have also undergone human selection and where the plethora of industrial strains originates from. Here. we present the genomes and phenomes of 157 industrial Saccharomyces cerevisiae yeasts. Our analyses reveal that today’s industrial yeasts can be divided into five sublineages that are genetically and phenotypically separated from wild strains and originate from only a few ancestors through complex patterns of domestication and local divergence. Large-scale phenotyping and genome analysis further show strong industry-specific selection for stress tolerance. sugar utilization. and flavor production. while the sexual cycle and other phenotypes related to survival in nature show decay. particularly in beer yeasts. Together. these results shed light on the origins …,True,A7rUODYAAAAJ:abG-DnoFyZgC,370,https://www.sciencedirect.com/science/article/pii/S0092867416310716,12300522216929102892,/scholar?cites=12300522216929102892,,,https://www.sciencedirect.com/science/article/pii/S0092867416310716,0,0,0
1278254,A novel. high performance enzyme for starch liquefaction: discovery and optimization of a low pH. thermostable α-amylase,2002,Toby H Richardson and Xuqiu Tan and Gerhard Frey and Walter Callen and Mark Cabell and David Lam and John Macomber and Jay M Short and Dan E Robertson and Carl Miller,277,Journal of Biological Chemistry,29,26501-26507,Elsevier,High throughput screening of microbial DNA libraries was used to identify α-amylases with phenotypic characteristics compatible with large scale corn wet milling process conditions. Single and multiorganism DNA libraries originating from various environments were targeted for activity and sequence-based screening approaches. After initial screening. 15 clones were designated as primary hits based upon activity at pH 4.5 or 95 °C without addition of endogenous Ca2+. After further characterization. three enzyme candidates were chosen each with an exceptional expression of one or more aspects of the necessary phenotype: temperature stability. pH optimum. lowered reliance on Ca2+ and/or enzyme rate. To combine the best aspects of the three phenotypes to optimize process compatibility. the natural gene homologues were used as a parental sequence set for gene reassembly. Approximately 21.000 …,True,A7rUODYAAAAJ:2osOgNQ5qMEC,291,https://www.sciencedirect.com/science/article/pii/S0021925819663994,5141031454772184656,/scholar?cites=5141031454772184656,,,https://www.sciencedirect.com/science/article/pii/S0021925819663994,0,0,0
1278255,Exploring nitrilase sequence space for enantioselective catalysis,2004,Dan E Robertson and Jennifer A Chaplin and Grace DeSantis and Mircea Podar and Mark Madden and Ellen Chi and Toby Richardson and Aileen Milan and Mark Miller and David P Weiner and Kelvin Wong and Jeff McQuaid and Bob Farwell and Lori A Preston and Xuqiu Tan and Marjory A Snead and Martin Keller and Eric Mathur and Patricia L Kretz and Mark J Burk and Jay M Short,70,Applied and Environmental Microbiology,4,2429-2436,American Society for Microbiology,Nitrilases are important in the biosphere as participants in synthesis and degradation pathways for naturally occurring. as well as xenobiotically derived. nitriles. Because of their inherent enantioselectivity. nitrilases are also attractive as mild. selective catalysts for setting chiral centers in fine chemical synthesis. Unfortunately. <20 nitrilases have been reported in the scientific and patent literature. and because of stability or specificity shortcomings. their utility has been largely unrealized. In this study. 137 unique nitrilases. discovered from screening of >600 biotope-specific environmental DNA (eDNA) libraries. were characterized. Using culture-independent means. phylogenetically diverse genomes were captured from entire biotopes. and their genes were expressed heterologously in a common cloning host. Nitrilase genes were targeted in a selection-based expression assay of clonal populations numbering 106 …,True,A7rUODYAAAAJ:qjMakFHDy7sC,244,https://aem.asm.org/content/70/4/2429.short,17266906840504025214,/scholar?cites=17266906840504025214,,,https://aem.asm.org/content/aem/70/4/2429.full.pdf,0,0,0
1278256,The vanadium nitrogenase of Azotobacter chroococcum. Purification and properties of the VFe protein,1987,RR Eady and Robert L Robson and Toby H Richardson and Richard W Miller and Marie Hawkins,244,Biochemical Journal,1,197-207,Portland Press Ltd.,1. Nitrogenase activity of a strain of Azotobacter chroococcum lacking the structural genes for conventional nitrogenase (nifHDK) was separated into two components: an Fe-containing protein and a vanadoprotein. 2. The larger protein was purified to homogeneity by the criterion of electrophoresis of 10% (w/v) acrylamide gels in the presence of SDS. Two types of subunit. of Mr 50.000 and 55.000. were present in equal amounts. 3. The protein had an Mr of 210.000 and contained 2 V atoms. 23 Fe atoms and 20 acid-labile sulphide groups per molecule. The Mo content was less than 0.06 g-atom/mol. All the common amino acids were present. with a predominance of acidic residues. Ultracentrifugal analysis gave a maximum sedimentation coefficient of 9.7 S and a symmetrical boundary at 5 mg of protein X ml-1; dissociation occurred at lower concentrations. The specific activities (nmol of product/min per mg of …,True,A7rUODYAAAAJ:UeHWp8X0CEIC,198,https://portlandpress.com/biochemj/article/244/1/197/22853,4043177277362352064,/scholar?cites=4043177277362352064,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1147972/pdf/biochemj00255-0191.pdf,0,0,0
1278257,Metagenomes from high-temperature chemotrophic systems reveal geochemical controls on microbial community structure and function,2010,William P Inskeep and Douglas B Rusch and Zackary J Jay and Markus J Herrgard and Mark A Kozubal and Toby H Richardson and Richard E Macur and Natsuko Hamamura and Ryan deM Jennings and Bruce W Fouke and Anna-Louise Reysenbach and Frank Roberto and Mark Young and Ariel Schwartz and Eric S Boyd and Jonathan H Badger and Eric J Mathur and Alice C Ortmann and Mary Bateson and Gill Geesey and Marvin Frazier,5,PloS one,3,e9773,Public Library of Science,The Yellowstone caldera contains the most numerous and diverse geothermal systems on Earth. yielding an extensive array of unique high-temperature environments that host a variety of deeply-rooted and understudied Archaea. Bacteria and Eukarya. The combination of extreme temperature and chemical conditions encountered in geothermal environments often results in considerably less microbial diversity than other terrestrial habitats and offers a tremendous opportunity for studying the structure and function of indigenous microbial communities and for establishing linkages between putative metabolisms and element cycling. Metagenome sequence (14–15.000 Sanger reads per site) was obtained for five high-temperature (>65°C) chemotrophic microbial communities sampled from geothermal springs (or pools) in Yellowstone National Park (YNP) that exhibit a wide range in geochemistry including pH. dissolved sulfide. dissolved oxygen and ferrous iron. Metagenome data revealed significant differences in the predominant phyla associated with each of these geochemical environments. Novel members of the Sulfolobales are dominant in low pH environments. while other Crenarchaeota including distantly-related Thermoproteales and Desulfurococcales populations dominate in suboxic sulfidic sediments. Several novel archaeal groups are well represented in an acidic (pH 3) Fe-oxyhydroxide mat. where a higher O2 influx is accompanied with an increase in archaeal diversity. The presence or absence of genes and pathways important in S oxidation-reduction. H2-oxidation. and aerobic respiration (terminal oxidation) provide insight …,True,A7rUODYAAAAJ:Tyk-4Ss8FVUC,192,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009773,4499319652489264269,/scholar?cites=4499319652489264269,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009773,0,0,0
1278258,A Universal Approach to the Expression of Human and Rabbit Cytochrome P450s of the 2C Subfamily inEscherichia coli,1995,Toby H Richardson and Frank Jung and Keith J Griffin and Mike Wester and Judy L Raucy and Byron Kemper and Lester M Bornheim and Christopher Hassett and Curtis J Omiecinski and Eric F Johnson,323,Archives of Biochemistry and Biophysics,1,87-96,Academic Press,Human cytochrome P450s 2C8. 2C9. 2C18. and 2C19 and rabbit cytochrome P450s 2C1. 2C2. 2C4. 2C5. and 2C16 were expressed from their respective cDNAs inEscherichia colias chimeric enzymes in which a portion of the N-terminal membrane anchor sequence was replaced with a modified sequence derived from P450 17A. For 2C1 and 2C2 removal of the extraneous 3′-untranslated sequence allowed the successful expression of constructs that were unproductive in its presence. The levels of expression varied from 180 to 1500 nmol/liter of culture and the addition of δ-aminolevulinic acid to the culture media increased the amount of spectrally detectable P450 for several of these enzymes 2- to 10-fold. The catalytic properties of the modified human 2C P450s expressed inE. coliwere concordant with previously published data for several marker substrates including (S)-mephenytoin for P450 2C19 …,True,A7rUODYAAAAJ:IjCSPb-OGe4C,170,https://www.sciencedirect.com/science/article/pii/S0003986185700136,10543385465662528865,/scholar?cites=10543385465662528865,,,,0,0,0
1278259,Rapid evolution of reversible denaturation and elevated melting temperature in a microbial haloalkane dehalogenase,2001,Kevin A Gray and Toby H Richardson and Keith Kretz and Jay M Short and Flash Bartnek and Ryan Knowles and Lynn Kan and Paul E Swanson and Dan E Robertson,343,Advanced Synthesis & Catalysis,6‐7,607-617,WILEY‐VCH Verlag,Haloalkane dehalogenases have the potential for use in high‐value biocatalytic processes to convert haloalkanes into epoxides via intermediate haloalcohols. Initial bioreactor studies probing the hydrolysis of 1.2.3‐trichloropropane by immobilized wild‐type dehalogenase isolated from Rhodococcus rhodochrous demonstrated. however. that productivity was too low to realize a commercially viable process. A strategy to increase enzyme performance was undertaken to increase the reaction temperature. however it was determined that the wild‐type enzyme was not stable for long periods of time at elevated temperatures. The accelerated laboratory evolution technique of Gene Site Saturation Mutagenesis (GSSM TM) was used to create a clonal enzyme library comprising all single site sequence variants of the Rhodococcus enzyme. Using high throughput screening techniques and rapid kinetics assays. this …,True,A7rUODYAAAAJ:zYLM7Y9cAGgC,149,https://onlinelibrary.wiley.com/doi/abs/10.1002/1615-4169(200108)343:6/7%3C607::AID-ADSC607%3E3.0.CO;2-M,13141409965678284549,/scholar?cites=13141409965678284549,,,,0,0,0
1278260,PyTorch: An imperative style. high-performance deep learning library,2019,Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Kopf and Edward Yang and Zachary DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala,,,,8024-8035,,Deep learning frameworks have often focused on either usability or speed. but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model. makes debugging easy and is consistent with other popular scientific computing libraries. while remaining efficient and supporting hardware accelerators such as GPUs.In this paper. we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.,True,GprA5UsAAAAJ:eQOLeE2rZwMC,5464,https://arxiv.org/abs/1912.01703,3528934790668989119,/scholar?cites=3528934790668989119,,,https://arxiv.org/pdf/1912.01703,0,0,0
1278261,Ask me anything: Dynamic memory networks for natural language processing,2016,Ankit Kumar and Ozan Irsoy and Peter Ondruska and Mohit Iyyer and James Bradbury and Ishaan Gulrajani and Victor Zhong and Romain Paulus and Richard Socher,,,,,,Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN). a neural network architecture which processes input sequences and questions. forms episodic memories. and generates relevant answers. Questions trigger an iterative attention process which allows the model to condition its attention on the inputs and the result of previous iterations. These results are then reasoned over in a hierarchical recurrent sequence model to generate answers. The DMN can be trained end-to-end and obtains state-of-the-art results on several types of tasks and datasets: question answering (Facebook’s bAbI dataset). text classification for sentiment analysis (Stanford Sentiment Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The training for these different tasks relies exclusively on trained word vector representations and input-question-answer triplets.,True,GprA5UsAAAAJ:u5HHmVD_uO8C,1053,http://proceedings.mlr.press/v48/kumar16.html,7594599060018037557,/scholar?cites=7594599060018037557,,,http://proceedings.mlr.press/v48/kumar16.pdf,0,0,0
1278262,Pointer Sentinel Mixture Models,2016,Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher,,,,,,Recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and larger corpora we also introduce the freely available WikiText corpus.,True,GprA5UsAAAAJ:u-x6o8ySG0sC,733,https://arxiv.org/abs/1609.07843,17812832384777278922,/scholar?cites=17812832384777278922,,,https://arxiv.org/pdf/1609.07843,0,0,0
1278263,Learned in Translation: Contextualized Word Vectors,2017,Bryan McCann and James Bradbury and Caiming Xiong and Richard Socher,,,,,,Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper. we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST. IMDb). question classification (TREC). entailment (SNLI). and question answering (SQuAD). For fine-grained sentiment analysis and entailment. CoVe improves performance of our baseline models to the state of the art.,True,GprA5UsAAAAJ:2osOgNQ5qMEC,676,https://arxiv.org/abs/1708.00107,12356231721397988330,/scholar?cites=12356231721397988330,,,https://arxiv.org/pdf/1708.00107,0,0,0
1278264,Quasi-Recurrent Neural Networks,2016,James Bradbury and Stephen Merity and Caiming Xiong and Richard Socher,,ICLR 2017,,,,Recurrent neural networks are a powerful tool for modeling sequential data. but the dependence of each timestep's computation on the previous timestep's output limits parallelism and makes RNNs unwieldy for very long sequences. We introduce quasi-recurrent neural networks (QRNNs). an approach to neural sequence modeling that alternates convolutional layers. which apply in parallel across timesteps. and a minimalist recurrent pooling function that applies in parallel across channels. Despite lacking trainable recurrent layers. stacked QRNNs have better predictive accuracy than stacked LSTMs of the same hidden size. Due to their increased parallelism. they are up to 16 times faster at train and test time. Experiments on language modeling. sentiment classification. and character-level neural machine translation demonstrate these advantages and underline the viability of QRNNs as a basic building block for a variety of sequence tasks.,True,GprA5UsAAAAJ:9yKSN-GCB0IC,338,https://arxiv.org/abs/1611.01576,4062513269935809949,/scholar?cites=4062513269935809949,,,https://arxiv.org/pdf/1611.01576.pdf?fbclid=IwAR3hreOvBGmJZe54-631X49XedcbsQoDYIRu87BcCHEBf_vMKF8FDKK_7Nw,0,0,0
1278265,Non-Autoregressive Neural Machine Translation,2018,Jiatao Gu and James Bradbury and Caiming Xiong and Victor OK Li and Richard Socher,,,,,,Existing approaches to neural machine translation condition each output word on previously generated outputs. We introduce a model that avoids this autoregressive property and produces its outputs in parallel. allowing an order of magnitude lower latency during inference. Through knowledge distillation. the use of input token fertilities as a latent variable. and policy gradient fine-tuning. we achieve this at a cost of as little as 2.0 BLEU points relative to the autoregressive Transformer network used as a teacher. We demonstrate substantial cumulative improvements associated with each of the three aspects of our training strategy. and validate our approach on IWSLT 2016 English-German and two WMT language pairs. By sampling fertilities in parallel at inference time. our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English-Romanian.,True,GprA5UsAAAAJ:IjCSPb-OGe4C,273,https://arxiv.org/abs/1711.02281,3482831974828539059,/scholar?cites=3482831974828539059,,,https://arxiv.org/pdf/1711.02281,0,0,0
1278266,JAX: composable transformations of Python+NumPy programs,2018,James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and Skye Wanderman-Milne,,,,18,,,True,GprA5UsAAAAJ:_FxGoFyzp5QC,210,http://scholar.google.com/scholar?cluster=8800325452556162710&hl=en&oi=scholarr,15904148009787232161,/scholar?cites=15904148009787232161,,,,0,0,0
1278267,OpenSpiel: A framework for reinforcement learning in games,2019,Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and Vinicius Zambaldi and Satyaki Upadhyay and Julien Pérolat and Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and Paul Muller and Timo Ewalds and Ryan Faulkner and János Kramár and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis,,arXiv preprint arXiv:1908.09453,,,,OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games. OpenSpiel supports n-player (single-and multi-agent) zero-sum. cooperative and general-sum. one-shot and sequential. strictly turn-taking and simultaneous-move. perfect and imperfect information games. as well as traditional multiagent environments such as (partially-and fully-observable) grid worlds and social dilemmas. OpenSpiel also includes tools to analyze learning dynamics and other common evaluation metrics. This document serves both as an overview of the code base and an introduction to the terminology. core concepts. and algorithms across the fields of reinforcement learning. computational game theory. and search.,True,GprA5UsAAAAJ:WF5omc3nYNoC,44,https://arxiv.org/abs/1908.09453,3722808320624005135,/scholar?cites=3722808320624005135,,,https://arxiv.org/pdf/1908.09453,0,0,0
1278268,MetaMind Neural Machine Translation System for WMT 2016,2016,James Bradbury and Richard Socher,,,,,,Neural Machine Translation (NMT) systems. introduced only in 2013. have achieved state of the art results in many MT tasks. MetaMind’s submissions to WMT’16 seek to push the state of the art in one such task. English→ German newsdomain translation. We integrate promising recent developments in NMT. including subword splitting and back-translation for monolingual data augmentation. and introduce the Y-LSTM. a novel neural translation architecture.,True,GprA5UsAAAAJ:d1gkVwhDpl0C,17,https://www.aclweb.org/anthology/W16-2308.pdf,3910559833532289371,/scholar?cites=3910559833532289371,,,https://www.aclweb.org/anthology/W16-2308.pdf,0,0,0
1278269,Towards Neural Machine Translation with Latent Tree Attention,2017,James Bradbury and Richard Socher,,,,,,Building models that take advantage of the hierarchical structure of language without a priori annotation is a longstanding goal in natural language processing. We introduce such a model for the task of machine translation. pairing a recurrent neural network grammar encoder with a novel attentional RNNG decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target. When trained on character-level datasets with no explicit segmentation or parse annotation. the model learns a plausible segmentation and shallow parse. obtaining performance close to an attentional baseline.,True,GprA5UsAAAAJ:qjMakFHDy7sC,13,https://arxiv.org/abs/1709.01915,5484613380871346388,/scholar?cites=5484613380871346388,,,https://arxiv.org/pdf/1709.01915,0,0,0
1278270,A Flexible Approach to Automated RNN Architecture Generation,2018,Martin Schrimpf and Stephen Merity and James Bradbury and Richard Socher,,,,,,The process of designing neural architectures requires expert knowledge and extensive trial and error. While automated architecture search may simplify these requirements. the recurrent neural network (RNN) architectures generated by existing methods are limited in both flexibility and components. We propose a domain-specific language (DSL) for use in automated architecture search which can produce novel RNNs of arbitrary depth and width. The DSL is flexible enough to define standard architectures such as the Gated Recurrent Unit and Long Short Term Memory and allows the introduction of non-standard RNN components such as trigonometric curves and layer normalization. Using two different candidate generation techniques. random search with a ranking function and reinforcement learning. we explore the novel architectures produced by the RNN DSL for language modeling and machine translation domains. The resulting architectures do not follow human intuition yet perform well on their targeted tasks. suggesting the space of usable RNN architectures is far larger than previously assumed.,True,GprA5UsAAAAJ:zYLM7Y9cAGgC,12,https://arxiv.org/abs/1712.07316,8111960316421570736,/scholar?cites=8111960316421570736,,,https://arxiv.org/pdf/1712.07316,0,0,0
1278271,Electric-field control of local ferromagnetism using a magnetoelectric multiferroic,2008,Ying-Hao Chu and Lane W Martin and Mikel B Holcomb and Martin Gajek and Shu-Jen Han and Qing He and Nina Balke and Chan-Ho Yang and Donkoun Lee and Wei Hu and Qian Zhan and Pei-Ling Yang and Arantxa Fraile-Rodríguez and Andreas Scholl and Shan X Wang and Ramamoorthy Ramesh,7,Nature materials,6,478-482,Nature Publishing Group,Multiferroics are of interest for memory and logic device applications. as the coupling between ferroelectric and magnetic properties enables the dynamic interaction between these order parameters. Here. we report an approach to control and switch local ferromagnetism with an electric field using multiferroics. We use two types of electromagnetic coupling phenomenon that are manifested in heterostructures consisting of a ferromagnet in intimate contact with the multiferroic BiFeO 3. The first is an internal. magnetoelectric coupling between antiferromagnetism and ferroelectricity in the BiFeO 3 film that leads to electric-field control of the antiferromagnetic order. The second is based on exchange interactions at the interface between a ferromagnet (Co 0.9 Fe 0.1) and the antiferromagnet. We have discovered a one-to-one mapping of the ferroelectric and ferromagnetic domains. mediated by the colinear coupling …,True,p1xH91gAAAAJ:ufrVoPGSRksC,1383,https://www.nature.com/articles/nmat2184,8471361269607731749,/scholar?cites=8471361269607731749,,,https://www.researchgate.net/profile/Mikel_Holcomb/publication/5415331_Electric-Field_Control_of_Local_Ferromagnetism_Using_a_Magnetoelectric_Multiferroic/links/0c96051adfa493ffd5000000/Electric-Field-Control-of-Local-Ferromagnetism-Using-a-Magnetoelectric-Multiferroic.pdf,0,0,0
1278272,Conduction at domain walls in oxide multiferroics,2009,Jan Seidel and Lane W Martin and Q He and Q Zhan and Y-H Chu and A Rother and ME Hawkridge and P Maksymovych and P Yu and M ea Gajek and N Balke and SV Kalinin and S Gemming and F Wang and G Catalan and JF Scott and NA Spaldin and J Orenstein and R Ramesh,8,Nature materials,3,229-234,Nature Publishing Group,Domain walls may play an important role in future electronic devices. given their small size as well as the fact that their location can be controlled. Here. we report the observation of room-temperature electronic conductivity at ferroelectric domain walls in the insulating multiferroic BiFeO 3. The origin and nature of the observed conductivity are probed using a combination of conductive atomic force microscopy. high-resolution transmission electron microscopy and first-principles density functional computations. Our analyses indicate that the conductivity correlates with structurally driven changes in both the electrostatic potential and the local electronic structure. which shows a decrease in the bandgap at the domain wall. Additionally. we demonstrate the potential for device applications of such conducting nanoscale features.,True,p1xH91gAAAAJ:_kc_bZDykSQC,1154,https://www.nature.com/articles/nmat2373,16745809133307441413,/scholar?cites=16745809133307441413,,,https://ir.nctu.edu.tw/bitstream/11536/7519/1/000263556800023.pdf,0,0,0
1278273,Tunnel junctions with multiferroic barriers,2007,Martin Gajek and Manuel Bibes and Stéphane Fusil and Karim Bouzehouane and Josep Fontcuberta and Agnes Barthelemy and Albert Fert,6,Nature materials,4,296-302,Nature Publishing Group,Multiferroics are singular materials that can exhibit simultaneously electric and magnetic orders. Some are ferroelectric and ferromagnetic and provide the opportunity to encode information in electric polarization and magnetization to obtain four logic states. However. such materials are rare and schemes allowing a simple electrical readout of these states have not been demonstrated in the same device. Here. we show that films of La 0.1 Bi 0.9 MnO 3 (LBMO) are ferromagnetic and ferroelectric. and retain both ferroic properties down to a thickness of 2 nm. We have integrated such ultrathin multiferroic films as barriers in spin-filter-type tunnel junctions that exploit the magnetic and ferroelectric degrees of freedom of LBMO. Whereas ferromagnetism permits read operations reminiscent of magnetic random access memories (MRAM). the electrical switching evokes a ferroelectric RAM write operation. Significantly. our …,True,p1xH91gAAAAJ:0EnyYjriUFMC,1110,https://www.nature.com/articles/nmat1860,10620095534652856332,/scholar?cites=10620095534652856332,,,https://www.researchgate.net/profile/Martin_Gajek/publication/6454682_Tunnel_Junctions_with_Multiferroic_Barriers/links/5480ef850cf20f081e726b7c.pdf,0,0,0
1278274,Electric modulation of conduction in multiferroic Ca-doped BiFeO 3 films,2009,C-H Yang and Jan Seidel and SY Kim and PB Rossen and Pu Yu and Martin Gajek and Ying-Hao Chu and Lane W Martin and MB Holcomb and Q He and Petro Maksymovych and Nina Balke and Sergei V Kalinin and Arthur P Baddorf and SR Basu and ML Scullin and R Ramesh,8,Nature materials,6,485-493,Nature Publishing Group,Many interesting materials phenomena such as the emergence of high-T c superconductivity in the cuprates and colossal magnetoresistance in the manganites arise out of a doping-driven competition between energetically similar ground states. Doped multiferroics present a tantalizing evolution of this generic concept of phase competition. Here. we present the observation of an electronic conductor–insulator transition by control of band-filling in the model antiferromagnetic ferroelectric BiFeO 3 through Ca doping. Application of electric field enables us to control and manipulate this electronic transition to the extent that ap–n junction can be created. erased and inverted in this material. A ‘dome-like’feature in the doping dependence of the ferroelectric transition is observed around a Ca concentration of∼ 1/8. where a new pseudo-tetragonal phase appears and the electric modulation of conduction is optimized …,True,p1xH91gAAAAJ:Se3iqnhoufwC,490,https://www.nature.com/articles/nmat2432,9609818036464246459,/scholar?cites=9609818036464246459,,,https://prometheus.berkeley.edu/assets/yang-naturemater-2009.pdf,0,0,0
1278275,Multiferroics and magnetoelectrics: thin films and nanostructures,2008,LW Martin and SP Crane and YH Chu and MB Holcomb and M Gajek and Mark Huijben and Chan-Ho Yang and N Balke and R Ramesh,20,,43,434220,IOP Publishing,Multiferroic materials. or materials that simultaneously possess two or more ferroic order parameters. have returned to the forefront of materials research. Driven by the desire to achieve new functionalities—such as electrical control of ferromagnetism at room temperature—researchers have undertaken a concerted effort to identify and understand the complexities of multiferroic materials. The ability to create high quality thin film multiferroics stands as one of the single most important landmarks in this flurry of research activity. In this review we discuss the basics of multiferroics including the important order parameters and magnetoelectric coupling in materials. We then discuss in detail the growth of single phase. horizontal multilayer. and vertical heterostructure multiferroics. The review ends with a look to the future and how multiferroics can be used to create new functionalities in materials.,True,p1xH91gAAAAJ:5nxA0vEk-isC,466,https://iopscience.iop.org/article/10.1088/0953-8984/20/43/434220/meta,10701190097939866061,/scholar?cites=10701190097939866061,,,https://pdfs.semanticscholar.org/e2df/081ba2d69246bbc6bda6d20f9b7c1d8eb71a.pdf,0,0,0
1278276,Photoconductivity in  thin films,2008,SR Basu and LW Martin and YH Chu and M Gajek and R Ramesh and RC Rai and X Xu and JL Musfeldt,92,Applied Physics Letters,9,091905,American Institute of Physics,The optical properties of epitaxial BiFeO3 thin films have been characterized in the visible range. Variable temperature spectra show an absorption onset near 2.17eV. a direct gap (2.667±0.005eV at 300K). and charge transfer excitations at higher energy. Additionally. we report photoconductivity in BiFeO3 films under illumination from a 100mW∕cm2 white light source. A direct correlation is observed between the magnitude of the photoconductivity and postgrowth cooling pressure. Dark conductivities increased by an order of magnitude when comparing films cooled in 760 and 0.1Torr. Large increases in photoconductivity are observed in light.,True,p1xH91gAAAAJ:roLk4NBRz8UC,465,https://aip.scitation.org/doi/abs/10.1063/1.2887908,9262876750956492206,/scholar?cites=9262876750956492206,,,https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1000&context=physicsxu,0,0,0
1278277,Spintronics with multiferroics,2008,H Béa and M Gajek and M Bibes and A Barthélémy,20,Journal of Physics: Condensed Matter,43,434221,IOP Publishing,In this paper. we review the recent research on the functionalization of multiferroics for spintronics applications. We focus more particularly on antiferromagnetic and ferroelectric BiFeO 3 and its integration in several types of architectures. For instance. when used as a tunnel barrier. BiFeO 3 allows the observation of a large tunnel magnetoresistance with Co and (La. Sr) MnO 3 ferromagnetic electrodes. Also. its antiferromagnetic and magnetoelectric properties have been exploited to induce an exchange coupling with a ferromagnet. The mechanisms of such an exchange coupling open ways to electrically control magnetization and possibly the logic state of spintronics devices. We also discuss recent results concerning the use of ferromagnetic and ferroelectric (La. Bi) MnO 3 as an active tunnel barrier in magnetic tunnel junctions with Au and (La. Sr) MnO 3 electrodes. A four-resistance-state device has been …,True,p1xH91gAAAAJ:MXK_kJrjxJIC,442,https://iopscience.iop.org/article/10.1088/0953-8984/20/43/434221/meta,7330271540432129633,/scholar?cites=7330271540432129633,,,,0,0,0
1278278,Spintronics with multiferroics,2008,H Béa and M Gajek and M Bibes and A Barthélémy,20,Journal of Physics: Condensed Matter,43,434221,IOP Publishing,In this paper. we review the recent research on the functionalization of multiferroics for spintronics applications. We focus more particularly on antiferromagnetic and ferroelectric BiFeO 3 and its integration in several types of architectures. For instance. when used as a tunnel barrier. BiFeO 3 allows the observation of a large tunnel magnetoresistance with Co and (La. Sr) MnO 3 ferromagnetic electrodes. Also. its antiferromagnetic and magnetoelectric properties have been exploited to induce an exchange coupling with a ferromagnet. The mechanisms of such an exchange coupling open ways to electrically control magnetization and possibly the logic state of spintronics devices. We also discuss recent results concerning the use of ferromagnetic and ferroelectric (La. Bi) MnO 3 as an active tunnel barrier in magnetic tunnel junctions with Au and (La. Sr) MnO 3 electrodes. A four-resistance-state device has been …,True,p1xH91gAAAAJ:WF5omc3nYNoC,442,https://iopscience.iop.org/article/10.1088/0953-8984/20/43/434221/meta,7330271540432129633,/scholar?cites=7330271540432129633,,,,0,0,0
1278279,Electric-field-induced magnetization reversal in a ferromagnet-multiferroic heterostructure,2011,JT Heron and M Trassin and K Ashraf and M Gajek and Q He and SY Yang and DE Nikonov and YH Chu and S Salahuddin and R Ramesh,107,Physical review letters,21,217202,American Physical Society,A reversal of magnetization requiring only the application of an electric field can lead to low-power spintronic devices by eliminating conventional magnetic switching methods. Here we show a nonvolatile. room temperature magnetization reversal determined by an electric field in a ferromagnet-multiferroic system. The effect is reversible and mediated by an interfacial magnetic coupling dictated by the multiferroic. Such electric-field control of a magnetoelectric device demonstrates an avenue for next-generation. low-energy consumption spintronics.,True,p1xH91gAAAAJ:2osOgNQ5qMEC,426,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.107.217202,3451429568019192083,/scholar?cites=3451429568019192083,,,https://apps.dtic.mil/sti/pdfs/ADA578253.pdf,0,0,0
1278280,Spin torque switching of 20 nm magnetic tunnel junctions with perpendicular anisotropy,2012,M Gajek and JJ Nowak and JZ Sun and PL Trouilloud and EJ O’sullivan and DW Abraham and MC Gaidis and G Hu and S Brown and Y Zhu and RP Robertazzi and WJ Gallagher and DC Worledge,100,Applied Physics Letters,13,132408,American Institute of Physics,Spin-transfer torque magnetic random access memory (STT-MRAM) is one of the most promising emerging non-volatile memory technologies. MRAM has so far been demonstrated with a unique combination of density. speed. and non-volatility in a single chip. however. without the capability to replace any single mainstream memory. In this paper. we demonstrate the basic physics of spin torque switching in 20 nm diameter magnetic tunnel junctions with perpendicular magnetic anisotropy materials. This deep scaling capability clearly indicates the STT MRAM device itself may be suitable for integration at much higher densities than previously proven.,True,p1xH91gAAAAJ:YOwf2qJgpHMC,293,https://aip.scitation.org/doi/abs/10.1063/1.3694270,16001616933727836872,/scholar?cites=16001616933727836872,,,,0,0,0
1278281,Spin filtering through ferromagnetic  tunnel barriers,2005,M Gajek and Manuel Bibes and Agnès Barthélémy and K Bouzehouane and S Fusil and M Varela and J Fontcuberta and Albert Fert,72,Physical Review B,2,020406,American Physical Society,We report on experiments of spin filtering through ultrathin single-crystal layers of the insulating and ferromagnetic oxide Bi Mn O 3 (BMO). The spin polarization of the electrons tunneling from a gold electrode through BMO is analyzed with a counterelectrode of the half-metallic oxide La 2∕ 3 Sr 1∕ 3 Mn O 3 (LSMO). At 3 K we find a 50% change of the tunnel resistances according to whether the magnetizations of BMO and LSMO are parallel or opposite. This effect corresponds to a spin-filtering efficiency of up to 22%. Our results thus show the potential of complex ferromagnetic insulating oxides for spin filtering and injection.,True,p1xH91gAAAAJ:IjCSPb-OGe4C,214,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.72.020406,4882576145207698563,/scholar?cites=4882576145207698563,,,https://arxiv.org/pdf/cond-mat/0504667,0,0,0
1278282,Activity recognition from acceleration data based on discrete consine transform and SVM,2009,Zhenyu He and Lianwen Jin,,,,5041-5044,IEEE,This paper developed a high-accuracy human activity recognition system based on single tri-axis accelerometer for use in a naturalistic environment. This system exploits the discrete cosine transform (DCT). the Principal Component Analysis (PCA) and Support Vector Machine (SVM) for classification human different activity. First. the effective features are extracted from accelerometer data using DCT. Next. feature dimension is reduced by PCA in DCT domain. After implementing the PCA. the most invariant and discriminating information for recognition is maintained. As a consequence. Multi-class Support Vector Machines is adopted to distinguish different human activities. Experiment results show that the proposed system achieves the best accuracy is 97.51%. which is better than other approaches.,True,WMUStEUAAAAJ:2osOgNQ5qMEC,316,https://ieeexplore.ieee.org/abstract/document/5346042/,9628299144229834968,/scholar?cites=9628299144229834968,,,http://www.dlvc-lab.net/download/papers/conference/Activity%20Recognition%20from%20acceleration%20data%20Based%20on%20Discrete%20Consine%20Transform%20and%20SVM.pdf,0,0,0
1278283,A new facial expression recognition method based on local Gabor filter bank and PCA plus LDA,2005,Hong-Bo Deng and Lian-Wen Jin and Li-Xin Zhen and Jian-Cheng Huang,11,International Journal of Information Technology,11,86-96,,This paper proposes a facial expression recognition system based on Gabor feature using a novel local Gabor filter bank. Traditionally. a global Gabor filter bank with 5 frequencies and 8 orientations is often used to extract the Gabor feature. A lot of time will be involved to extract feature and the dimensions of such Gabor feature vector are prohibitively high. A novel local Gabor filter bank with part of frequency and orientation parameters is proposed. In order to evaluate the performance of the local Gabor filter bank. we first employed a two-stage feature compression method PCA plus LDA to select and compress the Gabor feature. then adopted minimum distance classifier to recognize facial expression. Experimental results show that the method is effective for both dimension reduction and good recognition performance in comparison with traditional entire Gabor filter bank. The best average recognition rate achieves 97.33% for JAFFE facial expression database.,True,WMUStEUAAAAJ:u5HHmVD_uO8C,299,https://sigmaland.ir/wp-content/uploads/2019/02/Sigmaland.ir_A-New-Facial-Expression-Recognition-Method-Based-on-Local-Gabor-Filter-Bank-and-PCA-plus-LDA.pdf,5355720345275603115,/scholar?cites=5355720345275603115,,,https://sigmaland.ir/wp-content/uploads/2019/02/Sigmaland.ir_A-New-Facial-Expression-Recognition-Method-Based-on-Local-Gabor-Filter-Bank-and-PCA-plus-LDA.pdf,0,0,0
1278284,High performance offline handwritten chinese character recognition using googlenet and directional feature maps,2015,Zhuoyao Zhong and Lianwen Jin and Zecheng Xie,,,,846-850,IEEE,Just like its great success in solving many computer vision problems. the convolutional neural networks (CNN) provided new end-to-end approach to handwritten Chinese character recognition (HCCR) with very promising results in recent years. However. previous CNNs so far proposed for HCCR were neither deep enough nor slim enough. We show in this paper that. a deeper architecture can benefit HCCR a lot to achieve higher performance. meanwhile can be designed with less parameters. We also show that the traditional feature extraction methods. such as Gabor or gradient feature maps. are still useful for enhancing the performance of CNN. We design a streamlined version of GoogLeNet [13]. which was original proposed for image classification in recent years with very deep architecture. for HCCR (denoted as HCCR-GoogLeNet). The HCCR-GoogLeNet we used is 19 layers deep but involves with only 7 …,True,WMUStEUAAAAJ:QC_fukgq8lwC,232,https://ieeexplore.ieee.org/abstract/document/7333881/,4447097322579447604,/scholar?cites=4447097322579447604,,,https://arxiv.org/pdf/1505.04925,0,0,0
1278285,Deep matching prior network: Toward tighter multi-oriented text detection,2017,Yuliang Liu and Lianwen Jin,,,,1962-1969,,"Detecting incidental scene text is a challenging task because of multi-orientation. perspective distortion. and variation of text size. color and scale. Retrospective research has only focused on using rectangular bounding box or horizontal sliding window to localize text. which may result in redundant background noise. unnecessary overlap or even information loss. To address these issues. we propose a new Convolutional Neural Networks (CNNs) based method. named Deep Matching Prior Network (DMPNet). to detect text with tighter quadrangle. First. we use quadrilateral sliding windows in several specific intermediate convolutional layers to roughly recall the text with higher overlapping area and then a shared Monte-Carlo method is proposed for fast and accurate computing of the polygonal areas. After that. we designed a sequential protocol for relative regression which can exactly predict text with compact quadrangle. Moreover. a auxiliary smooth Ln loss is also proposed for further regressing the position of text. which has better overall performance than L2 loss and smooth L1 loss in terms of robustness and stability. The effectiveness of our approach is evaluated on a public word-level. multi-oriented scene text database. ICDAR 2015 Robust Reading Competition Challenge 4"" Incidental scene text localization"". The performance of our method is evaluated by using F-measure and found to be 70.64%. outperforming the existing state-of-the-art method with F-measure 63.76%.",True,WMUStEUAAAAJ:l04XxKJJ8swC,222,http://openaccess.thecvf.com/content_cvpr_2017/html/Liu_Deep_Matching_Prior_CVPR_2017_paper.html,17621265355024312105,/scholar?cites=17621265355024312105,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Liu_Deep_Matching_Prior_CVPR_2017_paper.pdf,0,0,0
1278286,Activity recognition from acceleration data using AR model representation and SVM,2008,Zhen-Yu He and Lian-Wen Jin,4,,,2245-2250,IEEE,In this paper. the autoregressive (AR) model of time-series is presented to recognize human activity from a tri-axial accelerometer data. Four orders of autoregressive model for accelerometer data is built and the AR coefficients are extracted as features for activity recognition. Classification of the human activities is performed with support vector machine (SVM). The average recognition results for four activities (running. still. jumping and walking) using the proposed AR-based features are 92.25%. which are better than using traditional frequently used time domains features (mean. standard deviation. energy and correlation of acceleration data) and FFT features. The results show that AR coefficients obvious discriminate different human activities and it can be extract as an effective feature for the recognition of accelerometer date.,True,WMUStEUAAAAJ:UeHWp8X0CEIC,196,https://ieeexplore.ieee.org/abstract/document/4620779/,12625723935093906748,/scholar?cites=12625723935093906748,,,http://www.hcii-lab.net/lianwen/Papers/Conference/%5BICMLC%202008%5D%20Activity%20recognition%20from%20acceleration%20data%20using%20AR%20model%20representation%20and%20SVM.pdf,0,0,0
1278287,Person re-identification by regularized smoothing kiss metric learning,2013,Dapeng Tao and Lianwen Jin and Yongfei Wang and Yuan Yuan and Xuelong Li,23,IEEE Transactions on Circuits and Systems for Video Technology,10,1675-1685,IEEE,With the rapid development of the intelligent video surveillance (IVS). person re-identification. which is a difficult yet unavoidable problem in video surveillance. has received increasing attention in recent years. That is because computer capacity has shown remarkable progress and the task of person re-identification plays a critical role in video surveillance systems. In short. person re-identification aims to find an individual again that has been observed over different cameras. It has been reported that KISS metric learning has obtained the state of the art performance for person re-identification on the VIPeR dataset . However. given a small size training set. the estimation to the inverse of a covariance matrix is not stable and thus the resulting performance can be poor. In this paper. we present regularized smoothing KISS metric learning (RS-KISS) by seamlessly integrating smoothing and regularization techniques …,True,WMUStEUAAAAJ:XiVPGOgt02cC,174,https://ieeexplore.ieee.org/abstract/document/6490028/,11413661253720050902,/scholar?cites=11413661253720050902,,,http://www.dlvc-lab.net/download/papers/journal/Person%20Re-Identification%20by%20Regularized%20Smoothing%20KISS%20Metric%20Learning.pdf,0,0,0
1278288,A novel feature extraction method using pyramid histogram of orientation gradients for smile recognition,2009,Yang Bai and Lihua Guo and Lianwen Jin and Qinghua Huang,,,,3305-3308,IEEE,Recognizing smiles is of much importance for detecting happy moods. Gabor features are conventionally widely applied to facial expression recognition. but the number of Gabor features is usually too large. We proposed to use pyramid histogram of oriented gradients (PHOG) as the features extracted for smile recognition in this paper. The comparisons between the PHOG and Gabor features using a publicly available dataset demonstrated that the PHOG with a significantly shorter vector length could achieve as high a recognition rate as the Gabor features did. Furthermore. the feature selection conducted by an AdaBoost algorithm was not needed when using the PHOG features. To further improve the recognition performance. we combined these two feature extraction methods and achieved the best smile recognition rate. indicating a good value of the PHOG features for smile recognitions.,True,WMUStEUAAAAJ:Y0pCki6q_DkC,147,https://ieeexplore.ieee.org/abstract/document/5413938/,10647564477674837950,/scholar?cites=10647564477674837950,,,http://www.dlvc-lab.net/download/papers/conference/A%20NOVEL%20FEATURE%20EXTRACTION%20METHOD%20USING%20PYRAMID%20HISTOGRAM%20OF%20ORIENTATION%20GRADIENTS%20FOR%20SMILE%20RECOGNITION.pdf,0,0,0
1278289,A new CNN-based method for multi-directional car license plate detection,2018,Lele Xie and Tasweer Ahmad and Lianwen Jin and Yuliang Liu and Sheng Zhang,19,IEEE Transactions on Intelligent Transportation Systems,2,507-517,IEEE,This paper presents a novel convolutional neural network (CNN) -based method for high-accuracy real-time car license plate detection. Many contemporary methods for car license plate detection are reasonably effective under the specific conditions or strong assumptions only. However. they exhibit poor performance when the assessed car license plate images have a degree of rotation. as a result of manual capture by traffic police or deviation of the camera. Therefore. we propose the a CNN-based MD-YOLO framework for multi-directional car license plate detection. Using accurate rotation angle prediction and a fast intersection-over-union evaluation strategy. our proposed method can elegantly manage rotational problems in real-time scenarios. A series of experiments have been carried out to establish that the proposed method outperforms over other existing state-of-the-art methods in terms of better …,True,WMUStEUAAAAJ:3RprE1g1McgC,129,https://ieeexplore.ieee.org/abstract/document/8253610/,6475460673608818879,/scholar?cites=6475460673608818879,,,https://www.researchgate.net/profile/Yuliang_Liu/publication/322372133_A_New_CNN-Based_Method_for_Multi-Directional_Car_License_Plate_Detection/links/5d2c255c92851cf44085017e/A-New-CNN-Based-Method-for-Multi-Directional-Car-License-Plate-Detection.pdf,0,0,0
1278290,Moran: A multi-object rectified attention network for scene text recognition,2019,Canjie Luo and Lianwen Jin and Zenghui Sun,90,Pattern Recognition,,109-118,Pergamon,Irregular text is widely used. However. it is considerably difficult to recognize because of its various shapes and distorted patterns. In this paper. we thus propose a multi-object rectified attention network (MORAN) for general scene text recognition. The MORAN consists of a multi-object rectification network and an attention-based sequence recognition network. The multi-object rectification network is designed for rectifying images that contain irregular text. It decreases the difficulty of recognition and enables the attention-based sequence recognition network to more easily read irregular text. It is trained in a weak supervision way. thus requiring only images and corresponding text labels. The attention-based sequence recognition network focuses on target characters and sequentially outputs the predictions. Moreover. to improve sensitivity of the attention-based sequence recognition network. a fractional pickup …,True,WMUStEUAAAAJ:Qx5QGsQ0O-cC,110,https://www.sciencedirect.com/science/article/pii/S0031320319300263,11461298717784244154,/scholar?cites=11461298717784244154,,,,0,0,0
1278291,Detecting curve text in the wild: New dataset and new solution,2017,Liu Yuliang and Jin Lianwen and Zhang Shuaitao and Zhang Sheng,,arXiv preprint arXiv:1712.02170,,,,Scene text detection has been made great progress in recent years. The detection manners are evolving from axis-aligned rectangle to rotated rectangle and further to quadrangle. However. current datasets contain very little curve text. which can be widely observed in scene images such as signboard. product name and so on. To raise the concerns of reading curve text in the wild. in this paper. we construct a curve text dataset named CTW1500. which includes over 10k text annotations in 1.500 images (1000 for training and 500 for testing). Based on this dataset. we pioneering propose a polygon based curve text detector (CTD) which can directly detect curve text without empirical combination. Moreover. by seamlessly integrating the recurrent transverse and longitudinal offset connection (TLOC). the proposed method can be end-to-end trainable to learn the inherent connection among the position offsets. This allows the CTD to explore context information instead of predicting points independently. resulting in more smooth and accurate detection. We also propose two simple but effective post-processing methods named non-polygon suppress (NPS) and polygonal non-maximum suppression (PNMS) to further improve the detection accuracy. Furthermore. the proposed approach in this paper is designed in an universal manner. which can also be trained with rectangular or quadrilateral bounding boxes without extra efforts. Experimental results on CTW-1500 demonstrate our method with only a light backbone can outperform state-of-the-art methods with a large margin. By evaluating only in the curve or non-curve subset. the CTD+ TLOC can …,True,WMUStEUAAAAJ:C75MlVM-XVcC,109,https://arxiv.org/abs/1712.02170,16169703394000298288,/scholar?cites=16169703394000298288,,,https://arxiv.org/pdf/1712.02170,0,0,0
1278292,Hessian regularized support vector machines for mobile image annotation on the cloud,2013,Dapeng Tao and Lianwen Jin and Weifeng Liu and Xuelong Li,15,IEEE Transactions on Multimedia,4,833-844,IEEE,With the rapid development of the cloud computing and mobile service. users expect a better experience through multimedia computing. such as automatic or semi-automatic personal image and video organization and intelligent user interface. These functions heavily depend on the success of image understanding. and thus large-scale image annotation has received intensive attention in recent years. The collaboration between mobile and cloud opens a new avenue for image annotation. because the heavy computation can be transferred to the cloud for immediately responding user actions. In this paper. we present a scheme for image annotation on the cloud. which transmits mobile images compressed by Hamming compressed sensing to the cloud and conducts semantic annotation through a novel Hessian regularized support vector machine on the cloud. We carefully explained the rationality of Hessian …,True,WMUStEUAAAAJ:mvPsJ3kp5DgC,109,https://ieeexplore.ieee.org/abstract/document/6409462/,10770568905240872999,/scholar?cites=10770568905240872999,,,http://jobdocs.ingridpeter.fastmail.us/files/dave/Hessian%20Regularized%20Support%20Vector%20Machines%20for%20Mobile%20Image%20Annotation%20on%20the%20Cloud.pdf,0,0,0
1278293,A survey on deep learning in medical image analysis,2017,Geert Litjens and Thijs Kooi and Babak Ehteshami Bejnordi and Arnaud Arindra Adiyoso Setio and Francesco Ciompi and Mohsen Ghafoorian and Jeroen Awm Van Der Laak and Bram Van Ginneken and Clara I Sánchez,42,,,60-88,Elsevier,Deep learning algorithms. in particular convolutional networks. have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field. most of which appeared in the last year. We survey the use of deep learning for image classification. object detection. segmentation. registration. and other tasks. Concise overviews are provided of studies per application area: neuro. retinal. pulmonary. digital pathology. breast. cardiac. abdominal. musculoskeletal. We end with a summary of the current state-of-the-art. a critical discussion of open challenges and directions for future research.,True,TxLhvpcAAAAJ:ufrVoPGSRksC,5437,https://www.sciencedirect.com/science/article/pii/S1361841517301135,17186798094825352745,/scholar?cites=17186798094825352745,,,https://arxiv.org/pdf/1702.05747.pdf?source=post_page---------------------------,0,0,0
1278294,Pulmonary nodule detection in CT images: false positive reduction using multi-view convolutional networks,2016,AAA Setio and F Ciompi and G Litjens and P Gerke and C Jacobs and S van Riel and M Winkler Wille and M Naqibullah and C Sanchez and B van Ginneken,,IEEE Transactions on Medical Imaging,,,IEEE,We propose a novel Computer-Aided Detection (CAD) system for pulmonary nodules using multi-view convolutional networks (ConvNets). for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid. subsolid. and large nodules. For each candidate. a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D ConvNets. for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available LIDC-IDRI dataset. our method reaches high detection sensitivities of 85.4% and 90.1% at 1 and 4 false positives per scan. respectively. An additional evaluation on independent datasets from …,True,TxLhvpcAAAAJ:Tyk-4Ss8FVUC,769,https://ieeexplore.ieee.org/abstract/document/7422783/,8158189024082045415,/scholar?cites=8158189024082045415,,,https://geertlitjens.nl/publication/seti-16/seti-16.pdf,0,0,0
1278295,Validation. comparison. and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge,2017,Arnaud Arindra Adiyoso Setio and Alberto Traverso and Thomas De Bel and Moira SN Berens and Cas van den Bogaard and Piergiorgio Cerello and Hao Chen and Qi Dou and Maria Evelina Fantacci and Bram Geurts and Robbert van der Gugten and Pheng Ann Heng and Bart Jansen and Michael MJ De Kaste and Valentin Kotov and Jack Yu-Hung Lin and Jeroen TMC Manders and Alexander Sónora-Mengana and Juan Carlos García-Naranjo and Evgenia Papavasileiou and Mathias Prokop and Marco Saletta and Cornelia M Schaefer-Prokop and Ernst T Scholten and Luuk Scholten and Miranda M Snoeren and Ernesto Lopez Torres and Jef Vandemeulebroucke and Nicole Walasek and Guido CA Zuidhof and Bram van Ginneken and Colin Jacobs,42,Medical image analysis,,1-13,Elsevier,Automatic detection of pulmonary nodules in thoracic computed tomography (CT) scans has been an active area of research for the last two decades. However. there have only been few studies that provide a comparative performance evaluation of different systems on a common database. We have therefore set up the LUNA16 challenge. an objective evaluation framework for automatic nodule detection algorithms using the largest publicly available reference database of chest CT scans. the LIDC-IDRI data set. In LUNA16. participants develop their algorithm and upload their predictions on 888 CT scans in one of the two tracks: 1) the complete nodule detection track where a complete CAD system should be developed. or 2) the false positive reduction track where a provided set of nodule candidates should be classified. This paper describes the setup of LUNA16 and presents the results of the challenge so far …,True,TxLhvpcAAAAJ:eQOLeE2rZwMC,414,https://www.sciencedirect.com/science/article/pii/S1361841517301020,2084538205545992787,/scholar?cites=2084538205545992787,,,https://arxiv.org/pdf/1612.08012.pdf).,0,0,0
1278296,Memory-centric accelerator design for Convolutional Neural Networks,2013,Maurice Peemen and Arnaud Arindra Adiyoso Setio and Bart Mesman and Henk Corporaal,,,,13-19,IEEE,In the near future. cameras will be used everywhere as flexible sensors for numerous applications. For mobility and privacy reasons. the required image processing should be local on embedded computer platforms with performance requirements and energy constraints. Dedicated acceleration of Convolutional Neural Networks (CNN) can achieve these targets with enough flexibility to perform multiple vision tasks. A challenging problem for the design of efficient accelerators is the limited amount of external memory bandwidth. We show that the effects of the memory bottleneck can be reduced by a flexible memory hierarchy that supports the complex data access patterns in CNN workload. The efficiency of the on-chip memories is maximized by our scheduler that uses tiling to optimize for data locality. Our design flow ensures that on-chip memory size is minimized. which reduces area and energy usage. The design …,True,TxLhvpcAAAAJ:u-x6o8ySG0sC,336,https://ieeexplore.ieee.org/abstract/document/6657019/,18388805989005877979,/scholar?cites=18388805989005877979,,,https://pure.tue.nl/ws/files/3997958/580711006684801.pdf,0,0,0
1278297,Off-the-shelf Convolutional Neural Network features for pulmonary nodule detection in computed tomography scans,2015,Bram van Ginneken and Arnaud Arindra Adiyoso Setio and Colin Jacobs and Francesco Ciompi,,IEEE International Symposium on Biomedical Imaging,,,,Convolutional neural networks (CNNs) have emerged as the most powerful technique for a range of different tasks in computer vision. Recent work suggested that CNN features are generic and can be used for classification tasks outside the exact domain for which the networks were trained. In this work we use the features from one such network. OverFeat. trained for object detection in natural images. for nodule detection in computed tomography scans. We use 865 scans from the publicly available LIDC data set. read by four thoracic radiologists. Nodule candidates are generated by a state-of-the-art nodule detection system. We extract 2D sagittal. coronal and axial patches for each nodule candidate and extract 4096 features from the penultimate layer of OverFeat and classify these with linear support vector machines. We show for various configurations that the off-the-shelf CNN features perform surprisingly well …,True,TxLhvpcAAAAJ:UeHWp8X0CEIC,261,https://ieeexplore.ieee.org/abstract/document/7163869/,3459188085599203383,/scholar?cites=3459188085599203383,,,,0,0,0
1278298,Towards automatic pulmonary nodule management in lung cancer screening with deep learning,2017,Francesco Ciompi and Kaman Chung and Sarah J Van Riel and Arnaud Arindra Adiyoso Setio and Paul K Gerke and Colin Jacobs and Ernst Th Scholten and Cornelia Schaefer-Prokop and Mathilde MW Wille and Alfonso Marchiano and Ugo Pastorino and Mathias Prokop and Bram Van Ginneken,7,Scientific reports,1,1-11,Nature Publishing Group,The introduction of lung cancer screening programs will produce an unprecedented amount of chest CT scans in the near future. which radiologists will have to read in order to decide on a patient follow-up strategy. According to the current guidelines. the workup of screen-detected nodules strongly relies on nodule size and nodule type. In this paper. we present a deep learning system based on multi-stream multi-scale convolutional networks. which automatically classifies all nodule types relevant for nodule workup. The system processes raw CT data containing a nodule without the need for any additional information such as nodule segmentation or nodule size and learns a representation of 3D data by analyzing an arbitrary number of 2D views of a given nodule. The deep learning system was trained with data from the Italian MILD screening trial and validated on an independent set of data from the Danish …,True,TxLhvpcAAAAJ:W7OEmFMy1HYC,223,https://www.nature.com/articles/srep46479,8567006734401252147,/scholar?cites=8567006734401252147,,,https://www.nature.com/articles/srep46479,0,0,0
1278299,Using deep learning to segment breast and fibroglandular tissue in MRI volumes,2017,Mehmet Ufuk Dalmış and Geert Litjens and Katharina Holland and Arnaud Setio and Ritse Mann and Nico Karssemeijer and Albert Gubern‐Mérida,44,Medical physics,2,533-546,,"Automated segmentation of breast and fibroglandular tissue (FGT) is required for various computer‐aided applications of breast MRI. Traditional image analysis and computer vision techniques. such atlas. template matching. or. edge and surface detection. have been applied to solve this task. However. applicability of these methods is usually limited by the characteristics of the images used in the study datasets. while breast MRI varies with respect to the different MRI protocols used. in addition to the variability in breast shapes. All this variability. in addition to various MRI artifacts. makes it a challenging task to develop a robust breast and FGT segmentation method using traditional approaches. Therefore. in this study. we investigated the use of a deep‐learning approach known as ""U‐net.""We used a dataset of 66 breast MRI's randomly selected from our scientific archive. which …",True,TxLhvpcAAAAJ:WF5omc3nYNoC,127,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12079,9993343296257816404,/scholar?cites=9993343296257816404,,,https://www.researchgate.net/profile/Geert_Litjens/publication/311991068_Using_Deep_Learning_to_Segment_Breast_and_Fibroglanduar_Tissue_in_MRI_Volumes/links/5ad85164a6fdcc293584c986/Using-Deep-Learning-to-Segment-Breast-and-Fibroglanduar-Tissue-in-MRI-Volumes.pdf,0,0,0
1278300,Automatic detection of large pulmonary solid nodules in thoracic CT images,2015,Arnaud AA Setio and Colin Jacobs and Jaap Gelderblom and Bram van Ginneken,42,Medical physics,10,5642-5653,American Association of Physicists in Medicine,Current computer‐aided detection (CAD) systems for pulmonary nodules in computed tomography (CT) scans have a good performance for relatively small nodules. but often fail to detect the much rarer larger nodules. which are more likely to be cancerous. We present a novel CAD system specifically designed to detect solid nodules larger than 10 mm.The proposed detection pipeline is initiated by a three‐dimensional lung segmentation algorithm optimized to include large nodules attached to the pleural wall via morphological processing. An additional preprocessing is used to mask out structures outside the pleural space to ensure that pleural and parenchymal nodules have a similar appearance. Next. nodule candidates are obtained via a multistage process of thresholding and morphological operations. to detect both larger and smaller candidates. After segmenting each candidate. a set …,True,TxLhvpcAAAAJ:IjCSPb-OGe4C,103,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.4929562,14121163271329355688,/scholar?cites=14121163271329355688,,,,0,0,0
1278301,Improving airway segmentation in computed tomography using leak detection with convolutional networks,2017,Jean-Paul Charbonnier and Eva M Van Rikxoort and Arnaud AA Setio and Cornelia M Schaefer-Prokop and Bram van Ginneken and Francesco Ciompi,36,Medical image analysis,,52-60,Elsevier,We propose a novel method to improve airway segmentation in thoracic computed tomography (CT) by detecting and removing leaks. Leak detection is formulated as a classification problem. in which a convolutional network (ConvNet) is trained in a supervised fashion to perform the classification task. In order to increase the segmented airway tree length. we take advantage of the fact that multiple segmentations can be extracted from a given airway segmentation algorithm by varying the parameters that influence the tree length and the amount of leaks. We propose a strategy in which the combination of these segmentations after removing leaks can increase the airway tree length while limiting the amount of leaks. This strategy therefore largely circumvents the need for parameter fine-tuning of a given airway segmentation algorithm.The ConvNet was trained and evaluated using a subset of inspiratory thoracic CT …,True,TxLhvpcAAAAJ:YsMSGLbcyi4C,71,https://www.sciencedirect.com/science/article/pii/S136184151630202X,10119306392018768738,/scholar?cites=10119306392018768738,,,https://drive.google.com/file/d/1yXfI7RDPlL61LuxieDhY3Bp4XiSwrKb8/view,0,0,0
1278302,Deep convolutional neural networks for automatic coronary calcium scoring in a screening study with low-dose chest CT,2016,N Lessmann and I Isgum and AAA Setio and BD de Vos and F Ciompi and PA de Jong and M Oudkerk and WP Th M Mali and MA Viergever and B van Ginneken,,SPIE Medical Imaging,,,,The amount of calcifications in the coronary arteries is a powerful and independent predictor of cardiovascular events and is used to identify subjects at high risk who might benefit from preventive treatment. Routine quantification of coronary calcium scores can complement screening programs using low-dose chest CT. such as lung cancer screening. We present a system for automatic coronary calcium scoring based on deep convolutional neural networks (CNNs). The system uses three independently trained CNNs to estimate a bounding box around the heart. In this region of interest. connected components above 130 HU are considered candidates for coronary artery calcifications. To separate them from other high intensity lesions. classification of all extracted voxels is performed by feeding two-dimensional 50 mm × 50 mm patches from three orthogonal planes into three concurrent CNNs. The networks consist …,True,TxLhvpcAAAAJ:zYLM7Y9cAGgC,31,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9785/978511/Deep-convolutional-neural-networks-for-automatic-coronary-calcium-scoring-in/10.1117/12.2216978.short,11932712040638875797,/scholar?cites=11932712040638875797,,,,0,0,0
1278303,Efficient organ localization using multi-label convolutional neural networks in thorax-abdomen CT scans,2018,Gabriel Efrain Humpire-Mamani and Arnaud Arindra Adiyoso Setio and Bram van Ginneken and Colin Jacobs,63,Physics in Medicine & Biology,8,085003,IOP Publishing,Automatic localization of organs and other structures in medical images is an important preprocessing step that can improve and speed up other algorithms such as organ segmentation. lesion detection. and registration. This work presents an efficient method for simultaneous localization of multiple structures in 3D thorax-abdomen CT scans.,True,TxLhvpcAAAAJ:hqOjcs7Dif8C,17,https://iopscience.iop.org/article/10.1088/1361-6560/aab4b3/meta,16888189080982033735,/scholar?cites=16888189080982033735,,,,0,0,0
1278304,Activity recognition and abnormality detection with the switching hidden semi-markov model,2005,Thi V Duong and Hung Hai Bui and Dinh Q Phung and Svetha Venkatesh,1,,,838-845,IEEE,This paper addresses the problem of learning and recognizing human activities of daily living (ADL). which is an important research issue in building a pervasive and smart environment. In dealing with ADL. we argue that it is beneficial to exploit both the inherent hierarchical organization of the activities and their typical duration. To this end. we introduce the switching hidden semi-markov model (S-HSMM). a two-layered extension of the hidden semi-Markov model (HSMM) for the modeling task. Activities are modeled in the S-HSMM in two ways: the bottom layer represents atomic activities and their duration using HSMMs; the top layer represents a sequence of high-level activities where each high-level activity is made of a sequence of atomic activities. We consider two methods for modeling duration: the classic explicit duration model using multinomial distribution. and the novel use of the discrete Coxian …,True,OtA9SwIAAAAJ:u5HHmVD_uO8C,703,https://ieeexplore.ieee.org/abstract/document/1467354/,8953661248773357609,/scholar?cites=8953661248773357609,,,https://espace.curtin.edu.au/bitstream/handle/20.500.11937/10349/116823_Activity%20recognition%20PID%20116823.pdf?sequence=2,0,0,0
1278305,Labeled random finite sets and the Bayes multi-target tracking filter,2014,Ba-Ngu Vo and Ba-Tuong Vo and Dinh Phung,,IEEE Transaction on Signal Processing,,,,An analytic solution to the multi-target Bayes recursion known as the δ-Generalized Labeled Multi-Bernoulli ( δ-GLMB) filter has been recently proposed by Vo and Vo in [“Labeled Random Finite Sets and Multi-Object Conjugate Priors.” IEEE Trans. Signal Process.. vol. 61. no. 13. pp. 3460-3475. 2014]. As a sequel to that paper. the present paper details efficient implementations of the δ-GLMB multi-target tracking filter. Each iteration of this filter involves an update operation and a prediction operation. both of which result in weighted sums of multi-target exponentials with intractably large number of terms. To truncate these sums. the ranked assignment and K-th shortest path algorithms are used in the update and prediction. respectively. to determine the most significant terms without exhaustively computing all of the terms. In addition. using tools derived from the same framework. such as probability hypothesis …,True,OtA9SwIAAAAJ:GO2DTSf4MZMC,527,https://ieeexplore.ieee.org/abstract/document/6928494/,4798077724436124236,/scholar?cites=4798077724436124236,,,https://arxiv.org/pdf/1312.2372,0,0,0
1278306,Learning and detecting activities from movement trajectories using the hierarchical hidden Markov model,2005,N. Nguyen and Dinh Q Phung and Svetha Venkatesh and Hung Bui,2,,,955-960,IEEE,Directly modeling the inherent hierarchy and shared structures of human behaviors. we present an application of the hierarchical hidden Markov model (HHMM) for the problem of activity recognition. We argue that to robustly model and recognize complex human activities. it is crucial to exploit both the natural hierarchical decomposition and shared semantics embedded in the movement trajectories. To this end. we propose the use of the HHMM. a rich stochastic model that has been recently extended to handle shared structures. for representing and recognizing a set of complex indoor activities. Furthermore. in the need of real-time recognition. we propose a Rao-Blackwellised particle filter (RBPF) that efficiently computes the filtering distribution at a constant time complexity for each new observation arrival. The main contributions of this paper lie in the application of the shared-structure HHMM. the estimation of …,True,OtA9SwIAAAAJ:u-x6o8ySG0sC,451,https://ieeexplore.ieee.org/abstract/document/1467545/,4468408870888640438,/scholar?cites=4468408870888640438,,,https://espace.curtin.edu.au/bitstream/handle/20.500.11937/15305/116822_Learning%20and%20detecting%20activities%20PID%20116822.pdf?sequence=2,0,0,0
1278307,Guidelines for developing and reporting machine learning predictive models in biomedical research: a multidisciplinary view,2016,Wei Luo and Dinh Phung and Truyen Tran and Sunil Gupta and Santu Rana and Chandan Karmakar and Alistair Shilton and John Yearwood and Nevenka Dimitrova and Tu Bao Ho and Svetha Venkatesh and Michael Berk,18,Journal of medical Internet research,12,e323,JMIR Publications Inc.. Toronto. Canada,As more and more researchers are turning to big data for new opportunities of biomedical discoveries. machine learning models. as the backbone of big data analysis. are mentioned more often in biomedical journals. However. owing to the inherent complexity of machine learning methods. they are prone to misuse. Because of the flexibility in specifying machine learning models. the results are often insufficiently reported in research articles. hindering reliable assessment of model validity and consistent interpretation of model outputs.To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence.A multidisciplinary panel of machine learning experts. clinicians. and traditional statisticians were interviewed. using an iterative process in accordance with the Delphi method.The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models.A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis. particularly with machine learning methods. in the biomedical research community.,True,OtA9SwIAAAAJ:W91e3rS6dHEC,239,https://www.jmir.org/2016/12/e323/,7020580512974096533,/scholar?cites=7020580512974096533,,,https://www.jmir.org/2016/12/e323/,0,0,0
1278308,A novel embedding model for knowledge base completion based on convolutional neural network,2017,Dai Quoc Nguyen and Tu Dinh Nguyen and Dat Quoc Nguyen and Dinh Phung,,arXiv preprint arXiv:1712.02121,,,,In this paper. we propose a novel embedding model. named ConvKB. for knowledge base completion. Our model ConvKB advances state-of-the-art models by employing a convolutional neural network. so that it can capture global relationships and transitional characteristics between entities and relations in knowledge bases. In ConvKB. each triple (head entity. relation. tail entity) is represented as a 3-column matrix where each column vector represents a triple element. This 3-column matrix is then fed to a convolution layer where multiple filters are operated on the matrix to generate different feature maps. These feature maps are then concatenated into a single feature vector representing the input triple. The feature vector is multiplied with a weight vector via a dot product to return a score. This score is then used to predict whether the triple is valid or not. Experiments show that ConvKB achieves better link prediction performance than previous state-of-the-art embedding models on two benchmark datasets WN18RR and FB15k-237.,True,OtA9SwIAAAAJ:BulkYocH2doC,229,https://arxiv.org/abs/1712.02121,5515928500707541108,/scholar?cites=5515928500707541108,,,https://arxiv.org/pdf/1712.02121,0,0,0
1278309,Deepcare: A deep dynamic memory model for predictive medicine,2016,Trang Pham and Truyen Tran and Dinh Phung and Svetha Venkatesh,,,,30-41,Springer. Cham,Personalized predictive medicine necessitates modeling of patient illness and care processes. which inherently have long-term temporal dependencies. Healthcare observations. recorded in electronic medical records. are episodic and irregular in time. We introduce DeepCare. a deep dynamic neural network that reads medical records and predicts future medical outcomes. At the data level. DeepCare models patient health state trajectories with explicit memory of illness. Built on Long Short-Term Memory (LSTM). DeepCare introduces time parameterizations to handle irregular timing by moderating the forgetting and consolidation of illness memory. DeepCare also incorporates medical interventions that change the course of illness and shape future medical risk. Moving up to the health state level. historical and present health states are then aggregated through multiscale temporal pooling. before …,True,OtA9SwIAAAAJ:cAUKuAERoUMC,219,https://link.springer.com/chapter/10.1007/978-3-319-31750-2_3,7556765048088716476,/scholar?cites=7556765048088716476,,,https://arxiv.org/pdf/1602.00357,0,0,0
1278310,Predicting healthcare trajectories from medical records: A deep learning approach,2017,Trang Pham and Truyen Tran and Dinh Phung and Svetha Venkatesh,69,Journal of biomedical informatics,,218-229,Academic Press,Personalized predictive medicine necessitates the modeling of patient illness and care processes. which inherently have long-term temporal dependencies. Healthcare observations. stored in electronic medical records are episodic and irregular in time. We introduce DeepCare. an end-to-end deep dynamic neural network that reads medical records. stores previous illness history. infers current illness states and predicts future medical outcomes. At the data level. DeepCare represents care episodes as vectors and models patient health state trajectories by the memory of historical records. Built on Long Short-Term Memory (LSTM). DeepCare introduces methods to handle irregularly timed events by moderating the forgetting and consolidation of memory. DeepCare also explicitly models medical interventions that change the course of illness and shape future medical risk. Moving up to the health state level …,True,OtA9SwIAAAAJ:ae0xyBWlIcIC,216,https://www.sciencedirect.com/science/article/pii/S1532046417300710,3180052582482977332,/scholar?cites=3180052582482977332,,,https://www.sciencedirect.com/science/article/pii/S1532046417300710,0,0,0
1278311,Dual discriminator generative adversarial nets,2017,Tu Dinh Nguyen and Trung Le and Hung Vu and Dinh Phung,,arXiv preprint arXiv:1709.03831,,,,We propose in this paper a novel approach to tackle the problem of mode collapse encountered in generative adversarial network (GAN). Our idea is intuitive but proven to be very effective. especially in addressing some key limitations of GAN. In essence. it combines the Kullback-Leibler (KL) and reverse KL divergences into a unified objective function. thus it exploits the complementary statistical properties from these divergences to effectively diversify the estimated density in capturing multi-modes. We term our method dual discriminator generative adversarial nets (D2GAN) which. unlike GAN. has two discriminators; and together with a generator. it also has the analogy of a minimax game. wherein a discriminator rewards high scores for samples from data distribution whilst another discriminator. conversely. favoring data from the generator. and the generator produces data to fool both two discriminators. We develop theoretical analysis to show that. given the maximal discriminators. optimizing the generator of D2GAN reduces to minimizing both KL and reverse KL divergences between data distribution and the distribution induced from the data generated by the generator. hence effectively avoiding the mode collapsing problem. We conduct extensive experiments on synthetic and real-world large-scale datasets (MNIST. CIFAR-10. STL-10. ImageNet). where we have made our best effort to compare our D2GAN with the latest state-of-the-art GAN's variants in comprehensive qualitative and quantitative evaluations. The experimental results demonstrate the competitive and superior performance of our approach in generating good quality and …,True,OtA9SwIAAAAJ:wyoMR1qFDH8C,179,https://arxiv.org/abs/1709.03831,5998408572298019483,/scholar?cites=5998408572298019483,,,https://arxiv.org/pdf/1709.03831,0,0,0
1278312,MGAN: Training generative adversarial nets with multiple generators,2018,Quan Hoang and Tu Dinh Nguyen and Trung Le and Dinh Phung,,International Conference on Learning Representation (ICLR),,,,We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators. instead of using a single one as in the original GAN. The idea is simple. yet proven to be extremely effective at covering diverse data modes. easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classifier. a discriminator. and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data. whilst the discriminator determines whether samples are true data or generated by generators. and the classifier specifies which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators. and then one of them will be randomly selected as final output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that. at the equilibrium. the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal. whilst the JSD among generators’ distributions is maximal. hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing. our proposed model adds minimal computational cost to the standard GAN. and thus can also efficiently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural …,True,OtA9SwIAAAAJ:BHd7YmozNHgC,166,https://openreview.net/forum?id=rkmu5b0a-,15083973924521420990,/scholar?cites=15083973924521420990,,,https://openreview.net/pdf?id=rkmu5b0a-,0,0,0
1278313,Affective and Content Analysis of Online Depression Communities,2014,T Nguyen and Dinh Phung and Bo Dao and S Venkatesh and M Berk,,IEEE Transaction on Affective Computing,,1-1,IEEE,A large number of people use online communities to discuss mental health issues. thus offering opportunities for new understanding of these communities. This paper aims to study the characteristics of online depression communities (CLINICAL) in comparison with those joining other online communities (CONTROL). We use machine learning and statistical methods to discriminate online messages between depression and control communities using mood. psycholinguistic processes and content topics extracted from the posts generated by members of these communities. All aspects including mood. the written content and writing style are found to be significantly different between two types of communities. Sentiment analysis shows the clinical group have lower valence than people in the control group. For language styles and topics. statistical tests reject the hypothesis of equality on psycholinguistic processes …,True,OtA9SwIAAAAJ:polMJLZb0X8C,153,https://ieeexplore.ieee.org/abstract/document/6784326/,4216686776234041800,/scholar?cites=4216686776234041800,,,,0,0,0
1278314,Efficient duration and hierarchical modeling for human activity recognition,2009,Thi Duong and Dinh Phung and Hung Bui and Svetha Venkatesh,173,Artificial Intelligence,7-8,830-856,Elsevier,A challenge in building pervasive and smart spaces is to learn and recognize human activities of daily living (ADLs). In this paper. we address this problem and argue that in dealing with ADLs. it is beneficial to exploit both their typical duration patterns and inherent hierarchical structures. We exploit efficient duration modeling using the novel Coxian distribution to form the Coxian hidden semi-Markov model (CxHSMM) and apply it to the problem of learning and recognizing ADLs with complex temporal dependencies. The Coxian duration model has several advantages over existing duration parameterization using multinomial or exponential family distributions. including its denseness in the space of nonnegative distributions. low number of parameters. computational efficiency and the existence of closed-form estimation solutions. Further we combine both hierarchical and duration extensions of the hidden Markov …,True,OtA9SwIAAAAJ:zYLM7Y9cAGgC,134,https://www.sciencedirect.com/science/article/pii/S0004370208002142,18349209609917921546,/scholar?cites=18349209609917921546,,,https://www.sciencedirect.com/science/article/pii/S0004370208002142/pdf?md5=0e414f03715fe2e0ebd39a826cf2fa1f&pid=1-s2.0-S0004370208002142-main.pdf,0,0,0
1278315,Ultra-wideband for multiple access communications,2005,Robert C Qiu and Huaping Liu and Xuemin Shen,43,,2,80-87,IEEE,Ultra-wideband wireless communications techniques have many merits. including an extremely simple radio that inherently leads to low-cost design. large processing gain for robust operations in the presence of narrowband interference. covert operations. and fine time resolution for accurate position sensing. However. there are a number of challenges in UWB receiver design. such as capturing multipath energy. intersymbol interference especially in a non-line-of-sight environment. and the need for high-sampling-rate analog-to-digital converters. In this article. we provide a comprehensive review of UWB multiple access and modulation schemes. and their comparison with narrowband radios. We also outline the issues with UWB signal reception and detection. and explore various suboptimal low-complexity receiving schemes,True,FTLNXX8AAAAJ:u5HHmVD_uO8C,374,https://ieeexplore.ieee.org/abstract/document/1391505/,12878210730623183008,/scholar?cites=12878210730623183008,,,http://bbcr.uwaterloo.ca/~xshen/paper/2005/uwfmac.pdf,0,0,0
1278316,60-GHz millimeter-wave radio: Principle. technology. and new results,2006,Nan Guo and Robert C Qiu and Shaomin S Mo and Kazuaki Takahashi,2007,EURASIP journal on Wireless Communications and Networking,,1-8,Springer International Publishing,The worldwide opening of a massive amount of unlicensed spectra around 60 GHz has triggered great interest in developing affordable 60-GHz radios. This interest has been catalyzed by recent advance of 60-GHz front-end technologies. This paper briefly reports recent work in the 60-GHz radio. Aspects addressed in this paper include global regulatory and standardization. justification of using the 60-GHz bands. 60-GHz consumer electronics applications. radio system concept. 60-GHz propagation and antennas. and key issues in system design. Some new simulation results are also given. Potentials and problems are explained in detail.,True,FTLNXX8AAAAJ:9yKSN-GCB0IC,338,https://link.springer.com/content/pdf/10.1155/2007/68253.pdf,16473658680363150922,/scholar?cites=16473658680363150922,,,https://link.springer.com/content/pdf/10.1155/2007/68253.pdf,0,0,0
1278317,Time reversal with MISO for ultrawideband communications: Experimental results,2006,Robert C Qiu and Chenming Zhou and Nan Guo and John Q Zhang,5,IEEE Antennas and Wireless Propagation Letters,,269-273,IEEE,Time reversal (TR) communications marks a paradigm shift in ultrawideband (UWB) communications. The system complexity can be shifted from the receiver to the transmitter. which is ideal to some applications. UWB multiple input-single output (MISO) is enabled by the use of the TR scheme. Two basic problems are investigated experimentally using short UWB radio pulses (nanosecond duration). Temporal focusing and increase in collected-energy with the number of antennas are verified. Also. the reciprocity of realistic channels. the cornerstone of TR. is demonstrated perhaps for the first time in electromagnetics,True,FTLNXX8AAAAJ:d1gkVwhDpl0C,275,https://ieeexplore.ieee.org/abstract/document/1645104/,14834114073236819529,/scholar?cites=14834114073236819529,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.718.8793&rep=rep1&type=pdf,0,0,0
1278318,Multiuser detection for DS-CDMA UWB in the home environment,2002,Qinghua Li and Leslie A Rusch,20,IEEE journal on Selected areas in Communications,9,1701-1711,IEEE,We demonstrate the effectiveness of multiuser detection for an ultra-wideband (UWB) pulse based direct sequence spread spectrum system using code division multiple access. Extensive simulations were run using channel soundings of the 2-8 GHz band collected in a residential setting and characterized by a high level of multipath fragmentation. We show that the adaptive minimum mean square error (MMSE) multiuser detection (MUD) receivers are able to gather multipath energy and reject intersymbol and interchip interference for these channels to a much greater extent than RAKE receivers with 4 and 8 arms. We also demonstrate the adaptive MMSE is able to reject a narrowband IEEE 802.11a OFDM interferer. even for signal-to-interference ratio as severe as -30 dB. We show the adaptive MMSE exhibits only a 6 dB penalty relative to the single user case for the heavy multi-access interference (number of …,True,FTLNXX8AAAAJ:wKETBy42zhYC,267,https://ieeexplore.ieee.org/abstract/document/1097836/,7676498941235374331,/scholar?cites=7676498941235374331,,,https://www.researchgate.net/profile/Qinghua_Li5/publication/3234892_Multiuser_detection_for_DS-CDMA_UWB_in_the_home_environment/links/00463524f49ff9db3c000000/Multiuser-detection-for-DS-CDMA-UWB-in-the-home-environment.pdf,0,0,0
1278319,A study of the ultra-wideband wireless propagation channel and optimum UWB receiver design,2002,Robert C Qiu,20,IEEE Journal on Selected Areas in Communications,9,1628-1637,IEEE,The paper addresses a crucial point in ultra-wideband (UWB) radio wave propagation. which is the spatial-temporal resolution of scattering objects into multiple frequency-dependent scattering centers. The effect contributes to the widely observed temporal dispersion of pulse-shaped transmit signals and their distortion. respectively. Particularly the latter is explained by (multiple) diffraction of the incident wave. leading to (multiple) band-limited impulse responses with characteristic frequency content. which in turn causes signal distortion and a degradation of the signal-to-noise ratio in a correlation receiver. We presented a new approach on UWB propagation modeling and optimum design of correlation receivers.,True,FTLNXX8AAAAJ:u-x6o8ySG0sC,252,https://ieeexplore.ieee.org/abstract/document/1097828/,15747554657110260406,/scholar?cites=15747554657110260406,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.719.272&rep=rep1&type=pdf,0,0,0
1278320,A big data architecture design for smart grids based on random matrix theory,2015,Xing He and Qian Ai and Robert Caiming Qiu and Wentao Huang and Longjian Piao and Haichun Liu,8,IEEE transactions on smart Grid,2,674-686,IEEE,Model-based analysis tools. built on assumptions and simplifications. are difficult to handle smart grids with data characterized by volume. velocity. variety. and veracity (i.e.. 4Vs data). This paper. using random matrix theory (RMT). motivates data-driven tools to perceive the complex grids in high-dimension; meanwhile. an architecture with detailed procedures is proposed. In algorithm perspective. the architecture performs a high-dimensional analysis and compares the findings with RMT predictions to conduct anomaly detections. Mean spectral radius (MSR). as a statistical indicator. is defined to reflect the correlations of system data in different dimensions. In management mode perspective. a group-work mode is discussed for smart grids operation. This mode breaks through regional limitations for energy flows and data flows. and makes advanced big data analyses possible. For a specific large-scale zone …,True,FTLNXX8AAAAJ:NXb4pA-qfm4C,217,https://ieeexplore.ieee.org/abstract/document/7154500/,6513515053572506601,/scholar?cites=6513515053572506601,,,https://arxiv.org/pdf/1501.07329,0,0,0
1278321,Cognitive radio network for the smart grid: Experimental system architecture. control algorithms. security. and microgrid testbed,2011,Robert Caiming Qiu and Zhen Hu and Zhe Chen and Nan Guo and Raghuram Ranganathan and Shujie Hou and Gang Zheng,2,IEEE Transactions on Smart Grid,4,724-740,IEEE,This paper systematically investigates the novel idea of applying the next generation wireless technology. cognitive radio network. for the smart grid. In particular. system architecture. algorithms. and hardware testbed are studied. A microgrid testbed supporting both power flow and information flow is also proposed. Control strategies and security considerations are discussed. Furthermore. the concept of independent component analysis (ICA) in combination with the robust principal component analysis (PCA) technique is employed to recover data from the simultaneous smart meter wireless transmissions in the presence of strong wideband interference. The performance illustrates the gain of bringing the state of the art mathematics to smart grid.,True,FTLNXX8AAAAJ:bEWYMUwI8FkC,193,https://ieeexplore.ieee.org/abstract/document/5971793/,16387576634219203359,/scholar?cites=16387576634219203359,,,https://www.researchgate.net/profile/Terry_Guo/publication/224251164_Cognitive_Radio_Network_for_the_Smart_Grid_Experimental_System_Architecture_Control_Algorithms_Security_and_Microgrid_Testbed/links/00b4951ed74b744e29000000/Cognitive-Radio-Network-for-the-Smart-Grid-Experimental-System-Architecture-Control-Algorithms-Security-and-Microgrid-Testbed.pdf,0,0,0
1278322,Ultra-wideband wireless communications and networks,2006,Xuemin Shen and Mohsen Guizani and Robert Caiming Qiu and Tho Le-Ngoc,,,,37-53,Wiley,Designations used by companies to distinguish their products are often claimed as trademarks. All brand names and product names used in this book are trade names. service marks. trademarks or registered trademarks of their respective owners. The Publisher is not associated with any product or vendor mentioned in this book.,True,FTLNXX8AAAAJ:UeHWp8X0CEIC,176,https://onlinelibrary.wiley.com/doi/pdf/10.1002/0470028521,13248853852648260884,/scholar?cites=13248853852648260884,,,https://www.academia.edu/download/52089043/UWB_interference_to_narrowband_receivers20170309-5591-86nmx9.pdf,0,0,0
1278323,Big data analytics in mobile cellular networks,2016,Ying He and Fei Richard Yu and Nan Zhao and Hongxi Yin and Haipeng Yao and Robert C Qiu,4,IEEE access,,1985-1996,IEEE,Mobile cellular networks have become both the generators and carriers of massive data. Big data analytics can improve the performance of mobile cellular networks and maximize the revenue of operators. In this paper. we introduce a unified data model based on the random matrix theory and machine learning. Then. we present an architectural framework for applying the big data analytics in the mobile cellular networks. Moreover. we describe several illustrative examples. including big signaling data. big traffic data. big location data. big radio waveforms data. and big heterogeneous data. in mobile cellular networks. Finally. we discuss a number of open research challenges of the big data analytics in the mobile cellular networks.,True,FTLNXX8AAAAJ:4hFrxpcac9AC,169,https://ieeexplore.ieee.org/abstract/document/7429688/,11449250542522678319,/scholar?cites=11449250542522678319,,,https://ieeexplore.ieee.org/iel7/6287639/6514899/07429688.pdf,0,0,0
1278324,Compressed meter reading for delay-sensitive and secure load report in smart grid,2010,Husheng Li and Rukun Mao and Lifeng Lai and Robert C Qiu,,,,114-119,IEEE,It is a key task in smart grid to send the readings of smart meters to an access point (AP) in a wireless manner. The requirements of scalability. realtimeness and security make the wireless meter reading highly challenging. On assuming that the number of smart meters is large and the data burst is sparse. i.e.. only a small fraction of the smart meters are reporting their power loads at the same time. the technique of compressed sensing is applied for the wireless meter reading. The distinguishing feature of the compressed meter reading is that the active smart meters are allowed to transmit simultaneously and the AP is able to distinguish the reports from different smart meters. The simultaneous access results in uniform delays. in contrast to the possible large delay in carrier sensing multiple access (CSMA) technique. The random sequence used in the compressed sensing enhances the privacy and integrity of the …,True,FTLNXX8AAAAJ:-f6ydRqryjwC,136,https://ieeexplore.ieee.org/abstract/document/5622027/,10946974646194243480,/scholar?cites=10946974646194243480,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.5107&rep=rep1&type=pdf,0,0,0
1278325,Reduced-complexity UWB time-reversal techniques and experimental results,2007,Nan Guo and Brian M Sadler and Robert C Qiu,6,IEEE Transactions on Wireless Communications,12,4221-4226,IEEE,This paper presents a reduced-complexity time reversal technique for ultra-wideband (UWB) communications. Time reversal takes advantage of rich scattering environments to achieve signal focusing via transmitter-side processing. which enables the use of simple receivers. The goal of this paper is to demonstrate a UWB time reversal system architecture based on experimental results and practical pulse waveform. taking into account some practical constraints. and to show feasibility of UWB time reversal. Pre-decorrelating in addition to time reversal processing is considered for a downlink multiuser configuration. Multiple transmit antennas are employed to improve the performance.,True,FTLNXX8AAAAJ:ufrVoPGSRksC,123,https://ieeexplore.ieee.org/abstract/document/4400786/,2004877675155238329,/scholar?cites=2004877675155238329,,,https://www.researchgate.net/profile/Terry_Guo/publication/3434292_Reduced-complexity_UWB_time-reversal_techniques_and_experimental_results/links/0046351eee34a2eb38000000.pdf,0,0,0
1278326,Dappled photography: Mask enhanced cameras for heterodyned light fields and coded aperture refocusing,2007,Ashok Veeraraghavan and Ramesh Raskar and Amit Agrawal and Ankit Mohan and Jack Tumblin,26,ACM Trans. Graph.,3,69,,We describe a theoretical framework for reversibly modulating 4D light fields using an attenuating mask in the optical path of a lens based camera. Based on this framework. we present a novel design to reconstruct the 4D light field from a 2D camera image without any additional refractive elements as required by previous light field cameras. The patterned mask attenuates light rays inside the camera instead of bending them. and the attenuation recoverably encodes the rays on the 2D sensor. Our mask-equipped camera focuses just as a traditional camera to capture conventional 2D photos at full sensor resolution. but the raw pixel values also hold a modulated 4D light field. The light field can be recovered by rearranging the tiles of the 2D Fourier transform of sensor values into 4D planes and computing the inverse Fourier transform. In addition. one can also recover the full resolution image information for the in-focus parts of the scene.,True,Q3puGtcAAAAJ:u-x6o8ySG0sC,767,https://www-ece.rice.edu/~av21/Documents/pre2011/Dappled%20Photography.pdf,13054374154452049848,/scholar?cites=13054374154452049848,,,https://www-ece.rice.edu/~av21/Documents/pre2011/Dappled%20Photography.pdf,0,0,0
1278327,Coded exposure photography: motion deblurring using fluttered shutter,2006,Ramesh Raskar and Amit Agrawal and Jack Tumblin,25,,3,795-804,ACM,"In a conventional single-exposure photograph. moving objects or moving cameras cause motion blur. The exposure time defines a temporal box filter that smears the moving object across the image by convolution. This box filter destroys important high-frequency spatial details so that deblurring via deconvolution becomes an ill-posed problem. Rather than leaving the shutter open for the entire exposure duration. we"" flutter"" the camera's shutter open and closed during the chosen exposure time with a binary pseudo-random sequence. The flutter changes the box filter to a broad-band filter that preserves high-frequency spatial details in the blurred image and the corresponding deconvolution becomes a well-posed problem. We demonstrate that manually-specified point spread functions are sufficient for several challenging cases of motion-blur removal including extremely large motions. textured backgrounds and …",True,Q3puGtcAAAAJ:u5HHmVD_uO8C,706,https://dl.acm.org/doi/abs/10.1145/1179352.1141957,9618925463414393307,/scholar?cites=9618925463414393307,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.415.6863&rep=rep1&type=pdf,0,0,0
1278328,Context encoding for semantic segmentation,2018,Hang Zhang and Kristin Dana and Jianping Shi and Zhongyue Zhang and Xiaogang Wang and Ambrish Tyagi and Amit Agrawal,,,,7151-7160,,Recent work has made significant progress in improving spatial resolution for pixelwise labeling with Fully Convolutional Network (FCN) framework by employing Dilated/Atrous convolution. utilizing multi-scale features and refining boundaries. In this paper. we explore the impact of global contextual information in semantic segmentation by introducing the Context Encoding Module. which captures the semantic context of scenes and selectively highlights class-dependent featuremaps. The proposed Context Encoding Module significantly improves semantic segmentation results with only marginal extra computation cost over FCN. Our approach has achieved new state-of-the-art results 51.7% mIoU on PASCAL-Context. 85.9% mIoU on PASCAL VOC 2012. Our single model achieves a final score of 0.5567 on ADE20K test set. which surpass the winning entry of COCO-Place Challenge in 2017. In addition. we also explore how the Context Encoding Module can improve the feature representation of relatively shallow networks for the image classification on CIFAR-10 dataset. Our 14 layer network has achieved an error rate of 3.45%. which is comparable with state-of-the-art approaches with over 10 times more layers. The source code for the complete system are publicly available.,True,Q3puGtcAAAAJ:nRpfm8aw39MC,550,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html,11819343174629820664,/scholar?cites=11819343174629820664,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Context_Encoding_for_CVPR_2018_paper.pdf,0,0,0
1278329,What is the range of surface reconstructions from a gradient field?,2006,Amit Agrawal and Ramesh Raskar and Rama Chellappa,,,,578-591,Springer. Berlin. Heidelberg,We propose a generalized equation to represent a continuum of surface reconstruction solutions of a given non-integrable gradient field. We show that common approaches such as Poisson solver and Frankot-Chellappa algorithm are special cases of this generalized equation. For a N × N pixel grid. the subspace of all integrable gradient fields is of dimension N 2 – 1. Our framework can be applied to derive a range of meaningful surface reconstructions from this high dimensional space. The key observation is that the range of solutions is related to the degree of anisotropy in applying weights to the gradients in the integration process. While common approaches use isotropic weights. we show that by using a progression of spatially varying anisotropic weights. we can achieve significant improvement in reconstructions. We propose (a) α-surfaces using binary weights. where the parameter α …,True,Q3puGtcAAAAJ:d1gkVwhDpl0C,380,https://link.springer.com/chapter/10.1007/11744023_45,642857688260182612,/scholar?cites=642857688260182612,,,https://link.springer.com/content/pdf/10.1007/11744023_45.pdf,0,0,0
1278330,Removing photography artifacts using gradient projection and flash-exposure sampling,2005,Amit Agrawal and Ramesh Raskar and Shree K Nayar and Yuanzhen Li,24,,3,828-835,ACM,Flash images are known to suffer from several problems: saturation of nearby objects. poor illumination of distant objects. reflections of objects strongly lit by the flash and strong highlights due to the reflection of flash itself by glossy surfaces. We propose to use a flash and no-flash (ambient) image pair to produce better flash images. We present a novel gradient projection scheme based on a gradient coherence model that allows removal of reflections and highlights from flash images. We also present a brightness-ratio based algorithm that allows us to compensate for the falloff in the flash image brightness due to depth. In several practical scenarios. the quality of flash/no-flash images may be limited in terms of dynamic range. In such cases. we advocate using several images taken under different flash intensities and exposures. We analyze the flash intensity-exposure space and propose a method for adaptively …,True,Q3puGtcAAAAJ:9yKSN-GCB0IC,371,https://dl.acm.org/doi/abs/10.1145/1186822.1073269,10758041567423651544,/scholar?cites=10758041567423651544,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.644.1301&rep=rep1&type=pdf,0,0,0
1278331,4D light field cameras,2010,Ramesh Raskar and Amit Kumar Agrawal,,,,,,A camera acquires a 4D light field of a scene. The camera includes a lens and sensor. A mask is arranged in a straight optical path between the lens and the sensor. The mask including an attenuation pattern to spatially modulate the 4D light field acquired of the scene by the sensor. The pattern has a low spatial frequency when the mask is arranged near the lens. and a high spatial frequency when the mask is arranged near the sensor.,True,Q3puGtcAAAAJ:ZeXyd9-uunAC,318,https://patents.google.com/patent/US7792423B2/en,16478334029088959014,/scholar?cites=16478334029088959014,,,https://patentimages.storage.googleapis.com/dc/e4/ba/301213e7c82ef8/US7792423.pdf,0,0,0
1278332,Method for deblurring images using optimized temporal coding patterns,2009,Ramesh Raskar and Jack Tumblin and Amit Agrawal,,,,,,A method and system deblurs images acquired of a scene by a camera. A light field acquired of a scene is modulated temporally according to a sequence of ons and offs. An optimal coding pattern is selected. The modulated light field is integrated by a sensor of a camera during an exposure time to generate an encoded input image. The encoded input image is decoded according to a pseudo-inverse of a smearing matrix to produce a decoded output image having a reduced blur.,True,Q3puGtcAAAAJ:Se3iqnhoufwC,245,https://patents.google.com/patent/US7580620B2/en,515539136666786744,/scholar?cites=515539136666786744,,,https://patentimages.storage.googleapis.com/7d/c5/b4/0ade0716cdf0a2/US7580620.pdf,0,0,0
1278333,An algebraic approach to surface reconstruction from gradient fields,2005,Amit Agrawal and Rama Chellappa and Ramesh Raskar,1,,,174-181,IEEE,Several important problems in computer vision such as shape from shading (SFS) and photometric stereo (PS) require reconstructing a surface from an estimated gradient field. which is usually non-integrable. i.e. have non-zero curl. We propose a purely algebraic approach to enforce integrability in discrete domain. We first show that enforcing integrability can be formulated as solving a single linear system Ax =b over the image. In general. this system is under-determined. We show conditions under which the system can be solved and a method to get to those conditions based on graph theory. The proposed approach is non-iterative. has the important property of local error confinement and can be applied to several problems. Results on SFS and PS demonstrate the applicability of our method.,True,Q3puGtcAAAAJ:2osOgNQ5qMEC,196,https://ieeexplore.ieee.org/abstract/document/1541254/,1130461703001861106,/scholar?cites=1130461703001861106,,,https://www.merl.com/publications/docs/TR2005-145.pdf,0,0,0
1278334,Automatically detecting pain using facial actions,2009,Patrick Lucey and Jeffrey Cohn and Simon Lucey and Iain Matthews and Sridha Sridharan and Kenneth M Prkachin,,,,1-8,IEEE,Pain is generally measured by patient self-report. normally via verbal communication. However. if the patient is a child or has limited ability to communicate (i.e. the mute. mentally impaired. or patients having assisted breathing) self-report may not be a viable measurement. In addition. these self-report measures only relate to the maximum pain level experienced during a sequence so a frame-by-frame measure is currently not obtainable. Using image data from patients with rotator-cuff injuries. in this paper we describe an AAM-based automatic system which can detect pain on a frame-by-frame level. We do this two ways: directly (straight from the facial features); and indirectly (through the fusion of individual AU detectors). From our results. we show that the latter method achieves the optimal results as most discriminant features from each AU detector (i.e. shape or appearance) are used.,True,Q3puGtcAAAAJ:EPG8bYD4jVwC,159,https://ieeexplore.ieee.org/abstract/document/5349321/,1194994863001697695,/scholar?cites=1194994863001697695,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3296481/,0,0,0
1278335,A theory of multi-layer flat refractive geometry,2012,Amit Agrawal and Srikumar Ramalingam and Yuichi Taguchi and Visesh Chari,,,,3346-3353,IEEE,Flat refractive geometry corresponds to a perspective camera looking through single/multiple parallel flat refractive mediums. We show that the underlying geometry of rays corresponds to an axial camera. This realization. while missing from previous works. leads us to develop a general theory of calibrating such systems using 2D-3D correspondences. The pose of 3D points is assumed to be unknown and is also recovered. Calibration can be done even using a single image of a plane. We show that the unknown orientation of the refracting layers corresponds to the underlying axis. and can be obtained independently of the number of layers. their distances from the camera and their refractive indices. Interestingly. the axis estimation can be mapped to the classical essential matrix computation and 5-point algorithm [15] can be used. After computing the axis. the thicknesses of layers can be obtained linearly when …,True,Q3puGtcAAAAJ:hkOj_22Ku90C,148,https://ieeexplore.ieee.org/abstract/document/6248073/,458499275230795407,/scholar?cites=458499275230795407,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.644.6710&rep=rep1&type=pdf,0,0,0
1278336,Structured light 3D scanning in the presence of global illumination,2011,Mohit Gupta and Amit Agrawal and Ashok Veeraraghavan and Srinivasa G Narasimhan,,,,713-720,IEEE,Global illumination effects such as inter-reflections. diffusion and sub-surface scattering severely degrade the performance of structured light-based 3D scanning. In this paper. we analyze the errors caused by global illumination in structured light-based shape recovery. Based on this analysis. we design structured light patterns that are resilient to individual global illumination effects using simple logical operations and tools from combinatorial mathematics. Scenes exhibiting multiple phenomena are handled by combining results from a small ensemble of such patterns. This combination also allows us to detect any residual errors that are corrected by acquiring a few additional images. Our techniques do not require explicit separation of the direct and global components of scene radiance and hence work even in scenarios where the separation fails or the direct component is too low. Our methods can be readily …,True,Q3puGtcAAAAJ:isC4tDSrTZIC,145,https://ieeexplore.ieee.org/abstract/document/5995321/,7926124424972938287,/scholar?cites=7926124424972938287,,,https://merl.com/publications/docs/TR2011-036.pdf,0,0,0
1278337,300 Faces in-the-Wild Challenge: The first facial landmark localization Challenge,2013,Christos Sagonas and Georgios Tzimiropoulos and Stefanos Zafeiriou and Maja Pantic,,,,,IEEE,Automatic facial point detection plays arguably the most important role in face analysis. Several methods have been proposed which reported their results on databases of both constrained and unconstrained conditions. Most of these databases provide annotations with different mark-ups and in some cases the are problems related to the accuracy of the fiducial points. The aforementioned issues as well as the lack of a evaluation protocol makes it difficult to compare performance between different systems. In this paper. we present the 300 Faces in-the-Wild Challenge: The first facial landmark localization Challenge which is held in conjunction with the International Conference on Computer Vision 2013. Sydney. Australia. The main goal of this challenge is to compare the performance of different methods on a new-collected dataset using the same evaluation protocol and the same mark-up and hence to develop the first standardized benchmark for facial landmark localization.,True,D4JkWxf-8fwC:ULOm3_A8WrAC,862,https://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W11/html/Sagonas_300_Faces_in-the-Wild_2013_ICCV_paper.html,7861246476672124064,/scholar?cites=7861246476672124064,,,https://www.cv-foundation.org/openaccess/content_iccv_workshops_2013/W11/papers/Sagonas_300_Faces_in-the-Wild_2013_ICCV_paper.pdf,0,0,0
1278338,How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230.000 3D facial landmarks),2017,Adrian Bulat and Georgios Tzimiropoulos,,,,1021-1030,,"This paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2D and 3D face alignment datasets. To this end. we make the following 5 contributions:(a) we construct. for the first time. a very strong baseline by combining a state-of-the-art architecture for landmark localization with a state-of-the-art residual block. train it on a very large yet synthetically expanded 2D facial landmark dataset and finally evaluate it on all other 2D facial landmark datasets.(b) We create a guided by 2D landmarks network which converts 2D landmark annotations to 3D and unifies all existing datasets. leading to the creation of LS3D-W. the largest and most challenging 3D facial landmark dataset to date 230.000 images.(c) Following that. we train a neural network for 3D face alignment and evaluate it on the newly introduced LS3D-W.(d) We further look into the effect of all"" traditional"" factors affecting face alignment performance like large pose. initialization and resolution. and introduce a"" new"" one. namely the size of the network.(e) We show that both 2D and 3D face alignment networks achieve performance of remarkable accuracy which is probably close to saturating the datasets used. Training and testing code as well as the dataset can be downloaded from https://www. adrianbulat. com/face-alignment/",True,D4JkWxf-8fwC:PkcyUWeTMh0C,643,http://openaccess.thecvf.com/content_iccv_2017/html/Bulat_How_Far_Are_ICCV_2017_paper.html,253169461545193453,/scholar?cites=253169461545193453,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Bulat_How_Far_Are_ICCV_2017_paper.pdf,0,0,0
1278339,300 faces in-the-wild challenge: Database and results,2016,Christos Sagonas and Epameinondas Antonakos and Georgios Tzimiropoulos and Stefanos Zafeiriou and Maja Pantic,47,Image and vision computing,,3-18,Elsevier,Computer Vision has recently witnessed great research advance towards automatic facial points detection. Numerous methodologies have been proposed during the last few years that achieve accurate and efficient performance. However. fair comparison between these methodologies is infeasible mainly due to two issues. (a) Most existing databases. captured under both constrained and unconstrained (in-the-wild) conditions have been annotated using different mark-ups and. in most cases. the accuracy of the annotations is low. (b) Most published works report experimental results using different training/testing sets. different error metrics and. of course. landmark points with semantically different locations. In this paper. we aim to overcome the aforementioned problems by (a) proposing a semi-automatic annotation technique that was employed to re-annotate most existing facial databases under a unified …,True,D4JkWxf-8fwC:raTqNPD5sRQC,521,https://www.sciencedirect.com/science/article/pii/S0262885616000147,4741451765657920988,/scholar?cites=4741451765657920988,,,https://ibug.doc.ic.ac.uk/media/uploads/documents/sagonas_2016_imavis.pdf,0,0,0
1278340,Human pose estimation via convolutional part heatmap regression,2016,Adrian Bulat and Georgios Tzimiropoulos,,,,717-732,Springer. Cham,This paper is on human pose estimation using Convolutional Neural Networks. Our main contribution is a CNN cascaded architecture specifically designed for learning part relationships and spatial context. and robustly inferring pose even for the case of severe part occlusions. To this end. we propose a detection-followed-by-regression CNN cascade. The first part of our cascade outputs part detection heatmaps and the second part performs regression on these heatmaps. The benefits of the proposed architecture are multi-fold: It guides the network where to focus in the image and effectively encodes part constraints and context. More importantly. it can effectively cope with occlusions because part detection heatmaps for occluded parts provide low confidence scores which subsequently guide the regression part of our network to rely on contextual information in order to predict the location of these parts …,True,D4JkWxf-8fwC:SGW5VrABaM0C,436,https://link.springer.com/chapter/10.1007/978-3-319-46478-7_44,15109846204694845795,/scholar?cites=15109846204694845795,,,https://arxiv.org/pdf/1609.01743,0,0,0
1278341,A semi-automatic methodology for facial landmark annotation,2013,Christos Sagonas and Georgios Tzimiropoulos and Stefanos Zafeiriou and Maja Pantic,,,,896-903,,Developing powerful deformable face models requires massive. annotated face databases on which techniques can be trained. validated and tested. Manual annotation of each facial image in terms of landmarks requires a trained expert and the workload is usually enormous. Fatigue is one of the reasons that in some cases annotations are inaccurate. This is why. the majority of existing facial databases provide annotations for a relatively small subset of the training images. Furthermore. there is hardly any correspondence between the annotated landmarks across different databases. These problems make cross-database experiments almost infeasible. To overcome these difficulties. we propose a semi-automatic annotation methodology for annotating massive face datasets. This is the first attempt to create a tool suitable for annotating massive facial databases. We employed our tool for creating annotations for MultiPIE. XM2VTS. AR. and FRGC Ver. 2 databases. The annotations will be made publicly available from http://ibug. doc. ic. ac. uk/resources/facial-point-annotations/. Finally. we present experiments which verify the accuracy of produced annotations.,True,D4JkWxf-8fwC:KlAtU1dfN6UC,389,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W16/html/Sagonas_A_Semi-automatic_Methodology_2013_CVPR_paper.html,15744661091744891,/scholar?cites=15744661091744891,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W16/papers/Sagonas_A_Semi-automatic_Methodology_2013_CVPR_paper.pdf,0,0,0
1278342,Large pose 3D face reconstruction from a single image via direct volumetric CNN regression,2017,Aaron S Jackson and Adrian Bulat and Vasileios Argyriou and Georgios Tzimiropoulos,,,,1031-1039,,3D face reconstruction is a fundamental Computer Vision problem of extraordinary difficulty. Current systems often assume the availability of multiple facial images (sometimes from the same subject) as input. and must address a number of methodological challenges such as establishing dense correspondences across large facial poses. expressions. and non-uniform illumination. In general these methods require complex and inefficient pipelines for model building and fitting. In this work. we propose to address many of these limitations by training a Convolutional Neural Network (CNN) on an appropriate dataset consisting of 2D images and 3D facial models or scans. Our CNN works with just a single 2D facial image. does not require accurate alignment nor establishes dense correspondence between images. works for arbitrary facial poses and expressions. and can be used to reconstruct the whole 3D facial geometry (including the non-visible parts of the face) bypassing the construction (during training) and fitting (during testing) of a 3D Morphable Model. We achieve this via a simple CNN architecture that performs direct regression of a volumetric representation of the 3D facial geometry from a single 2D image. We also demonstrate how the related task of facial landmark localization can be incorporated into the proposed framework and help improve reconstruction quality. especially for the cases of large poses and facial expressions.,True,D4JkWxf-8fwC:rbm3iO8VlycC,290,http://openaccess.thecvf.com/content_iccv_2017/html/Jackson_Large_Pose_3D_ICCV_2017_paper.html,15834263933659566679,/scholar?cites=15834263933659566679,,,https://openaccess.thecvf.com/content_ICCV_2017/papers/Jackson_Large_Pose_3D_ICCV_2017_paper.pdf,0,0,0
1278343,The first facial landmark tracking in-the-wild challenge: Benchmark and results,2015,Jie Shen and Stefanos Zafeiriou and Grigoris G Chrysos and Jean Kossaifi and Georgios Tzimiropoulos and Maja Pantic,,,,50-58,,Detection and tracking of faces in image sequences is among the most well studied problems in the intersection of statistical machine learning and computer vision. Often. tracking and detection methodologies use a rigid representation to describe the facial region 1. hence they can neither capture nor exploit the non-rigid facial deformations. which are crucial for countless of applications (eg. facial expression analysis. facial motion capture. high-performance face recognition etc.). Usually. the non-rigid deformations are captured by locating and tracking the position of a set of fiducial facial landmarks (eg. eyes. nose. mouth etc.). Recently. we witnessed a burst of research in automatic facial landmark localisation in static imagery. This is partly attributed to the availability of large amount of annotated data. many of which have been provided by the first facial landmark localisation challenge (also known as 300-W challenge). Even though now well established benchmarks exist for facial landmark localisation in static imagery. to the best of our knowledge. there is no established benchmark for assessing the performance of facial landmark tracking methodologies. containing an adequate number of annotated face videos. In conjunction with ICCV’2015 we run the first competition/challenge on facial landmark tracking in long-term videos. In this paper. we present the first benchmark for long-term facial landmark tracking. containing currently over 110 annotated videos. and we summarise the results of the competition.,True,D4JkWxf-8fwC:YsrPvlHIBpEC,285,https://www.cv-foundation.org/openaccess/content_iccv_2015_workshops/w25/papers/Shen_The_First_Facial_ICCV_2015_paper.pdf,7356039441836914478,/scholar?cites=7356039441836914478,,,https://www.cv-foundation.org/openaccess/content_iccv_2015_workshops/w25/papers/Shen_The_First_Facial_ICCV_2015_paper.pdf,0,0,0
1278344,Optimization problems for fast AAM fitting in-the-wild,2013,Georgios Tzimiropoulos and Maja Pantic,,,,,IEEE,We describe a very simple framework for deriving the most-well known optimization problems in Active Appearance Models (AAMs). and most importantly for providing efficient solutions. Our formulation results in two optimization problems for fast and exact AAM fitting. and one new algorithm which has the important advantage of being applicable to 3D. We show that the dominant cost for both forward and inverse algorithms is a few times mN which is the cost of projecting an image onto the appearance subspace. This makes both algorithms not only computationally realizable but also very attractive speed-wise for most current systems. Because exact AAM fitting is no longer computationally prohibitive. we trained AAMs in-the-wild with the goal of investigating whether AAMs benefit from such a training process. Our results show that although we did not use sophisticated shape priors. robust features or robust norms for improving performance. AAMs perform notably well and in some cases comparably with current state-ofthe-art methods. We provide Matlab source code for training. fitting and reproducing the results presented in this paper at http://ibug. doc. ic. ac. uk/resources.,True,D4JkWxf-8fwC:Zph67rFs4hoC,268,http://openaccess.thecvf.com/content_iccv_2013/html/Tzimiropoulos_Optimization_Problems_for_2013_ICCV_paper.html,11594217668672070275,/scholar?cites=11594217668672070275,,,https://openaccess.thecvf.com/content_iccv_2013/papers/Tzimiropoulos_Optimization_Problems_for_2013_ICCV_paper.pdf,0,0,0
1278345,Gauss-Newton Deformable Part Models for Face Alignment in-the-Wild,2014,Georgios Tzimiropoulos and Maja Pantic,,,,1851-1858,IEEE,Arguably. Deformable Part Models (DPMs) are one of the most prominent approaches for face alignment with impressive results being recently reported for both controlled lab and unconstrained settings. Fitting in most DPM methods is typically formulated as a two-step process during which discriminatively trained part templates are first correlated with the image to yield a filter response for each landmark and then shape optimization is performed over these filter responses. This process. although computationally efficient. is based on fixed part templates which are assumed to be independent. and has been shown to result in imperfect filter responses and detection ambiguities. To address this limitation. in this paper. we propose to jointly optimize a part-based. trained in-the-wild. flexible appearance model along with a global shape model which results in a joint translational motion model for the model parts via Gauss-Newton (GN) optimization. We show how significant computational reductions can be achieved by building a full model during training but then efficiently optimizing the proposed cost function on a sparse grid using weighted least-squares during fitting. We coin the proposed formulation Gauss-Newton Deformable Part Model (GN-DPM). Finally. we compare its performance against the state-of-the-art and show that the proposed GN-DPM outperforms it. in some cases. by a large margin. Code for our method is available from http://ibug. doc. ic. ac. uk/resources,True,D4JkWxf-8fwC:_kc_bZDykSQC,257,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Tzimiropoulos_Gauss-Newton_Deformable_Part_2014_CVPR_paper.html,14045759082690719692,/scholar?cites=14045759082690719692,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Tzimiropoulos_Gauss-Newton_Deformable_Part_2014_CVPR_paper.pdf,0,0,0
1278346,Project-out cascaded regression with an application to face alignment,2015,Georgios Tzimiropoulos,,,,3659-3667,,Cascaded regression approaches have been recently shown to achieve state-of-the-art performance for many computer vision tasks. Beyond its connection to boosting. cascaded regression has been interpreted as a learning-based approach to iterative optimization methods like the Newton's method. However. in prior work. the connection to optimization theory is limited only in learning a mapping from image features to problem parameters. In this paper. we consider the problem of facial deformable model fitting using cascaded regression and make the following contributions:(a) We propose regression to learn a sequence of averaged Jacobian and Hessian matrices from data. and from them descent directions in a fashion inspired by Gauss-Newton optimization.(b) We show that the optimization problem in hand has structure and devise a learning strategy for a cascaded regression approach that takes the problem structure into account. By doing so. the proposed method learns and employs a sequence of averaged Jacobians and descent directions in a subspace orthogonal to the facial appearance variation; hence. we call it Project-Out Cascaded Regression (PO-CR).(c) Based on the principles of PO-CR. we built a face alignment system that produces remarkably accurate results on the challenging iBUG data set outperforming previously proposed systems by a large margin. Code for our system is available from http://www. cs. nott. ac. uk/~ yzt/.,True,D4JkWxf-8fwC:9ZlFYXVOiuMC,239,http://openaccess.thecvf.com/content_cvpr_2015/html/Tzimiropoulos_Project-Out_Cascaded_Regression_2015_CVPR_paper.html,2254945008810470991,/scholar?cites=2254945008810470991,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Tzimiropoulos_Project-Out_Cascaded_Regression_2015_CVPR_paper.pdf,0,0,0
1278347,Deep machine learning provides state-of-the-art performance in image-based plant phenotyping.,2017,MP Pound and AJ Burgess and MH Wilson and JA Atkinson and M Griffiths and AS Jackson and A Bulat and G Tzimiropoulos and DM Wells and EH Murchie and TP Pridmore and AP French,,GigaScience,,,,In plant phenotyping. it has become important to be able to measure many features on large image sets in order to aid genetic discovery. The size of the datasets. now often captured robotically. often precludes manual inspection. hence the motivation for finding a fully automated approach. Deep learning is an emerging field that promises unparalleled results on many data analysis problems. Building on artificial neural networks. deep approaches have many more hidden layers in the network. and hence have greater discriminative and predictive power. We demonstrate the use of such approaches as part of a plant phenotyping pipeline. We show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping and demonstrate state-of-the-art results (>97% accuracy) for root and shoot feature identification and localization. We use fully automated trait …,True,D4JkWxf-8fwC:UmS_249rOGwC,184,https://academic.oup.com/gigascience/article-abstract/6/10/gix083/4091592,855270023776397338,/scholar?cites=855270023776397338,,,https://academic.oup.com/gigascience/article/6/10/gix083/4091592,0,0,0
1278348,Tensor-Train Decomposition,2011,IV Oseledets,33,SIAM Journal on Scientific Computing,,2295-2317,,A simple nonrecursive form of the tensor decomposition in d dimensions is presented. It does not inherently suffer from the curse of dimensionality. it has asymptotically the same number of parameters as the canonical decomposition. but it is stable and its computation is based on low-rank approximation of auxiliary unfolding matrices. The new form gives a clear and convenient way to implement all basic operations efficiently. A fast rounding procedure is presented. as well as basic linear algebra operations. Examples showing the benefits of the decomposition are given. and the efficiency is demonstrated by the computation of the smallest eigenvalue of a 19-dimensional operator.,True,5kMqBQEAAAAJ:Zph67rFs4hoC,1431,https://epubs.siam.org/doi/abs/10.1137/090752286,12189396058626511944,/scholar?cites=12189396058626511944,,,https://www.researchgate.net/profile/Ivan_Oseledets2/publication/220412263_Tensor-Train_Decomposition/links/5bbfb5c5299bf1004c5a56e3/Tensor-Train-Decomposition.pdf,0,0,0
1278349,Speeding-up convolutional neural networks using fine-tuned cp-decomposition,2014,Vadim Lebedev and Yaroslav Ganin and Maksim Rakhuba and Ivan Oseledets and Victor Lempitsky,,arXiv preprint arXiv:1412.6553,,,,We propose a simple two-step approach for speeding up convolution layers within large convolutional neural networks based on tensor decomposition and discriminative fine-tuning. Given a layer. we use non-linear least squares to compute a low-rank CP-decomposition of the 4D convolution kernel tensor into a sum of a small number of rank-one tensors. At the second step. this decomposition is used to replace the original convolutional layer with a sequence of four convolutional layers with small kernels. After such replacement. the entire network is fine-tuned on the training data using standard backpropagation process.We evaluate this approach on two CNNs and show that it is competitive with previous approaches. leading to higher obtained CPU speedups at the cost of lower accuracy drops for the smaller of the two networks. Thus. for the 36-class character classification CNN. our approach obtains a 8.5 x CPU speedup of the whole network with only minor accuracy drop (1% from 91% to 90%). For the standard ImageNet architecture (AlexNet). the approach speeds up the second convolution layer by a factor of 4x at the cost of  increase of the overall top-5 classification error.,True,5kMqBQEAAAAJ:ojlX30-wUrgC,562,https://arxiv.org/abs/1412.6553,3369289675757470591,/scholar?cites=3369289675757470591,,,https://arxiv.org/pdf/1412.6553,0,0,0
1278350,Breaking the curse of dimensionality. or how to use SVD in many dimensions,2009,Ivan V Oseledets and Eugene E Tyrtyshnikov,31,SIAM Journal on Scientific Computing,5,3744-3759,Society for Industrial and Applied Mathematics,For d-dimensional tensors with possibly large . an hierarchical data structure. called the Tree-Tucker format. is presented as an alternative to the canonical decomposition. It has asymptotically the same (and often even smaller) number of representation parameters and viable stability properties. The approach involves a recursive construction described by a tree with the leafs corresponding to the Tucker decompositions of three-dimensional tensors. and is based on a sequence of SVDs for the recursively obtained unfolding matrices and on the auxiliary dimensions added to the initial “spatial” dimensions. It is shown how this format can be applied to the problem of multidimensional convolution. Convincing numerical examples are given.,True,5kMqBQEAAAAJ:u-x6o8ySG0sC,463,https://epubs.siam.org/doi/abs/10.1137/090748330,12022954852213849176,/scholar?cites=12022954852213849176,,,http://www.mat.uniroma2.it/~tvmsscho/papers/Tyrtyshnikov4.pdf,0,0,0
1278351,TT-cross approximation for multidimensional arrays,2010,Ivan Oseledets and Eugene Tyrtyshnikov,432,Linear Algebra and its Applications,1,70-88,North-Holland,As is well known. a rank-r matrix can be recovered from a cross of r linearly independent columns and rows. and an arbitrary matrix can be interpolated on the cross entries. Other entries by this cross or pseudo-skeleton approximation are given with errors depending on the closeness of the matrix to a rank-r matrix and as well on the choice of cross. In this paper we extend this construction to d-dimensional arrays (tensors) and suggest a new interpolation formula in which a d-dimensional array is interpolated on the entries of some TT-cross (tensor train-cross). The total number of entries and the complexity of our interpolation algorithm depend on d linearly. so the approach does not suffer from the curse of dimensionality. We also propose a TT-cross method for computation of d-dimensional integrals and apply it to some examples with dimensionality in the range from d= 100 up to d= 4000 and the relative accuracy …,True,5kMqBQEAAAAJ:d1gkVwhDpl0C,444,https://www.sciencedirect.com/science/article/pii/S0024379509003747,444505331923684141,/scholar?cites=444505331923684141,,,https://www.sciencedirect.com/science/article/pii/S0024379509003747/pdf?md5=24febc00c64c9e0b7c5e16e07d9ef469&pid=1-s2.0-S0024379509003747-main.pdf&_valck=1,0,0,0
1278352,Unifying time evolution and optimization with matrix product states,2016,Jutho Haegeman and Christian Lubich and Ivan Oseledets and Bart Vandereycken and Frank Verstraete,94,Physical Review B,16,165116,American Physical Society,We show that the time-dependent variational principle provides a unifying framework for time-evolution methods and optimization methods in the context of matrix product states. In particular. we introduce a new integration scheme for studying time evolution. which can cope with arbitrary Hamiltonians. including those with long-range interactions. Rather than a Suzuki-Trotter splitting of the Hamiltonian. which is the idea behind the adaptive time-dependent density matrix renormalization group method or time-evolving block decimation. our method is based on splitting the projector onto the matrix product state tangent space as it appears in the Dirac-Frenkel time-dependent variational principle. We discuss how the resulting algorithm resembles the density matrix renormalization group (DMRG) algorithm for finding ground states so closely that it can be implemented by changing just a few lines of code and it inherits …,True,5kMqBQEAAAAJ:rFyVMFCKTwsC,285,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.94.165116,8124412568425659771,/scholar?cites=8124412568425659771,,,https://arxiv.org/pdf/1408.5056,0,0,0
1278353,Tensor networks for dimensionality reduction and large-scale optimization: Part 1 low-rank tensor decompositions,2016,Andrzej Cichocki and Namgil Lee and Ivan Oseledets and Anh-Huy Phan and Qibin Zhao and Danilo P Mandic,9,Foundations and Trends® in Machine Learning,4-5,249-429,Now Publishers Inc.,Modern applications in engineering and data science are increasinglybased on multidimensional data of exceedingly high volume. variety.and structural richness. However. standard machine learning algorithmstypically scale exponentially with data volume and complexityof cross-modal couplings - the so called curse of dimensionality -which is prohibitive to the analysis of large-scale. multi-modal andmulti-relational datasets. Given that such data are often efficientlyrepresented as multiway arrays or tensors. it is therefore timely andvaluable for the multidisciplinary machine learning and data analyticcommunities to review low-rank tensor decompositions and tensor networksas emerging tools for dimensionality reduction and large scaleoptimization problems. Our particular emphasis is on elucidating that.by virtue of the underlying low-rank approximations. tensor networkshave the ability to alleviate the curse of …,True,5kMqBQEAAAAJ:IHkkN1K1AlAC,277,https://dl.acm.org/doi/abs/10.1561/2200000059,14365721412131790573,/scholar?cites=14365721412131790573,,,https://dl.acm.org/doi/abs/10.1561/2200000059,0,0,0
1278354,Approximation of  Matrices Using Tensor Decomposition,2010,IV Oseledets,31,SIAM Journal on Matrix Analysis and Applications,,2130-2145,,A new method for structured representation of matrices and vectors is presented. The method is based on the representation of a matrix as a d-dimensional tensor and applying the TT-decomposition proposed recently. It turned out that for many important cases the number of parameters to represent an  matrix falls down to . giving a logarithmic storage. It is shown that this format can be used not only for storage reduction. but also for linear algebra operations. Possible applications include differential and integral equations. and data and image compression.,True,5kMqBQEAAAAJ:2osOgNQ5qMEC,210,https://epubs.siam.org/doi/abs/10.1137/090757861,17704335846171993080,/scholar?cites=17704335846171993080,,,,0,0,0
1278355,How to find a good submatrix,2010,Sergei A Goreinov and Ivan V Oseledets and Dimitry V Savostyanov and Eugene E Tyrtyshnikov and Nikolay L Zamarashkin,,,,247-256,,Pseudoskeleton approximation and some other problems require the knowledge of sufficiently well-conditioned submatrix in a largescale matrix. The quality of a submatrix can be measured by modulus of its determinant. also known as volume. In this paper we discuss a search algorithm for the maximum-volume submatrix which already proved to be useful in several matrix and tensor approximation algorithms. We investigate the behavior of this algorithm on random matrices and present some of its applications. including maximization of a bivariate functional.,True,5kMqBQEAAAAJ:WF5omc3nYNoC,194,https://www.worldscientific.com/doi/abs/10.1142/9789812836021_0015,4917345464519943067,/scholar?cites=4917345464519943067,,,,0,0,0
1278356,Tucker dimensionality reduction of three-dimensional arrays in linear time,2008,Ivan V Oseledets and DV Savostianov and Eugene E Tyrtyshnikov,30,SIAM Journal on Matrix Analysis and Applications,3,939-956,Society for Industrial and Applied Mathematics,We consider Tucker-like approximations with an  core tensor for three-dimensional  arrays in the case of  and possibly very large n (up to –). As the approximation contains only  parameters. it is natural to ask if it can be computed using only a small amount of entries of the given array. A similar question for matrices (two-dimensional tensors) was asked and positively answered in [S. A. Goreinov. E. E. Tyrtyshnikov. and N. L. Zamarashkin. A theory of pseudo-skeleton approximations. Linear Algebra Appl.. 261 (1997). pp. 1–21]. In the present paper we extend the positive answer to the case of three-dimensional tensors. More specifically. it is shown that if the tensor admits a good Tucker approximation for some (small) rank r. then this approximation can be computed using only  entries with  complexity.,True,5kMqBQEAAAAJ:u5HHmVD_uO8C,182,https://epubs.siam.org/doi/abs/10.1137/060655894,17388776419509858987,/scholar?cites=17388776419509858987,,,http://www.mat.uniroma2.it/~tvmsscho/papers/Tyrtyshnikov3.pdf,0,0,0
1278357,Solution of linear systems and matrix inversion in the TT-format,2012,Ivan V Oseledets and Sergey V Dolgov,34,SIAM Journal on Scientific Computing,5,A2718-A2739,Society for Industrial and Applied Mathematics,Tensors arise naturally in high-dimensional problems in chemistry. financial mathematics. and many other areas. The numerical treatment of such problems is difficult due to the curse of dimensionality: the number of unknowns and the computational complexity grow exponentially with the dimension of the problem. To break the curse of dimensionality. low-parametric representations. or formats. have to be used. In this paper we make use of the TT-format (tensor-train format) which is one of the most effective stable representations of high-dimensional tensors. Basic linear algebra operations in the TT-format are now well developed. Our goal is to provide a “black-box” type of solver for linear systems where both the matrix and the right-hand side are in the TT-format. An efficient DMRG (density matrix renormalization group) method is proposed. and several tricks are employed to make it work. The numerical …,True,5kMqBQEAAAAJ:vV6vV6tmYwMC,164,https://epubs.siam.org/doi/abs/10.1137/110833142,18311390617021486139,/scholar?cites=18311390617021486139,,,https://www.mis.mpg.de/preprints/2011/preprint2011_19.pdf,0,0,0
1278358,Tensor networks for dimensionality reduction and large-scale optimizations. part 2 applications and future perspectives,2017,Andrzej Cichocki and Anh-Huy Phan and Qibin Zhao and Namgil Lee and Ivan V Oseledets and Masashi Sugiyama and Danilo Mandic,,arXiv preprint arXiv:1708.09165,,,,Part 2 of this monograph builds on the introduction to tensor networks and their operations presented in Part 1. It focuses on tensor network models for super-compressed higher-order representation of data/parameters and related cost functions. while providing an outline of their applications in machine learning and data analytics. A particular emphasis is on the tensor train (TT) and Hierarchical Tucker (HT) decompositions. and their physically meaningful interpretations which reflect the scalability of the tensor network approach. Through a graphical approach. we also elucidate how. by virtue of the underlying low-rank tensor approximations and sophisticated contractions of core tensors. tensor networks have the ability to perform distributed computations on otherwise prohibitively large volumes of data/parameters. thereby alleviating or even eliminating the curse of dimensionality. The usefulness of this concept is illustrated over a number of applied areas. including generalized regression and classification (support tensor machines. canonical correlation analysis. higher order partial least squares). generalized eigenvalue decomposition. Riemannian optimization. and in the optimization of deep neural networks. Part 1 and Part 2 of this work can be used either as stand-alone separate texts. or indeed as a conjoint comprehensive review of the exciting field of low-rank tensor networks and tensor decompositions.,True,5kMqBQEAAAAJ:NXYAu82O0W8C,140,https://arxiv.org/abs/1708.09165,2350165683447327688,/scholar?cites=2350165683447327688,,,https://arxiv.org/pdf/1708.09165,0,0,0
1278359,Automatic seeded region growing for color image segmentation,2005,Frank Y Shih and Shouxian Cheng,23,Image and vision computing,10,877-886,Elsevier,In this paper. we present an automatic seeded region growing algorithm for color image segmentation. First. the input RGB color image is transformed into YCbCr color space. Second. the initial seeds are automatically selected. Third. the color image is segmented into regions where each region corresponds to a seed. Finally. region-merging is used to merge similar or small regions. Experimental results show that our algorithm can produce good results as favorably compared to some existing algorithms.,True,uXEp3MIAAAAJ:u5HHmVD_uO8C,531,https://www.sciencedirect.com/science/article/pii/S0262885605000673,16537601159013106248,/scholar?cites=16537601159013106248,,,http://papersim.com/wp-content/uploads/Image_Processing__region_growing_Segmentation_2005.pdf,0,0,0
1278360,Digital watermarking and steganography: fundamentals and techniques,2017,Frank Y Shih,,,,,CRC press,This book intends to provide a comprehensive overview on different aspects of mechanisms and techniques for information security. It is written for students. researchers. and professionals studying in the field of multimedia security and steganography. Multimedia security and steganography is especially relevant due to the global scale of digital multimedia and the rapid growth of the Internet. Digital watermarking technology can be used to guarantee authenticity and can be applied as proof that the content has not been altered since insertion. Updated techniques and advances in watermarking are explored in this new edition. The combinational spatial and frequency domains watermarking technique provides a new concept of enlarging the embedding capacity of watermarks. The genetic algorithm (GA) based watermarking technique solves the rounding error problem and provide an efficient embedding approach. Each chapter provides the reader with a fundamental. theoretical framework. while developing the extensive advanced techniques and considering the essential principles of the digital watermarking and steganographic systems. Several robust algorithms that are presented throughout illustrate the framework and provide assistance and tools in understanding and implementing the fundamental principles.,True,uXEp3MIAAAAJ:2osOgNQ5qMEC,411,http://books.google.com/books?hl=en&lr=&id=j4ujDgAAQBAJ&oi=fnd&pg=PR1&dq=info:ZNjplBSppTcJ:scholar.google.com&ots=aL19ATwyrf&sig=feID6TP4QSq-jo1LdreSi87FOnQ,4009796949106088036,/scholar?cites=4009796949106088036,,,,0,0,0
1278361,Image processing and pattern recognition: fundamentals and techniques,2010,Frank Y Shih,,,,,John Wiley & Sons,A comprehensive guide to the essential principles of image processing and pattern recognition Techniques and applications in the areas of image processing and pattern recognition are growing at an unprecedented rate. Containing the latest state-of-the-art developments in the field. Image Processing and Pattern Recognition presents clear explanations of the fundamentals as well as the most recent applications. It explains the essential principles so readers will not only be able to easily implement the algorithms and techniques. but also lead themselves to discover new problems and applications. Unlike other books on the subject. this volume presents numerous fundamental and advanced image processing algorithms and pattern recognition techniques to illustrate the framework. Scores of graphs and examples. technical assistance. and practical tools illustrate the basic principles and help simplify the problems. allowing students as well as professionals to easily grasp even complicated theories. It also features unique coverage of the most interesting developments and updated techniques. such as image watermarking. digital steganography. document processing and classification. solar image processing and event classification. 3-D Euclidean distance transformation. shortest path planning. soft morphology. recursive morphology. regulated morphology. and sweep morphology. Additional topics include enhancement and segmentation techniques. active learning. feature extraction. neural networks. and fuzzy logic. Featuring supplemental materials for instructors and students. Image Processing and Pattern Recognition is designed for …,True,uXEp3MIAAAAJ:u-x6o8ySG0sC,410,http://books.google.com/books?hl=en&lr=&id=M_Lr8NTfAHcC&oi=fnd&pg=PR5&dq=info:alnC0hrD4N4J:scholar.google.com&ots=hPCI8kZ7tL&sig=xugpgab0ked1BfHcAL4VQwznniU,16060050791175706986,/scholar?cites=16060050791175706986,,,,0,0,0
1278362,Image processing and mathematical morphology: fundamentals and applications,2009,Frank Y Shih,,,,,CRC press,In the development of digital multimedia. the importance and impact of image processing and mathematical morphology are well documented in areas ranging from automated vision detection and inspection to object recognition. image analysis and pattern recognition. Those working in these ever-evolving fields require a solid grasp of basic fundamentals. theory. and related applications—and few books can provide the unique tools for learning contained in this text. Image Processing and Mathematical Morphology: Fundamentals and Applications is a comprehensive. wide-ranging overview of morphological mechanisms and techniques and their relation to image processing. More than merely a tutorial on vital technical information. the book places this knowledge into a theoretical framework. This helps readers analyze key principles and architectures and then use the author’s novel ideas on implementation of advanced algorithms to formulate a practical and detailed plan to develop and foster their own ideas. The book: Presents the history and state-of-the-art techniques related to image morphological processing. with numerous practical examples Gives readers a clear tutorial on complex technology and other tools that rely on their intuition for a clear understanding of the subject Includes an updated bibliography and useful graphs and illustrations Examines several new algorithms in great detail so that readers can adapt them to derive their own solution approaches This invaluable reference helps readers assess and simplify problems and their essential requirements and complexities. giving them all the necessary data and methodology to …,True,uXEp3MIAAAAJ:epqYDVWIO7EC,317,http://books.google.com/books?hl=en&lr=&id=DVpqN_5BYEAC&oi=fnd&pg=PP1&dq=info:n-1qzHiOX_AJ:scholar.google.com&ots=9Kti1s5WxA&sig=7WLJ75i0KAh9n5K-Z2rAuKl-5cg,17320719341366996383,/scholar?cites=17320719341366996383,,,,0,0,0
1278363,Combinational image watermarking in the spatial and frequency domains,2003,Frank Y Shih and Scott YT Wu,36,Pattern Recognition,4,969-975,Pergamon,In order to provide more watermarks and to minimize the distortion of the watermarked image. a novel technique using the combinational spatial and frequency domains is presented in this paper. The splitting of the watermark image into two parts. respectively. for spatial and frequency insertion relies on the user's preference and data importance. Experimental results provide the comparisons when different sized watermarks are embedded into a grayscale image. The proposed combinational image watermarking possesses the following advantages. More watermark data can be inserted into the host image. so that the capacity is increased. The splitting of the watermark into two parts makes the degree of protection double. The splitting strategy can be designed even more complicated to be unable to compose. Furthermore. to enhance robustness. a random permutation of the watermark is used to defeat the attacks …,True,uXEp3MIAAAAJ:9yKSN-GCB0IC,235,https://www.sciencedirect.com/science/article/pii/S003132030200122X,5610691196154351561,/scholar?cites=5610691196154351561,,,,0,0,0
1278364,Threshold decomposition of gray-scale morphology into binary morphology,1989,Frank Y Shih and Owen Robert  Mitchell,11,IEEE Transactions on Pattern Analysis and Machine Intelligence,1,31-42,IEEE,Recently. a superposition property called threshold decomposition and another property called stacking were introduced and shown to apply successfully to gray-scale morphological operations. This property allows gray-scale signals to be decomposed into multiple binary signals. The signals are processed in parallel. and the results are combined to produce the desired gray-scale result. The authors present the threshold decomposition architecture and the stacking property that allows the implementation of this architecture. Gray-scale operations are decomposed into binary operations. This decomposition allows gray-scale morphological operations to be implemented using only logic gates in VLSI architectures that can significantly improve speed as well as give theoretical insight into the operations.< >,True,uXEp3MIAAAAJ:d1gkVwhDpl0C,215,https://ieeexplore.ieee.org/abstract/document/23111/,1364459298828719583,/scholar?cites=1364459298828719583,,,,0,0,0
1278365,Retinal vessels segmentation based on level set and region growing,2014,Yu Qian Zhao and Xiao Hong Wang and Xiao Fang Wang and Frank Y Shih,47,Pattern Recognition,7,2437-2446,Pergamon,Retinal vessels play an important role in the diagnostic procedure of retinopathy. Accurate segmentation of retinal vessels is crucial for pathological analysis. In this paper. we propose a new retinal vessel segmentation method based on level set and region growing. Firstly. a retinal vessel image is preprocessed by the contrast-limited adaptive histogram equalization and a 2D Gabor wavelet to enhance the vessels. Then. an anisotropic diffusion filter is used to smooth the image and preserve vessel boundaries. Finally. the region growing method and a region-based active contour model with level set implementation are applied to extract retinal vessels. and their results are combined to achieve the final segmentation. Comparisons are conducted on the publicly available DRIVE and STARE databases using three different measurements. Experimental results show that the proposed method reaches an average …,True,uXEp3MIAAAAJ:KlAtU1dfN6UC,213,https://www.sciencedirect.com/science/article/pii/S0031320314000247,16473444091756398701,/scholar?cites=16473444091756398701,,,http://ir.nsfc.gov.cn/paperDownload/1000008954523.pdf,0,0,0
1278366,Automatic extraction of head and face boundaries and facial features,2004,Frank Y Shih and Chao-Fa Chuang,158,Information Sciences,,117-130,Elsevier,This paper presents a novel approach for the extraction of human head. face and facial features. In the double-threshold method. the high-thresholded image is used to trace head boundary and the low-thresholded image is used to scan face boundary. We obtain facial features candidates and eliminate noises. and apply x- and y-projections to extract facial features such as eyes. nostrils and mouth. Because low contrast of chin occurs in some face images. its boundary cannot be completely detected. An elliptic model is used to repair it. Because of noises or clustered facial features candidates. we apply a geometric face model to locate facial features and an elliptic model to trace face boundary. The Gabor filter algorithm is adopted to locate two eyes. We have tested our algorithm on more than 100 FERET face images. Experimental results show that our algorithm can perform the extraction of human head. face and …,True,uXEp3MIAAAAJ:UeHWp8X0CEIC,179,https://www.sciencedirect.com/science/article/pii/S002002550300197X,483634323258401667,/scholar?cites=483634323258401667,,,,0,0,0
1278367,Exact and approximate algorithms for unordered tree matching,1994,Dennis Shasha and JT-L Wang and Kaizhong Zhang and Frank Y Shih,24,"IEEE Transactions on Systems, Man, and Cybernetics",4,668-678,IEEE,We consider the problem of comparison between unordered trees. i.e.. trees for which the order among siblings is unimportant. The criterion for comparison is the distance as measured by a weighted sum of the costs of deletion. insertion and relabel operations on tree nodes. Such comparisons may contribute to pattern recognition efforts in any field (e.g.. genetics) where data can naturally be characterized by unordered trees. In companion work. we have shown this problem to be NP-complete. This paper presents an efficient enumerative algorithm and several heuristics leading to approximate solutions. The algorithms are based on probabilistic hill climbing and bipartite matching techniques. The paper evaluates the accuracy and time efficiency of the heuristics by applying them to a set of trees transformed from industrial parts based on a previously proposed morphological model.< >,True,uXEp3MIAAAAJ:qjMakFHDy7sC,166,https://ieeexplore.ieee.org/abstract/document/286387/,3238319874435413546,/scholar?cites=3238319874435413546,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4078&rep=rep1&type=pdf,0,0,0
1278368,Performance comparisons of facial expression recognition in JAFFE database,2008,Frank Y Shih and Chao-Fa Chuang and Patrick SP Wang,22,International Journal of Pattern Recognition and Artificial Intelligence,03,445-459,World Scientific Publishing Company,Facial expression provides an important behavioral measure for studies of emotion. cognitive processes. and social interaction. Facial expression recognition has recently become a promising research area. Its applications include human-computer interfaces. human emotion analysis. and medical care and cure. In this paper. we investigate various feature representation and expression classification schemes to recognize seven different facial expressions. such as happy. neutral. angry. disgust. sad. fear and surprise. in the JAFFE database. Experimental results show that the method of combining 2D-LDA (Linear Discriminant Analysis) and SVM (Support Vector Machine) outperforms others. The recognition rate of this method is 95.71% by using leave-one-out strategy and 94.13% by using cross-validation strategy. It takes only 0.0357 second to process one image of size 256 × 256.,True,uXEp3MIAAAAJ:Tyk-4Ss8FVUC,160,https://www.worldscientific.com/doi/abs/10.1142/S0218001408006284,14965338028152033502,/scholar?cites=14965338028152033502,,,https://www.researchgate.net/profile/Patrick_Wang3/publication/220359507_Performance_Comparisons_of_Facial_Expression_Recognition_in_Jaffe_Database/links/00b4951a0f2b56b66e000000.pdf,0,0,0
1278369,Robust watermarking and compression for medical images based on genetic algorithms,2005,Frank Y Shih and Yi-Ta Wu,175,Information Sciences,3,200-216,Elsevier,A ROI (region of interest) of a medical image is an area including important information and must be stored without any distortion. In order to achieve optimal compression as well as satisfactory visualization of medical images. we compress the ROI by lossless compression. and the rest by lossy compression. Furthermore. security is an important issue in web-based medical information system. Watermarking skill is often used for protecting medical images. In this paper. we present a robust technique embedding the watermark of signature information or textual data around the ROI of a medical image based on genetic algorithms. A fragile watermark is adopted to detect any unauthorized modification. The embedding of watermark in the frequency domain is more difficult to be pirated than in spatial domain.,True,uXEp3MIAAAAJ:zYLM7Y9cAGgC,142,https://www.sciencedirect.com/science/article/pii/S0020025505000344,9548076192742891277,/scholar?cites=9548076192742891277,,,,0,0,0
1278370,Handbook of medical image processing and analysis,2008,Isaac Bankman,,,,,Elsevier,The Handbook of Medical Image Processing and Analysis is a comprehensive compilation of concepts and techniques used for processing and analyzing medical images after they have been generated or digitized. The Handbook is organized into six sections that relate to the main functions: enhancement. segmentation. quantification. registration. visualization. and compression. storage and communication. The second edition is extensively revised and updated throughout. reflecting new technology and research. and includes new chapters on: higher order statistics for tissue segmentation; tumor growth modeling in oncological image analysis; analysis of cell nuclear features in fluorescence microscopy images; imaging and communication in medical and public health informatics; and dynamic mammogram retrieval from web-based image libraries. For those looking to explore advanced concepts and access essential information. this second edition of Handbook of Medical Image Processing and Analysis is an invaluable resource. It remains the most complete single volume reference for biomedical engineers. researchers. professionals and those working in medical imaging and medical image processing. Dr. Isaac N. Bankman is the supervisor of a group that specializes on imaging. laser and sensor systems. modeling. algorithms and testing at the Johns Hopkins University Applied Physics Laboratory. He received his BSc degree in Electrical Engineering from Bogazici University. Turkey. in 1977. the MSc degree in Electronics from University of Wales. Britain. in 1979. and a PhD in Biomedical Engineering from the Israel Institute of …,True,cn4ifN0AAAAJ:cFHS6HbyZ2cC,1170,http://books.google.com/books?hl=en&lr=&id=AnRPBKb7qHUC&oi=fnd&pg=PP1&dq=info:OJfVC_SJs1oJ:scholar.google.com&ots=mJ_yOuI9F3&sig=ZMViHAvYRPHIiGSaixTSPvDke6w,6535719165508294456,/scholar?cites=6535719165508294456,,,,0,0,0
1278371,Dynamic imaging of allogeneic mesenchymal stem cells trafficking to myocardial infarction,2005,Dara L Kraitchman and Mitsuaki Tatsumi and Wesley D Gilson and Takayoshi Ishimori and Dorota Kedziorek and Piotr Walczak and W Paul Segars and Hunter H Chen and Danielle Fritzges and Izlem Izbudak and Randell G Young and Michelle Marcelino and Mark F Pittenger and Meiyappan Solaiyappan and Raymond C Boston and Benjamin MW Tsui and Richard L Wahl and Jeff WM Bulte,112,Circulation,10,1451,NIH Public Access,BackgroundRecent results from animal studies suggest that stem cells may be able to home to sites of myocardial injury to assist in tissue regeneration. However. the histological interpretation of postmortem tissue. on which many of these studies are based. has recently been widely debated.Methods and ResultsWith the use of the high sensitivity of a combined single-photon emission CT (SPECT)/CT scanner. the in vivo trafficking of allogeneic mesenchymal stem cells (MSCs) colabeled with a radiotracer and MR contrast agent to acute myocardial infarction was dynamically determined. Redistribution of the labeled MSCs after intravenous injection from initial localization in the lungs to nontarget organs such as the liver. kidney. and spleen was observed within 24 to 48 hours after injection. Focal and diffuse uptake of MSCs in the infarcted myocardium was already visible in SPECT/CT images in the first 24 hours …,True,cn4ifN0AAAAJ:qUcmZB5y_30C,657,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc1456731/,9367458460141117003,/scholar?cites=9367458460141117003,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc1456731/,0,0,0
1278372,Imaging cortical association tracts in the human brain using diffusion‐tensor‐based axonal tracking,2002,Susumu Mori and Walter E Kaufmann and Christos Davatzikos and Bram Stieltjes and Laura Amodei and Kim Fredericksen and Godfrey D Pearlson and Elias R Melhem and Meiyappan Solaiyappan and Gerald V Raymond and Hugo W Moser and Peter CM Van Zijl,47,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,2,215-223,John Wiley & Sons. Inc.,Diffusion‐tensor fiber tracking was used to identify the cores of several long‐association fibers. including the anterior (ATR) and posterior (PTR) thalamic radiations. and the uncinate (UNC). superior longitudinal (SLF). inferior longitudinal (ILF). and inferior fronto‐occipital (IFO) fasciculi. Tracking results were compared to existing anatomical knowledge. and showed good qualitative agreement. Guidelines were developed to reproducibly track these fibers in vivo. The interindividual variability of these reconstructions was assessed in a common spatial reference frame (Talairach space) using probabilistic mapping. As a first illustration of this technical capability. a reduction in brain connectivity in a patient with a childhood neurodegenerative disease (X‐linked adrenoleukodystrophy) was demonstrated. Magn Reson Med 47:215–223. 2002. © 2002 Wiley‐Liss. Inc.,True,cn4ifN0AAAAJ:hqOjcs7Dif8C,626,https://onlinelibrary.wiley.com/doi/abs/10.1002/Mrm.10074,4569039336150344927,/scholar?cites=4569039336150344927,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.10074,0,0,0
1278373,Diffusion tensor imaging and axonal tracking in the human brainstem,2001,Bram Stieltjes and Walter E Kaufmann and Peter CM Van Zijl and Kim Fredericksen and Godfrey D Pearlson and Meiyappan Solaiyappan and Susumu Mori,14,Neuroimage,3,723-735,Academic Press,Diffusiontensor MRI was used to demonstrate in vivo anatomical mapping of brainstem axonal connections. It was possible to identify the corticospinal tract (CST). medial lemniscus. and the superior. medial. and inferior cerebellar peduncles. In addition. the cerebral peduncle could be subparcellated into component tracts. namely. the frontopontine tract. the CST. and the temporo-/parieto-/occipitopontine tract. Anatomical landmarks and tracking thresholds were established for each fiber and. using these standards. reproducibility of automated tracking as assessed by intra- and interrater reliability was found to be high (κ > 0.82). Reconstructed fibers corresponded well to existing anatomical knowledge. validating the tracking. Information on the location of individual tracts was coregistered with quantitative MRI maps to automatically measure MRI parameters on a tract-by-tract basis. The results reveal that each tract …,True,cn4ifN0AAAAJ:ZHo1McVdvXMC,600,https://www.sciencedirect.com/science/article/pii/S1053811901908614,17534137778732295933,/scholar?cites=17534137778732295933,,,https://pdfs.semanticscholar.org/6582/fa54ec6db6abd5c10733d958dd59ba8be7a9.pdf,0,0,0
1278374,In vivo three‐dimensional reconstruction of rat brain axonal projections by diffusion tensor imaging,1999,Rong Xue and Peter CM van Zijl and Barbara J Crain and Meiyappan Solaiyappan and Susumu Mori,42,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,6,1123-1127,John Wiley & Sons. Inc.,The in situ assessment of axonal projections of the brain has been severely limited by the lack of noninvasive techniques to study this type of anatomy. We show here that in vivo three‐dimensional (3D) reconstruction of axonal projections can be achieved using a rapid 3D high‐resolution diffusion‐weighted imaging technique combined with a recently designed fiber reconstruction algorithm. As a first example. neuronal pathways in the rat brain were probed. Eight well‐known fiber projections; genu and splenium of corpus callosum. internal and external capsule. fimbria. anterior commissure. optic tract. and stria terminalis were tracked and shown to be in agreement with the location of these known axonal projections. The experiment took 2 hr and shorter times should be possible in the clinical situation. By combining anisotropy information with fiber tracking. the anisotropy of individual projections was also …,True,cn4ifN0AAAAJ:RGFaLdJalmkC,464,https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1522-2594(199912)42:6%3C1123::AID-MRM17%3E3.0.CO;2-H,15258510794507127816,/scholar?cites=15258510794507127816,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/%28SICI%291522-2594%28199912%2942%3A6%3C1123%3A%3AAID-MRM17%3E3.0.CO%3B2-H,0,0,0
1278375,Brain white matter anatomy of tumor patients evaluated with diffusion tensor imaging,2002,Susumu Mori and Kim Frederiksen and Peter CM van Zijl and Bram Stieltjes and Michael A Kraut and Meiyappan Solaiyappan and Martin G Pomper,51,Annals of Neurology: Official Journal of the American Neurological Association and the Child Neurology Society,3,377-380,Wiley Subscription Services. Inc.. A Wiley Company,We applied multislice. whole‐brain diffusion tensor imaging (DTI) to two patients with anaplastic astrocytoma. Data were analyzed using DTI‐based. color‐coded images and a 3‐D tract reconstruction technique for the study of altered white matter anatomy. Each tumor was near two major white matter tracts. namely. the superior longitudinal fasciculus and the corona radiata. Those tracts were identified using the color‐coded maps. and spatial relationships with the tumors were characterized. In one patient the tumor displaced adjacent white matter tracts. whereas in the other it infiltrated the superior longitudinal fasciclus without displacement of white matter. DTI provides new information regarding the detailed relationship between tumor growth and nearby white matter tracts. which may be useful for preoperative planning.,True,cn4ifN0AAAAJ:IWHjjKOFINEC,353,https://onlinelibrary.wiley.com/doi/abs/10.1002/ana.10137,9281870482669514294,/scholar?cites=9281870482669514294,,,https://openaccess.leidenuniv.nl/bitstream/handle/1887/18190/01%20opmaak%20proefschrift%20kompleet.pdf?sequence=1,0,0,0
1278376,Diffusion tensor imaging of the developing mouse brain,2001,Susumu Mori and Ryuta Itoh and Jiangyang Zhang and Walter E Kaufmann and Peter CM Van Zijl and Meiyappan Solaiyappan and Paul Yarowsky,46,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,1,18-23,John Wiley & Sons. Inc.,It is shown that diffusion tensor MR imaging (DTI) can discretely delineate the microstructure of white matter and gray matter in embryonic and early postnatal mouse brains based on the existence and orientation of ordered structures. This order was found not only in white matter but also in the cortical plate and the periventricular zone. which are precursors of the cerebral cortex. This DTI‐based information could be used to accomplish the automated spatial definition of the cortical plate and various axonal tracts. The DTI studies also revealed a characteristic evolution of diffusion anisotropy in the cortex of the developing brain. This ability to detect changes in the organization of the brain during development will greatly enhance morphological studies of transgenic and knockout models of cortical dysfunction. Magn Reson Med 46:18–23. 2001. © 2001 Wiley‐Liss. Inc.,True,cn4ifN0AAAAJ:5nxA0vEk-isC,268,https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1155,4953391096439715109,/scholar?cites=4953391096439715109,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.1155,0,0,0
1278377,Extracellular acidification alters lysosomal trafficking in human breast cancer cells,2003,Kristine Glunde and Sandra E Guggino and Meiyappan Solaiyappan and Arvind P Pathak and Yoshitaka Ichikawa and Zaver M Bhujwalla,5,Neoplasia,6,533-545,Elsevier,Cancer cells invade by secreting degradative enzymes. which are sequestered in lysosomal vesicles. In this study. the impact of an acidic extracellular environment on lysosome size. number. and distance from the nucleus in human mammary epithelial cells (HMECs) and breast cancer cells of different degrees of malignancy was characterized because the physiological microenvironment of tumors is frequently characterized by extracellular acidity. An acidic extracellular pH (pHe) resulted in a distinct shift of lysosomes from the perinuclear region to the cell periphery irrespective of the HMECs' degree of malignancy. With decreasing pH. larger lysosomal vesicles were observed more frequently in highly metastatic breast cancer cells. whereas smaller lysosomes were observed in poorly metastatic breast cancer cells and HMECs. The number of lysosomes decreased with acidic pH values. The displacement of …,True,cn4ifN0AAAAJ:35N4QoGY0k4C,265,https://www.sciencedirect.com/science/article/pii/S1476558603800374,16723916719217788065,/scholar?cites=16723916719217788065,,,https://www.sciencedirect.com/science/article/pii/S1476558603800374/pdf?md5=007b09b356220bc78be92191ad0c3eed&pid=1-s2.0-S1476558603800374-main.pdf,0,0,0
1278378,Simulation system for medical procedures,2004,James Anderson and Anthony Venbrux and Kieran Murphy and Meiyappan Solaiyappan and Chee-kong Chui and Zirui Li and Xin Ma and Zhen Wang and Jeremy Teo,,,,,,The invention provides a system for the simulation of image-guided medical procedures and methods of using the same. The system can be used for training and certification. pre-treatment planning. as well therapeutic device design. development and evaluation.,True,cn4ifN0AAAAJ:4OULZ7Gr8RgC,239,https://patents.google.com/patent/US20040009459A1/en,3478867510647519838,/scholar?cites=3478867510647519838,,,https://patentimages.storage.googleapis.com/40/4c/0c/14c6e418773e26/US20040009459A1.pdf,0,0,0
1278379,Diffusion tensor imaging of periventricular leukomalacia shows affected sensory cortex white matter pathways,2002,Alexander Holliday Hoon and WT Lawrie and ER Melhem and EM Reinhardt and PCM Van Zijl and Meiyappan Solaiyappan and Hangyi Jiang and Michael V Johnston and Susumu Mori,59,Neurology,5,752-756,Wolters Kluwer Health. Inc. on behalf of the American Academy of Neurology,The authors used diffusion-tensor imaging to examine central white matter pathways in two children with spastic quadriplegic cerebral palsy. Corticospinal tracts projecting from cortex to brainstem resembled controls. In contrast. posterior regions of the corpus callosum. internal capsule. and corona radiata were markedly reduced. primarily in white matter fibers connected to sensory cortex. These findings suggest that the motor impairment in periventricular leukomalacia may. in part. reflect disruption of sensory connections outside classic pyramidal motor pathways.,True,cn4ifN0AAAAJ:u5HHmVD_uO8C,206,https://n.neurology.org/content/59/5/752.short,421737804692527275,/scholar?cites=421737804692527275,,,,0,0,0
1278380,A framework for callosal fiber distribution analysis,2002,Dongrong Xu and Susumu Mori and Meiyappan Solaiyappan and Peter CM van Zijl and Christos Davatzikos,17,Neuroimage,3,1131-1143,Academic Press,This paper presents a framework for analyzing the spatial distribution of neural fibers in the brain. with emphasis on interhemispheric fiber bundles crossing through the corpus callosum. The proposed approach combines methodologies for fiber tracking and spatial normalization and is applied on diffusion tensor images and standard magnetic resonance images.,True,cn4ifN0AAAAJ:mB3voiENLucC,162,https://www.sciencedirect.com/science/article/pii/S1053811902912851,10502839747923079481,/scholar?cites=10502839747923079481,,,https://www.academia.edu/download/30638018/cc-fiber.pdf,0,0,0
1278381,Grad-CAM: Why did you say that?,2016,Ramprasaath R Selvaraju and Abhishek Das and Ramakrishna Vedantam and Michael Cogswell and Devi Parikh and Dhruv Batra,,,,,,We propose a technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing input regions that are'important'for predictions--or visual explanations. Our approach. called Gradient-weighted Class Activation Mapping (Grad-CAM). uses class-specific gradient information to localize important regions. These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided Grad-CAM. These methods help better understand CNN-based models. including image captioning and visual question answering (VQA) models. We evaluate our visual explanations by measuring their ability to discriminate between classes. to inspire trust in humans. and their correlation with occlusion maps. Grad-CAM provides a new way to understand CNN-based models.,True,v1CRzeAAAAAJ:zYLM7Y9cAGgC,4578,https://arxiv.org/abs/1611.07450,11803081582287838465,/scholar?cites=11803081582287838465,,,https://arxiv.org/pdf/1611.07450,0,0,0
1278382,CIDEr: Consensus-based Image Description Evaluation,2014,Ramakrishna Vedantam and C Lawrence Zitnick and Devi Parikh,,,,,IEEE,Automatically describing an image with a sentence is a long-standing challenge in computer vision and natural language processing. Due to recent progress in object detection. attribute classification. action recognition. etc.. there is renewed interest in this area. However. evaluating the quality of descriptions has proven to be challenging. We propose a novel paradigm for evaluating image descriptions that uses human consensus. This paradigm consists of three main parts: a new triplet-based method of collecting human annotations to measure consensus. a new automated metric that captures consensus. and two new datasets: PASCAL-50S and ABSTRACT-50S that contain 50 sentences describing each image. Our simple metric captures human judgment of consensus better than existing metrics across sentences generated by various sources. We also evaluate five state-of-the-art image description approaches using this new protocol and provide a benchmark for future comparisons. A version of CIDEr named CIDEr-D is available as a part of MS COCO evaluation server to enable systematic evaluation and benchmarking.,True,v1CRzeAAAAAJ:9yKSN-GCB0IC,1787,http://openaccess.thecvf.com/content_cvpr_2015/html/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.html,2428149707553201565,/scholar?cites=2428149707553201565,,,https://openaccess.thecvf.com/content_cvpr_2015/papers/Vedantam_CIDEr_Consensus-Based_Image_2015_CVPR_paper.pdf,0,0,0
1278383,Microsoft coco captions: Data collection and evaluation server,2015,Xinlei Chen and Hao Fang and Tsung-Yi Lin and Ramakrishna Vedantam and Saurabh Gupta and Piotr Dollár and C Lawrence Zitnick,,arXiv preprint arXiv:1504.00325,,,,In this paper we describe the Microsoft COCO Caption dataset and evaluation server. When completed. the dataset will contain over one and a half million captions describing over 330.000 images. For the training and validation images. five independent human generated captions will be provided. To ensure consistency in evaluation of automatic caption generation algorithms. an evaluation server is used. The evaluation server receives candidate captions and scores them using several popular metrics. including BLEU. METEOR. ROUGE and CIDEr. Instructions for using the evaluation server are provided.,True,v1CRzeAAAAAJ:2osOgNQ5qMEC,911,https://arxiv.org/abs/1504.00325,4232572309886474756,/scholar?cites=4232572309886474756,,,https://arxiv.org/pdf/1504.00325,0,0,0
1278384,Context-aware captions from context-agnostic supervision,2017,Ramakrishna Vedantam and Samy Bengio and Kevin Murphy and Devi Parikh and Gal Chechik,,,,,,"We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation). For example. given images and captions of"" siamese cat"" and"" tiger cat"". we generate language that describes the"" siamese cat"" in a way that distinguishes it from"" tiger cat"". Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts. We first apply our technique to a justification task. namely to describe why an image contains a particular fine-grained category as opposed to another closely-related category of the CUB-200-2011 dataset. We then study discriminative image captioning to generate language that uniquely refers to one of two semantically-similar images in the COCO dataset. Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning reveal that our approach outperforms baseline generative and speaker-listener approaches for discrimination.",True,v1CRzeAAAAAJ:Y0pCki6q_DkC,98,http://openaccess.thecvf.com/content_cvpr_2017/html/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.html,89318584606928440,/scholar?cites=89318584606928440,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf,0,0,0
1278385,Counting Everyday Objects in Everyday Scenes,2016,Prithvijit Chattopadhyay and Ramakrishna Vedantam and RS Ramprasaath and Dhruv Batra and Devi Parikh,,,,,,We are interested in counting the number of instances of object classes in natural. everyday images. Previous counting approaches tackle the problem in restricted domains such as counting pedestrians in surveillance videos. Counts can also be estimated from outputs of other vision tasks like object detection. In this work. we build dedicated models for counting designed to tackle the large variance in counts. appearances. and scales of objects found in natural scenes. Our approach is inspired by the phenomenon of subitizing-the ability of humans to make quick assessments of counts given a perceptual signal. for small count values. Given a natural scene. we employ a divide and conquer strategy while incorporating context across the scene to adapt the subitizing idea to counting. Our approach offers consistent improvements over numerous baseline approaches for counting on the PASCAL VOC 2007 and COCO datasets. Subsequently. we study how counting can be used to improve object detection. We then show a proof of concept application of our counting methods to the task of Visual Question Answering. by studying the'how many?'questions in the VQA and COCO-QA datasets.,True,v1CRzeAAAAAJ:IjCSPb-OGe4C,87,http://openaccess.thecvf.com/content_cvpr_2017/html/Chattopadhyay_Counting_Everyday_Objects_CVPR_2017_paper.html,10721680110605566702,/scholar?cites=10721680110605566702,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Chattopadhyay_Counting_Everyday_Objects_CVPR_2017_paper.pdf,0,0,0
1278386,Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes,2015,Satwik Kottur and Ramakrishna Vedantam and José MF Moura and Devi Parikh,,,,,,"We propose a model to learn visually grounded word embeddings (vis-w2v) to capture visual notions of semantic relatedness. While word embeddings trained using text have been extremely successful. they cannot uncover notions of semantic relatedness implicit in our visual world. For instance. although"" eats"" and"" stares at"" seem unrelated in text. they share semantics visually. When people are eating something. they also tend to stare at the food. Grounding diverse relations like"" eats"" and"" stares at"" into vision remains challenging. despite recent progress in vision. We note that the visual grounding of words depends on semantics. and not the literal pixels. We thus use abstract scenes created from clipart to provide the visual grounding. We find that the embeddings we learn capture fine-grained. visually grounded notions of semantic relatedness. We show improvements over text-only word embeddings (word2vec) on three tasks: common-sense assertion classification. visual paraphrasing and text-based image retrieval. Our code and datasets are available online.",True,v1CRzeAAAAAJ:UeHWp8X0CEIC,84,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Kottur_Visual_Word2Vec_vis-w2v_CVPR_2016_paper.html,17580740875274395402,/scholar?cites=17580740875274395402,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kottur_Visual_Word2Vec_vis-w2v_CVPR_2016_paper.pdf,0,0,0
1278387,Learning Common Sense Through Visual Abstraction,2015,Ramakrishna Vedantam and Xiao Lin and Tanmay Batra and C Lawrence Zitnick and Devi Parikh,,,,,IEEE,Common sense is essential for building intelligent machines. While some commonsense knowledge is explicitly stated in human-generated text and can be learnt by mining the web. much of it is unwritten. It is often unnecessary and even unnatural to write about commonsense facts. While unwritten. this commonsense knowledge is not unseen! The visual world around us is full of structure modeled by commonsense knowledge. Can machines learn common sense simply by observing our visual world? Unfortunately. this requires automatic and accurate detection of objects. their attributes. poses. and interactions between objects. which remain challenging problems. Our key insight is that while visual common sense is depicted in visual content. it is the semantic features that are relevant and not low-level pixel information. In other words. photorealism is not necessary to learn common sense. We explore the use of human-generated abstract scenes made from clipart for learning common sense. In particular. we reason about the plausibility of an interaction or relation between a pair of nouns by measuring the similarity of the relation and nouns with other relations and nouns we have seen in abstract scenes. We show that the commonsense knowledge we learn is complementary to what can be learnt from sources of text.,True,v1CRzeAAAAAJ:qjMakFHDy7sC,83,http://openaccess.thecvf.com/content_iccv_2015/html/Vedantam_Learning_Common_Sense_ICCV_2015_paper.html,13030447060873087804,/scholar?cites=13030447060873087804,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Vedantam_Learning_Common_Sense_ICCV_2015_paper.pdf,0,0,0
1278388,Adopting abstract images for semantic scene understanding,2014,C Lawrence Zitnick and Ramakrishna Vedantam and Devi Parikh,,IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),,,IEEE,Relating visual information to its linguistic semantic meaning remains an open and challenging area of research. The semantic meaning of images depends on the presence of objects. their attributes and their relations to other objects. But precisely characterizing this dependence requires extracting complex visual information from an image. which is in general a difficult and yet unsolved problem. In this paper. we propose studying semantic information in abstract images created from collections of clip art. Abstract images provide several advantages over real images. They allow for the direct study of how to infer high-level semantic information. since they remove the reliance on noisy low-level object. attribute and relation detectors. or the tedious hand-labeling of real images. Importantly. abstract images also allow the ability to generate sets of semantically similar scenes. Finding analogous sets of real images that …,True,v1CRzeAAAAAJ:u-x6o8ySG0sC,79,https://ieeexplore.ieee.org/abstract/document/6942196/,10586426192776650300,/scholar?cites=10586426192776650300,,,,0,0,0
