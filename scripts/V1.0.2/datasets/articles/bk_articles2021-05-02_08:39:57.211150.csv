,title,pub_year,author,volume,journal,number,pages,publisher,abstract,filled,author_pub_id,num_citations,pub_url,cites_id,citedby_url,gsrank,author_id,eprint_url,got_citations,got_author_ids,author_ids
1277114,X-ray imaging and analysis techniques for quantifying pore-scale structure and processes in subsurface porous medium systems,2013,Dorthe Wildenschild and Adrian P Sheppard,51,Advances in Water Resources,,217-246,Elsevier,We report here on recent developments and advances in pore-scale X-ray tomographic imaging of subsurface porous media. Our particular focus is on immiscible multi-phase fluid flow. i.e.. the displacement of one immiscible fluid by another inside a porous material. which is of central importance to many natural and engineered processes. Multiphase flow and displacement can pose a rather difficult problem. both because the underlying physics is complex. and also because standard laboratory investigation reveals little about the mechanisms that control micro-scale processes. X-ray microtomographic imaging is a non-destructive technique for quantifying these processes in three dimensions within individual pores. and as we report here. with rapidly increasing spatial and temporal resolution.,True,erjGsWoAAAAJ:738O_yMBCRsC,897,https://www.sciencedirect.com/science/article/pii/S0309170812002060,8396149342328011481,/scholar?cites=8396149342328011481,,,https://ir.library.oregonstate.edu/downloads/t148fh81z,0,0,0
1277115,Image processing of multiphase images obtained via X‐ray microtomography: a review,2014,Steffen Schlüter and Adrian Sheppard and Kendra Brown and Dorthe Wildenschild,50,,4,3615-3639,,Easier access to X‐ray microtomography (μCT) facilities has provided much new insight from high‐resolution imaging for various problems in porous media research. Pore space analysis with respect to functional properties usually requires segmentation of the intensity data into different classes. Image segmentation is a nontrivial problem that may have a profound impact on all subsequent image analyses. This review deals with two issues that are neglected in most of the recent studies on image segmentation: (i) focus on multiclass segmentation and (ii) detailed descriptions as to why a specific method may fail together with strategies for preventing the failure by applying suitable image enhancement prior to segmentation. In this way. the presented algorithms become very robust and are less prone to operator bias. Three different test images are examined: a synthetic image with ground‐truth information. a …,True,erjGsWoAAAAJ:FkBsMxS_Bp0C,412,https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2014WR015256,16310805104678879256,/scholar?cites=16310805104678879256,,,https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/2014WR015256,0,0,0
1277116,Assessment of bone ingrowth into porous biomaterials using MICRO-CT,2007,Anthony C Jones and Christoph H Arns and Adrian P Sheppard and Dietmar W Hutmacher and Bruce K Milthorpe and Mark A Knackstedt,28,Biomaterials,15,2491-2504,Elsevier,The three-dimensional (3D) structure and architecture of biomaterial scaffolds play a critical role in bone formation as they affect the functionality of the tissue-engineered constructs. Assessment techniques for scaffold design and their efficacy in bone ingrowth studies require an ability to accurately quantify the 3D structure of the scaffold and an ability to visualize the bone regenerative processes within the scaffold structure. In this paper. a 3D micro-CT imaging and analysis study of bone ingrowth into tissue-engineered scaffold materials is described. Seven specimens are studied in this paper; a set of three specimens with a cellular structure. varying pore size and implant material. and a set of four scaffolds with two different scaffold designs investigated at early (4 weeks) and late (12 weeks) explantation times. The difficulty in accurately phase separating the multiple phases within a scaffold undergoing bone …,True,erjGsWoAAAAJ:9yKSN-GCB0IC,408,https://www.sciencedirect.com/science/article/pii/S0142961207001287,10860703513713312633,/scholar?cites=10860703513713312633,,,https://www.academia.edu/download/45697951/j.biomaterials.2007.01.04620160517-17606-fhfnhf.pdf,0,0,0
1277117,Techniques for image enhancement and segmentation of tomographic images of porous materials,2004,Adrian P Sheppard and Robert M Sok and Holger Averdunk,339,Physica A: Statistical mechanics and its applications,1-2,145-151,North-Holland,This article presents a three-stage approach. combining novel and traditional algorithms. for the segmentation of images of porous and composite materials obtained from X-ray tomography. The first stage is an anisotropic diffusion filter which removes noise while preserving significant features. The second stage applies the unsharp mask sharpening filter which enhances edges and partially reverses the smoothing that is often a consequence of tomographic reconstruction. The final stage uses a combination of watershed and active contour methods for segmentation of the grey-scale data. For the data sets we have analysed. this approach gives the highest quality results. In addition. it has been implemented on cluster-type parallel computers and applied to cubic images comprising up to 20003 voxels.,True,erjGsWoAAAAJ:qjMakFHDy7sC,389,https://www.sciencedirect.com/science/article/pii/S037843710400370X,5875249240698477462,/scholar?cites=5875249240698477462,,,https://www.researchgate.net/profile/Robert_Sok/publication/222625287_Techniques_for_Image_Enhancement_and_Segmentation_of_Tomographic_Images_of_Porous_Materials/links/5e91ac5f4585150839d2467f/Techniques-for-Image-Enhancement-and-Segmentation-of-Tomographic-Images-of-Porous-Materials.pdf,0,0,0
1277118,The correlation of pore morphology. interconnectivity and physical properties of 3D ceramic scaffolds with bone ingrowth,2009,Anthony C Jones and Christoph H Arns and Dietmar W Hutmacher and Bruce K Milthorpe and Adrian P Sheppard and Mark A Knackstedt,30,Biomaterials,7,1440-1451,Elsevier,In the design of tissue engineering scaffolds. design parameters including pore size. shape and interconnectivity. mechanical properties and transport properties should be optimized to maximize successful inducement of bone ingrowth. In this paper we describe a 3D micro-CT and pore partitioning study to derive pore scale parameters including pore radius distribution. accessible radius. throat radius. and connectivity over the pore space of the tissue engineered constructs. These pore scale descriptors are correlated to bone ingrowth into the scaffolds. Quantitative and visual comparisons show a strong correlation between the local accessible pore radius and bone ingrowth; for well connected samples a cutoff accessible pore radius of ∼100 μm is observed for ingrowth. The elastic properties of different types of scaffolds are simulated and can be described by standard cellular solids theory: (E/E0) = (ρ/ρs)n …,True,erjGsWoAAAAJ:eQOLeE2rZwMC,335,https://www.sciencedirect.com/science/article/pii/S014296120800817X,5794118549335089033,/scholar?cites=5794118549335089033,,,https://www.academia.edu/download/45697934/j.biomaterials.2008.10.05620160517-14842-13czk06.pdf,0,0,0
1277119,Morphological clues to wet granular pile stability,2008,Mario Scheel and Ralf Seemann and MDMM Brinkmann and Marco Di Michiel and Adrian Sheppard and Boris Breidenbach and Stephan Herminghaus,7,Nature materials,3,189-193,Nature Publishing Group,When a granular material such as sand is mixed with a certain amount of liquid. the surface tension of the latter bestows considerable stiffness to the material. which enables. for example. sand castles to be sculpted 1. 2. 3. 4. The geometry of the liquid interface within the granular pile is of extraordinary complexity and strongly varies with the liquid content 5. 6. 7. Surprisingly. the mechanical properties of the pile are largely independent of the amount of liquid 2. 8. 9. 10. 11. 12. 13 over a wide range 14. 15. 16. We resolve this puzzle with the help of X-ray microtomography. showing that the remarkable insensitivity of the mechanical properties to the liquid content is due to the particular organization of the liquid in the pile into open structures. For spherical grains. a simple geometric rule is established. which relates the macroscopic properties to the internal liquid morphologies. We present evidence that this concept is …,True,erjGsWoAAAAJ:LkGwnXOMwfcC,326,https://www.nature.com/articles/nmat2117,14123985458477426080,/scholar?cites=14123985458477426080,,,https://www.researchgate.net/profile/Mario_Scheel/publication/5588225_Morphological_clues_to_wet_granular_pilestability/links/53f619d90cf2888a74929a0b.pdf,0,0,0
1277120,Pore scale characterization of carbonates using X-ray microtomography,2005,Christoph H Arns and Fabrice Bauget and Ajay Limaye and Arthur Sakellariou and Timothy Senden and Adrian Sheppard and Robert Martin Sok and Val Pinczewski and Stig Bakke and Lars Inge Berge and Paul E Oren and Mark A Knackstedt,10,Spe Journal,04,475-484,OnePetro,A reservoir carbonate core plug has been imaged in 3D across a range of length scales using high-resolution X-ray microtomography. Data from the original 40-mm diameter plug was obtained at the vug scale and allows the size. shape. and spatial distribution of the disconnected vuggy porosity to be measured. Within the imaged volume over 32.000 separate vugs are identified and a broad vug size distribution is measured. Higher resolution images on subsets of the plug exhibit interconnected porosity and allow one to measure characteristic. intergranular pore size. Pore scale structure and petrophysical properties (permeability. drainage capillary pressure. formation factor. and NMR response) are derived directly on the highest resolution tomographic dataset. We show that data over a range of porosity can be computed from a single plug fragment. Data for the carbonate core is compared to results derived from …,True,erjGsWoAAAAJ:roLk4NBRz8UC,296,https://onepetro.org/SJ/article-abstract/10/04/475/112624,11791131481384728416,/scholar?cites=11791131481384728416,,,,0,0,0
1277121,Theory and algorithms for constructing discrete Morse complexes from grayscale digital images,2011,Vanessa Robins and Peter John Wood and Adrian P Sheppard,33,IEEE Transactions on pattern analysis and machine intelligence,8,1646-1658,IEEE,We present an algorithm for determining the Morse complex of a two or three-dimensional grayscale digital image. Each cell in the Morse complex corresponds to a topological change in the level sets (i.e.. a critical point) of the grayscale image. Since more than one critical point may be associated with a single image voxel. we model digital images by cubical complexes. A new homotopic algorithm is used to construct a discrete Morse function on the cubical complex that agrees with the digital image and has exactly the number and type of critical cells necessary to characterize the topological changes in the level sets. We make use of discrete Morse theory and simple homotopy theory to prove correctness of this algorithm. The resulting Morse complex is considerably simpler than the cubical complex originally used to represent the image and may be used to compute persistent homology.,True,erjGsWoAAAAJ:2P1L_qKh6hAC,227,https://ieeexplore.ieee.org/abstract/document/5766002/,5388488681100176321,/scholar?cites=5388488681100176321,,,"https://www.ljll.math.upmc.fr/~frey/papers/scientific%20visualisation/Robins%20V.,%20Theory%20and%20algorithms%20for%20constructing%20discrete%20Morse%20complexes%20from%20grayscale%20digital%20images.pdf",0,0,0
1277122,Polarized dark solitons in isotropic Kerr media,1997,Adrian P Sheppard and Yuri S Kivshar,55,Physical Review E,4,4773,American Physical Society,We characterize dark-type vector optical solitons of arbitrary polarization in isotropic. Kerr-type media by applying Hirota's method to the integrable Manakov model with a defocusing nonlinearity. We find that nonuniformly polarized solitons comprise a rich solution family that can be divided into two categories: dark-dark and dark-bright vector solitons. We consider the propagation dynamics and the interactions of these vector solitons by deriving multisoliton solutions. and show the existence of stationary bound states. a phenomenon not observed for scalar dark solitons.,True,erjGsWoAAAAJ:d1gkVwhDpl0C,215,https://journals.aps.org/pre/abstract/10.1103/PhysRevE.55.4773,6451639865268998984,/scholar?cites=6451639865268998984,,,https://pdfs.semanticscholar.org/e0e0/ed946b12e013ac0c535b6983c93709ea3c37.pdf,0,0,0
1277123,Analysis of 3D bone ingrowth into polymer scaffolds via micro-computed tomography imaging,2004,Anthony C Jones and Bruce Milthorpe and Holger Averdunk and Ajay Limaye and Tim J Senden and Arthur Sakellariou and Adrian P Sheppard and Rob M Sok and Mark A Knackstedt and Arthur Brandwood and Dennis Rohner and Dietmar W Hutmacher,25,Biomaterials,20,4947-4954,Elsevier,This paper illustrates the utility of micro-computed tomography (micro-CT) to study the process of tissue engineered bone growth. A micro-CT facility for imaging and visualising biomaterials in three dimensions (3D) is described. The facility is capable of acquiring 3D images made up of 20003 voxels on specimens up to 60 mm in extent with resolutions down to 2 μm. This allows the 3D structure of tissue engineered materials to be imaged across three orders of magnitude of detail. The capabilities of micro-CT are demonstrated by imaging the Haversian network within human femoral cortical bone (distal diaphysis) and bone ingrowth into a porous scaffold at varying resolutions. Phase identification combined with 3D visualisation enables one to observe the complex topology of the canalicular system of the cortical bone. Imaging of the tissue engineered bone at a scale of 1 cm and resolutions of 10 μm allows …,True,erjGsWoAAAAJ:2osOgNQ5qMEC,200,https://www.sciencedirect.com/science/article/pii/S0142961204000882,2255406182442230151,/scholar?cites=2255406182442230151,,,https://www.academia.edu/download/51927759/Analysis_of_3D_bone_ingrowth_into_polyme20170224-1407-1lsc8r6.pdf,0,0,0
1277124,Effect of fluid topology on residual nonwetting phase trapping: Implications for geologic CO2 sequestration,2013,Anna L Herring and Elizabeth J Harper and Linnéa Andersson and Adrian Sheppard and Brian K Bay and Dorthe Wildenschild,62,Advances in Water Resources,,47-58,Elsevier,This work examines the influence of initial (i.e. post drainage) nonwetting (NW) fluid topology on total residual (i.e. after imbibition) NW phase saturation. Brine and air (used as a proxy for supercritical CO2) flow experiments were performed on Bentheimer sandstone; results were quantified via imaging with X-ray computed microtomography (X-ray CMT). which allows for three dimensional. non-destructive. pore-scale analysis of the amount. distribution. and connectivity of NW phase fluid within the sandstone cores. In order to investigate the phenomenon of fluid connectivity and how it changes throughout flow processes. the Bentheimer sandstone results are compared to previously collected X-ray CMT data from similar experiments performed in a sintered glass bead column. a loose packed glass bead column. and a column packed with crushed tuff. This allows us to interpret the results in a broader sense from the …,True,erjGsWoAAAAJ:SdhP9T11ey4C,170,https://www.sciencedirect.com/science/article/pii/S0309170813001760,3583426826347463313,/scholar?cites=3583426826347463313,,,http://research.engr.oregonstate.edu/immiscibles/sites/research.engr.oregonstate.edu.immiscibles/files/Papers/Herring_topology_AWR_2013.pdf,0,0,0
1277125,Fast corner detection,1998,Miroslav Trajković and Mark Hedley,16,Image and vision computing,2,75-87,Elsevier,This paper describes a new corner detection algorithm. based on the property of corners that the change of image intensity should be high in all directions. Consequently. the corner response function (CRF) is computed as a minimum change of intensity over all possible directions. To compute the intensity change in an arbitrary direction an interpixel approximation is used. A multigrid approach is employed to reduce the computational complexity and to improve the quality of the detected corners. This algorithm. and other popular corner detectors. were evaluated and compared on the basis of their consistency. accuracy and speed using a range of images and video sequences. It was found that our algorithm performs well compared to the other algorithms. but it is significantly faster to compute.,True,_3ziW3EAAAAJ:TFP_iSt0sucC,694,https://www.sciencedirect.com/science/article/pii/S0262885697000565,8109544284038569377,/scholar?cites=8109544284038569377,,,http://pzs.dstu.dp.ua/ComputerGraphics/bibl/Fast_Corner_Detection.pdf,0,0,0
1277126,Automatic system for monitoring person requiring care and his/her caretaker,2005,Srinivas Gutta and Eric Cohen-Solal and Miroslav Trajkovic,,,,,,A monitoring system for an infant. child. invalid. or other person requiring care uses computer vision and hearing. and inputs of other modalities. to analyze the status of a caretaker and/or cared-for person and its environment. The conditions are classified as normal or alarm conditions and an informative alarm signal is generated which may include records of the vision audio and other inputs. The system also has the ability to solicit responses from the occupants to stimulate a classifiable input to reduce ambiguity in its state signal.,True,_3ziW3EAAAAJ:D03iK_w7-QYC,599,https://patents.google.com/patent/US6968294B2/en,12324975564606436933,/scholar?cites=12324975564606436933,,,https://patentimages.storage.googleapis.com/75/9a/46/e813dd6b88830a/US6968294.pdf,0,0,0
1277127,System to aid a driver to determine whether to change lanes,2002,Srinivas Gutta and Miroslav Trajkovic and Antonio Colmenarez,,,,,,A vehicular vision system to aid a driver of a vehicle to determine whether it is safe to change lanes includes a camera having a field of view such that the field of view corresponds to at least a portion of an area proximate the vehicle. The system also includes an object identifier electrically coupled to the camera. a distance determiner which determines a distance of the object which is in the field of the camera. and a display electrically coupled to the camera which displays an image generated by the camera and provides an indication of the type of object which is in the field of view of the camera and the distance of the object from the vehicle.,True,_3ziW3EAAAAJ:OU6Ihb5iCvQC,538,https://patents.google.com/patent/US6424273B1/en,14550183522618282877,/scholar?cites=14550183522618282877,,,https://patentimages.storage.googleapis.com/pdfs/US6424273.pdf,0,0,0
1277128,Ball throwing assistant,2003,Miroslav Trajkovic and Eric Cohen-Solal and Srinivas Gutta,,,,,,A ball-throwing machine includes a camera connected to a computer vision unit and a microphone connected to a speech-processing unit. The computer vision unit processes images from the camera to determine a user's position. and to detect user gestures from a predetermined repertoire of gestures. The speech-processing unit recognizes user vocal commands from a predetermined repertoire of commands. A computer receives information from a control panel. from the computer vision unit. from the speech-processing unit. and from a file describing the ballistic properties of the ball to be thrown. The computer accordingly determines a ball trajectory according to the user's position and parameters indicated by a combination of control-panel settings. user gestures. and user vocal commands. The computer then adjusts the direction. elevation. ball speed. and ball spin to conform to the determined trajectory. and …,True,_3ziW3EAAAAJ:SeFeTyx0c_EC,499,https://patents.google.com/patent/US6539931B2/en,10093267760123836901,/scholar?cites=10093267760123836901,,,https://patentimages.storage.googleapis.com/2a/1f/b1/0b90650370cc23/US6539931.pdf,0,0,0
1277129,A background model initialization algorithm for video surveillance,2001,Daniel Gutchess and M Trajkovics and Eric Cohen-Solal and Damian Lyons and Anil K Jain,1,,,733-740,IEEE,Many motion detection and tracking algorithms rely on the process of background subtraction. a technique which detects changes from a model of the background scene. We present a new algorithm for the purpose of background model initialization. The algorithm takes as input a video sequence in which moving objects are present. and outputs a statistical background model describing the static parts of the scene. Multiple hypotheses of the background value at each pixel are generated by locating periods of stable intensity in the sequence. The likelihood of each hypothesis is then evaluated using optical flow information from the neighborhood around the pixel. and the most likely hypothesis is chosen to represent the background. Our results are compared with those of several standard background modeling techniques using surveillance video of humans in indoor environments.,True,_3ziW3EAAAAJ:5ugPr518TE4C,371,https://ieeexplore.ieee.org/abstract/document/937598/,12238262889715509256,/scholar?cites=12238262889715509256,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.7767&rep=rep1&type=pdf,0,0,0
1277130,Computer vision based parking assistant,2004,Miroslav Trajkovic and Antonio J Colmenarez and Srinivas Gutta and Karen I Trovato,,,,,,A computer-based assisted parking system and method for parking a vehicle into a parking space includes at least one sensor arranged to sense a position of the vehicle to be parked in a predetermined area adjacent the vehicle; a sensing system for at least two-dimensional reconstruction of feedback received from the one sensor; a path planning system for determining whether positions of other vehicles adjacent the parking space provide sufficient clearance for the vehicle to be parked and providing a planned path indicating how the vehicle to be parked will be maneuvered; a control system for controlling maneuvering of the vehicle to be parked based on the planned path determined by the path planning system. and the control system controls vehicle steering. direction. speed. and application of brakes. so that the vehicle to be parked is maneuvered into the parking space. Alternatively. directions may be …,True,_3ziW3EAAAAJ:xtRiw3GOFMkC,327,https://patents.google.com/patent/US6683539B2/en,13832653488998109589,/scholar?cites=13832653488998109589,,,https://patentimages.storage.googleapis.com/3c/cd/23/f0bf07a802b053/US6683539.pdf,0,0,0
1277131,Automatic access to an automobile via biometrics,2002,Antonio Colmenarez and Srinivas Gutta and Miroslav Trajkovic,,,,,,A system and method for identifying persons who are authorized to activate one or more vehicle mechanisms uses both an implicit identification of a face and an explicit identification of speech or a gesture. This system and method enables identification to be performed where a single identification is otherwise unable to perform the identification for some reason and improves the reliability and accuracy of an identification so that only authorized persons can activate the vehicle mechanisms. Vehicle mechanisms that can be activated using this multimodal identification system and method include. for example. automatic locks. automatic windows. a trunk lock. a vehicle engine. outdoor or interior lights. and a vehicle alarm.,True,_3ziW3EAAAAJ:CHSYGLWDkRkC,252,https://patents.google.com/patent/US6498970B2/en,13867125245128270238,/scholar?cites=13867125245128270238,,,https://patentimages.storage.googleapis.com/0e/f9/e0/e115869e9b50a3/US6498970.pdf,0,0,0
1277132,Method and apparatus for controlling a media player based on user activity,2002,Srinivas Gutta and Antonio Colmenarez and Miroslav Trajkovic,,,,,,A media player controller is disclosed that monitors user activity and automatically controls a media player in response to predefined events. The disclosed media player controller includes one or more audio/visual mage capture devices focused on one or more users. The captured audio and video information is processed by the media player controller to identify one or more predefined events. A number of rules can be utilized to define various user events. such as when the user has left the room. is on the telephone or is otherwise paying attention to the media player. Each rule contains one or more conditions. and. optionally. a corresponding action-item that should be performed when the rule is satisfied. Upon detection of a predefined event. the corresponding action. if any. is performed by the media player controller.,True,_3ziW3EAAAAJ:nb7KW1ujOQ8C,233,https://patents.google.com/patent/US20020144259A1/en,14002549359444751149,/scholar?cites=14002549359444751149,,,https://patentimages.storage.googleapis.com/20/df/aa/3f9b2678f0970c/US20020144259A1.pdf,0,0,0
1277133,Method and apparatus for finding and updating user group preferences in an entertainment system,2004,Miroslav Trajkovic and Srinivas Gutta and Vasanth Philomin,,,,,,A system. method. and article of manufacture suitable for automatically generating recommendations of a set of entertainment options from a larger set of entertainment options based on user preferences for those options. In particular. the present invention relates to the field of automatically generating recommendations for viewing television programs based on past viewing patterns and preferences of a group of television viewers. all of whom are physically present in front of the television. The present invention creates a user group profile based on the expressed preferences of the user group or preferences implied by past viewing patterns of the user group. The recommendations may be based on the user group's preferences and viewing patterns for viewing during certain times of day or week or certain dates.,True,_3ziW3EAAAAJ:HDshCWvjkbEC,219,https://patents.google.com/patent/US20040003392A1/en,6988305736736280626,/scholar?cites=6988305736736280626,,,https://patentimages.storage.googleapis.com/eb/1b/17/f995836ec99259/US20040003392A1.pdf,0,0,0
1277134,Vehicular blind spot vision system,2002,Srinivas Gutta and Miroslav Trajkovic and Antonio Colmenarez,,,,,,A blind spot vision system for a vehicle includes a camera having a field of view. The camera is positioned on the vehicle such that the field of view corresponds with at least a portion of an area proximate the vehicle which is not visible to a driver while the driver looks in mirrors that are positioned on the vehicle. The system also includes an object identifier electrically coupled to the camera. a relative speed identifier which determines the relative speed of an object which is in the field of view of the camera. and a display electrically coupled to the camera which displays an image generated by the camera and provides an indication of the type of object identified by the object identifier which is in the field of view of the camera and displayed on the display.,True,_3ziW3EAAAAJ:KlAtU1dfN6UC,216,https://patents.google.com/patent/US6424272B1/en,4116915820862484282,/scholar?cites=4116915820862484282,,,https://patentimages.storage.googleapis.com/pdfs/US6424272.pdf,0,0,0
1277135,Space-conditioning control employing image-based detection of occupancy and use,2003,Srinivas Gutta and Miroslav Trajkovic and Antonio José Colmanarez,,,,,,Cameras and image processing techniques are applied to the control of HVAC systems. Occupancy is detected using head-counting or motion detection. Activities are recognized in images and image sequences by machine-recognition techniques. The nature of activities. the intensity of activities. the number of occupants and their activities. etc. are all inferred from images and image sequences and used to predict current loads and/or required control signals for regulating an HVAC system.,True,_3ziW3EAAAAJ:1sJd4Hv_s6UC,208,https://patents.google.com/patent/US6645066B2/en,13929956598783366423,/scholar?cites=13929956598783366423,,,https://patentimages.storage.googleapis.com/0d/cb/79/6be5b92bd016c3/US6645066.pdf,0,0,0
1277136,Hyperspectral pansharpening: A review,2015,Laetitia Loncan and Luis B De Almeida and José M Bioucas-Dias and Xavier Briottet and Jocelyn Chanussot and Nicolas Dobigeon and Sophie Fabre and Wenzhi Liao and Giorgio A Licciardi and Miguel Simoes and Jean-Yves Tourneret and Miguel Angel Veganzones and Gemine Vivone and Qi Wei and Naoto Yokoya,3,,3,27-46,IEEE,Pansharpening aims at fusing a panchromatic image with a multispectral one. to generate an image with the high spatial resolution of the former and the high spectral resolution of the latter. In the last decade. many algorithms have been presented in the literatures for pansharpening using multispectral data. With the increasing availability of hyperspectral systems. these methods are now being adapted to hyperspectral images. In this work. we compare new pansharpening techniques designed for hyperspectral data with some of the state-of-the-art methods for multispectral pansharpening. which have been adapted for hyperspectral data. Eleven methods from different classes (component substitution. multiresolution analysis. hybrid. Bayesian and matrix factorization) are analyzed. These methods are applied to three datasets and their effectiveness and robustness are evaluated with widely used performance …,True,vHgDZDMAAAAJ:pAkWuXOU-OoC,455,https://ieeexplore.ieee.org/abstract/document/7284770/,15742022215552168841,/scholar?cites=15742022215552168841,,,https://arxiv.org/pdf/1504.04531,0,0,0
1277137,Hyperspectral and multispectral image fusion based on a sparse representation,2015,Qi Wei and José Bioucas-Dias and Nicolas Dobigeon and Jean-Yves Tourneret,53,IEEE Transactions on Geoscience and Remote Sensing,7,3658-3668,IEEE,This paper presents a variational-based approach for fusing hyperspectral and multispectral images. The fusion problem is formulated as an inverse problem whose solution is the target image assumed to live in a lower dimensional subspace. A sparse regularization term is carefully designed. relying on a decomposition of the scene on a set of dictionaries. The dictionary atoms and the supports of the corresponding active coding coefficients are learned from the observed images. Then. conditionally on these dictionaries and supports. the fusion problem is solved via alternating optimization with respect to the target image (using the alternating direction method of multipliers) and the coding coefficients. Simulation results demonstrate the efficiency of the proposed algorithm when compared with state-of-the-art fusion methods.,True,vHgDZDMAAAAJ:yxmsSjX2EkcC,381,https://ieeexplore.ieee.org/abstract/document/7010915/,16799776301482973837,/scholar?cites=16799776301482973837,,,https://arxiv.org/pdf/1409.5729,0,0,0
1277138,Nonlinear unmixing of hyperspectral images: Models and algorithms,2013,Nicolas Dobigeon and Jean-Yves Tourneret and Cédric Richard and José Carlos M Bermudez and Stephen McLaughlin and Alfred O Hero,31,IEEE Signal Processing Magazine,1,82-94,IEEE,When considering the problem of unmixing hyperspectral images. most of the literature in the geoscience and image processing areas relies on the widely used linear mixing model (LMM). However. the LMM may be not valid. and other nonlinear models need to be considered. for instance. when there are multiscattering effects or intimate interactions. Consequently. over the last few years. several significant contributions have been proposed to overcome the limitations inherent in the LMM. In this article. we present an overview of recent advances in nonlinear unmixing modeling.,True,vHgDZDMAAAAJ:a3BOlSfXSfwC,362,https://ieeexplore.ieee.org/abstract/document/6678284/,18093796706333405686,/scholar?cites=18093796706333405686,,,https://arxiv.org/pdf/1304.1875,0,0,0
1277139,Nonlinear unmixing of hyperspectral images using a generalized bilinear model,2011,Abderrahim Halimi and Yoann Altmann and Nicolas Dobigeon and Jean-Yves Tourneret,49,IEEE Transactions on Geoscience and Remote Sensing,11,4153-4162,IEEE,Nonlinear models have recently shown interesting properties for spectral unmixing. This paper studies a generalized bilinear model and a hierarchical Bayesian algorithm for unmixing hyperspectral images. The proposed model is a generalization not only of the accepted linear mixing model but also of a bilinear model that has been recently introduced in the literature. Appropriate priors are chosen for its parameters to satisfy the positivity and sum-to-one constraints for the abundances. The joint posterior distribution of the unknown parameter vector is then derived. Unfortunately. this posterior is too complex to obtain analytical expressions of the standard Bayesian estimators. As a consequence. a Metropolis-within-Gibbs algorithm is proposed. which allows samples distributed according to this posterior to be generated and to estimate the unknown model parameters. The performance of the resulting unmixing …,True,vHgDZDMAAAAJ:ufrVoPGSRksC,360,https://ieeexplore.ieee.org/abstract/document/5702384/,6701413814955599052,/scholar?cites=6701413814955599052,,,https://oatao.univ-toulouse.fr/5046/1/Halimi_5046.pdf,0,0,0
1277140,Joint Bayesian endmember extraction and linear unmixing for hyperspectral imagery,2009,Nicolas Dobigeon and Saïd Moussaoui and Martial Coulon and Jean-Yves Tourneret and Alfred O Hero,57,IEEE Transactions on Signal Processing,11,4355-4368,IEEE,This paper studies a fully Bayesian algorithm for endmember extraction and abundance estimation for hyperspectral imagery. Each pixel of the hyperspectral image is decomposed as a linear combination of pure endmember spectra following the linear mixing model. The estimation of the unknown endmember spectra is conducted in a unified manner by generating the posterior distribution of abundances and endmember parameters under a hierarchical Bayesian model. This model assumes conjugate prior distributions for these parameters. accounts for nonnegativity and full-additivity constraints. and exploits the fact that the endmember proportions lie on a lower dimensional simplex. A Gibbs sampler is proposed to overcome the complexity of evaluating the resulting posterior distribution. This sampler generates samples distributed according to the posterior distribution and estimates the unknown parameters …,True,vHgDZDMAAAAJ:d1gkVwhDpl0C,352,https://ieeexplore.ieee.org/abstract/document/5256272/,7947816586021507637,/scholar?cites=7947816586021507637,,,https://arxiv.org/pdf/0903.3060,0,0,0
1277141,Semi-supervised linear spectral unmixing using a hierarchical Bayesian model for hyperspectral imagery,2008,Nicolas Dobigeon and Jean-Yves Tourneret and Chein-I Chang,56,IEEE Transactions on Signal Processing,7,2684-2695,IEEE,This paper proposes a hierarchical Bayesian model that can be used for semi-supervised hyperspectral image unmixing. The model assumes that the pixel reflectances result from linear combinations of pure component spectra contaminated by an additive Gaussian noise. The abundance parameters appearing in this model satisfy positivity and additivity constraints. These constraints are naturally expressed in a Bayesian context by using appropriate abundance prior distributions. The posterior distributions of the unknown model parameters are then derived. A Gibbs sampler allows one to draw samples distributed according to the posteriors of interest and to estimate the unknown abundances. An extension of the algorithm is finally studied for mixtures with unknown numbers of spectral components belonging to a know library. The performance of the different unmixing strategies is evaluated via simulations …,True,vHgDZDMAAAAJ:u5HHmVD_uO8C,225,https://ieeexplore.ieee.org/abstract/document/4545260/,6071171652237661569,/scholar?cites=6071171652237661569,,,https://oatao.univ-toulouse.fr/803/1/dobigeon_803.pdf,0,0,0
1277142,Fast fusion of multi-band images based on solving a Sylvester equation,2015,Qi Wei and Nicolas Dobigeon and Jean-Yves Tourneret,24,IEEE Transactions on Image Processing,11,4109-4121,IEEE,This paper proposes a fast multi-band image fusion algorithm. which combines a high-spatial low-spectral resolution image and a low-spatial high-spectral resolution image. The well admitted forward model is explored to form the likelihoods of the observations. Maximizing the likelihoods leads to solving a Sylvester equation. By exploiting the properties of the circulant and downsampling matrices associated with the fusion problem. a closed-form solution for the corresponding Sylvester equation is obtained explicitly. getting rid of any iterative update step. Coupled with the alternating direction method of multipliers and the block coordinate descent method. the proposed algorithm can be easily generalized to incorporate prior information for the fusion problem. allowing a Bayesian estimator. Simulation results show that the proposed algorithm achieves the same performance as the existing algorithms with the …,True,vHgDZDMAAAAJ:U_HPUtbDl20C,205,https://ieeexplore.ieee.org/abstract/document/7163298/,7819550820466409235,/scholar?cites=7819550820466409235,,,https://arxiv.org/pdf/1502.03121,0,0,0
1277143,Ship and oil-spill detection using the degree of polarization in linear and hybrid/compact dual-pol SAR,2012,Reza Shirvany and Marie Chabert and Jean-Yves Tourneret,5,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,3,885-892,IEEE,Monitoring and detection of ships and oil spills using synthetic aperture radar (SAR) have received a considerable attention over the past few years. notably due to the wide area coverage and day and night all-weather capabilities of SAR systems. Among different polarimetric SAR modes. dual-pol SAR data are widely used for monitoring large ocean and coastal areas. The degree of polarization (DoP) is a fundamental quantity characterizing a partially polarized electromagnetic field. with significantly less computational complexity. readily adaptable for on-board implementation. compared with other well-known polarimetric discriminators. The performance of the DoP is studied for joint ship and oil-spill detection under different polarizations in hybrid/compact and linear dual-pol SAR imagery. Experiments are performed on RADARSAT-2 C-band polarimetric data sets. over San Francisco Bay. and L -band NASA …,True,vHgDZDMAAAAJ:xtoqd-5pKcoC,198,https://ieeexplore.ieee.org/abstract/document/6152171/,9988018724922750756,/scholar?cites=9988018724922750756,,,https://oatao.univ-toulouse.fr/6212/1/Shirvany_6212.pdf,0,0,0
1277144,Supervised nonlinear spectral unmixing using a postnonlinear mixing model for hyperspectral imagery,2012,Yoann Altmann and Abderrahim Halimi and Nicolas Dobigeon and Jean-Yves Tourneret,21,IEEE Transactions on Image Processing,6,3017-3025,IEEE,This paper presents a nonlinear mixing model for hyperspectral image unmixing. The proposed model assumes that the pixel reflectances are nonlinear functions of pure spectral components contaminated by an additive white Gaussian noise. These nonlinear functions are approximated using polynomial functions leading to a polynomial postnonlinear mixing model. A Bayesian algorithm and optimization methods are proposed to estimate the parameters involved in the model. The performance of the unmixing strategies is evaluated by simulations conducted on synthetic and real data.,True,vHgDZDMAAAAJ:u_35RYKgDlwC,189,https://ieeexplore.ieee.org/abstract/document/6151825/,12066260718945701373,/scholar?cites=12066260718945701373,,,https://oatao.univ-toulouse.fr/5623/1/altmann_5623.pdf,0,0,0
1277145,An affine combination of two LMS adaptive filters—transient mean-square analysis,2008,Neil J Bershad and José Carlos M Bermudez and Jean-Yves Tourneret,56,IEEE Transactions on Signal Processing,5,1853-1864,IEEE,This paper studies the statistical behavior of an affine combination of the outputs of two least mean-square (LMS) adaptive filters that simultaneously adapt using the same white Gaussian inputs. The purpose of the combination is to obtain an LMS adaptive filter with fast convergence and small steady-state mean-square deviation (MSD). The linear combination studied is a generalization of the convex combination. in which the combination factor lambda(n) is restricted to the interval (0.1). The viewpoint is taken that each of the two filters produces dependent estimates of the unknown channel. Thus. there exists a sequence of optimal affine combining coefficients which minimizes the mean-square error (MSE). First. the optimal unrealizable affine combiner is studied and provides the best possible performance for this class. Then two new schemes are proposed for practical applications. The mean-square …,True,vHgDZDMAAAAJ:u-x6o8ySG0sC,172,https://ieeexplore.ieee.org/abstract/document/4476036/,12620856405932342423,/scholar?cites=12620856405932342423,,,https://oatao.univ-toulouse.fr/361/2/Tourneret_361.pdf,0,0,0
1277146,Bayesian estimation of linear mixtures using the normal compositional model. Application to hyperspectral imagery,2010,Olivier Eches and Nicolas Dobigeon and Corinne Mailhes and Jean-Yves Tourneret,19,IEEE Transactions on Image Processing,6,1403-1413,IEEE,This paper studies a new Bayesian unmixing algorithm for hyperspectral images. Each pixel of the image is modeled as a linear combination of so-called endmembers. These endmembers are supposed to be random in order to model uncertainties regarding their knowledge. More precisely. we model endmembers as Gaussian vectors whose means have been determined using an endmember extraction algorithm such as the famous N-finder (N-FINDR) or Vertex Component Analysis (VCA) algorithms. This paper proposes to estimate the mixture coefficients (referred to as abundances) using a Bayesian algorithm. Suitable priors are assigned to the abundances in order to satisfy positivity and additivity constraints whereas conjugate priors are chosen for the remaining parameters. A hybrid Gibbs sampler is then constructed to generate abundance and variance samples distributed according to the joint posterior of …,True,vHgDZDMAAAAJ:8k81kl-MbHgC,166,https://ieeexplore.ieee.org/abstract/document/5427031/,8868828552744115431,/scholar?cites=8868828552744115431,,,https://oatao.univ-toulouse.fr/4089/1/Eches_4089.pdf,0,0,0
1277147,Hazardous effects of chemical pesticides on human health–Cancer and other associated disorders,2018,Akash Sabarwal and Kunal Kumar and Rana P Singh,63,,,103-114,Elsevier,Poisoning from pesticides is a global public health problem and accounts for nearly 300.000 deaths worldwide every year. Exposure to pesticides is inevitable; there are different modes through which humans get exposed to pesticides. The mode of exposure is an important factor as it also signifies the concentration of pesticides exposure. Pesticides are used extensively in agricultural and domestic settings. These chemicals are believed to cause many disorders in humans and wildlife. Research from past few decades has tried to answer the associated mechanism of action of pesticides in conjunction with their harmful effects. This perspective considers the past and present research in the field of pesticides and associated disorders. We have reviewed the most common diseases including cancer which are associated with pesticides. Pesticides have shown to be involved in the pathogenesis of Parkinson’s and …,True,YN21TkEAAAAJ:lLDkS9sB7dAC,129,https://www.sciencedirect.com/science/article/pii/S1382668918303077,18021707649764580908,/scholar?cites=18021707649764580908,,,,0,0,0
1277148,Linguistic interval-valued atanassov intuitionistic fuzzy sets and their applications to group decision making problems,2019,Harish Garg and Kamal Kumar,27,IEEE Transactions on Fuzzy Systems,12,2302-2311,IEEE,In this paper. we propose the concept of a linguistic interval-valued Atanassov intuitionistic fuzzy set (LIVAIFS). whose membership and nonmembership degrees are represented by the interval-valued linguistic terms. for better dealing with imprecise and uncertain information during the decision-making process. In it. first some operational laws. score. and accuracy functions of LIVAIFS are defined with a brief study of related properties. Then. based on these operational laws. several aggregating operators are proposed to aggregate the linguistic interval-valued Atanassov intuitionistic fuzzy (LIVAIF) information. Some properties and inequalities are established to show the effectiveness and validity of proposed operators. Furthermore. a group decision making (GDM) approach. based on proposed operators. has been presented to solve the multiattribute GDM problems under LIVAIF environment. Finally. an …,True,YN21TkEAAAAJ:D3btL2lJ8W4C,123,https://ieeexplore.ieee.org/abstract/document/8636267/,17897919748762511286,/scholar?cites=17897919748762511286,,,,0,0,0
1277149,Fatty acids. tocols. and carotenoids in pulp oil of three sea buckthorn species (Hippophae rhamnoides. H. salicifolia. and H. tibetana) grown in the Indian Himalayas,2006,A Ranjith and K Sarin Kumar and VV Venugopalan and C Arumughan and RC Sawhney and Virendra Singh,83,Journal of the American Oil Chemists' Society,4,359-364,Springer‐Verlag,Sea buckthorn berries from Hippophae rhamnoides. H. tibetana. and H. salicifolia were collected from the cold deserts of the Himalayas (Lahaul. Ladakh. and Spiti; India) and characterized in terms of the FA. carotenoid. tocopherol. and tocotrienol composition in their pulp oil. These varied from species to species. Total carotenoids ranged from 692 to 3420 mg/kg in pulp oils of fresh berries. and total tocols. from 666 to 1788 mg/kg. Hippophae salicifolia berries contained substantially lower amounts of pulp oil. with lower levels of carotenoids and tocopherols. There was little difference in the proportion of individual tocols in pulp among the three species. α‐Tocopherol alone constituted 40–60% of total pulp tocols in berries. Pulp oils had palmitoleic acid (32–53%) as the most abundant FA followed by palmitic (25–35%). oleic (8–26%). linoleic (5–16%). and linolenic (0.6–2.6%) acids. with the highest deviation …,True,YN21TkEAAAAJ:8LfMcXwVQboC,123,https://aocs.onlinelibrary.wiley.com/doi/abs/10.1007/s11746-006-1213-z,12885201968346893984,/scholar?cites=12885201968346893984,,,https://www.academia.edu/download/46233199/s11746-006-1213-z20160604-21189-1mlg19r.pdf,0,0,0
1277150,Photocatalytic. optical and magnetic properties of Fe-doped ZnO nanoparticles prepared by chemical route,2014,Khanesh Kumar and Mansi Chitkara and Inderjit Singh Sandhu and D Mehta and Sanjeev Kumar,588,Journal of Alloys and Compounds,,681-689,Elsevier,Polyvinyl pyrrolidone (PVP) capped Zn1−xFexO (0.000001 ⩽ x ⩽ 0.1) nanocrystalline powders were prepared by chemical co-precipitation technique. Structural. optical and magnetic characterizations of the annealed samples were performed using X-ray powder diffraction (XRD). transmission electron microscope (TEM). energy dispersive X-ray fluorescence (EDXRF). Fourier-transform infrared (FTIR) spectroscopy. UV–visible spectrophotometry. photoluminescence (PL) and vibrating sample magnetometer (VSM) measurements. XRD and TEM studies reveal that the synthesized ZnO nanocrystals have hexagonal wurtzite structure with average crystalline size ∼8–15 nm. EDXRF and FTIR measurements confirmed the doping and incorporation of Fe impurities in ZnO nanostructures. Photocatalytic efficiency of the synthesized samples was determined by degradation of methylene blue (MB) dye in aqueous …,True,YN21TkEAAAAJ:BLjb4ZUULPkC,119,https://www.sciencedirect.com/science/article/pii/S0925838813028685,13906078657987222981,/scholar?cites=13906078657987222981,,,,0,0,0
1277151,Outbreak investigation of Nipah virus disease in Kerala. India. 2018,2019,Govindakarnavar Arunkumar and Radhakrishnan Chandni and Devendra T Mourya and Sujeet K Singh and Rajeev Sadanandan and Preeti Sudan and Balram Bhargava,219,The Journal of infectious diseases,12,1867-1878,Oxford University Press,Nipah Virus (NiV) is a highly fatal emerging zoonotic virus and a potential threat to global health security. Here we describe the characteristics of the NiV outbreak that occurred in Kerala. India. during May–June 2018.We used real-time reverse transcription polymerase chain reaction analysis of throat swab. blood. urine. and cerebrospinal fluid specimens to detect NiV. Further. the viral genome was sequenced and subjected to phylogenetic analysis. We conducted an epidemiologic investigation to describe the outbreak and elucidate the dynamics of NiV transmission.During 2–29 May 2018. 23 cases were identified. including the index case; 18 were laboratory confirmed. The lineage of the NiV responsible for this outbreak was closer to the Bangladesh lineage. The median age of cases was 45 years; the sex of 15 (65%) was …,True,YN21TkEAAAAJ:f0OD9WVUAbYC,115,https://academic.oup.com/jid/article-abstract/219/12/1867/5144922,17536214231312551011,/scholar?cites=17536214231312551011,,,https://www.researchgate.net/profile/Arunkumar_Govindakarnavar2/publication/328561135_Outbreak_Investigation_of_Nipah_Virus_Disease_in_Kerala_India_2018/links/5ef9cfed92851c52d606abde/Outbreak-Investigation-of-Nipah-Virus-Disease-in-Kerala-India-2018.pdf,0,0,0
1277152,Direct and pulse current electrodeposition of Ni–W–TiO2 nanocomposite coatings,2013,K Arunsunai Kumar and G Paruthimal Kalaignan and VS Muralidharan,39,Ceramics International,3,2827-2834,Elsevier,Ni–W–TiO2 nanocomposite coatings have been obtained on mild steel surface by direct current (DC) and pulse current (PC) electrodeposition from Watts bath containing an ammonical citrate complexing agent. The morphology of the coatings was explored by scanning electron microscopy (SEM). atomic force microscopy (AFM) and the composition of the electrodeposits was analyzed by energy dispersive X-ray analysis (EDX). Surface morphology studies revealed that Ni–W alloy surface was covered by long needle like crystals and Ni–W–TiO2 composite coatings with smaller spherical sized grains. The coated surface contained 25.55% W and 5.55% Ti. XRD studies revealed that (111) plane was predominant in both Ni–W alloy deposits and Ni–W–TiO2 composite coatings. The patterns of the electrodeposits confirmed only fcc frame work structure. Microhardness values increased with TiO2 addition in the alloy …,True,YN21TkEAAAAJ:23fPMagKWYUC,101,https://www.sciencedirect.com/science/article/pii/S0272884212009042,2228411073096000307,/scholar?cites=2228411073096000307,,,,0,0,0
1277153,A novel exponential distance and its based TOPSIS method for interval-valued intuitionistic fuzzy sets using connection number of SPA theory,2020,Harish Garg and Kamal Kumar,53,Artificial Intelligence Review,1,595-624,Springer Netherlands,The objective of this work is to present a novel multi-attribute decision making (MADM) method under interval-valued intuitionistic fuzzy (IVIF) set environment by integrating a Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method. Set pair analysis (SPA) theory is the modern uncertainty theory which is composed by the three components. namely “identity”. “discrepancy” and “contrary” degrees of the connection number (CN) and overlap with the various existing theories for handling the uncertainties in the data. Thus. motivated by this. in the present work. an attempt is made to enrich the theory of information measure by presented some exponential based distance measures using CNs of the IVIF sets. The supremacy of the proposed measure is also discussed. Afterward. a TOPSIS method based on the proposed distance measures is developed to solve MADM problem under IVIF …,True,YN21TkEAAAAJ:8m4wTQn51gQC,99,https://link.springer.com/article/10.1007/s10462-018-9668-5,13893198819069676016,/scholar?cites=13893198819069676016,,,,0,0,0
1277154,Magnetohydrodynamic Cattaneo-Christov flow past a cone and a wedge with variable heat source/sink,2018,K Anantha Kumar and JV Ramana Reddy and V Sugunamma and N Sandeep,57,Alexandria engineering journal,1,435-443,Elsevier,In the present article. the problem of boundary layer flow of MHD electrically conducting fluid past a cone and a wedge with non-uniform heat source/sink along with Cattaneo-Christov heat flux is investigated numerically. At first. the flow equations are converted into ODE via appropriate self similarity transforms and the resulting equations are solved with the assistance of R.-K. and Newton’s methods. The influence of several dimensionless parameters on velocity and temperature fields in addition to the friction factor and reduced heat transfer coefficient has been examined with the support of graphs and numerical values. The heat transfer phenomenon in the flow caused by the cone is excessive when compared to the wedge flow. Also. the thermal and momentum boundary layers are not the same for the flow over a cone and wedge.,True,YN21TkEAAAAJ:gTm0F0ptQfkC,88,https://www.sciencedirect.com/science/article/pii/S1110016816303118,10483336607196477353,/scholar?cites=10483336607196477353,,,https://www.sciencedirect.com/science/article/pii/S1110016816303118,0,0,0
1277155,Sensitive data security in cloud computing aid of different encryption techniques,2017,M Rajesh and K Sathesh Kumar and K Shankar and M Ilayaraja,18,Journal of Advanced Research in Dynamical and Control Systems,,2888-2899,,,True,YN21TkEAAAAJ:OGpmogZ47U0C,76,http://scholar.google.com/scholar?cluster=2665846097642008067&hl=en&oi=scholarr,2665846097642008067,/scholar?cites=2665846097642008067,,,,0,0,0
1277156,Real time face recognition using adaboost improved fast PCA algorithm,2011,K Susheel Kumar and Vijay Bhaskar Semwal and Ramesh Chandra Tripathi,,arXiv preprint arXiv:1108.1353,,,,This paper presents an automated system for human face recognition in a real time background world for a large homemade dataset of persons face. The task is very difficult as the real time background subtraction in an image is still a challenge. Addition to this there is a huge variation in human face image in terms of size. pose and expression. The system proposed collapses most of this variance. To detect real time human face AdaBoost with Haar cascade is used and a simple fast PCA and LDA is used to recognize the faces detected. The matched face is then used to mark attendance in the laboratory. in our case. This biometric system is a real time attendance system based on the human face recognition with a simple and fast algorithms and gaining a high accuracy rate..,True,YN21TkEAAAAJ:u5HHmVD_uO8C,74,https://arxiv.org/abs/1108.1353,11025866151024132589,/scholar?cites=11025866151024132589,,,https://arxiv.org/pdf/1108.1353,0,0,0
1277157,Applied Z-numbers,2015,Purvag Patel and Shahram Rahimi and Elham Khorasani,,,,1-6,IEEE,Z-number is an emerging paradigm that has been utilized in computing with words among others. The concept of a Z-number is intended to provide a basis for computation with numbers that deal with reliability and likelihood. Z-numbers are confluence between the two most prominent approaches to uncertainty. probability and possibility. which allow computations on complex statements. computations on Z-numbers require solving a complex optimization problem over the space of all possible probability distribution which leads in to its slow adoption to computing with words machinery. This paper seeks to provide an applied model of Z-numbers based on certain realistic assumptions regarding the probability distributions. An algorithm and example is presented to demonstrate the applicability of the model.,True,YN21TkEAAAAJ:wyCGhLAOp5UC,71,https://ieeexplore.ieee.org/abstract/document/7284154/,16701454520088924059,/scholar?cites=16701454520088924059,,,https://www.researchgate.net/profile/Heta_Patel5/publication/278307795_Polyaniline-anchored_palladium_catalyst-mediated_Mizoroki-Heck_and_Suzuki-Miyaura_reactions_and_one-pot_Wittig-Heck_and_Wittig-Suzuki_reactions/links/5bb5a2e445851574f7f7f8ac/Polyaniline-anchored-palladium-catalyst-mediated-Mizoroki-Heck-and-Suzuki-Miyaura-reactions-and-one-pot-Wittig-Heck-and-Wittig-Suzuki-reactions.pdf,0,0,0
1277158,Character recognition systems: a guide for students and practitioners,2007,Mohamed Cheriet and Nawwaf Kharma and Cheng-Lin Liu and Ching Suen,,,,,John Wiley & Sons,""" Much of pattern recognition theory and practice. including methods such as Support Vector Machines. has emerged in an attempt to solve the character recognition problem. This book is written by very well-known academics who have worked in the field for many years and have made significant and lasting contributions. The book will no doubt be of value to students and practitioners.""-Sargur N. Srihari. SUNY Distinguished Professor. Department of Computer Science and Engineering. and Director. Center of Excellence for Document Analysis and Recognition (CEDAR). University at Buffalo. The State University of New York"" The disciplines of optical character recognition and document image analysis have a history of more than forty years. In the last decade. the importance and popularity of these areas have grown enormously. Surprisingly. however. the field is not well covered by any textbook. This book has been written by prominent leaders in the field. It includes all important topics in optical character recognition and document analysis. and is written in a very coherent and comprehensive style. This book satisfies an urgent need. It is a volume the community has been awaiting for a long time. and I can enthusiastically recommend it to everybody working in the area.""-Horst Bunke. Professor. Institute of Computer Science and Applied Mathematics (IAM). University of Bern. Switzerland In Character Recognition Systems. the authors provide practitioners and students with the fundamental principles and state-of-the-art computational methods of reading printed texts and handwritten materials. The information presented is analogous to the …",True,oG89PhIAAAAJ:d1gkVwhDpl0C,504,http://books.google.com/books?hl=en&lr=&id=txYpjiK_BmgC&oi=fnd&pg=PR7&dq=info:6smz93Kgf_cJ:scholar.google.com&ots=dGdilWujox&sig=tnM2CflQ8seN8Gdgl3t8yk0_EK4,17834149465052924394,/scholar?cites=17834149465052924394,,,,0,0,0
1277159,A recursive thresholding technique for image segmentation,1998,Mohamed Cheriet and Joseph N Said and Ching Y Suen,7,IEEE transactions on image processing,6,918-921,IEEE,In this correspondence. we present a general recursive approach for image segmentation by extending Otsu's (1978) method. The new approach has been implemented in the scope of document images. specifically real-life bank checks. This approach segments the brightest homogeneous object from a given image at each recursion. leaving only the darkest homogeneous object after the last recursion. The major steps of the new technique and the experimental results that illustrate the importance and the usefulness of the new approach for the specified class of document images of bank checks is presented.,True,oG89PhIAAAAJ:u5HHmVD_uO8C,402,https://ieeexplore.ieee.org/abstract/document/679444/,4679443346090438125,/scholar?cites=4679443346090438125,,,https://core.ac.uk/download/pdf/187608527.pdf,0,0,0
1277160,“One against one” or “one against all”: Which one is better for handwriting recognition with SVMs?,2006,Jonathan Milgram and Mohamed Cheriet and Robert Sabourin,,,,,Suvisoft,The “one against one” and the “one against all” are the two most popular strategies for multi-class SVM; however. according to the literature review. it seems impossible to conclude which one is better for handwriting recognition. Thus. we compared these two classical strategies on two different handwritten character recognition problems. Several post-processing methods for estimating posterior probability were also evaluated and the results were compared with the ones obtained using MLP. Finally. the “one against all” strategy appears significantly more accurate for digit recognition. while the difference between the two strategies is much less obvious with upper-case letters. Besides. the “one against one” strategy is substantially faster to train and seems preferable for problems with a very large number of classes. To conclude. SVMs allow significantly better estimation of probabilities than MLP. which is promising from the point of view of their incorporation into handwriting recognition systems.,True,oG89PhIAAAAJ:0EnyYjriUFMC,330,https://hal.inria.fr/inria-00103955/,14995908974376229237,/scholar?cites=14995908974376229237,,,https://hal.inria.fr/docs/00/10/39/55/PDF/cr102875872670.pdf,0,0,0
1277161,AdOtsu: An adaptive and parameterless generalization of Otsu's method for document image binarization,2012,Reza Farrahi Moghaddam and Mohamed Cheriet,45,Pattern Recognition,6,2419-2431,Pergamon,Adaptive binarization methods play a central role in document image processing. In this work. an adaptive and parameterless generalization of Otsu's method is presented. The adaptiveness is obtained by combining grid-based modeling and the estimated background map. The parameterless behavior is achieved by automatically estimating the document parameters. such as the average stroke width and the average line height. The proposed method is extended using a multiscale framework. and has been applied on various datasets. including the DIBCO'09 dataset. with promising results.,True,oG89PhIAAAAJ:zLWjf1WUPmwC,234,https://www.sciencedirect.com/science/article/pii/S0031320311005140,7150396333454933302,/scholar?cites=7150396333454933302,,,https://www.academia.edu/download/51056851/AdOtsu_An_adaptive_and_parameterless_gen20161225-6471-1c37cyi.pdf,0,0,0
1277162,Automatic model selection for the optimization of SVM kernels,2005,Nedjem-Eddine Ayat and Mohamed Cheriet and Ching Y Suen,38,Pattern Recognition,10,1733-1745,Pergamon,This approach aims to optimize the kernel parameters and to efficiently reduce the number of support vectors. so that the generalization error can be reduced drastically. The proposed methodology suggests the use of a new model selection criterion based on the estimation of the probability of error of the SVM classifier. For comparison. we considered two more model selection criteria: GACV (‘Generalized Approximate Cross-Validation’) and VC (‘Vapnik-Chernovenkis’) dimension. These criteria are algebraic estimates of upper bounds of the expected error. For the former. we also propose a new minimization scheme. The experiments conducted on a bi-class problem show that we can adequately choose the SVM hyper-parameters using the empirical error criterion. Moreover. it turns out that the criterion produces a less complex model with fewer support vectors. For multi-class data. the optimization strategy is …,True,oG89PhIAAAAJ:9yKSN-GCB0IC,233,https://www.sciencedirect.com/science/article/pii/S0031320305001433,10924607475730414560,/scholar?cites=10924607475730414560,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.4640&rep=rep1&type=pdf,0,0,0
1277163,Databases for recognition of handwritten Arabic cheques,2003,Yousef Al-Ohali and Mohamed Cheriet and Ching Suen,36,Pattern Recognition,1,111-121,Pergamon,This paper describes an effort towards the development of Arabic cheque databases for research in the recognition of hand-written Arabic cheques. Databases of real-life Arabic legal amounts. Arabic sub-words. courtesy amounts. Indian digits. and Arabic cheques are described. This paper highlights some characteristics of the Arabic language and presents the various steps that have been completed to build these databases including segmentation. binarization and data tagging. It also describes a solid validation procedure including grammars and algorithms used to verify the correctness of the tagging process. Detailed descriptions of the database organization and class distribution are included. These databases aim to facilitate experimental comparisons between various recognition methods. and will be provided to all interested researchers upon request to CENPARMI.1,True,oG89PhIAAAAJ:2osOgNQ5qMEC,223,https://www.sciencedirect.com/science/article/pii/S003132030200064X,11217594157789732805,/scholar?cites=11217594157789732805,,,http://en.etsmtl.ca/ETS/media/ImagesETS/Labo/LIVIA/Publications/2003/Yousef.PR.pdf,0,0,0
1277164,Support vector machine.,2009,Mathias M Adankon and Mohamed Cheriet,,,,1303-1308,,,True,oG89PhIAAAAJ:OR75R8vi5nAC,203,http://scholar.google.com/scholar?cluster=1572931122820008249&hl=en&oi=scholarr,1572931122820008249,/scholar?cites=1572931122820008249,,,,0,0,0
1277165,A multi-scale framework for adaptive binarization of degraded document images,2010,Reza Farrahi Moghaddam and Mohamed Cheriet,43,Pattern Recognition,6,2186-2198,Pergamon,In this work. a multi-scale binarization framework is introduced. which can be used along with any adaptive threshold-based binarization method. This framework is able to improve the binarization results and to restore weak connections and strokes. especially in the case of degraded historical documents. This is achieved thanks to localized nature of the framework on the spatial domain. The framework requires several binarizations on different scales. which is addressed by introduction of fast grid-based models. This enables us to explore high scales which are usually unreachable to the traditional approaches. In order to expand our set of adaptive methods. an adaptive modification of Otsu's method. called AdOtsu. is introduced. In addition. in order to restore document images suffering from bleed-through degradation. we combine the framework with recursive adaptive methods. The framework shows promising …,True,oG89PhIAAAAJ:mVmsd5A6BfQC,200,https://www.sciencedirect.com/science/article/pii/S0031320310000117,4114698749743055061,/scholar?cites=4114698749743055061,,,,0,0,0
1277166,Model selection for the LS-SVM. Application to handwriting recognition,2009,Mathias M Adankon and Mohamed Cheriet,42,Pattern Recognition,12,3264-3270,Pergamon,The support vector machine (SVM) is a powerful classifier which has been used successfully in many pattern recognition problems. It has also been shown to perform well in the handwriting recognition field. The least squares SVM (LS-SVM). like the SVM. is based on the margin-maximization principle performing structural risk minimization. However. it is easier to train than the SVM. as it requires only the solution to a convex linear problem. and not a quadratic problem as in the SVM. In this paper. we propose to conduct model selection for the LS-SVM using an empirical error criterion. Experiments on handwritten character recognition show the usefulness of this classifier and demonstrate that model selection improves the generalization performance of the LS-SVM.,True,oG89PhIAAAAJ:8k81kl-MbHgC,196,https://www.sciencedirect.com/science/article/pii/S0031320308004494,5773706252341411636,/scholar?cites=5773706252341411636,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.5614&rep=rep1&type=pdf,0,0,0
1277167,Taxonomy of information security risk assessment (ISRA),2016,Alireza Shameli-Sendi and Rouzbeh Aghababaei-Barzegar and Mohamed Cheriet,57,Computers & security,,14-30,Elsevier Advanced Technology,Information is a perennially significant business asset in all organizations. Therefore. it must be protected as any other valuable asset. This is the objective of information security. and an information security program provides this kind of protection for a company's information assets and for the company as a whole. One of the best ways to address information security problems in the corporate world is through a risk-based approach. In this paper. we present a taxonomy of security risk assessment drawn from 125 papers published from 1995 to May 2014. Organizations with different size may face problems in selecting suitable risk assessment methods that satisfy their needs. Although many risk-based approaches have been proposed. most of them are based on the old taxonomy. avoiding the need for considering and applying the important criteria in assessing risk raised by rapidly changing technologies and the …,True,oG89PhIAAAAJ:RoXSNcbkSzsC,184,https://www.sciencedirect.com/science/article/pii/S0167404815001650,3068458740830685646,/scholar?cites=3068458740830685646,,,http://www.synchromedia.ca/fr/system/files/SurveyRisk.pdf,0,0,0
1277168,Building a new generation of handwriting recognition systems,1993,Ching Y Suen and Raymond Legault and C Nadal and Mohamed Cheriet and Louisa Lam,14,Pattern Recognition Letters,4,303-315,North-Holland,This paper gives an assessment of the current state of the art in handwriting recognition. It summarizes the lessons learned. the difficulties involved. and the challenges ahead. Based on a review of the recent achievements in off-line computer recognition of totally unconstrained handwritten characters. and extensive research. the authors attempt to identify new frontiers for research which may lead to further breakthroughs in this field. They will present some evidences and novel ideas on ways of stretching the limits of handwriting recognition systems aiming at outperforming human beings.,True,oG89PhIAAAAJ:u-x6o8ySG0sC,152,https://www.sciencedirect.com/science/article/pii/016786559390096V,15057559476035666611,/scholar?cites=15057559476035666611,,,,0,0,0
1277169,Hierarchical Saliency Detection,2013,Qiong Yan and Li Xu and Jianping Shi and Jiaya Jia,,,,,,When dealing with objects with complex structures. saliency detection confronts a critical problem namely that detection accuracy could be adversely affected if salient foreground or background in an image contains small-scale high-contrast patterns. This issue is common in natural images and forms a fundamental challenge for prior methods. We tackle it from a scale point of view and propose a multi-layer approach to analyze saliency cues. The final saliency map is produced in a hierarchical model. Different from varying patch sizes or downsizing images. our scale-based region handling is by finding saliency values optimally in a tree model. Our approach improves saliency detection on many images that cannot be handled well traditionally. A new dataset is also constructed.,True,Go9TaC4AAAAJ:_Re3VWB3Y0AC,1380,http://openaccess.thecvf.com/content_cvpr_2013/html/Yan_Hierarchical_Saliency_Detection_2013_CVPR_paper.html,13060765674207068563,/scholar?cites=13060765674207068563,,,https://openaccess.thecvf.com/content_cvpr_2013/papers/Yan_Hierarchical_Saliency_Detection_2013_CVPR_paper.pdf,0,0,0
1277170,Image smoothing via L0 gradient minimization,2011,Li Xu and Cewu Lu and Yi Xu and Jiaya Jia,,,,1-12,,We present a new image editing method. particularly effective for sharpening major edges by increasing the steepness of transition while eliminating a manageable degree of low-amplitude structures. The seemingly contradictive effect is achieved in an optimization framework making use of L 0 gradient minimization. which can globally control how many non-zero gradients are resulted in to approximate prominent structure in a sparsity-control manner. Unlike other edge-preserving smoothing approaches. our method does not depend on local features. but instead globally locates important edges. It. as a fundamental tool. finds many applications and is particularly beneficial to edge extraction. clip-art JPEG artifact removal. and non-photorealistic effect generation.,True,Go9TaC4AAAAJ:hkOj_22Ku90C,1201,https://dl.acm.org/doi/abs/10.1145/2024156.2024208,1714802875695779273,/scholar?cites=1714802875695779273,,,https://core.ac.uk/download/pdf/192706430.pdf,0,0,0
1277171,Two-phase kernel estimation for robust motion deblurring,2010,Li Xu and Jiaya Jia,,,,157-170,Springer Berlin/Heidelberg,We discuss a few new motion deblurring problems that are significant to kernel estimation and non-blind deconvolution. We found that strong edges do not always profit kernel estimation. but instead under certain circumstance degrade it. This finding leads to a new metric to measure the usefulness of image edges in motion deblurring and a gradient selection process to mitigate their possible adverse effect. We also propose an efficient and high-quality kernel estimation method based on using the spatial prior and the iterative support detection (ISD) kernel refinement. which avoids hard threshold of the kernel elements to enforce sparsity. We employ the TV-ℓ1 deconvolution model. solved with a new variable substitution scheme to robustly suppress noise.,True,Go9TaC4AAAAJ:tkaPQYYpVKoC,991,https://link.springer.com/chapter/10.1007/978-3-642-15549-9_12,14509807527174720212,/scholar?cites=14509807527174720212,,,https://link.springer.com/content/pdf/10.1007/978-3-642-15549-9_12.pdf,0,0,0
1277172,Unnatural L0 Sparse Representation for Natural Image Deblurring,2013,Li Xu and Shicheng Zheng and Jiaya Jia,,,,,,We show in this paper that the success of previous maximum a posterior (MAP) based blur removal methods partly stems from their respective intermediate steps. which implicitly or explicitly create an unnatural representation containing salient image structures. We propose a generalized and mathematically sound L 0 sparse expression. together with a new effective method. for motion deblurring. Our system does not require extra filtering during optimization and demonstrates fast energy decreasing. making a small number of iterations enough for convergence. It also provides a unified framework for both uniform and non-uniform motion deblurring. We extensively validate our method and show comparison with other approaches with respect to convergence speed. running time. and result quality.,True,Go9TaC4AAAAJ:tzM49s52ZIMC,816,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Xu_Unnatural_L0_Sparse_2013_CVPR_paper.html,15965510549443992967,/scholar?cites=15965510549443992967,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Xu_Unnatural_L0_Sparse_2013_CVPR_paper.pdf,0,0,0
1277173,Deep convolutional neural network for image deconvolution,2014,Li Xu and Jimmy S Ren and Ce Liu and Jiaya Jia,,,,1790-1798,,Many fundamental image-related problems involve deconvolution operators. Real blur degradation seldom complies with an ideal linear convolution model due to camera noise. saturation. image compression. to name a few. Instead of perfectly modeling outliers. which is rather challenging from a generative model perspective. we develop a deep convolutional neural network to capture the characteristics of degradation. We note directly applying existing deep neural networks does not produce reasonable results. Our solution is to establish the connection between traditional optimization-based schemes and a neural network architecture where a novel. separable structure is introduced as a reliable support for robust deconvolution against artifacts. Our network contains two submodules. both trained in a supervised manner with proper initialization. They yield decent performance on non-blind image deconvolution compared to previous generative-model based methods.,True,Go9TaC4AAAAJ:9Nmd_mFXekcC,729,http://www.cse.cuhk.edu.hk/leojia/papers/deconv_nips14.pdf,2895078575192815499,/scholar?cites=2895078575192815499,,,http://www.cse.cuhk.edu.hk/leojia/papers/deconv_nips14.pdf,0,0,0
1277174,Motion detail preserving optical flow estimation,2011,Li Xu and Jiaya Jia and Yasuyuki Matsushita,34,IEEE Transactions on Pattern Analysis and Machine Intelligence,9,1744-1757,IEEE,A common problem of optical flow estimation in the multiscale variational framework is that fine motion structures cannot always be correctly estimated. especially for regions with significant and abrupt displacement variation. A novel extended coarse-to-fine (EC2F) refinement framework is introduced in this paper to address this issue. which reduces the reliance of flow estimates on their initial values propagated from the coarse level and enables recovering many motion details in each scale. The contribution of this paper also includes adaptation of the objective function to handle outliers and development of a new optimization procedure. The effectiveness of our algorithm is demonstrated by Middlebury optical flow benchmarkmarking and by experiments on challenging examples that involve large-displacement motion.,True,Go9TaC4AAAAJ:dTyEYWd-f8wC,630,https://ieeexplore.ieee.org/abstract/document/6104059/,7337015950658177560,/scholar?cites=7337015950658177560,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.896&rep=rep1&type=pdf,0,0,0
1277175,Structure extraction from texture via relative total variation,2012,Li Xu and Qiong Yan and Yang Xia and Jiaya Jia,31,ACM transactions on graphics (TOG),6,1-10,ACM,"It is ubiquitous that meaningful structures are formed by or appear over textured surfaces. Extracting them under the complication of texture patterns. which could be regular. near-regular. or irregular. is very challenging. but of great practical importance. We propose new inherent variation and relative total variation measures. which capture the essential difference of these two types of visual forms. and develop an efficient optimization system to extract main structures. The new variation measures are validated on millions of sample patches. Our approach finds a number of new applications to manipulate. render. and reuse the immense number of ""structure with texture"" images and drawings that were traditionally difficult to be edited properly.",True,Go9TaC4AAAAJ:Fu2w8maKXqMC,592,https://dl.acm.org/doi/abs/10.1145/2366145.2366158,16701321002489345724,/scholar?cites=16701321002489345724,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.8478&rep=rep1&type=pdf,0,0,0
1277176,Rolling Guidance Filter,2014,Qi Zhang and Xiaoyong Shen and Li Xu and Jiaya Jia,,,,815-830,Springer International Publishing,Images contain many levels of important structures and edges. Compared to masses of research to make filters edge preserving. finding scale-aware local operations was seldom addressed in a practical way. albeit similarly vital in image processing and computer vision. We propose a new framework to filter images with the complete control of detail smoothing under a scale measure. It is based on a rolling guidance implemented in an iterative manner that converges quickly. Our method is simple in implementation. easy to understand. fully extensible to accommodate various data operations. and fast to produce results. Our implementation achieves realtime performance and produces artifact-free results in separating different scale structures. This filter also introduces several inspiring properties different from previous edge-preserving ones.,True,Go9TaC4AAAAJ:t7zJ5fGR-2UC,441,https://link.springer.com/chapter/10.1007/978-3-319-10578-9_53,14672980783181511723,/scholar?cites=14672980783181511723,,,https://link.springer.com/content/pdf/10.1007/978-3-319-10578-9_53.pdf,0,0,0
1277177,Hierarchical Saliency Detection on Extended CSSD,2015,Jianping Shi and Qiong Yan and Li Xu and Jiaya Jia,,IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),,,,,True,Go9TaC4AAAAJ:zLWjf1WUPmwC,325,,858785760572791699,/scholar?cites=858785760572791699,,,,0,0,0
1277178,Accurate single stage detector using recurrent rolling convolution,2017,Jimmy Ren and Xiaohao Chen and Jianbo Liu and Wenxiu Sun and Jiahao Pang and Qiong Yan and Yu-Wing Tai and Li Xu,,,,5420-5428,,"Most of the recent successful methods in accurate object detection and localization used some variants of R-CNN style two stage Convolutional Neural Networks (CNN) where plausible regions were proposed in the first stage then followed by a second stage for decision refinement. Despite the simplicity of training and the efficiency in deployment. the single stage detection methods have not been as competitive when evaluated in benchmarks consider mAP for high IoU thresholds. In this paper. we proposed a novel single stage end-to-end trainable object detection network to overcome this limitation. We achieved this by introducing Recurrent Rolling Convolution (RRC) architecture over multi-scale feature maps to construct object classifiers and bounding box regressors which are"" deep in context"". We evaluated our method in the challenging KITTI dataset which measures methods under IoU threshold of 0.7. We showed that with RRC. a single reduced VGG-16 based model already significantly outperformed all the previously published results. At the time this paper was written our models ranked the first in KITTI car detection (the hard level). the first in cyclist detection and the second in pedestrian detection. These results were not reached by the previous single stage methods. The code is publicly available.",True,Go9TaC4AAAAJ:VaXvl8Fpj5cC,223,http://openaccess.thecvf.com/content_cvpr_2017/html/Ren_Accurate_Single_Stage_CVPR_2017_paper.html,5780311761574416093,/scholar?cites=5780311761574416093,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Ren_Accurate_Single_Stage_CVPR_2017_paper.pdf,0,0,0
1277179,100+ Times Faster Weighted Median Filter (WMF),2014,Qi Zhang and Li Xu and Jiaya Jia,,,,,,Weighted median. in the form of either solver or filter. has been employed in a wide range of computer vision solutions for its beneficial properties in sparsity representation. But it is hard to be accelerated due to the spatially varying weight and the median property. We propose a few efficient schemes to reduce computation complexity from O (r^ 2) to O (r) where r is the kernel size. Our contribution is on a new joint-histogram representation. median tracking. and a new data structure that enables fast data access. The effectiveness of these schemes is demonstrated on optical flow estimation. stereo matching. structure-texture separation. image filtering. to name a few. The running time is largely shortened from several minutes to less than 1 second. The source code is provided in the project website.,True,Go9TaC4AAAAJ:uJ-U7cs_P_0C,194,http://openaccess.thecvf.com/content_cvpr_2014/html/Zhang_100_Times_Faster_2014_CVPR_paper.html,6942815381174840763,/scholar?cites=6942815381174840763,,,http://openaccess.thecvf.com/content_cvpr_2014/papers/Zhang_100_Times_Faster_2014_CVPR_paper.pdf,0,0,0
1277180,Structural studies by electron tomography: from cells to molecules,2005,Vladan Lučić and Friedrich Förster and Wolfgang Baumeister,74,,,833-865,Annual Reviews,Electron tomography (ET) is uniquely suited to obtain three-dimensional reconstructions of pleomorphic structures. such as cells. organelles or supramolecular assemblies. Although the principles of ET have been known for decades. its use has gathered momentum only in recent years. thanks to technological advances and its combination with improved specimen preparation techniques. The rapid freezing/freeze-substitution preparation is applicable to whole cells and tissues. and it is the method of choice for ET investigations of cellular ultrastructure. The frozen-hydrated preparation provides the best possible structural preservation and allows the imaging of molecules. complexes. and supramolecular assemblies in their native state and their natural environment. Devoid of staining and chemical fixation artifacts. cryo-ET provides a faithful representation of both the surface and internal structure of …,True,FsmrkEcAAAAJ:u5HHmVD_uO8C,700,https://www.annualreviews.org/doi/abs/10.1146/annurev.biochem.73.011303.074112,17061070629289126175,/scholar?cites=17061070629289126175,,,,0,0,0
1277181,Nuclear pore complex structure and dynamics revealed by cryoelectron tomography,2004,Martin Beck and Friedrich Förster and Mary Ecke and Jürgen M Plitzko and Frauke Melchior and Günther Gerisch and Wolfgang Baumeister and Ohad Medalia,306,Science,5700,1387-1390,American Association for the Advancement of Science,Nuclear pore complexes (NPCs) are gateways for nucleocytoplasmic exchange. To analyze their structure in a close-to-life state. we studied transport-active. intact nuclei from Dictyostelium discoideum by means of cryoelectron tomography. Subvolumes of the tomograms containing individual NPCs were extracted in silico and subjected to three-dimensional classification and averaging. whereby distinct structural states were observed. The central plug/transporter (CP/T) was variable in volume and could occupy different positions along the nucleocytoplasmic axis. which supports the notion that it essentially represents cargo in transit. Changes in the position of the CP/T were accompanied by structural rearrangements in the NPC scaffold.,True,FsmrkEcAAAAJ:u-x6o8ySG0sC,576,https://science.sciencemag.org/content/306/5700/1387.abstract,7910485079958808258,/scholar?cites=7910485079958808258,,,https://www.academia.edu/download/45548036/Nuclear_Pore_Complex_Structure_and_Dynam20160511-14520-1f0kmht.pdf,0,0,0
1277182,Molecular architecture of the 26S proteasome holocomplex determined by an integrative approach,2012,Keren Lasker and Friedrich Förster and Stefan Bohn and Thomas Walzthoeni and Elizabeth Villa and Pia Unverdorben and Florian Beck and Ruedi Aebersold and Andrej Sali and Wolfgang Baumeister,109,Proceedings of the National Academy of Sciences,5,1380-1387,National Academy of Sciences,The 26S proteasome is at the executive end of the ubiquitin-proteasome pathway for the controlled degradation of intracellular proteins. While the structure of its 20S core particle (CP) has been determined by X-ray crystallography. the structure of the 19S regulatory particle (RP). which recruits substrates. unfolds them. and translocates them to the CP for degradation. has remained elusive. Here. we describe the molecular architecture of the 26S holocomplex determined by an integrative approach based on data from cryoelectron microscopy. X-ray crystallography. residue-specific chemical cross-linking. and several proteomics techniques. The “lid” of the RP (consisting of Rpn3/5/6/7/8/9/11/12) is organized in a modular fashion. Rpn3/5/6/7/9/12 form a horseshoe-shaped heterohexamer. which connects to the CP and roofs the AAA-ATPase module. positioning the Rpn8/Rpn11 heterodimer close to its mouth. Rpn2 …,True,FsmrkEcAAAAJ:_kc_bZDykSQC,471,https://www.pnas.org/content/109/5/1380.short,15405734999083147441,/scholar?cites=15405734999083147441,,,https://www.pnas.org/content/pnas/109/5/1380.full.pdf,0,0,0
1277183,TOM software toolbox: acquisition and analysis for electron tomography,2005,Stephan Nickell and Friedrich Förster and Alexandros Linaroudis and William Del Net and Florian Beck and Reiner Hegerl and Wolfgang Baumeister and Jürgen M Plitzko,149,Journal of structural biology,3,227-234,Academic Press,Automated data acquisition procedures have changed the perspectives of electron tomography (ET) in a profound manner. Elaborate data acquisition schemes with autotuning functions minimize exposure of the specimen to the electron beam and sophisticated image analysis routines retrieve a maximum of information from noisy data sets. ‘TOM software toolbox’ integrates established algorithms and new concepts tailored to the special needs of low dose ET. It provides a user-friendly unified platform for all processing steps: acquisition. alignment. reconstruction. and analysis. Designed as a collection of computational procedures it is a complete software solution within a highly flexible framework. TOM represents a new way of working with the electron microscope and can serve as the basis for future high-throughput applications.,True,FsmrkEcAAAAJ:roLk4NBRz8UC,416,https://www.sciencedirect.com/science/article/pii/S104784770400187X,17807410600627798023,/scholar?cites=17807410600627798023,,,,0,0,0
1277184,Snapshots of nuclear pore complexes in action captured by cryo-electron tomography,2007,Martin Beck and Vladan Lučić and Friedrich Förster and Wolfgang Baumeister and Ohad Medalia,449,Nature,7162,611-615,Nature Publishing Group,Nuclear pore complexes reside in the nuclear envelope of eukaryotic cells and mediate the nucleocytoplasmic exchange of macromolecules 1. Traffic is regulated by mobile transport receptors that target their cargo to the central translocation channel. where phenylalanine-glycine-rich repeats serve as binding sites 2. The structural analysis of the nuclear pore is a formidable challenge given its size. its location in a membranous environment and its dynamic nature. Here we have used cryo-electron tomography 3 to study the structure of nuclear pore complexes in their functional environment. that is. in intact nuclei of Dictyostelium discoideum. A new image-processing strategy compensating for deviations of the asymmetric units (protomers) from a perfect eight-fold symmetry enabled us to refine the structure and to identify new features. Furthermore. the superposition of a large number of tomograms taken in the …,True,FsmrkEcAAAAJ:d1gkVwhDpl0C,363,https://www.nature.com/articles/nature06170,4119866242907851086,/scholar?cites=4119866242907851086,,,,0,0,0
1277185,Visualizing the molecular sociology at the HeLa cell nuclear periphery,2016,Julia Mahamid and Stefan Pfeffer and Miroslava Schaffer and Elizabeth Villa and Radostin Danev and Luis Kuhn Cuellar and Friedrich Förster and Anthony A Hyman and Jürgen M Plitzko and Wolfgang Baumeister,351,Science,6276,969-972,American Association for the Advancement of Science,The molecular organization of eukaryotic nuclear volumes remains largely unexplored. Here we combined recent developments in cryo–electron tomography (cryo-ET) to produce three-dimensional snapshots of the HeLa cell nuclear periphery. Subtomogram averaging and classification of ribosomes revealed the native structure and organization of the cytoplasmic translation machinery. Analysis of a large dynamic structure—the nuclear pore complex—revealed variations detectable at the level of individual complexes. Cryo-ET was used to visualize previously elusive structures. such as nucleosome chains and the filaments of the nuclear lamina. in situ. Elucidation of the lamina structure provides insight into its contribution to metazoan nuclear stiffness.,True,FsmrkEcAAAAJ:g5m5HwL7SMYC,331,https://science.sciencemag.org/content/351/6276/969.abstract,12009995566735348881,/scholar?cites=12009995566735348881,,,https://www.researchgate.net/profile/Julia_Mahamid/publication/297379331_Visualizing_the_molecular_sociology_at_the_HeLa_cell_nuclear_periphery/links/56e4543908ae98445c1ef470/Visualizing-the-molecular-sociology-at-the-HeLa-cell-nuclear-periphery.pdf,0,0,0
1277186,Retrovirus envelope protein complex structure in situ studied by cryo-electron tomography,2005,Friedrich Förster and Ohad Medalia and Nathan Zauberman and Wolfgang Baumeister and Deborah Fass,102,Proceedings of the National Academy of Sciences,13,4729-4734,National Academy of Sciences,We used cryo-electron tomography in conjunction with single-particle averaging techniques to study the structures of frozen-hydrated envelope glycoprotein (Env) complexes on intact Moloney murine leukemia retrovirus particles. Cryo-electron tomography allows 3D imaging of viruses in toto at a resolution sufficient to locate individual macromolecules. and local averaging of abundant complexes substantially improves the resolution. The averaging of repetitive features in electron tomograms is hampered by a low signal-to-noise ratio and anisotropic resolution. which results from the “missing-wedge” effect. We developed an iterative 3D averaging algorithm that compensates for this effect and used it to determine the trimeric structure of Env to a resolution of 2.7 nm. at which individual domains can be resolved. Strikingly. the 3D reconstruction is shaped like a tripod in which the trimer penetrates the membrane at …,True,FsmrkEcAAAAJ:2osOgNQ5qMEC,317,https://www.pnas.org/content/102/13/4729.short,12358480218671015594,/scholar?cites=12358480218671015594,,,https://www.pnas.org/content/pnas/102/13/4729.full.pdf,0,0,0
1277187,A molecular census of 26S proteasomes in intact neurons,2015,Shoh Asano and Yoshiyuki Fukuda and Florian Beck and Antje Aufderheide and Friedrich Förster and Radostin Danev and Wolfgang Baumeister,347,Science,6220,439-442,American Association for the Advancement of Science,The 26S proteasome is a key player in eukaryotic protein quality control and in the regulation of numerous cellular processes. Here. we describe quantitative in situ structural studies of this highly dynamic molecular machine in intact hippocampal neurons. We used electron cryotomography with the Volta phase plate. which allowed high fidelity and nanometer precision localization of 26S proteasomes. We undertook a molecular census of single- and double-capped proteasomes and assessed the conformational states of individual complexes. Under the conditions of the experiment—that is. in the absence of proteotoxic stress—only 20% of the 26S proteasomes were engaged in substrate processing. The remainder was in the substrate-accepting ground state. These findings suggest that in the absence of stress. the capacity of the proteasome system is not fully used.,True,FsmrkEcAAAAJ:NMxIlDl6LWMC,260,https://science.sciencemag.org/content/347/6220/439.abstract,15995180030808388308,/scholar?cites=15995180030808388308,,,,0,0,0
1277188,Identification of macromolecular complexes in cryoelectron tomograms of phantom cells,2002,Achilleas S Frangakis and Jochen Böhm and Friedrich Förster and Stephan Nickell and Daniela Nicastro and Dieter Typke and Reiner Hegerl and Wolfgang Baumeister,99,Proceedings of the National Academy of Sciences,22,14153-14158,National Academy of Sciences,Electron tomograms of intact frozen-hydrated cells are essentially three-dimensional images of the entire proteome of the cell. and they depict the whole network of macromolecular interactions. However. this information is not easily accessible because of the poor signal-to-noise ratio of the tomograms and the crowded nature of the cytoplasm. Here. we describe a template matching algorithm that is capable of detecting and identifying macromolecules in tomographic volumes in a fully automated manner. The algorithm is based on nonlinear cross correlation and incorporates elements of multivariate statistical analysis. Phantom cells. i.e.. lipid vesicles filled with macromolecules. provide a realistic experimental scenario for an assessment of the fidelity of this approach. At the current resolution of ≈4 nm. macromolecules in the size range of 0.5–1 MDa can be identified with good fidelity.,True,FsmrkEcAAAAJ:9yKSN-GCB0IC,260,https://www.pnas.org/content/99/22/14153.short,3998153250882781710,/scholar?cites=3998153250882781710,,,https://www.pnas.org/content/pnas/99/22/14153.full.pdf,0,0,0
1277189,Near-atomic resolution structural model of the yeast 26S proteasome,2012,Florian Beck and Pia Unverdorben and Stefan Bohn and Andreas Schweitzer and Günter Pfeifer and Eri Sakata and Stephan Nickell and Jürgen M Plitzko and Elizabeth Villa and Wolfgang Baumeister and Friedrich Förster,109,Proceedings of the National Academy of Sciences,37,14870-14875,National Academy of Sciences,The 26S proteasome operates at the executive end of the ubiquitin-proteasome pathway. Here. we present a cryo-EM structure of the Saccharomyces cerevisiae 26S proteasome at a resolution of 7.4 Å or 6.7 Å (Fourier-Shell Correlation of 0.5 or 0.3. respectively). We used this map in conjunction with molecular dynamics-based flexible fitting to build a near-atomic resolution model of the holocomplex. The quality of the map allowed us to assign α-helices. the predominant secondary structure element of the regulatory particle subunits. throughout the entire map. We were able to determine the architecture of the Rpn8/Rpn11 heterodimer. which had hitherto remained elusive. The MPN domain of Rpn11 is positioned directly above the AAA-ATPase N-ring suggesting that Rpn11 deubiquitylates substrates immediately following commitment and prior to their unfolding by the AAA-ATPase module. The MPN domain of …,True,FsmrkEcAAAAJ:mVmsd5A6BfQC,251,https://www.pnas.org/content/109/37/14870.short,9350479876690622375,/scholar?cites=9350479876690622375,,,https://www.pnas.org/content/pnas/109/37/14870.full.pdf,0,0,0
1277190,The mechanism of HIV-1 core assembly: insights from three-dimensional reconstructions of authentic virions,2006,John AG Briggs and Kay Grünewald and Bärbel Glass and Friedrich Förster and Hans-Georg Kräusslich and Stephen D Fuller,14,Structure,1,15-20,Cell Press,Infectious HIV particles contain a characteristic cone-shaped core encasing the viral RNA and replication proteins. The core exhibits significant heterogeneity in size and shape. yet consistently forms a well-defined structure. The mechanism by which the core is assembled in the maturing virion remains poorly understood. Using cryo-electron tomography. we have produced three-dimensional reconstructions of authentic. unstained HIV-1. These reveal the viral morphology with unprecedented clarity and suggest the following mechanism for core formation inside the extracellular virion: core growth initiates at the narrow end of the cone and proceeds toward the distal side of the virion until limited by the viral membrane. Curvature and closure of the broad end of the core are then directed by the inner surface of the viral membrane. This mechanism accommodates significant flexibility in lattice growth while ensuring the …,True,FsmrkEcAAAAJ:Se3iqnhoufwC,251,https://www.sciencedirect.com/science/article/pii/S0969212605003898,14000430885739030134,/scholar?cites=14000430885739030134,,,https://www.sciencedirect.com/science/article/pii/S0969212605003898,0,0,0
1277191,Face recognition by support vector machines,2000,Guodong Guo and Stan Z Li and Kapluk Chan,,,,196-201,IEEE,Support vector machines (SVM) have been recently proposed as a new technique for pattern recognition. SVM with a binary tree recognition strategy are used to tackle the face recognition problem. We illustrate the potential of SVM on the Cambridge ORL face database. which consists of 400 images of 40 individuals. containing quite a high degree of variability in expression. pose. and facial details. We also present the recognition experiment on a larger face database of 1079 images of 137 individuals. We compare the SVM-based recognition with the standard eigenface approach using the nearest center classification (NCC) criterion.,True,f2Y5nygAAAAJ:u5HHmVD_uO8C,804,https://ieeexplore.ieee.org/abstract/document/840634/,15586062931187567127,/scholar?cites=15586062931187567127,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.3694&rep=rep1&type=pdf,0,0,0
1277192,Age synthesis and estimation via faces: A survey,2010,Yun Fu and Guodong Guo and Thomas S Huang,32,,11,1955-1976,IEEE,Human age. as an important personal trait. can be directly inferred by distinct patterns emerging from the facial appearance. Derived from rapid advances in computer graphics and machine vision. computer-based age synthesis and estimation via faces have become particularly prevalent topics recently because of their explosively emerging real-world applications. such as forensic art. electronic customer relationship management. security control and surveillance monitoring. biometrics. entertainment. and cosmetology. Age synthesis is defined to rerender a face image aesthetically with natural aging and rejuvenating effects on the individual face. Age estimation is defined to label a face image automatically with the exact age (year) or the age group (year range) of the individual face. Because of their particularity and complexity. both problems are attractive yet challenging to computer-based application system …,True,f2Y5nygAAAAJ:Y0pCki6q_DkC,781,https://ieeexplore.ieee.org/abstract/document/5406526/,2830637384878687406,/scholar?cites=2830637384878687406,,,,0,0,0
1277193,Image-based human age estimation by manifold learning and locally adjusted robust regression,2008,Guodong Guo and Yun Fu and Charles R Dyer and Thomas S Huang,17,IEEE Transactions on Image Processing,7,1178-1188,IEEE,Estimating human age automatically via facial image analysis has lots of potential real-world applications. such as human computer interaction and multimedia communication. However. it is still a challenging problem for the existing computer vision systems to automatically and effectively estimate human ages. The aging process is determined by not only the person's gene. but also many external factors. such as health. living style. living location. and weather conditions. Males and females may also age differently. The current age estimation performance is still not good enough for practical use and more effort has to be put into this research direction. In this paper. we introduce the age manifold learning scheme for extracting face aging features and design a locally adjusted robust regressor for learning and prediction of human ages. The novel approach improves the age estimation accuracy significantly over all …,True,f2Y5nygAAAAJ:2osOgNQ5qMEC,745,https://ieeexplore.ieee.org/abstract/document/4531189/,982825392735928876,/scholar?cites=982825392735928876,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.216.7753&rep=rep1&type=pdf,0,0,0
1277194,Human age estimation using bio-inspired features,2009,Guodong Guo and Guowang Mu and Yun Fu and Thomas S Huang,,,,112-119,IEEE,We investigate the biologically inspired features (BIF) for human age estimation from faces. As in previous bio-inspired models. a pyramid of Gabor filters are used at all positions of the input image for the S 1  units. But unlike previous models. we find that the pre-learned prototypes for the S 2  layer and then progressing to C 2  cannot work well for age estimation. We also propose to use Gabor filters with smaller sizes and suggest to determine the number of bands and orientations in a problem-specific manner. rather than using a predefined number. More importantly. we propose a new operator “STD” to encode the aging subtlety on faces. Evaluated on the large database YGA with 8.000 face images and the public available FG-NET database. our approach achieves significant improvements in age estimation accuracy over the state-of-the-art methods. By applying our system to some Internet face images. we …,True,f2Y5nygAAAAJ:UeHWp8X0CEIC,622,https://ieeexplore.ieee.org/abstract/document/5206681/,10006792582144466770,/scholar?cites=10006792582144466770,,,https://projet.liris.cnrs.fr/imagine/pub/proceedings/CVPR-2009/data/papers/1186.pdf,0,0,0
1277195,Support vector machines for face recognition,2001,Guodong Guo and Stan Z Li and Kap Luk Chan,19,Image and Vision computing,9-10,631-638,Elsevier,Support vector machines (SVMs) have been recently proposed as a new learning network for bipartite pattern recognition. In this paper. SVMs incorporated with a binary tree recognition strategy are proposed to tackle the multi-class face recognition problem. The binary tree extends naturally. the pairwise discrimination capability of the SVMs to the multi-class scenario. Two face databases are used to evaluate the proposed method. The performance of the SVMs based face recognition is compared with the standard eigenface approach. and also the more recently proposed algorithm called the nearest feature line (NFL).,True,f2Y5nygAAAAJ:d1gkVwhDpl0C,619,https://www.sciencedirect.com/science/article/pii/S0262885601000464,11491850139122519216,/scholar?cites=11491850139122519216,,,,0,0,0
1277196,Content-based audio classification and retrieval by support vector machines,2003,Guodong Guo and Stan Z Li,14,IEEE transactions on Neural Networks,1,209-215,IEEE,Support vector machines (SVMs) have been recently proposed as a new learning algorithm for pattern recognition. In this paper. the SVMs with a binary tree recognition strategy are used to tackle the audio classification problem. We illustrate the potential of SVMs on a common audio database. which consists of 409 sounds of 16 classes. We compare the SVMs based classification with other popular approaches. For audio retrieval. we propose a new metric. called distance-from-boundary (DFB). When a query audio is given. the system first finds a boundary inside which the query pattern is located. Then. all the audio patterns in the database are sorted by their distances to this boundary. All boundaries are learned by the SVMs and stored together with the audio database. Experimental comparisons for audio retrieval are presented to show the superiority of this novel metric to other similarity measures.,True,f2Y5nygAAAAJ:u-x6o8ySG0sC,605,https://ieeexplore.ieee.org/abstract/document/1176140/,8474311131171225844,/scholar?cites=8474311131171225844,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.445.3243&rep=rep1&type=pdf,0,0,0
1277197,Learning similarity measure for natural image retrieval with relevance feedback,2002,Guo-Dong Guo and Anil K Jain and Wei-Ying Ma and Hong-Jiang Zhang,13,IEEE Transactions on Neural Networks,4,811-820,IEEE,A new scheme of learning similarity measure is proposed for content-based image retrieval (CBIR). It learns a boundary that separates the images in the database into two clusters. Images inside the boundary are ranked by their Euclidean distances to the query. The scheme is called constrained similarity measure (CSM). which not only takes into consideration the perceptual similarity between images. but also significantly improves the retrieval performance of the Euclidean distance measure. Two techniques. support vector machine (SVM) and AdaBoost from machine learning. are utilized to learn the boundary. They are compared to see their differences in boundary learning. The positive and negative examples used to learn the boundary are provided by the user with relevance feedback. The CSM metric is evaluated in a large database of 10009 natural images with an accurate ground truth. Experimental …,True,f2Y5nygAAAAJ:9yKSN-GCB0IC,314,https://ieeexplore.ieee.org/abstract/document/1021882/,16848833453836211329,/scholar?cites=16848833453836211329,,,http://neuron.csie.ntust.edu.tw/homework/94/neuron/Homework1/M9415055&M9415023/media%20indexing%20and%20retrieval/01021882.pdf,0,0,0
1277198,Fusing spatiotemporal features and joints for 3d action recognition,2013,Yu Zhu and Wenbin Chen and Guodong Guo,,,,486-491,,We present a novel approach to 3D human action recognition based on a feature-level fusion of spatiotemporal features and skeleton joints. First. 3D interest points detection and local feature description are performed to extract spatiotemporal motion information. Then the frame difference and pairwise distances of skeleton joint positions are computed to characterize the spatial information of the joints in 3D space. These two features are complementary to each other. A fusion scheme is then proposed to combine them effectively based on the random forests method. The proposed approach is validated on three challenging 3D action datasets for human action recognition. Experimental results show that the proposed approach outperforms the state-of-the-art methods on all three datasets.,True,f2Y5nygAAAAJ:pqnbT2bcN3wC,253,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W12/html/Zhu_Fusing_Spatiotemporal_Features_2013_CVPR_paper.html,4365468014532039929,/scholar?cites=4365468014532039929,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W12/papers/Zhu_Fusing_Spatiotemporal_Features_2013_CVPR_paper.pdf,0,0,0
1277199,Learning from examples in the small sample case: face expression recognition,2005,Guodong Guo and Charles R Dyer,35,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",3,477-488,IEEE,Example-based learning for computer vision can be difficult when a large number of examples to represent each pattern or object class is not available. In such situations. learning from a small number of samples is of practical value. To study this issue. the task of face expression recognition with a small number of training images of each expression is considered. A new technique based on linear programming for both feature selection and classifier training is introduced. A pairwise framework for feature selection. instead of using all classes simultaneously. is presented. Experimental results compare the method with three others: a simplified Bayes classifier. support vector machine. and AdaBoost. Finally. each algorithm is analyzed and a new categorization of these algorithms is given. especially for learning from examples in the small sample case.,True,f2Y5nygAAAAJ:qjMakFHDy7sC,245,https://ieeexplore.ieee.org/abstract/document/1430832/,17650034140602413939,/scholar?cites=17650034140602413939,,,http://pages.cs.wisc.edu/~gdguo/myPapersOnWeb/IEEESMC05Guo.pdf,0,0,0
1277200,Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression,2011,Guodong Guo and Guowang Mu,,,,657-664,IEEE,Human age estimation has recently become an active research topic in computer vision and pattern recognition. because of many potential applications in reality. In this paper we propose to use the kernel partial least squares (KPLS) regression for age estimation. The KPLS (or linear PLS) method has several advantages over previous approaches: (1) the KPLS can reduce feature dimensionality and learn the aging function simultaneously in a single learning framework. instead of performing each task separately using different techniques; (2) the KPLS can find a small number of latent variables. e.g.. 20. to project thousands of features into a very low-dimensional subspace. which may have great impact on real-time applications; and (3) the KPLS regression has an output vector that can contain multiple labels. so that several related problems. e.g.. age estimation. gender classification. and ethnicity estimation can …,True,f2Y5nygAAAAJ:TQgYirikUcIC,235,https://ieeexplore.ieee.org/abstract/document/5995404/,17860137169615967145,/scholar?cites=17860137169615967145,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.7450&rep=rep1&type=pdf,0,0,0
1277201,A survey on still image based human action recognition,2014,Guodong Guo and Alice Lai,47,Pattern Recognition,10,3343-3361,Pergamon,Recently still image-based human action recognition has become an active research topic in computer vision and pattern recognition. It focuses on identifying a person׳s action or behavior from a single image. Unlike the traditional action recognition approaches where videos or image sequences are used. a still image contains no temporal information for action characterization. Thus the prevailing spatiotemporal features for video-based action analysis are not appropriate for still image-based action recognition. It is more challenging to perform still image-based action recognition than the video-based one. given the limited source of information as well as the cluttered background for images collected from the Internet. On the other hand. a large number of still images exist over the Internet. Therefore it is demanding to develop robust and efficient methods for still image-based action recognition to understand the …,True,f2Y5nygAAAAJ:NhqRSupF_l8C,204,https://www.sciencedirect.com/science/article/pii/S0031320314001642,7681091206342050597,/scholar?cites=7681091206342050597,,,http://romisatriawahono.net/lecture/rm/survey/computer%20vision/Guo%20-%20Human%20Action%20Recognition%20-%202014.pdf,0,0,0
1277202,Evidence and implications of recent climate change in northern Alaska and other arctic regions,2005,Larry D Hinzman and Neil D Bettez and W Robert Bolton and F Stuart Chapin and Mark B Dyurgerov and Chris L Fastie and Brad Griffith and Robert D Hollister and Allen Hope and Henry P Huntington and Anne M Jensen and Gensuo J Jia and Torre Jorgenson and Douglas L Kane and David R Klein and Gary Kofinas and Amanda H Lynch and Andrea H Lloyd and A David McGuire and Frederick E Nelson and Walter C Oechel and Thomas E Osterkamp and Charles H Racine and Vladimir E Romanovsky and Robert S Stone and Douglas A Stow and Matthew Sturm and Craig E Tweedie and George L Vourlitis and Marilyn D Walker and Donald A Walker and Patrick J Webber and Jeffrey M Welker and Kevin S Winker and Kenji Yoshikawa,72,,3,251-298,Kluwer Academic Publishers,The Arctic climate is changing. Permafrost is warming. hydrological processes are changing and biological and social systems are also evolving in response to these changing conditions. Knowing how the structure and function of arctic terrestrial ecosystems are responding to recent and persistent climate change is paramount to understanding the future state of the Earth system and how humans will need to adapt. Our holistic review presents a broad array of evidence that illustrates convincingly; the Arctic is undergoing a system-wide response to an altered climatic state. New extreme and seasonal surface climatic conditions are being experienced. a range of biophysical states and processes influenced by the threshold and phase change of freezing point are being altered. hydrological and biogeochemical cycles are shifting. and more regularly human sub-systems are being affected. Importantly. the …,True,TmYJPbwAAAAJ:u5HHmVD_uO8C,1536,https://link.springer.com/article/10.1007/s10584-005-5352-2,5450911017394996289,/scholar?cites=5450911017394996289,,,https://www.fs.usda.gov/treesearch/pubs/download/25527.pdf,0,0,0
1277203,Remote sensing of vegetation and land-cover change in Arctic Tundra Ecosystems,2004,Douglas A Stow and Allen Hope and David McGuire and David Verbyla and John Gamon and Fred Huemmrich and Stan Houston and Charles Racine and Matthew Sturm and Kenneth Tape and Larry Hinzman and Kenji Yoshikawa and Craig Tweedie and Brian Noyle and Cherie Silapaswan and David Douglas and Brad Griffith and Gensuo Jia and Howard Epstein and Donald Walker and Scott Daeschner and Aaron Petersen and Liming Zhou and Ranga Myneni,89,,3,281-308,Elsevier,The objective of this paper is to review research conducted over the past decade on the application of multi-temporal remote sensing for monitoring changes of Arctic tundra lands. Emphasis is placed on results from the National Science Foundation Land–Air–Ice Interactions (LAII) program and on optical remote sensing techniques. Case studies demonstrate that ground-level sensors on stationary or moving track platforms and wide-swath imaging sensors on polar orbiting satellites are particularly useful for capturing optical remote sensing data at sufficient frequency to study tundra vegetation dynamics and changes for the cloud prone Arctic. Less frequent imaging with high spatial resolution instruments on aircraft and lower orbiting satellites enable more detailed analyses of land cover change and calibration/validation of coarser resolution observations.The strongest signals of ecosystem change detected thus …,True,TmYJPbwAAAAJ:u-x6o8ySG0sC,767,https://www.sciencedirect.com/science/article/pii/S0034425703002803,2943914391139405122,/scholar?cites=2943914391139405122,,,http://cliveg.bu.edu/download/manuscripts/stow02.pdf,0,0,0
1277204,Variability of the seasonally integrated normalized difference vegetation index across the north slope of Alaska in the 1990s,2003,D Stow and Scott Daeschner and A Hope and D Douglas and A Petersen and R Myneni and L Zhou and W Oechel,24,International Journal of Remote Sensing,5,1111-1117,Taylor & Francis Group,The interannual variability and trend of above-ground photosynthetic activity of Arctic tundra vegetation in the 1990s is examined for the north slope region of Alaska. based on the seasonally integrated normalized difference vegetation index (SINDVI) derived from local area coverage (LAC) National Oceanic and Atmospheric Administration (NOAA) Advanced Very High Resolution Radiometer (AVHRR) data. Smaller SINDVI values occurred during the three years (1992-1994) following the volcanic eruption of Mt Pinatubo. Even after implementing corrections for this stratospheric aerosol effect and adjusting for changes in radiometric calibration coefficients. an apparent increasing trend of SINDVI in the 1990s is evident for the entire north slope. The most pronounced increase was observed for the foothills physiographical province.,True,TmYJPbwAAAAJ:JoZmwDi-zQgC,348,https://www.tandfonline.com/doi/abs/10.1080/0143116021000020144,736181834823024636,/scholar?cites=736181834823024636,,,http://sites.bu.edu/cliveg/files/2013/12/stow01.pdf,0,0,0
1277205,Examining the effect of spatial resolution and texture window size on classification accuracy: an urban environment case,2004,D Chen* and DA Stow and P Gong,25,International Journal of Remote Sensing,11,2177-2192,Taylor & Francis Group,The purpose of this paper is to evaluate spatial resolution effects on image classification. Classification maps were generated with a maximum likelihood (ML) classifier applied to three multi-spectral bands and variance texture images. A total of eight urban land use/cover classes were obtained at six spatial resolution levels based on a series of aggregated Colour Infrared Digital Orthophoto Quarter Quadrangle (DOQQ) subsets in urban and rural fringe areas of the San Diego metropolitan area. The classification results were compared using overall and individual classification accuracies.Classification accuracies were shown to be influenced by image spatial resolution. window size used in texture extraction and differences in spatial structure within and between categories. The more heterogeneous are the land use/cover units and the more fragmented are the landscapes. the finer the resolution required. Texture …,True,TmYJPbwAAAAJ:dTyEYWd-f8wC,296,https://www.tandfonline.com/doi/abs/10.1080/01431160310001618464,10765741857753187964,/scholar?cites=10765741857753187964,,,,0,0,0
1277206,Mapping land-cover modifications over large areas: A comparison of machine learning algorithms,2008,John Rogan and Janet Franklin and Doug Stow and Jennifer Miller and Curtis Woodcock and Dar Roberts,112,Remote Sensing of Environment,5,2272-2283,Elsevier,Large area land-cover monitoring scenarios. involving large volumes of data. are becoming more prevalent in remote sensing applications. Thus. there is a pressing need for increased automation in the change mapping process. The objective of this research is to compare the performance of three machine learning algorithms (MLAs); two classification tree software routines (S-plus and C4.5) and an artificial neural network (ARTMAP). in the context of mapping land-cover modifications in northern and southern California study sites between 1990/91 and 1996. Comparisons were based on several criteria: overall accuracy. sensitivity to data set size and variation. and noise. ARTMAP produced the most accurate maps overall (∼ 84%). for two study areas — in southern and northern California. and was most resistant to training data deficiencies. The change map generated using ARTMAP has similar accuracies to a …,True,TmYJPbwAAAAJ:0KyAp5RtaNEC,240,https://www.sciencedirect.com/science/article/pii/S003442570700449X,5227337944373200037,/scholar?cites=5227337944373200037,,,http://www.econgeography.org/departments/geography/pdfs/rogan%20et%20al%202008.pdf,0,0,0
1277207,Land-cover change monitoring with classification trees using Landsat TM and ancillary data,2003,John Rogan and Jennifer Miller and Doug Stow and Janet Franklin and Lisa Levien and Chris Fischer,69,Photogrammetric Engineering & Remote Sensing,7,793-804,American Society for Photogrammetry and Remote Sensing,We monitored land-cover change in San Diego County (1990–1996) using multitemporal Landsat TM data. Change vectors of Kauth Thomas features were combined with stable multitemporal Kauth Thomas features and a suite of ancillary variables within a classification tree classifier. A combination of aerial photointerpretation and field measurements yielded training and validation data. Maps of land-cover change were generated for three hierarchical levels of change classification of increasing detail: change vs. no-change; four classes representing broad increase and decrease classes; and nine classes distinguishing increases or decreases in tree canopy cover. shrub cover. and urban change. The multitemporal Kauth Thomas (both stable and change features representing brightness. greenness. and wetness) provided information for magnitude and direction of land-cover change. Overall accuracies of the …,True,TmYJPbwAAAAJ:yB1At4FlUx8C,238,https://www.ingentaconnect.com/content/asprs/pers/2003/00000069/00000007/art00005,5251673913169237894,/scholar?cites=5251673913169237894,,,https://www.ingentaconnect.com/contentone/asprs/pers/2003/00000069/00000007/art00005?crawler=true,0,0,0
1277208,The effect of training strategies on supervised classification at different spatial resolutions,2002,D Chen and Douglas Stow,68,Photogrammetric Engineering and Remote Sensing,11,1155-1162,ASPRS AMERICAN SOCIETY FOR PHOTOGRAMMETRY AND,Three different training strategies often used for supervised classification-single pixel. seed. and block or polygon training-are compared in this paper. The range parameter of semi-variograms obtained from sample image subsets of each land-uselland-cover class was used to measure the autocorrelation level during training set selection. Eight training sets with different sizes were generated and then applied to image subsets with three multispectral bands and variance texture images in the classification of six land-use classes. The classification results using these training sets were compared at five resolution levels and were based on six Color Infrared Digital Orthophoto Quarter Quadrangle (DOQQ) subsets of different urban land types in urban and rural fringe areas of the San Diego metropolitan area. The performance of different training strategies is shown to be influenced by the training size. the image resolution. and the degree of autocorrelation inherent within each class. Training approaches had more impact on classification results at fine resolution levels than at coarse resolutions. For spectrally homogeneous classes. a spatially independent. single-pixel training approach is preferred. But for spatially heterogeneous classes. small block training has the advantage of readily capturing spectral and spatial information and reduces the amount of interaction time for the analyst.,True,TmYJPbwAAAAJ:UeHWp8X0CEIC,212,https://www.researchgate.net/profile/Dongmei_Chen4/publication/265659743_The_Effect_of_Training_Strategies_on_Supervised_Classification_at_Different_Spatial_Resolutions/links/559fd5c608aedb0e66f42fad/The-Effect-of-Training-Strategies-on-Supervised-Classification-at-Different-Spatial-Resolutions.pdf,18373037513511982388,/scholar?cites=18373037513511982388,,,https://www.researchgate.net/profile/Dongmei_Chen4/publication/265659743_The_Effect_of_Training_Strategies_on_Supervised_Classification_at_Different_Spatial_Resolutions/links/559fd5c608aedb0e66f42fad/The-Effect-of-Training-Strategies-on-Supervised-Classification-at-Different-Spatial-Resolutions.pdf,0,0,0
1277209,Assessing the relationship between spectral vegetation indices and shrub cover in the Jornada Basin. New Mexico,1993,Jeff Duncan and D Stow and J Franklin and A Hope,14,International Journal of Remote Sensing,18,3395-3416,Taylor & Francis Group,We assessed the statistical relations between spectral vegetation indices (SVIs) derived from SPOT multi-spectral data and semi-arid shrub cover at the Jornada LTER site in New Mexico. Despite a limited range of shrub cover in the sample the analyses resulted in r2 values as high as 0.77. Greenness SVIs (e.g.. Simple Ratio. NDVI. SAVI. PVI and an orthogonal Greenness index) were shown to be more sensitive to shrub type and phenology than brightness SVIs (e.g.. green. red and near-infrared reflectances and a Brightness index). The results varied substantially with small-scale changes in plot size (60 m by 60 m to 100 m by 100 m) as a consequence of landscape heterogeneity. The results also indicated the potential for the spectral differentiation of shrub types. and shrubs from grass. using multi-temporal. multi-spectral analysis.,True,TmYJPbwAAAAJ:d1gkVwhDpl0C,189,https://www.tandfonline.com/doi/abs/10.1080/01431169308904454,99415132271267485,/scholar?cites=99415132271267485,,,https://jornada.nmsu.edu/files/bibliography/JRN00165.pdf,0,0,0
1277210,Sensitivity of multitemporal NOAA AVHRR data of an urbanizing region to land-use/land-cover changes and misregistration,2002,Douglas A Stow and Dong Mei Chen,80,Remote Sensing of Environment,2,297-307,Elsevier,Our objectives were to: (1) investigate the sensitivity of multitemporal image data from the Advanced Very High Resolution Radiometer (AVHRR) satellite data for detecting land-use/land-cover changes primarily associated with urbanization and (2) test the effectiveness of a misregistration compensation model on the same data set. Empirical analyses were conducted using two near-anniversary. single-date NOAA AVHHR images of a rapidly urbanizing region of southern and Baja California. Analyses were facilitated by reference data from detailed GIS data layers of land-use/land-cover types for the 2 years corresponding to image acquisition dates (1990 and 1995). Almost all AVHRR pixels containing land-use/land-cover changes were mixed with nonchange areas. even when the extent of change features was greater than the nominal 1 km2 ground sampling area. The strongest signals of image brightness …,True,TmYJPbwAAAAJ:zYLM7Y9cAGgC,170,https://www.sciencedirect.com/science/article/pii/S003442570100311X,17475883703776257878,/scholar?cites=17475883703776257878,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1071.1922&rep=rep1&type=pdf,0,0,0
1277211,The Changning-Menglian suture zone; a segment of the major Cathaysian-Gondwana divide in Southeast Asia,1995,Haoruo Wu and CA Boulter and Baojia Ke and DAV Stow and Zhongcheng Wang,242,Tectonophysics,3-4,267-280,Elsevier,In southwest China. the major Cathaysian-Gondwana divide (the Palaeo-Tethyan suture) is very well delineated by a narrow north-south zone of oceanic siliceous sedimentary rocks and dismembered ophiolite complexes including probable remains of reef-capped oceanic islands. The location of this zone. the Changning-Menglian suture. is not well appreciated in the English language literature. probably because of the failure to recognise the approximately 600 × 400 km Simao terrane which lies to the east of the suture. Many analyses mistakenly include the Simao element in the Sibumasu terrane thus placing a terrane of distinct Cathaysian affinities on the Gondwana side of the major palaeogeographic divide. A measure of the size and time span of Palaeo-Tethys is contained in the Changning-Menglian suture zone sedimentary rocks; deep marine cherts are dated between Early Devonian and Middle Permian …,True,TmYJPbwAAAAJ:e_rmSamDkqQC,166,https://www.sciencedirect.com/science/article/pii/004019519400210Z,3382857983182028045,/scholar?cites=3382857983182028045,,,,0,0,0
1277212,Can we spot a neighborhood from the air? Defining neighborhood structure in Accra. Ghana,2007,John R Weeks and Allan Hill and Douglas Stow and Arthur Getis and Debbie Fugate,69,GeoJournal,1-2,9-22,Springer Netherlands,Slums are home to a large fraction of urban residents in cities of developing nations. but little attempt has been made to go beyond a simple slum/non-slum dichotomy. nor to identify slums more quantitatively than through local reputation. We use census data from Accra. Ghana. to create an index that applies the UN-Habitat criteria for a place to be a slum. We use this index to identify neighborhoods on a continuum of slum characteristics and on that basis are able to locate the worst slums in Accra. These do include the areas with a local reputation for being slums. lending qualitative validation to the index. We show that slums also have footprints that can be identified from data classified from satellite imagery. However. variability among slums in Accra is also associated with some variability in the land cover characteristics of slums.,True,TmYJPbwAAAAJ:Y0pCki6q_DkC,161,https://link.springer.com/content/pdf/10.1007/s10708-007-9098-4.pdf,14641827873751820008,/scholar?cites=14641827873751820008,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2686612/,0,0,0
1277213,Detection of blood vessels in retinal images using two-dimensional matched filters,1989,Subhasis Chaudhuri and Shankar Chatterjee and Norman Katz and Mark Nelson and Michael Goldbaum,8,IEEE Transactions on medical imaging,3,263-269,IEEE,Blood vessels usually have poor local contrast. and the application of existing edge detection algorithms yield results which are not satisfactory. An operator for feature extraction based on the optical and spatial properties of objects to be recognized is introduced. The gray-level profile of the cross section of a blood vessel is approximated by a Gaussian-shaped curve. The concept of matched filter detection of signals is used to detect piecewise linear segments of blood vessels in these images. Twelve different templates that are used to search for vessel segments along all possible directions are constructed. Various issues related to the implementation of these matched filters are discussed. The results are compared to those obtained with other methods.< >,True,84VkdegAAAAJ:PQEM9vzQD9gC,1972,https://ieeexplore.ieee.org/abstract/document/34715/,9067784276279787462,/scholar?cites=9067784276279787462,,,http://www.ee.iitb.ac.in/~sc/papers/tmi-89.pdf,0,0,0
1277214,Super-resolution imaging,2001,Subhasis Chaudhuri,632,,,,Springer Science & Business Media,Super-Resolution Imaging serves as an essential reference for both academicians and practicing engineers. It can be used both as a text for advanced courses in imaging and as a desk reference for those working in multimedia. electrical engineering. computer science. and mathematics. The first book to cover the new research area of super-resolution imaging. this text includes work on the following groundbreaking topics: Image zooming based on wavelets and generalized interpolation; Super-resolution from sub-pixel shifts; Use of blur as a cue; Use of warping in super-resolution; Resolution enhancement using multiple apertures; Super-resolution from motion data; Super-resolution from compressed video; Limits in super-resolution imaging. Written by the leading experts in the field. Super-Resolution Imaging presents a comprehensive analysis of current technology. along with new research findings and directions for future work.,True,84VkdegAAAAJ:17ZO-CJnx_8C,392,http://books.google.com/books?hl=en&lr=&id=ecMPFroqmH0C&oi=fnd&pg=PR10&dq=info:UTx4dTiLQlYJ:scholar.google.com&ots=oRR4vqTKz2&sig=ZAlIXiWMZaRSvxd5RTc_pSA5q3o,6215683510329949265,/scholar?cites=6215683510329949265,,,,0,0,0
1277215,Super-resolution imaging,2001,Subhasis Chaudhuri,632,,,,Springer,Super-Resolution Imaging serves as an essential reference for both academicians and practicing engineers. It can be used both as a text for advanced courses in imaging and as a desk reference for those working in multimedia. electrical engineering. computer science. and mathematics. The first book to cover the new research area of super-resolution imaging. this text includes work on the following groundbreaking topics: Image zooming based on wavelets and generalized interpolation; Super-resolution from sub-pixel shifts; Use of blur as a cue; Use of warping in super-resolution; Resolution enhancement using multiple apertures; Super-resolution from motion data; Super-resolution from compressed video; Limits in super-resolution imaging. Written by the leading experts in the field. Super-Resolution Imaging presents a comprehensive analysis of current technology. along with new research findings and directions for future work.,True,84VkdegAAAAJ:WwIwg2wKZ0QC,392,http://books.google.com/books?hl=en&lr=&id=ecMPFroqmH0C&oi=fnd&pg=PR10&dq=info:UTx4dTiLQlYJ:scholar.google.com&ots=oRR4vqTKz4&sig=R6YSFh_SFljmingjkGe0U7f_Dv0,6215683510329949265,/scholar?cites=6215683510329949265,,,,0,0,0
1277216,Content based image retrieval using motif cooccurrence matrix,2004,N Jhanwar and Subhasis Chaudhuri and Guna Seetharaman and Bertrand Zavidovique,22,Image and Vision Computing,14,1211-1220,Elsevier,We present a new technique for content based image retrieval using motif cooccurrence matrix (MCM). The MCM is derived from the motif transformed image. The whole image is divided into 2×2 pixel grids. Each grid is replaced by a scan motif that minimizes the local gradient while traversing the 2×2 grid forming a motif transformed image. The MCM is then defined as a 3D matrix whose (i.j.k) entry denotes the probability of finding a motif i at a distance k from the motif j in the transformed image. Conceptually. the MCM is quite similar to the color cooccurrence matrix (CCM). however. the retrieval using the MCM is better than the CCM since it captures the third order image statistics in the local neighborhood. Experiments confirm that the use of MCM considerably improves the retrieval performance.,True,84VkdegAAAAJ:w2UhwfzvF0QC,389,https://www.sciencedirect.com/science/article/pii/S0262885604000666,11824007731735470073,/scholar?cites=11824007731735470073,,,http://repository.ias.ac.in/7859/1/346.pdf,0,0,0
1277217,Depth from defocus: a real aperture imaging approach,2012,Subhasis Chaudhuri and Ambasamudram N Rajagopalan,,,,,Springer Science & Business Media,Computer vision is becoming increasingly important in several industrial applications such as automated inspection. robotic manipulations and autonomous vehicle guidance. These tasks are performed in a 3-D world and it is imperative to gather reliable information on the 3-D structure of the scene. This book is about passive techniques for depth recovery. where the scene is illuminated only by natural light as opposed to active methods where a special lighting device is used for scene illumination. Passive methods have a wider range of applicability and also correspond to the way humans infer 3-D structure from visual images.,True,84VkdegAAAAJ:wuD5JclIwkYC,323,http://books.google.com/books?hl=en&lr=&id=mQDaBwAAQBAJ&oi=fnd&pg=PP17&dq=info:mc1VGC4RhH4J:scholar.google.com&ots=vpxlJ5BT9H&sig=IjcWZRwqBRzJXbdbNJrnDWL4Zpw,9116430435379170713,/scholar?cites=9116430435379170713,,,,0,0,0
1277218,Super-resolution image reconstruction,2003,Moon Gi Kang and Subhasis Chaudhuri,20,IEEE Signal Processing Magazine,3,19-20,IEEE,The spatial resolution that represents the number of pixels per unit area in an image is the principal factor in determining the quality of an image. With the development of image processing applications. there is a big demand for high-resolution (HR) images since HR images not only give the viewer a pleasing picture but also offer additional detail that is important for the analysis in many applications. The current technology to obtain HR images mainly depends on sensor manufacturing technology that attempts to increase the number of pixels per unit area by reducing the pixel size. However. the cost for high-precision optics and sensors may be inappropriate for general purpose commercial applications. and there is a limitation to pixel size reduction due to shot noise encountered in the sensor itself. Therefore. a resolution enhancement approach using signal processing techniques has been a great concern in …,True,84VkdegAAAAJ:VHM5RxzNINsC,203,https://ieeexplore.ieee.org/abstract/document/1203206/,11121768750456681062,/scholar?cites=11121768750456681062,,,,0,0,0
1277219,Perception-based data reduction and transmission of haptic data in telepresence and teleaction systems,2008,Peter Hinterseer and Sandra Hirche and Subhasis Chaudhuri and Eckehard Steinbach and Martin Buss,56,IEEE Transactions on Signal Processing,2,588-597,IEEE,We present a novel approach for the transmission of haptic data in telepresence and teleaction systems. The goal of this work is to reduce the packet rate between an operator and a teleoperator without impairing the immersiveness of the system. Our approach exploits the properties of human haptic perception and is. more specifically. based on the concept of just noticeable differences. In our scheme. updates of the haptic amplitude values are signaled across the network only if the change of a haptic stimulus is detectable by the human operator. We investigate haptic data communication for a 1 degree-of-freedom (DoF) and a 3 DoF teleaction system. Our experimental results show that the presented approach is able to reduce the packet rate between the operator and teleoperator by up to 90% of the original rate without affecting the performance of the system.,True,84VkdegAAAAJ:x21FZCSn4ZoC,194,https://ieeexplore.ieee.org/abstract/document/4374151/,17503315662604287135,/scholar?cites=17503315662604287135,,,http://dspace.library.iitb.ac.in/xmlui/bitstream/handle/10054/568/Perception-based%20data%20reduction.pdf?sequence=3,0,0,0
1277220,Depth estimation and image restoration using defocused stereo pairs,2004,AN Rajagopalan and Subhasis Chaudhuri and Uma Mudenagudi,26,IEEE transactions on pattern analysis and machine intelligence,11,1521-1525,IEEE,We propose a method for estimating depth from images captured with a real aperture camera by fusing defocus and stereo cues. The idea is to use stereo-based constraints in conjunction with defocusing to obtain improved estimates of depth over those of stereo or defocus alone. The depth map as well as the original image of the scene are modeled as Markov random fields with a smoothness prior. and their estimates are obtained by minimizing a suitable energy function using simulated annealing. The main advantage of the proposed method. despite being computationally less efficient than the standard stereo or DFD method. is simultaneous recovery of depth as well as space-variant restoration of the original focused image of the scene.,True,84VkdegAAAAJ:yJjnfzR0HrkC,161,https://ieeexplore.ieee.org/abstract/document/1335456/,17662430661429068293,/scholar?cites=17662430661429068293,,,http://www.ee.iitm.ac.in/~raju/journals/j14.pdf,0,0,0
1277221,Bilateral filter based compositing for variable exposure photography,2009,Shanmuganathan Raman and Subhasis Chaudhuri,,,,93-96,Eurographics Association},Compositing a scene from multiple images is of considerable interest to graphics professionals. Typical compositing techniques involve estimation or explicit preparation of matte by an artist. In this article. we address the problem of automatic compositing of a scene from images obtained through variable exposure photography. We consider the High Dynamic Range Imaging (HDRI) problem and review some of the existing approaches for directly generating a Low Dynamic Range (LDR) image from multi-exposure images. We propose a computationally efficient method of scene compositing using edge-preserving filters such as bilateral filters. The key challenge is to composite the multi-exposure images in such a way so as to preserve details in both brightly and poorly illuminated regions of the scene within the limited dynamic range.,True,84VkdegAAAAJ:6ZzL7HXColQC,156,https://www.academia.edu/download/33888374/EG09.pdf,11528454492934483364,/scholar?cites=11528454492934483364,,,https://www.academia.edu/download/33888374/EG09.pdf,0,0,0
1277222,Simultaneous estimation of super-resolved scene and depth map from low resolution defocused observations,2003,Deepu Rajan and Subhasis Chaudhuri,25,IEEE Transactions on Pattern Analysis and Machine Intelligence,9,1102-1117,IEEE,This paper presents a novel technique to simultaneously estimate the depth map and the focused image of a scene. both at a super-resolution. from its defocused observations. Super-resolution refers to the generation of high spatial resolution images from a sequence of low resolution images. Hitherto. the super-resolution technique has been restricted mostly to the intensity domain. In this paper. we extend the scope of super-resolution imaging to acquire depth estimates at high spatial resolution simultaneously. Given a sequence of low resolution. blurred. and noisy observations of a static scene. the problem is to generate a dense depth map at a resolution higher than one that can be generated from the observations as well as to estimate the true high resolution focused image. Both the depth and the image are modeled as separate Markov random fields (MRF) and a maximum a posteriori estimation method is …,True,84VkdegAAAAJ:oTdOBqtIf_kC,145,https://ieeexplore.ieee.org/abstract/document/1227986/,4209278717295046541,/scholar?cites=4209278717295046541,,,http://repository.ias.ac.in/7789/1/308.pdf,0,0,0
1277223,Finding faces in photographs,1998,AN Rajagopalan and K Sunil Kumar and Jayashree Karlekar and R Manivasakan and M Milind Patil and Uday B.  Desai and PG Poonacha and Subhasis Chaudhuri,,,,640-645,IEEE,Two new schemes are presented for finding human faces in a photograph. The first scheme approximates the unknown distributions of the face and the face-like manifolds wing higher order statistics (HOS). An HOS-based data clustering algorithm is also proposed. In the second scheme. the face to non-face and non-face to face transitions are learnt using a hidden Markov model (HMM). The HMM parameters are estimated corresponding to a given photograph and the faces are located by examining the optimal state sequence of the HMM. Experimental results are presented on the performance of both the schemes.,True,84VkdegAAAAJ:DXE8ND7PrJAC,144,https://ieeexplore.ieee.org/abstract/document/710785/,9206990984868341652,/scholar?cites=9206990984868341652,,,https://www.researchgate.net/profile/Uday_Desai2/publication/3766315_Finding_faces_in_photographs/links/5421b1c80cf2a39f4af65b73.pdf,0,0,0
1277224,High accuracy optical flow estimation based on a theory for warping,2004,Thomas Brox and Andrés Bruhn and Nils Papenberg and Joachim Weickert,,,,25-36,Springer Berlin/Heidelberg,We study an energy functional for computing optical flow that combines three assumptions: a brightness constancy assumption. a gradient constancy assumption. and a discontinuity-preserving spatio-temporal smoothness constraint. In order to allow for large displacements. linearisations in the two data terms are strictly avoided. We present a consistent numerical scheme based on two nested fixed point iterations. By proving that this scheme implements a coarse-to-fine warping strategy. we give a theoretical foundation for warping which has been used on a mainly experimental basis so far. Our evaluation demonstrates that the novel method gives significantly smaller angular errors than previous techniques for optical flow estimation. We show that it is fairly insensitive to parameter variations. and we demonstrate its excellent robustness under noise.,True,PtIe6OkAAAAJ:u5HHmVD_uO8C,3107,https://link.springer.com/chapter/10.1007/978-3-540-24673-2_3,10898719343102937370,/scholar?cites=10898719343102937370,,,https://link.springer.com/content/pdf/10.1007/978-3-540-24673-2_3.pdf,0,0,0
1277225,Lucas/Kanade meets Horn/Schunck: Combining local and global optic flow methods,2005,Andrés Bruhn and Joachim Weickert and Christoph Schnörr,61,International Journal of Computer Vision (IJCV),3,211-231,Springer Netherlands,Differential methods belong to the most widely used techniques for optic flow computation in image sequences. They can be classified into local methods such as the Lucas–Kanade technique or Bigün's structure tensor method. and into global methods such as the Horn/Schunck approach and its extensions. Often local methods are more robust under noise. while global techniques yield dense flow fields. The goal of this paper is to contribute to a better understanding and the design of novel differential methods in four ways; (i) We juxtapose the role of smoothing/regularisation processes that are required in local and global differential methods for optic flow computation. (ii) This discussion motivates us to describe and evaluate a novel method that combines important advantages of local and global approaches: It yields dense flow fields that are robust against noise. (iii) Spatiotemporal and nonlinear …,True,PtIe6OkAAAAJ:u-x6o8ySG0sC,1655,https://link.springer.com/article/10.1023/B:VISI.0000045324.43199.43,8409923169601871861,/scholar?cites=8409923169601871861,,,http://helios.mi.parisdescartes.fr/~lomn/Cours/CV/SeqVideo/Articles2017/ShunckMeetsKanade_4.pdf,0,0,0
1277226,Highly accurate optic flow computation with theoretically justified warping,2006,Nils Papenberg and Andrés Bruhn and Thomas Brox and Stephan Didas and Joachim Weickert,67,International Journal of Computer Vision (IJCV),2,141-158,Springer Netherlands,In this paper. we suggest a variational model for optic flow computation based on non-linearised and higher order constancy assumptions. Besides the common grey value constancy assumption. also gradient constancy. as well as the constancy of the Hessian and the Laplacian are proposed. Since the model strictly refrains from a linearisation of these assumptions. it is also capable to deal with large displacements. For the minimisation of the rather complex energy functional. we present an efficient numerical scheme employing two nested fixed point iterations. Following a coarse-to-fine strategy it turns out that there is a theoretical foundation of so-called warping techniques hitherto justified only on an experimental basis. Since our algorithm consists of the integration of various concepts. ranging from different constancy assumptions to numerical implementation issues. a detailed account of the effect of …,True,PtIe6OkAAAAJ:d1gkVwhDpl0C,576,https://link.springer.com/content/pdf/10.1007/s11263-005-3960-y.pdf,11778950581876228467,/scholar?cites=11778950581876228467,,,https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/26330/1/preprint_124_05.pdf,0,0,0
1277227,Optic flow in harmony,2011,Henning Zimmer and Andrés Bruhn and Joachim Weickert,93,International Journal of Computer Vision (IJCV),3,368-388,Springer Berlin,Most variational optic flow approaches just consist of three constituents: a data term. a smoothness term and a smoothness weight. In this paper. we present an approach that harmonises these three components. We start by developing an advanced data term that is robust under outliers and varying illumination conditions. This is achieved by using constraint normalisation. and an HSV colour representation with higher order constancy assumptions and a separate robust penalisation. Our novel anisotropic smoothness is designed to work complementary to the data term. To this end. it incorporates directional information from the data constraints to enable a filling-in of information solely in the direction where the data term gives no information. yielding an optimal complementary smoothing behaviour. This strategy is applied in the spatial as well as in the spatio-temporal domain. Finally. we propose a simple …,True,PtIe6OkAAAAJ:Zph67rFs4hoC,271,https://link.springer.com/article/10.1007/s11263-011-0422-6,11194653129066067226,/scholar?cites=11194653129066067226,,,https://www.researchgate.net/profile/Henning_Zimmer/publication/220659368_Optic_Flow_in_Harmony/links/54f48b350cf2f28c1361dcba/Optic-Flow-in-Harmony.pdf,0,0,0
1277228,Variational optical flow computation in real time,2005,Andrés Bruhn and Joachim Weickert and Christian Feddern and Timo Kohlberger and Christoph Schnörr,14,IEEE Transactions on Image Processing (TIP),5,608-615,IEEE,This paper investigates the usefulness of bidirectional multigrid methods for variational optical flow computations. Although these numerical schemes are among the fastest methods for solving equation systems. they are rarely applied in the field of computer vision. We demonstrate how to employ those numerical methods for the treatment of variational optical flow formulations and show that the efficiency of this approach even allows for real-time performance on standard PCs. As a representative for variational optic flow methods. we consider the recently introduced combined local-global method. It can be considered as a noise-robust generalization of the Horn and Schunck technique. We present a decoupled. as well as a coupled. version of the classical Gau/spl szlig/-Seidel solver. and we develop several multigrid implementations based on a discretization coarse grid approximation. In contrast. with standard …,True,PtIe6OkAAAAJ:9yKSN-GCB0IC,229,https://ieeexplore.ieee.org/abstract/document/1420392/,4227116272193217037,/scholar?cites=4227116272193217037,,,http://julien.marzat.free.fr/Publications/2008_Stage_Ingenieur_INRIA/publication/Variational%20Optical%20Flow%20Computation%20in%20Real%20Time.pdf,0,0,0
1277229,A multigrid platform for real-time motion computation with discontinuity-preserving variational methods,2006,Andrés Bruhn and Joachim Weickert and Timo Kohlberger and Christoph Schnörr,70,International Journal of Computer Vision (IJCV),3,257-277,Springer Netherlands,Variational methods are among the most accurate techniques for estimating the optic flow. They yield dense flow fields and can be designed such that they preserve discontinuities. estimate large displacements correctly and perform well under noise and varying illumination. However. such adaptations render the minimisation of the underlying energy functional very expensive in terms of computational costs: Typically one or more large linear or nonlinear equation systems have to be solved in order to obtain the desired solution. Consequently. variational methods are considered to be too slow for real-time performance. In our paper we address this problem in two ways: (i) We present a numerical framework based on bidirectional multigrid methods for accelerating a broad class of variational optic flow methods with different constancy and smoothness assumptions. Thereby. our work focuses particularly on …,True,PtIe6OkAAAAJ:2osOgNQ5qMEC,211,https://link.springer.com/content/pdf/10.1007/s11263-006-6616-7.pdf,6193845782953950734,/scholar?cites=6193845782953950734,,,https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/26338/1/preprint_136_05.pdf,0,0,0
1277230,Towards ultimate motion estimation: Combining highest accuracy with real-time performance,2005,Andres Bruhn and Joachim Weickert,1,,,749-755 Vol. 1,IEEE,Although variational methods are among the most accurate techniques for estimating the optical flow. they have not yet entered the field of real-time vision. Main reason is the great popularity of standard numerical schemes that are easy to implement. however. at the expense of being too slow for real-time performance. In our paper we address this problem in two ways: (i) we present an improved version of the highly accurate technique of Brox et al. (2004). Thereby we show that a separate robustification of the constancy assumptions is very useful. in particular if the I-norm is used as penalizer. As a result. a method is obtained that yields the lowest angular errors in the literature. (ii) We develop an efficient numerical scheme for the proposed approach that allows real-time performance for sequences of size 160 /spl times/ 720. To this end. we combine two hierarchical strategies: a coarse-to-fine warping strategy as …,True,PtIe6OkAAAAJ:qjMakFHDy7sC,178,https://ieeexplore.ieee.org/abstract/document/1541328/,46593831834734611,/scholar?cites=46593831834734611,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9969&rep=rep1&type=pdf,0,0,0
1277231,Image compression with anisotropic diffusion,2008,Irena Galić and Joachim Weickert and Martin Welk and Andrés Bruhn and Alexander Belyaev and Hans-Peter Seidel,31,Journal of Mathematical Imaging and Vision (JMIV),2-3,255-269,Springer US,Compression is an important field of digital image processing where well-engineered methods with high performance exist. Partial differential equations (PDEs). however. have not much been explored in this context so far. In our paper we introduce a novel framework for image compression that makes use of the interpolation qualities of edge-enhancing diffusion. Although this anisotropic diffusion equation with a diffusion tensor was originally proposed for image denoising. we show that it outperforms many other PDEs when sparse scattered data must be interpolated. To exploit this property for image compression. we consider an adaptive triangulation method for removing less significant pixels from the image. The remaining points serve as scattered interpolation data for the diffusion process. They can be coded in a compact way that reflects the B-tree structure of the triangulation. We supplement the …,True,PtIe6OkAAAAJ:WF5omc3nYNoC,162,https://link.springer.com/article/10.1007/s10851-008-0087-0,6687651545538648551,/scholar?cites=6687651545538648551,,,https://link.springer.com/content/pdf/10.1007/s10851-008-0087-0.pdf,0,0,0
1277232,Complementary optic flow,2009,Henning Zimmer and Andrés Bruhn and Joachim Weickert and Levi Valgaerts and Agustín Salgado and Bodo Rosenhahn and Hans-Peter Seidel,,,,207-220,Springer Berlin/Heidelberg,We introduce the concept of complementarity between data and smoothness term in modern variational optic flow methods. First we design a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions. completely separate robust penalisation. and constraint normalisation. Our anisotropic smoothness term reduces smoothing in the data constraint direction instead of the image edge direction. while enforcing a strong filling-in effect orthogonal to it. This allows optimal complementarity between both terms and avoids undesirable interference. The high quality of our complementary optic flow (COF) approach is demonstrated by the current top ranking result at the Middlebury benchmark.,True,PtIe6OkAAAAJ:ufrVoPGSRksC,160,https://link.springer.com/chapter/10.1007/978-3-642-03641-5_16,14842514606388207564,/scholar?cites=14842514606388207564,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.399.1601&rep=rep1&type=pdf,0,0,0
1277233,Lightweight binocular facial performance capture under uncontrolled lighting,2012,Levi Valgaerts and Chenglei Wu and Andrés Bruhn and Hans-Peter Seidel and Christian Theobalt,31,ACM Transactions on Graphics (TOG),6,187,ACM,Recent progress in passive facial performance capture has shown impressively detailed results on highly articulated motion. However. most methods rely on complex multi-camera set-ups. controlled lighting or fiducial markers. This prevents them from being used in general environments. outdoor scenes. during live action on a film set. or by freelance animators and everyday users who want to capture their digital selves. In this paper. we therefore propose a lightweight passive facial performance capture approach that is able to reconstruct high-quality dynamic facial geometry from only a single pair of stereo cameras. Our method succeeds under uncontrolled and time-varying lighting. and also in outdoor scenes. Our approach builds upon and extends recent image-based scene flow computation. lighting estimation and shading-based refinement algorithms. It integrates them into a pipeline that is specifically tailored towards facial performance reconstruction from challenging binocular footage under uncontrolled lighting. In an experimental evaluation. the strong capabilities of our method become explicit: We achieve detailed and spatio-temporally coherent results for expressive facial motion in both indoor and outdoor scenes–even from low quality input images recorded with a hand-held consumer stereo camera. We believe that our approach is the first to capture facial performances of such high quality from a single stereo rig and we demonstrate that it brings facial performance capture out of the studio. into the wild. and within the reach of everybody.,True,PtIe6OkAAAAJ:ldfaerwXgEUC,156,https://gvv.mpi-inf.mpg.de/files/SIGGRAPH_ASIA_2012/facecap.pdf,11293787304197701956,/scholar?cites=11293787304197701956,,,https://gvv.mpi-inf.mpg.de/files/SIGGRAPH_ASIA_2012/facecap.pdf,0,0,0
1277234,Freehand HDR Imaging of Moving Scenes with Simultaneous Resolution Enhancement,2011,Henning Zimmer and Andrés Bruhn and Joachim Weickert,30,Computer Graphics Forum (CGF),2,405-414,Blackwell Publishing Ltd,Despite their high popularity. common high dynamic range (HDR) methods are still limited in their practical applicability: They assume that the input images are perfectly aligned. which is often violated in practise. Our paper does not only free the user from this unrealistic limitation. but even turns the missing alignment into an advantage: By exploiting the multiple exposures. we can create a super‐resolution image. The alignment step is performed by a modern energy‐based optic flow approach that takes into account the varying exposure conditions. Moreover. it produces dense displacement fields with subpixel precision. As a consequence. our approach can handle arbitrary complex motion patterns. caused by severe camera shake and moving objects. Additionally. it benefits from several advantages over existing strategies: (i) It is robust under outliers (noise. occlusions. saturation problems) and allows for sharp …,True,PtIe6OkAAAAJ:4JMBOYKVnBMC,144,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.01870.x,13284170777051203364,/scholar?cites=13284170777051203364,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.706.1269&rep=rep1&type=pdf,0,0,0
1277235,Correlation of VEGF and angiopoietin expression with disruption of blood–brain barrier and angiogenesis after focal cerebral ischemia,2002,Zheng Gang Zhang and Li Zhang and Wayne Tsang and Hamid Soltanian-Zadeh and Daniel Morris and Ruilan Zhang and Anton Goussev and Cecylia Powers and Thomas Yeich and Michael Chopp,22,Journal of Cerebral Blood Flow & Metabolism,4,379-392,SAGE Publications,In an effort to elucidate the molecular mechanisms underlying cerebral vascular alteration after stroke. the authors measured the spatial and temporal profiles of blood–brain barrier (BBB) leakage. angiogenesis. vascular endothelial growth factor (VEGF). associated receptors. and angiopoietins and receptors after embolic stroke in the rat. Two to four hours after onset of ischemia. VEGF mRNA increased. whereas angiopoietin 1 (Ang 1) mRNA decreased. Three-dimensional immunofluorescent analysis revealed spatial coincidence between increases of VEGF immunoreactivity and BBB leakage in the ischemic core. Two to 28 days after the onset of stroke. increased expression of VEGF/VEGF receptors and Ang/Tie2 was detected at the boundary of the ischemic lesion. Concurrently. enlarged and thin-walled vessels were detected at the boundary of the ischemic lesion. and these vessels developed into smaller …,True,Lc1LZWIAAAAJ:u5HHmVD_uO8C,555,https://journals.sagepub.com/doi/abs/10.1097/00004647-200204000-00002,15904065468854069225,/scholar?cites=15904065468854069225,,,https://journals.sagepub.com/doi/pdf/10.1097/00004647-200204000-00002,0,0,0
1277236,Radon transform orientation estimation for rotation invariant texture analysis,2005,Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh,27,IEEE transactions on pattern analysis and machine intelligence,6,1004-1008,IEEE,This paper presents a new approach to rotation invariant texture classification. The proposed approach benefits from the fact that most of the texture patterns either have directionality (anisotropic textures) or are not with a specific direction (isotropic textures). The wavelet energy features of the directional textures change significantly when the image is rotated. However. for the isotropic images. the wavelet features are not sensitive to rotation. Therefore. for the directional textures. it is essential to calculate the wavelet features along a specific direction. In the proposed approach. the Radon transform is first employed to detect the principal direction of the texture. Then. the texture is rotated to place its principal direction at 0 degrees. A wavelet transform is applied to the rotated image to extract texture features. This approach provides a features space with small intraclass variability and. therefore. good separation …,True,Lc1LZWIAAAAJ:d1gkVwhDpl0C,342,https://ieeexplore.ieee.org/abstract/document/1424459/,6764383646204894133,/scholar?cites=6764383646204894133,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2706151/,0,0,0
1277237,Multiwavelet grading of pathological images of prostate,2003,Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh,50,IEEE Transactions on Biomedical Engineering,6,697-704,IEEE,Histological grading of pathological images is used to determine the level of malignancy of cancerous tissues. This is a very important task in prostate cancer prognosis. since it is used for treatment planning. If infection of cancer is not rejected by noninvasive diagnostic techniques like magnetic resonance imaging. computed tomography scan. and ultrasound. then biopsy specimens of tissue are tested. For prostate. biopsied tissue is stained by hematoxyline and eosine method and viewed by pathologists under a microscope to determine its histological grade. Human grading is very subjective due to interobserver and intraobserver variations and in some cases difficult and time-consuming. Thus. an automatic and repeatable technique is needed for grading. The Gleason grading system is the most common method for histological grading of prostate tissue samples. According to this system. each cancerous …,True,Lc1LZWIAAAAJ:2osOgNQ5qMEC,241,https://ieeexplore.ieee.org/abstract/document/1203808/,7711597790662191881,/scholar?cites=7711597790662191881,,,https://www.academia.edu/download/51474736/Multiwavelet_grading_of_prostate_patholo20170122-12401-99astd.pdf,0,0,0
1277238,Comparison of multiwavelet. wavelet. Haralick. and shape features for microcalcification classification in mammograms,2004,Hamid Soltanian-Zadeh and Farshid Rafiee-Rad,37,Pattern recognition,10,1973-1986,Pergamon,We present an evaluation and comparison of the performance of four different texture and shape feature extraction methods for classification of benign and malignant microcalcifications in mammograms. For 103 regions containing microcalcification clusters. texture and shape features were extracted using four approaches: conventional shape quantifiers; co-occurrence-based method of Haralick; wavelet transformations; and multi-wavelet transformations. For each set of features. most discriminating features and their optimal weights were found using real-valued and binary genetic algorithms (GA) utilizing a k-nearest-neighbor classifier and a malignancy criterion for generating ROC curves for measuring the performance. The best set of features generated areas under the ROC curve ranging from 0.84 to 0.89 when using real-valued GA and from 0.83 to 0.88 when using binary GA. The multi-wavelet method …,True,Lc1LZWIAAAAJ:9yKSN-GCB0IC,240,https://www.sciencedirect.com/science/article/pii/S0031320304001323,9924942674545252072,/scholar?cites=9924942674545252072,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.6106&rep=rep1&type=pdf,0,0,0
1277239,Rotation-invariant multiresolution texture analysis using Radon and wavelet transforms,2005,Kourosh Jafari-Khouzani and Hamid Soltanian-Zadeh,14,IEEE transactions on image processing,6,783-795,IEEE,A new rotation-invariant texture-analysis technique using Radon and wavelet transforms is proposed. This technique utilizes the Radon transform to convert the rotation to translation and then applies a translation-invariant wavelet transform to the result to extract texture features. A k-nearest neighbors classifier is employed to classify texture patterns. A method to find the optimal number of projections for the Radon transform is proposed. It is shown that the extracted features generate an efficient orthogonal feature space. It is also shown that the proposed features extract both of the local and directional information of the texture patterns. The proposed method is robust to additive white noise as a result of summing pixel values to generate projections in the Radon transform step. To test and evaluate the method. we employed several sets of textures along with different wavelet bases. Experimental results show the …,True,Lc1LZWIAAAAJ:UeHWp8X0CEIC,225,https://ieeexplore.ieee.org/abstract/document/1430767/,15673455102486341351,/scholar?cites=15673455102486341351,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2661821/,0,0,0
1277240,Image retrieval based on shape similarity by edge orientation autocorrelogram,2003,Fariborz Mahmoudi and Jamshid Shanbehzadeh and Amir-Masoud Eftekhari-Moghadam and Hamid Soltanian-Zadeh,36,Pattern recognition,8,1725-1736,Pergamon,This paper introduces a new feature vector for shape-based image indexing and retrieval. This feature classifies image edges based on two factors: their orientations and correlation between neighboring edges. Hence it includes information of continuous edges and lines of images and describes major shape properties of images. This scheme is effective and robustly tolerates translation. scaling. color. illumination. and viewing position variations. Experimental results show superiority of proposed scheme over several other indexing methods. Averages of precision and recall rates of this new indexing scheme for retrieval as compared with traditional color histogram are 1.99 and 1.59 times. respectively. These ratios are 1.26 and 1.04 compared to edge direction histogram.,True,Lc1LZWIAAAAJ:IjCSPb-OGe4C,216,https://www.sciencedirect.com/science/article/pii/S0031320303000104,16453284784207439664,/scholar?cites=16453284784207439664,,,,0,0,0
1277241,Automatic recognition of five types of white blood cells in peripheral blood,2011,Seyed Hamid Rezatofighi and Hamid Soltanian-Zadeh,35,Computerized Medical Imaging and Graphics,4,333-343,Pergamon,This paper proposes image processing algorithms to recognize five types of white blood cells in peripheral blood automatically. First. a method based on Gram–Schmidt orthogonalization is proposed along with a snake algorithm to segment nucleus and cytoplasm of the cells. Then. a variety of features are extracted from the segmented regions. Next. most discriminative features are selected using a Sequential Forward Selection (SFS) algorithm and performances of two classifiers. Artificial Neural Network (ANN) and Support Vector Machine (SVM). are compared. The results demonstrate that the proposed methods are accurate and sufficiently fast to be used in hematological laboratories.,True,Lc1LZWIAAAAJ:fEOibwPWpKIC,209,https://www.sciencedirect.com/science/article/pii/S0895611111000048,506637815800747452,/scholar?cites=506637815800747452,,,http://users.cecs.anu.edu.au/~hrezatofighi/Papers/Rezatofighi_CMIG_2011.pdf,0,0,0
1277242,Time Course of ADCw Changes in Ischemic Stroke: Beyond the Human Eye!,1998,V Nagesh and KMA Welch and JP Windham and S Patel and SR Levine and D Hearshen and D Peck and K Robbins and L D’Olhaberriague and H Soltanian-Zadeh and MD Boska,29,Stroke,9,1778-1782,Lippincott Williams & Wilkins,Background and Purpose—Using newly developed computerized image analysis. we studied the heterogeneity of apparent diffusion coefficient of water (ADCw) values in human ischemic stroke within 10 hours of onset.Methods—Echo-planar trace diffusion-weighted images from 9 patients with focal cortical ischemic stroke were obtained within 10 hours of symptom onset. An Iterative Self-Organizing Data Analysis (ISODATA) clustering algorithm was implemented to segment different tissue types with a series of DW images. ADCw maps were calculated from 4 DW images on a pixel-by-pixel basis. The segmented zones within the lesion were characterized as low. pseudonormal. or high. expressed as a ratio of the mean±SD of ADCw of contralateral noninvolved tissue.Results—The average ADCw in the ischemic stroke region within 10 hours of onset was significantly depressed compared with …,True,Lc1LZWIAAAAJ:u-x6o8ySG0sC,156,https://www.ahajournals.org/doi/abs/10.1161/01.STR.29.9.1778,4636034058399534191,/scholar?cites=4636034058399534191,,,https://www.ahajournals.org/doi/full/10.1161/01.STR.29.9.1778,0,0,0
1277243,Segmentation of multiple sclerosis lesions in MR images: a review,2012,Daryoush Mortazavi and Abbas Z Kouzani and Hamid Soltanian-Zadeh,54,,4,299-320,Springer-Verlag,Multiple sclerosis (MS) is an inflammatory demyelinating disease that the parts of the nervous system through the lesions generated in the white matter of the brain. It brings about disabilities in different organs of the body such as eyes and muscles. Early detection of MS and estimation of its progression are critical for optimal treatment of the disease.For diagnosis and treatment evaluation of MS lesions. they may be detected and segmented in Magnetic Resonance Imaging (MRI) scans of the brain. However. due to the large amount of MRI data to be analyzed. manual segmentation of the lesions by clinical experts translates into a very cumbersome and time consuming task. In addition. manual segmentation is subjective and prone to human errors. Several groups have developed computerized methods to detect and segment MS …,True,Lc1LZWIAAAAJ:KxtntwgDAa4C,153,https://link.springer.com/content/pdf/10.1007/s00234-011-0886-7.pdf,12507651437337399810,/scholar?cites=12507651437337399810,,,,0,0,0
1277244,Pigment melanin: Pattern for iris recognition,2010,Mahdi S Hosseini and Babak N Araabi and Hamid Soltanian-Zadeh,59,IEEE Transactions on Instrumentation and Measurement,4,792-804,IEEE,Recognition of iris based on visible light (VL) imaging is a difficult problem because of the light reflection from the cornea. Nonetheless. pigment melanin provides a rich feature source in VL. which is unavailable in near-infrared (NIR) imaging. This is due to the biological spectroscopy of eumelanin. a chemical not stimulated in NIR. In this case. a plausible solution to observe such patterns may be provided by an adaptive procedure using a variational technique on the image histogram. To describe the patterns. a shape analysis method is used to derive the feature code for each subject. An important question is how the melanin patterns. which are extracted from VL. are independent of the iris texture in NIR. With this question in mind. the present investigation proposes fusion of features extracted from NIR and VL to boost recognition performance. We have collected our own database (UTIRIS). consisting of both NIR …,True,Lc1LZWIAAAAJ:J_g5lzvAfSwC,144,https://ieeexplore.ieee.org/abstract/document/5427304/,12995690711673382424,/scholar?cites=12995690711673382424,,,https://arxiv.org/pdf/0911.5462,0,0,0
1277245,A comparative analysis of several transformations for enhancement and segmentation of magnetic resonance image scene sequences,1992,Hamid Soltanian-Zadeh and Joe P Windham and Donald J Peck and Andrew E Yagle,11,IEEE transactions on medical imaging,3,302-318,IEEE,The performance of the eigenimage filter is compared with those of several other filters as applied to magnetic resonance image (MRI) scene sequences for image enhancement and segmentation. Comparisons are made with principal component analysis. matched. modified-matched. maximum contrast. target point. ratio. log-ratio. and angle image filters. Signal-to-noise ratio (SNR). contrast-to-noise ratio (CNR). segmentation of a desired feature (SDF). and correction for partial volume averaging effects (CPV) are used as performance measures. For comparison. analytical expressions for SNRs and CNRs of filtered images are derived. and CPV by a linear filter is studied. Properties of filters are illustrated through their applications to simulated and acquired MRI sequences of a phantom study and a clinical case; advantages and weaknesses are discussed. The conclusion is that the eigenimage filter is the optimal …,True,Lc1LZWIAAAAJ:qjMakFHDy7sC,135,https://ieeexplore.ieee.org/abstract/document/158934/,10325981988463363234,/scholar?cites=10325981988463363234,,,,0,0,0
1277246,FSIM: A feature similarity index for image quality assessment,2011,Lin Zhang and Lei Zhang and Xuanqin Mou and David Zhang,20,IEEE transactions on Image Processing,8,2378-2386,IEEE,Image quality assessment (IQA) aims to use computational models to measure the image quality consistently with subjective evaluations. The well-known structural similarity index brings IQA from pixel- to structure-based stage. In this paper. a novel feature similarity (FSIM) index for full reference IQA is proposed based on the fact that human visual system (HVS) understands an image mainly according to its low-level features. Specifically. the phase congruency (PC). which is a dimensionless measure of the significance of a local structure. is used as the primary feature in FSIM. Considering that PC is contrast invariant while the contrast information does affect HVS' perception of image quality. the image gradient magnitude (GM) is employed as the secondary feature in FSIM. PC and GM play complementary roles in characterizing the image local quality. After obtaining the local quality map. we use PC again as a …,True,G9deVsEAAAAJ:u5HHmVD_uO8C,3192,https://ieeexplore.ieee.org/abstract/document/5705575/,10173695476098164994,/scholar?cites=10173695476098164994,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.460.3538&rep=rep1&type=pdf,0,0,0
1277247,Gradient magnitude similarity deviation: A highly efficient perceptual image quality index,2013,Wufeng Xue and Lei Zhang and Xuanqin Mou and Alan C Bovik,23,IEEE Transactions on Image Processing,2,684-695,IEEE,It is an important task to faithfully evaluate the perceptual quality of output images in many applications. such as image compression. image restoration. and multimedia streaming. A good image quality assessment (IQA) model should not only deliver high quality prediction accuracy. but also be computationally efficient. The efficiency of IQA metrics is becoming particularly important due to the increasing proliferation of high-volume visual data in high-speed networks. We present a new effective and efficient IQA model. called gradient magnitude similarity deviation (GMSD). The image gradients are sensitive to image distortions. while different local structures in a distorted image suffer different degrees of degradations. This motivates us to explore the use of global variation of gradient based local quality map for overall image quality prediction. We find that the pixel-wise gradient magnitude similarity (GMS) between …,True,G9deVsEAAAAJ:3s1wT3WcHBgC,898,https://ieeexplore.ieee.org/abstract/document/6678238/,6216804196942670858,/scholar?cites=6216804196942670858,,,https://arxiv.org/pdf/1308.3052,0,0,0
1277248,Low-dose CT image denoising using a generative adversarial network with Wasserstein distance and perceptual loss,2018,Qingsong Yang and Pingkun Yan and Yanbo Zhang and Hengyong Yu and Yongyi Shi and Xuanqin Mou and Mannudeep K Kalra and Yi Zhang and Ling Sun and Ge Wang,37,IEEE transactions on medical imaging,6,1348-1357,IEEE,The continuous development and extensive use of computed tomography (CT) in medical practice has raised a public concern over the associated radiation dose to the patient. Reducing the radiation dose may lead to increased noise and artifacts. which can adversely affect the radiologists' judgment and confidence. Hence. advanced image reconstruction from low-dose CT data is needed to improve the diagnostic performance. which is a challenging problem due to its ill-posed nature. Over the past years. various low-dose CT methods have produced impressive results. However. most of the algorithms developed for this application. including the recently popularized deep learning techniques. aim for minimizing the mean-squared error (MSE) between a denoised CT image and the ground truth under generic penalties. Although the peak signal-to-noise ratio is improved. MSE- or weighted-MSE-based methods …,True,G9deVsEAAAAJ:nrtMV_XWKgEC,544,https://ieeexplore.ieee.org/abstract/document/8340157/,14200170558494174963,/scholar?cites=14200170558494174963,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6021013/,0,0,0
1277249,Low-dose X-ray CT reconstruction via dictionary learning,2012,Qiong Xu and Hengyong Yu and Xuanqin Mou and Lei Zhang and Jiang Hsieh and Ge Wang,31,IEEE transactions on medical imaging,9,1682-1697,IEEE,Although diagnostic medical imaging provides enormous benefits in the early detection and accuracy diagnosis of various diseases. there are growing concerns on the potential side effect of radiation induced genetic. cancerous and other diseases. How to reduce radiation dose while maintaining the diagnostic performance is a major challenge in the computed tomography (CT) field. Inspired by the compressive sensing theory. the sparse constraint in terms of total variation (TV) minimization has already led to promising results for low-dose CT reconstruction. Compared to the discrete gradient transform used in the TV method. dictionary learning is proven to be an effective way for sparse representation. On the other hand. it is important to consider the statistical property of projection data in the low-dose CT case. Recently. we have developed a dictionary learning based approach for low-dose X-ray CT. In this …,True,G9deVsEAAAAJ:BrmTIyaxlBUC,487,https://ieeexplore.ieee.org/abstract/document/6188527/,5294181839005189411,/scholar?cites=5294181839005189411,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777547/,0,0,0
1277250,Blind image quality assessment using joint statistics of gradient magnitude and Laplacian features,2014,Wufeng Xue and Xuanqin Mou and Lei Zhang and Alan C Bovik and Xiangchu Feng,23,IEEE Transactions on Image Processing,11,4850-4862,IEEE,Blind image quality assessment (BIQA) aims to evaluate the perceptual quality of a distorted image without information regarding its reference image. Existing BIQA models usually predict the image quality by analyzing the image statistics in some transformed domain. e.g.. in the discrete cosine transform domain or wavelet domain. Though great progress has been made in recent years. BIQA is still a very challenging task due to the lack of a reference image. Considering that image local contrast features convey important structural information that is closely related to image perceptual quality. we propose a novel BIQA model that utilizes the joint statistics of two types of commonly used local contrast features: 1) the gradient magnitude (GM) map and 2) the Laplacian of Gaussian (LOG) response. We employ an adaptive procedure to jointly normalize the GM and LOG features. and show that the joint statistics of …,True,G9deVsEAAAAJ:AXPGKjj_ei8C,361,https://ieeexplore.ieee.org/abstract/document/6894197/,10772425698648759098,/scholar?cites=10772425698648759098,,,https://live.ece.utexas.edu/publications/2014/BIQAUsingGM-LoG.pdf,0,0,0
1277251,On the dynamical degradation of digital piecewise linear chaotic maps,2005,Shujun Li and Guanrong Chen and Xuanqin Mou,15,,10,3119-3151,World Scientific Publishing Company,When chaotic systems are realized with finite precisions in digital computers. their dynamical properties are often found to be entirely different from the original versions in the continuous setting. In the literature. there does not seem to be much work on quantitative analysis of such degradation of digitized chaos and how to reduce its negative influence on chaos-based digital systems. Focusing on 1D piecewise linear chaotic maps (PWLCM). this paper reports some findings on a new series of dynamical indicators. which can quantitatively reflect the degradation effects on a digital PWLCM realized with a fixed-point finite precision. On top of that. the paper introduces a new method for studying digital chaos from an algorithmic point of view. In addition. the theoretical results obtained in this paper should be very helpful for the consideration of reducing negative influence of dynamical degradation in real design of …,True,G9deVsEAAAAJ:9yKSN-GCB0IC,353,https://www.worldscientific.com/doi/abs/10.1142/S0218127405014052,344605269992504607,/scholar?cites=344605269992504607,,,http://epubs.surrey.ac.uk/532630/1/IJBC2005.pdf,0,0,0
1277252,Learning without human scores for blind image quality assessment,2013,Wufeng Xue and Lei Zhang and Xuanqin Mou,,,,995-1002,,General purpose blind image quality assessment (BIQA) has been recently attracting significant attention in the fields of image processing. vision and machine learning. Stateof-the-art BIQA methods usually learn to evaluate the image quality by regression from human subjective scores of the training samples. However. these methods need a large number of human scored images for training. and lack an explicit explanation of how the image quality is affected by image local features. An interesting question is then: can we learn for effective BIQA without using human scored images? This paper makes a good effort to answer this question. We partition the distorted images into overlapped patches. and use a percentile pooling strategy to estimate the local quality of each patch. Then a quality-aware clustering (QAC) method is proposed to learn a set of centroids on each quality level. These centroids are then used as a codebook to infer the quality of each patch in a given image. and subsequently a perceptual quality score of the whole image can be obtained. The proposed QAC based BIQA method is simple yet effective. It not only has comparable accuracy to those methods using human scored images in learning. but also has merits such as high linearity to human perception of image quality. real-time implementation and availability of image local quality map.,True,G9deVsEAAAAJ:TQgYirikUcIC,332,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Xue_Learning_without_Human_2013_CVPR_paper.html,10159825713158224591,/scholar?cites=10159825713158224591,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Xue_Learning_without_Human_2013_CVPR_paper.pdf,0,0,0
1277253,Pseudo-random bit generator based on couple chaotic systems and its applications in stream-cipher cryptography,2001,Li Shujun and Mou Xuanqin and Cai Yuanlong,,,,316-329,Springer. Berlin. Heidelberg,Chaotic cryptology is widely investigated recently. This paper reviews the progress in this area and points out some existent problems in digital chaotic ciphers. As a comprehensive solution to these problems. a novel pseudo-random bit generator based on a couple of chaotic systems called CCS-PRBG is presented. Detailed theoretical analyses show that it has perfect cryptographic properties. and can be used to construct stream ciphers with higher security than other chaotic ciphers. Some experiments are made for confirmation. Finally. several examples of stream ciphers based on digital CCS-PRBG are given. and their security is discussed.,True,G9deVsEAAAAJ:epqYDVWIO7EC,308,https://link.springer.com/chapter/10.1007/3-540-45311-3_30,11758621111707305193,/scholar?cites=11758621111707305193,,,http://epubs.surrey.ac.uk/532408/1/INDOCRYPT2001.pdf,0,0,0
1277254,On the security of a chaotic encryption scheme: problems with computerized chaos in finite computing precision,2003,Shujun Li and Xuanqin Mou and Yuanlong Cai and Zhen Ji and Jihong Zhang,153,Computer physics communications,1,52-58,North-Holland,Zhou et al. have proposed a chaotic encryption scheme. which is based on a kind of computerized piecewise linear chaotic map (PWLCM) realized in finite computing precision. In this paper. we point out that Zhou's encryption scheme is not secure enough from strict cryptographic viewpoint. The reason lies in the dynamical degradation of the computerized piecewise linear chaotic map employed by Zhou et al. The dynamical degradation of the computerized chaos induces many weak keys to cause large information leaking of the plaintext. In addition. we also discuss three simple countermeasures to enhance the security of Zhou's cryptosystem. but none of them can essentially enhance the security.,True,G9deVsEAAAAJ:u-x6o8ySG0sC,220,https://www.sciencedirect.com/science/article/pii/S0010465502008755,6437054555054695518,/scholar?cites=6437054555054695518,,,http://epubs.surrey.ac.uk/532641/1/CPC2003.pdf,0,0,0
1277255,A comprehensive evaluation of full reference image quality assessment algorithms,2012,Lin Zhang and Lei Zhang and Xuanqin Mou and David Zhang,,,,1477-1480,IEEE,Recent years have witnessed a growing interest in developing objective image quality assessment (IQA) algorithms that can measure the image quality consistently with subjective evaluations. For the full reference (FR) IQA problem. great progress has been made in the past decade. On the other hand. several new large scale image datasets have been released for evaluating FR IQA methods in recent years. Meanwhile. no work has been reported to evaluate and compare the performance of state-of-the-art and representative FR IQA methods on all the available datasets. In this paper. we aim to fulfill this task by reporting the performance of eleven selected FR IQA algorithms on all the seven public IQA image datasets. Our evaluation results and the associated discussions will be very helpful for relevant researchers to have a clearer understanding about the status of modern FR IQA indices. Evaluation results …,True,G9deVsEAAAAJ:M3ejUd6NZC8C,195,https://ieeexplore.ieee.org/abstract/document/6467150/,2847792254685523650,/scholar?cites=2847792254685523650,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.381.392&rep=rep1&type=pdf,0,0,0
1277256,RFSIM: A feature based image quality assessment metric using Riesz transforms,2010,Lin Zhang and Lei Zhang and Xuanqin Mou,,,,321-324,IEEE,Image quality assessment (IQA) aims to provide computational models to measure the image quality in a perceptually consistent manner. In this paper. a novel feature based IQA model. namely Riesz-transform based Feature SIMilarity metric (RFSIM). is proposed based on the fact that the human vision system (HVS) perceives an image mainly according to its low-level features. The 1 st -order and 2 nd -order Riesz transform coefficients of the image are taken as image features. while a feature mask is defined as the edge locations of the image. The similarity index between the reference and distorted images is measured by comparing the two feature maps at key locations marked by the feature mask. Extensive experiments on the comprehensive TID2008 database indicate that the proposed RFSIM metric is more consistent with the subjective evaluation than all the other competing methods evaluated.,True,G9deVsEAAAAJ:W7OEmFMy1HYC,194,https://ieeexplore.ieee.org/abstract/document/5649275/,1994957677690269287,/scholar?cites=1994957677690269287,,,http://azadproject.ir/wp-content/uploads/2014/07/2010-RFSIM-A-FEATURE-BASED-IMAGE-QUALITY-ASSESSMENT-METRIC-USING-RIESZ-TRANSFORMS.pdf,0,0,0
1277257,Robust point matching via vector field consensus,2014,Jiayi Ma and Ji Zhao and Jinwen Tian and Alan L Yuille and Zhuowen Tu,23,IEEE Transactions on Image Processing,4,1706-1721,IEEE,In this paper. we propose an efficient algorithm. called vector field consensus. for establishing robust point correspondences between two sets of points. Our algorithm starts by creating a set of putative correspondences which can contain a very large number of false correspondences. or outliers. in addition to a limited number of true correspondences (inliers). Next. we solve for correspondence by interpolating a vector field between the two point sets. which involves estimating a consensus of inlier points whose matching follows a nonparametric geometrical constraint. We formulate this a maximum a posteriori (MAP) estimation of a Bayesian model with hidden/latent variables indicating whether matches in the putative set are outliers or inliers. We impose nonparametric geometrical constraints on the correspondence. as a prior distribution. using Tikhonov regularizers in a reproducing kernel Hilbert space. MAP …,True,kdAw20QAAAAJ:kzcrU_BdoSEC,384,https://ieeexplore.ieee.org/abstract/document/6746218/,8647930855131110118,/scholar?cites=8647930855131110118,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc5748387/,0,0,0
1277258,Local Manifold Learning-Based-Nearest-Neighbor for Hyperspectral Image Classification,2010,Li Ma and Melba M Crawford and Jinwen Tian,48,IEEE Transactions on Geoscience and Remote Sensing,11,4099-4109,IEEE,Approaches to combine local manifold learning (LML) and the  k  -nearest-neighbor ( k NN) classifier are investigated for hyperspectral image classification. Based on supervised LML (SLML) and  k NN. a new SLML-weighted  k NN (SLML-W  k NN) classifier is proposed. This method is appealing as it does not require dimensionality reduction and only depends on the weights provided by the kernel function of the specific ML method. Performance of the proposed classifier is compared to that of unsupervised LML (ULML) and SLML for dimensionality reduction in conjunction with the  k NN (ULML-  k NN and SLML- k  NN). Three LML methods. locally linear embedding (LLE). local tangent space alignment (LTSA). and Laplacian eigenmaps. are investigated with these classifiers. In experiments with Hyperion and AVIRIS hyperspectral data. the proposed SLML-W k NN performed better than ULML-  k NN and SLML- k …,True,kdAw20QAAAAJ:u-x6o8ySG0sC,361,https://ieeexplore.ieee.org/abstract/document/5555996/,2853173829369099841,/scholar?cites=2853173829369099841,,,,0,0,0
1277259,Robust feature matching for remote sensing image registration via locally linear transforming,2015,Jiayi Ma and Huabing Zhou and Ji Zhao and Yuan Gao and Junjun Jiang and Jinwen Tian,53,IEEE Transactions on Geoscience and Remote Sensing,12,6469-6481,IEEE,Feature matching. which refers to establishing reliable correspondence between two sets of features (particularly point features). is a critical prerequisite in feature-based registration. In this paper. we propose a flexible and general algorithm. which is called locally linear transforming (LLT). for both rigid and nonrigid feature matching of remote sensing images. We start by creating a set of putative correspondences based on the feature similarity and then focus on removing outliers from the putative set and estimating the transformation as well. We formulate this as a maximum-likelihood estimation of a Bayesian model with hidden/latent variables indicating whether matches in the putative set are outliers or inliers. To ensure the well-posedness of the problem. we develop a local geometrical constraint that can preserve local structures among neighboring feature points. and it is also robust to a large number of outliers …,True,kdAw20QAAAAJ:U3qCfcK-7lkC,354,https://ieeexplore.ieee.org/abstract/document/7128687/,11840501135458613031,/scholar?cites=11840501135458613031,,,https://yuan-gao.net/pdf/TGRS2015.pdf,0,0,0
1277260,Image segmentation by three-level thresholding based on maximum fuzzy entropy and genetic algorithm,2003,Wen-Bing Tao and Jin-Wen Tian and Jian Liu,24,Pattern Recognition Letters,16,3069-3078,North-Holland,In the paper. a three-level thresholding method for image segmentation is presented. based on probability partition. fuzzy partition and entropy theory. A new fuzzy entropy has been defined through probability analysis. The image is divided into three parts. namely. dark. gray and white part. whose member functions of the fuzzy region are Z-function and Π-function and S-function. respectively. while the width and attribute of the fuzzy region can be determined by maximizing fuzzy entropy. The procedure for finding the optimal combination of all the fuzzy parameters is implemented by a genetic algorithm with appropriate coding method so as to avoid useless chromosomes. The experiment results show that the proposed method gives good performance.,True,kdAw20QAAAAJ:u5HHmVD_uO8C,294,https://www.sciencedirect.com/science/article/pii/S0167865503001661,1162208784037510279,/scholar?cites=1162208784037510279,,,http://individual.utoronto.ca/asli/papers/Segmentation/4.pdf,0,0,0
1277261,Field study on occupants’ thermal comfort and residential thermal environment in a hot-humid climate of China,2007,Jie Han and Guoqiang Zhang and Quan Zhang and Jinwen Zhang and Jianlong Liu and Liwei Tian and Cong Zheng and Junhong Hao and Jianping Lin and Yanhui Liu and Demetrios J Moschandreas,42,Building and Environment,12,4043-4050,Pergamon,This paper discusses thermal comfort inside residences of three cities in the hot-humid climate of central southern China. Only a few thermal comfort studies have been performed in hot-humid climates and none in Central Southern China. Field sampling took place in the summers of 2003 and 2004 by obtaining 110 responses to a survey questionnaire and measuring environmental comfort variables in three rooms in each of 26 residences. The objectives are to measure and characterize occupant thermal perceptions in residences. compare observed and predicted percent of dissatisfied and discern differences between this study and similar studies performed in different climate zones. Average clothing insulation for seated subjects was 0.54 clo with 0.15 clo of chairs. Only 48.2% of the measured variables are within the ASHRAE Standard 55-1992 summer comfort zone. but approximately 87.3% of the occupants …,True,kdAw20QAAAAJ:rbGdIwl2e6cC,204,https://www.sciencedirect.com/science/article/pii/S0360132306003763,14626165783254472748,/scholar?cites=14626165783254472748,,,http://www.chinasbe.com/uploadfile/2015/1208/20151208090321514.pdf,0,0,0
1277262,Non-rigid visible and infrared face registration via regularized Gaussian fields criterion,2015,Jiayi Ma and Ji Zhao and Yong Ma and Jinwen Tian,48,Pattern Recognition,3,772-784,Pergamon,Registration of multi-sensor data (particularly visible color sensors and infrared sensors) is a prerequisite for multimodal image analysis such as image fusion. Typically. the relationships between image pairs are modeled by rigid or affine transformations. However. this cannot produce accurate alignments when the scenes are not planar. for example. face images. In this paper. we propose a regularized Gaussian fields criterion for non-rigid registration of visible and infrared face images. The key idea is to represent an image by its edge map and align the edge maps by a robust criterion with a non-rigid model. We model the transformation between images in a reproducing kernel Hilbert space and a sparse approximation is applied to the transformation to avoid high computational complexity. Moreover. a coarse-to-fine strategy by applying deterministic annealing is used to overcome local convergence problems …,True,kdAw20QAAAAJ:oAywNP-vUhwC,196,https://www.sciencedirect.com/science/article/pii/S0031320314003471,6445744870611733454,/scholar?cites=6445744870611733454,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.5687&rep=rep1&type=pdf,0,0,0
1277263,Multisource image fusion method using support value transform,2007,Sheng Zheng and Wen-Zhong Shi and Jian Liu and Guang-Xi Zhu and Jin-Wen Tian,16,IEEE Transactions on Image Processing,7,1831-1839,IEEE,With the development of numerous imaging sensors. many images can be simultaneously pictured by various sensors. However. there are many scenarios where no one sensor can give the complete picture. Image fusion is an important approach to solve this problem and produces a single image which preserves all relevant information from a set of different sensors. In this paper. we proposed a new image fusion method using the support value transform. which uses the support value to represent the salient features of image. This is based on the fact that. in support vector machines (SVMs). the data with larger support values have a physical meaning in the sense that they reveal relative more importance of the data points for contributing to the SVM model. The mapped least squares SVM (mapped LS-SVM) is used to efficiently compute the support values of image. The support value analysis is developed by …,True,kdAw20QAAAAJ:9yKSN-GCB0IC,167,https://ieeexplore.ieee.org/abstract/document/4237214/,5436965028159867478,/scholar?cites=5436965028159867478,,,https://www.researchgate.net/profile/Sheng_Zheng2/publication/6233011_Multisource_Image_Fusion_Method_Using_Support_Value_Transform/links/549221090cf2ac83c53dbefd/Multisource-Image-Fusion-Method-Using-Support-Value-Transform.pdf,0,0,0
1277264,Robust estimation of nonrigid transformation for point set registration,2013,Jiayi Ma and Ji Zhao and Jinwen Tian and Zhuowen Tu and Alan L Yuille,,,,2147-2154,,We present a new point matching algorithm for robust nonrigid registration. The method iteratively recovers the point correspondence and estimates the transformation between two point sets. In the first step of the iteration. feature descriptors such as shape context are used to establish rough correspondence. In the second step. we estimate the transformation using a robust estimator called L 2 E. This is the main novelty of our approach and it enables us to deal with the noise and outliers which arise in the correspondence step. The transformation is specified in a functional space. more specifically a reproducing kernel Hilbert space. We apply our method to nonrigid sparse image feature correspondence on 2D images and 3D surfaces. Our results quantitatively show that our approach outperforms state-ofthe-art methods. particularly when there are a large number of outliers. Moreover. our method of robustly estimating transformations from correspondences is general and has many other applications.,True,kdAw20QAAAAJ:4JMBOYKVnBMC,164,http://openaccess.thecvf.com/content_cvpr_2013/html/Ma_Robust_Estimation_of_2013_CVPR_paper.html,6976258821812156998,/scholar?cites=6976258821812156998,,,http://openaccess.thecvf.com/content_cvpr_2013/papers/Ma_Robust_Estimation_of_2013_CVPR_paper.pdf,0,0,0
1277265,Regularized vector field learning with sparse approximation for mismatch removal,2013,Jiayi Ma and Ji Zhao and Jinwen Tian and Xiang Bai and Zhuowen Tu,46,Pattern Recognition,12,3519-3532,Pergamon,In vector field learning. regularized kernel methods such as regularized least-squares require the number of basis functions to be equivalent to the training sample size. N. The learning process thus has O (N 3) and O (N 2) in the time and space complexity. respectively. This poses significant burden on the vector learning problem for large datasets. In this paper. we propose a sparse approximation to a robust vector field learning method. sparse vector field consensus (SparseVFC). and derive a statistical learning bound on the speed of the convergence. We apply SparseVFC to the mismatch removal problem. The quantitative results on benchmark datasets demonstrate the significant speed advantage of SparseVFC over the original VFC algorithm (two orders of magnitude faster) without much performance degradation; we also demonstrate the large improvement by SparseVFC over traditional methods like …,True,kdAw20QAAAAJ:KxtntwgDAa4C,161,https://www.sciencedirect.com/science/article/pii/S0031320313002410,6815135269755865220,/scholar?cites=6815135269755865220,,,http://matlabtools.com/wp-content/uploads/p410-3.pdf,0,0,0
1277266,A robust directional saliency-based method for infrared small-target detection under various complex backgrounds,2012,Shengxiang Qi and Jie Ma and Chao Tao and Changcai Yang and Jinwen Tian,10,IEEE Geoscience and Remote Sensing Letters,3,495-499,IEEE,Infrared small-target detection plays an important role in image processing for infrared remote sensing. In this letter. different from traditional algorithms. we formulate this problem as salient region detection. which is inspired by the fact that a small target can often attract attention of human eyes in infrared images. This visual effect arises from the discrepancy that a small target resembles isotropic Gaussian-like shape due to the optics point spread function of the thermal imaging system at a long distance. whereas background clutters are generally local orientational. Based on this observation. a new robust directional saliency-based method is proposed incorporating with visual attention theory for infrared small-target detection. Experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art methods for real infrared images with various typical complex backgrounds.,True,kdAw20QAAAAJ:r0BpntZqJG4C,161,https://ieeexplore.ieee.org/abstract/document/6297996/,9375786935496257183,/scholar?cites=9375786935496257183,,,,0,0,0
1277267,Expression and function of miRNA in postoperative radiotherapy sensitive and resistant patients of non-small cell lung cancer,2011,Xiao-Chun Wang and Li-Qing Du and Li-Li Tian and Hai-Liang Wu and Xiao-Yan Jiang and Heng Zhang and De-Guan Li and Yue-Ying Wang and Hong-Ying Wu and Yi She and Qing-fen Liu and Fei-Yue Fan and Ai-Min Meng,72,Lung cancer,1,92-99,Elsevier,To investigate the different miRNA expression profiles of postoperative radiotherapy sensitive and resistant patients of non-small cell lung cancer. explore their potential role and find some radio-sensitivity markers.Thirty non-small cell lung cancer patients who have been treated by postoperative radiotherapy were selected and were divided into radiotherapy sensitive group and resistant group according to overall survival and local or distant recurrence rate. Expression profile of miRNA in these two groups was detected by a microarray assay and the results were validated by quantitative RT-PCR and Northern blot. At the molecular level. the effect of one differently expressed miRNA (miR-126) on the growth and apoptosis of SK-MES-1 cells induced by irradiation was examined.Comparing with resistant patients. five miRNAs (miRNA-126. miRNA-let-7a. miRNA-495. miRNA …,True,kdAw20QAAAAJ:KD63RgGzVVoC,136,https://www.sciencedirect.com/science/article/pii/S0169500210003776,17939181022855566799,/scholar?cites=17939181022855566799,,,,0,0,0
1277268,Model-based analysis synthesis image coding (MBASIC) system for a person's face,1989,Kiyoharu Aizawa and Hiroshi Harashima and Takahiro Saito,1,Signal Processing: Image Communication,2,139-152,Elsevier,The initial conception of a model-based analysis synthesis image coding (MBASIC) system is described and a construction method for a three-dimensional (3-D) facial model that includes synthesis methods for facial expressions is presented. The proposed MBASIC system is an image coding method that utilizes a 3-D model of the object which is to be reproduced. An input image is first analyzed and an output image using the 3-D model is then synthesized. A very low bit rate image transmission can be realized because the encoder sends only the required analysis parameters. Output images can be reconstructed without the noise corruption that reduces naturalness because the decoder synthesizes images from a similar 3-D model.In order to construct a 3-D model of a person's face. a method is developed which uses a 3-D wire frame face model. A full-face image is then projected onto this wire frame model. For …,True,CJRhhi0AAAAJ:u5HHmVD_uO8C,385,https://www.sciencedirect.com/science/article/pii/0923596589900064,17603963068757147212,/scholar?cites=17603963068757147212,,,,0,0,0
1277269,Sketch-based Manga Retrieval using Manga109 Dataset,2017,Yusuke Matsui and Kota Ito and Yuji Aramaki and Toshihiko Yamasaki and Kiyoharu Aizawa,76,Multimedia Tools and Applications,20,21811–21838,Springer,Manga (Japanese comics) are popular worldwide. However. current e-manga archives offer very limited search support. i.e.. keyword-based search by title or author. To make the manga search experience more intuitive. efficient. and enjoyable. we propose a manga-specific image retrieval system. The proposed system consists of efficient margin labeling. edge orientation histogram feature description with screen tone removal. and approximate nearest-neighbor search using product quantization. For querying. the system provides a sketch-based interface. Based on the interface. two interactive reranking schemes are presented: relevance feedback and query retouch. For evaluation. we built a novel dataset of manga images. Manga109. which consists of 109 comic books of 21.142 pages drawn by professional manga artists. To the best of our knowledge. Manga109 is currently the biggest dataset of …,True,CJRhhi0AAAAJ:s1ouQE5r0WUC,353,https://link.springer.com/article/10.1007/s11042-016-4020-z,8241212901806038917,/scholar?cites=8241212901806038917,,,https://link.springer.com/article/10.1007/s11042-016-4020-z,0,0,0
1277270,Model-based image coding advanced video coding techniques for very low bit-rate applications,1995,Kiyoharu Aizawa and Thomas S Huang,83,Proceedings of the IEEE,2,259-271,IEEE,The paper gives an overview of model-based approaches applied to image coding. by looking at image source models. In these model-based schemes. which are different from the various conventional waveform coding methods. the 3-D properties of the scenes are taken into consideration. They can achieve very low bit rate image transmission. The 2-D model and 3-D model based approaches are explained. Among them. a 3-D model based method using a 3-D facial model and a 2-D model based method utilizing 2-D deformable triangular patches are described. Works related to 3-D model-based coding of facial images and some of the remaining problems are also described.< >,True,CJRhhi0AAAAJ:u-x6o8ySG0sC,348,https://ieeexplore.ieee.org/abstract/document/364463/,11519449468330740289,/scholar?cites=11519449468330740289,,,,0,0,0
1277271,Joint optimization framework for learning with noisy labels,2018,Daiki Tanaka and Daiki Ikami and Toshihiko Yamasaki and Kiyoharu Aizawa,,,,5552-5560,,Deep neural networks (DNNs) trained on large-scale datasets have exhibited significant performance in image classification. Many large-scale datasets are collected from websites. however they tend to contain inaccurate labels that are termed as noisy labels. Training on such noisy labeled datasets causes performance degradation because DNNs easily overfit to noisy labels. To overcome this problem. we propose a joint optimization framework of learning DNN parameters and estimating true labels. Our framework can correct labels during training by alternating update of network parameters and labels. We conduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset. The results indicate that our approach significantly outperforms other state-of-the-art methods.,True,CJRhhi0AAAAJ:rUnQDpM0TEQC,234,http://openaccess.thecvf.com/content_cvpr_2018/html/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.html,3807170069699318846,/scholar?cites=3807170069699318846,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.pdf,0,0,0
1277272,Video coding: the second generation approach,1996,,,,,,Springer Science & Business Media,,True,CJRhhi0AAAAJ:oAywNP-vUhwC,198,,16532921022143099068,/scholar?cites=16532921022143099068,,,,0,0,0
1277273,Food detection and recognition using convolutional neural network,2014,Hokuto Kagaya and Kiyoharu Aizawa and Makoto Ogawa,,,,1085-1088,,In this paper. we apply a convolutional neural network (CNN) to the tasks of detecting and recognizing food images. Because of the wide diversity of types of food. image recognition of food items is generally very difficult. However. deep learning has been shown recently to be a very powerful image recognition technique. and CNN is a state-of-the-art approach to deep learning. We applied CNN to the tasks of food detection and recognition through parameter optimization. We constructed a dataset of the most frequent food items in a publicly available food-logging system. and used it to evaluate recognition performance. CNN showed significantly higher accuracy than did traditional support-vector-machine-based methods with handcrafted features. In addition. we found that the convolution kernels show that color dominates the feature extraction process. For food image detection. CNN also showed significantly …,True,CJRhhi0AAAAJ:27LrP4qxOz0C,197,https://dl.acm.org/doi/abs/10.1145/2647868.2654970,12421404514681990573,/scholar?cites=12421404514681990573,,,https://www.researchgate.net/profile/Kiyoharu_Aizawa/publication/305513345_Food_Detection_and_Recognition_Using_Convolutional_Neural_Network/links/5ed8b5284585152945313105/Food-Detection-and-Recognition-Using-Convolutional-Neural-Network.pdf,0,0,0
1277274,Analysis and synthesis of facial image sequences in model-based image coding,1994,Chang Seek Choi and Kiyoharu Aizawa and Hiroshi Harashima and Tsuyoshi Takebe,4,IEEE Transactions on Circuits and Systems for Video Technology,3,257-275,IEEE,This paper proposes new methods for analyzing image sequences and updating textures of the three-dimensional (3-D) facial model. It also describes a method for synthesizing various facial expressions. These three methods are the key technologies for the model-based image coding system. The input image analysis technique directly and robustly estimates the 3-D head motions and the facial expressions without any two-dimensional (2-D) entity correspondences. This technique resolves the 2-D correspondence mismatch errors and provides quality reproduction of the original images by fully incorporating the synthesis rules. To verify the analysis algorithm. the paper performs quantitative and subjective evaluations. It presents two methods for updating the texture of the facial model to improve the quality of the synthesized images. The first method focuses on the facial parts with large change of brightness …,True,CJRhhi0AAAAJ:d1gkVwhDpl0C,196,https://ieeexplore.ieee.org/abstract/document/305871/,327427251567085442,/scholar?cites=327427251567085442,,,,0,0,0
1277275,Efficient retrieval of life log based on context and content,2004,Kiyoharu Aizawa and Datchakorn Tancharoen and Shinya Kawasaki and Toshihiko Yamasaki,,,,22-31,,In this paper. we present continuous capture of our life log with various sensors plus additional data and propose effective retrieval methods using this context and content. Our life log system contains video. audio. acceleration sensor. gyro. GPS. annotations. documents. web pages. and emails. In our previous studies. we showed our retrieval methodology [8].[9]. which mainly depends on context information from sensor data. In this paper. we extend our methodology with additional functions. They are (1) spatio-temporal sampling for extraction of key frames for summarization; and (2) conversation scene detection. With the first of these. key frames for the summarization are extracted using time and location data (GPS). Because our life log captures dense location data. we can also make use of derivatives of location data. that is. speed and acceleration in the movement of the person. The summarizing key frames …,True,CJRhhi0AAAAJ:9yKSN-GCB0IC,180,https://dl.acm.org/doi/abs/10.1145/1026653.1026656,7500743939368483109,/scholar?cites=7500743939368483109,,,https://pdfs.semanticscholar.org/4e84/c8ed4cdf717d5d43667f8918e8cc494457d8.pdf,0,0,0
1277276,Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation,2018,Naoto Inoue and Ryosuke Furuta and Toshihiko Yamasaki and Kiyoharu Aizawa,,,,5001-5009,,Can we detect common objects in a variety of image domains without instance-level annotations? In this paper. we present a framework for a novel task. cross-domain weakly supervised object detection. which addresses this question. For this paper. we have access to images with instance-level annotations in a source domain (eg. natural image) and images with image-level annotations in a target domain (eg. watercolor). In addition. the classes to be detected in the target domain are all or a subset of those in the source domain. Starting from a fully supervised object detector. which is pre-trained on the source domain. we propose a two-step progressive domain adaptation technique by fine-tuning the detector on two types of artificially and automatically generated samples. We test our methods on our newly collected datasets containing three image domains. and achieve an improvement of approximately 5 to 20 percentage points in terms of mean average precision (mAP) compared to the best-performing baselines.,True,CJRhhi0AAAAJ:aVq8r21TQD4C,175,http://openaccess.thecvf.com/content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html,6318150909176455782,/scholar?cites=6318150909176455782,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.pdf,0,0,0
1277277,Signal-processing based method for acquiring very high resolution images with multiple cameras and its theoretical analysis,1993,T Komatsu and K Aizawa and T Igarashi and T Saito,140,"IEE Proceedings I (Communications, Speech and Vision)",1,19-25,IET Digital Library,This paper describes VHD (very high definition) image media competing in spatial resolution with the familiar film media as a new digital image media concept. and discusses a problem of image acquisition as a key technology for achieving VHD image systems. Towards the development of a VHD image acquisition system. the work presents a new signal-processing based approach using multiple different cameras. The image acquisition approach. processing and integrating multiple images taken simultaneously with multiple different cameras. produces an improved spatial resolution image with sufficiently high signal-to-noise ratio. Theoretical analysis and experimental simulations show clearly the improvement in the high frequencies and details.,True,CJRhhi0AAAAJ:2osOgNQ5qMEC,161,https://digital-library.theiet.org/content/journals/10.1049/ip-i-2.1993.0005,11217258976564665799,/scholar?cites=11217258976564665799,,,,0,0,0
1277278,Summarizing wearable video,2001,Kiyoharu Aizawa and Kenichiro Ishijima and Makoto Shiina,3,,,398-401,IEEE,"""We want to record our entire life by video"" is the motivation of this research. Developing wearable devices and huge storage devices will make it possible to keep entire life by video. We could capture 70 years of our life. however. the problem is how to handle such a huge amount of data. Automatic summarization based on personal interest should be required. In this paper we propose an approach to the automatic structuring and summarization of wearable video. (Wearable video is our abbreviation of ""video captured by a wearable camera"".) In our approach. we make use of a wearable camera and a sensor of brain waves. The video is firstly structured by objective features of video. and the shots are rated by subjective measures based on brain waves. The approach is very successful for real world experiments and it automatically extracted all the events that the subjects reported they had felt interesting.",True,CJRhhi0AAAAJ:UeHWp8X0CEIC,134,https://ieeexplore.ieee.org/abstract/document/958135/,4892355306772962203,/scholar?cites=4892355306772962203,,,https://www.researchgate.net/profile/Kiyoharu_Aizawa/publication/3919904_Summarizing_wearable_video/links/0046352b58452b4d60000000.pdf,0,0,0
1277279,Scale-based fuzzy connected image segmentation: theory. algorithms. and validation,2000,Punam K Saha and Jayaram K Udupa and Dewey Odhner,77,Computer Vision and Image Understanding,2,145-174,Academic Press,This paper extends a previously reported theory and algorithms for object definition based on fuzzy connectedness. In this approach. a strength of connectedness is determined between every pair of image elements. This is done by considering all possible connecting paths between the two elements in each pair. The strength assigned to a particular path is defined as the weakest affinity between successive pairs of elements along the path. Affinity specifies the degree to which elements hang together locally in the image. Although the theory allowed any neighborhood size for affinity definition. it did not indicate how this was to be selected. By bringing object scale into the framework in this paper. not only the size of the neighborhood is specified but also it is allowed to change in different parts of the image. This paper argues that scale-based affinity. and hence connectedness. is natural in object definition and …,True,-uz6-4EAAAAJ:u5HHmVD_uO8C,445,https://www.sciencedirect.com/science/article/pii/S1077314299908135,17224666644821647675,/scholar?cites=17224666644821647675,,,,0,0,0
1277280,Optimum image thresholding via class uncertainty and region homogeneity,2001,Punam K.  Saha and Jayaram K.  Udupa,23,IEEE transactions on pattern analysis and machine intelligence,7,689-706,IEEE,Thresholding is a popular image segmentation method that converts a gray-level image into a binary image. The selection of optimum thresholds has remained a challenge over decades. Besides being a segmentation tool on its own. often it is also a step in many advanced image segmentation techniques in spaces other than the image space. We introduce a thresholding method that accounts for both intensity-based class uncertainty-a histogram-based property-and region homogeneity-an image morphology-based property. A scale-based formulation is used for region homogeneity computation. At any threshold. intensity-based class uncertainty is computed by fitting a Gaussian to the intensity distribution of each of the two regions segmented at that threshold. The theory of the optimum thresholding method is based on the postulate that objects manifest themselves with fuzzy boundaries in any digital image …,True,-uz6-4EAAAAJ:9yKSN-GCB0IC,266,https://ieeexplore.ieee.org/abstract/document/935844/,14403262150193450402,/scholar?cites=14403262150193450402,,,,0,0,0
1277281,Relative fuzzy connectedness and object definition: theory. algorithms. and applications in image segmentation,2002,Jayaram K. Udupa and Punam K. Saha and Roberto de Alencar Lotufo,24,"Pattern Analysis and Machine Intelligence, IEEE Transactions on",11,I485-1500,IEEE,,True,-uz6-4EAAAAJ:u-x6o8ySG0sC,264,,3334297680730823942,/scholar?cites=3334297680730823942,,,,0,0,0
1277282,Fuzzy connectedness and image segmentation,2003,Jayaram K Udupa and Punam K Saha,91,Proceedings of the IEEE,10,1649-1669,IEEE,Image segmentation-the process of defining objects in images-remains the most challenging problem in image processing despite decades of research. Many general methodologies have been proposed to date to tackle this problem. An emerging framework that has shown considerable promise recently is that of fuzzy connectedness. Images are by nature fuzzy. Object regions manifest themselves in images with a heterogeneity of image intensities owing to the inherent object material heterogeneity. and artifacts such as blurring. noise and background variation introduced by the imaging device. In spite of this gradation of intensities. knowledgeable observers can perceive object regions as a gestalt. The fuzzy connectedness framework aims at capturing this notion via a fuzzy topological notion called fuzzy connectedness which defines how the image elements hang together spatially in spite of their gradation of …,True,-uz6-4EAAAAJ:qjMakFHDy7sC,263,https://ieeexplore.ieee.org/abstract/document/1232198/,7973105116274682866,/scholar?cites=7973105116274682866,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.504.6911&rep=rep1&type=pdf,0,0,0
1277283,Digital topological analysis of in vivo magnetic resonance microimages of trabecular bone reveals structural implications of osteoporosis,2001,Felix W Wehrli and Bryon R Gomberg and Punam K Saha and Hee Kwon Song and Scott N Hwang and Peter J Snyder,16,Journal of bone and mineral research,8,1520-1531,John Wiley and Sons and The American Society for Bone and Mineral Research (ASBMR),Osteoporosis is a disease characterized by bone volume loss and architectural deterioration. The majority of work aimed at evaluating the structural implications of the disease has been performed based on stereologic analysis of histomorphometric sections. Only recently noninvasive imaging methods have emerged that provide sufficient resolution to resolve individual trabeculae. In this article. we apply digital topological analysis (DTA) to magnetic resonance microimages (μ‐MRI) of the radius obtained at 137 × 137 × 350 μm3 voxel size in a cohort of 79 women of widely varying bone mineral density (BMD) and vertebral deformity status. DTA is a new method that allows unambiguous determination of the three‐dimensional (3D) topology of each voxel in a trabecular bone network. The analysis involves generation of a bone volume fraction map. which is subjected to subvoxel processing to alleviate partial …,True,-uz6-4EAAAAJ:d1gkVwhDpl0C,254,https://asbmr.onlinelibrary.wiley.com/doi/abs/10.1359/jbmr.2001.16.8.1520,15628714385114604375,/scholar?cites=15628714385114604375,,,https://asbmr.onlinelibrary.wiley.com/doi/full/10.1359/jbmr.2001.16.8.1520,0,0,0
1277284,A survey on skeletonization algorithms and their applications,2016,Punam K Saha and Gunilla Borgefors and G Sanniti di Baja,76,Pattern Recognition Letters,,3-12,,Skeletonization provides an effective and compact representation of objects. which is useful for object description. retrieval. manipulation. matching. registration. tracking. recognition. and compression. It also facilitates efficient assessment of local object properties. e.g.. scale. orientation. topology. etc. Several computational approaches are available in literature toward extracting the skeleton of an object. some of which are widely different in terms of their principles. In this paper. we present a comprehensive and concise survey of different skeletonization algorithms and discuss their principles. challenges. and benefits. Topology preservation. parallelization. and multi-scale skeletonization approaches are discussed. Finally. various applications of skeletonization are reviewed and the fundamental challenges of assessing the performance of different skeletonization algorithms are discussed.,True,-uz6-4EAAAAJ:Ak0FvsSvgGUC,244,https://www.sciencedirect.com/science/article/pii/S0167865515001233,17591908991257387275,/scholar?cites=17591908991257387275,,,,0,0,0
1277285,3D digital topology under binary transformation with applications,1996,Punam K Saha and Bidyut Baran Chaudhuri,63,Computer vision and image understanding,3,418-429,Academic Press,In this paper we study 3D digital topology under the transformation of an object point to a nonobject point and vice versa. As a result of such a transformation. an object component in the 3 × 3 × 3 neighborhood of the affected point may vanish or split into two or more components or more than one object components may merge into one. Also. cavities or tunnels in the 3 × 3 × 3 neighborhood may be destroyed or created. One of the goals of this paper is to develop an efficient algorithm (topo_para) to compute the change in the numbers of object components. tunnels and cavities in the 3 × 3 × 3 neighborhood of the transformed point. Another important contribution is the classification of different types of points (e.g.. arc inner point. arc edge point. surface inner point. surface edge point) and detection of different types of junction points (e.g.. junction between arcs. junction between surfaces and arcs. junction between …,True,-uz6-4EAAAAJ:zYLM7Y9cAGgC,243,https://www.sciencedirect.com/science/article/pii/S1077314296900326,2738809419143413772,/scholar?cites=2738809419143413772,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.9679&rep=rep1&type=pdf,0,0,0
1277286,Detection of 3-D simple points for topology preserving transformations with application to thinning,1994,Punam K.  Saha and Bidyut Baran Chaudhuri,16,IEEE transactions on pattern analysis and machine intelligence,10,1028-1032,IEEE,The problems of 3-D digital topology preservation under binary transformations and 3-D object thinning are considered in this correspondence. First. the authors establish the conditions under which transformation of an object voxel to a non-object voxel. or its inverse does not affect the image topology. An efficient algorithm to detect a simple point has been proposed on the basis of those conditions. In this connection. some other interesting properties of 3-D digital geometry are also discussed. Using these properties and the simple point detection algorithm. the authors have proposed an algorithm to generate a surface-skeleton so that the topology of the original image is preserved. the shape of the image is maintained as much as possible. and the results are less affected by noise.< >,True,-uz6-4EAAAAJ:2osOgNQ5qMEC,232,https://ieeexplore.ieee.org/abstract/document/329007/,6241513234960962922,/scholar?cites=6241513234960962922,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/5359/1/Detection%20of%203-D%20simple%20points%20for%20topology%20preserving%20transformat%20-IEEETOPAAMI-16-10-1994-%20p%201028-1032.pdf,0,0,0
1277287,A new shape preserving parallel thinning algorithm for 3D digital images,1997,Punam K Saha and Bidyut Baran Chaudhuri and D Dutta Majumder,30,Pattern Recognition,12,1939-1955,Pergamon,This paper is concerned with a new parallel thinning algorithm for three-dimensional digital images that preserves the topology and maintains their shape. We introduce an approach of selecting shape points and outer-layer used for erosion during each iteration. The approach produces good skeleton for different types of corners. The concept of using two image versions in thinning is introduced and its necessity in parallel thinning is justified. The robustness of the algorithm under pseudo-random noise as well as rotation with respect to shape properties is studied and the results are found to be satisfactory.,True,-uz6-4EAAAAJ:UeHWp8X0CEIC,231,https://www.sciencedirect.com/science/article/pii/S0031320397000162,11460668446529453687,/scholar?cites=11460668446529453687,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/4119/1/Binder1.pdf,0,0,0
1277288,Role of magnetic resonance for assessing structure and function of trabecular bone,2002,Felix W Wehrli and Punam K Saha and Bryon R Gomberg and Hee Kwon Song and Peter J Snyder and Maria Benito and Alex Wright and Richard Weening,13,,5,335-355,LWW,The strength of trabecular bone and its resistance to fracture traditionally have been associated with apparent density. This paradigm assumes that neither the ultrastructural nor microstructural make-up of the bone is altered during aging and osteoporosis. During the past decade there has been growing evidence from both laboratory and clinical studies against this view. Recent advances in noninvasive imaging technology. notably micro-magnetic resonance imaging (μ MRI) and computed tomography. offer an opportunity to test the hypothesis that architecture is an independent contributor to bone strength. MRI appears to be ideally suited for this task because bone marrow has uniform high signal intensity while bone appears with background intensity. thus yielding a binary system tomographic system. However. in vivo trabecular bone imaging is hampered by the limited signal-to-noise ratio that precludes voxel …,True,-uz6-4EAAAAJ:IjCSPb-OGe4C,228,https://journals.lww.com/topicsinmri/Fulltext/2002/10000/Role_of_Magnetic_Resonance_for_Assessing_Structure.5.aspx,15448321900269114928,/scholar?cites=15448321900269114928,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.497.199&rep=rep1&type=pdf,0,0,0
1277289,Complete volumetric decomposition of individual trabecular plates and rods and its morphological correlations with anisotropic elastic moduli in human trabecular bone,2008,X Sherry Liu and Paul Sajda and Punam K Saha and Felix W Wehrli and Grant Bevill and Tony M Keaveny and X Edward Guo,23,Journal of Bone and Mineral Research,2,223-235,John Wiley and Sons and The American Society for Bone and Mineral Research (ASBMR),Trabecular plates and rods are important microarchitectural features in determining mechanical properties of trabecular bone. A complete volumetric decomposition of individual trabecular plates and rods was used to assess the orientation and morphology of 71 human trabecular bone samples. The ITS‐based morphological analyses better characterize microarchitecture and help predict anisotropic mechanical properties of trabecular bone.Introduction: Standard morphological analyses of trabecular architecture lack explicit segmentations of individual trabecular plates and rods. In this study. a complete volumetric decomposition technique was developed to segment trabecular bone microstructure into individual plates and rods. Contributions of trabecular type‐associated morphological parameters to the anisotropic elastic moduli of trabecular bone were studied.Materials and Methods: Seventy‐one human …,True,-uz6-4EAAAAJ:0EnyYjriUFMC,223,https://asbmr.onlinelibrary.wiley.com/doi/abs/10.1359/jbmr.071009,7344509659183911659,/scholar?cites=7344509659183911659,,,https://asbmr.onlinelibrary.wiley.com/doi/full/10.1359/jbmr.071009,0,0,0
1277290,Massively parallel digital transcriptional profiling of single cells,2017,Grace XY Zheng and Jessica M Terry and Phillip Belgrader and Paul Ryvkin and Zachary W Bent and Ryan Wilson and Solongo B Ziraldo and Tobias D Wheeler and Geoff P McDermott and Junjie Zhu and Mark T Gregory and Joe Shuga and Luz Montesclaros and Jason G Underwood and Donald A Masquelier and Stefanie Y Nishimura and Michael Schnall-Levin and Paul W Wyatt and Christopher M Hindson and Rajiv Bharadwaj and Alexander Wong and Kevin D Ness and Lan W Beppu and H Joachim Deeg and Christopher McFarland and Keith R Loeb and William J Valente and Nolan G Ericson and Emily A Stevens and Jerald P Radich and Tarjei S Mikkelsen and Benjamin J Hindson and Jason H Bielas,8,Nature communications,1,1-12,Nature Publishing Group,Characterizing the transcriptome of individual cells is fundamental to understanding complex biological systems. We describe a droplet-based system that enables 3′ mRNA counting of tens of thousands of single cells per sample. Cell encapsulation. of up to 8 samples at a time. takes place in∼ 6 min. with∼ 50% cell capture efficiency. To demonstrate the system’s technical performance. we collected transcriptome data from∼ 250k single cells across 29 samples. We validated the sensitivity of the system and its ability to detect rare populations using cell lines and synthetic RNAs. We profiled 68k peripheral blood mononuclear cells to demonstrate the system’s ability to characterize large immune populations. Finally. we used sequence variation in the transcriptome data to determine host and donor chimerism at single-cell resolution from bone marrow mononuclear cells isolated from transplant patients.,True,i7h8-dYAAAAJ:9VeumLvkZSQC,2010,https://www.nature.com/articles/ncomms14049?report=reader,17926869542004746646,/scholar?cites=17926869542004746646,,,https://www.nature.com/articles/ncomms14049?report=reader,0,0,0
1277291,Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images,2020,Linda Wang and Zhong Qiu Lin and Alexander Wong,10,Scientific Reports,1,1-12,Nature Publishing Group,The Coronavirus Disease 2019 (COVID-19) pandemic continues to have a devastating effect on the health and well-being of the global population. A critical step in the fight against COVID-19 is effective screening of infected patients. with one of the key screening approaches being radiology examination using chest radiography. It was found in early studies that patients present abnormalities in chest radiography images that are characteristic of those infected with COVID-19. Motivated by this and inspired by the open source efforts of the research community. in this study we introduce COVID-Net. a deep convolutional neural network design tailored for the detection of COVID-19 cases from chest X-ray (CXR) images that is open source and available to the general public. To the best of the authors’ knowledge. COVID-Net is one of the first open source network designs for COVID-19 detection from CXR images at the …,True,i7h8-dYAAAAJ:cF7EPgIk0B4C,664,https://www.nature.com/articles/s41598-020-76550-z,12232147793008983229,/scholar?cites=12232147793008983229,,,https://www.nature.com/articles/s41598-020-76550-z,0,0,0
1277292,Haplotyping germline and cancer genomes with high-throughput linked-read sequencing,2016,Grace XY Zheng and Billy T Lau and Michael Schnall-Levin and Mirna Jarosz and John M Bell and Christopher M Hindson and Sofia Kyriazopoulou-Panagiotopoulou and Donald A Masquelier and Landon Merrill and Jessica M Terry and Patrice A Mudivarti and Paul W Wyatt and Rajiv Bharadwaj and Anthony J Makarewicz and Yuan Li and Phillip Belgrader and Andrew D Price and Adam J Lowe and Patrick Marks and Gerard M Vurens and Paul Hardenbol and Luz Montesclaros and Melissa Luo and Lawrence Greenfield and Alexander Wong and David E Birch and Steven W Short and Keith P Bjornson and Pranav Patel and Erik S Hopmans and Christina Wood and Sukhvinder Kaur and Glenn K Lockwood and David Stafford and Joshua P Delaney and Indira Wu and Heather S Ordonez and Susan M Grimes and Stephanie Greer and Josephine Y Lee and Kamila Belhocine and Kristina M Giorda and William H Heaton and Geoffrey P McDermott and Zachary W Bent and Francesca Meschi and Nikola O Kondov and Ryan Wilson and Jorge A Bernate and Shawn Gauby and Alex Kindwall and Clara Bermejo and Adrian N Fehr and Adrian Chan and Serge Saxonov and Kevin D Ness and Benjamin J Hindson and Hanlee P Ji,34,Nature biotechnology,3,303-311,Nature Publishing Group,Haplotyping of human chromosomes is a prerequisite for cataloguing the full repertoire of genetic variation. We present a microfluidics-based. linked-read sequencing technology that can phase and haplotype germline and cancer genomes using nanograms of input DNA. This high-throughput platform prepares barcoded libraries for short-read sequencing and computationally reconstructs long-range haplotype and structural variant information. We generate haplotype blocks in a nuclear trio that are concordant with expected inheritance patterns and phase a set of structural variants. We also resolve the structure of the EML4-ALK gene fusion in the NCI-H2228 cancer cell line using phased exome sequencing. Finally. we assign genetic aberrations to specific megabase-scale haplotypes generated from whole-genome sequencing of a primary colorectal adenocarcinoma. This approach resolves haplotype …,True,i7h8-dYAAAAJ:5F1dSjz1ScoC,520,https://www.nature.com/articles/nbt.3432,3431526901086086467,/scholar?cites=3431526901086086467,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4786454/,0,0,0
1277293,Enteropathogenic and enterohaemorrhagic Escherichia coli: even more subversive elements,2011,Alexander RC Wong and Jaclyn S Pearson and Michael D Bright and Diana Munera and Keith S Robinson and Sau Fung Lee and Gad Frankel and Elizabeth L Hartland,80,,6,1420-1438,Blackwell Publishing Ltd,The human pathogens enteropathogenic and enterohemorrhagic Escherichia coli (EPEC and EHEC) share a unique mechanism of colonization that results from the concerted action of effector proteins translocated into the host cell by a type III secretion system (T3SS). EPEC and EHEC not only induce characteristic attaching and effacing (A/E) lesions. but also subvert multiple host cell signalling pathways during infection. Our understanding of the mechanisms by which A/E pathogens hijack host cell signalling has advanced dramatically in recent months with the identification of novel activities for many effectors. In addition to further characterization of established effectors (Tir. EspH and Map). new effectors have emerged as important mediators of virulence through activities such as mimicry of Rho guanine nucleotide exchange factors (Map and EspM). inhibition of apoptosis (NleH and NleD). interference with …,True,i7h8-dYAAAAJ:BW2nPTmhBn4C,320,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2958.2011.07661.x,3707750534944395125,/scholar?cites=3707750534944395125,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2958.2011.07661.x,0,0,0
1277294,Lung nodule classification using deep features in CT images,2015,Devinder Kumar and Alexander Wong and David A Clausi,,,,133-138,IEEE,"Early detection of lung cancer can help in a sharp decrease in the lung cancer mortality rate. which accounts for more than 17% percent of the total cancer related deaths. A large number of cases are encountered by radiologists on a daily basis for initial diagnosis. Computer-aided diagnosis (CAD) systems can assist radiologists by offering a ""second opinion"" and making the whole process faster. We propose a CAD system which uses deep features extracted from an auto encoder to classify lung nodules as either malignant or benign. We use 4303 instances containing 4323 nodules from the National Cancer Institute (NCI) Lung Image Database Consortium (LIDC) dataset to obtain an overall accuracy of 75.01% with a sensitivity of 83.35% and false positive of 0.39/patient over a 10 fold cross validation.",True,i7h8-dYAAAAJ:anf4URPfarAC,266,https://ieeexplore.ieee.org/abstract/document/7158331/,15314003468816340404,/scholar?cites=15314003468816340404,,,https://www.researchgate.net/profile/Alexander_Wong7/publication/283434355_Lung_Nodule_Classification_Using_Deep_Features_in_CT_Images/links/56a0db6708aee4d26ad8b619/Lung-Nodule-Classification-Using-Deep-Features-in-CT-Images.pdf,0,0,0
1277295,A nonlocal-means approach to exemplar-based inpainting,2008,Alexander Wong and Jeff Orchard,,,,2600-2603,IEEE,This paper introduces a novel approach to the problem of image inpainting through the use of nonlocal-means. In traditional inpainting techniques. only local information around the target regions are used to fill in the missing information. which is insufficient in many cases. More recent inpainting techniques based on the concept of exemplar-based synthesis utilize nonlocal information but in a very limited way. In the proposed algorithm. we use nonlocal image information from multiple samples within the image. The contribution of each sample to the reconstruction of a target pixel is determined using an weighted similarity function and aggregated to form the missing information. Experimental results show that the proposed method yields quantitative and qualitative improvements compared to the current exemplar-based approach. The proposed approach can also be integrated into existing exemplar-based …,True,i7h8-dYAAAAJ:d1gkVwhDpl0C,252,https://ieeexplore.ieee.org/abstract/document/4712326/,3383607262272247951,/scholar?cites=3383607262272247951,,,https://www.academia.edu/download/49580703/An_20Adaptive_20Non-local_20Means_20Approach_20to_20Exemplar-based_20Inpainting.pdf,0,0,0
1277296,ARRSI: Automatic registration of remote-sensing images,2007,Alexander Wong and David A Clausi,45,IEEE Transactions on Geoscience and Remote Sensing,5,1483-1493,IEEE,This paper presents the Automatic Registration of Remote-Sensing Images (ARRSI); an automatic registration system built to register satellite and aerial remotely sensed images. The system is designed specifically to address the problems associated with the registration of remotely sensed images obtained at different times and/or from different sensors. The ARRSI system is capable of handling remotely sensed images geometrically distorted by various transformations such as translation. rotation. and shear. Global and local contrast issues associated with remotely sensed images are addressed in ARRSI using control-point detection and matching processes based on a phase-congruency model. Intensity-difference issues associated with multimodal registration of remotely sensed images are addressed in ARRSI through the use of features that are invariant to intensity mappings during the control-point matching …,True,i7h8-dYAAAAJ:u5HHmVD_uO8C,247,https://ieeexplore.ieee.org/abstract/document/4156348/,15798008769246511737,/scholar?cites=15798008769246511737,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.5853&rep=rep1&type=pdf,0,0,0
1277297,Human RNA polymerase III transcriptomes and relationships to Pol II promoter chromatin and enhancer-binding factors,2010,Andrew J Oler and Ravi K Alla and Douglas N Roberts and Alexander Wong and Peter C Hollenhorst and Katherine J Chandler and Patrick A Cassiday and Cassie A Nelson and Curt H Hagedorn and Barbara J Graves and Bradley R Cairns,17,Nature structural & molecular biology,5,620,Nature Publishing Group,RNA polymerase (Pol) III transcribes many noncoding RNAs (for example. transfer RNAs) important for translational capacity and other functions. We localized Pol III. alternative TFIIIB complexes (BRF1 or BRF2) and TFIIIC in HeLa cells to determine the Pol III transcriptome. define gene classes and reveal'TFIIIC-only'sites. Pol III localization in other transformed and primary cell lines reveals previously uncharacterized and cell type–specific Pol III loci as well as one microRNA. Notably. only a fraction of the in silico–predicted Pol III loci are occupied. Many occupied Pol III genes reside within an annotated Pol II promoter. Outside of Pol II promoters. occupied Pol III genes overlap with enhancer-like chromatin and enhancer-binding proteins such as ETS1 and STAT1. Moreover. Pol III occupancy scales with the levels of nearby Pol II. active chromatin and CpG content. These results suggest that active chromatin gates …,True,i7h8-dYAAAAJ:h1pkognVyKwC,241,https://www.nature.com/articles/nsmb.1801.pdf?origin=ppub,6558881390048095232,/scholar?cites=6558881390048095232,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2945309/,0,0,0
1277298,Intra-retinal layer segmentation in optical coherence tomography images,2009,Akshaya Mishra and Alexander Wong and Kostadinka Bizheva and David A Clausi,17,Optics express,26,23719-23728,Optical Society of America,Retinal layer thickness. evaluated as a function of spatial position from optical coherence tomography (OCT) images is an important diagnostics marker for many retinal diseases. However. due to factors such as speckle noise. low image contrast. irregularly shaped morphological features such as retinal detachments. macular holes. and drusen. accurate segmentation of individual retinal layers is difficult. To address this issue. a computer method for retinal layer segmentation from OCT images is presented. An efficient two-step kernel-based optimization scheme is employed to first identify the approximate locations of the individual layers. which are then refined to obtain accurate segmentation results for the individual layers. The performance of the algorithm was tested on a set of retinal images acquired in-vivo from healthy and diseased rodent models with a high speed. high resolution OCT system. Experimental …,True,i7h8-dYAAAAJ:9yKSN-GCB0IC,234,https://www.osapublishing.org/abstract.cfm?uri=oe-17-26-23719,3101569107408611590,/scholar?cites=3101569107408611590,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-17-26-23719&seq=0,0,0,0
1277299,Analysis of cannabis seizures in NSW. Australia: cannabis potency and cannabinoid profile,2013,Wendy Swift and Alex Wong and Kong M Li and Jonathon C Arnold and Iain S McGregor,8,PloS one,7,e70052,Public Library of Science,Recent analysis of the cannabinoid content of cannabis plants suggests a shift towards use of high potency plant material with high levels of Δ9-tetrahydrocannabinol (THC) and low levels of other phytocannabinoids. particularly cannabidiol (CBD). Use of this type of cannabis is thought by some to predispose to greater adverse outcomes on mental health and fewer therapeutic benefits. Australia has one of the highest per capita rates of cannabis use in the world yet there has been no previous systematic analysis of the cannabis being used. In the present study we examined the cannabinoid content of 206 cannabis samples that had been confiscated by police from recreational users holding 15 g of cannabis or less. under the New South Wales “Cannabis Cautioning” scheme. A further 26 “Known Provenance” samples were analysed that had been seized by police from larger indoor or outdoor cultivation sites rather than from street level users. An HPLC method was used to determine the content of 9 cannabinoids: THC. CBD. cannabigerol (CBG). and their plant-based carboxylic acid precursors THC-A. CBD-A and CBG-A. as well as cannabichromene (CBC). cannabinol (CBN) and tetrahydrocannabivarin (THC-V). The “Cannabis Cautioning” samples showed high mean THC content (THC+THC-A = 14.88%) and low mean CBD content (CBD+CBD-A = 0.14%). A modest level of CBG was detected (CBG+CBG-A = 1.18%) and very low levels of CBC. CBN and THC-V (<0.1%). “Known Provenance” samples showed no significant differences in THC content between those seized from indoor versus outdoor cultivation sites. The present analysis …,True,i7h8-dYAAAAJ:HhcuHIWmDEUC,184,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0070052,11940076520097507942,/scholar?cites=11940076520097507942,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0070052,0,0,0
1277300,Efficient nonlocal-means denoising using the SVD,2008,Jeff Orchard and Mehran Ebrahimi and Alexander Wong,,,,1732-1735,IEEE,Nonlocal-means (NL-means) is an image denoising method that replaces each pixel by a weighted average of all the pixels in the image. Unfortunately. the method requires the computation of the weighting terms for all possible pairs of pixels. making it computationally expensive. Some short-cuts assign a weight of zero to any pixel pairs whose neighbourhood averages are too dissimilar. In this paper. we propose an alternative strategy that uses the SVD to more efficiently eliminate pixel pairs that are dissimilar. Experiments comparing this method against other NL-means speed-up strategies show that its refined discrimination between similar and dissimilar pixel neighbourhoods significantly improves the denoising effect.,True,i7h8-dYAAAAJ:u-x6o8ySG0sC,180,https://ieeexplore.ieee.org/abstract/document/4712109/,5485562213884970592,/scholar?cites=5485562213884970592,,,https://www.researchgate.net/profile/Alexander_Wong7/publication/221122164_Efficient_nonlocal-means_denoising_using_the_SVD/links/562c21d708ae04c2aeb35a43.pdf,0,0,0
1277301,Visual comfort of binocular and 3D displays,2004,F.L. Kooi and Alexander Toet,,,,1-14,Marcel Dekker Inc.,Imperfections in binocular image pairs can cause serious viewing discomfort. For example. in stereo vision systems eye strain is caused by unintentional mismatches between the left and right eye images (stereo imperfections). Head-mounted displays can induce eye strain due to optical misalignments. We have experimentally determined the level of (dis)comfort experienced by human observers viewing brief presentations of imperfect binocular image pairs. We used a wide range of binocular image imperfections that are representative for commonly encountered optical errors (spatial distortions: shifts. magnification. rotation. keystone). imperfect filters (photometric asymmetries: luminance. color. contrast. crosstalk). and stereoscopic disparities. The results show that nearly all binocular image asymmetries seriously reduce visual comfort if present in a large enough amount. From our data we estimate threshold …,True,pDcGtccAAAAJ:uJ-U7cs_P_0C,735,https://www.sciencedirect.com/science/article/pii/S0141938204000502,17184397383123536023,/scholar?cites=17184397383123536023,,,https://www.researchgate.net/profile/Alexander_Toet/publication/223205160_Visual_Comfort_of_Binocular_and_3-D_Displays/links/5aa9045aa6fdccd3b9b8ebd6/Visual-Comfort-of-Binocular-and-3-D-Displays.pdf,0,0,0
1277302,Merging thermal and visual images by a contrast pyramid,1989,Alexander Toet and Lodewik J Van Ruyven and J Mathee Valeton,28,Optical engineering,7,287789,International Society for Optics and Photonics,Integration of images from different sensing modalities can produce information that cannot be obtained by viewing the sensor outputs separately and consecutively. This paper introduces a hierarchical image merging scheme based on a multiresolution contrast decomposition (the ratio of a low-pass pyramid). The composite images produced by this scheme preserve those details from the input images that are most relevant to visual perception. The method is tested by merging parallel registered thermal and visual images. The results show that the fused images present a more detailed representation of the depicted scene. Detection. recognition. and search tasks may therefore benefit from this new image representation.,True,pDcGtccAAAAJ:u5HHmVD_uO8C,720,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-28/issue-7/287789/Merging-Thermal-And-Visual-Images-By-A-Contrast-Pyramid/10.1117/12.7977034.short,5430117742540099841,/scholar?cites=5430117742540099841,,,https://www.academia.edu/download/48950766/Toet-1989.pdf,0,0,0
1277303,Image fusion by a ratio of low-pass pyramid,1989,Alexander Toet,9,Pattern Recognition Letters,4,245-253,North-Holland,This paper introduces a hierarchial image merging scheme based on a multiresolution contrast decomposition (the ratio of low-pass pyramid). The composite images produced by this scheme preserve those details from the input images that are most relevant to visual perception. Some applications of the method are indicated.,True,pDcGtccAAAAJ:2osOgNQ5qMEC,685,https://www.sciencedirect.com/science/article/pii/0167865589900032,1177238055297078391,/scholar?cites=1177238055297078391,,,https://www.academia.edu/download/44966895/Image_fusion_by_a_ratio_of_low-pass_pyra20160421-25888-1nupvn.pdf,0,0,0
1277304,The Two-Dimensional Shape of Spatial Interaction Zones in the Parafovea,1992,Alexander Toet and Dennis M. Levi,32,Vision Res,7,1349-1357.1992,,The spatial analysis of a target may be strongly degraded by the simultaneous presentation of nearby pattern elements. The present study investigated the shape and extent of the region of interaction as a function of retinal location. The stimuli consisted of 3 collinear Ts which were randomly oriented up (T) or down (⊥). The task was to discriminate the orientation of the middle T. The retinal locations studied were at 0. 2.5. 5 and 10°. on the lower vertical meridian and on the nasal halves of both the horizontal and the 45° diagonal visual field meridians. The extent of the interaction region was defined as the separation between the midpoint of two adjacent Ts that resulted in 75% correct discrimination. The shape of the interaction region was determined by using several orientations (horizontal. vertical. left diagonal and right diagonal) for the virtual line joining the 3 Ts. Our results show that the size of the interaction …,True,pDcGtccAAAAJ:u-x6o8ySG0sC,594,https://www.sciencedirect.com/science/article/pii/004269899290227A,1182337156375066139,/scholar?cites=1182337156375066139,,,https://www.researchgate.net/profile/Alexander_Toet/publication/21699426_Toet_A_Levi_DM_The_two-dimensional_shape_of_spatial_interaction_zones_in_the_parafovea_Vision_Res_32_1349-1357/links/59eda1a5aca272cddde074a7/Toet-A-Levi-DM-The-two-dimensional-shape-of-spatial-interaction-zones-in-the-parafovea-Vision-Res-32-1349-1357.pdf,0,0,0
1277305,Hierarchical image fusion,1990,Alexander Toet,3,Machine Vision and Applications,1,1-11,Springer-Verlag,A hierarchical image fusion scheme is presented that preserves those details from the input images that are most relevant to visual perception. Results show that fused images present a more detailed representation of the scene and provide information that cannot be obtained by viewing the input images separately. Detection. recognition. and search tasks may therefore benefit from this fused image representation.,True,pDcGtccAAAAJ:d1gkVwhDpl0C,394,https://link.springer.com/article/10.1007/BF01211447,7548768582627674988,/scholar?cites=7548768582627674988,,,https://www.researchgate.net/profile/Alexander_Toet/publication/220465102_Hierachical_image_fusion/links/0912f50bdb6b80165f000000/Hierachical-image-fusion.pdf,0,0,0
1277306,The effect of similarity and duration on spatial interaction in peripheral vision,1994,Frank L Kooi and Alex Toet and Srimant P Tripathy and Dennis M Levi,8,Spatial Vision,2,255-279,VSP. an imprint of Brill,"Spatial interactions are extensive in the peripheral visual field. extending up to about half the retinal eccentricity ofthe target (Toet and Levt. Vision Res. 32. 1349-1357. 1992). In the present study it is shown that the degree and extent of peripheral spatial interaction depends in large measure on the similarity between test and flanking stimuli. The stimulus consisted of a test T surrounded by four distracting flanking Ts. each randomly oriented. The task was to determine the orientation of the test T. The test and flanking Ts differed in contrast polarity. shape. depth. color. eye of origin. or contrast. When the target and flanks differed in contrasl polarity. depth. or shape. performance improved markedlv for all observers. A color difference enhanced the performance of most but not all observers. Eve-of-origin had no effect. that is. spatial interaction was identical when the target and tlanks were presented to the same eye. or to opposite eyes. The role of stimulus duration in spatial interaction was examined in tr'"" o additional experiments. In the first. the stimulus viewing duration was increased in order to allow the observer time to serially search for the test T. In the second experiment. a postmask u'as presented at the location of the test T. The results of these experiments showed that the influence of similarity was independent of stimulus duration and the postmask. and suggest that serial search cloes not play an important role in the spatial interaction effects reported here. The extent ofspatial interaction is correlated with the abilitv to do parallel search.",True,pDcGtccAAAAJ:tzM49s52ZIMC,382,https://www.researchgate.net/profile/Alexander_Toet/publication/15205120_The_effect_of_similarity_and_duration_on_spatial_interaction_in_peripheral_vision/links/5a11b20b0f7e9bd1b2c0f5ce/The-effect-of-similarity-and-duration-on-spatial-interaction-in-peripheral-vision.pdf,7954081490212487973,/scholar?cites=7954081490212487973,,,https://www.researchgate.net/profile/Alexander_Toet/publication/15205120_The_effect_of_similarity_and_duration_on_spatial_interaction_in_peripheral_vision/links/5a11b20b0f7e9bd1b2c0f5ce/The-effect-of-similarity-and-duration-on-spatial-interaction-in-peripheral-vision.pdf,0,0,0
1277307,A morphological pyramidal image decomposition,1989,Alexander Toet,9,Pattern recognition letters,4,255-261,North-Holland,A multiresolution image representation is presented in which iterative morphological filters of many scales but identical shape serve as basis functions. Structural pattern decomposition is achieved by subtracting successive layers in the multiresolution representation. The representation differs from established techniques in that the code elements have a well defined location and size. The resulting image description provides a useful basis for multiresolution shape analysis and is well suited for VLSI implementation.,True,pDcGtccAAAAJ:UeHWp8X0CEIC,335,https://www.sciencedirect.com/science/article/pii/0167865589900044,17240393791207857398,/scholar?cites=17240393791207857398,,,https://www.academia.edu/download/48994079/A_morphological_pyramidal_image_decompos20160920-7955-9ar0m8.pdf,0,0,0
1277308,Multiscale contrast enhancement with applications to image fusion,1992,Alexander Toet,31,Optical Engineering,05,1026-1031,,A method to merge images from different sensing modalities for visual display was introduced by Toet. van Ruyven. and Valeton in 1989. which produces a fused image by nonlinear recombination of the ratio of low-pass (R0LP) pyramidal decompositions ofthe original images. The appearance of merged images that are produced by this scheme is highly dependent on the contrast and mean gray level ofthe input images. That nonlinear multiplication of the successive layers of a ratio of low-pass pyramid results in a contrast-enhanced image representation that is highly invariant for changes in the global gray-level characteristics of the original image is shown. Application of this nonlinear multiplication procedure in the image fusion process results in composite images that appear highly independent of changes in lighting and gray-level gradients in the input images. The method is tested by merging different …,True,pDcGtccAAAAJ:9yKSN-GCB0IC,325,https://www.spiedigitallibrary.org/journals/optical-engineering/volume-31/issue-5/0000/Multiscale-contrast-enhancement-with-applications-to-image-fusion/10.1117/12.56155.short,16096893862745671175,/scholar?cites=16096893862745671175,,,https://www.academia.edu/download/50939220/Multiscale_contrast_enhancement_with_app20161217-30655-1errwbq.pdf,0,0,0
1277309,Visual processing of optic acceleration,1992,Peter Werkhoven and Herman P. Snippe and Alexander Toet,32,Vision research,12,2313-2329,Pergamon,We present data on the human sensitivity to optic acceleration i.e. temporal modulations of the speed and direction of moving objects. Modulation thresholds are measured as a function of modulation frequency and speed for different periodical velocity vector modulation functions using a localized target. Evidence is presented that human detection of velocity vector modulations is not directly based on the acceleration signal (the temporal derivative of the velocity vector modulation). Instead. modulation detection is accurately described by a two-stage model: a low-pass temporal filter transformation of the true velocity vector modulation followed by a variance detection stage. A functional description of the first stage is a second order low-pass temporal filter having a characteristic time constant of 40 msec. In effect. the temporal low-pass filter is an integration of the velocity vector modulation within a temporal window …,True,pDcGtccAAAAJ:_Re3VWB3Y0AC,279,https://www.sciencedirect.com/science/article/pii/004269899290095Z,7784200777283658003,/scholar?cites=7784200777283658003,,,https://www.academia.edu/download/30914909/WerkhovenSnippe1992.pdf,0,0,0
1277310,New false color mapping for image fusion,1996,Alexander Toet and Jan Walraven,35,Optical engineering,3,650-658,International Society for Optics and Photonics,A pixel-based color-mapping algorithm is presented that produces a fused false color rendering of two gray-level images representing different sensor modalities. The resulting images have a higher information content than each of the original images and retain sensorspecific image information. The unique component of each image modality is enhanced in the resulting fused color image representation. First. the common component of the two original input images is determined. Second. the common component is subtracted from the original images to obtain the unique component of each image. Third. the unique component of each image modality is subtracted from the image of the other modality. This step serves to enhance the representation of sensor-specific details in the final fused result. Finally. a fused color image is produced by displaying the images resulting from the last step through. respectively. the …,True,pDcGtccAAAAJ:qjMakFHDy7sC,265,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-35/issue-3/0000/New-false-color-mapping-for-image-fusion/10.1117/1.600657.short,16982290622004711987,/scholar?cites=16982290622004711987,,,,0,0,0
1277311,Computational versus psychophysical bottom-up image saliency: A comparative evaluation study,2011,Alexander Toet,33,IEEE transactions on pattern analysis and machine intelligence,11,2131-2146,IEEE,The predictions of 13 computational bottom-up saliency models and a newly introduced Multiscale Contrast Conspicuity (MCC) metric are compared with human visual conspicuity measurements. The agreement between human visual conspicuity estimates and model saliency predictions is quantified through their rank order correlation. The maximum of the computational saliency value over the target support area correlates most strongly with visual conspicuity for 12 of the 13 models. A simple multiscale contrast model and the MCC metric both yield the largest correlation with human visual target conspicuity (>;0.84). Local image saliency largely determines human visual inspection and interpretation of static and dynamic scenes. Computational saliency models therefore have a wide range of important applications. like adaptive content delivery. region-of-interest-based image compression. video summarization …,True,pDcGtccAAAAJ:pqnbT2bcN3wC,247,https://ieeexplore.ieee.org/abstract/document/5740916/,5136501850009411291,/scholar?cites=5136501850009411291,,,https://www.researchgate.net/profile/Alexander_Toet/publication/50596078_Computational_versus_Psychophysical_Bottom-Up_Image_Saliency_A_Comparative_Evaluation_Study/links/0912f502b9b9aa5319000000.pdf,0,0,0
1277312,Polyester materials with superwetting silicone nanofilaments for oil/water separation and selective oil absorption,2011,Junping Zhang and Stefan Seeger,21,Advanced Functional Materials,24,4699-4704,WILEY‐VCH Verlag,Superhydrophobic and superoleophilic polyester materials are successfully prepared by one‐step growth of silicone nanofilaments onto the textile via chemical vapor deposition of trichloromethylsilane. The successful growth of silicone nanofilaments is confirmed with scanning electron microscopy. energy‐dispersive X‐ray analysis. and investigation of the wetting behavior of water on the textile. Even microfibers deeply imbedded inside a woven material could be coated very well with the nanofilaments. The coated textile is water repellant and could only be wetted by liquids of low surface tension. The applications of the coated textile as a membrane for oil/water separation and as a bag for selective oil absorption from water are studied in detail. Owing to the superwetting properties and flexibility of the coated textile. excellent reusability. oil/water separation efficiency. and selective oil absorption capacity are …,True,XEUiPccAAAAJ:dQ2og3OwTAUC,661,https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.201101090,13844296297744665933,/scholar?cites=13844296297744665933,,,,0,0,0
1277313,Chitosan-alginate nanoparticles as a novel drug delivery system for nifedipine,2008,Ping Li and Ya-Ni Dai and Jun-Ping Zhang and Ai-Qin Wang and Qin Wei,4,International journal of biomedical science: IJBS,3,221,Master Publishing Group,Chitosan-alginate (CS/ALG) nanoparticles were prepared by ionotropic pre-gelation of an alginate core followed by chitosan polyelectrolyte complexation. nifedipine was chosen as a model drug. Morphology and structure characterization of nanoparticles were investigated by transmission electron microscope (TEM) and Fourier transform infrared spectra (FTIR). respectively. The diameter of the nanoparticles was about 20-50 nm. suitable for uptake within the gastrointestinal tract due to their nanosize range and mucoadhesive properties. A reversed-phase high-performance liquid chromatographic (HPLC) method has been developed and validated for the determination of nifedipine in nanoparticulate dosage forms. In addition. the delivery behavior of nifedipine from nanoparticles was studied. Nifedipine released from chitosan-alginate nanoparticles was 26.52% at pH1. 5. 69.69% at pH6. 8 and 56.50% at pH7. 4 …,True,XEUiPccAAAAJ:JQOojiI6XY0C,352,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3614711/,15975095810054887167,/scholar?cites=15975095810054887167,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3614711/,0,0,0
1277314,Superoleophobic coatings with ultralow sliding angles based on silicone nanofilaments,2011,Junping Zhang and Stefan Seeger,50,Angewandte Chemie International Edition,29,6652-6656,WILEY‐VCH Verlag,Superoleophobic surfaces were fabricated by using organosilanes. The surfaces feature high contact angles and ultralow sliding angles for various nonpolar liquids. excellent transparency. and chemical and environmental stability. The microstructure and superoleophobicity of the surfaces can be regulated simply by the water concentration in toluene used during the coating procedure.,True,XEUiPccAAAAJ:mvPsJ3kp5DgC,342,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.201101008,1976011723348609818,/scholar?cites=1976011723348609818,,,https://www.academia.edu/download/38812220/Zhang_and_Seeger_2011.pdf,0,0,0
1277315,Removal of methylene blue from aqueous solution using chitosan-g-poly (acrylic acid)/montmorillonite superadsorbent nanocomposite,2008,Li Wang and Junping Zhang and Aiqin Wang,322,Colloids and Surfaces A: Physicochemical and Engineering Aspects,1-3,47-53,Elsevier,Batch adsorption experiments were carried out for the removal of methylene blue (MB) cationic dye from its aqueous solution using chitosan-g-poly(acrylic acid)/montmorillonite (CTS-g-PAA/MMT) nanocomposites as adsorbent. The factors influencing adsorption capacity of the nanocomposite such as initial pH value (pH0) of the dye solution. MMT content (wt%). weight ratio (wr) of AA to CTS and adsorption temperature (T) were investigated. The results showed that the wr of AA to CTS of the nanocomposites have great influence on adsorption capacities and introducing a small amount of MMT could improve adsorption ability of the CTS-g-PAA. The adsorption behaviors of the nanocomposite showed that the adsorption kinetics and isotherms were in good agreement with pseudo-second-order equation and the Langmuir equation. respectively. and the maximum adsorption capacity is 1859 mg/g for CTS-g-PAA …,True,XEUiPccAAAAJ:WA5NYHcadZ8C,326,https://www.sciencedirect.com/science/article/pii/S0927775708001271,5677375545500040656,/scholar?cites=5677375545500040656,,,http://www.emec.licp.cas.cn/kycg/2008/201207/W020110605409048096930.pdf,0,0,0
1277316,Magnetic. Durable. and Superhydrophobic Polyurethane@Fe3O4@SiO2@Fluoropolymer Sponges for Selective Oil Absorption and Oil/Water Separation,2015,Lei Wu and Lingxiao Li and Bucheng Li and Junping Zhang and Aiqin Wang,7,ACS applied materials & interfaces,8,4936-4946,American Chemical Society,Magnetic. durable. and superhydrophobic polyurethane (PU) sponges were fabricated by chemical vapor deposition (CVD) of tetraethoxysilane (TEOS) to bind the Fe3O4 nanoparticles tightly on the sponge and then dip-coating in a fluoropolymer (FP) aqueous solution. The sponges were characterized using scanning electron microscopy and other analytical techniques. The effects of CVD time of TEOS and FP concentration on wettability. mechanical properties. oil absorbency. and oil/water selectivity of the sponges were also investigated. The sponges exhibit fast magnetic responsivity and excellent superhydrophobicity/superoleophilicity (CAwater = 157° and CAoil ≈ 0°). The sponges also show very high efficiency in oil/water separation and could. driven by a magnet. quickly absorb floating oils on the water surface and heavy oils under water. Moreover. the PU@Fe3O4@SiO2@FP sponges could be used as …,True,XEUiPccAAAAJ:W5xh706n7nkC,304,https://pubs.acs.org/doi/abs/10.1021/am5091353,16521802671338009511,/scholar?cites=16521802671338009511,,,,0,0,0
1277317,Utilization of starch and clay for the preparation of superabsorbent composite,2007,An Li and Junping Zhang and Aiqin Wang,98,Bioresource technology,2,327-332,Elsevier,Starch and attapulgite were utilized as raw material for synthesizing starch-graft-poly(acrylic acid)/attapulgite superabsorbent composite by graft copolymerization reaction of starch and acrylic acid (AA) in the presence of attapulgite micropowder in aqueous solution. Major factors affecting on water absorbency such as weight ratio of AA to starch. initial monomer concentration. neutralization degree of AA. amount of crosslinker. initiator and attapulgite were investigated. The superabsorbent composite synthesized under optimal synthesis conditions with an attapulgite content of 10 wt% exhibit absorption of 1077 g H2O/g sample and 61 g H2O/g sample in distilled water and in 0.9 wt% NaCl solution. respectively. This superabsorbent composite with excellent water absorbency and water retention under load. being biodegradable in nature. economical and environment-friendly. could be especially useful in agricultural …,True,XEUiPccAAAAJ:9vf0nzSNQJEC,252,https://www.sciencedirect.com/science/article/pii/S0960852406000101,10035107107788924137,/scholar?cites=10035107107788924137,,,,0,0,0
1277318,Fast removal of methylene blue from aqueous solution by adsorption onto chitosan-g-poly (acrylic acid)/attapulgite composite,2011,Li Wang and Junping Zhang and Aiqin Wang,266,Desalination,1-3,33-39,Elsevier,Batch adsorption experiments were carried out for the removal of methylene blue (MB) cationic dye from aqueous solution using chitosan-g-poly (acrylic acid)/attapulgite composites (CTS-g-PAA/APT) as adsorbent. The effects of attapulgite (APT) content. initial pH value of the dye solution and temperature on adsorption were investigated. Results showed that APT content of composites had some influence on adsorption capacities. and introducing a small amount of APT could improve adsorption capacity of chitosan-g-poly (acrylic acid) (CTS-g-PAA) to a certain extent. Results from kinetic experimental data showed that the adsorption rate of MB on CTS-g-PAA and CTS-g-PAA/APT with 30% of APT was fast. and more than 90% of the maximum adsorption capacities for MB were achieved within the initial 15 min. The adsorption behaviors of CTS-g-PAA and CTS-g-PAA/APT showed that the adsorption kinetics and …,True,XEUiPccAAAAJ:5awf1xo2G04C,250,https://www.sciencedirect.com/science/article/pii/S0011916410005631,10569205499288262963,/scholar?cites=10569205499288262963,,,http://www.emec.licp.cas.cn/kycg/201011/W020110416389475361562.pdf,0,0,0
1277319,Preparation and characterization of a novel pH-sensitive chitosan-g-poly (acrylic acid)/attapulgite/sodium alginate composite hydrogel bead for controlled release of diclofenac …,2009,Qin Wang and Junping Zhang and Aiqin Wang,78,Carbohydrate Polymers,4,731-737,Elsevier,A series of pH-sensitive composite hydrogel beads composed of chitosan-g-poly (acrylic acid)/attapulgite/sodium alginate (CTS-g-PAA/APT/SA) was prepared as drug delivery matrices crosslinked by Ca2+ owing to the ionic gelation of SA. The structure and surface morphology of the composite hydrogel beads were characterized by FTIR and SEM. respectively. pH-sensitivity of these composite hydrogels beads and the release behaviors of drug from them were investigated. The results showed that the composite hydrogel beads had good pH-sensitivity. The cumulative release ratios of diclofenac sodium (DS) from the composite hydrogel beads were 3.76% in pH 2.1 solution and 100% in pH 6.8 solutions within 24 h. respectively. However. the cumulative release ratio of DS in pH 7.4 solution reached 100% within 2 h. The DS cumulative release ratio reduced with increasing APT content from 0 to 50 wt%. The drug …,True,XEUiPccAAAAJ:eMMeJKvmdy0C,249,https://www.sciencedirect.com/science/article/pii/S0144861709003324,6637751685364902246,/scholar?cites=6637751685364902246,,,http://www.emec.licp.cas.cn/kycg/2009/201207/W020110418555192776164.pdf,0,0,0
1277320,In situ generation of sodium alginate/hydroxyapatite nanocomposite beads as drug-controlled release matrices,2010,Junping Zhang and Qin Wang and Aiqin Wang,6,Acta Biomaterialia,2,445-454,Elsevier,In order to find a new way to slow down the release of drugs and to solve the burst release problem of drugs from traditionally used hydrogel matrices. a series of novel pH-sensitive sodium alginate/hydroxyapatite (SA/HA) nanocomposite beads was prepared by the in situ generation of HA micro-particles in the beads during the sol–gel transition process of SA. The SA/HA nanocomposites were characterized by Fourier transform IR spectroscopy. X-ray fluorescence spectrometry. scanning electron microscopy and field emission SEM in order to reveal their composition and surface morphology as well as the role that the in situ generated HA micro-particles play. The factors influencing the swelling behavior. drug loading and controlled release behavior of the SA/HA nanocomposite beads were also investigated using diclofenac sodium (DS) as the model drug. The HA micro-particles act as inorganic crosslinkers in …,True,XEUiPccAAAAJ:N5tVd3kTz84C,215,https://www.sciencedirect.com/science/article/pii/S1742706109002864,11849715445444317609,/scholar?cites=11849715445444317609,,,,0,0,0
1277321,Durable superhydrophobic/superoleophilic PDMS sponges and their applications in selective oil absorption and in plugging oil leakages,2014,Xia Zhao and Lingxiao Li and Bucheng Li and Junping Zhang and Aiqin Wang,2,Journal of Materials Chemistry A,43,18281-18287,Royal Society of Chemistry,A facile method for preparing porous polydimethylsiloxane (PDMS) sponges is reported. The PDMS sponges are fabricated by the polymerization of the PDMS prepolymer and a curing agent in dimethicone using NaCl microparticles as the hard templates. The porous structure of the PDMS sponges is controllable simply by regulating the weight ratio of prepolymer to dimethicone and the size of the NaCl microparticles. The PDMS sponges feature high compressibility and stretchability. excellent superhydrophobicity/superoleophilicity. as well as high chemical and thermal stability. The PDMS sponge can completely recover its original shape even after 50 cycles of 90% strain. The elongation at breaking the sponge is as high as 97%. The PDMS sponge is superhydrophobic with a water contact angle of 151.5° but can be easily wetted by oils. The sponge also exhibits excellent repellency to corrosive aqueous liquids …,True,XEUiPccAAAAJ:t6usbXjVLHcC,195,https://pubs.rsc.org/ko/content/articlehtml/2014/ta/c4ta04406a,4674828712503464552,/scholar?cites=4674828712503464552,,,,0,0,0
1277322,Study on superabsorbent composites. IX: synthesis. characterization and swelling behaviors of polyacrylamide/clay composites based on various clays,2007,Junping Zhang and Aiqin Wang,67,Reactive and Functional Polymers,8,737-745,Elsevier,A series of clay-based superabsorbent composite from acrylamide (AM) and various clays. such as attapulgite. kaolinite. mica. vermiculate and Na+-montmorillonite. was prepared by free-radical aqueous polymerization. using N.N′-methylenebisacrylamide (MBA) as a crosslinker and ammonium persulfate (APS) as an initiator. and then saponified with sodium hydroxide solution. In this paper. the reaction mechanism and thermal stability of the superabsorbent composites incorporated with various clays were characterized by FTIR. XRD and TGA. respectively. The effects of clay kind and clay content on equilibrium water absorbency of these composites were also investigated and compared. In addition. the influences of clay kind on comprehensive swelling behaviors of the PAM/clay superabsorbent composites were studied. The results indicated that the introduced clays could influence physicochemical properties …,True,XEUiPccAAAAJ:V3AGJWp-ZtQC,192,https://www.sciencedirect.com/science/article/pii/S1381514807000776,2863170642781315482,/scholar?cites=2863170642781315482,,,,0,0,0
1277323,A cooperative approach to particle swarm optimization,2004,Frans Van den Bergh and Andries Petrus Engelbrecht,8,IEEE transactions on evolutionary computation,3,225-239,IEEE,The particle swarm optimizer (PSO) is a stochastic. population-based optimization technique that can be applied to a wide range of problems. including neural network training. This paper presents a variation on the traditional PSO algorithm. called the cooperative particle swarm optimizer. or CPSO. employing cooperative behavior to significantly improve the performance of the original algorithm. This is achieved by using multiple swarms to optimize different components of the solution vector cooperatively. Application of the new PSO algorithm on several benchmark optimization problems shows a marked improvement in performance over the traditional PSO.,True,5QgVm4YAAAAJ:u-x6o8ySG0sC,2235,https://ieeexplore.ieee.org/abstract/document/1304845/,846231454659678828,/scholar?cites=846231454659678828,,,https://staff.fmi.uvt.ro/~daniela.zaharie/ma2017/projects/techniques/coevolution/cooperativePSO2004.pdf,0,0,0
1277324,An Analysis of Particle Swarm Optimizers,2002,F van den Bergh,,,,,,,True,5QgVm4YAAAAJ:2P1L_qKh6hAC,1606,,3636880421420411319,/scholar?cites=3636880421420411319,,,,0,0,0
1277325,A study of particle swarm optimization particle trajectories,2006,Frans Van den Bergh and Andries Petrus Engelbrecht,176,Information sciences,8,937-971,Elsevier,Particle swarm optimization (PSO) has shown to be an efficient. robust and simple optimization algorithm. Most of the PSO studies are empirical. with only a few theoretical analyses that concentrate on understanding particle trajectories. These theoretical studies concentrate mainly on simplified PSO systems. This paper overviews current theoretical studies. and extend these studies to investigate particle trajectories for general swarms to include the influence of the inertia term. The paper also provides a formal proof that each particle converges to a stable point. An empirical analysis of multi-dimensional stochastic particles is also presented. Experimental results are provided to support the conclusions drawn from the theoretical findings.,True,5QgVm4YAAAAJ:35N4QoGY0k4C,1386,https://www.sciencedirect.com/science/article/pii/S0020025505000630,7973273329241806423,/scholar?cites=7973273329241806423,,,http://researchspace.csir.co.za/dspace/bitstream/handle/10204/1155/van%20den%20bergh_2006_D.pdf?sequence=1,0,0,0
1277326,A new locally convergent particle swarm optimiser,2002,Frans van den Bergh and AP Engelbrecht,3,,,6 pp. vol. 3,Ieee,This paper introduces a new Particle Swarm Optimisation (PSO) algorithm with strong local convergence properties. The new algorithm performs much better with a smaller number of particles. compared to the original PSO. This property is desirable when designing a niching PSO algorithm.,True,5QgVm4YAAAAJ:2osOgNQ5qMEC,639,https://ieeexplore.ieee.org/abstract/document/1176018/,18222055224991800656,/scholar?cites=18222055224991800656,,,,0,0,0
1277327,Cooperative learning in neural networks using particle swarm optimizers,2000,Frans Van den Bergh and Andries Petrus Engelbrecht,2000,South African Computer Journal,26,84-90,South African Computer Society (SAICSIT),       This paper presents a method to employ particle swarms optimizers in a cooperative configuration. This is achieved by splitting the input vector into several sub-vectors. each which is       optimized cooperatively in its own swarm. the application of this technique to neural network training is investigated. with promising results.     ,True,5QgVm4YAAAAJ:9yKSN-GCB0IC,505,https://journals.co.za/doi/abs/10.10520/EJC27898,15573516249875779861,/scholar?cites=15573516249875779861,,,,0,0,0
1277328,A niching particle swarm optimizer,2002,R Brits and Andries P Engelbrecht and F Van den Bergh,2,Proceedings of the 4th Asia-Pacific conference on simulated evolution and learning,,692-696,Singapore: Orchid Country Club,This paper describes a technique that extends the unimodal particle swarm optimizer to efficiently locate multiple optimal solutions in multimodal problems. Multiple subswarms are grown from an initial particle swarm by monitoring the fitness of individual particles. Experimental results show that the proposed algorithm can successfully locate all maxima on a small set of test functions during all simulation runs.,True,5QgVm4YAAAAJ:UeHWp8X0CEIC,488,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.6137&rep=rep1&type=pdf,6498949325588746660,/scholar?cites=6498949325588746660,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.6137&rep=rep1&type=pdf,0,0,0
1277329,Using neighbourhoods with the guaranteed convergence PSO,2003,ES Peer and F Van den Bergh and AP Engelbrecht,,,,235-242,Ieee,The standard particle swarm optimiser (PSO) may prematurely converge on suboptimal solutions that are not even guaranteed to be local extrema. The guaranteed convergence modifications to the PSO algorithm ensure that the PSO at least converges on a local extremum at the expense of even faster convergence. This faster convergence means that less of the search space is explored reducing the opportunity of the swarm to find better local extrema. Various neighbourhood topologies inhibit premature convergence by preserving swarm diversity during the search. This paper investigates the performance of the guaranteed convergence PSO (GCPSO) using different neighbourhood topologies and compares the results with their standard PSO counterparts.,True,5QgVm4YAAAAJ:zYLM7Y9cAGgC,276,https://ieeexplore.ieee.org/abstract/document/1202274/,5983749817708075811,/scholar?cites=5983749817708075811,,,,0,0,0
1277330,Locating multiple optima using particle swarm optimization,2007,R Brits and AP Engelbrecht and F Van den Bergh,189,Applied Mathematics and Computation,2,1859-1883,Elsevier,Many scientific and engineering applications require optimization methods to find more than one solution to multi-modal optimization problems. This paper presents a new particle swarm optimization (PSO) technique to locate and refine multiple solutions to such problems. The technique. NichePSO. extends the inherent unimodal nature of the standard PSO approach by growing multiple swarms from an initial particle population. Each subswarm represents a different solution or niche; optimized individually. The outcome of the NichePSO algorithm is a set of particle swarms. each representing a unique solution. Experimental results are provided to show that NichePSO can successfully locate all optima on a small set of test functions. These results are compared with another PSO niching algorithm. lbest PSO. and two genetic algorithm niching approaches. The influence of control parameters is investigated …,True,5QgVm4YAAAAJ:Tyk-4Ss8FVUC,267,https://www.sciencedirect.com/science/article/pii/S0096300306017826,1274764260554972512,/scholar?cites=1274764260554972512,,,http://researchspace.csir.co.za/dspace/bitstream/handle/10204/801/Brits_2007.pdf?sequence=1&isAllowed=y,0,0,0
1277331,Effects of swarm size on cooperative particle swarm optimisers,2001,Frans Van den Bergh and Andries P Engelbrecht,,,,,,,True,5QgVm4YAAAAJ:IjCSPb-OGe4C,246,,17678204766959696520,/scholar?cites=17678204766959696520,,,,0,0,0
1277332,Training product unit networks using cooperative particle swarm optimisers,2001,Frans Van Den Bergh and Andries P Engelbrecht,1,,,126-131,IEEE,The cooperative particle swarm optimiser (CPSO) is a variant of the particle swarm optimiser (PSO) that splits the problem vector. for example a neural network weight vector. across several swarms. The paper investigates the influence that the number of swarms used (also called the split factor) has on the training performance of a product unit neural network. Results are presented. comparing the training performance of the two algorithms. PSO and CPSO. as applied to the task of training the weight vector of a product unit neural network.,True,5QgVm4YAAAAJ:qjMakFHDy7sC,231,https://ieeexplore.ieee.org/abstract/document/939004/,6317459590788982375,/scholar?cites=6317459590788982375,,,https://www.researchgate.net/profile/Andries_Engelbrecht/publication/2371428_Training_Product_Unit_Networks_using_Cooperative_Particle_Swarm_Optimisers/links/00b7d524a5d3d21dda000000/Training-Product-Unit-Networks-using-Cooperative-Particle-Swarm-Optimisers.pdf,0,0,0
1277333,Limits to detectability of land degradation by trend analysis of vegetation index data,2012,KJ Wessels and F Van den Bergh and RJ Scholes,125,Remote Sensing of Environment,,10-22,Elsevier,This paper demonstrates a simulation approach for testing the sensitivity of linear and non-parametric trend analysis methods applied to remotely sensed vegetation index data for the detection of land degradation. The intensity. rate and timing of reductions in seasonally-summed NDVI are systematically varied on sample data to simulate land degradation. after which the trend analysis was applied and its sensitivity evaluated. The study was based on a widely-used. 1 km2 AVHRR data set for a test area in southern Africa. The trends were the most negative and significant when the degradation was introduced rapidly (over a period of 2–5 years) and in the middle of a 16-year time series. The seasonally-summed NDVI needs to be reduced by 30–40% before a significant negative linear slope or Kendall's correlation coefficient was apparent. given an underlying positive trend caused by rainfall. The seasonally …,True,5QgVm4YAAAAJ:M3NEmzRMIkIC,230,https://www.sciencedirect.com/science/article/pii/S0034425712002581,16255185518253869164,/scholar?cites=16255185518253869164,,,,0,0,0
1277334,Genetic variants in novel pathways influence blood pressure and cardiovascular disease risk,2011,Georg B Ehret and Patricia B Munroe and Kenneth M Rice and Murielle Bochud and Andrew D Johnson and Daniel I Chasman and Albert V Smith and Martin D Tobin and Germaine C Verwoert and Shih-Jen Hwang and Vasyl Pihur and Peter Vollenweider and Paul F O’Reilly and Najaf Amin and Jennifer L Bragg-Gresham and Alexander Teumer and Nicole L Glazer and Lenore Launer and Jing Hua Zhao and Yurii Aulchenko and Simon Heath and Siim Sõber and Afshin Parsa and Jian’an Luan and Pankaj Arora and Abbas Dehghan and Feng Zhang and Gavin Lucas and Andrew A Hicks and Anne U Jackson and John F Peden and Toshiko Tanaka and Sarah H Wild and Igor Rudan and Wilmar Igl and Yuri Milaneschi and Alex N Parker and Cristiano Fava and John C Chambers and Ervin R Fox and Meena Kumari and Min Jin Go and Pim van der Harst and Wen Hong Linda Kao and Marketa Sjögren and DG Vinay and Myriam Alexander and Yasuharu Tabara and Sue Shaw-Hawkins and Peter H Whincup and Yongmei Liu and Gang Shi and Johanna Kuusisto and Bamidele Tayo and Mark Seielstad and Xueling Sim and Khanh-Dung Hoang Nguyen and Terho Lehtimäki and Giuseppe Matullo and Ying Wu and Tom R Gaunt and N Charlotte Onland-Moret and Matthew N Cooper and Carl GP Platou and Elin Org and Rebecca Hardy and Santosh Dahgam and Jutta Palmen and Veronique Vitart and Peter S Braund and Tatiana Kuznetsova and Cuno SPM Uiterwaal and Adebowale Adeyemo and Walter Palmas and Harry Campbell and Barbara Ludwig and Maciej Tomaszewski and Ioanna Tzoulaki and Nicholette D Palmer and Thor Aspelund and Melissa Garcia and Yen-Pei C Chang and Jeffrey R O’Connell and Nanette I Steinle and Diederick E Grobbee and Dan E Arking and Sharon L Kardia and Alanna C Morrison and Dena Hernandez and Samer Najjar and Wendy L McArdle and David Hadley and Morris J Brown and John M Connell and Aroon D Hingorani and Ian NM Day and Debbie A Lawlor and John P Beilby and Robert W Lawrence and Robert Clarke and Jemma C Hopewell and Halit Ongen and Albert W Dreisbach and Yali Li and J Hunter Young and Joshua C Bis and Mika Kähönen and Jorma Viikari and Linda S Adair and Nanette R Lee and Ming-Huei Chen and Matthias Olden and Cristian Pattaro and Judith A Hoffman Bolton and Anna Köttgen and Sven Bergmann and Vincent Mooser and Nish Chaturvedi and Timothy M Frayling and Muhammad Islam and Tazeen H Jafar and Jeanette Erdmann and Smita R Kulkarni and Stefan R Bornstein and Jürgen Grässler and Leif Groop and Benjamin F Voight and Johannes Kettunen and Philip Howard and Andrew Taylor and Simonetta Guarrera and Fulvio Ricceri and Valur Emilsson and Andrew Plump and Inês Barroso and Kay-Tee Khaw and Alan B Weder and Steven C Hunt and Yan V Sun and Richard N Bergman and Francis S Collins and Lori L Bonnycastle and Laura J Scott and Heather M Stringham and Leena Peltonen and Markus Perola and Erkki Vartiainen and Stefan-Martin Brand and Jan A Staessen and Thomas J Wang,478,Nature,7367,103,Nature Publishing Group,Blood pressure is a heritable trait 1 influenced by several biological pathways and responsive to environmental stimuli. Over one billion people worldwide have hypertension (≥ 140 mm Hg systolic blood pressure or≥ 90 mm Hg diastolic blood pressure) 2. Even small increments in blood pressure are associated with an increased risk of cardiovascular events 3. This genome-wide association study of systolic and diastolic blood pressure. which used a multi-stage design in 200.000 individuals of European descent. identified sixteen novel loci: six of these loci contain genes previously known or suspected to regulate blood pressure (GUCY1A3–GUCY1B3. NPR3–C5orf23. ADM. FURIN–FES. GOSR2. GNAS–EDN3); the other ten provide new clues to blood pressure physiology. A genetic risk score based on 29 genome-wide significant variants was associated with hypertension. left ventricular wall thickness. stroke …,True,O4cuJDQAAAAJ:YanO1q2l3soC,1894,https://www.nature.com/articles/nature10405,8003231049648615606,/scholar?cites=8003231049648615606,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3340926/,0,0,0
1277335,A prospective. single-arm. multicenter trial of ultrasound-facilitated. catheter-directed. low-dose fibrinolysis for acute massive and submassive pulmonary embolism: the …,2015,Gregory Piazza and Benjamin Hohlfelder and Michael R Jaff and Kenneth Ouriel and Tod C Engelhardt and Keith M Sterling and Noah J Jones and John C Gurley and Rohit Bhatheja and Robert J Kennedy and Nilesh Goswami and Kannan Natarajan and John Rundback and Immad R Sadiq and Stephen K Liu and Narinder Bhalla and M Laiq Raja and Barry S Weinstock and Jacob Cynamon and Fakhir F Elmasri and Mark J Garcia and Mark Kumar and Juan Ayerdi and Peter Soukas and William Kuo and Ping-Yu Liu and Samuel Z Goldhaber and SEATTLE II Investigators,8,JACC: Cardiovascular Interventions,10,1382-1392,American College of Cardiology Foundation,This study conducted a prospective. single-arm. multicenter trial to evaluate the safety and efficacy of ultrasound-facilitated. catheter-directed. low-dose fibrinolysis. using the EkoSonic Endovascular System (EKOS. Bothell. Washington).Systemic fibrinolysis for acute pulmonary embolism (PE) reduces cardiovascular collapse but causes hemorrhagic stroke at a rate exceeding 2%.Eligible patients had a proximal PE and a right ventricular (RV)-to-left ventricular (LV) diameter ratio ≥0.9 on chest computed tomography (CT). We included 150 patients with acute massive (n = 31) or submassive (n = 119) PE. We used 24 mg of tissue-plasminogen activator (t-PA) administered either as 1 mg/h for 24 h with a unilateral catheter or 1 mg/h/catheter for 12 h with bilateral catheters. The primary safety outcome was major bleeding within 72 h of procedure initiation. The primary efficacy outcome …,True,O4cuJDQAAAAJ:qOpkhvVCMvUC,501,https://www.jacc.org/doi/abs/10.1016/j.jcin.2015.04.020,5939563065043377565,/scholar?cites=5939563065043377565,,,https://www.sciencedirect.com/science/article/pii/S1936879815008353,0,0,0
1277336,Sensitivity of food pathogens to garlic (Allium sativum),1998,M Kumar and JS Berwal,84,Journal of Applied Microbiology,2,213-215,Blackwell Science Ltd,The inhibitory activity of garlic (Allium sativum) against Staphylococcus aureus. Salmonella typhi. Escherichia coli and Listeria monocytogenes was measured by the ‘turbidity’ method. Minimum inhibitory concentration (MIC) of garlic at 80% inhibition level was calculated for these bacteria. All bacterial pathogenic strains tested were inhibited by garlic; E. coli was most sensitive and Listeria monocytogenes was least sensitive. Therefore. garlic has potential for the preservation of processed foods.,True,O4cuJDQAAAAJ:yFnVuubrUp4C,278,https://sfamjournals.onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2672.1998.00327.x,4728623273538666282,/scholar?cites=4728623273538666282,,,https://sfamjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1046/j.1365-2672.1998.00327.x,0,0,0
1277337,Type 1 autoimmune pancreatitis and IgG4-related sclerosing cholangitis is associated with extrapancreatic organ failure. malignancy. and mortality in a prospective UK cohort,2014,Matthew T Huggett and EL Culver and M Kumar and JM Hurst and M Rodriguez-Justo and MH Chapman and GJ Johnson and SP Pereira and RW Chapman and George JM Webster and E Barnes,109,The American journal of gastroenterology,10,1675,Europe PMC Funders,OBJECTIVESType I autoimmune pancreatitis (AIP) and IgG4-related sclerosing cholangitis (IgG4-related SC) are now recognized as components of a multisystem IgG4-related disease (IgG4-RD). We aimed to define the clinical course and long-term outcomes in patients with AIP/IgG4-SC recruited from two large UK tertiary referral centers.METHODSData were collected from 115 patients identified between 2004 and 2013. and all were followed up prospectively from diagnosis for a median of 33 months (range 1–107). and evaluated for response to therapy. the development of multiorgan involvement. and malignancy. Comparisons were made with national UK statistics.RESULTSAlthough there was an initial response to steroids in 97%. relapse occurred in 50% of patients. IgG4-SC was an important predictor of relapse (P< 0.01). Malignancy occurred in 11% shortly before or after the diagnosis of IgG4-RD …,True,O4cuJDQAAAAJ:EmjvLWWcsQIC,188,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4552254/,11090767313742156325,/scholar?cites=11090767313742156325,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4552254/,0,0,0
1277338,Relative severity of aflatoxin contamination of cereal crops in West Africa,2007,Ranajit Bandyopadhyay and Manjula Kumar and John F Leslie,24,Food additives and contaminants,10,1109-1114,Taylor & Francis Group,Aflatoxins are a common contaminant of cereals that can cause cancer. liver disease. immune suppression. retarded growth and development. and death. depending on the level and duration of exposure. Maize is an introduced crop to Africa and there have been efforts over the last 20 years or so to replace traditional cereal crops. such as sorghum (Sorghum bicolor) and pearl millet (Pennisetum glaucum). with maize. We found that maize was significantly more heavily colonized by aflatoxin-producing Aspergillus spp. than either sorghum or millet. with overall aflatoxin levels being correspondingly higher. On average. Nigerians consume 138 kg cereals annually. If the primary cereal is sorghum instead of maize. then the risk of aflatoxin-related problems is reduced 4-fold; if it is pearl millet. then the risks are reduced 8-fold. Development programs and other ventures to increase maize production in marginal …,True,O4cuJDQAAAAJ:qPeb-qHga9sC,171,https://www.tandfonline.com/doi/abs/10.1080/02652030701553251,15407227510505792799,/scholar?cites=15407227510505792799,,,,0,0,0
1277339,Antioxidant and antimicrobial activities of Bauhinia racemosa L. stem bark,2005,RS Kumar and T Sivakumar and RS Sunderam and M Gupta and UK Mazumdar and P Gomathi and Y Rajeshwar and S Saravanan and MS Kumar and K Murugesh and KA Kumar,38,Brazilian journal of medical and biological research,7,1015-1024,Brazilian Journal of Medical and Biological Research,The present study was carried out to evaluate the antioxidant and antimicrobial activities of a methanol extract of Bauhinia racemosa (MEBR) (Caesalpiniaceae) stem bark in various systems. 1.1-Diphenyl-2-picryl-hydrazyl (DPPH) radical. superoxide anion radical. nitric oxide radical. and hydroxyl radical scavenging assays were carried out to evaluate the antioxidant potential of the extract. The antioxidant activity of the methanol extract increased in a concentration-dependent manner. About 50. 100. 250. and 500 µg MEBR inhibited the peroxidation of a linoleic acid emulsion by 62.43. 67.21. 71.04. and 76.83%. respectively. Similarly. the effect of MEBR on reducing power increased in a concentration-dependent manner. In DPPH radical scavenging assays the IC50 value of the extract was 152.29 µg/ml. MEBR inhibited the nitric oxide radicals generated from sodium nitroprusside with an IC50 of 78.34 µg/ml. as opposed to 20.4 µg/ml for curcumin. Moreover. MEBR scavenged the superoxide generated by the PMS/NADH-NBT system. MEBR also inhibited the hydroxyl radical generated by Fenton's reaction. with an IC50 value of more than 1000 µg/ml. as compared to 5 µg/ml for catechin. The amounts of total phenolic compounds were also determined and 64.7 µg pyrocatechol phenol equivalents were detected in MEBR (1 mg). The antimicrobial activities of MEBR were determined by disc diffusion with five Gram-positive. four Gram-negative and four fungal species. MEBR showed broad-spectrum antimicrobial activity against all tested microorganisms. The results obtained in the present study indicate that MEBR can be a potential source of …,True,O4cuJDQAAAAJ:2hrGa7H818QC,169,https://www.scielo.br/scielo.php?pid=S0100-879X2005000700004&script=sci_arttext,18362481589438358750,/scholar?cites=18362481589438358750,,,https://www.scielo.br/scielo.php?pid=S0100-879X2005000700004&script=sci_arttext,0,0,0
1277340,Larvicidal and chemosterilant activity of Annona squamosa alkaloids against Anopheles stephensi,1993,RC Saxena and V Harshan and A Saxena and P Sukumaran and MC Sharma and M Lakshmana Kumar,9,JOURNAL-AMERICAN MOSQUITO CONTROL ASSOCIATION,,84-84,AMCA AMERICAN MOSQUITO CONTROL ASSOCIATION,Alkaloids isolated from Annona squarnosa have shown larvicidal growth-regulating and che. mosterilan-t activities against Anopheles stephensi at concentrations of 50 to 200 ppm. Adults exposed as larvae to different treatments showed reduced fecundity and fertility in females. Mortality in the larvae. pupae and adults produced about a 52-92Vo decrease in the laboratory experiment. The total developmental period was slightly reduced from the control. Treatment with the alkaloids had a significant effect on the mortality. emergence and reproductive physiology of An. stephensi.,True,O4cuJDQAAAAJ:bFuYayV9R1gC,123,http://www.biodiversitylibrary.org/content/part/JAMCA/JAMCA_V09_N1_P084-087.pdf,13851654807890245002,/scholar?cites=13851654807890245002,,,http://www.biodiversitylibrary.org/content/part/JAMCA/JAMCA_V09_N1_P084-087.pdf,0,0,0
1277341,Indigenous phytotherapy for genito-urinary diseases used by the Kandha tribe of Orissa. India,2005,Soumit K Behera and Malaya K Misra,102,Journal of ethnopharmacology,3,319-325,Elsevier,Studies on ethnomedicobotany of Kandha tribe of Orissa. India. are scanty. In view of this the original ethno-botanical information and plant specimens were collected from the Kandhamal district of Orissa by visiting the area several times. The paper reports 27 plant species belonging to 24 families used in the treatment of 17 diseases under the broad heading genito-urinary diseases by the Kandhas of Orissa. The use of these plants does not necessarily imply efficacy. but it does give a list of species that can be studied pharmacologically for its active principles and bioactive effect.,True,O4cuJDQAAAAJ:cAWJABFkdiUC,117,https://www.sciencedirect.com/science/article/pii/S0378874105004149,1710495881417931130,/scholar?cites=1710495881417931130,,,,0,0,0
1277342,Artocarpus gomezianus aided green synthesis of ZnO nanoparticles: luminescence. photocatalytic and antioxidant properties,2015,D Suresh and RM Shobharani and PC Nethravathi and MA Pavan Kumar and H Nagabhushana and SC Sharma,141,Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy,,128-134,Elsevier,We report green synthesis of multifunctional ZnO nanoparticles (NPs) using Artocarpus gomezianus (AG) extract as fuel by solution combustion synthesis. The formation of NPs was confirmed by powder XRD. SEM. TEM and UV–Visible studies. The NPs were subjected for photoluminescence. photodegradative and antioxidant studies. XRD data reveals that the ZnO NPs possess wurtzite structure. UV–Visible spectrum shows absorbance maximum at 370 nm which corresponds to the energy band gap of 3.3 eV. Morphology studies indicate the highly porous nature of the NPs. PL spectra of NPs found to display very interesting blue. green and red emissions upon excitation at 325 nm. The NPs exhibit potential photocatalytic activity towards the degradation of methylene blue (MB) dye upon exposure to sun light and UV light. ZnO NPs found to have considerable antioxidant activity against DPPH (2.2-diphenyl-1 …,True,O4cuJDQAAAAJ:xa5BkEQK8BgC,115,https://www.sciencedirect.com/science/article/pii/S1386142515000694,10298325605356548137,/scholar?cites=10298325605356548137,,,,0,0,0
1277343,Trace element studies on Tinospora cordifolia (Menispermaceae). Ocimum sanctum (Lamiaceae). Moringa oleifera (Moringaceae). and Phyllanthus niruri (Euphorbiaceae) using PIXE,2010,Ramadurai Gowrishankar and Manish Kumar and Vinay Menon and Sai Mangala Divi and M Saravanan and P Magudapathy and BK Panigrahi and KGM Nair and K Venkataramaniah,133,Biological trace element research,3,357-363,Humana Press Inc,Traditionally. Tinospora cordifolia (Willd.) Hook. F. & Thomson (Menispermaceae). Ocimum sanctum L. (Lamiaceae). Moringa oleifera Lam. (Moringaceae). and Phyllanthus niruri L. (Euphorbiaceae) are some of the commonly used medicinal plants in India for curing ailments ranging from common cold. skin diseases. and dental infections to major disorders like diabetes. hypertension. jaundice. rheumatism. etc. To understand and correlate their medicinal use. trace element studies on the aqueous extract of these medicinal plants have been carried out using particle-induced X-ray emission technique. A 2-MeV proton beam was used to identify and characterize major and minor elements namely Cl. K. Ca. Ti. Cr. Mn. Fe. Co. Ni. Cu. Zn. Br. and Sr in them. Results have revealed that these elements are present in varying concentrations in the selected plants. Notable results include very high concentrations of …,True,O4cuJDQAAAAJ:cB__R-XWw9UC,96,https://link.springer.com/article/10.1007/s12011-009-8439-1,17995969200794117791,/scholar?cites=17995969200794117791,,,https://www.researchgate.net/profile/Gowrishankar_Ramadurai/publication/225343733_Trace_Element_Studies_on_Tinospora_cordifolia_Menispermaceae_Ocimum_sanctum_Lamiaceae_Moringa_oleifera_Moringaceae_and_Phyllanthus_niruri_Euphorbiaceae_Using_PIXE/links/0c96051baa49f815c6000000.pdf,0,0,0
1277344,The association between vulvovaginal atrophy symptoms and quality of life among postmenopausal women in the United States and Western Europe,2015,Marco DiBonaventura and Xuemei Luo and Margaret Moffatt and Andrew G Bushmakin and Maya Kumar and Joel Bobula,24,Journal of women's health,9,713-722,Mary Ann Liebert. Inc.,Background: Vulvovaginal atrophy (VVA) is a condition associated with decreased estrogenization of the vaginal tissue. which can result in vaginal dryness. irritation. and dyspareunia. This study quantified the burden associated with VVA symptoms across the United States and Europe and compared this burden with other chronic conditions.Methods: Data were analyzed from the International Women's Health Study. a cross-sectional Internet survey of women aged 40–75 years in the United States and Europe. All postmenopausal women aged 40–75 years were included in the analyses (Germany n=970. Spain n=294. France n=1054. Italy n=387. United Kingdom n=1096. United States n=3267). VVA symptom severity (none. mild. moderate. severe) was assessed using the Menopause Rating Scale and included in general linear models to predict EuroQol-5D (EQ-5D) quality of life scores.Results: The …,True,O4cuJDQAAAAJ:Nufq_to8ts0C,91,https://www.liebertpub.com/doi/abs/10.1089/jwh.2014.5177,4699632244519021600,/scholar?cites=4699632244519021600,,,,0,0,0
1277345,Bioinspired surface immobilization of hyaluronic acid on monodisperse magnetite nanocrystals for targeted cancer imaging,2008,Yuhan Lee and Haeshin Lee and Young Beom Kim and Jaeyoon Kim and Taeghwan Hyeon and HyunWook Park and Phillip B Messersmith and Tae Gwan Park,20,Advanced Materials,21,4154-4157,WILEY‐VCH Verlag,Hyaluronic‐acid immobilized monodisperse magnetic nanocrystals (HA‐DN/MNCs) are synthesized. Dopamine. the analogue of 3. 4‐dihydroxy‐L‐phenylalanine responsible for the adhesion properties in proteins excreted by mussels. plays a key role in the surface modification of nanocrystals. HA‐DN/MNCs exhibit great stability in aqueous solution. applicable for in vivo targeted‐cancer imaging.,True,8CQAn68AAAAJ:Tyk-4Ss8FVUC,330,https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.200800756,13456871184463260204,/scholar?cites=13456871184463260204,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2709854/,0,0,0
1277346,Statistical textural features for detection of microcalcifications in digitized mammograms,1999,Jong Kook Kim and Hyun Wook Park,18,IEEE transactions on medical imaging,3,231-238,IEEE,Clustered microcalcifications on X-ray mammograms are an important sign for early detection of breast cancer. Texture-analysis methods can be applied to detect clustered microcalcifications in digitized mammograms. In this paper. a comparative study of texture-analysis methods is performed for the surrounding region-dependence method. which has been proposed by the authors. and conventional texture-analysis methods. such as the spatial gray level dependence method. the gray-level run-length method. and the gray-level difference method. Textural features extracted by these methods are exploited to classify regions of interest (ROI's) into positive ROI's containing clustered microcalcifications and negative ROI's containing normal tissues. A three-layer backpropagation neural network is used as a classifier. The results of the neural network for the texture-analysis methods are evaluated by using a receiver …,True,8CQAn68AAAAJ:d1gkVwhDpl0C,315,https://ieeexplore.ieee.org/abstract/document/764896/,6806233936505585213,/scholar?cites=6806233936505585213,,,https://www.researchgate.net/profile/Hyunwook_Park/publication/12934713_Statistical_textural_features_for_detection_of_microcalcifications_in_digitized_mammograms/links/53d8e0ae0cf2a19eee838d2f/Statistical-textural-features-for-detection-of-microcalcifications-in-digitized-mammograms.pdf,0,0,0
1277347,Brain–computer interface using fMRI: spatial navigation by thoughts,2004,Seung-Schik Yoo and Ty Fairneny and Nan-Kuei Chen and Seh-Eun Choo and Lawrence P Panych and HyunWook Park and Soo-Young Lee and Ferenc A Jolesz,15,Neuroreport,10,1591-1595,LWW,A brain–computer interface (BCI) is a way of conveying an individual's thoughts to control computer or electromechanical hardware. Capitalizing on the ability to characterize brain activity in a reproducible manner. we explored the possibility of using real-time fMRI to interpret the spatial distribution of brain function as BCI commands. Using a high-field (3 T) MRI scanner. brain activities associated with four distinct covert functional tasks were detected and subsequently translated into predetermined computer commands for moving four directional cursors. The proposed fMRI-BCI method allowed volunteer subjects to navigate through a simple 2D maze solely through their thought processes.,True,8CQAn68AAAAJ:9yKSN-GCB0IC,301,https://journals.lww.com/neuroreport/Fulltext/2004/07190/Brain_computer_interface_using_fMRI_spatial.12.aspx,13966058374554098637,/scholar?cites=13966058374554098637,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.689&rep=rep1&type=pdf,0,0,0
1277348,Loop-filtering method for image data and apparatus therefor,2003,Yung-Lyul Lee and Hyun-Wook Park,,,,,,A loop-filtering method for reducing quantization effect generated when an image data is encoded and decoded. and an apparatus therefor. The loop-filtering method includes the steps of extracting a flag indicating whether the image data requires loop-filtering using the distribution of inverse quantized coefficients (IQCs) of an inverse quantized image data and a motion vector indicating the difference between the previous frame and the current frame. The image data corresponding to the flag is then filtered by a predetermined method if the extracted flag indicates a need for the loop-filtering. Using the flags and an adaptive filter reduces the quantization effect and is useful to reduce the amount of computation required for the filtering. Also. the filtering can be performed through parallel processing without multiplication and division. so that the complexity of hardware can be reduced.,True,8CQAn68AAAAJ:3fE2CSJIrl8C,294,https://patents.google.com/patent/US6665346B1/en,10809788763288700078,/scholar?cites=10809788763288700078,,,https://patentimages.storage.googleapis.com/34/d6/b0/155d596edf6b5b/US6665346.pdf,0,0,0
1277349,Motion estimation using low-band-shift method for wavelet-based moving-picture coding,2000,Hyun-Wook Park and Hyung-Sun Kim,9,IEEE Transactions on Image processing,4,577-587,IEEE,The discrete wavelet transform (DWT) has several advantages of multiresolution analysis and subband decomposition. which has been successfully used in image processing. However. the shift-variant property is intrinsic due to the decimation process of the wavelet transform. and it makes the wavelet-domain motion estimation and compensation inefficient. To overcome the shift-variant property. a low-band-shift method is proposed and a motion estimation and compensation method in the wavelet-domain is presented. The proposed method has a superior performance to the conventional motion estimation methods in terms of the mean absolute difference (MAD) as well as the subjective quality. The proposed method can be a model method for the motion estimation in wavelet-domain just like the full-search block matching in the spatial domain.,True,8CQAn68AAAAJ:u5HHmVD_uO8C,258,https://ieeexplore.ieee.org/abstract/document/841935/,13680134027857413218,/scholar?cites=13680134027857413218,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1008.5104&rep=rep1&type=pdf,0,0,0
1277350,Blocking effect reduction of JPEG images by signal adaptive filtering,1998,YL Lee and HC Kim and HyunWook Park,7,IEEE Transactions on Image Processing,2,229-234,IEEE,A postprocessing algorithm is proposed to reduce the blocking artifacts of Joint Photographic Experts Group (JPEG) decompressed images. The reconstructed images from JPEG compression produce noticeable image degradation near the block boundaries. in particular for highly compressed images. because each block is transformed and quantized independently. The blocking effects are classified into three types of noises in this paper: grid noise. staircase noise. and corner outlier. The proposed postprocessing algorithm. which consists of three stages. reduces these blocking artifacts efficiently. A comparison study between the proposed algorithm and other postprocessing algorithms is made by computer simulation with several JPEG images.,True,8CQAn68AAAAJ:u-x6o8ySG0sC,240,https://ieeexplore.ieee.org/abstract/document/661000/,8322494168353515027,/scholar?cites=8322494168353515027,,,https://www.researchgate.net/profile/Hyunwook_Park/publication/3326748_Blocking_effect_reduction_of_JPEG_images_by_signal_adaptive_filtering/links/53fc2de10cf2dca8fffeec91/Blocking-effect-reduction-of-JPEG-images-by-signal-adaptive-filtering.pdf,0,0,0
1277351,Image data post-processing method for reducing quantization effect. apparatus therefor,2003,Yung-Lyul Lee and Hyun-Wook Park,,,,,,An image data post-processing method for reducing quantization effect induced when image data compressed based on a block is decoded. and an apparatus therefor. The image data post-processing method includes the steps of:(a) detecting semaphore representing whether or not post-processing is required. using distribution of inverse quantization coefficients of inverse-quantized image data and a motion vector representing the difference between the blocks of a previous video object plane (VOP) and blocks of a current VOP; and (b) filtering the decoded image data corresponding to the semaphore by a predetermined method. if it is determined by checking the detected semaphore that post-processing is required. Therefore. the quantization effect can be reduced by using the semaphore and an adaptive filter. and the amount of computation for filtering is also reduced. Also. the complexity of the hardware is …,True,8CQAn68AAAAJ:2osOgNQ5qMEC,215,https://patents.google.com/patent/US6539060B1/en,1394311056717661799,/scholar?cites=1394311056717661799,,,https://patentimages.storage.googleapis.com/pdfs/US6539060.pdf,0,0,0
1277352,Adaptive mammographic image enhancement using first derivative and local statistics,1997,Jong Kook Kim and Jeong Mi Park and Koun Sik Song and Hyun Wook Park,16,IEEE Transactions on medical imaging,5,495-502,IEEE,This paper proposes an adaptive image enhancement method for mammographic images. which is based on the first derivative and the local statistics. The adaptive enhancement method consists of three processing steps. The first step is to remove the film artifacts which may be misread as microcalcifications. The second step is to compute the gradient images by using the first derivative operators. The third step is to enhance the important features of the mammographic image by adding the adaptively weighted gradient images. Local statistics of the image are utilized for adaptive realization of the enhancement. so that image details can be enhanced and image noises can be suppressed. The objective performances of the proposed method were compared with those by the conventional image enhancement methods for a simulated image and the seven mammographic images containing real microcalcifications …,True,8CQAn68AAAAJ:qjMakFHDy7sC,196,https://ieeexplore.ieee.org/abstract/document/640739/,3566171077680485793,/scholar?cites=3566171077680485793,,,https://www.researchgate.net/profile/Hyunwook_Park/publication/13861985_Adaptive_mammographic_image_enhancement_using_first_derivative_and_local_statistics/links/547ee5190cf2d2200edeb033.pdf,0,0,0
1277353,Cultural influences on neural basis of intergroup empathy,2011,Bobby K Cheon and Dong-mi Im and Tokiko Harada and Ji-Sook Kim and Vani A Mathur and Jason M Scimeca and Todd B Parrish and Hyun Wook Park and Joan Y Chiao,57,NeuroImage,2,642-650,Academic Press,Cultures vary in the extent to which people prefer social hierarchical or egalitarian relations between individuals and groups. Here we examined the effect of cultural variation in preference for social hierarchy on the neural basis of intergroup empathy. Using cross-cultural neuroimaging. we measured neural responses while Korean and American participants observed scenes of racial ingroup and outgroup members in emotional pain. Compared to Caucasian-American participants. Korean participants reported experiencing greater empathy and elicited stronger activity in the left temporo-parietal junction (L-TPJ). a region previously associated with mental state inference. for ingroup compared to outgroup members. Furthermore. preferential reactivity within this region to the pain of ingroup relative to outgroup members was associated with greater preference for social hierarchy and ingroup biases in empathy …,True,8CQAn68AAAAJ:FgeqF4j-V1wC,195,https://www.sciencedirect.com/science/article/pii/S1053811911004307,17303341365256009193,/scholar?cites=17303341365256009193,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.705.7368&rep=rep1&type=pdf,0,0,0
1277354,Image resolution enhancement using inter-subband correlation in wavelet domain,2007,Yinji Piao and HyunWook Park,1,,,I-445-I-448,IEEE,Wavelet-based resolution enhancement methods improve the image resolution by estimating the high-frequency band information. In this paper. we propose a new resolution enhancement method using inter-subband correlation in which the sampling phase in DWT is considered. Interpolation filters are designed by analyzing correlations between subbands having different sampling phases in the lower level. and applied to the correlated subbands in the higher level. The filters are estimated under the assumption that correlations between two subbands in the higher level are similar to that in the lower level in DWT. The experimental results show that our proposed method outperforms the conventional interpolation methods including the other wavelet-based methods with respect to peak signal-to-noise-ratio (PSNR) as well as the subjective quality.,True,8CQAn68AAAAJ:qUcmZB5y_30C,193,https://ieeexplore.ieee.org/abstract/document/4378987/,15270129909972028040,/scholar?cites=15270129909972028040,,,https://koasas.kaist.ac.kr/bitstream/10203/3146/3/Image%20Resolution%20Enhancement%20using%20Inter-Subband%20Correlation%20in%20Wavelet%20Domain%28%EC%B6%9C%ED%8C%90%EC%82%AC%EB%B2%84%EC%A0%84_%EB%B0%95%ED%98%84%EC%9A%B1%29.pdf,0,0,0
1277355,Bioinspired Synthesis and Characterization of Gadolinium-Labeled Magnetite Nanoparticles for Dual Contrast T1- and T2-Weighted Magnetic Resonance Imaging,2010,Ki Hyun Bae and Young Beom Kim and Yuhan Lee and JinYoung Hwang and HyunWook Park and Tae Gwan Park,21,Bioconjugate chemistry,3,505-512,American Chemical Society,Gadolinium-labeled magnetite nanoparticles (GMNPs) were synthesized via a bioinspired manner to use as dual contrast agents for T1- and T2-weighted magnetic resonance imaging. A mussel-derived adhesive moiety. 3.4-dihydroxy-l-phenylalanine (DOPA). was utilized as a robust anchor to form a mixed layer of poly(ethylene glycol) (PEG) chains and dopamine molecules on the surface of iron oxide nanoparticles. Gadolinium ions were subsequently complexed at the distal end of the dopamine molecules that were prefunctionalized with a chelating ligand for gadolinium. The resultant GMNPs exhibited high dispersion stability in aqueous solution. Crystal structure and superparamagnetic properties of magnetite nanocrystals were also maintained after the complexation of gadolinium. The potential of GMNPs as dual contrast agents for T1 and T2-weighted magnetic resonance imaging was demonstrated by …,True,8CQAn68AAAAJ:5nxA0vEk-isC,191,https://pubs.acs.org/doi/abs/10.1021/bc900424u,12253756650263410997,/scholar?cites=12253756650263410997,,,,0,0,0
1277356,On observability of discrete-event systems,1988,Feng Lin and Walter Murray Wonham,44,Information sciences,3,173-198,Elsevier,The observability of discrete-event systems is investigated. A discrete-event system G is modeled as the controlled generator of a formal language L m (G) in the framework of Ramadge and Wonham. To control G. a supervisor S is developed whose action is to enable and disable the controllable events of G according to a record of occurrences of the observable events of G. in such a way that the resulting closed-loop system obeys some prespecified operating rules embodied in a given language K. A necessary and sufficient condition is found for the existence of a supervisor S such that L m (S/G)= K. Based on this condition. a solution of the supervisory control and observation problem (SCOP) is obtained. Two examples are provided.,True,dk_xvMcAAAAJ:1qzjygNMrQYC,888,https://www.sciencedirect.com/science/article/pii/0020025588900011,11314335964045906520,/scholar?cites=11314335964045906520,,,,0,0,0
1277357,Diagnosability of discrete event systems and its applications,1994,Feng Lin,4,Discrete Event Dynamic Systems,2,197-212,Kluwer Academic Publishers,As man-made systems become more and more complex. diagnostics of component failures is no longer an easy task that can be performed based on experience and intuition. Therefore. it is important to develop a systematic approach to diagnostic problems. Diagnostics can be done either on-line or off-line. By on-line diagnostics. we mean diagnostics performed while the system to be diagnosed is in normal operation. On the other hand. in off-line diagnostics. the system is not in normal operation. We will study both on-line and off-line diagnostics in this paper and identify main features and differences of these two types of diagnostics. We will also introduce the concept of diagnosability and study its properties. all in the framework of discrete event systems. This study is motivated by diagnostic problems in the automotive industry and we will emphasize its applications.,True,dk_xvMcAAAAJ:5ugPr518TE4C,401,https://link.springer.com/article/10.1007/BF01441211,2785771979581162850,/scholar?cites=2785771979581162850,,,,0,0,0
1277358,Decentralized supervisory control of discrete-event systems,1988,Feng Lin and Walter Murray Wonham,44,Information sciences,3,199-224,Elsevier,A discrete-event system G is modeled as the controlled generator of a formal language L (G). in the framework of Ramadge and Wonham. In general a centralized global supervisory controller S for G can be defined which generates a suitable closed-loop languageL (S/G). The paper develops the idea of local supervisors S i whose concurrent operation results in the closed-loop language L (ΛS i/G). Conditions are obtained which guarantee that L (ΛS i/G)= L (S/G). namely. distributed local supervision is equivalent to global supervision. For illustration a simple manufacturing system is discussed.,True,dk_xvMcAAAAJ:J-pR_7NvFogC,361,https://www.sciencedirect.com/science/article/pii/0020025588900023,10961748718538501709,/scholar?cites=10961748718538501709,,,,0,0,0
1277359,Decentralized control and coordination of discrete-event systems with partial observation,1990,Feng Lin and W Murray Wonham,35,IEEE Transactions on automatic control,12,1330-1337,IEEE,Decentralized supervision and coordination are studied for partially observed discrete-event systems. The authors' (1988) previous results on decentralized supervision and supervision under partial observation are extended by incorporating both these features in the control structure. In addition. a concept of coordination is introduced. and conditions for the existence of a coordinating supervisor are established. It is concluded that decentralized supervision will be easier to design and implement that centralized supervision; under suitable conditions it will be equivalent with respect to overall closed-loop system behavior. In achieving this equivalence a key role is played by the linguistic property of normality. As shown by an illustrative example. the results have application to such complex systems as manufacturing systems. which the qualitative modeling framework adopted.< >,True,dk_xvMcAAAAJ:wbdj-CoPYUoC,354,https://ieeexplore.ieee.org/abstract/document/61009/,15612076171250196456,/scholar?cites=15612076171250196456,,,,0,0,0
1277360,Robust control design: an optimal control approach,2007,Feng Lin,18,,,,John Wiley & Sons,Comprehensive and accessible guide to the three main approaches to robust control design and its applications Optimal control is a mathematical field that is concerned with control policies that can be deduced using optimization algorithms. The optimal control approach to robust control design differs from conventional direct approaches to robust control that are more commonly discussed by firstly translating the robust control problem into its optimal control counterpart. and then solving the optimal control problem. Robust Control Design: An Optimal Control Approach offers a complete presentation of this approach to robust control design. presenting modern control theory in an concise manner. The other two major approaches to robust control design. the H_infinite approach and the Kharitonov approach. are also covered and described in the simplest terms possible. in order to provide a complete overview of the area. It includes up-to-date research. and offers both theoretical and practical applications that include flexible structures. robotics. and automotive and aircraft control. Robust Control Design: An Optimal Control Approach will be of interest to those needing an introductory textbook on robust control theory. design and applications as well as graduate and postgraduate students involved in systems and control research. Practitioners will also find the applications presented useful when solving practical problems in the engineering field.,True,dk_xvMcAAAAJ:Mojj43d5GZwC,320,http://books.google.com/books?hl=en&lr=&id=cpgkjiic9vYC&oi=fnd&pg=PR7&dq=info:_bGYS5OH7ZQJ:scholar.google.com&ots=csAdXANg0J&sig=oV1XN8kGw2Y0w078x1s8Hx3BB-g,10731382553792000509,/scholar?cites=10731382553792000509,,,,0,0,0
1277361,Modeling and control of fuzzy discrete event systems,2002,Feng Lin and Hao Ying,32,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",4,408-415,IEEE,In order to make it possible to effectively represent deterministic uncertainties and vagueness as well as the human subjective observation and judgement inherent to many real-world problems. especially those in biomedicine. we introduce. in this paper. fuzzy states and fuzzy events and generalize (crisp) discrete event systems (DES) to fuzzy DES. The largely graph-based current framework of the crisp DES is unsuitable for the expansion. and we have thus reformulated it using state vectors and event transition matrices which can be extended to fuzzy vectors and matrices by allowing their elements to take values between 0 and 1. To measure information related to fuzzy DES. we generalize the crisp DES observability. The new observability allows one to determine whether or not the system output observed is sufficient for decision making. Finally. we extend the optimal control of DES to fuzzy DES. The new fuzzy …,True,dk_xvMcAAAAJ:olpn-zPbct0C,237,https://ieeexplore.ieee.org/abstract/document/1018761/,13082949639185739124,/scholar?cites=13082949639185739124,,,https://www.researchgate.net/profile/Hao_Ying3/publication/5614105_Modeling_and_control_of_fuzzy_discrete_event_systems/links/53f10bab0cf2711e0c43261c/Modeling-and-control-of-fuzzy-discrete-event-systems.pdf,0,0,0
1277362,Limited lookahead policies in supervisory control of discrete event systems,1992,S-L Chung and Stephane Lafortune and Feng Lin,37,IEEE Transactions on Automatic Control,12,1921-1935,IEEE,A supervisory control scheme which is based on limited lookahead control policies is proposed. using an online scheme where after the occurrence of an event. the next control action is determined on the basis of an N-step-ahead projection of the behavior of the process (represented as an N-level tree). This procedure then repeats after the execution of the next event. Different attitudes can be adopted to calculate a control action for the given N-level tree in order to resolve uncertainties about the process behavior beyond N steps. Two such attitudes. termed conservative and optimistic. are studied. Results are presented pertaining to monotonicity and convergence properties of the optimistic and conservative N-step policies in terms of N. and comparison of these policies with the optimal offline solution; closed-form expression for the language generated by the N-step conservative policy for prefix-closed legal …,True,dk_xvMcAAAAJ:bnK-pcrLprsC,233,https://ieeexplore.ieee.org/abstract/document/182478/,14331799813553687939,/scholar?cites=14331799813553687939,,,,0,0,0
1277363,Formulas for calculating supremal controllable and normal sublanguages,1990,RD Brandt and Vijay Garg and R Kumar and F Lin and SI Marcus and WM Wonham,15,Systems & Control Letters,2,111-117,North-Holland,Supremal controllable and normal sublanguages have been shown to play an important role in supervisor synthesis. In this paper. we discuss the computation of supremal controllable and normal sublanguages. We derive formulas for both supremal controllable sublanguages and supremal normal sublanguages when the languages involved are closed. As a result. those languages can be computed without applying recursive algorithms. We also discuss those aspects of these formulas.,True,dk_xvMcAAAAJ:XiVPGOgt02cC,222,https://www.sciencedirect.com/science/article/pii/016769119090004E,1243576251020015241,/scholar?cites=1243576251020015241,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.2576&rep=rep1&type=pdf,0,0,0
1277364,Robust hovering control of a PVTOL aircraft,1999,Feng Lin and William Zhang and Robert D Brandt,7,IEEE Transactions on Control Systems Technology,3,343-351,IEEE,We study robust hovering control of vertical/short takeoff and landing (V/STOL) aircraft. For hovering control. we can model a V/STOL aircraft as a planar vertical takeoff and landing (PVTOL) aircraft. We use an optimal control approach to design a robust hovering control. The resulting control is a nonlinear state feedback whose robustness is demonstrated by numerical simulations.,True,dk_xvMcAAAAJ:t6usbXjVLHcC,183,https://ieeexplore.ieee.org/abstract/document/761054/,5296370811302634926,/scholar?cites=5296370811302634926,,,https://pdfs.semanticscholar.org/8956/ce31101fbd730d1917ad60db835c1974455d.pdf,0,0,0
1277365,An optimal control approach to robust control of robot manipulators,1998,Feng Lin and Robert D Brandt,14,IEEE Transactions on robotics and automation,1,69-77,IEEE,We present a new optimal control approach to robust control of robot manipulators in the framework of Lin (1997). Due to the unknown load placed on a manipulator and the other uncertainties in the manipulator dynamics. it is important to design a robust control law that will guarantee the performance of the manipulator under these uncertainties. To solve this robust control problem. we first translate the robust control problem into an optimal control problem. where the uncertainties are reflected in the performance index. We then use the optimal control approach to solve the robust control problem. We show that the solution to the optimal control problem is indeed a solution to the robust control problem. We illustrate this approach using a two-joint SCARA type robot. whose robust control is obtained by solving an algebraic Riccati equation.,True,dk_xvMcAAAAJ:AXPGKjj_ei8C,175,https://ieeexplore.ieee.org/abstract/document/660845/,2432233934732435280,/scholar?cites=2432233934732435280,,,https://www.researchgate.net/profile/Robert_Brandt/publication/3298797_An_optimal_control_approach_to_robust_control_of_robot_manipulators/links/00b49528542396eb5b000000.pdf,0,0,0
1277366,Robust and adaptive supervisory control of discrete event systems,1993,Feng Lin,38,IEEE Transactions on Automatic Control,12,1848-1852,IEEE,Both robust and adaptive supervisory control in discrete-event systems are discussed. It is assumed that the system G to be controlled is not known exactly. It is only known either that it belongs to a set or that it has certain lower and upper bounds. The task of robust supervision is to synthesize a supervisor that realizes a given desired behavior for all possible G. A necessary and sufficient condition for the existence of such a robust supervisor is derived. Based on this condition. a robust supervisory control and observation problem of synthesizing a robust supervisor whose behavior is both legal and acceptable is solved. Adaptive supervision is discussed. As the system progresses. the information on occurrences of events may help to resolve or reduce uncertainties.< >,True,dk_xvMcAAAAJ:HE397vMXCloC,175,https://ieeexplore.ieee.org/abstract/document/250564/,839747477972412064,/scholar?cites=839747477972412064,,,,0,0,0
1277367,An analysis of co-occurrence texture statistics as a function of grey level quantization,2002,David A Clausi,28,Canadian Journal of remote sensing,1,45-62,Taylor & Francis,In this paper. the effect of grey level quantization on the ability of co-occurrence probability statistics to classify natural textures is studied. Generally. as a function of increasing grey levels. many of the statistics demonstrate a decrease in classification ability while a few maintain constant classification accuracy. None of the individual statistics show increasing classification accuracy throughout all grey levels. Correlation analysis is used to rationalize a preferred subset of statistics. The preferred statistics set (contrast. correlation. and entropy) is demonstrated to be an improvement over using single statistics or using the entire set of statistics. If the feature space dimension only allows for a single statistic. one of contrast. dissimilarity. inverse difference normalized. or inverse difference moment normalized. is recommended. Testing that compares (using all orientations separately). the average of all orientations and look …,True,Q5qzD7EAAAAJ:u-x6o8ySG0sC,1055,https://www.tandfonline.com/doi/abs/10.5589/m02-004,2489456380548746617,/scholar?cites=2489456380548746617,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.2001&rep=rep1&type=pdf,0,0,0
1277368,Designing Gabor filters for optimal texture separability,2000,David A Clausi and M Ed Jernigan,33,Pattern Recognition,11,1835-1849,Pergamon,The discrimination of textures is a critical aspect of identification in digital imagery. Texture features generated by Gabor filters have been increasingly considered and applied to image analysis. Here. a comprehensive classification and segmentation comparison of different techniques used to produce texture features using Gabor filters is presented. These techniques are based on existing implementations as well as new. innovative methods. The functional characterization of the filters as well as feature extraction based on the raw filter outputs are both considered. Overall. using the Gabor filter magnitude response given a frequency bandwidth and spacing of one octave and orientation bandwidth and spacing of 30° augmented by a measure of the texture complexity generated preferred results.,True,Q5qzD7EAAAAJ:u5HHmVD_uO8C,473,https://www.sciencedirect.com/science/article/pii/S0031320399001818,12048035951560883933,/scholar?cites=12048035951560883933,,,http://www.eng.uwaterloo.ca/~dclausi/Papers/Published%202000/Clausi%20-%20Gabor%20parameters%20-%20Pattern%20Recognition%202000.pdf,0,0,0
1277369,Lung nodule classification using deep features in CT images,2015,Devinder Kumar and Alexander Wong and David A Clausi,,,,133-138,IEEE,"Early detection of lung cancer can help in a sharp decrease in the lung cancer mortality rate. which accounts for more than 17% percent of the total cancer related deaths. A large number of cases are encountered by radiologists on a daily basis for initial diagnosis. Computer-aided diagnosis (CAD) systems can assist radiologists by offering a ""second opinion"" and making the whole process faster. We propose a CAD system which uses deep features extracted from an auto encoder to classify lung nodules as either malignant or benign. We use 4303 instances containing 4323 nodules from the National Cancer Institute (NCI) Lung Image Database Consortium (LIDC) dataset to obtain an overall accuracy of 75.01% with a sensitivity of 83.35% and false positive of 0.39/patient over a 10 fold cross validation.",True,Q5qzD7EAAAAJ:g3aElNc5_aQC,266,https://ieeexplore.ieee.org/abstract/document/7158331/,15314003468816340404,/scholar?cites=15314003468816340404,,,https://www.researchgate.net/profile/Alexander_Wong7/publication/283434355_Lung_Nodule_Classification_Using_Deep_Features_in_CT_Images/links/56a0db6708aee4d26ad8b619/Lung-Nodule-Classification-Using-Deep-Features-in-CT-Images.pdf,0,0,0
1277370,Unsupervised image segmentation using a simple MRF model with a new implementation scheme,2004,Huawu Deng and David A Clausi,37,Pattern recognition,12,2323-2335,Pergamon,A simple Markov random field model with a new implementation scheme is proposed for unsupervised image segmentation based on image features. The traditional two-component MRF model for segmentation requires training data to estimate necessary model parameters and is thus unsuitable for unsupervised segmentation. The new implementation scheme solves this problem by introducing a function-based weighting parameter between the two components. Using this method. the simple MRF model is able to automatically estimate model parameters and produce accurate unsupervised segmentation results. Experiments demonstrate that the proposed algorithm is able to segment various types of images (gray scale. color. texture) and achieves an improvement over the traditional method.,True,Q5qzD7EAAAAJ:d1gkVwhDpl0C,265,https://www.sciencedirect.com/science/article/pii/S0031320304001955,11747327514091122829,/scholar?cites=11747327514091122829,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.472.6160&rep=rep1&type=pdf,0,0,0
1277371,Design-based texture feature fusion using Gabor filters and co-occurrence probabilities,2005,David A Clausi and Huang Deng,14,IEEE Transactions on Image Processing,7,925-936,IEEE,A design-based method to fuse Gabor filter and grey level co-occurrence probability (GLCP) features for improved texture recognition is presented. The fused feature set utilizes both the Gabor filter's capability of accurately capturing lower and mid-frequency texture information and the GLCP's capability in texture information relevant to higher frequency components. Evaluation methods include comparing feature space separability and comparing image segmentation classification rates. The fused feature sets are demonstrated to produce higher feature space separations. as well as higher segmentation accuracies relative to the individual feature sets. Fused feature sets also outperform individual feature sets for noisy images. across different noise magnitudes. The curse of dimensionality is demonstrated not to affect segmentation using the proposed the 48-dimensional fused feature set. Gabor magnitude …,True,Q5qzD7EAAAAJ:2osOgNQ5qMEC,258,https://ieeexplore.ieee.org/abstract/document/1439565/,16898271571715358744,/scholar?cites=16898271571715358744,,,https://core.ac.uk/download/pdf/190796199.pdf,0,0,0
1277372,ARRSI: Automatic registration of remote-sensing images,2007,Alexander Wong and David A Clausi,45,IEEE Transactions on Geoscience and Remote Sensing,5,1483-1493,IEEE,This paper presents the Automatic Registration of Remote-Sensing Images (ARRSI); an automatic registration system built to register satellite and aerial remotely sensed images. The system is designed specifically to address the problems associated with the registration of remotely sensed images obtained at different times and/or from different sensors. The ARRSI system is capable of handling remotely sensed images geometrically distorted by various transformations such as translation. rotation. and shear. Global and local contrast issues associated with remotely sensed images are addressed in ARRSI using control-point detection and matching processes based on a phase-congruency model. Intensity-difference issues associated with multimodal registration of remotely sensed images are addressed in ARRSI through the use of features that are invariant to intensity mappings during the control-point matching …,True,Q5qzD7EAAAAJ:W7OEmFMy1HYC,247,https://ieeexplore.ieee.org/abstract/document/4156348/,15798008769246511737,/scholar?cites=15798008769246511737,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.5853&rep=rep1&type=pdf,0,0,0
1277373,IRGS: Image segmentation using edge penalties and region growing,2008,Qiyao Yu and David A Clausi,30,IEEE transactions on pattern analysis and machine intelligence,12,2126-2139,IEEE,This paper proposes an image segmentation method named iterative region growing using semantics (IRGS). which is characterized by two aspects. First. it uses graduated increased edge penalty (GIEP) functions within the traditional Markov random field (MRF) context model in formulating the objective functions. Second. IRGS uses a region growing technique in searching for the solutions to these objective functions. The proposed IRGS is an improvement over traditional MRF based approaches in that the edge strength information is utilized and a more stable estimation of model parameters is achieved. Moreover. the IRGS method provides the possibility of building a hierarchical representation of the image content. and allows various region features and even domain knowledge to be incorporated in the segmentation process. The algorithm has been successfully tested on several artificial images and synthetic …,True,Q5qzD7EAAAAJ:roLk4NBRz8UC,241,https://ieeexplore.ieee.org/abstract/document/4429180/,8760502840965924766,/scholar?cites=8760502840965924766,,,http://www.eng.uwaterloo.ca/~dclausi/Papers/Published%202008/Yu%20and%20Clausi%20-%20IRGS%20-%20IEEE%20PAMI%20Dec%202008.pdf,0,0,0
1277374,Unsupervised segmentation of synthetic aperture radar sea ice imagery using a novel Markov random field model,2005,Huawu Deng and David A Clausi,43,IEEE Transactions on Geoscience and Remote Sensing,3,528-538,IEEE,Environmental and sensor challenges pose difficulties for the development of computer-assisted algorithms to segment synthetic aperture radar (SAR) sea ice imagery. In this research. in support of operational activities at the Canadian Ice Service. images containing visually separable classes of either ice and water or multiple ice classes are segmented. This work uses image intensity to discriminate ice from water and uses texture features to identify distinct ice types. In order to seamlessly combine image spatial relationships with various image features. a novel Bayesian segmentation approach is developed and applied. This new approach uses a function-based parameter to weight the two components in a Markov random field (MRF) model. The devised model allows for automatic estimation of MRF model parameters to produce accurate unsupervised segmentation results. Experiments demonstrate that the …,True,Q5qzD7EAAAAJ:qjMakFHDy7sC,240,https://ieeexplore.ieee.org/abstract/document/1396325/,6427973098251205355,/scholar?cites=6427973098251205355,,,http://www.eng.uwaterloo.ca/~dclausi/Papers/Published%202005/Deng%20and%20Clausi%20-%20SAR%20Sea%20Ice%20and%20Novel%20MRF%20-%20IEEE%20Geoscience%202005.pdf,0,0,0
1277375,Intra-retinal layer segmentation in optical coherence tomography images,2009,Akshaya Mishra and Alexander Wong and Kostadinka Bizheva and David A Clausi,17,Optics express,26,23719-23728,Optical Society of America,Retinal layer thickness. evaluated as a function of spatial position from optical coherence tomography (OCT) images is an important diagnostics marker for many retinal diseases. However. due to factors such as speckle noise. low image contrast. irregularly shaped morphological features such as retinal detachments. macular holes. and drusen. accurate segmentation of individual retinal layers is difficult. To address this issue. a computer method for retinal layer segmentation from OCT images is presented. An efficient two-step kernel-based optimization scheme is employed to first identify the approximate locations of the individual layers. which are then refined to obtain accurate segmentation results for the individual layers. The performance of the algorithm was tested on a set of retinal images acquired in-vivo from healthy and diseased rodent models with a high speed. high resolution OCT system. Experimental …,True,Q5qzD7EAAAAJ:hqOjcs7Dif8C,234,https://www.osapublishing.org/abstract.cfm?uri=oe-17-26-23719,3101569107408611590,/scholar?cites=3101569107408611590,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-17-26-23719&seq=0,0,0,0
1277376,Comparing cooccurrence probabilities and Markov random fields for texture analysis of SAR sea ice imagery,2004,David A Clausi and Bing Yue,42,IEEE Transactions on Geoscience and Remote Sensing,1,215-228,IEEE,This paper compares the discrimination ability of two texture analysis methods: Markov random fields (MRFs) and gray-level cooccurrence probabilities (GLCPs). There exists limited published research comparing different texture methods. especially with regard to segmenting remotely sensed imagery. The role of window size in texture feature consistency and separability as well as the role in handling of multiple textures within a window are investigated. Necessary testing is performed on samples of synthetic (MRF generated). Brodatz. and synthetic aperture radar (SAR) sea ice imagery. GLCPs are demonstrated to have improved discrimination ability relative to MRFs with decreasing window size. which is important when performing image segmentation. On the other hand. GLCPs are more sensitive to texture boundary confusion than MRFs given their respective segmentation procedures.,True,Q5qzD7EAAAAJ:9yKSN-GCB0IC,232,https://ieeexplore.ieee.org/abstract/document/1262599/,14198292015411300333,/scholar?cites=14198292015411300333,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.6693&rep=rep1&type=pdf,0,0,0
1277377,Unsupervised polarimetric SAR image segmentation and classification using region growing with edge penalty,2011,Peter Yu and A Kai Qin and David A Clausi,50,IEEE Transactions on Geoscience and Remote Sensing,4,1302-1317,IEEE,A region-based unsupervised segmentation and classification algorithm for polarimetric synthetic aperture radar (SAR) imagery that incorporates region growing and a Markov random field edge strength model is designed and implemented. This algorithm is an extension of the successful Iterative Region Growing with Semantics (IRGS) segmentation and classification algorithm. which was designed for amplitude only SAR imagery. to polarimetric data. Polarimetric IRGS (PolarIRGS) extends IRGS by incorporating a polarimetric feature model based on the Wishart distribution and modifying key steps such as initialization. edge strength computation. and the region growing criterion. Like IRGS. PolarIRGS oversegments an image into regions and employs iterative region growing to reduce the size of the solution search space. The incorporation of an edge penalty in the spatial context model improves segmentation …,True,Q5qzD7EAAAAJ:70eg2SAEIzsC,203,https://ieeexplore.ieee.org/abstract/document/6020785/,18009448672510506457,/scholar?cites=18009448672510506457,,,,0,0,0
1277378,Registration techniques for multisensor remotely sensed imagery,1996,Leila MG Fonseca and BS Manjunath,62,PE & RS- Photogrammetric Engineering & Remote Sensing,9,1049-1056,,Image registration is one of the basic image processing operations in remote sensing. With the increase in the number of images collected every day from different sensors. automated registration of multisensor/multispectral images has become a very important issue. A wide range of registration techniques has been developed for many different types of applications and data. Given the diversity of the data. it is unlikely that a single registration scheme will work satisfactorily for all different applications. A possible solution is to integrate multiple registration algorithms into a rule-based artificial intelligence system so that appropriate methods for any given set of multisensor data can be automatically selected. The first step in the development of such an expert system for remote sensing application would be to obtain a better understanding and characterization of the various existing techniques for image registration. This is the main objective of this paper as we present a comparative study of some recent image registration methods. We emphasize in particular techniques for multisensor image data. and a brief discussion of each of the techniques is given. This comprehensive study will enable the user to select algorithms that work best for hidher particular application domain.,True,lwIjU8EAAAAJ:cUMtEw7vMgQC,423,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.2227&rep=rep1&type=pdf,6239426527249948253,/scholar?cites=6239426527249948253,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.2227&rep=rep1&type=pdf,0,0,0
1277379,Satellite imagery segmentation: a region growing approach,1996,L Sant’anna Bins and LM Garcia Fonseca and Guaraci José Erthal and F Mitsuo Ii,8,Simpósio Brasileiro de Sensoriamento Remoto,1996,677-680,Imagem Multimidia. São Paulo. Proceedings. CD,This work presents a segmentation method based on a region growing approach. It has been implemented in the geographic information and image processing system (SPRING) which has been developed at INPE. The technique is applied to segment images which are being used to assess land use changes in the Amazon region. Segmented Landsat-TM images are shown to illustrate the technique.,True,lwIjU8EAAAAJ:u5HHmVD_uO8C,226,http://marte.sid.inpe.br/col/sid.inpe.br/deise/1999/02.05.09.30/doc/T205.pdf,5485568059879333964,/scholar?cites=5485568059879333964,,,http://marte.sid.inpe.br/col/sid.inpe.br/deise/1999/02.05.09.30/doc/T205.pdf,0,0,0
1277380,Processamento digital de imagens,2000,Bibliografia Básica and Bibliografia Complementar,,,,,,"Page 1. COORDENAÇÃO DO PROGRAMA DEPÓS- GRADUAÇÃO EM ENGENHARIA ELÉTRICA
Processamento Digital de Imagens Área de Concentração: Telecomunicações Linha de Pesquisa:
Processamento de Sinais Obrigatória: ( ) SIM (X ) NÃO Carga Horária: 45h Créditos: 03 Ementa:
Representação digital de uma imagem. Transformações de imagens. Melhoramento de imagens.
Restauração de imagens. Técnicas de compressão. Segmentação e classificação de imagens.
Reconhecimento e interpretação de imagens. Noções básicas de Morfologia Matemática.
Arquiteturas básicas para implementação de algoritmos de PDI. Bibliografia Básica: GONZALEZ.
RC; Woods. RE Digital Image Processing. 2. ed. New Jersey: Prentice Hall. 2002. 793p. JAIN.
AK Fundamentals of Digital Image Processing. 2. ed. New Jersey: Prentice Hall. 1988. 569p … 
",True,lwIjU8EAAAAJ:2osOgNQ5qMEC,144,https://estudante.ifpb.edu.br/media/cursos/93/disciplina/Processamento_Digital_de_Imagens.pdf,15208305783739328159,/scholar?cites=15208305783739328159,,,,0,0,0
1277381,A concepção brasileira de “cooperação Sul-Sul estruturante em saúde,2010,Celia Maria de Almeida and Rodrigo Pires de Campos and Paulo Buss Marchiori Buss and José Roberto Ferreira,4,"Revista Eletrônica de Comunicação, Informação e Inovação em Saúde",1,,,No despontar do novo milênio. as necessidades em saúde dos países pobres além de não terem diminuído parecem ter piorado. devido a uma complexa interação entre vários fatores. que resulta em agudas iniquidades. num mesmo país e entre os países. Essa situação crítica questiona. mais uma vez. a cooperação internacional para o desenvolvimento e estimula a reflexão. Nesse processo. a cooperação Sul-Sul tem ganhado crescente importância. No início do século XXI. a cooperação internacional. principalmente no âmbito Sul-Sul. passou a ocupar um lugar estratégico na política externa brasileira e a saúde é considerada um tema prioritário nessa agenda. Este artigo discute a concepção brasileira de “cooperação estruturante em saúde” entre os países em desenvolvimento. Apresenta uma breve revisão histórica sobre a cooperação para o desenvolvimento e a cooperação em saúde; elabora o conceito de “cooperação estruturante em saúde”. discute a proposta brasileira formulada ao longo da última década e a sua implementação até o presente momento. A abordagem brasileira está centrada no conceito de “construção de capacidades para o desenvolvimento”. mas inova em dois aspectos: integra formação de recursos humanos. fortalecimento organizacional e desenvolvimento institucional; e rompe com a tradicional transferência passiva de conhecimentos e tecnologias. É cedo para avaliar o seu impacto. mas essa cooperação vem sendo implementada com base em cinco aspectos estratégicos. políticos e técnicos interrelacionados:(a) priorização da cooperação horizontal;(b) foco no desenvolvimento de capacidades …,True,lwIjU8EAAAAJ:e9bUPLv0EjcC,142,https://homologacao-reciis.icict.fiocruz.br/index.php/reciis/article/view/696,9429689586532023567,/scholar?cites=9429689586532023567,,,https://homologacao-reciis.icict.fiocruz.br/index.php/reciis/article/view/696/1341,0,0,0
1277382,Automatic registration of satellite images,1997,Leila MG Fonseca and Max HM Costa,,,,219-226,IEEE,Image registration is one of the basic image processing operations in remote sensing. With the increase in the number of images collected every day from different sensors. automated registration of multi-sensor/multi-spectral images has become an important issue. A wide range of registration techniques has been developed for many different types of applications and data. Given the diversity of the data. it is unlikely that a single registration scheme will work satisfactorily for all different applications. A possible solution is to integrate multiple registration algorithms into a rule-based artificial intelligence system. so that appropriate methods for any given set of multisensor data can be automatically selected. The objective of this paper is to present an automatic registration algorithm which has been developed at INPE. It uses a multiresolution analysis procedure based upon the wavelet transform. The procedure is …,True,lwIjU8EAAAAJ:d1gkVwhDpl0C,127,https://ieeexplore.ieee.org/abstract/document/625182/,12998500983699022948,/scholar?cites=12998500983699022948,,,https://www.researchgate.net/profile/Max_Costa2/publication/3714469_Automatic_registration_of_satellite_images/links/54c8cdce0cf289f0ced0e4a8.pdf,0,0,0
1277383,Digital change detection with the aid of multiresolution wavelet analysis,2001,LMT de Carvalho and LMG Fonseca and F Murtagh and JGPW Clevers,22,International Journal of Remote Sensing,18,3871-3876,Taylor & Francis Group,This Letter presents the preliminary findings of a new approach to deal with misregistration effects on change detection results. A multiresolution analysis with wavelet transforms applied to image differencing results enabled the extraction of changed sites according to size classes. Changes of interest were pinpointed successfully without the necessity of accurate spatial registration or radiometric rectification while differences not related to land cover changes were bypassed. The method's applicability is demonstrated with a multitemporal data set of Landsat MSS and TM images for the detection of deforestation and new areas of rock exploitation in south-eastern Brazil.,True,lwIjU8EAAAAJ:qjMakFHDy7sC,106,https://www.tandfonline.com/doi/abs/10.1080/01431160110069836,14282203109801046240,/scholar?cites=14282203109801046240,,,,0,0,0
1277384,Semivariogram textural classification of JERS-1 (Fuyo-1) SAR data obtained over a flooded area of the Amazon rainforest,1998,FP Miranda and LEN Fonseca and JR Carr,19,International Journal of Remote Sensing,3,549-556,Taylor & Francis Group,Classification of JERS-1 (Fuyo-1) SAR data from the rainforestcovered area of the Uaupes River (Brazil) was performed using the semivariogram textural classifier (STC). This method increased the discrimination between upland and flooded vegetation. Because the fluvial channel in the investigated site is oriented either parallel or perpendicular to radar illumination. the study resulted in better understanding of the textural signature of the double-bounce effect of microwave energy at river margins. This unique geomorphological setting provided a crucial check for a semivariogram classification approach that was previously tested farther north-east in the Amazon Basin.,True,lwIjU8EAAAAJ:K4-iKlO5MD4C,104,https://www.tandfonline.com/doi/abs/10.1080/014311698216170,15042942843993232461,/scholar?cites=15042942843993232461,,,https://www.researchgate.net/profile/Fernando_Miranda6/publication/277514036_Semivariogram_textural_classification_of_JERS-1_Fuyo-1_SAR_data_obtained_over_a_flooded_area_of_the_Amazon_rainforest/links/5613c6de08aedf29a44f5ed5/Semivariogram-textural-classification-of-JERS-1-Fuyo-1-SAR-data-obtained-over-a-flooded-area-of-the-Amazon-rainforest.pdf,0,0,0
1277385,Um método de classificação não supervisionada por regiões,1993,Leonardo Sant’ana Bins and Guaraci José Erthal and LEILA MARIA GARCIA FoNSECA,5,Simpósio Brasileiro de Computação Gráfica e Processamento de Imagens,,65-68,,A clustering classification method is described and applied to Landsat TM images. This method differs from the conventional unsupervised classification. in the sense that the clustering algorithm is applied to a set of regions. obtained from the segmented image. The statistical parameters of these regions are used to classsify each.,True,lwIjU8EAAAAJ:u-x6o8ySG0sC,95,https://www.researchgate.net/profile/Bins_Leonardo/publication/47446477_Um_metodo_de_classificacao_nao_supervisionada_por_regioes/links/571f652208aed056fa23471f/Um-metodo-de-classificacao-nao-supervisionada-por-regioes.pdf,16270999555256998115,/scholar?cites=16270999555256998115,,,https://www.researchgate.net/profile/Bins_Leonardo/publication/47446477_Um_metodo_de_classificacao_nao_supervisionada_por_regioes/links/571f652208aed056fa23471f/Um-metodo-de-classificacao-nao-supervisionada-por-regioes.pdf,0,0,0
1277386,GeoDMA—Geographic data mining analyst,2013,Thales Sehn Körting and Leila Maria Garcia Fonseca and Gilberto Câmara,57,Computers & Geosciences,,133-145,Pergamon,Remote sensing images obtained by remote sensing are a key source of data for studying large-scale geographic areas. From 2013 onwards. a new generation of land remote sensing satellites from USA. China. Brazil. India and Europe will produce in 1 year as much data as 5 years of the Landsat-7 satellite. Thus. the research community needs new ways to analyze large data sets of remote sensing imagery. To address this need. this paper describes a toolbox for combing land remote sensing image analysis with data mining techniques. Data mining methods are being extensively used for statistical analysis. but up to now have had limited use in remote sensing image interpretation due to the lack of appropriate tools. The toolbox described in this paper is the Geographic Data Mining Analyst (GeoDMA). It has algorithms for segmentation. feature extraction. feature selection. classification. landscape metrics and …,True,lwIjU8EAAAAJ:V63Ir2N1OTwC,90,https://www.sciencedirect.com/science/article/pii/S0098300413000538,10170218344099132006,/scholar?cites=10170218344099132006,,,https://www.academia.edu/download/45425513/geodma_print.pdf,0,0,0
1277387,Agricultural land use dynamics in the Brazilian Amazon based on remote sensing and census data,2012,Giovana M De Espindola and Ana Paula D De Aguiar and Edzer Pebesma and Gilberto Câmara and Leila Fonseca,32,Applied Geography,2,240-252,Pergamon,The potential impact of deforestation in the Brazilian Amazon on greenhouse gas emissions to the atmosphere calls for policies that take account of changes in forest cover. Although much research has focused on the location and effects of deforestation. little is known about the distribution and reasons for the agricultural uses that replace forest cover. We used Landsat TM-based deforestation and agricultural census data to generate maps of the distribution and proportion of four major agricultural land uses throughout the Brazilian Amazon in 1997 and 2007. We built linear and spatial regression models to assess the determinant factors of deforestation and those major agricultural land uses – pasture. temporary agriculture and permanent agriculture – for the states of Pará. Rondônia. and Mato Grosso. The data include 30 determinant factors that were grouped into two years (1996 and 2006) and in four categories …,True,lwIjU8EAAAAJ:dTyEYWd-f8wC,89,https://www.sciencedirect.com/science/article/pii/S0143622811000634,6014597315582350812,/scholar?cites=6014597315582350812,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.4279&rep=rep1&type=pdf,0,0,0
1277388,Land-cover classification of an intra-urban environment using high-resolution images and object-based image analysis,2012,Carolina Moutinho Duque de Pinho and Leila Maria Garcia Fonseca and Thales Sehn Korting and Claudia Maria De Almeida and Hermann Johann Heinrich Kux,33,International Journal of Remote Sensing,19,5973-5995,Taylor & Francis,Detailed. up-to-date information on intra-urban land cover is important for urban planning and management. Differentiation between permeable and impermeable land. for instance. provides data for surface run-off estimates and flood prevention. whereas identification of vegetated areas enables studies of urban micro-climates. In place of maps. high-resolution images. such as those from the satellites IKONOS II. Quickbird. Orbview and WorldView II. can be used after processing. Object-based image analysis (OBIA) is a well-established method for classifying high-resolution images of urban areas. Despite the large number of previous studies of OBIA in the context of intra-urban analysis. there are many issues in this area that are still open to discussion and resolution. Intra-urban analysis using OBIA can be lengthy and complex because of the processing difficulties related to image segmentation. the large number …,True,lwIjU8EAAAAJ:eH23hyXCXa4C,83,https://www.tandfonline.com/doi/abs/10.1080/01431161.2012.675451,15351492874532348914,/scholar?cites=15351492874532348914,,,,0,0,0
1277389,Statistical modeling of complex backgrounds for foreground object detection,2004,Liyuan Li and Weimin Huang and Irene Yu-Hua Gu and Qi Tian,13,IEEE Transactions on Image Processing,11,1459-1472,IEEE,"This paper addresses the problem of background modeling for foreground object detection in complex environments. A Bayesian framework that incorporates spectral. spatial. and temporal features to characterize the background appearance is proposed. Under this framework. the background is represented by the most significant and frequent features. i.e.. the principal features . at each pixel. A Bayes decision rule is derived for background and foreground classification based on the statistics of principal features. Principal feature representation for both the static and dynamic background pixels is investigated. A novel learning method is proposed to adapt to both gradual and sudden ""once-off"" background changes. The convergence of the learning process is analyzed and a formula to select a proper learning rate is derived. Under the proposed framework. a novel algorithm for detecting foreground objects from …",True,HJt0niEAAAAJ:zA6iFVUQeVQC,1201,https://ieeexplore.ieee.org/abstract/document/1344037/,10664844301324557176,/scholar?cites=10664844301324557176,,,https://www.researchgate.net/profile/Irene_Gu2/publication/51371284_Statistical_Modeling_of_Complex_Backgrounds_for_Foreground_Object_Detection/links/0c960531856bd88aa9000000.pdf,0,0,0
1277390,Foreground object detection from videos containing complex background,2003,Liyuan Li and Weimin Huang and Irene YH Gu and Qi Tian,,,,2-10,,"This paper proposes a novel method for detection and segmentation of foreground objects from a video which contains both stationary and moving background objects and undergoes both gradual and sudden"" once-off"" changes. A Bayes decision rule for classification of background and foreground from selected feature vectors is formulated. Under this rule. different types of background objects will be classified from foreground objects by choosing a proper feature vector. The stationary background object is described by the color feature. and the moving background object is represented by the color co-occurrence feature. Foreground objects are extracted by fusing the classification results from both stationary and moving pixels. Learning strategies for the gradual and sudden"" once-off"" background changes are proposed to adapt to various changes in background through the video. The convergence of the …",True,HJt0niEAAAAJ:fPk4N6BV_jEC,634,https://dl.acm.org/doi/abs/10.1145/957013.957017,9190446138363258172,/scholar?cites=9190446138363258172,,,https://www.researchgate.net/profile/Liyuan_Li/publication/221571587_Foreground_object_detection_from_videos_containing_complex_background/links/09e4150bdf566d110c000000/Foreground-object-detection-from-videos-containing-complex-background.pdf,0,0,0
1277391,Algorithms for subpixel registration,1986,Qi Tian and Michael N Huhns,35,"Computer Vision, Graphics, and Image Processing",2,220-233,Academic Press,This paper presents an analysis of four algorithms which are able to register images with subpixel accuracy; these are correlation interpolation. intensity interpolation. differential method. and phase correlation. The subpixel registration problem is described in detail and the resampling process for subpixel registration is analyzed theoretically. It is shown that the main factors affecting registration accuracy are the interpolation function. sampling frequency. number of bits per pixel. and frequency content of the image. An iterative version of the intensity interpolation algorithm. which achieves maximum computational efficiency. is also presented. Analyses. computer simulations. and experiments for measuring displacements of objects using their speckle images have shown that this algorithm is faster than a direct intensity interpolation algorithm by a factor of more than ten thousand. Using bilinear interpolation and …,True,HJt0niEAAAAJ:u_35RYKgDlwC,581,https://www.sciencedirect.com/science/article/pii/0734189X86900289,13204158163852793435,/scholar?cites=13204158163852793435,,,http://tianqi.wikidot.com/local--files/research/CVGIP-1986-VOL35.pdf,0,0,0
1277392,Multimedia security: steganography and digital watermarking techniques for protection of intellectual property: steganography and digital watermarking techniques for protection …,2004,Chun-Shien Lu,,,,,Igi Global,Multimedia security has become a major research topic. yielding numerous academic papers in addition to many watermarking-related companies. In this emerging area. there are many challenging research issues that deserve sustained studying towards an effective and practical system. Multimedia Security: Steganography and Digital Watermarking Techniques for Protection of Intellectual Property explores the myriad of issues regarding multimedia security. This book covers various issues. including perceptual fidelity analysis. image. audio. and 3D mesh object watermarking. medical watermarking. error detection (authentication) and concealment. fingerprinting. digital signature and digital right management.,True,HJt0niEAAAAJ:Mojj43d5GZwC,304,http://books.google.com/books?hl=en&lr=&id=PF_U_x1TajUC&oi=fnd&pg=PR1&dq=info:wMWAncDL6XwJ:scholar.google.com&ots=RRkYakfkhs&sig=pUEQOyyzEg7KYf1SCLuKN7v6PXw,9000949358413268416,/scholar?cites=9000949358413268416,,,https://www.researchgate.net/profile/Chun-Shien_Lu/publication/265031832_Multimedia_Security_Steganography_and_Digital_Watermarking_Techniques_for_Protection_of_Intellectual_Property/links/55685dfe08aeccd77737d02b.pdf,0,0,0
1277393,A unified framework for semantic shot classification in sports video,2005,Ling-Yu Duan and Min Xu and Qi Tian and Chang-Sheng Xu and Jesse S Jin,7,IEEE Transactions on multimedia,6,1066-1083,IEEE,The extensive amount of multimedia information available necessitates content-based video indexing and retrieval methods. Since humans tend to use high-level semantic concepts when querying and browsing multimedia databases. there is an increasing need for semantic video indexing and analysis. For this purpose. we present a unified framework for semantic shot classification in sports video. which has been widely studied due to tremendous commercial potentials. Unlike most existing approaches. which focus on clustering by aggregating shots or key-frames with similar low-level features. the proposed scheme employs supervised learning to perform a top-down video shot classification. Moreover. the supervised learning procedure is constructed on the basis of effective mid-level representations instead of exhaustive low-level features. This framework consists of three main steps: 1) identify video shot …,True,HJt0niEAAAAJ:cFHS6HbyZ2cC,264,https://ieeexplore.ieee.org/abstract/document/1542084/,2202004273452228387,/scholar?cites=2202004273452228387,,,https://dl.acm.org/doi/pdf/10.1145/641007.641096,0,0,0
1277394,Creating audio keywords for event detection in soccer video,2003,Min Xu and Namunu C Maddage and Changsheng Xu and Mohan Kankanhalli and Qi Tian,2,,,II-281,IEEE,This paper presents a novel framework called audio keywords to assist event detection in soccer video. Audio keyword is a middle-level representation that can bridge the gap between low-level features and high-level semantics. Audio keywords are created from low-level audio features by using support vector machine learning. The created audio keywords can be used to detect semantic events in soccer video by applying a heuristic mapping. Experiments of audio keywords creation and event detection based on audio keywords have illustrated promising results. According to the experimental results. we believe that audio keyword is an effective representation that is able to achieve more intuitionistic result for event detection in sports video compared with the method of event detection directly based on low-level features.,True,HJt0niEAAAAJ:yD5IFk8b50cC,221,https://ieeexplore.ieee.org/abstract/document/1221608/,8153299402849145109,/scholar?cites=8153299402849145109,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.8662&rep=rep1&type=pdf,0,0,0
1277395,A mid-level representation framework for semantic sports video analysis,2003,Ling-Yu Duan and Min Xu and Tat-Seng Chua and Qi Tian and Chang-Sheng Xu,,,,33-44,,Sports video has been widely studied due to its tremendous commercial potentials. Despite encouraging results from various specific sports games. it is almost impossible to extend a system for a new sports game because they usually employ different sets of low-level features appropriate for the specific games and closely coupled with the use of game specific rules to detect events or highlights. There is a lack of internal representation and structure to be generic and applicable for many different sports. In this paper. we present a generic mid-level representation framework for semantic sports video analysis. The mid-level representation layer is introduced between the low-level audio-visual processing and high-level semantic analysis. It allows us to separate sports specific knowledge and rules from the low-level and mid-level feature extraction. This makes sports video analysis more efficient. effective. and less ad …,True,HJt0niEAAAAJ:dfsIfKJdRG4C,219,https://dl.acm.org/doi/abs/10.1145/957013.957020,5909517765826077244,/scholar?cites=5909517765826077244,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.66.5651&rep=rep1&type=pdf,0,0,0
1277396,Trajectory-based ball detection and tracking with applications to semantic analysis of broadcast soccer video,2003,Xinguo Yu and Changsheng Xu and Hon Wai Leong and Qi Tian and Qing Tang and Kong Wah Wan,,,,11-20,,This paper first presents an improved trajectory-based algorithm for automatically detecting and tracking the ball in broadcast soccer video. Unlike the object-based algorithms. our algorithm does not evaluate whether a sole object is a ball. Instead. it evaluates whether a candidate trajectory. which is generated from the candidate feature image by a candidate verification procedure based on Kalman filter.. which is generated from the candidate feature image by a candidate verification procedure based on Kalman filter. is a ball trajectory. Secondly. a new approach for automatically analyzing broadcast soccer video is proposed. which is based on the ball trajectory. The algorithms in this approach not only improve play-break analysis and high-level semantic event detection. but also detect the basic actions and analyze team ball possession. which may not be analyzed based only on the low-level feature. Moreover …,True,HJt0niEAAAAJ:4OULZ7Gr8RgC,218,https://dl.acm.org/doi/abs/10.1145/957013.957018,17188376816174998443,/scholar?cites=17188376816174998443,,,,0,0,0
1277397,On pixel count based crowd density estimation for visual surveillance,2004,Ruihua Ma and Liyuan Li and Weimin Huang and Qi Tian,1,,,170-173 vol. 1,IEEE,Surveillance systems for public security are going beyond the conventional CCTV. A new generation of systems relies on image processing and computer vision techniques. deliver more ready-to-use information. and provide assistance for early detection of unusual events. Crowd density is a useful source of information because unusual crowdedness is often related to unusual events. Previous works on crowd density estimation either ignore perspective distortion or perform the correction based on incorrect formulation. Also there is no investigation on whether the geometric correction derived for the ground plane can be applied to human objects standing upright to the plane. This paper derives the relation for geometric correction for the ground plane and proves formally that it can be directly applied to all the foreground pixels. We also propose a very efficient implementation because it is important for a real-time …,True,HJt0niEAAAAJ:KxtntwgDAa4C,213,https://ieeexplore.ieee.org/abstract/document/1460406/,12073174263578620280,/scholar?cites=12073174263578620280,,,,0,0,0
1277398,Musical genre classification using support vector machines,2003,Changsheng Xu and Namunu C Maddage and Xi Shao and Fang Cao and Qi Tian,5,,,V-429,IEEE,Automatic musical genre classification is very useful for music indexing and retrieval. In this paper. an efficient and effective automatic musical genre classification approach is presented. A set of features is extracted and used to characterize music content. A multi-layer classifier based on support vector machines is applied to musical genre classification. Support vector machines are used to obtain the optimal class boundaries between different genres of music by learning from training data. Experimental results of multi-layer support vector machines illustrate good performance in musical genre classification and are more advantageous than traditional Euclidean distance based method and other statistic learning methods.,True,HJt0niEAAAAJ:4fKUyHm3Qg0C,187,https://ieeexplore.ieee.org/abstract/document/1199998/,13251440446089550514,/scholar?cites=13251440446089550514,,,https://www.researchgate.net/profile/Namunu_Maddage/publication/4015150_Musical_genre_classification_using_support_vector_machines/links/55193d850cf2d241f355e3dc/Musical-genre-classification-using-support-vector-machines.pdf,0,0,0
1277399,HMM-based audio keyword generation,2005,Min Xu and Ling-Yu Duan and Jianfei Cai and Liang-Tien Chia and Changsheng Xu and Qi Tian,,Advances in Multimedia Information Processing-PCM 2004,,566-574,Springer Berlin/Heidelberg,With the exponential growth in the production creation of multimedia data. there is an increasing need for video semantic analysis. Audio. as a significant part of video. provides important cues to human perception when humans are browsing and understanding video contents. To detect semantic content by useful audio information. we introduce audio keywords which are sets of specific audio sounds related to semantic events. In our previous work. we designed a hierarchical Support Vector Machine (SVM) classifier for audio keyword identification. However. a weakness of our previous work is that audio signals are artificially segmented into 20 ms frames for frame-based SVM identification without any contextual information. In this paper. we propose a classification method based on Hidden Markov Modal (HMM) for audio keyword identification as an improved work instead of using hierarchical SVM …,True,HJt0niEAAAAJ:uWQEDVKXjbEC,143,https://link.springer.com/chapter/10.1007/978-3-540-30543-9_71,2800355409209215192,/scholar?cites=2800355409209215192,,,https://www.researchgate.net/profile/Liang-Tien_Chia/publication/220763160_HMM-Based_Audio_Keyword_Generation/links/0046351bfe677e120f000000/HMM-Based-Audio-Keyword-Generation.pdf,0,0,0
1277400,Automatic lung segmentation for accurate quantitation of volumetric X-ray CT images,2001,Shiying Hu and Eric A Hoffman and Joseph M Reinhardt,20,IEEE transactions on medical imaging,6,490-498,IEEE,Segmentation of pulmonary X-ray computed tomography (CT) images is a precursor to most pulmonary image analysis applications. This paper presents a fully automatic method for identifying the lungs in three-dimensional (3-D) pulmonary X-ray CT images. The method has three main steps. First. the lung region is extracted from the CT images by gray-level thresholding. Then. the left and right lungs are separated by identifying the anterior and posterior junctions by dynamic programming. Finally. a sequence of morphological operations is used to smooth the irregular boundary along the mediastinum in order to obtain results consistent with these obtained by manual analysis. in which only the most central pulmonary arteries are excluded from the lung region. The method has been tested by processing 3-D CT data sets from eight normal subjects. each imaged three times at biweekly intervals with lungs at 90 …,True,Jew4mUwAAAAJ:u5HHmVD_uO8C,1203,https://ieeexplore.ieee.org/abstract/document/929615/,12686441508917088924,/scholar?cites=12686441508917088924,,,http://www.magic5.unile.it/PapDoc/Article/Document/20040611114256107.pdf,0,0,0
1277401,Evaluation of registration methods on thoracic CT: the EMPIRE10 challenge,2011,Keelin Murphy and Bram Van Ginneken and Joseph M Reinhardt and Sven Kabus and Kai Ding and Xiang Deng and Kunlin Cao and Kaifang Du and Gary E Christensen and Vincent Garcia and Tom Vercauteren and Nicholas Ayache and Olivier Commowick and Grégoire Malandain and Ben Glocker and Nikos Paragios and Nassir Navab and Vladlena Gorbunova and Jon Sporring and Marleen De Bruijne and Xiao Han and Mattias P Heinrich and Julia A Schnabel and Mark Jenkinson and Cristian Lorenz and Marc Modat and Jamie R McClelland and Sébastien Ourselin and Sascha EA Muenzing and Max A Viergever and Dante De Nigris and D Louis Collins and Tal Arbel and Marta Peroni and Rui Li and Gregory C Sharp and Alexander Schmidt-Richberg and Jan Ehrhardt and René Werner and Dirk Smeets and Dirk Loeckx and Gang Song and Nicholas Tustison and Brian Avants and James C Gee and Marius Staring and Stefan Klein and Berend C Stoel and Martin Urschler and Manuel Werlberger and Jef Vandemeulebroucke and Simon Rit and David Sarrut and Josien PW Pluim,30,IEEE transactions on medical imaging,11,1901-1920,IEEE,EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration 2010) is a public platform for fair and meaningful comparison of registration algorithms which are applied to a database of intra patient thoracic CT image pairs. Evaluation of nonrigid registration techniques is a nontrivial task. This is compounded by the fact that researchers typically test only on their own data. which varies widely. For this reason. reliable assessment and comparison of different registration algorithms has been virtually impossible in the past. In this work we present the results of the launch phase of EMPIRE10. which comprised the comprehensive evaluation and comparison of 20 individual algorithms from leading academic and industrial research groups. All algorithms are applied to the same set of 30 thoracic CT pairs. Algorithm settings and parameters are chosen by researchers expert in the con figuration of their own method …,True,Jew4mUwAAAAJ:35N4QoGY0k4C,422,https://ieeexplore.ieee.org/abstract/document/5782992/,11653185328679959383,/scholar?cites=11653185328679959383,,,https://research.tue.nl/en/publications/evaluation-of-registration-methods-on-thoracic-ct-the-empire10-ch,0,0,0
1277402,CT-based geometry analysis and finite element models of the human and ovine bronchial tree,2004,Merryn H Tawhai and Peter Hunter and Juerg Tschirren and Joseph Reinhardt and Geoffrey McLennan and Eric A Hoffman,97,Journal of applied physiology,6,2310-2321,American Physiological Society,The interpretation of experimental results from functional medical imaging is complicated by intersubject and interspecies differences in airway geometry. The application of computational models in understanding the significance of these differences requires methods for generation of subject-specific geometric models of the bronchial airway tree. In the current study. curvilinear airway centerline and diameter models have been fitted to human and ovine bronchial trees using detailed data segmented from multidetector row X-ray-computed tomography scans. The trees have been extended to model the entire conducting airway system by using a volume-filling algorithm to generate airway centerline locations within detailed volume descriptions of the lungs or lobes. Analysis of the geometry of the scan-based and model-based airways has verified their consistency with measures from previous anatomic studies and …,True,Jew4mUwAAAAJ:2osOgNQ5qMEC,330,https://journals.physiology.org/doi/abs/10.1152/japplphysiol.00520.2004,3265714095443528317,/scholar?cites=3265714095443528317,,,https://journals.physiology.org/doi/full/10.1152/japplphysiol.00520.2004,0,0,0
1277403,Segmentation and analysis of the human airway tree from three-dimensional X-ray CT images,2003,Deniz Aykac and Eric A Hoffman and Geoffrey McLennan and Joseph M Reinhardt,22,IEEE transactions on medical imaging,8,940-950,IEEE,The lungs exchange air with the external environment via the pulmonary airways. Computed tomography (CT) scanning can be used to obtain detailed images of the pulmonary anatomy. including the airways. These images have been used to measure airway geometry. study airway reactivity. and guide surgical interventions. Prior to these applications. airway segmentation can be used to identify the airway lumen in the CT images. Airway tree segmentation can be performed manually by an image analyst. but the complexity of the tree makes manual segmentation tedious and extremely time-consuming. We describe a fully automatic technique for segmenting the airway tree in three-dimensional (3-D) CT images of the thorax. We use grayscale morphological reconstruction to identify candidate airways on CT slices and then reconstruct a connected 3-D airway tree. After segmentation. we estimate airway …,True,Jew4mUwAAAAJ:u-x6o8ySG0sC,313,https://ieeexplore.ieee.org/abstract/document/1216218/,7679856609525628091,/scholar?cites=7679856609525628091,,,https://www.researchgate.net/profile/Eric_Hoffman2/publication/10624129_Segmentation_and_analysis_of_the_human_airway_tree_from_three-dimensional_X-ray_CT_images/links/0fcfd50b7a7d8d609f000000.pdf,0,0,0
1277404,Registration-based estimates of local lung tissue expansion compared to xenon CT measures of specific ventilation,2008,Joseph M Reinhardt and Kai Ding and Kunlin Cao and Gary E Christensen and Eric A Hoffman and Shalmali V Bodas,12,Medical image analysis,6,752-763,Elsevier,The main function of the respiratory system is gas exchange. Since many disease or injury conditions can cause biomechanical or material property changes that can alter lung function. there is a great interest in measuring regional lung ventilation and regional specific volume change. We describe a registration-based technique for estimating local lung expansion from multiple respiratory-gated CT images of the thorax. The degree of regional lung expansion is measured using the Jacobian (a function of local partial derivatives) of the registration displacement field. which we show is directly related to specific volume change. We compare the ventral–dorsal patterns of lung expansion estimated across five pressure changes to a xenon CT based measure of specific ventilation in five anesthetized sheep studied in the supine orientation. Using 3D image registration to match images acquired at 10 cm H 2 O and 15 cm …,True,Jew4mUwAAAAJ:Y0pCki6q_DkC,303,https://www.sciencedirect.com/science/article/pii/S1361841508000303,20718550394182417,/scholar?cites=20718550394182417,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2692217/,0,0,0
1277405,Automated early detection of diabetic retinopathy,2010,Michael D Abràmoff and Joseph M Reinhardt and Stephen R Russell and James C Folk and Vinit B Mahajan and Meindert Niemeijer and Gwénolé Quellec,117,Ophthalmology,6,1147-1154,Elsevier,To compare the performance of automated diabetic retinopathy (DR) detection. using the algorithm that won the 2009 Retinopathy Online Challenge Competition in 2009. the Challenge2009. against that of the one currently used in EyeCheck. a large computer-aided early DR detection project.Evaluation of diagnostic test or technology.Fundus photographic sets. consisting of 2 fundus images from each eye. were evaluated from 16 670 patient visits of 16 670 people with diabetes who had not previously been diagnosed with DR.The fundus photographic set from each visit was analyzed by a single retinal expert; 793 of the 16 670 sets were classified as containing more than minimal DR (threshold for referral). The outcomes of the 2 algorithmic detectors were applied separately to the dataset and were compared by standard statistical measures.The area …,True,Jew4mUwAAAAJ:mVmsd5A6BfQC,236,https://www.sciencedirect.com/science/article/pii/S0161642010003258,17956965532162894340,/scholar?cites=17956965532162894340,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2881172/,0,0,0
1277406,Accurate measurement of intrathoracic airways,1997,Joseph M Reinhardt and N D'Souza and Eric A Hoffman,16,IEEE transactions on medical imaging,6,820-827,IEEE,"Airway geometry measurements can provide information regarding pulmonary physiology and pathophysiology. There has been considerable interest in measuring intrathoracic airways in two-dimensional (2-D) slices from volumetric X-ray computed tomography (CT). Such measurements can be used to evaluate and track the progression of diseases affecting the airways. A popular airway measurement method uses the ""half-max"" criteria. in which the gray level at the airway wall is estimated to be halfway between the minimum and maximum gray levels along a ray crossing the edge. However. because the scanning process introduces blurring. the half-max approach may not be applicable across all airway sizes. The authors propose a new measurement method based on a model of the scanning process. In their approach. they examine the gray-level profile of a ray crossing the airway wall and use a maximum …",True,Jew4mUwAAAAJ:d1gkVwhDpl0C,236,https://ieeexplore.ieee.org/abstract/document/650878/,7606261746312078865,/scholar?cites=7606261746312078865,,,https://www.researchgate.net/profile/Eric_Hoffman2/publication/3220789_Accurate_measurement_of_intrathoracic_airways/links/53e129820cf2235f352736e4/Accurate-measurement-of-intrathoracic-airways.pdf,0,0,0
1277407,Atlas-driven lung lobe segmentation in volumetric X-ray CT images,2005,Li Zhang and Eric A Hoffman and Joseph M Reinhardt,25,IEEE transactions on medical imaging,1,1-16,IEEE,High-resolution X-ray computed tomography (CT) imaging is routinely used for clinical pulmonary applications. Since lung function varies regionally and because pulmonary disease is usually not uniformly distributed in the lungs. it is useful to study the lungs on a lobe-by-lobe basis. Thus. it is important to segment not only the lungs. but the lobar fissures as well. In this paper. we demonstrate the use of an anatomic pulmonary atlas. encoded with a priori information on the pulmonary anatomy. to automatically segment the oblique lobar fissures. Sixteen volumetric CT scans from 16 subjects are used to construct the pulmonary atlas. A ridgeness measure is applied to the original CT images to enhance the fissure contrast. Fissure detection is accomplished in two stages: an initial fissure search and a final fissure search. A fuzzy reasoning system is used in the fissure search to analyze information from three sources …,True,Jew4mUwAAAAJ:zYLM7Y9cAGgC,228,https://ieeexplore.ieee.org/abstract/document/1564322/,13770799860797595610,/scholar?cites=13770799860797595610,,,https://www.academia.edu/download/46009694/Atlas-driven_lung_lobe_segmentation_in_v20160527-357-h54ns3.pdf,0,0,0
1277408,Three-dimensional human airway segmentation methods for clinical virtual bronchoscopy,2002,Atilla P Kiraly and William E Higgins and Geoffrey McLennan and Eric A Hoffman and Joseph M Reinhardt,9,Academic radiology,10,1153-1168,Elsevier,The segmentation of airways from CT images is a critical first step for numerous virtual bronchoscopic (VB) applications. Automatic or semiautomatic methods are necessary. since manual segmentation is prohibitively time consuming. The methods must be robust and operate within a reasonable time frame to be useful for clinical VB use. The authors developed an integrated airway segmentation system and demonstrated its effectiveness on a series of human images.The authors' airway segmentation system draws on two segmentation algorithms: (a) an adaptive region-growing algorithm and (b) a new hybrid algorithm that uses both region growing and mathematical morphology. Images from an ongoing VB study were segmented by means of both the adaptive region-growing and the new hybrid methods. The segmentation volume. branch number estimate. and …,True,Jew4mUwAAAAJ:qjMakFHDy7sC,228,https://www.sciencedirect.com/science/article/pii/S1076633203805172,14911746427894904252,/scholar?cites=14911746427894904252,,,https://core.ac.uk/download/pdf/207954697.pdf,0,0,0
1277409,Characterization of the interstitial lung diseases via density-based and texture-based analysis of computed tomography images of lung structure and function,2003,Eric A Hoffman and Joseph M Reinhardt and Milan Sonka and Brett A Simon and Junfeng Guo and Osama Saba and Deokiee Chon and Shaher Samrah and Hidenori Shikata and Juerg Tschirren and Kalman Palagyi and Kenneth C Beck and Geoffrey McLennan,10,Academic radiology,10,1104-1118,Elsevier,Rationale and Objectives. Efforts to establish a quantitative approach to the computed tomography (CT)-based characterization of the lung parenchyma in interstitial lung disease (including emphysema) has been sought. The accuracy of these tools must be site independent. Multi-detector row CT has remained the gold standard for imaging the lung. and it provides the ability to image both lung structure as well as lung function.Material and Methods. Imaging is via multi-detector row CT and protocols include careful control of lung volume during scanning. Characterization includes not only anatomic-based measures but also functional measures including regional parameters derived from measures of pulmonary blood flow and ventilation. Image processing includes the automated detection of the lungs. lobes. and airways. The airways provide the road map to the lung parenchyma. Software automatically detects …,True,Jew4mUwAAAAJ:9yKSN-GCB0IC,214,https://www.sciencedirect.com/science/article/pii/S1076633203003301,2643735702178057038,/scholar?cites=2643735702178057038,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.204.1662&rep=rep1&type=pdf,0,0,0
1277410,Extraction of airways from CT (EXACT'09),2012,Pechin Lo and Bram Van Ginneken and Joseph M Reinhardt and Tarunashree Yavarna and Pim A De Jong and Benjamin Irving and Catalin Fetita and Margarete Ortner and Rômulo Pinho and Jan Sijbers and Marco Feuerstein and Anna Fabijanska and Christian Bauer and Reinhard Beichel and Carlos S Mendoza and Rafael Wiemker and Jaesung Lee and Anthony P Reeves and Silvia Born and Oliver Weinheimer and Eva M van Rikxoort and Juerg Tschirren and Ken Mori and Benjamin Odry and David P Naidich and Ieneke Hartmann and Eric A Hoffman and Mathias Prokop and Jesper H Pedersen and Marleen de Bruijne,31,IEEE Transactions on Medical Imaging,11,2093-2107,IEEE,This paper describes a framework for establishing a reference airway tree segmentation. which was used to quantitatively evaluate 15 different airway tree extraction algorithms in a standardized manner. Because of the sheer difficulty involved in manually constructing a complete reference standard from scratch. we propose to construct the reference using results from all algorithms that are to be evaluated. We start by subdividing each segmented airway tree into its individual branch segments. Each branch segment is then visually scored by trained observers to determine whether or not it is a correctly segmented part of the airway tree. Finally. the reference airway trees are constructed by taking the union of all correctly extracted branch segments. Fifteen airway tree extraction algorithms from different research groups are evaluated on a diverse set of 20 chest computed tomography (CT) scans of subjects ranging …,True,Jew4mUwAAAAJ:4TOpqqG69KYC,204,https://ieeexplore.ieee.org/abstract/document/6249784/,7968104102758490533,/scholar?cites=7968104102758490533,,,https://www.researchgate.net/profile/Carlos_S_Mendoza/publication/236131625_Extraction_of_airways_from_CT_EXACT'09/links/00b495163eba0c9b30000000/Extraction-of-airways-from-CT-EXACT09.pdf,0,0,0
1277411,Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis,2002,Bruno Aiazzi and Luciano Alparone and Stefano Baronti and Andrea Garzelli,40,IEEE Transactions on geoscience and remote sensing,10,2300-2312,IEEE,This paper compares two general and formal solutions to the problem of fusion of multispectral images with high-resolution panchromatic observations. The former exploits the undecimated discrete wavelet transform. which is an octave bandpass representation achieved from a conventional discrete wavelet transform by omitting all decimators and upsampling the wavelet filter bank. The latter relies on the generalized Laplacian pyramid. which is another oversampled structure obtained by recursively subtracting from an image an expanded decimated lowpass version. Both the methods selectively perform spatial-frequencies spectrum substitution from an image to another. In both schemes. context dependency is exploited by thresholding the local correlation coefficient between the images to be merged. to avoid injection of spatial details that are not likely to occur in the target image. Unlike other multiscale fusion …,True,377IQlAAAAAJ:zaHkCSmj5XkC,744,https://ieeexplore.ieee.org/abstract/document/1105917/,14175686553794476225,/scholar?cites=14175686553794476225,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/3203007_Context-driven_fusion_of_high_spatial_and_spectral_resolution_data_based_on_oversampled_multiresolution_analysis/links/5804c9ea08ae0b2b3ef4429c.pdf,0,0,0
1277412,Improving Component Substitution Pansharpening Through Multivariate Regression of MSPan Data,2007,Bruno Aiazzi and Stefano Baronti and Massimo Selva,45,IEEE Transactions on Geoscience and Remote Sensing,10,3230-3239,IEEE,In this paper. multivariate regression is adopted to improve spectral quality. without diminishing spatial quality. in image fusion methods based on the well-established component substitution (CS) approach. A general scheme that is capable of modeling any CS image fusion method is presented and discussed. According to this scheme. a generalized intensity component is defined as the weighted average of the multispectral (MS) bands. The weights are obtained as regression coefficients between the MS bands and the spatially degraded panchromatic (Pan) image. with the aim of capturing the spectral responses of the sensors. Once it has been integrated into the Gram-Schmidt spectral-sharpening method. which is implemented in environment for visualizing images (ENVI) program. and into the generalized intensity-hue-saturation fusion method. the proposed preprocessing module allows the production of …,True,377IQlAAAAAJ:JoHZYnTS1h4C,656,https://ieeexplore.ieee.org/abstract/document/4305344/,14125445661770578289,/scholar?cites=14125445661770578289,,,https://www.academia.edu/download/48446856/tgrs.2007.90100720160830-4045-b5r3a4.pdf,0,0,0
1277413,Remote sensing image fusion using the curvelet transform,2007,Filippo Nencini and Andrea Garzelli and Stefano Baronti and Luciano Alparone,8,Information fusion,2,143-156,Elsevier,This paper presents an image fusion method suitable for pan-sharpening of multispectral (MS) bands. based on nonseparable multiresolution analysis (MRA). The low-resolution MS bands are resampled to the fine scale of the panchromatic (Pan) image and sharpened by injecting highpass directional details extracted from the high-resolution Pan image by means of the curvelet transform (CT). CT is a nonseparable MRA. whose basis functions are directional edges with progressively increasing resolution. The advantage of CT with respect to conventional separable MRA. either decimated or not. is twofold. Firstly. directional detail coefficients matching image edges may be preliminarily soft-thresholded to achieve a noise reduction that is better than that obtained in the separable wavelet domain. Secondly. modeling of the relationships between high-resolution detail coefficients of the MS bands and of the Pan …,True,377IQlAAAAAJ:9yKSN-GCB0IC,604,https://www.sciencedirect.com/science/article/pii/S1566253506000340,10240371414117550501,/scholar?cites=10240371414117550501,,,,0,0,0
1277414,A global quality measurement of pan-sharpened multispectral imagery,2004,Luciano Alparone and Stefano Baronti and Andrea Garzelli and Filippo Nencini,1,IEEE Geoscience and Remote Sensing Letters,4,313-317,IEEE,This letter focuses on quality assessment of fusion of multispectral (MS) images with high-resolution panchromatic (Pan) observations. A new quality index suitable for MS imagery having four spectral bands is defined from the theory of hypercomplex numbers. or quaternions. Both spectral and radiometric distortion measurements are encapsulated in a unique measurement. simultaneously accounting for local mean bias. changes in contrast. and loss of correlation of individual bands. together with spectral distortion. Results are presented and discussed on very high-resolution QuickBird data. through comparisons between state-of-the-art and advanced MS+Pan merge algorithms.,True,377IQlAAAAAJ:v7SMsomtfXcC,562,https://ieeexplore.ieee.org/abstract/document/1347130/,10972150802793145515,/scholar?cites=10972150802793145515,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/3449561_A_Global_Quality_Measurement_of_Pan-Sharpened_Multispectral_Imagery/links/58a6bc794585150402ee1b52/A-Global-Quality-Measurement-of-Pan-Sharpened-Multispectral-Imagery.pdf,0,0,0
1277415,MTF-tailored multiscale fusion of high-resolution MS and Pan imagery,2006,B Aiazzi and L Alparone and S Baronti and A Garzelli and M Selva,72,Photogrammetric Engineering & Remote Sensing,5,591-596,American Society for Photogrammetry and Remote Sensing,This work presents a multiresolution framework for merging a multispectral image having an arbitrary number of bands with a higher-resolution panchromatic observation. The fusion method relies on the generalized Laplacian pyramid (GLP). which is a multiscale. oversampled structure. The goal is to selectively perform injection of spatial frequencies from an image to another with the constraint of thoroughly retaining the spectral information of the coarser data. The novel idea is that a model of the modulation transfer functions (MTF) of the multispectral scanner is exploited to design the GLP reduction filter. Thus. the interband structure model (IBSM). which is calculated at the coarser scale. where both MS and PAN data are available. can be extended to the finer scale. without the drawback of the poor enhancement occurring when MTFs are assumed to be ideal filters. Experiments carried out on QuickBird data …,True,377IQlAAAAAJ:H-3wYkpcA84C,497,https://www.ingentaconnect.com/content/asprs/pers/2006/00000072/00000005/art00007,2993960246376865325,/scholar?cites=2993960246376865325,,,https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000005/art00007?crawler=true&mimetype=application/pdf,0,0,0
1277416,Multispectral and panchromatic data fusion assessment without reference,2008,Luciano Alparone and Bruno Aiazzi and Stefano Baronti and Andrea Garzelli and Filippo Nencini and Massimo Selva,74,Photogrammetric Engineering & Remote Sensing,2,193-200,American Society for Photogrammetry and Remote Sensing,This paper introduces a novel approach for evaluating the quality of pansharpened multispectral (MS) imagery without resorting to reference originals. Hence. evaluations are feasible at the highest spatial resolution of the panchromatic (PAN) sensor. Wang and Bovik’s image quality index (QI) provides a statistical similarity measurement between two monochrome images. The QI values between any couple of MS bands are calculated before and after fusion and used to define a measurement of spectral distortion. Analogously. QI values between each MS band and the PAN image are calculated before and after fusion to yield a measurement of spatial distortion. The rationale is that such QI values should be unchanged after fusion. i.e.. when the spectral information is translated from the coarse scale of the MS data to the fine scale of the PAN image. Experimental results. carried out on very high-resolution Ikonos …,True,377IQlAAAAAJ:PQY3Tb_h0-cC,446,https://www.ingentaconnect.com/content/asprs/pers/2008/00000074/00000002/art00003,16317041751687196137,/scholar?cites=16317041751687196137,,,https://www.ingentaconnect.com/content/asprs/pers/2008/00000074/00000002/art00003?crawler=true&mimetype=application/pdf,0,0,0
1277417,Image fusion—The ARSIS concept and some successful implementation schemes,2003,Thierry Ranchin and Bruno Aiazzi and Luciano Alparone and Stefano Baronti and Lucien Wald,58,ISPRS Journal of Photogrammetry and Remote Sensing,1-2,4-18,Elsevier,This article aims at explaining the ARSIS concept. By fusing two sets of images A and B. one with a high spatial resolution. the other with a low spatial resolution and different spectral bands. the ARSIS concept permits to synthesise the dataset B at the resolution of A that is as close as possible to reality. It is based on the assumption that the missing information is linked to the high frequencies in the sets A and B. It searches a relationship between the high frequencies in the multispectral set B and the set A and models this relationship. The general problem for the synthesis is presented first. The general properties of the fused product are given. Then. the ARSIS concept is discussed. The general scheme for the implementation of a method belonging to this concept is presented. Then. this article intends to help practitioners and researchers to better understand this concept through practical details about …,True,377IQlAAAAAJ:u-x6o8ySG0sC,445,https://www.sciencedirect.com/science/article/pii/S0924271603000133,7189809840140974960,/scholar?cites=7189809840140974960,,,https://hal.archives-ouvertes.fr/hal-00356163/document,0,0,0
1277418,A comparison between global and context-adaptive pansharpening of multispectral images,2009,Bruno Aiazzi and Stefano Baronti and Franco Lotti and Massimo Selva,6,IEEE Geoscience and Remote Sensing Letters,2,302-306,IEEE,Multiresolution analysis (MRA) and component substitution (CS) are the two basic frameworks to which image fusion algorithms can be reported when merging multispectral (MS) and panchromatic (Pan) images (pansharpening). acquired with different spatial and spectral resolutions. State-of-the-art algorithms add the spatial details extracted from the Pan into the MS data set by considering different injection strategies. The capability of efficiently modeling the relationships between MS and Pan is crucial for the quality of fusion results and particularly for a correct recovery of local features with a consequent reduction of spectral distortions. Although context-adaptive (CA) injection models have been proposed in the MRA framework. their adoption in CS schemes has been scarcely investigated so far. In this letter. CA strategies are compared with global models by considering a general protocol in which both MRA …,True,377IQlAAAAAJ:KlAtU1dfN6UC,192,https://ieeexplore.ieee.org/abstract/document/4776454/,4602536853224359694,/scholar?cites=4602536853224359694,,,,0,0,0
1277419,Landsat ETM+ and SAR image fusion based on generalized intensity modulation,2004,Luciano Alparone and Stefano Baronti and Andrea Garzelli and Filippo Nencini,42,IEEE Transactions on geoscience and remote sensing,12,2832-2839,IEEE,"This work presents a novel multisensor image fusion algorithm. which extends panchrmomatic sharpening of multispectral (MS) data through intensity modulation to the integration of MS and synthetic aperture radar (SAR) imagery. The method relies on SAR texture. extracted by ratioing the despeckled SAR image to its low-pass approximation. SAR texture is used to modulate the generalized intensity (GI) of the MS image. which is given by a linear transform extending intensity-hue-saturation transform to an arbitrary number of bands. Before modulation. the GI is enhanced by injection of high-pass details extracted from the available panchrmomatic image by means of the ""a/spl grave/-trous"" wavelet decomposition. The texture-modulated panchrmomatic-sharpened GI replaces the GI calculated from the resampled original MS data. Then. the inverse transform is applied to obtain the fusion product. Experimental …",True,377IQlAAAAAJ:zYLM7Y9cAGgC,183,https://ieeexplore.ieee.org/abstract/document/1369379/,17288480062992139609,/scholar?cites=17288480062992139609,,,https://www.academia.edu/download/48446836/tgrs.2004.83834420160830-2597-1h6temc.pdf,0,0,0
1277420,Multispectral imaging system for the mapping of pigments in works of art by use of principal-component analysis,1998,S Baronti and A Casini and F Lotti and S Porcinai,37,Applied optics,8,1299-1309,Optical Society of America,Image spectroscopy (IS) is an important tool for the noninvasive analysis of works of art. It generates a wide sequence of multispectral images from which a reflectance spectrum for each imaged point can be recovered. In addition. digital processing techniques can be employed to divide the images into areas of similar spectral behavior. An IS system designed and developed in our laboratory is described. The methodology used to process the acquired data integrates spectral analysis with statistical image processing: in particular. the potential of principal-component analysis applied in this area is investigated. A selection of the results obtained from a sixteenth-century oil-painted panel by Luca Signorelli is also reported.,True,377IQlAAAAAJ:qjMakFHDy7sC,183,https://www.osapublishing.org/abstract.cfm?uri=ao-37-8-1299,5920909617199724365,/scholar?cites=5920909617199724365,,,https://www.academia.edu/download/48446867/AO.37.00129920160830-5833-8ob10w.pdf,0,0,0
1277421,Lossless compression of multi/hyper-spectral imagery based on a 3-D fuzzy prediction,1999,Bruno Aiazzi and Pasquale Alba and Luciano Alparone and Stefano Baronti,37,IEEE Transactions on Geoscience and Remote Sensing,5,2287-2294,IEEE,This paper describes an original application of fuzzy logic to the reversible compression of multispectral data. The method consists of a space spectral varying prediction followed by context-based classification and arithmetic coding of the outcome residuals. Prediction of a pixel to be encoded is obtained from the fuzzy-switching of a set of linear regression predictors. Pixels both on the current band and on previously encoded bands may be used to define a causal neighborhood. The coefficients of each predictor are calculated so as to minimize the mean-squared error for those pixels whose intensity level patterns lying on the causal neighborhood. belong in a fuzzy sense to a predefined cluster. The size and shape of the causal neighborhood. as well as the number of predictors to be switched. may be chosen by the user and determine the tradeoff between coding performances and computational cost. The …,True,377IQlAAAAAJ:2osOgNQ5qMEC,149,https://ieeexplore.ieee.org/abstract/document/789625/,567720534591418209,/scholar?cites=567720534591418209,,,,0,0,0
1277422,High quality depth map upsampling for 3d-tof cameras,2011,Jaesik Park and Hyeongwoo Kim and Yu-Wing Tai and Michael S Brown and Inso Kweon,,,,1623-1630,IEEE,This paper describes an application framework to perform high quality upsampling on depth maps captured from a low-resolution and noisy 3D time-of-flight (3D-ToF) camera that has been coupled with a high-resolution RGB camera. Our framework is inspired by recent work that uses nonlocal means filtering to regularize depth maps in order to maintain fine detail and structure. Our framework extends this regularization with an additional edge weighting scheme based on several image features based on the additional high-resolution RGB input. Quantitative and qualitative results show that our method outperforms existing approaches for 3D-ToF upsampling. We describe the complete process for this system. including device calibration. scene warping for input alignment. and even how the results can be further processed using simple user markup.,True,Gv1QGSMAAAAJ:HDshCWvjkbEC,520,https://ieeexplore.ieee.org/abstract/document/6126423/,8455092905456974970,/scholar?cites=8455092905456974970,,,https://www.researchgate.net/profile/Jaesik_Park2/publication/221110931_High_Quality_Depth_Map_Upsampling_for_3D-TOF_Cameras/links/5698125e08ae1c4279053e64.pdf,0,0,0
1277423,Multi-projector displays using camera-based registration,1999,Ramesh Raskar and Michael S Brown and Ruigang Yang and Wei-Chao Chen and Greg Welch and Herman Towles and Brent Scales and Henry Fuchs,,,,161-522,IEEE,Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed. it also means painstaking construction and ongoing maintenance. In previously published work. we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper. we present flexible yet practical methods for realizing this vision. enabling low-cost mega-pixel display systems with large physical dimensions. higher resolution. or both. The techniques afford new opportunities to build personal 3D visualization systems in offices. conference rooms. theaters. or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect. we show in the included video that a 10-year old child can …,True,Gv1QGSMAAAAJ:u5HHmVD_uO8C,506,https://ieeexplore.ieee.org/abstract/document/809883/,4775243012157864248,/scholar?cites=4775243012157864248,,,https://www.academia.edu/download/30716896/p161-raskar.pdf,0,0,0
1277424,As-projective-as-possible image stitching with moving DLT,2013,Julio Zaragoza and Tat-Jun Chin and Michael S Brown and David Suter,,,,2339-2346,,We investigate projective estimation under model inadequacies. ie. when the underpinning assumptions of the projective model are not fully satisfied by the data. We focus on the task of image stitching which is customarily solved by estimating a projective warp-a model that is justified when the scene is planar or when the views differ purely by rotation. Such conditions are easily violated in practice. and this yields stitching results with ghosting artefacts that necessitate the usage of deghosting algorithms. To this end we propose as-projective-as-possible warps. ie. warps that aim to be globally projective. yet allow local non-projective deviations to account for violations to the assumed imaging conditions. Based on a novel estimation technique called Moving Direct Linear Transformation (Moving DLT). our method seamlessly bridges image regions that are inconsistent with the projective model. The result is highly accurate image stitching. with significantly reduced ghosting effects. thus lowering the dependency on post hoc deghosting.,True,Gv1QGSMAAAAJ:Mojj43d5GZwC,427,http://openaccess.thecvf.com/content_cvpr_2013/html/Zaragoza_As-Projective-As-Possible_Image_Stitching_2013_CVPR_paper.html,925117536783210971,/scholar?cites=925117536783210971,,,http://openaccess.thecvf.com/content_cvpr_2013/papers/Zaragoza_As-Projective-As-Possible_Image_Stitching_2013_CVPR_paper.pdf,0,0,0
1277425,Rain streak removal using layer priors,2016,Yu Li and Robby T Tan and Xiaojie Guo and Jiangbo Lu and Michael S Brown,,,,2736-2744,,This paper addresses the problem of rain streak removal from a single image. Rain streaks impair visibility of an image and introduce undesirable interference that can severely affect the performance of computer vision algorithms. Rain streak removal can be formulated as a layer decomposition problem. with a rain streak layer superimposed on a background layer containing the true scene content. Existing decomposition methods that address this problem employ either dictionary learning methods or impose a low rank structure on the appearance of the rain streaks. While these methods can improve the overall visibility. they tend to leave too many rain streaks in the background image or over-smooth the background image. In this paper. we propose an effective method that uses simple patch-based priors for both the background and rain layers. These priors are based on Gaussian mixture models and can accommodate multiple orientations and scales of the rain streaks. This simple approach removes rain streaks better than the existing methods qualitatively and quantitatively. We overview our method and demonstrate its effectiveness over prior work on a number of examples.,True,Gv1QGSMAAAAJ:AYInfyleIOsC,376,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Li_Rain_Streak_Removal_CVPR_2016_paper.html,4421295834015997808,/scholar?cites=4421295834015997808,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Li_Rain_Streak_Removal_CVPR_2016_paper.pdf,0,0,0
1277426,Camera-based calibration techniques for seamless multiprojector displays,2005,Michael Brown and Aditi Majumder and Ruigang Yang,11,IEEE Transactions on Visualization and Computer Graphics,2,193-206,IEEE,"Multiprojector. large-scale displays are used in scientific visualization. virtual reality. and other visually intensive applications. In recent years. a number of camera-based computer vision techniques have been proposed to register the geometry and color of tiled projection-based display. These automated techniques use cameras to ""calibrate"" display geometry and photometry. computing per-projector corrective warps and intensity corrections that are necessary to produce seamless imagery across projector mosaics. These techniques replace the traditional labor-intensive manual alignment and maintenance steps. making such displays cost-effective. flexible. and accessible. In this paper. we present a survey of different camera-based geometric and photometric registration techniques reported in the literature to date. We discuss several techniques that have been proposed and demonstrated. each addressing …",True,Gv1QGSMAAAAJ:d1gkVwhDpl0C,342,https://ieeexplore.ieee.org/abstract/document/1388230/,17074855652982980859,/scholar?cites=17074855652982980859,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2973&rep=rep1&type=pdf,0,0,0
1277427,Super resolution using edge prior and single image detail synthesis,2010,Yu-Wing Tai and Shuaicheng Liu and Michael S Brown and Stephen Lin,,,,2400-2407,IEEE,Edge-directed image super resolution (SR) focuses on ways to remove edge artifacts in upsampled images. Under large magnification. however. textured regions become blurred and appear homogenous. resulting in a super-resolution image that looks unnatural. Alternatively. learning-based SR approaches use a large database of exemplar images for “hallucinating” detail. The quality of the upsampled image. especially about edges. is dependent on the suitability of the training images. This paper aims to combine the benefits of edge-directed SR with those of learning-based SR. In particular. we propose an approach to extend edge-directed super-resolution to include detail from an image/texture example provided by the user (e.g.. from the Internet). A significant benefit of our approach is that only a single exemplar image is required to supply the missing detail - strong edges are obtained in the SR image even if …,True,Gv1QGSMAAAAJ:aqlVkmm33-oC,331,https://ieeexplore.ieee.org/abstract/document/5539933/,4630902319735797357,/scholar?cites=4630902319735797357,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.5872&rep=rep1&type=pdf,0,0,0
1277428,Richardson-lucy deblurring for scenes under a projective motion path,2010,Yu-Wing Tai and Ping Tan and Michael S Brown,33,IEEE Transactions on Pattern Analysis and Machine Intelligence,8,1603-1618,IEEE,This paper addresses how to model and correct image blur that arises when a camera undergoes ego motion while observing a distant scene. In particular. we discuss how the blurred image can be modeled as an integration of the clear scene under a sequence of planar projective transformations (i.e.. homographies) that describe the camera's path. This projective motion path blur model is more effective at modeling the spatially varying motion blur exhibited by ego motion than conventional methods based on space-invariant blur kernels. To correct the blurred image. we describe how to modify the Richardson-Lucy (RL) algorithm to incorporate this new blur model. In addition. we show that our projective motion RL algorithm can incorporate state-of-the-art regularization priors to improve the deblurred results. The projective motion path blur model. along with the modified RL algorithm. is detailed. together with …,True,Gv1QGSMAAAAJ:5nxA0vEk-isC,329,https://ieeexplore.ieee.org/abstract/document/5674049/,767741698256595891,/scholar?cites=767741698256595891,,,,0,0,0
1277429,Pixelflex: A reconfigurable multi-projector display system,2001,Ruigang Yang and David Gotz and Justin Hensley and Herman Towles and Michael S Brown,,,,167-554,IEEE,This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors. each with computer-controlled pan. tilt. zoom and focus; and a camera for closed-loop calibration. Working collectively. these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density. size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces. thus giving the user the flexibility to quickly create. save and restore multiple screen configurations. Overall. PixelFlex provides a new level of automatic reconfigurability and usage. departing from the static. one-size-fits-all design of traditional large-format displays. As a front-projection system …,True,Gv1QGSMAAAAJ:u-x6o8ySG0sC,270,https://ieeexplore.ieee.org/abstract/document/964508/,6520153887366763708,/scholar?cites=6520153887366763708,,,https://wwwx.cs.unc.edu/Research/ootf/publications/Yang_Vis01.pdf,0,0,0
1277430,Single image layer separation using relative smoothness,2014,Yu Li and Michael S Brown,,,,2752-2759,,This paper addresses extracting two layers from an image where one layer is smoother than the other. This problem arises most notably in intrinsic image decomposition and reflection interference removal. Layer decomposition from a single-image is inherently ill-posed and solutions require additional constraints to be enforced. We introduce a novel strategy that regularizes the gradients of the two layers such that one has a long tail distribution and the other a short tail distribution. While imposing the long tail distribution is a common practice. our introduction of the short tail distribution on the second layer is unique. We formulate our problem in a probabilistic framework and describe an optimization scheme to solve this regularization with only a few iterations. We apply our approach to the intrinsic image and reflection removal problems and demonstrate high quality layer separation on par with other techniques but being significantly faster than prevailing methods.,True,Gv1QGSMAAAAJ:rHJHxKgnXwkC,243,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Li_Single_Image_Layer_2014_CVPR_paper.html,11036474170624221788,/scholar?cites=11036474170624221788,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Li_Single_Image_Layer_2014_CVPR_paper.pdf,0,0,0
1277431,Constructing image panoramas using dual-homography warping,2011,Junhong Gao and Seon Joo Kim and Michael S Brown,,,,49-56,IEEE,This paper describes a method to construct seamless image mosaics of a panoramic scene containing two predominate planes: a distant back plane and a ground plane that sweeps out from the camera's location. While this type of panorama can be stitched when the camera is carefully rotated about its optical center. such ideal scene capture is hard to perform correctly. Existing techniques use a single homography per image to perform alignment followed by seam cutting or image blending to hide inevitable alignments artifacts. In this paper. we demonstrate how to use two homographies per image to produce a more seamless image. Specifically. our approach blends the homographies in the alignment procedure to perform a nonlinear warping. Once the images are geometrically stitched. they are further processed to blend seams and reduce curvilinear visual artifacts due to the nonlinear warping. As …,True,Gv1QGSMAAAAJ:JV2RwH3_ST0C,227,https://ieeexplore.ieee.org/abstract/document/5995433/,12130654627336847023,/scholar?cites=12130654627336847023,,,http://www.cse.yorku.ca/~mbrown/pdf/cvpr_dualhomography2011.pdf,0,0,0
1277432,Illuminant estimation for color constancy: why spatial-domain methods work and the role of the color distribution,2014,Dongliang Cheng and Dilip K Prasad and Michael S Brown,31,JOSA A,5,1049-1058,Optical Society of America,Color constancy is a well-studied topic in color vision. Methods are generally categorized as (1) low-level statistical methods. (2) gamut-based methods. and (3) learning-based methods. In this work. we distinguish methods depending on whether they work directly from color values (i.e.. color domain) or from values obtained from the image’s spatial information (e.g.. image gradients/frequencies). We show that spatial information does not provide any additional information that cannot be obtained directly from the color distribution and that the indirect aim of spatial-domain methods is to obtain large color differences for estimating the illumination direction. This finding allows us to develop a simple and efficient illumination estimation method that chooses bright and dark pixels using a projection distance in the color distribution and then applies principal component analysis to estimate the illumination direction. Our …,True,Gv1QGSMAAAAJ:hsZV8lGYWTMC,211,https://www.osapublishing.org/abstract.cfm?uri=josaa-31-5-1049,8551502405238937091,/scholar?cites=8551502405238937091,,,https://pdfs.semanticscholar.org/58ac/c16bb633fd0cef2d53e0ed35f6eb4956ff89.pdf,0,0,0
1277433,Deep learning for remote sensing data: A technical tutorial on the state of the art,2016,Liangpei Zhang and Lefei Zhang and Bo Du,4,IEEE Geoscience and Remote Sensing Magazine,2,22-40,IEEE,Deep-learning (DL) algorithms. which learn the representative and discriminative features in a hierarchical manner from the data. have recently become a hotspot in the machine-learning area and have been introduced into the geoscience and remote sensing (RS) community for RS big data analysis. Considering the low-level features (e.g.. spectral and texture) as the bottom level. the output feature representation from the top level of the network can be directly fed into a subsequent classifier for pixel-based classification. As a matter of fact. by carefully addressing the practical demands in RS applications and designing the input?output levels of the whole network. we have found that DL is actually everywhere in RS data analysis: from the traditional topics of image preprocessing. pixel-based classification. and target recognition. to the recent challenging tasks of high-level semantic feature extraction and RS scene …,True,BBLD3z8AAAAJ:jD_Q_A4-jPwC,1046,https://ieeexplore.ieee.org/abstract/document/7486259/,16909941970341464017,/scholar?cites=16909941970341464017,,,https://www.academia.edu/download/50993030/Deep_Learning_for_Remote_Sensing_Data.pdf,0,0,0
1277434,Saliency-guided unsupervised feature learning for scene classification,2014,Fan Zhang and Bo Du and Liangpei Zhang,53,IEEE Transactions on Geoscience and Remote Sensing,4,2175-2184,IEEE,Due to the rapid technological development of various different satellite sensors. a huge volume of high-resolution image data sets can now be acquired. How to efficiently represent and recognize the scenes from such high-resolution image data has become a critical task. In this paper. we propose an unsupervised feature learning framework for scene classification. By using the saliency detection algorithm. we extract a representative set of patches from the salient regions in the image data set. These unlabeled data patches are exploited by an unsupervised feature learning method to learn a set of feature extractors which are robust and efficient and do not need elaborately designed descriptors such as the scale-invariant-feature-transform-based algorithm. We show that the statistics generated from the learned feature extractors can characterize a complex scene very well and can produce excellent classification …,True,BBLD3z8AAAAJ:b1wdh0AR-JQC,428,https://ieeexplore.ieee.org/abstract/document/6910306/,6037850356129320155,/scholar?cites=6037850356129320155,,,https://www.researchgate.net/profile/Fan_Zhang237/publication/269725613_Saliency-Guided_Unsupervised_Feature_Learning_for_Scene_Classification/links/57cad9b408aedb6d6d9a20ee/Saliency-Guided-Unsupervised-Feature-Learning-for-Scene-Classification.pdf,0,0,0
1277435,Scene classification via a gradient boosting random convolutional network framework,2015,Fan Zhang and Bo Du and Liangpei Zhang,54,IEEE Transactions on Geoscience and Remote Sensing,3,1793-1802,IEEE,Due to the recent advances in satellite sensors. a large amount of high-resolution remote sensing images is now being obtained each day. How to automatically recognize and analyze scenes from these satellite images effectively and efficiently has become a big challenge in the remote sensing field. Recently. a lot of work in scene classification has been proposed. focusing on deep neural networks. which learn hierarchical internal feature representations from image data sets and produce state-of-the-art performance. However. most methods. including the traditional shallow methods and deep neural networks. only concentrate on training a single model. Meanwhile. neural network ensembles have proved to be a powerful and practical tool for a number of different predictive tasks. Can we find a way to combine different deep neural networks effectively and efficiently for scene classification? In this paper. we …,True,BBLD3z8AAAAJ:VDARjI3xf8gC,307,https://ieeexplore.ieee.org/abstract/document/7310864/,12308161245411438369,/scholar?cites=12308161245411438369,,,https://www.researchgate.net/profile/Fan_Zhang237/publication/283523609_Scene_Classification_via_a_Gradient_Boosting_Random_Convolutional_Network_Framework/links/57cadb5408ae598251835587/Scene-Classification-via-a-Gradient-Boosting-Random-Convolutional-Network-Framework.pdf,0,0,0
1277436,Stacked convolutional denoising auto-encoders for feature representation,2016,Bo Du and Wei Xiong and Jia Wu and Lefei Zhang and Liangpei Zhang and Dacheng Tao,47,IEEE transactions on cybernetics,4,1017-1027,IEEE,Deep networks have achieved excellent performance in learning representation from visual data. However. the supervised deep models like convolutional neural network require large quantities of labeled data. which are very expensive to obtain. To solve this problem. this paper proposes an unsupervised deep network. called the stacked convolutional denoising auto-encoders. which can map images to hierarchical representations without any label information. The network. optimized by layer-wise training. is constructed by stacking layers of denoising auto-encoders in a convolutional way. In each layer. high dimensional feature maps are generated by convolving features of the lower layer with kernels learned by a denoising auto-encoder. The auto-encoder is trained on patches extracted from feature maps in the lower layer to learn robust feature detectors. To better train the large network. a layer-wise …,True,BBLD3z8AAAAJ:eTOb990cMygC,286,https://ieeexplore.ieee.org/abstract/document/7434593/,17268315241393644282,/scholar?cites=17268315241393644282,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Stacked%20Convolutional%20Denoising%20Auto-Encoders%20for%20Feature%20Representation.pdf,0,0,0
1277437,Ensemble manifold regularized sparse low-rank approximation for multiview feature embedding,2015,Lefei Zhang and Qian Zhang and Liangpei Zhang and Dacheng Tao and Xin Huang and Bo Du,48,Pattern Recognition,10,3102-3112,Pergamon,In computer vision and pattern recognition researches. the studied objects are often characterized by multiple feature representations with high dimensionality. thus it is essential to encode that multiview feature into a unified and discriminative embedding that is optimal for a given task. To address this challenge. this paper proposes an ensemble manifold regularized sparse low-rank approximation (EMR-SLRA) algorithm for multiview feature embedding. The EMR-SLRA algorithm is based on the framework of least-squares component analysis. in particular. the low dimensional feature representation and the projection matrix are obtained by the low-rank approximation of the concatenated multiview feature matrix. By considering the complementary property among multiple features. EMR-SLRA simultaneously enforces the ensemble manifold regularization on the output feature embedding. In order to further …,True,BBLD3z8AAAAJ:iWMDS-dds2cC,262,https://www.sciencedirect.com/science/article/pii/S0031320314005275,12546183331266501246,/scholar?cites=12546183331266501246,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Ensemble%20Manifold%20Regularized%20Sparse%20Low-Rank%20Approximation%20for%20Multiview%20Feature%20Embedding.pdf,0,0,0
1277438,Random-selection-based anomaly detector for hyperspectral imagery,2010,Bo Du and Liangpei Zhang,49,IEEE Transactions on Geoscience and Remote Sensing,5,1578-1589,IEEE,Anomaly detection in hyperspectral images is of great interest in the target detection domain since it requires no prior information and makes full use of the spectral differences revealed in hyperspectral images. The current anomaly detection methods are susceptible to anomalies in the processing window range or the image scope. In addition. for the local anomaly detection methods themselves. it is difficult to determine the window size suitable for processing background statistics. This paper proposes an anomaly detection method based on the random selection of background pixels. the random-selection-based anomaly detector (RSAD). Pixels are randomly selected from the image scene to represent the background statistics; the random selections are performed a sufficient number of times; blocked adaptive computationally efficient outlier nominators are used to detect anomalies each time after a proper …,True,BBLD3z8AAAAJ:cFHS6HbyZ2cC,251,https://ieeexplore.ieee.org/abstract/document/5628269/,12257303955278968758,/scholar?cites=12257303955278968758,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Random-Selection-Based%20Anomaly%20Detector.pdf,0,0,0
1277439,A discriminative metric learning based anomaly detection method,2014,Bo Du and Liangpei Zhang,52,IEEE Transactions on Geoscience and Remote Sensing,11,6844-6857,IEEE,Due to the high spectral resolution. anomaly detection from hyperspectral images provides a new way to locate potential targets in a scene. especially those targets that are spectrally different from the majority of the data set. Conventional Mahalanobis-distance-based anomaly detection methods depend on the background statistics to construct the anomaly detection metric. One of the main problems with these methods is that the Gaussian distribution assumption of the background may not be reasonable. Furthermore. these methods are also susceptible to contamination of the conventional background covariance matrix by anomaly pixels. This paper proposes a new anomaly detection method by effectively exploiting a robust anomaly degree metric for increasing the separability between anomaly pixels and other background pixels. using discriminative information. First. the manifold feature is used so as to divide …,True,BBLD3z8AAAAJ:NJ774b8OgUMC,239,https://ieeexplore.ieee.org/abstract/document/6757026/,974737052148118660,/scholar?cites=974737052148118660,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/A%20Discriminative%20Metric%20Learning%20Based%20Anomaly%20Detection%20Method.pdf,0,0,0
1277440,Weakly supervised learning based on coupled convolutional neural networks for aircraft detection,2016,Fan Zhang and Bo Du and Liangpei Zhang and Miaozhong Xu,54,IEEE Transactions on Geoscience and Remote Sensing,9,5553-5563,IEEE,Aircraft detection from very high resolution (VHR) remote sensing images has been drawing increasing interest in recent years due to the successful civil and military applications. However. several challenges still exist: 1) extracting the high-level features and the hierarchical feature representations of the objects is difficult; 2) manual annotation of the objects in large image sets is generally expensive and sometimes unreliable; and 3) locating objects within such a large image is difficult and time consuming. In this paper. we propose a weakly supervised learning framework based on coupled convolutional neural networks (CNNs) for aircraft detection. which can simultaneously solve these problems. We first develop a CNN-based method to extract the high-level features and the hierarchical feature representations of the objects. We then employ an iterative weakly supervised learning framework to automatically …,True,BBLD3z8AAAAJ:M0jDNLgoRFEC,171,https://ieeexplore.ieee.org/abstract/document/7485835/,16195225902509250256,/scholar?cites=16195225902509250256,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Weakly%20Supervised%20Learning%20Based%20on%20Coupled%20Convolutional%20Neural%20Networks%20for%20Aircraft%20Detection.pdf,0,0,0
1277441,A low-rank and sparse matrix decomposition-based Mahalanobis distance method for hyperspectral anomaly detection,2015,Yuxiang Zhang and Bo Du and Liangpei Zhang and Shugen Wang,54,IEEE Transactions on Geoscience and Remote Sensing,3,1376-1389,IEEE,Anomaly detection is playing an increasingly important role in hyperspectral image (HSI) processing. The traditional anomaly detection methods mainly extract knowledge from the background and use the difference between the anomalies and the background to distinguish them. Anomaly contamination and the inverse covariance matrix problem are the main difficulties with these methods. The low-rank and sparse matrix decomposition (LRaSMD) technique may have the potential to solve the aforementioned hyperspectral anomaly detection problem since it can extract knowledge from both the background and the anomalies. This paper proposes an LRaSMD-based Mahalanobis distance method for hyperspectral anomaly detection (LSMAD). This approach has the following capabilities: 1) takes full advantage of the LRaSMD technique to set the background apart from the anomalies; 2) explores the low-rank …,True,BBLD3z8AAAAJ:NWFKKQzSIN4C,170,https://ieeexplore.ieee.org/abstract/document/7293169/,4821317651415832794,/scholar?cites=4821317651415832794,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/A%20Low-Rank%20and%20Sparse%20Matrix%20Decomposition%20Based%20Mahalanobis%20Distance%20Method%20for%20Hyperspectral%20Anomaly%20Detection.pdf,0,0,0
1277442,Feature learning using spatial-spectral hypergraph discriminant analysis for hyperspectral image,2018,Fulin Luo and Bo Du and Liangpei Zhang and Lefei Zhang and Dacheng Tao,49,IEEE transactions on cybernetics,7,2406-2419,IEEE,Hyperspectral image (HSI) contains a large number of spatial-spectral information. which will make the traditional classification methods face an enormous challenge to discriminate the types of land-cover. Feature learning is very effective to improve the classification performances. However. the current feature learning approaches are mostly based on a simple intrinsic structure. To represent the complex intrinsic spatial-spectral of HSI. a novel feature learning algorithm. termed spatialspectral hypergraph discriminant analysis (SSHGDA). has been proposed on the basis of spatial-spectral information. discriminant information. and hypergraph learning. SSHGDA constructs a reconstruction between-class scatter matrix. a weighted withinclass scatter matrix. an intraclass spatial-spectral hypergraph. and an interclass spatial-spectral hypergraph to represent the intrinsic properties of HSI. Then. in low-dimensional …,True,BBLD3z8AAAAJ:2pCWc5Tf3J4C,165,https://ieeexplore.ieee.org/abstract/document/8351966/,8198674169653922848,/scholar?cites=8198674169653922848,,,,0,0,0
1277443,Simultaneous spectral-spatial feature selection and extraction for hyperspectral images,2016,Lefei Zhang and Qian Zhang and Bo Du and Xin Huang and Yuan Yan Tang and Dacheng Tao,48,IEEE Transactions on Cybernetics,1,16-28,IEEE,In hyperspectral remote sensing data mining. it is important to take into account of both spectral and spatial information. such as the spectral signature. texture feature. and morphological property. to improve the performances. e.g.. the image classification accuracy. In a feature representation point of view. a nature approach to handle this situation is to concatenate the spectral and spatial features into a single but high dimensional vector and then apply a certain dimension reduction technique directly on that concatenated vector before feed it into the subsequent classifier. However. multiple features from various domains definitely have different physical meanings and statistical properties. and thus such concatenation has not efficiently explore the complementary properties among different features. which should benefit for boost the feature discriminability. Furthermore. it is also difficult to interpret the transformed …,True,BBLD3z8AAAAJ:71XFh8zZwT8C,164,https://ieeexplore.ieee.org/abstract/document/7564440/,10288918583770083724,/scholar?cites=10288918583770083724,,,https://arxiv.org/pdf/1904.03982,0,0,0
1277444,A global reference for human genetic variation,2015,1000 Genomes Project Consortium,526,Nature,7571,68-74,Nature Publishing Group,The 1000 Genomes Project set out to provide a comprehensive description of common human genetic variation by applying whole-genome sequencing to a diverse set of individuals from multiple populations. Here we report completion of the project. having reconstructed the genomes of 2.504 individuals from 26 populations using a combination of low-coverage whole-genome sequencing. deep exome sequencing. and dense microarray genotyping. We characterized a broad spectrum of genetic variation. in total over 88 million variants (84.7 million single nucleotide polymorphisms (SNPs). 3.6 million short insertions/deletions (indels). and 60.000 structural variants). all phased onto high-quality haplotypes. This resource includes> 99% of SNP variants with a frequency of> 1% for a variety of ancestries. We describe the distribution of genetic variation across the global sample. and discuss the implications for …,True,inD0figAAAAJ:LkGwnXOMwfcC,7879,https://www.nature.com/articles/nature15393,4920627857991727214,/scholar?cites=4920627857991727214,,,https://www.nature.com/articles/nature15393,0,0,0
1277445,EUCLID DEFINITION STUDY REPORT,2011,et. al. R. Laureijs,12,,,116,ESA/SRE(2011)12,Euclid is a space-based survey mission from the European Space Agency designed to understand the origin of the Universe's accelerating expansion. It will use cosmological probes to investigate the nature of dark energy. dark matter and gravity by tracking their observational signatures on the geometry of the universe and on the cosmic history of structure formation. The mission is optimised for two independent primary cosmological probes: Weak gravitational Lensing (WL) and Baryonic Acoustic Oscillations (BAO). The Euclid payload consists of a 1.2 m Korsch telescope designed to provide a large field of view. It carries two instruments with a common field-of-view of~ 0.54 deg2: the visual imager (VIS) and the near infrared instrument (NISP) which contains a slitless spectrometer and a three bands photometer. The Euclid wide survey will cover 15.000 deg2 of the extragalactic sky and is complemented by two 20 deg2 deep fields. For WL. Euclid measures the shapes of 30-40 resolved galaxies per arcmin2 in one broad visible R+ I+ Z band (550-920 nm). The photometric redshifts for these galaxies reach a precision of dz/(1+ z)< 0.05. They are derived from three additional Euclid NIR bands (Y. J. H in the range 0.92-2.0 micron). complemented by ground based photometry in visible bands derived from public data or through engaged collaborations. The BAO are determined from a spectroscopic survey with a redshift accuracy dz/(1+ z)= 0.001. The slitless spectrometer. with spectral resolution~ 250. predominantly detects Ha emission line galaxies. Euclid is a Medium Class mission of the ESA Cosmic Vision 2015-2025 programme. with a …,True,inD0figAAAAJ:Y0pCki6q_DkC,833,https://arxiv.org/abs/1110.3193,18258181278125637153,/scholar?cites=18258181278125637153,,,https://arxiv.org/pdf/1110.3193&sa=U&ei=mDe5U8bxJaXb7AbIyYGICw&ved=0CC4QFjAE&usg=AFQjCNFN7mYnsx1-pPbbcitiiWzyKAudvA,0,0,0
1277446,Euclid Definition Study Report,2011,N Shane and C Surace and A Taylor and G Verdoes-Kleijn and C Vuerli and A Zacchei and B Altieri and I Escudero Sanz and R Kohley and T Oosterbroek and P Astier and D Bacon and S Bardelli and C Baugh and F Bellagamba and C Benoist and D Bianchi and A Biviano and E Branchini and C Carbone and V Cardone and D Clements and S Colombi and C Conselice and G Cresci and N Deacon and J Dunlop and C Fedeli and F Fontanot and P Franzetti and C Giocoli and J Garcia-Bellido and J Gow and A Heavens and P Hewett and C Heymans and A Holland and Z Huang and O Ilbert and B Joachimi and E Jennins and E Kerins and A Kiessling and D Kirk and R Kotak and O Krause and O Lahav and F Leeuwen and J Lesgourgues and M Lombardi and M Magliocchetti and K Maguire and E Majerotto and R Maoli and F Marulli and S Maurogordato and H Mccracken and R Mclure and A Melchiorri and A Merson and M Moresco and M Nonino and P Norberg and J Peacock and R Pellò and M Penny and V Pettorino and C Di Porto and L Pozzetti and C Quercellini and M Radovich and A Rassat and N Roche and S Ronayette and E Rossetti and B Sartoris and P Schneider and E Semboloni and S Serjeant and F Simpson and C Skordis and G Smadja and S Smartt and P Spano and S Spiro and M Sullivan and A Tilquin and R Trotta and L Verde and Y Wang and G Williger and G Zhao and J Zoubian and E Zucca and R Laureijs and J Amiaux and S Arduini and J Brinchmann and R Cole and M Cropper and C Dabin and L Duvet and A Ealet and B Garilli and P Gondoin and L Guzzo and J Hoar and H Hoekstra and R Holmes and T Kitching and T Maciaszek and Y Mellier and F Pasian and W Percival and J Rhodes and G Saavedra Criado and M Sauvage and R Scaramella and L Valenziano and S Warren and R Bender and F Castander and A Cimatti and O Le Fèvre and H Kurki-Suonio and M Levi and P Lilje and G Meylan and R Nichol and K Pedersen and V Popa and R Rebolo Lopez and H Röttgering and W Zeilinger and F Grupp and P Hudelot and R Massey and M Meneghetti and L Miller and S Paltani and S Paulin-Henriksson and S Pires and C Saxton and T Schrabback and G Seidel and J Walsh and N Aghanim and L Amendola and J Bartlett and C Baccigalupi,,ArXiv e-prints,,,,,True,inD0figAAAAJ:wSy_KLzO7YEC,761,,18258181278125637153,/scholar?cites=18258181278125637153,,,,0,0,0
1277447,The first and second data releases of the Kilo-Degree Survey,2015,Jelte TA de Jong and Gijs A Verdoes Kleijn and Danny R Boxhoorn and Hugo Buddelmeijer and Massimo Capaccioli and Fedor Getman and Aniello Grado and Ewout Helmich and Zhuoyi Huang and Nancy Irisarri and Konrad Kuijken and Francesco La Barbera and John P McFarland and Nicola R Napolitano and Mario Radovich and Gert Sikkema and Edwin A Valentijn and Kor G Begeman and Massimo Brescia and Stefano Cavuoti and Ami Choi and Oliver-Mark Cordes and Giovanni Covone and Massimo Dall’Ora and Hendrik Hildebrandt and Giuseppe Longo and Reiko Nakajima and Maurizio Paolillo and Emanuella Puddu and Agatino Rifatto and Crescenzo Tortora and Edo van Uitert and Axel Buddendiek and Joachim Harnois-Déraps and Thomas Erben and Martin B Eriksen and Catherine Heymans and Henk Hoekstra and Benjamin Joachimi and Thomas D Kitching and Dominik Klaes and Léon VE Koopmans and Fabian Köhlinger and Nivya Roy and Cristóbal Sifón and Peter Schneider and Will J Sutherland and Massimo Viola and Willem-Jan Vriend,582,Astronomy & Astrophysics,,A62,EDP Sciences,,True,inD0figAAAAJ:W7OEmFMy1HYC,232,https://www.aanda.org/articles/aa/abs/2015/10/aa26601-15/aa26601-15.html,6445571761420128537,/scholar?cites=6445571761420128537,,,https://www.aanda.org/articles/aa/abs/2015/10/aa26601-15/aa26601-15.html,0,0,0
1277448,The first and second data releases of the Kilo-Degree Survey,2015,Kleijn GA Verdoes and DR Boxhoorn and H Buddelmeijer and M Capaccioli and F Getman and A Grado and E Helmich and Z Huang and Mendez N Irisarri and KH Kuijken and Barbera F La and JP McFarland and NR Napolitano and M Radovich and G Sikkema and EA Valentijn and KG Begeman and M Brescia and S Cavuoti and A Choi and O Cordes and G Covone and M Dall'Ora and H Hildebrandt and G Longo and R Nakajima and M Paolillo and E Puddu and A Rifatto and C Tortora and E Uitert and A Buddendiek and J Harnois-Déraps and T Erben and MB Eriksen and C Heymans and H Hoekstra and B Joachimi and TD Kitching and D Klaes and LVE Koopmans and F Köhlinger and N Roy and C Sifon and P Schneider and WJ Sutherland and M Viola and W-J Vriend,582,Astronomy & Astrophysics,,,,,True,inD0figAAAAJ:Og1tA8FjbJAC,232,,6445571761420128537,/scholar?cites=6445571761420128537,,,,0,0,0
1277449,The third data release of the Kilo-Degree Survey and associated data products,2017,Jelte TA de Jong and Gijs A Verdoes Kleijn and Thomas Erben and Hendrik Hildebrandt and Konrad Kuijken and Gert Sikkema and Massimo Brescia and Maciej Bilicki and Nicola R Napolitano and Valeria Amaro and Kor G Begeman and Danny R Boxhoorn and Hugo Buddelmeijer and Stefano Cavuoti and Fedor Getman and Aniello Grado and Ewout Helmich and Zhuoyi Huang and Nancy Irisarri and Francesco La Barbera and Giuseppe Longo and John P McFarland and Reiko Nakajima and Maurizio Paolillo and Emanuella Puddu and Mario Radovich and Agatino Rifatto and Crescenzo Tortora and Edwin A Valentijn and Civita Vellucci and Willem-Jan Vriend and Alexandra Amon and Chris Blake and Ami Choi and Ian Fenech Conti and Stephen DJ Gwyn and Ricardo Herbonnet and Catherine Heymans and Henk Hoekstra and Dominik Klaes and Julian Merten and Lance Miller and Peter Schneider and Massimo Viola,604,Astronomy & Astrophysics,,A134,EDP Sciences,,True,inD0figAAAAJ:BOlwja0KXvYC,148,https://www.aanda.org/articles/aa/abs/2017/08/aa30747-17/aa30747-17.html,8106201263646282346,/scholar?cites=8106201263646282346,,,https://www.aanda.org/articles/aa/abs/2017/08/aa30747-17/aa30747-17.html,0,0,0
1277450,WGSA: an annotation pipeline for human genome sequencing studies,2015,Xiaoming Liu and Simon White and Bo Peng and Andrew D Johnson and Jennifer A Brody and Alexander H Li and Zhuoyi Huang and Andrew Carroll and Peng Wei and Richard Gibbs and Robert J Klein and Eric Boerwinkle,,Journal of medical genetics,,jmedgenet-2015-103423,BMJ Publishing Group Ltd,DNA sequencing technologies continue to make progress in increased throughput and quality. and decreased cost. As we transition from whole exome capture sequencing to whole genome sequencing (WGS). our ability to convert machine-generated variant calls. including single nucleotide variant (SNV) and insertion-deletion variants (indels). into human-interpretable knowledge has lagged far behind the ability to obtain enormous amounts of variants. To help narrow this gap. here we present WGSA (WGS annotator). a functional annotation pipeline for human genome sequencing studies. which is runnable out of the box on the Amazon Compute Cloud and is freely downloadable at (https://sites. google. com/site/jpopgen/wgsa/). Functional annotation is a key step in WGS analysis. In one way. annotation helps the analyst filter to a subset of elements of particular interest (eg. cell type specific enhancers). in …,True,inD0figAAAAJ:WF5omc3nYNoC,64,https://jmg.bmj.com/content/53/2/111.short,16606607313524163253,/scholar?cites=16606607313524163253,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124490/,0,0,0
1277451,Holographic explanation of wide-angle power correlation suppression in the cosmic microwave background radiation,2006,Zhuo-Yi Huang and Bin Wang and Elcio Abdalla and Ru-Keng Su,2006,Journal of Cosmology and Astroparticle Physics,05,013,IOP Publishing,We investigate the question of the suppression of the CMB power spectrum for the lowest multipoles in closed Universes. The intrinsic reason for a lowest cut-off in closed Universes. connected with the discrete spectrum of the wavelength. is shown not to be enough to explain observations. We thus extend the holographic cosmic duality to closed universes by relating the dark energy equation of state and the power spectrum. showing a suppression behaviour which describes the low <?TeX \ell ?>   features extremely well. We also explore the possibility to disclose the nature of the dark energy from the observed small <?TeX \ell ?>   CMB spectrum by employing the holographic idea.,True,inD0figAAAAJ:u5HHmVD_uO8C,54,https://iopscience.iop.org/article/10.1088/1475-7516/2006/05/013/meta,9229408622846764861,/scholar?cites=9229408622846764861,,,https://arxiv.org/pdf/hep-th/0501059,0,0,0
1277452,On the shear estimation bias induced by the spatial variation of colour across galaxy profiles,2013,Elisabetta Semboloni and Henk Hoekstra and Zhuoyi Huang and VF Cardone and Mark Cropper and Benjamin Joachimi and Thomas Kitching and Konrad Kuijken and Marco Lombardi and Roberto Maoli and Yannick Mellier and Lance Miller and Jason Rhodes and Roberto Scaramella and Tim Schrabback and Malin Velander,432,Monthly Notices of the Royal Astronomical Society,3,2385-2401,Oxford University Press,The spatial variation of the colour of a galaxy may introduce a bias in the measurement of its shape if the point spread function (PSF) profile depends on wavelength. We study how this bias depends on the properties of the PSF and the galaxies themselves. The bias depends on the scales used to estimate the shape. which may be used to optimize methods to reduce the bias. Here. we develop a general approach to quantify the bias. Although applicable to any weak lensing survey. we focus on the implications for the ESA Euclid mission.Based on our study of synthetic galaxies. we find that the bias is a few times 10−3 for a typical galaxy observed by Euclid. Consequently. it cannot be neglected and needs to be accounted for. We demonstrate how one can do so using spatially resolved observations of galaxies in two filters. We show that Hubble Space Telescope (HST) observations in the F606W and …,True,inD0figAAAAJ:9yKSN-GCB0IC,47,https://academic.oup.com/mnras/article-abstract/432/3/2385/1749151,11152252676807265029,/scholar?cites=11152252676807265029,,,https://academic.oup.com/mnras/article/432/3/2385/1749151,0,0,0
1277453,Practical Approaches for Whole-Genome Sequence Analysis of Heart-and Blood-Related Traits,2017,Alanna C Morrison and Zhuoyi Huang and Bing Yu and Ginger Metcalf and Xiaoming Liu and Christie Ballantyne and Josef Coresh and Fuli Yu and Donna Muzny and Elena Feofanova and Navin Rustagi and Richard Gibbs and Eric Boerwinkle,100,The American Journal of Human Genetics,2,205-215,Cell Press,Whole-genome sequencing (WGS) allows for a comprehensive view of the sequence of the human genome. We present and apply integrated methodologic steps for interrogating WGS data to characterize the genetic architecture of 10 heart- and blood-related traits in a sample of 1.860 African Americans. In order to evaluate the contribution of regulatory and non-protein coding regions of the genome. we conducted aggregate tests of rare variation across the entire genomic landscape using a sliding window. complemented by an annotation-based assessment of the genome using predefined regulatory elements and within the first intron of all genes. These tests were performed treating all variants equally as well as with individual variants weighted by a measure of predicted functional consequence. Significant findings were assessed in 1.705 individuals of European ancestry. After these steps. we identified and …,True,inD0figAAAAJ:sJPMR1oEGYQC,28,https://www.sciencedirect.com/science/article/pii/S000292971630533X,10461959093343317536,/scholar?cites=10461959093343317536,,,https://www.sciencedirect.com/science/article/pii/S000292971630533X,0,0,0
1277454,Whole-exome Sequencing Reveals Uncaptured Variation and Distinct Ancestry in the Southern African Population of Botswana,2018,Gaone Retshabile and Busisiwe C Mlotshwa and Lesedi Williams and Savannah Mwesigwa and Gerald Mboowa and Zhuoyi Huang and Navin Rustagi and Shanker Swaminathan and Eric Katagirya and Samuel Kyobe and Misaki Wayengera and Grace P Kisitu and David P Kateete and Eddie M Wampande and Koketso Maplanka and Ishmael Kasvosve and Edward D Pettitt and Mogomotsi Matshaba and Betty Nsangi and Marape Marape and Masego Tsimako-Johnstone and Chester W Brown and Fuli Yu and Adeodata Kekitiinwa and Moses Joloba and Sununguko W Mpoloka and Graeme Mardon and Gabriel Anabwani and Neil A Hanchard,102,The American Journal of Human Genetics,5,731-743,Cell Press,Large-scale. population-based genomic studies have provided a context for modern medical genetics. Among such studies. however. African populations have remained relatively underrepresented. The breadth of genetic diversity across the African continent argues for an exploration of local genomic context to facilitate burgeoning disease mapping studies in Africa. We sought to characterize genetic variation and to assess population substructure within a cohort of HIV-positive children from Botswana—a Southern African country that is regionally underrepresented in genomic databases. Using whole-exome sequencing data from 164 Batswana and comparisons with 150 similarly sequenced HIV-positive Ugandan children. we found that 13%–25% of variation observed among Batswana was not captured by public databases. Uncaptured variants were significantly enriched (p = 2.2 × 10−16) for coding variants …,True,inD0figAAAAJ:AZju0d2GQJ0C,26,https://www.sciencedirect.com/science/article/pii/S0002929718300995,119329157333139289,/scholar?cites=119329157333139289,,,https://www.sciencedirect.com/science/article/pii/S0002929718300995,0,0,0
1277455,Hyperspectral image restoration using low-rank matrix recovery,2013,Hongyan Zhang and Wei He and Liangpei Zhang and Huanfeng Shen and Qiangqiang Yuan,52,IEEE transactions on geoscience and remote sensing,8,4729-4743,IEEE,Hyperspectral images (HSIs) are often degraded by a mixture of various kinds of noise in the acquisition process. which can include Gaussian noise. impulse noise. dead lines. stripes. and so on. This paper introduces a new HSI restoration method based on low-rank matrix recovery (LRMR). which can simultaneously remove the Gaussian noise. impulse noise. dead lines. and stripes. By lexicographically ordering a patch of the HSI into a 2-D matrix. the low-rank property of the hyperspectral imagery is explored. which suggests that a clean HSI patch can be regarded as a low-rank matrix. We then formulate the HSI restoration problem into an LRMR framework. To further remove the mixed noise. the “Go Decomposition” algorithm is applied to solve the LRMR problem. Several experiments were conducted in both simulated and real data conditions to verify the performance of the proposed LRMR-based HSI …,True,ore_9NIAAAAJ:lSLTfruPkqcC,493,https://ieeexplore.ieee.org/abstract/document/6648433/,7634343867462362785,/scholar?cites=7634343867462362785,,,http://www.lmars.whu.edu.cn/prof_web/zhanghongyan/papers/Hyperspectral%20Image%20Restoration%20Using%20Low-Rank%20Matrix%20Recovery.pdf,0,0,0
1277456,Hyperspectral image denoising employing a spectral–spatial adaptive total variation model,2012,Qiangqiang Yuan and Liangpei Zhang and Huanfeng Shen,50,IEEE Transactions on Geoscience and Remote Sensing,10,3660-3677,IEEE,The amount of noise included in a hyperspectral image limits its application and has a negative impact on hyperspectral image classification. unmixing. target detection. and so on. In hyperspectral images. because the noise intensity in different bands is different. to better suppress the noise in the high-noise-intensity bands and preserve the detailed information in the low-noise-intensity bands. the denoising strength should be adaptively adjusted with the noise intensity in the different bands. Meanwhile. in the same band. there exist different spatial property regions. such as homogeneous regions and edge or texture regions; to better reduce the noise in the homogeneous regions and preserve the edge and texture information. the denoising strength applied to pixels in different spatial property regions should also be different. Therefore. in this paper. we propose a hyperspectral image denoising algorithm …,True,ore_9NIAAAAJ:hqOjcs7Dif8C,385,https://ieeexplore.ieee.org/abstract/document/6165657/,4282662794829043656,/scholar?cites=4282662794829043656,,,http://sendimage.whu.edu.cn/wp-content/uploads/2015/08/82012_Hyperspectral-Image-Denoising-Employing-a.pdf,0,0,0
1277457,A MAP approach for joint motion estimation. segmentation. and super resolution,2007,Huanfeng Shen and Liangpei Zhang and Bo Huang and Pingxiang Li,16,IEEE Transactions on Image processing,2,479-490,IEEE,Super resolution image reconstruction allows the recovery of a high-resolution (HR) image from several low-resolution images that are noisy. blurred. and down sampled. In this paper. we present a joint formulation for a complex super-resolution problem in which the scenes contain multiple independently moving objects. This formulation is built upon the maximum a posteriori (MAP) framework. which judiciously combines motion estimation. segmentation. and super resolution together. A cyclic coordinate descent optimization procedure is used to solve the MAP formulation. in which the motion fields. segmentation fields. and HR images are found in an alternate manner given the two others. respectively. Specifically. the gradient-based methods are employed to solve the HR image and motion fields. and an iterated conditional mode optimization method to obtain the segmentation fields. The proposed algorithm has …,True,ore_9NIAAAAJ:u5HHmVD_uO8C,313,https://ieeexplore.ieee.org/abstract/document/4060953/,9030840448124702090,/scholar?cites=9030840448124702090,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.692.4884&rep=rep1&type=pdf,0,0,0
1277458,Total-variation-regularized low-rank matrix factorization for hyperspectral image restoration,2015,Wei He and Hongyan Zhang and Liangpei Zhang and Huanfeng Shen,54,IEEE transactions on geoscience and remote sensing,1,178-188,IEEE,In this paper. we present a spatial spectral hyperspectral image (HSI) mixed-noise removal method named total variation (TV)-regularized low-rank matrix factorization (LRTV). In general. HSIs are not only assumed to lie in a low-rank subspace from the spectral perspective but also assumed to be piecewise smooth in the spatial dimension. The proposed method integrates the nuclear norm. TV regularization. and L 1 -norm together in a unified framework. The nuclear norm is used to exploit the spectral low-rank property. and the TV regularization is adopted to explore the spatial piecewise smooth structure of the HSI. At the same time. the sparse noise. which includes stripes. impulse noise. and dead pixels. is detected by the L 1 -norm regularization. To tradeoff the nuclear norm and TV regularization and to further remove the Gaussian noise of the HSI. we also restrict the rank of the clean image to be no larger than …,True,ore_9NIAAAAJ:MLfJN-KU85MC,300,https://ieeexplore.ieee.org/abstract/document/7167714/,14952956456675036317,/scholar?cites=14952956456675036317,,,http://202.114.114.81/papers/Total-Variation-Regularized%20Low-rank%20Matrix%20Factorization%20for%20Hyperspectral%20Image%20Restoration.pdf,0,0,0
1277459,A super-resolution reconstruction algorithm for surveillance images,2010,Liangpei Zhang and Hongyan Zhang and Huanfeng Shen and Pingxiang Li,90,Signal Processing,3,848-859,Elsevier,In many surveillance video applications. it is of interest to recognize a region of interest (ROI). which often occupies a small portion of a low-resolution. noisy video. This paper proposes an edge-preserving maximum a posteriori (MAP) estimation based super-resolution algorithm using a weighted directional Markov image prior model for a ROI from more than one low-resolution surveillance image. Conjugate gradient (CG) optimization based on standard operations on images is then developed to improve the computational efficiency of the algorithm. The proposed algorithm is tested on different series of surveillance images. The experimental results indicate that the proposed algorithm has considerable effectiveness in terms of both objective measurements and visual evaluation.,True,ore_9NIAAAAJ:d1gkVwhDpl0C,248,https://www.sciencedirect.com/science/article/pii/S0165168409003776,5640300277512203754,/scholar?cites=5640300277512203754,,,,0,0,0
1277460,A total variation regularization based super-resolution reconstruction algorithm for digital video,2007,Michael K Ng and Huanfeng Shen and Edmund Y Lam and Liangpei Zhang,2007,EURASIP Journal on Advances in Signal Processing,,1-16,Springer International Publishing,Super-resolution (SR) reconstruction technique is capable of producing a high-resolution image from a sequence of low-resolution images. In this paper. we study an efficient SR algorithm for digital video. To effectively deal with the intractable problems in SR video reconstruction. such as inevitable motion estimation errors. noise. blurring. missing regions. and compression artifacts. the total variation (TV) regularization is employed in the reconstruction model. We use the fixed-point iteration method and preconditioning techniques to efficiently solve the associated nonlinear Euler-Lagrange equations of the corresponding variational problem in SR. The proposed algorithm has been tested in several cases of motion and degradation. It is also compared with the Laplacian regularization-based SR algorithm and other TV-based SR algorithms. Experimental results are presented to illustrate the effectiveness of …,True,ore_9NIAAAAJ:u-x6o8ySG0sC,241,https://link.springer.com/content/pdf/10.1155/2007/74585.pdf,13526966344110143422,/scholar?cites=13526966344110143422,,,https://link.springer.com/content/pdf/10.1155/2007/74585.pdf,0,0,0
1277461,Image super-resolution: The techniques. applications. and future,2016,Linwei Yue and Huanfeng Shen and Jie Li and Qiangqiang Yuan and Hongyan Zhang and Liangpei Zhang,128,,,389-408,Elsevier,Super-resolution (SR) technique reconstructs a higher-resolution image or sequence from the observed LR images. As SR has been developed for more than three decades. both multi-frame and single-frame SR have significant applications in our daily life. This paper aims to provide a review of SR from the perspective of techniques and applications. and especially the main contributions in recent years. Regularized SR methods are most commonly employed in the last decade. Technical details are discussed in this article. including reconstruction models. parameter selection methods. optimization algorithms and acceleration strategies. Moreover. an exhaustive summary of the current applications using SR techniques has been presented. Lastly. the article discusses the current obstacles for future research.,True,ore_9NIAAAAJ:0N-VGjzr574C,240,https://www.sciencedirect.com/science/article/pii/S0165168416300536,10494911124317521990,/scholar?cites=10494911124317521990,,,"http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/Image%20super-resolution%20The%20techniques,%20applications,%20and%20future.pdf",0,0,0
1277462,A MAP-based algorithm for destriping and inpainting of remotely sensed images,2008,Huanfeng Shen and Liangpei Zhang,47,IEEE Transactions on Geoscience and Remote Sensing,5,1492-1502,IEEE,Remotely sensed images often suffer from the common problems of stripe noise and random dead pixels. The techniques to recover a good image from the contaminated one are called image destriping (for stripes) and image inpainting (for dead pixels). This paper presents a maximum  a posteriori  (MAP)-based algorithm for both destriping and inpainting problems. The main advantage of this algorithm is that it can constrain the solution space according to  a priori  knowledge during the destriping and inpainting processes. In the MAP framework. the likelihood probability density function (PDF) is constructed based on a linear image observation model. and a robust Huber-Markov model is used as the prior PDF. The gradient descent optimization method is employed to produce the desired image. The proposed algorithm has been tested using moderate resolution imaging spectrometer images for destriping and …,True,ore_9NIAAAAJ:2osOgNQ5qMEC,206,https://ieeexplore.ieee.org/abstract/document/4703209/,11863138712684915745,/scholar?cites=11863138712684915745,,,http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/publication/A%20MAP-Based%20Algorithm%20for%20Destriping%20and.pdf,0,0,0
1277463,Recovering missing pixels for Landsat ETM+ SLC-off imagery using multi-temporal regression analysis and a regularization method,2013,Chao Zeng and Huanfeng Shen and Liangpei Zhang,131,Remote Sensing of Environment,,182-194,Elsevier,Since the scan line corrector (SLC) of the Landsat Enhanced Thematic Mapper Plus (ETM +) sensor failed permanently in 2003. about 22% of the pixels in an SLC-off image are not scanned. To improve the usability of the ETM + SLC-off data. we propose an integrated method to recover the missing pixels. The majority of the degraded pixels are filled using multi-temporal images as referable information by building a regression model between the corresponding pixels. When the auxiliary multi-temporal data cannot completely recover the missing pixels. a non-reference regularization algorithm is used to implement the pixel filling. To assess the efficacy of the proposed method. simulated and actual SLC-off ETM + images were tested. The quantitative evaluations suggest that the proposed method can predict the missing values very accurately. The method performs especially well in edges. and is able to keep the …,True,ore_9NIAAAAJ:ZeXyd9-uunAC,200,https://www.sciencedirect.com/science/article/pii/S0034425712004786,13912268608031302077,/scholar?cites=13912268608031302077,,,http://sendimage.whu.edu.cn/wp-content/uploads/2015/08/342013_Recovering-missing-pixels-for-Landsat-ETM-SLC-off-imagery-using-multi-temporal.pdf,0,0,0
1277464,Missing information reconstruction of remote sensing data: A technical review,2015,Huanfeng Shen and Xinghua Li and Qing Cheng and Chao Zeng and Gang Yang and Huifang Li and Liangpei Zhang,3,,3,61-85,IEEE,Because of sensor malfunction and poor atmospheric conditions. there is usually a great deal of missing information in optical remote sensing data. which reduces the usage rate and hinders the follow-up interpretation. In the past decades. missing information reconstruction of remote sensing data has become an active research field. and a large number of algorithms have been developed. However. to the best of our knowledge. there has not. to date. been a study that has been aimed at expatiating and summarizing the current situation. This is therefore our motivation in this review. This paper provides an introduction to the principles and theories of missing information reconstruction of remote sensing data. We classify the established and emerging algorithms into four main categories. followed by a comprehensive comparison of them from both experimental and theoretical perspectives. This paper also predicts …,True,ore_9NIAAAAJ:ILKRHgRFtOwC,199,https://ieeexplore.ieee.org/abstract/document/7284768/,2301140444047735533,/scholar?cites=2301140444047735533,,,http://sendimage.whu.edu.cn/wp-content/uploads/2015/08/37g2015_Missing-Information-Reconstruction-of-Remote-Sensing-Data.pdf,0,0,0
1277465,Boosting the accuracy of multispectral image pansharpening by learning a deep residual network,2017,Yancong Wei and Qiangqiang Yuan and Huanfeng Shen and Liangpei Zhang,14,IEEE Geoscience and Remote Sensing Letters,10,1795-1799,IEEE,In the field of multispectral (MS) and panchromatic image fusion (pansharpening). the impressive effectiveness of deep neural networks has recently been employed to overcome the drawbacks of the traditional linear models and boost the fusion accuracy. However. the existing methods are mainly based on simple and flat networks with relatively shallow architectures. which severely limits their performance. In this letter. the concept of residual learning is introduced to form a very deep convolutional neural network to make the full use of the high nonlinearity of the deep learning models. Through both quantitative and visual assessments on a large number of high-quality MS images from various sources. it is confirmed that the proposed model is superior to all the mainstream algorithms included in the comparison. and achieves the highest spatial-spectral unified accuracy.,True,ore_9NIAAAAJ:4vMrXwiscB8C,190,https://ieeexplore.ieee.org/abstract/document/8012503/,14656506787473334522,/scholar?cites=14656506787473334522,,,https://arxiv.org/pdf/1705.07556,0,0,0
1277466,A robust skin color based face detection algorithm,2003,SK Singh and DS Chauhan and M Vatsa and R Singh,6,Tamkang Journal of Science and Engineering,4,227-234,,,True,-DAxp-cAAAAJ:u5HHmVD_uO8C,520,,1749752889764018419,/scholar?cites=1749752889764018419,,,,0,0,0
1277467,Improving iris recognition performance using segmentation. quality enhancement. match score fusion. and indexing,2008,Mayank Vatsa and Richa Singh and Afzel Noore,38,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",4,1021-1035,IEEE,This paper proposes algorithms for iris segmentation. quality enhancement. match score fusion. and indexing to improve both the accuracy and the speed of iris recognition. A curve evolution approach is proposed to effectively segment a nonideal iris image using the modified Mumford-Shah functional. Different enhancement algorithms are concurrently applied on the segmented iris image to produce multiple enhanced versions of the iris image. A support-vector-machine-based learning algorithm selects locally enhanced regions from each globally enhanced image and combines these good-quality regions to create a single high-quality iris image. Two distinct features are extracted from the high-quality iris image. The global textural feature is extracted using the 1-D log polar Gabor transform. and the local topological feature is extracted using Euler numbers. An intelligent fusion algorithm combines the textural …,True,-DAxp-cAAAAJ:u-x6o8ySG0sC,318,https://ieeexplore.ieee.org/abstract/document/4510759/,12618659214318666346,/scholar?cites=12618659214318666346,,,https://www.academia.edu/download/48051683/Iris-SMC.pdf,0,0,0
1277468,Computationally efficient face spoofing detection with motion magnification,2013,Samarth Bharadwaj and Tejas I Dhamecha and Mayank Vatsa and Richa Singh,,,,105-110,,For a robust face biometric system. a reliable antispoofing approach must be deployed to circumvent the print and replay attacks. Several techniques have been proposed to counter face spoofing. however a robust solution that is computationally efficient is still unavailable. This paper presents a new approach for spoofing detection in face videos using motion magnification. Eulerian motion magnification approach is used to enhance the facial expressions commonly exhibited by subjects in a captured video. Next. two types of feature extraction algorithms are proposed:(i) a configuration of LBP that provides improved performance compared to other computationally expensive texture based approaches and (ii) motion estimation approach using HOOF descriptor. On the Print Attack and Replay Attack spoofing datasets. the proposed framework improves the state-of-art performance; especially HOOF descriptor yielding a near perfect half total error rate of 0% and 1.25% respectively.,True,-DAxp-cAAAAJ:KxtntwgDAa4C,230,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W02/html/Bharadwaj_Computationally_Efficient_Face_2013_CVPR_paper.html,5741243058834848337,/scholar?cites=5741243058834848337,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2013/W02/papers/Bharadwaj_Computationally_Efficient_Face_2013_CVPR_paper.pdf,0,0,0
1277469,Plastic surgery: A new dimension to face recognition,2010,Richa Singh and Mayank Vatsa and Himanshu S Bhatt and Samarth Bharadwaj and Afzel Noore and Shahin S Nooreyezdan,5,IEEE Transactions on Information Forensics and Security,3,441-448,IEEE,Advancement and affordability is leading to the popularity of plastic surgery procedures. Facial plastic surgery can be reconstructive to correct facial feature anomalies or cosmetic to improve the appearance. Both corrective as well as cosmetic surgeries alter the original facial information to a large extent thereby posing a great challenge for face recognition algorithms. The contribution of this research is 1) preparing a face database of 900 individuals for plastic surgery. and 2) providing an analytical and experimental underpinning of the effect of plastic surgery on face recognition algorithms. The results on the plastic surgery database suggest that it is an arduous research challenge and the current state-of-art face recognition algorithms are unable to provide acceptable levels of identification performance. Therefore. it is imperative to initiate a research effort so that future face recognition systems will be able to …,True,-DAxp-cAAAAJ:roLk4NBRz8UC,195,https://ieeexplore.ieee.org/abstract/document/5492195/,5285765924325407195,/scholar?cites=5285765924325407195,,,http://www.iab-rubric.org/papers/TIFS10-FacePS.pdf,0,0,0
1277470,Periocular biometrics: When iris recognition fails,2010,Samarth Bharadwaj and Himanshu S Bhatt and Mayank Vatsa and Richa Singh,,,,1-6,IEEE,The performance of iris recognition is affected if iris is captured at a distance. Further. images captured in visible spectrum are more susceptible to noise than if captured in near infrared spectrum. This research proposes periocular biometrics as an alternative to iris recognition if the iris images are captured at a distance. We propose a novel algorithm to recognize periocular images in visible spectrum and study the effect of capture distance on the performance of periocular biometrics. The performance of the algorithm is evaluated on more than 11.000 images of the UBIRIS v2 database. The results show promise towards using periocular region for recognition when the information is not sufficient for iris recognition.,True,-DAxp-cAAAAJ:4TOpqqG69KYC,177,https://ieeexplore.ieee.org/abstract/document/5634498/,8663873263414013032,/scholar?cites=8663873263414013032,,,https://www.researchgate.net/profile/Himanshu_Bhatt12/publication/224194478_Periocular_biometrics_When_iris_recognition_fails/links/547009dc0cf216f8cfa9e8c0.pdf,0,0,0
1277471,Integrated multilevel image fusion and match score fusion of visible and infrared face images for robust face recognition,2008,Richa Singh and Mayank Vatsa and Afzel Noore,41,Pattern Recognition,3,880-893,Pergamon,This paper presents an integrated image fusion and match score fusion of multispectral face images. The fusion of visible and long wave infrared face images is performed using 2 ν-granular SVM which uses multiple SVMs to learn both the local and global properties of the multispectral face images at different granularity levels and resolution. The 2 ν-GSVM performs accurate classification which is subsequently used to dynamically compute the weights of visible and infrared images for generating a fused face image. 2D log polar Gabor transform and local binary pattern feature extraction algorithms are applied to the fused face image to extract global and local facial features. respectively. The corresponding match scores are fused using Dezert Smarandache theory of fusion which is based on plausible and paradoxical reasoning. The efficacy of the proposed algorithm is validated using the Notre Dame and …,True,-DAxp-cAAAAJ:9yKSN-GCB0IC,172,https://www.sciencedirect.com/science/article/pii/S0031320307003081,13572575013558260991,/scholar?cites=13572575013558260991,,,http://fs.unm.edu/IntegratedMultilevelImageFusion.pdf,0,0,0
1277472,Reducing the false rejection rate of iris recognition using textural and topological features. Int,2005,Mayank Vatsa and Richa Singh and Afzel Noore,,,,,,This paper presents a novel iris recognition system using 1D log polar Gabor wavelet and Euler numbers. 1D log polar Gabor wavelet is used to extract the textural features. and Euler numbers are used to extract topological features of the iris. The proposed decision strategy uses these features to authenticate an individual’s identity while maintaining a low false rejection rate. The algorithm was tested on CASIA iris image database and found to perform better than existing approaches with an overall accuracy of 99.93%. Keywords—Iris recognition. textural features. topological features. I.,True,-DAxp-cAAAAJ:2osOgNQ5qMEC,140,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.307.3788,17730964771359817806,/scholar?cites=17730964771359817806,,,,0,0,0
1277473,Feature based RDWT watermarking for multimodal biometric system,2009,Mayank Vatsa and Richa Singh and Afzel Noore,27,Image and Vision Computing,3,293-304,Elsevier,This paper presents a 3-level RDWT biometric watermarking algorithm to embed the voice biometric MFC coefficients in a color face image of the same individual for increased robustness. security and accuracy. Phase congruency model is used to compute the embedding locations which preserves the facial features from being watermarked and ensures that the face recognition accuracy is not compromised. The proposed watermarking algorithm uses adaptive user-specific watermarking parameters for improved performance. Using face. voice and multimodal recognition algorithms. and statistical evaluation. we show that the proposed RDWT watermarking algorithm is robust to different frequency and geometric attacks. and provides the multimodal biometric verification accuracy of 94%.,True,-DAxp-cAAAAJ:qjMakFHDy7sC,138,https://www.sciencedirect.com/science/article/pii/S0262885607000807,6998782850265785744,/scholar?cites=6998782850265785744,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.409.5019&rep=rep1&type=pdf,0,0,0
1277474,Memetically optimized MCWLD for matching sketches with digital face images,2012,Himanshu S Bhatt and Samarth Bharadwaj and Richa Singh and Mayank Vatsa,7,IEEE Transactions on Information Forensics and Security,5,1522-1535,IEEE,One of the important cues in solving crimes and apprehending criminals is matching sketches with digital face images. This paper presents an automated algorithm to extract discriminating information from local regions of both sketches and digital face images. Structural information along with minute details present in local facial regions are encoded using multiscale circular Weber's local descriptor. Further. an evolutionary memetic optimization algorithm is proposed to assign optimal weight to every local facial region to boost the identification performance. Since forensic sketches or digital face images can be of poor quality. a preprocessing technique is used to enhance the quality of images and improve the identification performance. Comprehensive experimental evaluation on different sketch databases show that the proposed algorithm yields better identification performance compared to existing face …,True,-DAxp-cAAAAJ:zA6iFVUQeVQC,133,https://ieeexplore.ieee.org/abstract/document/6215045/,7841593457242500237,/scholar?cites=7841593457242500237,,,https://repository.iiitd.edu.in/xmlui/bitstream/handle/123456789/27/IIITD-TR-2011-006.pdf?sequence=1,0,0,0
1277475,Face recognition with disguise and single gallery images,2009,Richa Singh and Mayank Vatsa and Afzel Noore,27,Image and Vision Computing,3,245-257,Elsevier,This paper presents a face recognition algorithm that addresses two major challenges. The first is when an individual intentionally alters the appearance and features using disguises. and the second is when limited gallery images are available for recognition. The algorithm uses a dynamic neural network architecture to extract the phase features of the face texture using 2D log polar Gabor transform. The phase features are divided into frames which are matched using the Hamming distance. The performance of the proposed algorithm is evaluated using three databases that comprise of real and synthetic face images with different disguise artifacts. The performance of the algorithm is evaluated for decreasing number of gallery images and various types of disguises. In all cases the proposed algorithm shows a better performance compared to other existing algorithms.,True,-DAxp-cAAAAJ:UeHWp8X0CEIC,130,https://www.sciencedirect.com/science/article/pii/S0262885607001060,2865194836386161290,/scholar?cites=2865194836386161290,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.9517&rep=rep1&type=pdf,0,0,0
1277476,Unraveling the effect of textured contact lenses on iris recognition,2014,Daksha Yadav and Naman Kohli and James S Doyle and Richa Singh and Mayank Vatsa and Kevin W Bowyer,9,IEEE Transactions on Information Forensics and Security,5,851-862,IEEE,The presence of a contact lens. particularly a textured cosmetic lens. poses a challenge to iris recognition as it obfuscates the natural iris patterns. The main contribution of this paper is to present an in-depth analysis of the effect of contact lenses on iris recognition. Two databases. namely. the IIIT-D Iris Contact Lens database and the ND-Contact Lens database. are prepared to analyze the variations caused due to contact lenses. We also present a novel lens detection algorithm that can be used to reduce the effect of contact lenses. The proposed approach outperforms other lens detection algorithms on the two databases and shows improved iris recognition performance.,True,-DAxp-cAAAAJ:Pqt4MY__2vwC,128,https://ieeexplore.ieee.org/abstract/document/6776569/,11107451510983494382,/scholar?cites=11107451510983494382,,,,0,0,0
1277477,Online palmprint identification,2003,David Zhang and Wai-Kin Kong and Jane You and Michael Wong,25,IEEE Transactions on pattern analysis and machine intelligence,9,1041-1050,IEEE,Biometrics-based personal identification is regarded as an effective method for automatically recognizing. with a high confidence. a person's identity. This paper presents a new biometric approach to online personal identification using palmprint technology. In contrast to the existing methods. our online palmprint identification system employs low-resolution palmprint images to achieve effective personal identification. The system consists of two parts: a novel device for online palmprint image acquisition and an efficient algorithm for fast palmprint recognition. A robust image coordinate system is defined to facilitate image alignment for feature extraction. In addition. a 2D Gabor phase encoding scheme is proposed for palmprint feature extraction and representation. The experimental results demonstrate the feasibility of the proposed system.,True,oo84BesAAAAJ:u5HHmVD_uO8C,1763,https://ieeexplore.ieee.org/abstract/document/1227981/,13807934975682764832,/scholar?cites=13807934975682764832,,,http://158.132.160.118/bitstream/10397/209/1/94.pdf,0,0,0
1277478,Retinopathy online challenge: automatic detection of microaneurysms in digital color fundus photographs,2009,Meindert Niemeijer and Bram Van Ginneken and Michael J Cree and Atsushi Mizutani and Gwénolé Quellec and Clara I Sánchez and Bob Zhang and Roberto Hornero and Mathieu Lamard and Chisako Muramatsu and Xiangqian Wu and Guy Cazuguel and Jane You and Agustín Mayo and Qin Li and Yuji Hatanaka and Béatrice Cochener and Christian Roux and Fakhri Karray and María García and Hiroshi Fujita and Michael D Abràmoff,29,IEEE transactions on medical imaging,1,185-195,IEEE,The detection of microaneurysms in digital color fundus photographs is a critical first step in automated screening for diabetic retinopathy (DR). a common complication of diabetes. To accomplish this detection numerous methods have been published in the past but none of these was compared with each other on the same data. In this work we present the results of the first international microaneurysm detection competition. organized in the context of the Retinopathy Online Challenge (ROC). a multiyear online competition for various aspects of DR detection. For this competition. we compare the results of five different methods. produced by five different teams of researchers on the same set of data. The evaluation was performed in a uniform manner using an algorithm presented in this work. The set of data used for the competition consisted of 50 training images with available reference standard and 50 test images …,True,oo84BesAAAAJ:9yKSN-GCB0IC,484,https://ieeexplore.ieee.org/abstract/document/5282586/,9532443460643942339,/scholar?cites=9532443460643942339,,,https://hal.archives-ouvertes.fr/hal-00473901/file/TMI-2009-0430_author.pdf,0,0,0
1277479,Hierarchical palmprint identification via multiple feature extraction,2002,Jane You and Wenxin Li and David Zhang,35,Pattern recognition,4,847-859,Pergamon,Biometric computing offers an effective approach to identify personal identity by using individual's unique. reliable and stable physical or behavioral characteristics. This paper describes a new method to authenticate individuals based on palmprint identification and verification. Firstly. a comparative study of palmprint feature extraction is presented. The concepts of texture feature and interesting points are introduced to define palmprint features. A texture-based dynamic selection scheme is proposed to facilitate the fast search for the best matching of the sample in the database in a hierarchical fashion. The global texture energy. which is characterized with high convergence of inner-palm similarities and good dispersion of inter-palm discrimination. is used to guide the dynamic selection of a small set of similar candidates from the database at coarse level for further processing. An interesting point based image …,True,oo84BesAAAAJ:u-x6o8ySG0sC,353,https://www.sciencedirect.com/science/article/pii/S0031320301001005,17044197962831885238,/scholar?cites=17044197962831885238,,,http://ai.pku.edu.cn/application/files/1315/1124/1831/Hierarchical_palmprint_identification_via_multiple_feature_extraction.pdf,0,0,0
1277480,An analysis of biohashing and its variants,2006,Adams Kong and King-Hong Cheung and David Zhang and Mohamed Kamel and Jane You,39,,7,1359-1368,Pergamon,As a result of the growing demand for accurate and reliable personal authentication. biometric recognition. a substitute for or complement to existing authentication technologies. has attracted considerable attention. It has recently been reported that. along with its variants. BioHashing. a new technique that combines biometric features and a tokenized (pseudo-) random number (TRN). has achieved perfect accuracy. having zero equal error rates (EER) for faces. fingerprints and palmprints. There are. however. anomalies in this approach. These are identified in this paper. in which we systematically analyze the details of the approach and conclude that the claim of having achieved a zero EER is based upon an impractical hidden assumption. We simulate the claimants’ experiments and find that it is not possible to achieve their reported performance without the hidden assumption and that. indeed. the results are …,True,oo84BesAAAAJ:d1gkVwhDpl0C,306,https://www.sciencedirect.com/science/article/pii/S0031320305004280,1157988354642372361,/scholar?cites=1157988354642372361,,,,0,0,0
1277481,Detection of microaneurysms using multi-scale correlation coefficients,2010,Bob Zhang and Xiangqian Wu and Jane You and Qin Li and Fakhri Karray,43,Pattern Recognition,6,2237-2248,Pergamon,This paper presents a new approach to the computer aided diagnosis (CAD) of diabetic retinopathy (DR)—a common and severe complication of long-term diabetes which damages the retina and cause blindness. Since microaneurysms are regarded as the first signs of DR. there has been extensive research on effective detection and localization of these abnormalities in retinal images. In contrast to existing algorithms. a new approach based on multi-scale correlation filtering (MSCF) and dynamic thresholding is developed. This consists of two levels. microaneurysm candidate detection (coarse level) and true microaneurysm classification (fine level). The approach was evaluated based on two public datasets—ROC (retinopathy on-line challenge. http://roc.healthcare.uiowa.edu) and DIARETDB1 (standard diabetic retinopathy database. http://www.it.lut.fi/project/imageret/diaretdb1). We conclude our method to be …,True,oo84BesAAAAJ:zYLM7Y9cAGgC,251,https://www.sciencedirect.com/science/article/pii/S003132031000004X,13458060533875347008,/scholar?cites=13458060533875347008,,,,0,0,0
1277482,On hierarchical palmprint coding with multiple features for personal identification in large databases,2004,Jane You and Wai-Kin Kong and David Zhang and King Hong Cheung,14,IEEE Transactions on Circuits and Systems for Video Technology,2,234-243,IEEE,"Automatic personal identification is a significant component of security systems with many challenges and practical applications. The advances in biometric technology have led to the very rapid growth in identity authentication. This paper presents a new approach to personal identification using palmprints. To tackle the key issues such as feature extraction. representation. indexing. similarity measurement. and fast search for the best match. we propose a hierarchical multifeature coding scheme to facilitate coarse-to-fine matching for efficient and effective palmprint verification and identification in a large database. In our approach. four-level features are defined: global geometry-based key point distance (Level-1 feature). global texture energy (Level-2 feature). fuzzy ""interest"" line (Level-3 feature). and local directional texture energy (Level-4 feature). In contrast to the existing systems that employ a fixed mechanism …",True,oo84BesAAAAJ:2osOgNQ5qMEC,162,https://ieeexplore.ieee.org/abstract/document/1269756/,7162910479592162517,/scholar?cites=7162910479592162517,,,https://core.ac.uk/download/pdf/61004186.pdf,0,0,0
1277483,Palm vein extraction and matching for personal authentication,2007,Yi-Bo Zhang and Qin Li and Jane You and Prabir Bhattacharya,,,,154-164,Springer. Berlin. Heidelberg,In this paper. we propose a scheme of personal authentication using palm vein. The infrared palm images which contain the palm vein information are used for our system. Because the vein information represents the liveness of a human. this system can provide personal authentication and liveness detection concurrently. The proposed system include: 1) Infrared palm images capture; 2) Detection of Region of Interest; 3) Palm vein extraction by multiscale filtering; 4) Matching. The experimental results demonstrate that the recognition rate using palm vein is good.,True,oo84BesAAAAJ:IjCSPb-OGe4C,143,https://link.springer.com/chapter/10.1007/978-3-540-76414-4_16,12074014626008854146,/scholar?cites=12074014626008854146,,,https://www.researchgate.net/profile/Prabir_Bhattacharya/publication/221146566_Palm_Vein_Extraction_and_Matching_for_Personal_Authentication/links/09e4150b0f4ae3ef85000000.pdf,0,0,0
1277484,Data uncertainty in face recognition,2014,Yong Xu and Xiaozhao Fang and Xuelong Li and Jiang Yang and Jane You and Hong Liu and Shaohua Teng,44,IEEE transactions on cybernetics,10,1950-1961,IEEE,The image of a face varies with the illumination. pose. and facial expression. thus we say that a single face image is of high uncertainty for representing the face. In this sense. a face image is just an observation and it should not be considered as the absolutely accurate representation of the face. As more face images from the same person provide more observations of the face. more face images may be useful for reducing the uncertainty of the representation of the face and improving the accuracy of face recognition. However. in a real world face recognition system. a subject usually has only a limited number of available face images and thus there is high uncertainty. In this paper. we attempt to improve the face recognition accuracy by reducing the uncertainty. First. we reduce the uncertainty of the face representation by synthesizing the virtual training samples. Then. we select useful training samples that are …,True,oo84BesAAAAJ:R3hNpaxXUhUC,142,https://ieeexplore.ieee.org/abstract/document/6729058/,8948606263732708301,/scholar?cites=8948606263732708301,,,,0,0,0
1277485,A New Discriminative Sparse Representation Method for Robust Face Recognition via  Regularization,2016,Yong Xu and Zuofeng Zhong and Jian Yang and Jane You and David Zhang,28,IEEE transactions on neural networks and learning systems,10,2233-2242,IEEE,Sparse representation has shown an attractive performance in a number of applications. However. the available sparse representation methods still suffer from some problems. and it is necessary to design more efficient methods. Particularly. to design a computationally inexpensive. easily solvable. and robust sparse representation method is a significant task. In this paper. we explore the issue of designing the simple. robust. and powerfully efficient sparse representation methods for image classification. The contributions of this paper are as follows. First. a novel discriminative sparse representation method is proposed and its noticeable performance in image classification is demonstrated by the experimental results. More importantly. the proposed method outperforms the existing state-of-the-art sparse representation methods. Second. the proposed method is not only very computationally efficient but also has an …,True,oo84BesAAAAJ:e_rmSamDkqQC,133,https://ieeexplore.ieee.org/abstract/document/7499803/,15846317792211860224,/scholar?cites=15846317792211860224,,,http://www.yongxu.org/paper/A%20New%20Discriminative%20Sparse%20Representation%20Method%20for%20Robust%20Face%20Recognition%20via%20L2%20Regularization.pdf,0,0,0
1277486,Classification and segmentation of rotated and scaled textured images using texture “tuned” masks,1993,Jane You and Harvey A Cohen,26,Pattern Recognition,2,245-258,Pergamon,A rotation and scale invariant texture classifier function is described for effective classification and segmentation of images involving textures of unknown rotation and scale changes. The classifier used is the texture energy associated with a mask that has been “tuned” to be both discriminant between different textures. and to be invariant to rotation and scale changes. The mask tuning scheme utilized is based on task-oriented criterion optimization via a guided random search procedure to incorporate the changes. Both a dynamic texture sample set using a two-dimensional (2D) linked list and a re-ranking procedure are applied for training. Maximum feature dispersion of inter texture classes and high feature convergence of inner texture class samples associated with other statistical measures are suggested as key criteria in training. In a study based on 15 distinct Brodatz textures it is found that: the tuning process …,True,oo84BesAAAAJ:qjMakFHDy7sC,130,https://www.sciencedirect.com/science/article/pii/003132039390033S,16381235605285539685,/scholar?cites=16381235605285539685,,,,0,0,0
1277487,Incremental semi-supervised clustering ensemble for high dimensional data clustering,2015,Zhiwen Yu and Peinan Luo and Jane You and Hau-San Wong and Hareton Leung and Si Wu and Jun Zhang and Guoqiang Han,28,IEEE Transactions on Knowledge and Data Engineering,3,701-714,IEEE,Traditional cluster ensemble approaches have three limitations: (1) They do not make use of prior knowledge of the datasets given by experts. (2) Most of the conventional cluster ensemble methods cannot obtain satisfactory results when handling high dimensional data. (3) All the ensemble members are considered. even the ones without positive contributions. In order to address the limitations of conventional cluster ensemble approaches. we first propose an incremental semi-supervised clustering ensemble framework (ISSCE) which makes use of the advantage of the random subspace technique. the constraint propagation approach. the proposed incremental ensemble member selection process. and the normalized cut algorithm to perform high dimensional data clustering. The random subspace technique is effective for handling high dimensional data. while the constraint propagation approach is useful for …,True,oo84BesAAAAJ:ILKRHgRFtOwC,126,https://ieeexplore.ieee.org/abstract/document/7323847/,16745557323772226573,/scholar?cites=16745557323772226573,,,,0,0,0
1277488,RMPE: Regional multi-person pose estimation,2017,Haoshu Fang and Shuqin Xie and Yu-Wing Tai and Cewu Lu,,,,,,Multi-person pose estimation in the wild is challenging. Although state-of-the-art human detectors have demonstrated good performance. small errors in localization and recognition are inevitable. These errors can cause failures for a single-person pose estimator (SPPE). especially for methods that solely depend on human detection results. In this paper. we propose a novel regional multi-person pose estimation (RMPE) framework to facilitate pose estimation in the presence of inaccurate human bounding boxes. Our framework consists of three components: Symmetric Spatial Transformer Network (SSTN). Parametric Pose Non-Maximum-Suppression (NMS). and Pose-Guided Proposals Generator (PGPG). Our method is able to handle inaccurate bounding boxes and redundant detections. allowing it to achieve 76.7 mAP on the MPII (multi person) dataset. Our model and source codes are made publicly available.,True,nFhLmFkAAAAJ:08ZZubdj9fEC,607,http://openaccess.thecvf.com/content_iccv_2017/html/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.html,1149163492102972816,/scholar?cites=1149163492102972816,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Fang_RMPE_Regional_Multi-Person_ICCV_2017_paper.pdf,0,0,0
1277489,High quality depth map upsampling for 3d-tof cameras,2011,Jaesik Park and Hyeongwoo Kim and Yu-Wing Tai and Michael S Brown and Inso Kweon,,,,1623-1630,IEEE,This paper describes an application framework to perform high quality upsampling on depth maps captured from a low-resolution and noisy 3D time-of-flight (3D-ToF) camera that has been coupled with a high-resolution RGB camera. Our framework is inspired by recent work that uses nonlocal means filtering to regularize depth maps in order to maintain fine detail and structure. Our framework extends this regularization with an additional edge weighting scheme based on several image features based on the additional high-resolution RGB input. Quantitative and qualitative results show that our method outperforms existing approaches for 3D-ToF upsampling. We describe the complete process for this system. including device calibration. scene warping for input alignment. and even how the results can be further processed using simple user markup.,True,nFhLmFkAAAAJ:_FxGoFyzp5QC,520,https://ieeexplore.ieee.org/abstract/document/6126423/,8455092905456974970,/scholar?cites=8455092905456974970,,,https://www.researchgate.net/profile/Jaesik_Park2/publication/221110931_High_Quality_Depth_Map_Upsampling_for_3D-TOF_Cameras/links/5698125e08ae1c4279053e64.pdf,0,0,0
1277490,Network trimming: A data-driven neuron pruning approach towards efficient deep architectures,2016,Hengyuan Hu and Rui Peng and Yu-Wing Tai and Chi-Keung Tang,,arXiv preprint arXiv:1607.03250,,,,State-of-the-art neural networks are getting deeper and wider. While their performance increases with the increasing number of layers and neurons. it is crucial to design an efficient deep architecture in order to reduce computational and memory costs. Designing an efficient neural network. however. is labor intensive requiring many experiments. and fine-tunings. In this paper. we introduce network trimming which iteratively optimizes the network by pruning unimportant neurons based on analysis of their outputs on a large dataset. Our algorithm is inspired by an observation that the outputs of a significant portion of neurons in a large network are mostly zero. regardless of what inputs the network received. These zero activation neurons are redundant. and can be removed without affecting the overall accuracy of the network. After pruning the zero activation neurons. we retrain the network using the weights before pruning as initialization. We alternate the pruning and retraining to further reduce zero activations in a network. Our experiments on the LeNet and VGG-16 show that we can achieve high compression ratio of parameters without losing or even achieving higher accuracy than the original network.,True,nFhLmFkAAAAJ:D03iK_w7-QYC,429,https://arxiv.org/abs/1607.03250,6940912612242167520,/scholar?cites=6940912612242167520,,,https://arxiv.org/pdf/1607.03250,0,0,0
1277491,Local color transfer via probabilistic segmentation by expectation-maximization,2005,Yu-Wing Tai and Jiaya Jia and Chi-Keung Tang,1,,,747-754,IEEE,We address the problem of regional color transfer between two natural images by probabilistic segmentation. We use a new expectation-maximization (EM) scheme to impose both spatial and color smoothness to infer natural connectivity among pixels. Unlike previous work. our method takes local color information into consideration. and segment image with soft region boundaries for seamless color transfer and compositing. Our modified EM method has two advantages in color manipulation: first. subject to different levels of color smoothness in image space. our algorithm produces an optimal number of regions upon convergence. where the color statistics in each region can be adequately characterized by a component of a Gaussian mixture model (GMM). Second. we allow a pixel to fall in several regions according to our estimated probability distribution in the EM step. resulting in a transparency-like ratio for …,True,nFhLmFkAAAAJ:u5HHmVD_uO8C,389,https://ieeexplore.ieee.org/abstract/document/1467343/,6657731397320035776,/scholar?cites=6657731397320035776,,,https://repository.ust.hk/ir/bitstream/1783.1-2711/1/cvpr05_postrefereed.pdf,0,0,0
1277492,Accurate depth map estimation from a lenslet light field camera,2015,Hae-Gon Jeon and Jaesik Park and Gyeongmin Choe and Jinsun Park and Yunsu Bok and Yu-Wing Tai and In So Kweon,,,,1547-1555,,This paper introduces an algorithm that accurately estimates depth maps using a lenslet light field camera. The proposed algorithm estimates the multi-view stereo correspondences with sub-pixel accuracy using the cost volume. The foundation for constructing accurate costs is threefold. First. the sub-aperture images are displaced using the phase shift theorem. Second. the gradient costs are adaptively aggregated using the angular coordinates of the light field. Third. the feature correspondences between the sub-aperture images are used as additional constraints. With the cost volume. the multi-label optimization propagates and corrects the depth map in the weak texture regions. Finally. the local depth map is iteratively refined through fitting the local quadratic function to estimate a non-discrete depth map. Because micro-lens images contain unexpected distortions. a method is also proposed that corrects this error. The effectiveness of the proposed algorithm is demonstrated through challenging real world examples and including comparisons with the performance of advanced depth estimation algorithms.,True,nFhLmFkAAAAJ:vV6vV6tmYwMC,382,http://openaccess.thecvf.com/content_cvpr_2015/html/Jeon_Accurate_Depth_Map_2015_CVPR_paper.html,1959944997786925128,/scholar?cites=1959944997786925128,,,https://openaccess.thecvf.com/content_cvpr_2015/papers/Jeon_Accurate_Depth_Map_2015_CVPR_paper.pdf,0,0,0
1277493,Deep saliency with encoded low level distance map and high level features,2016,Gayoung Lee and Yu-Wing Tai and Junmo Kim,,,,660-668,,Recent advances in saliency detection have utilized deep learning to obtain high level features to detect salient regions in a scene. They have demonstrated superior results over previous works that utilize hand-crafted low level features for saliency detection. In this paper. we demonstrate that the hand-crafted features can provide complementary effects to enhance performance of saliency detection that utilizes only high level features. Our method utilizes both high level and low level features for saliency detection under a unified deep learning framework. The high level features are extracted using the VGG-net. and the low level features are compared with other parts of an image to form a low level distance map. The low level distance map is then encoded using a CNN with multiple 1* 1 convolutional and ReLU layers. We concatenate the encoded low level distance map and the high level features. and connect them to a fully connected neural network classifier to evaluate the saliency of a query region. Our experiments show that our method can further improve performance of the state-of-the-art deep learning based saliency detection methods.,True,nFhLmFkAAAAJ:cFHS6HbyZ2cC,376,http://openaccess.thecvf.com/content_cvpr_2016/html/Lee_Deep_Saliency_With_CVPR_2016_paper.html,572273089181625491,/scholar?cites=572273089181625491,,,https://openaccess.thecvf.com/content_cvpr_2016/papers/Lee_Deep_Saliency_With_CVPR_2016_paper.pdf,0,0,0
1277494,Super resolution using edge prior and single image detail synthesis,2010,Yu-Wing Tai and Shuaicheng Liu and Michael S Brown and Stephen Lin,,,,2400-2407,IEEE,Edge-directed image super resolution (SR) focuses on ways to remove edge artifacts in upsampled images. Under large magnification. however. textured regions become blurred and appear homogenous. resulting in a super-resolution image that looks unnatural. Alternatively. learning-based SR approaches use a large database of exemplar images for “hallucinating” detail. The quality of the upsampled image. especially about edges. is dependent on the suitability of the training images. This paper aims to combine the benefits of edge-directed SR with those of learning-based SR. In particular. we propose an approach to extend edge-directed super-resolution to include detail from an image/texture example provided by the user (e.g.. from the Internet). A significant benefit of our approach is that only a single exemplar image is required to supply the missing detail - strong edges are obtained in the SR image even if …,True,nFhLmFkAAAAJ:W7OEmFMy1HYC,331,https://ieeexplore.ieee.org/abstract/document/5539933/,4630902319735797357,/scholar?cites=4630902319735797357,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.5872&rep=rep1&type=pdf,0,0,0
1277495,Richardson-lucy deblurring for scenes under a projective motion path,2010,Yu-Wing Tai and Ping Tan and Michael S Brown,33,IEEE Transactions on Pattern Analysis and Machine Intelligence,8,1603-1618,IEEE,This paper addresses how to model and correct image blur that arises when a camera undergoes ego motion while observing a distant scene. In particular. we discuss how the blurred image can be modeled as an integration of the clear scene under a sequence of planar projective transformations (i.e.. homographies) that describe the camera's path. This projective motion path blur model is more effective at modeling the spatially varying motion blur exhibited by ego motion than conventional methods based on space-invariant blur kernels. To correct the blurred image. we describe how to modify the Richardson-Lucy (RL) algorithm to incorporate this new blur model. In addition. we show that our projective motion RL algorithm can incorporate state-of-the-art regularization priors to improve the deblurred results. The projective motion path blur model. along with the modified RL algorithm. is detailed. together with …,True,nFhLmFkAAAAJ:zYLM7Y9cAGgC,329,https://ieeexplore.ieee.org/abstract/document/5674049/,767741698256595891,/scholar?cites=767741698256595891,,,,0,0,0
1277496,Salient Region Detection via High-Dimensional Color Transform,2014,Jiwhan Kim and Dongyoon Han and Yu-Wing Tai and Junmo Kim,,,,,,In this paper. we introduce a novel technique to automatically detect salient regions of an image via high-dimensional color transform. Our main idea is to represent a saliency map of an image as a linear combination of high-dimensional color space where salient regions and backgrounds can be distinctively separated. This is based on an observation that salient regions often have distinctive colors compared to the background in human perception. but human perception is often complicated and highly nonlinear. By mapping a low dimensional RGB color to a feature vector in a high-dimensional color space. we show that we can linearly separate the salient regions from the background by finding an optimal linear combination of color coefficients in the high-dimensional color space. Our high dimensional color space incorporates multiple color representations including RGB. CIELab. HSV and with gamma corrections to enrich its representative power. Our experimental results on three benchmark datasets show that our technique is effective. and it is computationally efficient in comparison to previous state-of-the-art techniques.,True,nFhLmFkAAAAJ:4JMBOYKVnBMC,301,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Kim_Salient_Region_Detection_2014_CVPR_paper.html,11681996891024962189,/scholar?cites=11681996891024962189,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kim_Salient_Region_Detection_2014_CVPR_paper.pdf,0,0,0
1277497,High-resolution hyperspectral imaging via matrix factorization,2011,Rei Kawakami and John Wright and Yu-Wing Tai and Yasuyuki Matsushita and Moshe Ben-Ezra and Katsushi Ikeuchi,,,,2329-2336,IEEE,Hyperspectral imaging is a promising tool for applications in geosensing. cultural heritage and beyond. However. compared to current RGB cameras. existing hyperspectral cameras are severely limited in spatial resolution. In this paper. we introduce a simple new technique for reconstructing a very high-resolution hyperspectral image from two readily obtained measurements: A lower-resolution hyper-spectral image and a high-resolution RGB image. Our approach is divided into two stages: We first apply an unmixing algorithm to the hyperspectral input. to estimate a basis representing reflectance spectra. We then use this representation in conjunction with the RGB input to produce the desired result. Our approach to unmixing is motivated by the spatial sparsity of the hyperspectral input. and casts the unmixing problem as the search for a factorization of the input into a basis and a set of maximally sparse …,True,nFhLmFkAAAAJ:WF5omc3nYNoC,229,https://ieeexplore.ieee.org/abstract/document/5995457/,3895240933160591927,/scholar?cites=3895240933160591927,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.430&rep=rep1&type=pdf,0,0,0
1277498,Accurate single stage detector using recurrent rolling convolution,2017,Jimmy Ren and Xiaohao Chen and Jianbo Liu and Wenxiu Sun and Jiahao Pang and Qiong Yan and Yu-Wing Tai and Li Xu,,,,5420-5428,,"Most of the recent successful methods in accurate object detection and localization used some variants of R-CNN style two stage Convolutional Neural Networks (CNN) where plausible regions were proposed in the first stage then followed by a second stage for decision refinement. Despite the simplicity of training and the efficiency in deployment. the single stage detection methods have not been as competitive when evaluated in benchmarks consider mAP for high IoU thresholds. In this paper. we proposed a novel single stage end-to-end trainable object detection network to overcome this limitation. We achieved this by introducing Recurrent Rolling Convolution (RRC) architecture over multi-scale feature maps to construct object classifiers and bounding box regressors which are"" deep in context"". We evaluated our method in the challenging KITTI dataset which measures methods under IoU threshold of 0.7. We showed that with RRC. a single reduced VGG-16 based model already significantly outperformed all the previously published results. At the time this paper was written our models ranked the first in KITTI car detection (the hard level). the first in cyclist detection and the second in pedestrian detection. These results were not reached by the previous single stage methods. The code is publicly available.",True,nFhLmFkAAAAJ:nb7KW1ujOQ8C,223,http://openaccess.thecvf.com/content_cvpr_2017/html/Ren_Accurate_Single_Stage_CVPR_2017_paper.html,5780311761574416093,/scholar?cites=5780311761574416093,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Ren_Accurate_Single_Stage_CVPR_2017_paper.pdf,0,0,0
1277499,TID2008-a database for evaluation of full-reference visual quality assessment metrics,2009,Nikolay Ponomarenko and Vladimir Lukin and Alexander Zelensky and Karen Egiazarian and Marco Carli and Federica Battisti,10,Advances of Modern Radioelectronics,4,30-45,,TID2008. for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images. 17 types of distortions for each reference image. 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests. observers from three countries (Finland. Italy. and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database. we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.,True,XI9iavwAAAAJ:u5HHmVD_uO8C,1204,http://k504.khai.edu/attachments/article/89/mre2009tid.pdf,10197442694825674852,/scholar?cites=10197442694825674852,,,http://k504.khai.edu/attachments/article/89/mre2009tid.pdf,0,0,0
1277500,Image database TID2013: Peculiarities. results and perspectives,2015,Nikolay Ponomarenko and Lina Jin and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Jaakko Astola and Benoit Vozel and Kacem Chehdi and Marco Carli and Federica Battisti and C-C Jay Kuo,30,Signal processing: Image communication,,57-77,Elsevier,This paper describes a recently created image database. TID2013. intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008. the new database contains a larger number (3000) of test images obtained from 25 reference images. 24 types of distortions for each reference image. and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland. France. Italy. Ukraine. and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore. existing visual quality metrics have been tested with the proposed …,True,XI9iavwAAAAJ:jL-93Qbq4QoC,689,https://www.sciencedirect.com/science/article/pii/S0923596514001490,5014264754084340197,/scholar?cites=5014264754084340197,,,https://www.sciencedirect.com/science/article/pii/S0923596514001490,0,0,0
1277501,On between-coefficient contrast masking of DCT basis functions,2007,Nikolay Ponomarenko and Flavia Silvestri and Karen Egiazarian and Marco Carli and Jaakko Astola and Vladimir Lukin,4,Proceedings of the third international workshop on video processing and quality metrics,,,,In this paper we propose a simple and effective model of visual between-coefficient contrast masking of DCT basis functions based on a human visual system (HVS). The model operates with the values of DCT coefficients of 8x8 pixel block of an image. For each DCT coefficient of the block the model allows to calculate its maximal distortion that is not visible due to the between-coefficient masking. A modification of the PSNR is also described in this paper. The proposed metric. PSNR-HVS-M. takes into account the proposed model and the contrast sensitivity function (CSF). For efficiency analysis of the proposed model. a set of 18 test images with different effects of noise masking has been used. During experiments. 155 observers have sorted this set of test images in the order of their visual appearance comparing them to undistorted original. The new metric. PSNRHVS-M has outperformed other well-known reference based quality metrics and demonstrated high correlation with the results of subjective experiments (Spearman correlation is 0.984. Kendall correlation is 0.948).,True,XI9iavwAAAAJ:u-x6o8ySG0sC,454,http://ponomarenko.info/vpqm07_p.pdf,12374871955639270101,/scholar?cites=12374871955639270101,,,http://ponomarenko.info/vpqm07_p.pdf,0,0,0
1277502,Color image database TID2013: Peculiarities and preliminary results,2013,Nikolay Ponomarenko and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Lina Jin and Jaakko Astola and Benoit Vozel and Kacem Chehdi and Marco Carli and Federica Battisti and C-C Jay Kuo,,,,106-111,IEEE,Visual quality of color images is an important aspect in various applications of digital image processing and multimedia. A large number of visual quality metrics (indices) has been proposed recently. In order to assess their reliability. several databases of color images with various sets of distortions have been exploited. Here we present a new database called TID2013 that contains a larger number of images. Compared to its predecessor TID2008. seven new types and one more level of distortions are included. The need for considering these new types of distortions is briefly described. Besides. preliminary results of experiments with a large number of volunteers for determining the mean opinion score (MOS) are presented. Spearman and Kendall rank order correlation factors between MOS and a set of popular metrics are calculated and presented. Their analysis shows that adequateness of the existing metrics is …,True,XI9iavwAAAAJ:R3hNpaxXUhUC,403,https://ieeexplore.ieee.org/abstract/document/6623960/,17384081905530121099,/scholar?cites=17384081905530121099,,,https://www.researchgate.net/profile/Marco_Carli/publication/261094981_Color_image_database_TID2013_Peculiarities_and_preliminary_results/links/0deec536c86764dad6000000/Color-image-database-TID2013-Peculiarities-and-preliminary-results.pdf,0,0,0
1277503,New full-reference quality metrics based on HVS,2006,Karen Egiazarian and Jaakko Astola and Nikolay Ponomarenko and Vladimir Lukin and Federica Battisti and Marco Carli,4,Proceedings of the Second International Workshop on Video Processing and Quality Metrics,,,,In this paper. two new full-reference metrics for image quality assessment are presented. They are based on the Peak-Signal-to-Noise Ratio (PSNR) and Universal Quality Index (UQI) modified to take into account the Human Visual System (HVS) properties. Many studies confirm that the HVS is more sensitive to low frequency distortions rather than to high frequency ones. It is also very sensitive to contrast changes and noise. To test the effectiveness of the proposed metrics. we have performed a subjective experiment. In our experiment we have used seven types of distortions with three distortion levels in each. Three independent groups of observers from Finland. Ukraine and Italy. have been participating in image quality evaluation test. The analysis of the results shows that the proposed PSNR-HVS provides better correlation to Mean Observer Score (MOS) than PSNR. and that the proposed UQI-HVS metric …,True,XI9iavwAAAAJ:d1gkVwhDpl0C,347,https://www.researchgate.net/profile/Vladimir_Lukin2/publication/251229783_A_NEW_FULL-REFERENCE_QUALITY_METRICS_BASED_ON_HVS/links/0046351f669a9c1869000000.pdf,254551988233235440,/scholar?cites=254551988233235440,,,https://www.researchgate.net/profile/Vladimir_Lukin2/publication/251229783_A_NEW_FULL-REFERENCE_QUALITY_METRICS_BASED_ON_HVS/links/0046351f669a9c1869000000.pdf,0,0,0
1277504,Color image database for evaluation of image quality metrics,2008,N Ponomarenko and V Lukin and K Egiazarian and Jaakko Astola and Marco Carli and Federica Battisti,,,,403-408,IEEE,In this contribution. a new image database for testing full-reference image quality assessment metrics is presented. It is based on 1700 test images (25 reference images. 17 types of distortions for each reference image. 4 levels for each type of distortion). Using this image database. 654 observers from three different countries (Finland. Italy. and Ukraine) have carried out about 400000 individual human quality judgments (more than 200 judgments for each distorted image). The obtained mean opinion scores for the considered images can be used for evaluating the performances of visual quality metrics as well as for comparison and for the design of new metrics. The database. with testing results. is freely available.,True,XI9iavwAAAAJ:CB2v5VPnA5kC,210,https://ieeexplore.ieee.org/abstract/document/4665112/,5134212323661291120,/scholar?cites=5134212323661291120,,,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/Color%20Image%20Database%20for%20Evaluation%20of%20Image%20Quality%20Metrics.pdf,0,0,0
1277505,Metrics performance comparison for color image database,2009,Nikolay Ponomarenko and Federica Battisti and Karen Egiazarian and Jaakko Astola and Vladimir Lukin,27,Fourth international workshop on video processing and quality metrics for consumer electronics,,1-6,,In this paper. we exploit a new database of distorted test images TID2008 for verification of full-reference metrics of image visual quality. A comparative analysis of TID20008 and its nearest analog LIVE Database is presented. For a wide variety of known metrics. their correspondence to human visual system is evaluated. The values of rank correlations of Spearman and Kendall with the considered metrics and Mean Opinion Score (MOS) obtained by exploiting TID2008 in experiments are presented. The metrics are verified for both full set of distorted test images in TID2008 (1700 distorted images. 17 types of distortions) and for particular subsets of TID2008 that include distortions most important for digital image processing applications.,True,XI9iavwAAAAJ:9yKSN-GCB0IC,147,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/METRICS%20PERFORMANCE%20COMPARISON%20FOR%20COLOR%20IMAGE%20DATABASE.pdf,6139492325250458546,/scholar?cites=6139492325250458546,,,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/METRICS%20PERFORMANCE%20COMPARISON%20FOR%20COLOR%20IMAGE%20DATABASE.pdf,0,0,0
1277506,DCT based high quality image compression,2005,Nikolay Ponomarenko and Vladimir Lukin and Karen Egiazarian and Jaakko Astola,,,,1177-1185,Springer. Berlin. Heidelberg,DCT based image compression using blocks of size 32x32 is considered. An effective method of bit-plane coding of quantized DCT coefficients is proposed. Parameters of post-filtering for removing of blocking artifacts in decoded images are given. The efficiency of the proposed method for test images compression is analyzed. It is shown that the proposed method is able to provide the quality of decoding images higher than for JPEG2000 by up to 1.9 dB.,True,XI9iavwAAAAJ:2osOgNQ5qMEC,127,https://link.springer.com/chapter/10.1007/11499145_119,16868295085921118402,/scholar?cites=16868295085921118402,,,https://link.springer.com/content/pdf/10.1007/11499145_119.pdf,0,0,0
1277507,Modified image visual quality metrics for contrast change and mean shift accounting,2011,Nikolay Ponomarenko and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Marco Carli,,,,305-311,IEEE,Graphical information as color images is widely used in CAD and telecommunication systems. Several factors can contribute to impair the quality of an image. This paper deals with image visual quality assessment using objective metrics. Experimental results show that the two modified quality metrics outperform existing ones for a wide set of possible distortions.,True,XI9iavwAAAAJ:hFOr9nPyWt4C,107,https://ieeexplore.ieee.org/abstract/document/5744476/,17984532548489114357,/scholar?cites=17984532548489114357,,,https://ponomarenko.info/papers/psnrhma.pdf,0,0,0
1277508,Local signal-dependent noise variance estimation from hyperspectral textural images,2011,Mikhail L Uss and Benoit Vozel and Vladimir V Lukin and Kacem Chehdi,5,IEEE Journal of Selected Topics in Signal Processing,3,469-486,IEEE,A maximum-likelihood method for estimating hyperspectral sensors random noise components. both dependent and independent from the signal. is proposed. A hyperspectral image is locally jointly processed in the spatial and spectral dimensions within a multicomponent scanning window (MSW). as small as 7 × 7 × 7 spatial-spectral pixels. Each MSW is regarded as an additive mixture of spectrally correlated fractal Brownian motion (fBm)-samples and random noise. The main advantage of the proposed method is its ability to accurately estimate band noise variances locally by using spatial and spectral texture correlations from a single textural MSW. For each spectral band. both additive and signal-dependent band noise components are estimated by linear fit of local noise variances obtained from many MSWs distributed over the whole band intensity range. CRLB-based analysis of the estimator performance …,True,XI9iavwAAAAJ:UeHWp8X0CEIC,107,https://ieeexplore.ieee.org/abstract/document/5716656/,11925065309762645032,/scholar?cites=11925065309762645032,,,,0,0,0
1277509,Locally adaptive DCT filtering for signal-dependent noise removal,2007,Ruşen Öktem and Karen Egiazarian and Vladimir V Lukin and Nikolay N Ponomarenko and Oleg V Tsymbal,2007,EURASIP Journal on Advances in Signal Processing,,1-10,Springer International Publishing,This work addresses the problem of signal-dependent noise removal in images. An adaptive nonlinear filtering approach in the orthogonal transform domain is proposed and analyzed for several typical noise environments in the DCT domain. Being applied locally. that is. within a window of small support. DCT is expected to approximate the Karhunen-Loeve decorrelating transform. which enables effective suppression of noise components. The detail preservation ability of the filter allowing not to destroy any useful content in images is especially emphasized and considered. A local adaptive DCT filtering for the two cases. when signal-dependent noise can be and cannot be mapped into additive uncorrelated noise with homomorphic transform. is formulated. Although the main issue is signal-dependent and pure multiplicative noise. the proposed filtering approach is also found to be competing with the …,True,XI9iavwAAAAJ:qjMakFHDy7sC,82,https://link.springer.com/content/pdf/10.1155/2007/42472.pdf,5897666347723209547,/scholar?cites=5897666347723209547,,,https://link.springer.com/content/pdf/10.1155/2007/42472.pdf,0,0,0
1277510,Effects of green buildings on employee health and productivity,2010,Amanjeet Singh and Matt Syal and Sue C Grady and Sinem Korkmaz,100,American journal of public health,9,1665-1668,American Public Health Association,We investigated the effects of improved indoor environmental quality (IEQ) on perceived health and productivity in occupants who moved from conventional to green (according to Leadership in Energy and Environmental Design ratings) office buildings. In 2 retrospective–prospective case studies we found that improved IEQ contributed to reductions in perceived absenteeism and work hours affected by asthma. respiratory allergies. depression. and stress and to self-reported improvements in productivity. These preliminary findings indicate that green buildings may positively affect public health.,True,iQjrBV4AAAAJ:zdX0sdgBH_kC,329,https://ajph.aphapublications.org/doi/abs/10.2105/AJPH.2009.180687,6786200524251686665,/scholar?cites=6786200524251686665,,,https://ajph.aphapublications.org/doi/pdfplus/10.2105/AJPH.2009.180687,0,0,0
1277511,Tests. measurements and research methods in behavioural sciences,1986,Arun Kumar Singh,,,,,Tata McGraw-Hill,,True,iQjrBV4AAAAJ:AdUz3-SiDfgC,240,http://scholar.google.com/scholar?cluster=7219181630381180453&hl=en&oi=scholarr,7219181630381180453,/scholar?cites=7219181630381180453,,,,0,0,0
1277512,Job involvement. organizational commitment. professional commitment. and team commitment,2015,Ajay Singh and Bindu Gupta,,Benchmarking: An International Journal,,,Emerald Group Publishing Limited, – The purpose of this paper is to examine the relationship among job involvement. organizational commitment. team commitment and professional commitment and to explore generational differences for these variables.  – It used structured questionnaire survey approach for which data were collected from 477 full-time employees of 13 organizations from diverse sectors in India. Respondents were categorized into four generational cohorts following the classification reported in Robbins et al. (2011).  – The findings of the study indicated that professional commitment is negatively related with job involvement. affective organizational commitment. normative organizational commitment. and team commitment. Job involvement. affective and normative organizational commitment. and team …,True,iQjrBV4AAAAJ:wH03y5nBhxsC,196,https://www.emerald.com/insight/content/doi/10.1108/BIJ-01-2014-0007/full/html,13181996304386323132,/scholar?cites=13181996304386323132,,,,0,0,0
1277513,Integrating Internet. telephones. and call centers for delivering better quality e-governance to all citizens,2008,Awdhesh K Singh and Rajendra Sahu,25,Government Information Quarterly,3,477-490,JAI,This article examines the present approach of providing e-government services through the Internet. Since the Internet is not accessible to most of the populations of the world. the article advocates adopting a multi-platform approach in which mobile and fixed line phones can be used to enhance the Internet in the delivery of e-government services. The article also suggests the concept of Government Call Centers to overcome the limitations posed by the digital divide. The study concludes that integration of the Internet. phones. and call centers can enable governments to deliver e-government to every citizen of a nation. Finally. the article makes specific recommendations to spread e-government services to more citizens through the approach suggested in this paper.,True,iQjrBV4AAAAJ:eTOb990cMygC,120,https://www.sciencedirect.com/science/article/pii/S0740624X07000044,739848569073292885,/scholar?cites=739848569073292885,,,https://www.academia.edu/download/49192690/j.giq.2007.01.00120160928-5348-etfbhw.pdf,0,0,0
1277514,In-line content based security for data at rest in a network storage system,2009,Ajay Singh and Ananthan Subramanian and Christoph Kogelnik,,,,,,A network storage server receives multiple write requests from a set of clients via a network and internally buffers multiple data blocks written by the write requests. At a consistency point. the storage server commits the data blocks to a nonvolatile mass storage facility. The consistency point process includes using a storage operating system in the network storage server to compress the data blocks. encrypt selected data blocks. and store the compressed and (possibly) encrypted data blocks in the nonvolatile mass storage facility. Data blocks can also be fingerprinted in parallel with compression and/or encryption. to facilitate subsequent deduplication. Data blocks can be indexed and classified according to content or attributes of the data. Encryption can be applied at different levels of logical container granularity. where a separate. unique cryptographic key is used for each encrypted logical container.,True,iQjrBV4AAAAJ:jD_Q_A4-jPwC,89,https://patents.google.com/patent/US20090319772A1/en,9432218145471781600,/scholar?cites=9432218145471781600,,,https://patentimages.storage.googleapis.com/5c/51/5b/136d8f4da05e18/US20090319772A1.pdf,0,0,0
1277515,Filling and slotting: Analysis and algorithms,1998,Andrew B Kahng and Gabriel Robins and Anish Singh and Huijuan Wang and Alexander Zelikovsky,,,,95-102,,In very deep-submicron VLSI. certain manufacturing steps &mdash notably optical exposure. resist development and etch. chemical vapor deposition and chemical-mechanical polishing (CMP) &mdash have varying effects on device and interconnect features depending on local characteristics of the layout. To make these effects uniform and predictable. the layout itself must be made uniform with respect to certain density parameters. Traditionally. only foundries have performed the post-processing needed to achieve this uniformity. via insertion (“filling”) or partial deletion (“slotting”) of features in the layout. Today. however. physical design and verification tools cannot remain oblivious to such foundry post-processing. Without an accurate estimate of the filling and slotting. RC extraction. delay calculation. and timing and noise analysis flows will all suffer from wild inaccuracies. Therefore. future place-and-route tools …,True,iQjrBV4AAAAJ:ZD92IwzDgOkC,88,https://dl.acm.org/doi/abs/10.1145/274535.274549,8770584114334238450,/scholar?cites=8770584114334238450,,,https://www.researchgate.net/profile/G_Robins/publication/234828998_Filling_and_slotting_analysis_and_algorithms/links/00b49520e42cfc45ad000000/Filling-and-slotting-analysis-and-algorithms.pdf,0,0,0
1277516,Costs and benefits of IEQ improvements in LEED office buildings,2011,Amanjeet Singh and Matt Syal and Sinem Korkmaz and Sue Grady,17,Journal of Infrastructure Systems,2,86-94,American Society of Civil Engineers,Costs and benefits resulting from improved indoor environmental quality (IEQ) in Leadership in Energy and Environmental Design (LEED)-certified buildings are often hypothesized; however. the precise quantification of such costs and benefits remains a challenge. This research examined the incremental hard and soft costs of realizing IEQ improvements in LEED office buildings and related benefits to occupant well-being and productivity using a case study approach. Self-reported well-being and productivity data were collected by surveying employees occupying conventional offices compared to similar data upon their move to LEED offices. These pre- and postmove findings were analyzed using the life cycle cost analysis (LCCA) framework to calculate the potential economic gains of IEQ improvements to the organizations. The results indicate economically viable investments in LEED-IEQ credits and offers …,True,iQjrBV4AAAAJ:tgTmbKTkO1IC,62,https://ascelibrary.org/doi/abs/10.1061/(ASCE)IS.1943-555X.0000046,6030488370334096496,/scholar?cites=6030488370334096496,,,,0,0,0
1277517,Adventitious shoot organogenesis and plant regeneration from cotyledons of Dalbergia sissoo Roxb.. a timber yielding tree legume,2002,Ayay K Singh and S Chand and S Pattnaik and Pradeep K Chand,68,"Plant cell, tissue and organ culture",2,203-209,Kluwer Academic Publishers,A procedure is outlined to induce adventitious shoot organogenesis from semi-mature as well as mature cotyledons lacking the embryonic axis of Dalbergia sissoo Roxb.. an economically important leguminous tree. Shoot buds were induced in the proximal region of the semi-mature cotyledons on Murashige and Skoog's (MS) medium supplemented with 4.44 μM 6-benzyladenine (BA) and 0.26 μM ∝-naphthaleneacetic acid (NAA). These buds elongated into shoots following transfer to a similar medium containing half-strength macro-nutrients. Adventitious shoot bud formation was also induced in the mature cotyledons. However. unlike the semi-mature explants. the mature cotyledons exhibited shoot bud differentiation on MS medium containing 22.20 μM BA without NAA. Pre-culture of mature cotyledons in liquid MS medium containing 8.88 μM BA for a duration of 48 h improved shoot bud regeneration …,True,iQjrBV4AAAAJ:JzGFD3-rS6kC,57,https://link.springer.com/article/10.1023/A:1013870803937,9668476166003523527,/scholar?cites=9668476166003523527,,,,0,0,0
1277518,Numerical Simulation of Multiphase Hydro-mechanical Processes Induced by CO {sub 2} Injection into Deep Saline Aquifers; Simulation numerique des processus hydromecaniques …,2011,UJ Goerke and CH Park and W Wang and AK Singh and O Kolditz and O Kolditz,,,,,,,True,iQjrBV4AAAAJ:pk6FPx6l9xIC,56,,13319211264722551930,/scholar?cites=13319211264722551930,,,,0,0,0
1277519,Hiding secret message in edges of the image,2007,Kh Manglem Singh and L Shyamsudar Singh and A Buboo Singh and Kh Subhabati Devi,,,,238-241,IEEE,The purpose of steganography is covert communication - to hide the very existence of a message from a third party. The paper proposes a new least significant bit embedding algorithm for hiding secret messages in nonadjacent pixel locations of edges of images. It ensures a better security against eavesdroppers.,True,iQjrBV4AAAAJ:PQEM9vzQD9gC,56,https://ieeexplore.ieee.org/abstract/document/4261407/,5908683880520399459,/scholar?cites=5908683880520399459,,,,0,0,0
1277520,Virtual presence via mobile,2015,Saurabh Kumar and Sorabh Saxena and Anand K Singh,,,,,,Devices. systems. and methods are disclosed for connecting a plurality of mobile devices in a videoconference over a cellular network via a videoconferencing server. At least one of the mobile devices includes a camera to capture a video of a participant in the videoconference. The video is transmitted to the videoconferencing server on the cellular network. The videoconferencing server edits the video and sends the edited video to receiving mobile devices in real-time. The receiving mobile devices output the video as a projection by using an internal mobile projector or transmit the video to an external display device. A sending mobile device may also act as a receiving mobile device. such that each of the participants may view video of other participants in his/her own background/environment while communicating with the other participants. In some variations. the videoconferencing server removes the …,True,iQjrBV4AAAAJ:OBae9N4Z9bMC,50,https://patents.google.com/patent/US9024997B2/en,17270229510041349329,/scholar?cites=17270229510041349329,,,https://patentimages.storage.googleapis.com/03/be/d8/e0a21275d2a4bc/US9024997.pdf,0,0,0
1277521,PIK3CA as an oncogene in cervical cancer,2000,Yen-Ying Ma and Sung-Jen Wei and Yu-Chen Lin and Jia-Chyi Lung and Ting-Chang Chang and Jacqueline Whang-Peng and Jacqueline M Liu and Deng-Mei Yang and Wen K Yang and Chen-Yang Shen,19,Oncogene,23,2739-2744,Nature Publishing Group,Amplification of chromosome arm 3q is the most consistent aberration in cervical cancer. and is implicated in the progression of dysplastic uterine cervical cells into invasive cancer. The present study employed the ‘positional candidate gene’strategy to determine the contribution of PIK3CA. which is located in 3q26. 3. in cervical tumorigenesis. PIK3CA is known to be involved in the PI 3-kinase/AKT signaling pathway. which plays an important role in regulating cell growth and apoptosis. The results of comparative genomic hybridization show that the 3q26. 3 amplification was the most consistent chromosomal aberration in primary tissues of cervical carcinoma. and a positive correlation between an increased copy number of PIK3CA (detected by competitive PCR) and 3q26. 3 amplification was found in tumor tissues and in cervical cancer cell lines. In cervical cancer cell lines harboring amplified PIK3CA. the …,True,tI26CY8AAAAJ:4hFrxpcac9AC,574,https://www.nature.com/articles/1203597,17372210846719516234,/scholar?cites=17372210846719516234,,,https://www.nature.com/articles/1203597,0,0,0
1277522,Carriers of inactive hepatitis B virus are still at risk for hepatocellular carcinoma and liver-related death,2010,Jin–De Chen and Hwai–I Yang and Uchenna H Iloeje and San–Lin You and Sheng–Nan Lu and Li–Yu Wang and Jun Su and Chien–An Sun and Yun–Fan Liaw and Chien–Jen Chen,138,Gastroenterology,5,1747-1754. e1,WB Saunders,The risk and the predictors of liver disease progression in carriers of inactive hepatitis B virus (HBV) are unclear.Participants in the Risk Evaluation of Viral Load Elevation and Associated Liver Disease/Cancer-Hepatitis B Virus (REVEAL-HBV) study who were seronegative for hepatitis B e antigen; had serum levels of HBV DNA <10.000 copies/mL; and did not have cirrhosis. hepatocellular carcinoma. or increased serum levels of alanine aminotransferase were classified as carriers of inactive HBV (n = 1932). Study participants who were seronegative for HB surface antigen and antibodies against hepatitis C virus. yet had similar clinical liver features. were the controls (n = 18.137). Liver-related death and new cases of hepatocellular carcinoma were ascertained through computerized data linkage with National Cancer Registry and Death Certification profiles. The disease progression …,True,tI26CY8AAAAJ:UOgPUojWnykC,295,https://www.sciencedirect.com/science/article/pii/S0016508510001484,4569482262581173125,/scholar?cites=4569482262581173125,,,https://www.gastrojournal.org/article/S0016-5085%2810%2900148-4/fulltext,0,0,0
1277523,Changes in serum levels of HBV DNA and alanine aminotransferase determine risk for hepatocellular carcinoma,2011,Chuen–Fei Chen and Wen–Chung Lee and Hwai–I Yang and Hung–Chuen Chang and Chin–Lan Jen and Uchenna H Iloeje and Jun Su and Chuhsing K Hsiao and Li–Yu Wang and San–Lin You and Sheng–Nan Lu and Chien–Jen Chen,141,Gastroenterology,4,1240-1248. e2,WB Saunders,It is not clear whether risk for hepatocellular carcinoma can be accurately determined from long-term changes in serum levels of hepatitis B virus (HBV) DNA or alanine aminotransferase (ALT).We measured serum levels of HBV DNA and ALT at enrollment and during follow-up analysis of 3160 participants in the REVEAL-HBV study. Development of hepatocellular carcinoma was determined from follow-up examinations and computerized linkage with National Cancer Registry and National Death Certification profiles. Multivariate-adjusted hazard ratios (HRs) and 95% confidence intervals (CIs) were estimated using Cox regression models.During 38.330 person-years of follow-up. 81 participants developed hepatocellular carcinoma (incidence rate. 211.3/100.000 person-years). The risk for hepatocellular carcinoma was only slightly higher for participants whose follow-up levels of …,True,tI26CY8AAAAJ:TNEldfgDb5MC,227,https://www.sciencedirect.com/science/article/pii/S0016508511008158,17709281489467923708,/scholar?cites=17709281489467923708,,,https://www.gastrojournal.org/article/S0016-5085(11)00815-8/fulltext,0,0,0
1277524,The prevalence of subjective frailty and factors associated with frailty in Taiwan,2010,Chin-Ying Chen and Shwu-Chong Wu and Liang-Ju Chen and Bee-Horng Lue,50,Archives of gerontology and geriatrics,,S43-S47,Elsevier,This study estimated the prevalence of frailty and identified the factors associated with frailty in Taiwan using data from the Survey of Health and Living Status of the Elderly. A nationwide probability sample including 2.238 individuals aged ≥65 years was interviewed in 2003. Based on the Cardiovascular Health Study conducted by Fried. five phenotypes of frailty were selected: poor appetite. exhaustion. low physical activity. poor walking ability. and poor twisting ability of fingers. Participants were classified as nonfrail. prefrail. and frail if they met 0. 1 or 2. and ≥3 criteria. The prevalences of nonfrailty. prefrailty. and frailty were 55.1%. 40.0%. and 4.9%. respectively. The prevalence of frailty increased with age and was greater in women. Frailty was associated with less education. no spouse. disability. higher rates of comorbid chronic diseases. depressive symptoms. and geriatric syndromes. Specific drug use. such …,True,tI26CY8AAAAJ:n94QCav8jycC,215,https://www.sciencedirect.com/science/article/pii/S0167494310700121,11681847442518542610,/scholar?cites=11681847442518542610,,,https://www.researchgate.net/profile/Chin_Ying_Chen/publication/265090259_Prevalence_and_Associated_Factors_of_Frailty_Among_Elderly_People_in_Taiwan/links/55745cf908ae7536374fed78/Prevalence-and-Associated-Factors-of-Frailty-Among-Elderly-People-in-Taiwan.pdf,0,0,0
1277525,Conversion of fructose into 5-hydroxymethylfurfural catalyzed by recyclable sulfonic acid-functionalized metal–organic frameworks,2014,Jinzhu Chen and Kegui Li and Limin Chen and Ruliang Liu and Xing Huang and Daiqi Ye,16,Green Chemistry,5,2490-2499,Royal Society of Chemistry,A series of sulfonic acid-functionalized metal–organic frameworks (MOF-SO3H) were prepared by postsynthetic modification (PSM) of the organic linkers within the MOF with chlorosulfonic acid. The obtained MOF-SO3H. including sulfonic acid-functionalized MIL-101(Cr) [MIL-101(Cr)-SO3H]. UIO-66(Zr) [UIO-66(Zr)-SO3H]. and MIL-53(Al) [MIL-53(Al)-SO3H]. have been systematically studied as solid acids in fructose transformation to 5-hydroxymethylfurfural (HMF). With MIL-101(Cr)-SO3H as catalyst. a HMF yield of 90% with a full fructose conversion was obtained at 120 °C for 60 min in DMSO. The concentration of –SO3H in MOF-SO3H as well as the contribution of Brønsted acidity of MOF-SO3H parallels its –SO3H grafting rate. Under a lower –SO3H grafting level. a good linear correlation between catalytic activity. in terms of turnover frequency. and sulfonic acid-site density of MOF-SO3H was found. Moreover …,True,tI26CY8AAAAJ:3u3nxgfnd-AC,213,https://pubs.rsc.org/am/content/articlehtml/2014/gc/c3gc42414f,17487047235859373634,/scholar?cites=17487047235859373634,,,https://pubs.rsc.org/lv/content/getauthorversionpdf/C3GC42414F,0,0,0
1277526,Conversion of fructose into 5-hydroxymethylfurfural and alkyl levulinates catalyzed by sulfonic acid-functionalized carbon materials,2013,Ruliang Liu and Jinzhu Chen and Xing Huang and Limin Chen and Longlong Ma and Xinjun Li,15,Green chemistry,10,2895-2903,Royal Society of Chemistry,A series of sulfonic acid-functionalized carbon materials (C–SO3H). including poly(p-styrenesulfonic acid)-grafted carbon nanotubes (CNT-PSSA). poly(p-styrenesulfonic acid)-grafted carbon nanofibers (CNF-PSSA). benzenesulfonic acid-grafted CMK-5 (CMK-5-BSA). and benzenesulfonic acid-grafted carbon nanotubes (CNT-BSA). have been studied for fructose dehydration to 5-hydroxymethylfurfural (HMF) and fructose alcoholysis to alkyl levulinate. A study for optimizing the reaction conditions such as the catalyst loading. the reaction time. and the temperature has been performed. Under the optimal conditions. high HMF and ethyl levulinate yields of up to 89% and 86%. respectively. are obtained. The catalytic activities of C–SO3H for the conversions of fructose into both HMF and ethyl levulinate follow the order of their acid strength. The relationship between the catalytic activity and acid density of C–SO3H …,True,tI26CY8AAAAJ:vG0dlTq9_mQC,169,https://pubs.rsc.org/en/content/articlehtml/2013/gc/c3gc41139g,1485807827835439258,/scholar?cites=1485807827835439258,,,,0,0,0
1277527,Hydrodeoxygenation of lignin-derived phenolic monomers and dimers to alkane fuels over bifunctional zeolite-supported metal catalysts,2014,Wei Zhang and Jinzhu Chen and Ruliang Liu and Shengpei Wang and Limin Chen and Kegui Li,2,ACS Sustainable Chemistry & Engineering,4,683-691,American Chemical Society,A bifunctional catalyst of Ru supported in zeolite HZSM-5. Ru/HZSM-5 (Si/Al = 25). exhibited excellent hydrodeoxygenation activity toward the conversion of lignin-derived phenolic monomers and dimers to cycloalkanes in aqueous solution. The oxygen-containing groups in mono- and binuclear phenols were removed through a cleavage of C–O bonds in phenolics followed by an integrated metal- and acid-catalyzed hydrogenation and dehydration. As a bifunctional catalyst Ru/HZSM-5. the presence of both the Brønsted acid site in the pores of HZSM-5 for dehydration and a metallic function of Ru for hydrogenation was indispensible for the formation of alkanes from lignin-derived phenolics. Our findings also reveal that the Ru/HZSM-5 with the lowest Si/Al ratio of HZSM-5 proved to be most selective to cycloalkanes. indicating that more acid sites over zeolite are favorable for the dehydration of cyclohexanol during …,True,tI26CY8AAAAJ:x-IcQEm-ju4C,163,https://pubs.acs.org/doi/abs/10.1021/sc400401n,13746355804332734677,/scholar?cites=13746355804332734677,,,,0,0,0
1277528,Enterovirus-induced miR-141 contributes to shutoff of host protein translation by targeting the translation initiation factor eIF4E,2011,Bing-Ching Ho and Sung-Liang Yu and Jeremy JW Chen and Sui-Yuan Chang and Bo-Shiun Yan and Qi-Sheng Hong and Sher Singh and Chuan-Liang Kao and Hsuan-Yu Chen and Kang-Yi Su and Ker-Chau Li and Chiou-Ling Cheng and Hao-Wei Cheng and Jen-Yi Lee and Chun-Nan Lee and Pan-Chyr Yang,9,Cell host & microbe,1,58-69,Cell Press,Viruses rely on the host translation machinery to complete their life cycles. Picornaviruses use an internal ribosome entry site to initiate cap-independent protein translation and in parallel host cap-dependent translation is shut off. This process is thought to occur primarily via cleavage of host translation initiation factors eIF4GI and eIF4GII by viral proteases. Here we describe another mechanism whereby miR-141 induced upon enterovirus infection targets the cap-dependent translation initiation factor. eIF4E. for shutoff of host protein synthesis. Knockdown of miR-141 reduces viral propagation. and silencing of eIF4E can completely reverse the inhibitory effect of the miR-141 antagomiR on viral propagation. Ectopic expression of miR-141 promotes the switch from cap-dependent to cap-independent translation. Moreover. we identified a transcription factor. EGR1. which is partly responsible for miR-141 induction in …,True,tI26CY8AAAAJ:iC1Mcd5kvfwC,144,https://www.sciencedirect.com/science/article/pii/S1931312810004117,10138672244240624491,/scholar?cites=10138672244240624491,,,https://www.sciencedirect.com/science/article/pii/S1931312810004117,0,0,0
1277529,Cytokinin-induced somatic embryogenesis and plant regeneration in Corydalis yanhusuo (Fumariaceae)—a medicinal plant,2000,AP Sagare and YL Lee and TC Lin and CC Chen and HS Tsay,160,Plant Science,1,139-147,Elsevier,An efficient method has been developed for regeneration of complete plants via somatic embryogenesis in Corydalis yanhusuo (Fumariaceae). an important medicinal plant. using tuber-derived callus. Primary callus was induced by culturing mature tuber pieces on Murashige and Skoog's (MS) medium supplemented with 2.0 mg l−1 N6-benzyladenine (BA) and 0.5 mg l−1 α-naphthaleneacetic acid (NAA) in darkness. Somatic embryos were induced by subculturing the primary callus on MS medium supplemented with 0.5–4.0 mg l−1 BA. kinetin. or zeatin. within 2 weeks of culture in light. Embryos with well-developed cotyledonary leaves were transferred in half-strength liquid MS medium supplemented with 1.0 mg l−1 zeatin riboside for the development of roots. Converted somatic embryos were cultured on half-strength MS medium supplemented with 6% sucrose. and with 0.5–10.0 mg l−1 abscisic acid (ABA …,True,tI26CY8AAAAJ:SuREjsGmJT0C,144,https://www.sciencedirect.com/science/article/pii/S0168945200003770,6415042378994768428,/scholar?cites=6415042378994768428,,,,0,0,0
1277530,Characterization of MnFe2O4/LiMn2O4 aqueous asymmetric supercapacitor,2011,Yen-Po Lin and Nae-Lih Wu,196,Journal of Power Sources,2,851-854,Elsevier,A new type of asymmetric supercapacitor containing a MnFe2O4 negative electrode and a LiMn2O4 positive electrode in aqueous LiNO3 electrolyte has been synthesized and characterized. The nanocrystalline MnFe2O4 anode material has a specific capacitance of 99 F g−1 and the LiMn2O4 cathode a specific capacity of 130–100 mAh g−1 under 10–100 C rate. The cell has a maximum operating voltage window of ca. 1.3 V. limited by irreversible reaction of MnFe2O4 toward reducing potential. The specific power and specific energy of the full-cell increase with increasing anode-to-cathode mass ratio (A/C) and saturate at A/C ∼4.0. which gives specific cell energies. based on total mass of the two electrodes. of 10 and 5.5 Wh kg−1 at 0.3 and 1.8 kW kg−1. respectively. The cell shows good cycling stability and exhibits significantly slower self-discharge rate than either the MnFe2O4 symmetric cell or the other …,True,tI26CY8AAAAJ:N3pez2oqSB0C,135,https://www.sciencedirect.com/science/article/pii/S0378775310012899,14298314363834413701,/scholar?cites=14298314363834413701,,,,0,0,0
1277531,Urinary pharmacokinetics of baicalein. wogonin and their glycosides after oral administration of Scutellariae Radix in humans,2003,Miao-Ying Lai and Su-Lan Hsiu and Chung-Chuan Chen and Yu-Chi Hou and Pei-Dawn Lee Chao,26,Biological and Pharmaceutical Bulletin,1,79-83,The Pharmaceutical Society of Japan,Baicalin. baicalein. wogonoside and wogonin are flavone constituents of Scutellariae Radix with various beneficial biological activities. The purpose of this study was to investigate the urinary pharmacokinetics of these flavones after oral administration of Scutellariae Radix commercial powder. Ten healthy male volunteers received a dose of 5.2 g commercial powder (comparable to 9g crude drug). respectively. The concentrations of baicalin. baicalein and wogonin in the commercial powder as well as their metabolites in urine were assayed by HPLC method. The glucuronides and sulfates of baicalein and wogonin in urine were hydrolyzed with b-glucuronidase and sulfatase. respectively. Our results showed that the mean cumulated renal excretion of baicalein glucuronides and sulfates were 43.1 4.5 mmol (2.9% of dose) and 64.8 6.3 mmol (4.3% of dose). respectively. whereas wogonin glucuronides and sulfates were 21.6 2.0 mmol (5.9% of dose) and 20.7 1.7 mmol (5.7% of dose). respectively. The result indicated that the renal excretion of conjugated metabolites of wogonin (11.6% of dose) were higher than that of baicalein (7.2% of dose). The baicalein sulfates was predominant than the corresponding glucuronides. whereas wogonin sulfates was comparable to the corresponding glucuronides.,True,tI26CY8AAAAJ:b1ISl_ktn64C,133,https://www.jstage.jst.go.jp/article/bpb/26/1/26_1_79/_article/-char/ja/,4429331343896246849,/scholar?cites=4429331343896246849,,,https://www.jstage.jst.go.jp/article/bpb/26/1/26_1_79/_pdf,0,0,0
1277532,Hyperspectral unmixing overview: Geometrical. statistical. and sparse regression-based approaches,2012,José M Bioucas-Dias and Antonio Plaza and Nicolas Dobigeon and Mario Parente and Qian Du and Paul Gader and Jocelyn Chanussot,5,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2,354-379,IEEE,Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis. which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs. microscopic material mixing. and multiple scattering. spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus. accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials. called endmembers. Unmixing involves estimating all or some of: the number of endmembers. their spectral signatures. and their abundances at …,True,YPQFwDYAAAAJ:I9gX6wnfuA8C,2156,https://ieeexplore.ieee.org/abstract/document/6200362/,17205403180489548653,/scholar?cites=17205403180489548653,,,https://arxiv.org/pdf/1202.6294,0,0,0
1277533,Hyperspectral pansharpening: a review,2015,Laetitia Loncan and Luis B. Almeida and Jose M. Bioucas-Dias and Xavier Briottet and Jocelyn Chanussot and Nicolas Dobigeon and Sophie Fabre and Wenzhi Liao and Giorgio Licciardi and Miguel Simoes and Jean-Yves Tourneret and Miguel Veganzones and Gemine Vivone and Qi Wei and Naoto Yokoya,3,IEEE Geoscience and Remote Sensing Magazine,3,27-46,IEEE,Pansharpening aims at fusing a panchromatic image with a multispectral one. to generate an image with the high spatial resolution of the former and the high spectral resolution of the latter. In the last decade. many algorithms have been presented in the literatures for pansharpening using multispectral data. With the increasing availability of hyperspectral systems. these methods are now being adapted to hyperspectral images. In this work. we compare new pansharpening techniques designed for hyperspectral data with some of the state-of-the-art methods for multispectral pansharpening. which have been adapted for hyperspectral data. Eleven methods from different classes (component substitution. multiresolution analysis. hybrid. Bayesian and matrix factorization) are analyzed. These methods are applied to three datasets and their effectiveness and robustness are evaluated with widely used performance …,True,YPQFwDYAAAAJ:NU-BerS4NX4C,455,https://ieeexplore.ieee.org/abstract/document/7284770/,15742022215552168841,/scholar?cites=15742022215552168841,,,https://arxiv.org/pdf/1504.04531,0,0,0
1277534,Hyperspectral and multispectral image fusion based on a sparse representation,2015,Qi Wei and José Bioucas-Dias and Nicolas Dobigeon and Jean-Yves Tourneret,53,IEEE Transactions on Geoscience and Remote Sensing,7,3658-3668,IEEE,This paper presents a variational-based approach for fusing hyperspectral and multispectral images. The fusion problem is formulated as an inverse problem whose solution is the target image assumed to live in a lower dimensional subspace. A sparse regularization term is carefully designed. relying on a decomposition of the scene on a set of dictionaries. The dictionary atoms and the supports of the corresponding active coding coefficients are learned from the observed images. Then. conditionally on these dictionaries and supports. the fusion problem is solved via alternating optimization with respect to the target image (using the alternating direction method of multipliers) and the coding coefficients. Simulation results demonstrate the efficiency of the proposed algorithm when compared with state-of-the-art fusion methods.,True,YPQFwDYAAAAJ:oTdOBqtIf_kC,381,https://ieeexplore.ieee.org/abstract/document/7010915/,16799776301482973837,/scholar?cites=16799776301482973837,,,https://arxiv.org/pdf/1409.5729,0,0,0
1277535,Nonlinear unmixing of hyperspectral images: models and algorithms,2014,Nicolas Dobigeon and Jean-Yves Tourneret and Cédric Richard and José Bermudez and Stephen McLaughlin and Alfred O Hero,31,IEEE Signal Processing Magazine,1,,IEEE,When considering the problem of unmixing hyperspectral images. most of the literature in the geoscience and image processing areas relies on the widely used linear mixing model (LMM). However. the LMM may be not valid. and other nonlinear models need to be considered. for instance. when there are multiscattering effects or intimate interactions. Consequently. over the last few years. several significant contributions have been proposed to overcome the limitations inherent in the LMM. In this article. we present an overview of recent advances in nonlinear unmixing modeling.,True,YPQFwDYAAAAJ:OU6Ihb5iCvQC,362,https://ieeexplore.ieee.org/abstract/document/6678284/,18093796706333405686,/scholar?cites=18093796706333405686,,,https://arxiv.org/pdf/1304.1875,0,0,0
1277536,Nonlinear unmixing of hyperspectral images using a generalized bilinear model,2011,Abderrahim Halimi and Yoann Altmann and Nicolas Dobigeon and Jean-Yves Tourneret,49,IEEE Transactions on Geoscience and Remote Sensing,11,4153-4162,IEEE,Nonlinear models have recently shown interesting properties for spectral unmixing. This paper studies a generalized bilinear model and a hierarchical Bayesian algorithm for unmixing hyperspectral images. The proposed model is a generalization not only of the accepted linear mixing model but also of a bilinear model that has been recently introduced in the literature. Appropriate priors are chosen for its parameters to satisfy the positivity and sum-to-one constraints for the abundances. The joint posterior distribution of the unknown parameter vector is then derived. Unfortunately. this posterior is too complex to obtain analytical expressions of the standard Bayesian estimators. As a consequence. a Metropolis-within-Gibbs algorithm is proposed. which allows samples distributed according to this posterior to be generated and to estimate the unknown model parameters. The performance of the resulting unmixing …,True,YPQFwDYAAAAJ:URolC5Kub84C,360,https://ieeexplore.ieee.org/abstract/document/5702384/,6701413814955599052,/scholar?cites=6701413814955599052,,,https://oatao.univ-toulouse.fr/5046/1/Halimi_5046.pdf,0,0,0
1277537,Joint Bayesian endmember extraction and linear unmixing for hyperspectral imagery,2009,Nicolas Dobigeon and Saïd Moussaoui and Martial Coulon and Jean-Yves Tourneret and Alfred O Hero,57,IEEE Transactions on Signal Processing,11,4355-4368,IEEE,This paper studies a fully Bayesian algorithm for endmember extraction and abundance estimation for hyperspectral imagery. Each pixel of the hyperspectral image is decomposed as a linear combination of pure endmember spectra following the linear mixing model. The estimation of the unknown endmember spectra is conducted in a unified manner by generating the posterior distribution of abundances and endmember parameters under a hierarchical Bayesian model. This model assumes conjugate prior distributions for these parameters. accounts for nonnegativity and full-additivity constraints. and exploits the fact that the endmember proportions lie on a lower dimensional simplex. A Gibbs sampler is proposed to overcome the complexity of evaluating the resulting posterior distribution. This sampler generates samples distributed according to the posterior distribution and estimates the unknown parameters …,True,YPQFwDYAAAAJ:u-x6o8ySG0sC,352,https://ieeexplore.ieee.org/abstract/document/5256272/,7947816586021507637,/scholar?cites=7947816586021507637,,,https://arxiv.org/pdf/0903.3060,0,0,0
1277538,Semi-supervised linear spectral unmixing using a hierarchical Bayesian model for hyperspectral imagery,2008,Nicolas Dobigeon and Jean-Yves Tourneret and Chein-I Chang,56,IEEE Transactions on Signal Processing,7,2684-2695,IEEE,This paper proposes a hierarchical Bayesian model that can be used for semi-supervised hyperspectral image unmixing. The model assumes that the pixel reflectances result from linear combinations of pure component spectra contaminated by an additive Gaussian noise. The abundance parameters appearing in this model satisfy positivity and additivity constraints. These constraints are naturally expressed in a Bayesian context by using appropriate abundance prior distributions. The posterior distributions of the unknown model parameters are then derived. A Gibbs sampler allows one to draw samples distributed according to the posteriors of interest and to estimate the unknown abundances. An extension of the algorithm is finally studied for mixtures with unknown numbers of spectral components belonging to a know library. The performance of the different unmixing strategies is evaluated via simulations …,True,YPQFwDYAAAAJ:uWiczbcajpAC,225,https://ieeexplore.ieee.org/abstract/document/4545260/,6071171652237661569,/scholar?cites=6071171652237661569,,,https://oatao.univ-toulouse.fr/803/1/dobigeon_803.pdf,0,0,0
1277539,Fast fusion of multi-band images based on solving a Sylvester equation,2015,Qi Wei and Nicolas Dobigeon and Jean-Yves Tourneret,24,IEEE Transactions on Image Processing,11,4109-4121,IEEE,This paper proposes a fast multi-band image fusion algorithm. which combines a high-spatial low-spectral resolution image and a low-spatial high-spectral resolution image. The well admitted forward model is explored to form the likelihoods of the observations. Maximizing the likelihoods leads to solving a Sylvester equation. By exploiting the properties of the circulant and downsampling matrices associated with the fusion problem. a closed-form solution for the corresponding Sylvester equation is obtained explicitly. getting rid of any iterative update step. Coupled with the alternating direction method of multipliers and the block coordinate descent method. the proposed algorithm can be easily generalized to incorporate prior information for the fusion problem. allowing a Bayesian estimator. Simulation results show that the proposed algorithm achieves the same performance as the existing algorithms with the …,True,YPQFwDYAAAAJ:VnuxuLaQPLMC,207,https://ieeexplore.ieee.org/abstract/document/7163298/,7819550820466409235,/scholar?cites=7819550820466409235,,,https://arxiv.org/pdf/1502.03121,0,0,0
1277540,Temporal dynamics of host molecular responses differentiate symptomatic and asymptomatic Influenza A infection,2011,Yongsheng Huang and Aimee K Zaas and Arvind Rao and Nicolas Dobigeon and Peter J Woolf and Timothy Veldman and N Christine Øien and Micah T McClain and Jay B Varkey and Bradley Nicholson and Lawrence Carin and Stephen Kingsmore and Christopher W Woods and Geoffrey S Ginsburg and Alfred O Hero III,7,PLoS genetics,8,e1002234,Public Library of Science,Exposure to influenza viruses is necessary. but not sufficient. for healthy human hosts to develop symptomatic illness. The host response is an important determinant of disease progression. In order to delineate host molecular responses that differentiate symptomatic and asymptomatic Influenza A infection. we inoculated 17 healthy adults with live influenza (H3N2/Wisconsin) and examined changes in host peripheral blood gene expression at 16 timepoints over 132 hours. Here we present distinct transcriptional dynamics of host responses unique to asymptomatic and symptomatic infections. We show that symptomatic hosts invoke. simultaneously. multiple pattern recognition receptors-mediated antiviral and inflammatory responses that may relate to virus-induced oxidative stress. In contrast. asymptomatic subjects tightly regulate these responses and exhibit elevated expression of genes that function in antioxidant responses and cell-mediated responses. We reveal an ab initio molecular signature that strongly correlates to symptomatic clinical disease and biomarkers whose expression patterns best discriminate early from late phases of infection. Our results establish a temporal pattern of host molecular responses that differentiates symptomatic from asymptomatic infections and reveals an asymptomatic host-unique non-passive response signature. suggesting novel putative molecular targets for both prognostic assessment and ameliorative therapeutic intervention in seasonal and pandemic influenza.,True,YPQFwDYAAAAJ:epqYDVWIO7EC,194,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1002234,12139753072454901350,/scholar?cites=12139753072454901350,,,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1002234,0,0,0
1277541,Supervised nonlinear spectral unmixing using a post-nonlinear mixing model for hyperspectral imagery,2012,Yoann Altmann and Abderrahim Halimi and Nicolas Dobigeon and Jean-Yves Tourneret,21,IEEE Transactions on Image Processing,6,3017-3025,IEEE,This paper presents a nonlinear mixing model for hyperspectral image unmixing. The proposed model assumes that the pixel reflectances are nonlinear functions of pure spectral components contaminated by an additive white Gaussian noise. These nonlinear functions are approximated using polynomial functions leading to a polynomial postnonlinear mixing model. A Bayesian algorithm and optimization methods are proposed to estimate the parameters involved in the model. The performance of the unmixing strategies is evaluated by simulations conducted on synthetic and real data.,True,YPQFwDYAAAAJ:ULOm3_A8WrAC,189,https://ieeexplore.ieee.org/abstract/document/6151825/,12066260718945701373,/scholar?cites=12066260718945701373,,,https://oatao.univ-toulouse.fr/5623/1/altmann_5623.pdf,0,0,0
1277542,Bayesian estimation of linear mixtures using the normal compositional model. Application to hyperspectral imagery,2010,Olivier Eches and Nicolas Dobigeon and Corinne Mailhes and Jean-Yves Tourneret,19,IEEE Transactions on Image Processing,6,1403-1413,IEEE,This paper studies a new Bayesian unmixing algorithm for hyperspectral images. Each pixel of the image is modeled as a linear combination of so-called endmembers. These endmembers are supposed to be random in order to model uncertainties regarding their knowledge. More precisely. we model endmembers as Gaussian vectors whose means have been determined using an endmember extraction algorithm such as the famous N-finder (N-FINDR) or Vertex Component Analysis (VCA) algorithms. This paper proposes to estimate the mixture coefficients (referred to as abundances) using a Bayesian algorithm. Suitable priors are assigned to the abundances in order to satisfy positivity and additivity constraints whereas conjugate priors are chosen for the remaining parameters. A hybrid Gibbs sampler is then constructed to generate abundance and variance samples distributed according to the joint posterior of …,True,YPQFwDYAAAAJ:Tyk-4Ss8FVUC,166,https://ieeexplore.ieee.org/abstract/document/5427031/,8868828552744115431,/scholar?cites=8868828552744115431,,,https://oatao.univ-toulouse.fr/4089/1/Eches_4089.pdf,0,0,0
1277543,Monodisperse magnetic single‐crystal ferrite microspheres,2005,Hong Deng and Xiaolin Li and Qing Peng and Xun Wang and Jinping Chen and Yadong Li,117,Angewandte Chemie,18,2842-2845,WILEY‐VCH Verlag,It has been thought that many novel properties and potential applications would emerge from monodisperse materials with small dimensions. Therefore. the synthesis of monodisperse nanoparticles has been intensively pursued for their technological and fundamental scientific importance.[1–7] The synthesis of nanostructured magnetic materials has become a particularly important area of research and is attracting a growing interest because of the potential applications such materials have in ferrofluids. advanced magnetic materials. catalysts. colored pigments. high-density magnetic recording media. and medical diagnostics.[8–13] Spinel ferrites (MFe2O4; M= Fe. Mn. Zn. or Co) are among the most important magnetic materials and have been widely used in electronic devices. information storage. magnetic resonance imaging (MRI). and drug-delivery technology.[8. 9. 14] Magnetite (Fe3O4) has recently been …,True,7RDAJ2cAAAAJ:abG-DnoFyZgC,2192,https://onlinelibrary.wiley.com/doi/abs/10.1002/ange.200462551,9894841803974433273,/scholar?cites=9894841803974433273,,,https://journal.materialsscience.net/wp-content/uploads/2019/03/deng2005.pdf,0,0,0
1277544,Antisense oligonucleotides inhibit intercellular adhesion molecule 1 expression by two distinct mechanisms.,1991,Ming-Yi Chiang and Hedy Chan and Mary Ann Zounes and Susan M Freier and Walt F Lima and C Frank Bennett,266,Journal of Biological Chemistry,27,18162-18171,Elsevier,Intercellular adhesion molecule 1 (ICAM-1) is a glycoprotein expressed on the surface of both hemopoietic and nonhemopoietic cells that mediates. in part. the emigration of leukocytes out of the vasculature. Expression of ICAM-1 on the surface of human umbilical vein endothelial cells and a human lung carcinoma cell line (A549) was increased by interleukin-1 beta. tumor necrosis factor alpha. and interferon gamma in a concentration-dependent manner. Phosphorothioate antisense oligonucleotides designed to hybridize to 10 target sites on the human ICAM-1 mRNA were tested for inhibition of ICAM-1 expression in both cell lines by an ICAM-1 enzyme-linked immunosorbent assay. Based upon potency and unique mRNA target sites. two oligonucleotides were studied in greater detail: ISIS 1570. which targeted the AUG translation initiation codon. and ISIS 1939. which targeted specific sequences in the 3' …,True,7RDAJ2cAAAAJ:adgdM4TzidAC,640,https://www.sciencedirect.com/science/article/pii/S0021925818552509,10934058381171026672,/scholar?cites=10934058381171026672,,,https://www.sciencedirect.com/science/article/pii/S0021925818552509,0,0,0
1277545,Formation control: a review and a new consideration,2005,Yang Quan Chen and Zhongmin Wang,,,,3181-3186,IEEE,In this paper. we presented a review on the current control issues and strategies on a group of unmanned autonomous vehicles/robots formation. Formation control has broad applications and becomes an active research topic in the recent years. In this paper. we attempt to review the key issues in formation control with a focus on the main control strategies for formation control under different kinds of scenarios. Then. we point out some important open questions and the possible future research directions on formation control. This paper contributes with a new and interesting consideration on formation control and its application in distributed parameter systems. We pointed out that formation control should be classified as formation regulation control and formation tracking control. similar to regulator and tracker in conventional control.,True,7RDAJ2cAAAAJ:Zph67rFs4hoC,484,https://ieeexplore.ieee.org/abstract/document/1545539/,2148347201978328585,/scholar?cites=2148347201978328585,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.139.1654&rep=rep1&type=pdf,0,0,0
1277546,Ultra-wideband compressed sensing: Channel estimation,2007,Jose L Paredes and Gonzalo R Arce and Zhongmin Wang,1,IEEE Journal of Selected Topics in Signal Processing,3,383-395,IEEE,In this paper. ultra-wideband (UWB) channel estimation based on the theory of compressive sensing (CS) is developed. The proposed approach relies on the fact that transmitting an ultra-short pulse through a multipath UWB channel leads to a received UWB signal that can be approximated by a linear combination of a few atoms from a pre-defined dictionary. yielding thus a sparse representation of the received UWB signal. The key in the proposed approach is in the design of a dictionary of parameterized waveforms (atoms) that closely matches the information-carrying pulseshape leading thus to higher energy compaction and sparse representation. and. therefore higher probability for CS reconstruction. Two approaches for UWB channel estimation are developed under a data-aided framework. In the first approach. the CS reconstruction capabilities are exploited to recover the composite pulse-multipath channel …,True,7RDAJ2cAAAAJ:u5HHmVD_uO8C,384,https://ieeexplore.ieee.org/abstract/document/4336106/,7580265407953688632,/scholar?cites=7580265407953688632,,,https://www.academia.edu/download/46960120/Ultra-Wideband_Compressed_Sensing_Channe20160702-20050-ekz7jw.pdf,0,0,0
1277547,Halftone visual cryptography via error diffusion,2009,Zhongmin Wang and Gonzalo R Arce and Giovanni Di Crescenzo,4,IEEE transactions on information forensics and security,3,383-396,IEEE,Halftone visual cryptography (HVC) enlarges the area of visual cryptography by the addition of digital halftoning techniques. In particular. in visual secret sharing schemes. a secret image can be encoded into halftone shares taking meaningful visual information. In this paper. HVC construction methods based on error diffusion are proposed. The secret image is concurrently embedded into binary valued shares while these shares are halftoned by error diffusion-the workhorse standard of halftoning algorithms. Error diffusion has low complexity and provides halftone shares with good image quality. A reconstructed secret image. obtained by stacking qualified shares together. does not suffer from cross interference of share images. Factors affecting the share image quality and the contrast of the reconstructed image are discussed. Simulation results show several illustrative examples.,True,7RDAJ2cAAAAJ:u-x6o8ySG0sC,299,https://ieeexplore.ieee.org/abstract/document/5075630/,9723663926937486425,/scholar?cites=9723663926937486425,,,,0,0,0
1277548,Variable density compressed image sampling,2009,Zhongmin Wang and J. L. Paredes and G. R. Arce,,,,,,Compressed sensing (CS) provides an efficient way to acquire and reconstruct natural images from a limited number of linear projection measurements leading to sub-Nyquist sampling rates. A key to the success of CS is the design of the measurement ensemble. This correspondence focuses on the design of a novel variable density sampling strategy. where the  a priori  information of the statistical distributions that natural images exhibit in the wavelet domain is exploited. The proposed variable density sampling has the following advantages: 1) the generation of the measurement ensemble is computationally efficient and requires less memory; 2) the necessary number of measurements for image reconstruction is reduced; 3) the proposed sampling method can be applied to several transform domains and leads to simple implementations. Extensive simulations show the effectiveness of the proposed sampling …,True,7RDAJ2cAAAAJ:hMod-77fHWUC,128,https://ieeexplore.ieee.org/abstract/document/5256257/,8460083334370511234,/scholar?cites=8460083334370511234,,,https://www.eecis.udel.edu/~arce/files/Research/VariableDensityCIS.pdf,0,0,0
1277549,The relationship between glycemic variability and diabetic peripheral neuropathy in type 2 diabetes with well-controlled HbA1c,2014,Feng Xu and Li-hua Zhao and Jian-bin Su and Tong Chen and Xue-qin Wang and Jin-feng Chen and Gang Wu and Yan Jin and Xiao-hua Wang,6,Diabetology & metabolic syndrome,1,1-7,BioMed Central,Diabetic peripheral neuropathy (DPN) is one of the most common microvascular complications of diabetes. Glycemic variability could be an independent risk factor for diabetes complications in addition to average glucose. Type 2 diabetes with well-controlled glycosylated hemoglobin A1c (HbA1c) may have different terms of glycemic variability and vascular complication consequences. The aim of the study is to investigate the relationship between glycemic variability and DPN in type 2 diabetes with well-controlled HbA1c (HbA1c < 7.0%). 45 type 2 diabetes with well-controlled HbA1c(HbA1c < 7.0%) and with DPN (DM/DPN group) were recruited in the study. and 45 type 2 diabetes with well-controlled HbA1c and without DPN (DM/–DPN group) were set as controls. The two groups were also matched for age and diabetic duration. Blood pressure. body mass index(BMI). insulin sensitivity index (Matsuda index …,True,7RDAJ2cAAAAJ:Y7HEs_YmcnEC,92,https://link.springer.com/article/10.1186/1758-5996-6-139,2524657937112442770,/scholar?cites=2524657937112442770,,,https://link.springer.com/article/10.1186/1758-5996-6-139,0,0,0
1277550,Whole-genome sequencing reveals diverse models of structural variations in esophageal squamous cell carcinoma,2016,Caixia Cheng and Yong Zhou and Hongyi Li and Teng Xiong and Shuaicheng Li and Yanghui Bi and Pengzhou Kong and Fang Wang and Heyang Cui and Yaoping Li and Xiaodong Fang and Ting Yan and Yike Li and Juan Wang and Bin Yang and Ling Zhang and Zhiwu Jia and Bin Song and Xiaoling Hu and Jie Yang and Haile Qiu and Gehong Zhang and Jing Liu and Enwei Xu and Ruyi Shi and Yanyan Zhang and Haiyan Liu and Chanting He and Zhenxiang Zhao and Yu Qian and Ruizhou Rong and Zhiwei Han and Yanlin Zhang and Wen Luo and Jiaqian Wang and Shaoliang Peng and Xukui Yang and Xiangchun Li and Lin Li and Hu Fang and Xingmin Liu and Li Ma and Yunqing Chen and Shiping Guo and Xing Chen and Yanfeng Xi and Guodong Li and Jianfang Liang and Xiaofeng Yang and Jiansheng Guo and JunMei Jia and Qingshan Li and Xiaolong Cheng and Qimin Zhan and Yongping Cui,98,The American Journal of Human Genetics,2,256-274,Cell Press,Comprehensive identification of somatic structural variations (SVs) and understanding their mutational mechanisms in cancer might contribute to understanding biological differences and help to identify new therapeutic targets. Unfortunately. characterization of complex SVs across the whole genome and the mutational mechanisms underlying esophageal squamous cell carcinoma (ESCC) is largely unclear. To define a comprehensive catalog of somatic SVs. affected target genes. and their underlying mechanisms in ESCC. we re-analyzed whole-genome sequencing (WGS) data from 31 ESCCs using Meerkat algorithm to predict somatic SVs and Patchwork to determine copy-number changes. We found deletions and translocations with NHEJ and alt-EJ signature as the dominant SV types. and 16% of deletions were complex deletions. SVs frequently led to disruption of cancer-associated genes (e.g.. CDKN2A …,True,7RDAJ2cAAAAJ:B9zx5l6rxUEC,84,https://www.sciencedirect.com/science/article/pii/S000292971500508X,9912053061908258453,/scholar?cites=9912053061908258453,,,https://www.sciencedirect.com/science/article/pii/S000292971500508X,0,0,0
1277551,Metal-mediated oxidation of fluoroquinolone antibiotics in water: a review on kinetics. transformation products. and toxicity assessment,2018,Mingbao Feng and Zunyao Wang and Dionysios D Dionysiou and Virender K Sharma,344,,,1136-1154,Elsevier,Fluoroquinolones (FQs) are among the most potent antimicrobial agents. which have seen their increasing use as human and veterinary medicines to control bacterial infections. FQs have been extensively found in surface water and municipal wastewaters. which has raised great concerns due to their negative impacts to humans and ecological health. It is of utmost importance that FQs are treated before their release into the environment. This paper reviews oxidative removal of FQs using reactive oxygen (O3 and OH). sulfate radicals (SO4−). and high-valent transition metal (MnVII and FeVI) species. The role of metals in enhancing the performance of reactive oxygen and sulfur species is presented. The catalysts can significantly enhance the production of OH and/or SO4− radicals. At neutral pH. the second-order rate constants (k. M−1 s−1) of the reactions between FQs and oxidants follow the order as k(OH) > k(O …,True,7RDAJ2cAAAAJ:crhHmGRhyBgC,83,https://www.sciencedirect.com/science/article/pii/S0304389417306593,17185046447829787657,/scholar?cites=17185046447829787657,,,,0,0,0
1277552,Aquatic photodegradation of sunscreen agent p-aminobenzoic acid in the presence of dissolved organic matter,2013,Lei Zhou and Yuefei Ji and Chao Zeng and Ya Zhang and Zunyao Wang and Xi Yang,47,Water research,1,153-162,Pergamon,Dissolved organic matter (DOM) is an important photosensitizer for the phototransformation of organic contaminants in sunlit natural waters. This article focuses on the photolysis kinetics and mechanism of sunscreen agent p-aminobenzoic acid (PABA) in the presence of four kinds of DOM; Suwannee River fulvic acid (SRFA). Suwannee River humic acid (SRHA). Nordic Lake fulvic acid (NOFA) and Nordic Lake humic acid (NOHA). It is evident that direct photolysis of PABA is highly pH-dependent because different species of PABA have different electrical densities on the ring system. The presence of four kinds of DOM inhibits the photolysis of PABA primarily due to their light screening effect. Meanwhile. a complex interaction involving energy transfer. triplet carbonyl group induced electron transfer. and amino acid induced proton abstraction between PABA and DOM is verified by competition kinetics experiments …,True,7RDAJ2cAAAAJ:V3RZsmw8swMC,78,https://www.sciencedirect.com/science/article/pii/S0043135412006884,7780796952143952207,/scholar?cites=7780796952143952207,,,,0,0,0
1277553,Degradation of the UV-filter benzophenone-3 in aqueous solution using persulfate activated by heat. metal ions and light,2018,Xiaoxue Pan and Liqing Yan and Ruijuan Qu and Zunyao Wang,196,Chemosphere,,95-104,Pergamon,The goals of this study were to bring forward new data and insights into the effect of activation methods. operational variables and reaction pathways during sulfate radicals-based oxidation of benzophenone-3 (BP-3) in aqueous solution. Heat. transition metal ions (Fe2+. Cu2+. Co2+). UV and visible light irradiation were used to activate persulfate (PS) to degrade BP-3. The results showed that these three activation methods can remarkably enhance BP-3 removal efficiency. Under the conditions of [BP-3]0: [PS]0 = 1: 500. pH = 7.0. and 40 °C. complete removal of BP-3 (1.31 μM) was observed in 3 h. In the pH range of 3.0–9.0. the degradation of BP-3 decreased with increasing pH. Increasing the PS dosage accelerated the reaction. while the presence of humic acid (HA) significantly inhibited the efficiency of BP-3 removal. Based on electron paramagnetic resonance (EPR) and radical quenching studies …,True,7RDAJ2cAAAAJ:xIQbs6uk08UC,75,https://www.sciencedirect.com/science/article/pii/S0045653517321306,10310491593919980762,/scholar?cites=10310491593919980762,,,,0,0,0
1277554,Unique signatures of histograms for local surface description,2010,Federico Tombari and Samuele Salti and Luigi Di Stefano,,,,356-369,Springer. Berlin. Heidelberg,This paper deals with local 3D descriptors for surface matching. First. we categorize existing methods into two classes: Signatures and Histograms. Then. by discussion and experiments alike. we point out the key issues of uniqueness and repeatability of the local reference frame. Based on these observations. we formulate a novel comprehensive proposal for surface representation. which encompasses a new unique and repeatable local reference frame as well as a new 3D descriptor. The latter lays at the intersection between Signatures and Histograms. so as to possibly achieve a better balance between descriptiveness and robustness. Experiments on publicly available datasets as well as on range scans obtained with Spacetime Stereo provide a thorough validation of our proposal.,True,xZVTzyAAAAAJ:UeHWp8X0CEIC,1316,https://link.springer.com/chapter/10.1007/978-3-642-15558-1_26,11721480337507062431,/scholar?cites=11721480337507062431,,,https://link.springer.com/content/pdf/10.1007/978-3-642-15558-1_26.pdf,0,0,0
1277555,A fast area-based stereo matching algorithm,2004,Luigi Di Stefano and Massimiliano Marchionni and Stefano Mattoccia,22,Image and vision computing,12,983-1005,Elsevier,This paper proposes an area-based stereo algorithm suitable to real time applications. The core of the algorithm relies on the uniqueness constraint and on a matching process that rejects previous matches as soon as more reliable ones are found. The proposed approach is also compared with bidirectional matching (BM). since the latter is the basic method for detecting unreliable matches in most area-based stereo algorithms. We describe the algorithm's matching core. the additional constraints introduced to improve the reliability and the computational optimizations carried out to achieve a very fast implementation. We provide a large set of experimental results. obtained on a standard set of images with ground-truth as well as on stereo sequences. and computation time measurements. These data are used to evaluate the proposed algorithm and compare it with a well-known algorithm based on BM.,True,xZVTzyAAAAAJ:WbkHhVStYXYC,411,https://www.sciencedirect.com/science/article/pii/S0262885604000733,6671941660797877498,/scholar?cites=6671941660797877498,,,https://www.researchgate.net/profile/Stefano_Mattoccia/publication/223945996_A_fast_area-based_stereo_matching_algorithm/links/5bbb8a5c299bf1049b74f708/A-fast-area-based-stereo-matching-algorithm.pdf,0,0,0
1277556,SHOT: Unique signatures of histograms for surface and texture description,2014,Samuele Salti and Federico Tombari and Luigi Di Stefano,125,Computer Vision and Image Understanding,,251-264,Academic Press,This paper presents a local 3D descriptor for surface matching dubbed SHOT. Our proposal stems from a taxonomy of existing methods which highlights two major approaches. referred to as Signatures and Histograms. inherently emphasizing descriptiveness and robustness respectively. We formulate a comprehensive proposal which encompasses a repeatable local reference frame as well as a 3D descriptor. the latter featuring an hybrid structure between Signatures and Histograms so as to aim at a more favorable balance between descriptive power and robustness. A quite peculiar trait of our method concerns seamless integration of multiple cues within the descriptor to improve distinctiveness. which is particularly relevant nowadays due to the increasing availability of affordable RGB-D sensors which can gather both depth and color information. A thorough experimental evaluation based on datasets acquired …,True,xZVTzyAAAAAJ:bnK-pcrLprsC,381,https://www.sciencedirect.com/science/article/pii/S1077314214000988,13443673962152134642,/scholar?cites=13443673962152134642,,,https://www.academia.edu/download/42972440/SHOT_Unique_Signatures_of_Histograms_for20160223-22934-hz4swl.pdf,0,0,0
1277557,A simple and efficient connected components labeling algorithm,1999,Luigi Di Stefano and Andrea Bulgarelli,,,,322-327,IEEE,We describe a two-scan algorithm for labeling connected components in binary images in raster format. Unlike the classical two-scan approach. our algorithm processes equivalences during the first scan by merging equivalence classes as soon as a new equivalence is found. We show that this significantly improves the efficiency of the labeling process with respect to the classical approach. The data structure used to support the handling of equivalences is a 1D-array. This renders the more frequent operation of finding class identifiers very fast. while the less-frequent class-merging operation has a relatively high computational cost. Nonetheless. it is possible to reduce significantly the merging cost by two slight modifications to the algorithm's basic structure. The idea of merging equivalence classes is present also in Samet's general labeling algorithm. However when considering the case of binary images in raster …,True,xZVTzyAAAAAJ:u5HHmVD_uO8C,379,https://ieeexplore.ieee.org/abstract/document/797615/,967989280017310880,/scholar?cites=967989280017310880,,,https://www.researchgate.net/profile/Andrea_Bulgarelli/publication/3820852_A_simple_and_efficient_connected_components_labeling_algorithm/links/00b7d51496cb6be714000000.pdf,0,0,0
1277558,A combined texture-shape descriptor for enhanced 3D feature matching,2011,Federico Tombari and Samuele Salti and Luigi Di Stefano,,,,809-812,IEEE,Motivated by the increasing availability of 3D sensors capable of delivering both shape and texture information. this paper presents a novel descriptor for feature matching in 3D data enriched with texture. The proposed approach stems from the theory of a recently proposed descriptor for 3D data which relies on shape only. and represents its generalization to the case of multiple cues associated with a 3D mesh. The proposed descriptor. dubbed CSHOT. is demonstrated to notably improve the accuracy of feature matching in challenging object recognition scenarios characterized by the presence of clutter and occlusions.,True,xZVTzyAAAAAJ:4DMP91E08xMC,334,https://ieeexplore.ieee.org/abstract/document/6116679/,6744857606876042765,/scholar?cites=6744857606876042765,,,https://www.academia.edu/download/30773810/icip11.pdf,0,0,0
1277559,Performance evaluation of 3D keypoint detectors,2013,Federico Tombari and Samuele Salti and Luigi Di Stefano,102,International Journal of Computer Vision,1-3,198-220,Springer US,In the past few years detection of repeatable and distinctive keypoints on 3D surfaces has been the focus of intense research activity. due on the one hand to the increasing diffusion of low-cost 3D sensors. on the other to the growing importance of applications such as 3D shape retrieval and 3D object recognition. This work aims at contributing to the maturity of this field by a thorough evaluation of several recent 3D keypoint detectors. A categorization of existing methods in two classes. that allows for highlighting their common traits. is proposed. so as to abstract all algorithms to two general structures. Moreover. a comprehensive experimental evaluation is carried out in terms of repeatability. distinctiveness and computational efficiency. based on a vast data corpus characterized by nuisances such as noise. clutter. occlusions and viewpoint changes.,True,xZVTzyAAAAAJ:JV2RwH3_ST0C,310,https://link.springer.com/article/10.1007%252Fs11263-012-0545-4,3094076794416989681,/scholar?cites=3094076794416989681,,,,0,0,0
1277560,Segmentation-based adaptive support for accurate stereo correspondence,2007,Federico Tombari and Stefano Mattoccia and Luigi Di Stefano,,,,427-438,Springer. Berlin. Heidelberg,Significant achievements have been attained in the field of dense stereo correspondence by local algorithms based on an adaptive support. Given the problem of matching two correspondent pixels within a local stereo process. the basic idea is to consider as support for each pixel only those points which lay on the same disparity plane. rather than those belonging to a fixed support.This paper proposes a novel support aggregation strategy which includes information obtained from a segmentation process. Experimental results on the Middlebury dataset demonstrate that our approach is effective in improving the state of the art.,True,xZVTzyAAAAAJ:u-x6o8ySG0sC,269,https://link.springer.com/chapter/10.1007/978-3-540-77129-6_38,4042729611223976989,/scholar?cites=4042729611223976989,,,https://link.springer.com/content/pdf/10.1007/978-3-540-77129-6_38.pdf,0,0,0
1277561,Classification and evaluation of cost aggregation methods for stereo correspondence,2008,Federico Tombari and Stefano Mattoccia and Luigi Di Stefano and Elisa Addimanda,,,,1-8,IEEE,In the last decades several cost aggregation methods aimed at improving the robustness of stereo correspondence within local and global algorithms have been proposed. Given the recent developments and the lack of an appropriate comparison. in this paper we survey. classify and compare experimentally on a standard data set the main cost aggregation approaches proposed in literature. The experimental evaluation addresses both accuracy and computational requirements. so as to outline the best performing methods under these two criteria.,True,xZVTzyAAAAAJ:d1gkVwhDpl0C,257,https://ieeexplore.ieee.org/abstract/document/4587677/,543784051527730734,/scholar?cites=543784051527730734,,,https://www.academia.edu/download/505422/cvpr08.pdf,0,0,0
1277562,Unique shape context for 3D data description,2010,Federico Tombari and Samuele Salti and Luigi Di Stefano,,,,57-62,,The use of robust feature descriptors is now key for many 3D tasks such as 3D object recognition and surface alignment. Many descriptors have been proposed in literature which are based on a non-unique local Reference Frame and hence require the computation of multiple descriptions at each feature points. In this paper we show how to deploy a unique local Reference Frame to improve the accuracy and reduce the memory footprint of the well-known 3D Shape Context descriptor. We validate our proposal by means of an experimental analysis carried out on a large dataset of 3D scenes and addressing an object recognition scenario.,True,xZVTzyAAAAAJ:aqlVkmm33-oC,231,https://dl.acm.org/doi/abs/10.1145/1877808.1877821,2434015705874816467,/scholar?cites=2434015705874816467,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.726.7564&rep=rep1&type=pdf,0,0,0
1277563,ZNCC-based template matching using bounded partial correlation,2005,Luigi Di Stefano and Stefano Mattoccia and Federico Tombari,26,Pattern recognition letters,14,2129-2134,North-Holland,This paper describes a class of algorithms enabling efficient and exhaustive matching of a template into an image based on the Zero mean Normalized Cross-Correlation function (ZNCC). The approach consists in checking at each image position two sufficient conditions obtained at a reduced computational cost. This allows to skip rapidly most of the expensive calculations required to evaluate the ZNCC at those image points that cannot improve the best correlation score found so far. The algorithms shown in this paper generalize and extend the concept of Bounded Partial Correlation (BPC). previously devised for a template matching process based on the Normalized Cross-Correlation function (NCC).,True,xZVTzyAAAAAJ:2osOgNQ5qMEC,215,https://www.sciencedirect.com/science/article/pii/S0167865505000905,15842104022668597883,/scholar?cites=15842104022668597883,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.1159&rep=rep1&type=pdf,0,0,0
1277564,Augmented reality for aircraft maintenance training and operations support,2010,Francesca De Crescenzio and Massimiliano Fantini and Franco Persiani and Luigi Di Stefano and Pietro Azzari and Samuele Salti,31,IEEE Computer Graphics and Applications,1,96-101,IEEE,Recent statistics on causes of aviation accidents and incidents demonstrate that to increase air-transportation safety. we must reduce human errors' impact on operations. So. the industry should first address human factors related to people in stressful roles to significantly minimize such errors. In particular. aviation maintenance employees work under high-pressure conditions- that is. they're under strict time constraints and must adhere to stringent guidelines. Because of such constraints. they might be prone to making errors. Unfortunately. many of these errors might not become apparent until an accident occurs. Although maintenance errors are a recognized threat to aviation safety. there are few simulation and computer-based tools for managing human factor issues in this field. The main advantages in using computer-based systems to train or support technicians are that computers don't forget and that they can …,True,xZVTzyAAAAAJ:MXK_kJrjxJIC,206,https://ieeexplore.ieee.org/abstract/document/5675633/,5185194865499299188,/scholar?cites=5185194865499299188,,,https://www.academia.edu/download/48177697/mcg.2011.420160819-9780-tc7w88.pdf,0,0,0
1277565,Optical sectioning deep inside live embryos by selective plane illumination microscopy,2004,Jan Huisken and Jim Swoger and Filippo Del Bene and Joachim Wittbrodt and Ernst HK Stelzer,305,Science,5686,1007-1009,American Association for the Advancement of Science,Large. living biological specimens present challenges to existing optical imaging techniques because of their absorptive and scattering properties. We developed selective plane illumination microscopy (SPIM) to generate multidimensional images of samples up to a few millimeters in size. The system combines two-dimensional illumination with orthogonal camera-based detection to achieve high-resolution. optically sectioned imaging throughout the sample. with minimal photodamage and at speeds capable of capturing transient biological phenomena. We used SPIM to visualize all muscles in vivo in the transgenic Medaka line Arnie. which expresses green fluorescent protein in muscle tissue. We also demonstrate that SPIM can be applied to visualize the embryogenesis of the relatively opaque Drosophila melanogaster in vivo.,True,cK56nKsAAAAJ:u5HHmVD_uO8C,1991,https://science.sciencemag.org/content/305/5686/1007.abstract,5764347062910566949,/scholar?cites=5764347062910566949,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.456.2250&rep=rep1&type=pdf,0,0,0
1277566,Selective plane illumination microscopy techniques in developmental biology,2009,Jan Huisken and Didier YR Stainier,136,,12,1963-1975,The Company of Biologists Ltd,Selective plane illumination microscopy (SPIM) and other fluorescence microscopy techniques in which a focused sheet of light serves to illuminate the sample have become increasingly popular in developmental studies. Fluorescence light-sheet microscopy bridges the gap in image quality between fluorescence stereomicroscopy and high-resolution imaging of fixed tissue sections. In addition. high depth penetration. low bleaching and high acquisition speeds make light-sheet microscopy ideally suited for extended time-lapse experiments in live embryos. This review compares the benefits and challenges of light-sheet microscopy with established fluorescence microscopy techniques such as confocal microscopy and discusses the different implementations and applications of this easily adaptable technology.,True,cK56nKsAAAAJ:d1gkVwhDpl0C,617,https://dev.biologists.org/content/136/12/1963.short,8364520265025047095,/scholar?cites=8364520265025047095,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2685720/,0,0,0
1277567,Optogenetic control of cardiac function,2010,Aristides B Arrenberg and Didier YR Stainier and Herwig Baier and Jan Huisken,330,Science,6006,971-974,American Association for the Advancement of Science,The cardiac pacemaker controls the rhythmicity of heart contractions and can be substituted by a battery-operated device as a last resort. We created a genetically encoded. optically controlled pacemaker by expressing halorhodopsin and channelrhodopsin in zebrafish cardiomyocytes. Using patterned illumination in a selective plane illumination microscope. we located the pacemaker and simulated tachycardia. bradycardia. atrioventricular blocks. and cardiac arrest. The pacemaker converges to the sinoatrial region during development and comprises fewer than a dozen cells by the time the heart loops. Perturbation of the activity of these cells was entirely reversible. demonstrating the resilience of the endogenous pacemaker. Our studies combine optogenetics and light-sheet microscopy to reveal the emergence of organ function during development.,True,cK56nKsAAAAJ:9yKSN-GCB0IC,433,https://science.sciencemag.org/content/330/6006/971.abstract,2900832518471468924,/scholar?cites=2900832518471468924,,,https://www.researchgate.net/profile/Aristides_Arrenberg/publication/47755612_Optogenetic_Control_of_Cardiac_Function/links/0a85e5319bf242648e000000.pdf,0,0,0
1277568,Even fluorescence excitation by multidirectional selective plane illumination microscopy (mSPIM),2007,Jan Huisken and Didier YR Stainier,32,Optics letters,17,2608-2610,Optical Society of America,Multidirectional selective plane illumination microscopy (mSPIM) reduces absorption and scattering artifacts and provides an evenly illuminated focal plane. mSPIM solves two common problems in light-sheet-based imaging techniques: The shadowing in the excitation path due to absorption in the specimen is eliminated by pivoting the light sheet; the spread of the light sheet by scattering in the sample is compensated by illuminating the sample consecutively from opposing directions. The resulting two images are computationally fused yielding a superior image. The effective light sheet is thinner. and the axial resolution is increased by square root 2 over single-directional SPIM. The multidirectional illumination proves essential in biological specimens such as millimeter-sized embryos. The performance of mSPIM is demonstrated by the imaging of live zebrafish embryos.,True,cK56nKsAAAAJ:IjCSPb-OGe4C,349,https://www.osapublishing.org/abstract.cfm?uri=ol-32-17-2608,3451525699023059930,/scholar?cites=3451525699023059930,,,https://www.researchgate.net/profile/Jan_Huisken/publication/6073788_Even_fluorescence_excitation_by_multidirectional_selective_plane_illumination_microscopy_mSPIM/links/0046353987478b7e5b000000/Even-fluorescence-excitation-by-multidirectional-selective-plane-illumination-microscopy-mSPIM.pdf,0,0,0
1277569,A guide to light-sheet fluorescence microscopy for multiscale imaging,2017,Rory M Power and Jan Huisken,14,,4,360-373,Nature Publishing Group,The impact of light-sheet fluorescence microscopy (LSFM) is visible in fields as diverse as developmental and cell biology. anatomical science. biophysics and neuroscience. Although adoption among biologists has been steady. LSFM has not displaced more traditional imaging methods despite its often-superior performance. One reason for this is that the field has largely conformed to a do-it-yourself ethic. although the challenges of big image data cannot be overstated. With the most powerful implementations of LSFM available to only a few groups worldwide. the scope of this technique is unnecessarily limited. Here we elucidate the key developments and define a simple set of underlying principles governing LSFM. In doing so. we aim to clarify the decisions to be made for those who wish to develop and use bespoke light-sheet systems and to assist in identifying the best approaches to apply this powerful …,True,cK56nKsAAAAJ:abG-DnoFyZgC,341,https://www.nature.com/nmeth/journal/v14/n4/abs/nmeth.4224.html,15823853771926234010,/scholar?cites=15823853771926234010,,,http://www.microscopist.co.uk/wp-content/uploads/2017/04/Lightsheet-review-2017.pdf,0,0,0
1277570,Arterial-venous segregation by selective cell sprouting: an alternative mode of blood vessel formation,2009,Shane P Herbert and Jan Huisken and Tyson N Kim and Morri E Feldman and Benjamin T Houseman and Rong A Wang and Kevan M Shokat and Didier YR Stainier,326,Science,5950,294-298,American Association for the Advancement of Science,Blood vessels form de novo (vasculogenesis) or upon sprouting of capillaries from preexisting vessels (angiogenesis). With high-resolution imaging of zebrafish vascular development. we uncovered a third mode of blood vessel formation whereby the first embryonic artery and vein. two unconnected blood vessels. arise from a common precursor vessel. The first embryonic vein formed by selective sprouting of progenitor cells from the precursor vessel. followed by vessel segregation. These processes were regulated by the ligand EphrinB2 and its receptor EphB4. which are expressed in arterial-fated and venous-fated progenitors. respectively. and interact to orient the direction of progenitor migration. Thus. directional control of progenitor migration drives arterial-venous segregation and generation of separate parallel vessels from a single precursor vessel. a process essential for vascular development.,True,cK56nKsAAAAJ:u-x6o8ySG0sC,341,https://science.sciencemag.org/content/326/5950/294.abstract,11990655409440323491,/scholar?cites=11990655409440323491,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2865998/,0,0,0
1277571,Rapid 3D light-sheet microscopy with a tunable lens,2013,Florian O Fahrbach and Fabian F Voigt and Benjamin Schmid and Fritjof Helmchen and Jan Huisken,21,Optics express,18,21010-21026,Optical Society of America,The in-vivo investigation of highly dynamic biological samples. for example the beating zebrafish heart. requires high-speed volume imaging techniques. Light-sheet microscopy is ideal for such samples as it records high-contrast images of entire planes within large samples at once. However. in order to obtain images of different planes. it has been necessary to move the sample relative to the fixed focal plane of the detection objective lens. This mechanical movement limits speed. precision and may be harmful to the sample. We have built a light-sheet microscope that uses remote focusing with an electrically tunable lens (ETL). Without moving specimen or objective we have thereby achieved flexible volume imaging at much higher speeds than previously reported. Our high-speed microscope delivers 3D snapshots of sensitive biological samples. As an example. we imaged 17 planes within a beating zebrafish …,True,cK56nKsAAAAJ:NMxIlDl6LWMC,284,https://www.osapublishing.org/abstract.cfm?uri=oe-21-18-21010,15707386330450067369,/scholar?cites=15707386330450067369,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-21-18-21010&seq=0,0,0,0
1277572,OpenSPIM: an open-access light-sheet microscopy platform,2013,Peter G Pitrone and Johannes Schindelin and Luke Stuyvenberg and Stephan Preibisch and Michael Weber and Kevin W Eliceiri and Jan Huisken and Pavel Tomancak,10,nature methods,7,598-599,Nature Publishing Group,Light-sheet microscopy is revolutionizing biology by enabling live in toto imaging of entire embryos or organs with minimal phototoxicity 1. We present an open hardware and software platform for constructing a customizable microscope for selective-plane illumination microscopy (SPIM). The OpenSPIM platform is shared with the scientific community through a public website (http://openspim. org/). making light-sheet microscopy more accessible so that it can be optimized for various applications.SPIM is ideally suited for capturing anatomy and patterns of gene activity in large developing specimens expressing fluorescent reporters 2. However. because genomes contain thousands of genes and development can last for days. it is necessary to increase the throughput of SPIM acquisitions. We propose to do this by building arrays of affordable SPIM systems that allow the parallel imaging of many samples.,True,cK56nKsAAAAJ:qxL8FJ1GzNcC,253,https://www.nature.com/articles/nmeth.2507,1110415538149516330,/scholar?cites=1110415538149516330,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7450513/,0,0,0
1277573,Genetic and physiologic dissection of the vertebrate cardiac conduction system,2008,Neil C Chi and Robin M Shaw and Benno Jungblut and Jan Huisken and Tania Ferrer and Rima Arnaout and Ian Scott and Dimitris Beis and Tong Xiao and Herwig Baier and Lily Y Jan and Martin Tristani-Firouzi and Didier YR Stainier,6,PLoS Biol,5,e109,Public Library of Science,Vertebrate hearts depend on highly specialized cardiomyocytes that form the cardiac conduction system (CCS) to coordinate chamber contraction and drive blood efficiently and unidirectionally throughout the organism. Defects in this specialized wiring system can lead to syncope and sudden cardiac death. Thus. a greater understanding of cardiac conduction development may help to prevent these devastating clinical outcomes. Utilizing a cardiac-specific fluorescent calcium indicator zebrafish transgenic line. Tg(cmlc2:gCaMP)s878. that allows for in vivo optical mapping analysis in intact animals. we identified and analyzed four distinct stages of cardiac conduction development that correspond to cellular and anatomical changes of the developing heart. Additionally. we observed that epigenetic factors. such as hemodynamic flow and contraction. regulate the fast conduction network of this specialized electrical system. To identify novel regulators of the CCS. we designed and performed a new. physiology-based. forward genetic screen and identified for the first time. to our knowledge. 17 conduction-specific mutations. Positional cloning of hobgoblins634 revealed that tcf2. a homeobox transcription factor gene involved in mature onset diabetes of the young and familial glomerulocystic kidney disease. also regulates conduction between the atrium and the ventricle. The combination of the Tg(cmlc2:gCaMP)s878 line/in vivo optical mapping technique and characterization of cardiac conduction mutants provides a novel multidisciplinary approach to further understand the molecular determinants of the vertebrate CCS.,True,cK56nKsAAAAJ:qjMakFHDy7sC,238,https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060109,2608898839782362551,/scholar?cites=2608898839782362551,,,https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060109,0,0,0
1277574,Zebrafish model for human long QT syndrome,2007,Rima Arnaout and Tania Ferrer and Jan Huisken and Kenneth Spitzer and Didier YR Stainier and Martin Tristani-Firouzi and Neil C Chi,104,Proceedings of the National Academy of Sciences,27,11316-11321,National Academy of Sciences,Long QT syndrome (LQTS) is a disorder of ventricular repolarization that predisposes affected individuals to lethal cardiac arrhythmias. To date. an appropriate animal model of inherited LQTS does not exist. The zebrafish is a powerful vertebrate model used to dissect molecular pathways of cardiovascular development and disease. Because fundamental electrical properties of the zebrafish heart are remarkably similar to those of the human heart. the zebrafish may be an appropriate model for studying human inherited arrhythmias. Here we describe the molecular. cellular. and electrophysiological basis of a zebrafish mutant characterized by ventricular asystole. Genetic mapping and direct sequencing identify the affected gene as kcnh2. which encodes the channel responsible for the rapidly activating delayed rectifier K+ current (IKr). We show that complete loss of functional IKr in embryonic hearts leads to …,True,cK56nKsAAAAJ:UeHWp8X0CEIC,228,https://www.pnas.org/content/104/27/11316.short,5207244948902419581,/scholar?cites=5207244948902419581,,,https://www.pnas.org/content/pnas/104/27/11316.full.pdf,0,0,0
1277575,Multilayer mounting enables long-term imaging of zebrafish development in a light sheet microscope,2012,Anna Kaufmann and Michaela Mickoleit and Michael Weber and Jan Huisken,139,Development,17,3242-3247,Oxford University Press for The Company of Biologists Limited,Light sheet microscopy techniques. such as selective plane illumination microscopy (SPIM). are ideally suited for time-lapse imaging of developmental processes lasting several hours to a few days. The success of this promising technology has mainly been limited by the lack of suitable techniques for mounting fragile samples. Embedding zebrafish embryos in agarose. which is common in conventional confocal microscopy. has resulted in severe growth defects and unreliable results. In this study. we systematically quantified the viability and mobility of zebrafish embryos mounted under more suitable conditions. We found that tubes made of fluorinated ethylene propylene (FEP) filled with low concentrations of agarose or methylcellulose provided an optimal balance between sufficient confinement of the living embryo in a physiological environment over 3 days and optical clarity suitable for fluorescence imaging …,True,cK56nKsAAAAJ:UebtZRa9Y70C,215,https://dev.biologists.org/content/139/17/3242.short,7076758028943587684,/scholar?cites=7076758028943587684,,,https://www.researchgate.net/profile/Michael_Weber21/publication/230632614_Multilayer_mounting_enables_long-term_imaging_of_zebrafish_development_in_a_light_sheet_microscope/links/5696264e08ae820ff0755ae6/Multilayer-mounting-enables-long-term-imaging-of-zebrafish-development-in-a-light-sheet-microscope.pdf,0,0,0
1277576,Detecting moving objects. ghosts. and shadows in video streams,2003,Rita Cucchiara and Costantino Grana and Massimo Piccardi and Andrea Prati,25,IEEE transactions on pattern analysis and machine intelligence,10,1337-1342,IEEE,Background subtraction methods are widely exploited for moving object detection in videos in many applications. such as traffic monitoring. human motion capture. and video surveillance. How to correctly and efficiently model and update the background model and how to deal with shadows are two of the most distinguishing and challenging aspects of such approaches. The article proposes a general-purpose method that combines statistical assumptions with the object-level knowledge of moving objects. apparent objects (ghosts). and shadows acquired in the processing of the previous frames. Pixels belonging to moving objects. ghosts. and shadows are processed differently in order to supply an object-based selective update. The proposed approach exploits color information for both background subtraction and shadow detection to improve object segmentation and background update. The approach proves …,True,PJAxU3QAAAAJ:u5HHmVD_uO8C,2079,https://ieeexplore.ieee.org/abstract/document/1233909/,13707903931037071145,/scholar?cites=13707903931037071145,,,https://opus.lib.uts.edu.au/bitstream/10453/5772/3/2003000355.pdf,0,0,0
1277577,Detecting moving shadows: algorithms and evaluation,2003,Andrea Prati and Ivana Mikic and Mohan M Trivedi and Rita Cucchiara,25,IEEE transactions on pattern analysis and machine intelligence,7,918-923,IEEE,Moving shadows need careful consideration in the development of robust dynamic scene analysis systems. Moving shadow detection is critical for accurate object detection in video streams since shadow points are often misclassified as object points. causing errors in segmentation and tracking. Many algorithms have been proposed in the literature that deal with shadows. However. a comparative evaluation of the existing approaches is still lacking. In this paper. we present a comprehensive survey of moving shadow detection approaches. We organize contributions reported in the literature in four classes two of them are statistical and two are deterministic. We also present a comparative empirical evaluation of representative algorithms selected from these four classes. Novel quantitative (detection and discrimination rate) and qualitative metrics (scene and object independence. flexibility to shadow situations. and …,True,PJAxU3QAAAAJ:u-x6o8ySG0sC,1158,https://ieeexplore.ieee.org/abstract/document/1206520/,3247248895188815727,/scholar?cites=3247248895188815727,,,https://escholarship.org/content/qt2kj2g2f7/qt2kj2g2f7.pdf,0,0,0
1277578,Improving shadow suppression in moving object detection with HSV color information,2001,Rita Cucchiara and Costantino Grana and Massimo Piccardi and Andrea Prati and Stefano Sirotti,,,,334-339,IEEE,Video-surveillance and traffic analysis systems can be heavily improved using vision-based techniques able to extract. manage and track objects in the scene. However. problems arise due to shadows. In particular. moving shadows can affect the correct localization. measurements and detection of moving objects. This work aims to present a technique for shadow detection and suppression used in a system for moving visual object detection and tracking. The major novelty of the shadow detection technique is the analysis carried out in the HSV color space to improve the accuracy in detecting shadows. Signal processing and optic motivations of the approach proposed are described. The integration and exploitation of the shadow detection module into the system are outlined and experimental results are shown and evaluated.,True,PJAxU3QAAAAJ:d1gkVwhDpl0C,731,https://ieeexplore.ieee.org/abstract/document/948679/,16382601736780867231,/scholar?cites=16382601736780867231,,,https://www.researchgate.net/profile/Costantino_Grana/publication/3913726_Improving_shadow_suppression_in_moving_object_detection_with_HSV_color_information/links/0fcfd508a4f714d975000000/Improving-shadow-suppression-in-moving-object-detection-with-HSV-color-information.pdf,0,0,0
1277579,Probabilistic posture classification for human-behavior analysis,2004,Rita Cucchiara and Costantino Grana and Andrea Prati and Roberto Vezzani,35,"IEEE Transactions on systems, man, and cybernetics-Part A: Systems and Humans",1,42-54,IEEE,Computer vision and ubiquitous multimedia access nowadays make feasible the development of a mostly automated system for human-behavior analysis. In this context. our proposal is to analyze human behaviors by classifying the posture of the monitored person and. consequently. detecting corresponding events and alarm situations. like a fall. To this aim. our approach can be divided in two phases: for each frame. the projection histograms (Haritaoglu et al.. 1998) of each person are computed and compared with the probabilistic projection maps stored for each posture during the training phase; then. the obtained posture is further validated exploiting the information extracted by a tracking module in order to take into account the reliability of the classification of the first phase. Moreover. the tracking algorithm is used to handle occlusions. making the system particularly robust even in indoors environments …,True,PJAxU3QAAAAJ:9yKSN-GCB0IC,245,https://ieeexplore.ieee.org/abstract/document/1369344/,16816592983505560297,/scholar?cites=16816592983505560297,,,ftp://ftp.prip.tuwien.ac.at/pub/outgoing/zamba/fallpapers/Cucchiara05.pdf,0,0,0
1277580,A multi‐camera vision system for fall detection and alarm generation,2007,Rita Cucchiara and Andrea Prati and Roberto Vezzani,24,Expert Systems,5,334-345,Blackwell Publishing Ltd, In‐house video surveillance can represent an excellent support for people with some difficulties (e.g. elderly or disabled people) living alone and with a limited autonomy. New hardware technologies and in particular digital cameras are now affordable and they have recently gained credit as tools for (semi‐)automatically assuring people's safety. In this paper a multi‐camera vision system for detecting and tracking people and recognizing dangerous behaviours and events such as a fall is presented. In such a situation a suitable alarm can be sent. e.g. by means of an SMS. A novel technique of warping people's silhouette is proposed to exchange visual information between partially overlapped cameras whenever a camera handover occurs. Finally. a multi‐client and multi‐threaded transcoding video server delivers live video streams to operators/remote users in order to check the validity of a received alarm …,True,PJAxU3QAAAAJ:W7OEmFMy1HYC,230,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0394.2007.00438.x,10202601409545213212,/scholar?cites=10202601409545213212,,,https://aimagelab.ing.unimore.it/imagelab/pubblicazioni/ExpertSystems_2007.pdf,0,0,0
1277581,Detecting objects. shadows and ghosts in video streams by exploiting color and motion information,2001,Rita Cucchiara and Costantino Grana and Massimo Piccardi and Andrea Prati,,,,360-365,IEEE,Many approaches to moving object detection for traffic monitoring and video surveillance proposed in the literature are based on background suppression methods. How to correctly and efficiently update the background model and how to deal with shadows are two of the more distinguishing and challenging features of such approaches. This work presents a general-purpose method for segmentation of moving visual objects (MVO) based on an object-level classification in MVO. ghosts and shadows. Background suppression needs the background model to be estimated and updated: we use motion and shadow information to selectively exclude from the background model MVO and their shadows. while retaining ghosts. The color information (in the HSV color space) is exploited to shadow suppression and. consequently. to enhance both MVO segmentation and background update.,True,PJAxU3QAAAAJ:2osOgNQ5qMEC,219,https://ieeexplore.ieee.org/abstract/document/957036/,7945434851629407670,/scholar?cites=7945434851629407670,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.620.5650&rep=rep1&type=pdf,0,0,0
1277582,Shadow detection algorithms for traffic flow analysis: a comparative study,2001,Andrea Prati and Ivana Mikic and Costantino Grana and Mohan M Trivedi,,,,340-345,IEEE,Shadow detection is critical for robust and reliable vision-based systems for traffic flow analysis. In this paper we discuss various shadow detection approaches and compare two critically. The goal of these algorithms is to prevent moving shadows being misclassified as moving objects (or parts of them). thus avoiding the merging of two or more objects into one and improving the accuracy of object localization. The environment considered is an outdoor highway scene with multiple lanes observed by a single fixed camera. The important features of shadow detection algorithms and the parameter set-up are analyzed and discussed. A critical evaluation of the results both in terms of accuracy and in terms of computational complexity are outlined. Finally. possible integration of the two approaches into a robust shadow detector is presented as future direction of our research.,True,PJAxU3QAAAAJ:qjMakFHDy7sC,159,https://ieeexplore.ieee.org/abstract/document/948680/,11498508628224939726,/scholar?cites=11498508628224939726,,,https://www.academia.edu/download/42665541/Shadow_detection_algorithms_for_traffic_20160214-4826-w1oifl.pdf,0,0,0
1277583,Analysis and detection of shadows in video streams: a comparative evaluation,2001,Andrea Prati and Rita Cucchiara and Ivana Mikic and Mohan M Trivedi,2,,,II-II,IEEE,Robustness to changes in illumination conditions as well as viewing perspectives is an important requirement for many computer vision applications. One of the key factors in enhancing the robustness of dynamic scene analysis is that of accurate and reliable means for shadow detection. Shadow detection is critical for correct object detection in image sequences. Many algorithms have been proposed in the literature that deal with shadows. However. a comparative evaluation of the existing approaches is still lacking. In this paper. the full range of problems underlying the shadow detection is identified and discussed. We classify the proposed solutions to this problem using a taxonomy of four main classes. deterministic model and non-model based. and statistical parametric and nonparametric. Novel quantitative (detection and discrimination accuracy) and qualitative metrics (scene and object independence …,True,PJAxU3QAAAAJ:IjCSPb-OGe4C,144,https://ieeexplore.ieee.org/abstract/document/991013/,14849654399039582275,/scholar?cites=14849654399039582275,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.470.6760&rep=rep1&type=pdf,0,0,0
1277584,Statistic and knowledge-based moving object detection in traffic scenes,2000,Rita Cucchiara and Costantino Grana and Metal Piccardi and A Prati,,,,27-32,IEEE,The most common approach used for vision-based traffic surveillance consists of a fast segmentation of moving visual objects (MVOs) in the scene together with an intelligent reasoning module capable of identifying. tracking and classifying the MVOs in dependency of the system goal. In this paper we describe our approach for MVOs segmentation in an unstructured traffic environment. We consider complex situations with moving people. vehicles and infrastructures that have different aspect model and motion model. In this case we define a specific approach based on background subtraction with statistic and knowledge-based background update. We show many results of real-time tracking of traffic MVOs in outdoor traffic scene such as roads. parking area intersections. and entrance with barriers.,True,PJAxU3QAAAAJ:UeHWp8X0CEIC,139,https://ieeexplore.ieee.org/abstract/document/881013/,16475778254882796122,/scholar?cites=16475778254882796122,,,https://www.academia.edu/download/42665489/Statistic_and_knowledge-based_moving_obj20160214-27177-2fftpj.pdf,0,0,0
1277585,The sakbot system for moving object detection and tracking,2002,Rita Cucchiara and Costantino Grana and Gianni Neri and Massimo Piccardi and Andrea Prati,,,,145-157,Springer. Boston. MA,This paper presents Sakbot. a system for moving object detection in traffic monitoring and video surveillance applications. The system is endowed with robust and efficient detection techniques. which main features are the statistical and knowledge-based background update and the use of HSV color information for shadow suppression. Tracking is provided by a symbolic reasoning module allowing flexible object tracking over a variety of different applications. This system proves effective on many different situations. both from the point of view of the scene appearance and the purpose of the application.,True,PJAxU3QAAAAJ:zYLM7Y9cAGgC,135,https://link.springer.com/chapter/10.1007/978-1-4615-0913-4_12,5490467510472950347,/scholar?cites=5490467510472950347,,,https://www.academia.edu/download/42665542/The_Sakbot_system_for_moving_object_dete20160214-27539-1fjypbk.pdf,0,0,0
1277586,A fast and effective ellipse detector for embedded vision applications,2014,Michele Fornaciari and Andrea Prati and Rita Cucchiara,47,Pattern Recognition,11,3693-3708,Pergamon,Several papers addressed ellipse detection as a first step for several computer vision applications. but most of the proposed solutions are too slow to be applied in real time on large images or with limited hardware resources. This paper presents a novel algorithm for fast and effective ellipse detection and demonstrates its superior speed performance on large and challenging datasets. The proposed algorithm relies on an innovative selection strategy of arcs which are candidate to form ellipses and on the use of Hough transform to estimate parameters in a decomposed space. The final aim of this solution is to represent a building block for new generation of smart-phone applications which need fast and accurate ellipse detection also with limited computational resources.,True,PJAxU3QAAAAJ:LjlpjdlvIbIC,112,https://www.sciencedirect.com/science/article/pii/S0031320314001976,11510767005682470225,/scholar?cites=11510767005682470225,,,https://www.researchgate.net/profile/Michele_Fornaciari/publication/263893437_A_fast_and_effective_ellipse_detector_for_embedded_vision_applications/links/5e6a17e5299bf1b9f7ceb631/A-fast-and-effective-ellipse-detector-for-embedded-vision-applications.pdf,0,0,0
1277587,The MPEG-4 fine-grained scalable video coding method for multimedia streaming over IP,2001,Hayder M Radha and Mihaela Van der Schaar and Yingwei Chen,3,IEEE Transactions on multimedia,1,53-68,IEEE,Real-time streaming of audiovisual content over the Internet is emerging as an important technology area in multimedia communications. Due to the wide variation of available bandwidth over Internet sessions. there is a need for scalable video coding methods and (corresponding) flexible streaming approaches that are capable of adapting to changing network conditions in real time. In this paper. we describe a new scalable video-coding framework that has been adopted recently by the MPEG-4 video standard. This new MPEG-4 video approach. which is known as Fine-Granular-Scalability (FGS). consists of a rich set of video coding tools that support quality (i.e.. SNR). temporal. and hybrid temporal-SNR scalabilities. Moreover. one of the desired features of the MPEG-J FGS method is its simplicity and flexibility in supporting unicast and multicast streaming applications over IF.,True,GJaAw1EAAAAJ:4JMBOYKVnBMC,538,https://ieeexplore.ieee.org/abstract/document/909594/,3715482256737300743,/scholar?cites=3715482256737300743,,,https://www.researchgate.net/profile/Hayder_Radha/publication/3424050_The_MPEG-4_fine-grained_scalable_video_coding_method_for_multimedia_streaming_over_IP/links/54216dde0cf2ce3a91b75142.pdf,0,0,0
1277588,Wavelet-based contourlet transform and its application to image coding,2004,Ramin Eslami and Hayder Radha,5,,,3189-3192,IEEE,In this paper. we first propose a new family of geometrical image transforms that decompose images both radially and angularly. Our construction comprises two stages of filter banks that are non-redundant and perfect reconstruction and therefore lead to an overall non-redundant and perfect reconstruction transform. Using the wavelet transform as the first stage. we apply directional filter banks to the wavelet coefficients in such a way to maintain the anisotropy scaling law. Furthermore. we propose a new image coding scheme based on the proposed transform. the wavelet-based contourlet transform (WBCT). using a new contourlet-based set partitioning in hierarchical trees (CSPIHT) algorithm that provides an embedded code. Due to differences in parent-child relationships between the WBCT coefficients and wavelet coefficients. under CSPIHT. we developed an elaborated repositioning algorithm for the WBCT …,True,GJaAw1EAAAAJ:mB3voiENLucC,252,https://ieeexplore.ieee.org/abstract/document/1421791/,3242536188935030015,/scholar?cites=3242536188935030015,,,http://www.egr.msu.edu/waves/people/ramin_files/Eslami_CISS05.pdf,0,0,0
1277589,System and method for fine granular scalable video with selective quality enhancement,2001,Yingwei Chen and Hayder Radha and Mihaela van der Schaar,,,,,,There is disclosed an adaptive quantization controller for use in a video encoder comprising a base layer circuit for receiving an input stream of video frames and generating compressed base layer video frames suitable for transmission to a streaming video receiver and an enhancement layer circuit for receiving the input stream of video frames and a decoded version of the compressed base layer video frames and generating enhancement layer video data associated with. and allocated to. corresponding ones of the compressed base layer video frames. The adaptive quantization controller receives at least one quantization parameter from the base layer circuit and. in response thereto. determines a corresponding shifting factor for shifting a bit plane associated with the enhancement layer video data. The adaptive quantizaion controller also modifies a data field in the enhancement layer video data to cause the …,True,GJaAw1EAAAAJ:LjlpjdlvIbIC,239,https://patents.google.com/patent/US6263022B1/en,9714335749718405042,/scholar?cites=9714335749718405042,,,https://patentimages.storage.googleapis.com/pdfs/US6263022.pdf,0,0,0
1277590,Translation-invariant contourlet transform and its application to image denoising,2006,Ramin Eslami and Hayder Radha,15,IEEE Transactions on image processing,11,3362-3374,IEEE,Most subsampled filter banks lack the feature of translation invariance. which is an important characteristic in denoising applications. In this paper. we study and develop new methods to convert a general multichannel. multidimensional filter bank to a corresponding translation-invariant (TI) framework. In particular. we propose a generalized algorithme agrave trous. which is an extension of the algorithme agrave trous introduced for 1-D wavelet transforms. Using the proposed algorithm. as well as incorporating modified versions of directional filter banks. we construct the TI contourlet transform (TICT). To reduce the high redundancy and complexity of the TICT. we also introduce semi-translation-invariant contourlet transform (STICT). Then. we employ an adapted bivariate shrinkage scheme to the STICT to achieve an efficient image denoising approach. Our experimental results demonstrate the benefits and …,True,GJaAw1EAAAAJ:PoWvk5oyLR8C,222,https://ieeexplore.ieee.org/abstract/document/1709981/,13648010826056400224,/scholar?cites=13648010826056400224,,,https://www.researchgate.net/profile/Hayder_Radha/publication/6720900_Translation-Invariant_Contourlet_Transform_and_Its_Application_to_Image_Denoising/links/54216d6c0cf203f155c68db5.pdf,0,0,0
1277591,The contourlet transform for image denoising using cycle spinning,2003,Ramin Eslami and Hayder Radha,2,,,1982-1986,IEEE,A new method for image denoising based on the contourlet transform. which has been recently introduced is presented in this paper. Image denoising by means of the contourlet transform introduces many visual artifacts due to the Gibbs-Iike phenomena. Due to the lack of translation invariance of the contourlet transform. we employ a cycle-spinning-based technique to develop translation invariant contourlet denoising scheme. This scheme achieves enhanced estimation results for images that are corrupted with additive Gaussian noise over a wide range of noise variance. Our experiments show that the proposed approach outperforms the translation invariant wavelets both visually and in terms of the PSNR values. especially for the images that include mostly fine textures and contours.,True,GJaAw1EAAAAJ:e_rmSamDkqQC,204,https://ieeexplore.ieee.org/abstract/document/1292328/,13349415490481664086,/scholar?cites=13349415490481664086,,,https://www.researchgate.net/profile/Hayder_Radha/publication/4072000_The_contourlet_transform_for_image_denoising_using_cycle_spinning/links/54216d750cf203f155c68f07/The-contourlet-transform-for-image-denoising-using-cycle-spinning.pdf,0,0,0
1277592,A hybrid temporal-SNR fine-granular scalability for internet video,2001,Mihaela Van Der Schaar and Hayder Radha,11,IEEE Transactions on circuits and systems for video technology,3,318-331,IEEE,Transmission of video over bandwidth varying networks like the Internet requires a highly scalable solution capable of adapting to the network condition in real-time. To address this requirement. scalable video-coding schemes with multiple enhancement layers have been proposed. However. under this multiple-layer paradigm. the transmission bit-rate of each layer has to be predetermined at encoding time. Consequently. the range of bit-rates that can be covered with these compression schemes is limited and often lower than. or different from. the desired range required at transmission time. In this paper. a novel scalable video-coding framework and a corresponding compression method for Internet video streaming are introduced. Building upon the MPEG-4 SNR fine-granular-scalability (FGS) approach. the proposed framework provides a new level of abstraction between the encoding and transmission process …,True,GJaAw1EAAAAJ:GFxP56DSvIMC,199,https://ieeexplore.ieee.org/abstract/document/911158/,18117398374003291769,/scholar?cites=18117398374003291769,,,http://medianetlab.ee.ucla.edu/papers/2.pdf,0,0,0
1277593,Seamless splicing of MPEG-2 multimedia data streams,2004,Hayder Radha and Mahesh Balakrishnan and Kavitha Parthasarathy,,,,,,Respective encoders provide a first and second encoded MPEG-2 data streams for a first and second program respectively. Each stream includes at least video and audio components. The encoder provides seamless video splice-in and splice-out points. A play-to-air splicer is commanded to switch the broadcast output from the first input stream to the second input streams. The splicer identifies approximately aligned seamless video splice-in and seamless video splice-out points in the respective first and second video streams. The splicer splices the second video stream to the first video stream. but continues to broadcast the first audio stream. The splicer identifies corresponding audio splice-in and splice-out points. The splicer splices the second audio component to the first audio component. The splicer adjusts the decode and presentation times in the second stream after the respective slice-in to be consistent …,True,GJaAw1EAAAAJ:4TOpqqG69KYC,188,https://patents.google.com/patent/US6806909B1/en,2191549484344477080,/scholar?cites=2191549484344477080,,,https://patentimages.storage.googleapis.com/3f/aa/80/24a94977fdeab7/US6806909.pdf,0,0,0
1277594,Scalable internet video using MPEG-4,1999,Hayder Radha and Yingwei Chen and Kavitha Parthasarathy and Robert Cohen,15,Signal Processing: Image Communication,1-2,95-126,Elsevier,Real-time streaming of audio-visual content over Internet Protocol (IP) based networks has enabled a wide range of multimedia applications. An Internet streaming solution has to provide real-time delivery and presentation of a continuous media content while compensating for the lack of Quality-of-Service (QoS) guarantees over the Internet. Due to the variation and unpredictability of bandwidth and other performance parameters (e.g. packet loss rate) over IP networks. in general. most of the proposed streaming solutions are based on some type of a data loss handling method and a layered video coding scheme. In this paper. we describe a real-time streaming solution suitable for non-delay-sensitive video applications such as video-on-demand and live TV viewing.The main aspects of our proposed streaming solution are:1. An MPEG-4 based scalable video coding method using both a prediction-based base …,True,GJaAw1EAAAAJ:XiVPGOgt02cC,175,https://www.sciencedirect.com/science/article/pii/S0923596599000260,8661510770013694780,/scholar?cites=8661510770013694780,,,https://core.ac.uk/download/pdf/193554395.pdf,0,0,0
1277595,Decoder buffer for streaming video receiver and method of operation,2003,Hayder Radha and Kavitha Parthasarathy,,,,,,There is disclosed a decoder buffer capable of receiving streaming video data packets and storing the data packets in a plurality of access units. Each of the access units holds at least one data packet associated with a selected frame in the streaming video. The decoder buffer comprises: 1) a first buffer region comprising at least one access unit for storing data packets that are less immediately needed by the video decoder; and 2) a re-transmission region comprising at least one access unit for storing data packets that are most immediately needed by the video decoder. The decoder buffer. in response to a detection of a missing data packet in the re-transmission region. requests that the streaming video transmitter retransmit the missing packet.,True,GJaAw1EAAAAJ:nZcligLrVowC,167,https://patents.google.com/patent/US6629318B1/en,17941271694189266582,/scholar?cites=17941271694189266582,,,https://patentimages.storage.googleapis.com/77/7e/eb/7ca7a96205a104/US6629318.pdf,0,0,0
1277596,Unequal packet loss resilience for fine-granular-scalability video,2001,Mihaela van der Schaar and Hayder Radha,3,IEEE Transactions on Multimedia,4,381-394,IEEE,Several embedded video coding schemes have been recently developed for multimedia streaming over IP. In particular. fine-granular-scalability (FGS) video coding has been recently adopted by the MPEG-4 standard as the core video-compression method for streaming applications. From its inception. the FGS scalability structure was designed to be packet-loss resilient especially under unequal packet-loss protection (UPP). However. since the introduction of FGS. there has not been a comprehensive study evaluating its packet-loss resilience under unrecoverable packet losses that are common in Internet streaming applications. In this paper. we evaluate two important aspects of FGS packet-loss resilience. First. we study the impact of applying UPP between the base- and enhancement-layers on FGS-based streams. and we compare equal packet-loss protection (EPP) with UPP scenarios. Second. we introduce …,True,GJaAw1EAAAAJ:abG-DnoFyZgC,152,https://ieeexplore.ieee.org/abstract/document/966110/,6272366541182315310,/scholar?cites=6272366541182315310,,,http://medianetlab.ee.ucla.edu/papers/3.pdf,0,0,0
1277597,Method for efficient retransmission timeout estimation in NACK-based protocols,2005,Dmitri Loguinov and Hayder Radha,,,,,,Disclosed is a system and method for estimating retransmission timeout (RTO) in a real-time streaming applications over the Internet between a server and a client. Accordingly. the present invention employs retransmission timeout (RTO) in NACK-based applications to support multiple retransmission attempts per lost packet. wherein the RTO is estimated by an actual around-trip delay (RTT) and a smooth inter-packet delay variance.,True,GJaAw1EAAAAJ:86PQX7AUzd4C,151,https://patents.google.com/patent/US6907460B2/en,14683814814078759600,/scholar?cites=14683814814078759600,,,https://patentimages.storage.googleapis.com/e1/84/b7/781b1713b1b226/US6907460.pdf,0,0,0
1277598,Adaptive degraded document image binarization,2006,Basilios Gatos and Ioannis Pratikakis and Stavros J Perantonis,39,Pattern recognition,3,317-327,Pergamon,This paper presents a new adaptive approach for the binarization and enhancement of degraded documents. The proposed method does not require any parameter tuning by the user and can deal with degradations which occur due to shadows. non-uniform illumination. low contrast. large signal-dependent noise. smear and strain. We follow several distinct steps: a pre-processing procedure using a low-pass Wiener filter. a rough estimation of foreground regions. a background surface calculation by interpolating neighboring background intensities. a thresholding by combining the calculated background surface with the original image while incorporating image up-sampling and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. After extensive experiments. our method demonstrated superior performance against four (4) well-known techniques on …,True,lCVokogAAAAJ:u5HHmVD_uO8C,706,https://www.sciencedirect.com/science/article/pii/S0031320305003821,12042145634159388474,/scholar?cites=12042145634159388474,,,https://users.iit.demokritos.gr/~bgat/PatRec2006.pdf,0,0,0
1277599,ICDAR 2009 document image binarization contest (DIBCO 2009),2009,Basilis Gatos and Konstantinos Ntirogiannis and Ioannis Pratikakis,,,,1375-1382,IEEE,DIBCO 2009 is the first International Document Image Binarization Contest organized in the context of ICDAR 2009 conference. The general objective of the contest is to identify current advances in document image binarization using established evaluation performance measures. This paper describes the contest details including the evaluation measures used as well as the performance of the 43 submitted methods along with a short description of each method.,True,lCVokogAAAAJ:2osOgNQ5qMEC,377,https://ieeexplore.ieee.org/abstract/document/5277767/,12888309301448973021,/scholar?cites=12888309301448973021,,,https://www.academia.edu/download/44158993/3725b375.pdf,0,0,0
1277600,ICDAR 2013 document image binarization contest (DIBCO 2013),2013,Ioannis Pratikakis and Basilis Gatos and Konstantinos Ntirogiannis,,,,1471-1476,IEEE,DIBCO 2013 is the international Document Image Binarization Contest organized in the context of ICDAR 2013 conference. The general objective of the contest is to identify current advances in document image binarization for both machine-printed and handwritten document images using evaluation performance measures that conform to document image analysis and recognition. This paper describes the contest details including the evaluation measures used as well as the performance of the 23 submitted methods along with a short description of each method.,True,lCVokogAAAAJ:qUcmZB5y_30C,326,https://ieeexplore.ieee.org/abstract/document/6628857/,17758204742660239277,/scholar?cites=17758204742660239277,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.5291&rep=rep1&type=pdf,0,0,0
1277601,Text line and word segmentation of handwritten documents,2009,Georgios Louloudis and Basilios Gatos and Ioannis Pratikakis and Constantin Halatsis,42,Pattern recognition,12,3169-3183,Pergamon,In this paper. we present a segmentation methodology of handwritten documents in their distinct entities. namely. text lines and words. Text line segmentation is achieved by applying Hough transform on a subset of the document image connected components. A post-processing step includes the correction of possible false alarms. the detection of text lines that Hough transform failed to create and finally the efficient separation of vertically connected characters using a novel method based on skeletonization. Word segmentation is addressed as a two class problem. The distances between adjacent overlapped components in a text line are calculated using the combination of two distance metrics and each of them is categorized either as an inter- or an intra-word distance in a Gaussian mixture modeling framework. The performance of the proposed methodology is based on a consistent and concrete evaluation …,True,lCVokogAAAAJ:IjCSPb-OGe4C,253,https://www.sciencedirect.com/science/article/pii/S0031320308005335,13992227749798385638,/scholar?cites=13992227749798385638,,,http://courses.cs.tau.ac.il/0368-4341/shared/Papers/Alignment/Louloud_1_2009.pdf,0,0,0
1277602,H-DIBCO 2010-handwritten document image binarization competition,2010,Ioannis Pratikakis and Basilis Gatos and Konstantinos Ntirogiannis,,,,727-732,IEEE,H-DIBCO 2010 is the International Document Image Binarization Contest which is dedicated to handwritten document images organized in conjunction with ICFHR 2010 conference. The general objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 17 submitted methods along with a short description of each method.,True,lCVokogAAAAJ:LO7wyVUgiFcC,234,https://ieeexplore.ieee.org/abstract/document/5693650/,4092835164711883986,/scholar?cites=4092835164711883986,,,https://www.academia.edu/download/44159031/H-DIBCO_2010_-_Handwritten_Document_Imag20160327-28069-1expk0r.pdf,0,0,0
1277603,Efficient 3D shape matching and retrieval using a concrete radialized spherical projection representation,2007,Panagiotis Papadakis and Ioannis Pratikakis and Stavros Perantonis and Theoharis Theoharis,40,Pattern Recognition,9,2437-2452,Pergamon,We present a 3D shape retrieval methodology based on the theory of spherical harmonics. Using properties of spherical harmonics. scaling and axial flipping invariance is achieved. Rotation normalization is performed by employing the continuous principal component analysis along with a novel approach which applies PCA on the face normals of the model. The 3D model is decomposed into a set of spherical functions which represents not only the intersections of the corresponding surface with rays emanating from the origin but also points in the direction of each ray which are closer to the origin than the furthest intersection point. The superior performance of the proposed methodology is demonstrated through a comparison against state-of-the-art approaches on standard databases.,True,lCVokogAAAAJ:d1gkVwhDpl0C,228,https://www.sciencedirect.com/science/article/pii/S0031320307000106,8967594556235432347,/scholar?cites=8967594556235432347,,,https://hal.inria.fr/docs/00/75/89/64/PDF/p27.pdf,0,0,0
1277604,Panorama: A 3d shape descriptor based on panoramic views for unsupervised 3d object retrieval,2010,Panagiotis Papadakis and Ioannis Pratikakis and Theoharis Theoharis and Stavros Perantonis,89,International Journal of Computer Vision,2,177-192,Springer US,We present a novel 3D shape descriptor that uses a set of panoramic views of a 3D object which describe the position and orientation of the object’s surface in 3D space. We obtain a panoramic view of a 3D object by projecting it to the lateral surface of a cylinder parallel to one of its three principal axes and centered at the centroid of the object. The object is projected to three perpendicular cylinders. each one aligned with one of its principal axes in order to capture the global shape of the object. For each projection we compute the corresponding 2D Discrete Fourier Transform as well as 2D Discrete Wavelet Transform. We further increase the retrieval performance by employing a local (unsupervised) relevance feedback technique that shifts the descriptor of an object closer to its cluster centroid in feature space. The effectiveness of the proposed 3D object retrieval methodology is demonstrated via an …,True,lCVokogAAAAJ:LkGwnXOMwfcC,220,https://link.springer.com/article/10.1007/s11263-009-0281-6,16186330522221908478,/scholar?cites=16186330522221908478,,,https://hal.inria.fr/docs/00/75/89/78/PDF/p34.pdf,0,0,0
1277605,3D mesh segmentation methodologies for CAD applications,2007,Alexander Agathos and Ioannis Pratikakis and Stavros Perantonis and Nikolaos Sapidis and Philip Azariadis,4,Computer-Aided Design and Applications,6,827-841,Taylor & Francis,3D mesh segmentation is a fundamental process for Digital Shape Reconstruction in a variety of applications including Reverse Engineering. Medical Imaging. etc. It is used to provide a high level representation of the raw 3D data which is required for CAD. CAM and CAE. In this paper. we present an exhaustive overview of 3D mesh segmentation methodologies examining their suitability for CAD models. In particular. a classification of the various methods is given based on their corresponding underlying fundamental methodology concept as well as on the distinct criteria and features used in the segmentation process.,True,lCVokogAAAAJ:qjMakFHDy7sC,201,https://www.tandfonline.com/doi/abs/10.1080/16864360.2007.10738515,1959593363187182244,/scholar?cites=1959593363187182244,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.481.229&rep=rep1&type=pdf,0,0,0
1277606,An adaptive binarization technique for low quality historical documents,2004,Basilios Gatos and Ioannis Pratikakis and Stavros J Perantonis,,,,102-113,Springer. Berlin. Heidelberg,Historical document collections are a valuable resource for human history. This paper proposes a novel digital image binarization scheme for low quality historical documents allowing further content exploitation in an efficient way. The proposed scheme consists of five distinct steps: a pre-processing procedure using a low-pass Wiener filter. a rough estimation of foreground regions using Niblack’s approach. a background surface calculation by interpolating neighboring background intensities. a thresholding by combining the calculated background surface with the original image and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. The proposed methodology works with great success even in cases of historical manuscripts with poor quality. shadows. nonuniform illumination. low contrast. large signal- dependent noise. smear and strain. After …,True,lCVokogAAAAJ:XvxMoLDsR5gC,194,https://link.springer.com/chapter/10.1007/978-3-540-28640-0_10,12859936210084405190,/scholar?cites=12859936210084405190,,,https://link.springer.com/content/pdf/10.1007/978-3-540-28640-0_10.pdf,0,0,0
1277607,Shape retrieval on non-rigid 3D watertight meshes,2011,Z Lian and A Godil and B Bustos and M Daoudi and J Hermans and S Kawamura and Y Kurita and G Lavoua and P Dp Suetens,,Eurographics workshop on 3d object retrieval (3DOR),,,,Non-rigid 3D shape retrieval has become an important research topic in content-based 3D object retrieval. The aim of this track is to measure and compare the performance of non-rigid 3D shape retrieval methods implemented by different participants around the world. The track is based on a new non-rigid 3D shape benchmark. which contains 600 watertight triangle meshes that are equally classified into 30 categories. In this track. 25 runs have been submitted by 9 groups and their retrieval accuracies were evaluated using 6 commonly-utilized measures.,True,lCVokogAAAAJ:FPJr55Dyh1AC,177,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.375.549&rep=rep1&type=pdf,12887351191063888129,/scholar?cites=12887351191063888129,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.375.549&rep=rep1&type=pdf,0,0,0
1277608,Text line detection in handwritten documents,2008,Georgios Louloudis and Basilios Gatos and Ioannis Pratikakis and Constantin Halatsis,41,Pattern Recognition,12,3758-3772,Pergamon,In this paper. we present a new text line detection method for handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes image binarization and enhancement. connected component extraction. partitioning of the connected component domain into three spatial sub-domains and average character height estimation. In the second step. a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible splitting. to detect text lines that the previous step did not reveal and. finally. to separate vertically connected characters and assign them to text lines. The performance evaluation of the proposed approach is based on a consistent and concrete evaluation methodology.,True,lCVokogAAAAJ:eQOLeE2rZwMC,153,https://www.sciencedirect.com/science/article/pii/S0031320308001775,16399655465827235250,/scholar?cites=16399655465827235250,,,https://www.academia.edu/download/38302263/Louloud2008.pdf,0,0,0
1277609,Adaptive degraded document image binarization,2006,Basilios Gatos and Ioannis Pratikakis and Stavros J Perantonis,39,Pattern recognition,3,317-327,Pergamon,This paper presents a new adaptive approach for the binarization and enhancement of degraded documents. The proposed method does not require any parameter tuning by the user and can deal with degradations which occur due to shadows. non-uniform illumination. low contrast. large signal-dependent noise. smear and strain. We follow several distinct steps: a pre-processing procedure using a low-pass Wiener filter. a rough estimation of foreground regions. a background surface calculation by interpolating neighboring background intensities. a thresholding by combining the calculated background surface with the original image while incorporating image up-sampling and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. After extensive experiments. our method demonstrated superior performance against four (4) well-known techniques on …,True,0bNXadoAAAAJ:u5HHmVD_uO8C,706,https://www.sciencedirect.com/science/article/pii/S0031320305003821,12042145634159388474,/scholar?cites=12042145634159388474,,,https://users.iit.demokritos.gr/~bgat/PatRec2006.pdf,0,0,0
1277610,ICDAR 2009 document image binarization contest (DIBCO 2009),2009,Basilis Gatos and Konstantinos Ntirogiannis and Ioannis Pratikakis,,,,1375-1382,IEEE,DIBCO 2009 is the first International Document Image Binarization Contest organized in the context of ICDAR 2009 conference. The general objective of the contest is to identify current advances in document image binarization using established evaluation performance measures. This paper describes the contest details including the evaluation measures used as well as the performance of the 43 submitted methods along with a short description of each method.,True,0bNXadoAAAAJ:M05iB0D1s5AC,377,https://ieeexplore.ieee.org/abstract/document/5277767/,12888309301448973021,/scholar?cites=12888309301448973021,,,https://www.academia.edu/download/44158993/3725b375.pdf,0,0,0
1277611,ICDAR 2013 document image binarization contest (DIBCO 2013),2013,Ioannis Pratikakis and Basilis Gatos and Konstantinos Ntirogiannis,,,,1471-1476,IEEE,DIBCO 2013 is the international Document Image Binarization Contest organized in the context of ICDAR 2013 conference. The general objective of the contest is to identify current advances in document image binarization for both machine-printed and handwritten document images using evaluation performance measures that conform to document image analysis and recognition. This paper describes the contest details including the evaluation measures used as well as the performance of the 23 submitted methods along with a short description of each method.,True,0bNXadoAAAAJ:_xSYboBqXhAC,326,https://ieeexplore.ieee.org/abstract/document/6628857/,17758204742660239277,/scholar?cites=17758204742660239277,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.723.5291&rep=rep1&type=pdf,0,0,0
1277612,Text line and word segmentation of handwritten documents,2009,Georgios Louloudis and Basilios Gatos and Ioannis Pratikakis and Constantin Halatsis,42,Pattern recognition,12,3169-3183,Pergamon,In this paper. we present a segmentation methodology of handwritten documents in their distinct entities. namely. text lines and words. Text line segmentation is achieved by applying Hough transform on a subset of the document image connected components. A post-processing step includes the correction of possible false alarms. the detection of text lines that Hough transform failed to create and finally the efficient separation of vertically connected characters using a novel method based on skeletonization. Word segmentation is addressed as a two class problem. The distances between adjacent overlapped components in a text line are calculated using the combination of two distance metrics and each of them is categorized either as an inter- or an intra-word distance in a Gaussian mixture modeling framework. The performance of the proposed methodology is based on a consistent and concrete evaluation …,True,0bNXadoAAAAJ:UeHWp8X0CEIC,253,https://www.sciencedirect.com/science/article/pii/S0031320308005335,13992227749798385638,/scholar?cites=13992227749798385638,,,http://courses.cs.tau.ac.il/0368-4341/shared/Papers/Alignment/Louloud_1_2009.pdf,0,0,0
1277613,H-DIBCO 2010-handwritten document image binarization competition,2010,Ioannis Pratikakis and Basilis Gatos and Konstantinos Ntirogiannis,,,,727-732,IEEE,H-DIBCO 2010 is the International Document Image Binarization Contest which is dedicated to handwritten document images organized in conjunction with ICFHR 2010 conference. The general objective of the contest is to identify current advances in handwritten document image binarization using meaningful evaluation performance measures. This paper reports on the contest details including the evaluation measures used as well as the performance of the 17 submitted methods along with a short description of each method.,True,0bNXadoAAAAJ:HoB7MX3m0LUC,234,https://ieeexplore.ieee.org/abstract/document/5693650/,4092835164711883986,/scholar?cites=4092835164711883986,,,https://www.academia.edu/download/44159031/H-DIBCO_2010_-_Handwritten_Document_Imag20160327-28069-1expk0r.pdf,0,0,0
1277614,ICDAR 2009 page segmentation competition,2009,Apostolos Antonacopoulos and Stefan Pletschacher and David Bridson and Christos Papadopoulos,,,,1370-1374,IEEE,This paper presents an objective comparative evaluation of layout analysis methods in realistic circumstances. It describes the Page Segmentation competition (modus operandi. dataset and evaluation methodology) held in the context of ICDAR2009 and presents the results of the evaluation of four submitted methods. Two state-of-the art methods are also compared as well as the three methods from the ICDA2007 Page Segmentation competition. The results indicate that although methods continue to mature. there is still a considerable need to develop robust methods that deal with everyday documents.,True,0bNXadoAAAAJ:jmjb1lOE9QIC,223,https://ieeexplore.ieee.org/abstract/document/5277763/,12585338285697972372,/scholar?cites=12585338285697972372,,,https://users.iit.demokritos.gr/~bgat/ICDAR2005_PageSegmComp.pdf,0,0,0
1277615,A new approach for multilevel threshold selection,1994,Nikos Papamarkos and Basilios Gatos,56,CVGIP: Graphical Models and Image Processing,5,357-370,Academic Press,This paper describes a new method for multilevel threshold selection of gray level images. The proposed method includes three main stages. First. a hill-clustering technique is applied to the image histogram in order to approximately determine the peak locations of the histogram. Then. the histogram segments between the peaks are approximated by rational functions using a linear minimax approximation algorithm. Finally. the application of the one-dimensional Golden search minimization algorithm gives the global minimum of each rational function. which corresponds to a multilevel threshold value. Experimental results for histograms with two or more peaks are presented.,True,0bNXadoAAAAJ:u-x6o8ySG0sC,207,https://www.sciencedirect.com/science/article/pii/S1049965284710339,12767609446051075856,/scholar?cites=12767609446051075856,,,https://pdfs.semanticscholar.org/1d82/37039244543cf8bca7cc022cf6c8e39aa260.pdf,0,0,0
1277616,An adaptive binarization technique for low quality historical documents,2004,Basilios Gatos and Ioannis Pratikakis and Stavros J Perantonis,,,,102-113,Springer. Berlin. Heidelberg,Historical document collections are a valuable resource for human history. This paper proposes a novel digital image binarization scheme for low quality historical documents allowing further content exploitation in an efficient way. The proposed scheme consists of five distinct steps: a pre-processing procedure using a low-pass Wiener filter. a rough estimation of foreground regions using Niblack’s approach. a background surface calculation by interpolating neighboring background intensities. a thresholding by combining the calculated background surface with the original image and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. The proposed methodology works with great success even in cases of historical manuscripts with poor quality. shadows. nonuniform illumination. low contrast. large signal- dependent noise. smear and strain. After …,True,0bNXadoAAAAJ:9yKSN-GCB0IC,194,https://link.springer.com/chapter/10.1007/978-3-540-28640-0_10,12859936210084405190,/scholar?cites=12859936210084405190,,,https://link.springer.com/content/pdf/10.1007/978-3-540-28640-0_10.pdf,0,0,0
1277617,ICDAR 2013 handwriting segmentation contest,2013,Nikolaos Stamatopoulos and Basilis Gatos and Georgios Louloudis and Umapada Pal and Alireza Alaei,,,,1402-1406,IEEE,This paper presents the results of the Handwriting Segmentation Contest that was organized in the context of the ICDAR2013. The general objective of the contest was to use well established evaluation practices and procedures to record recent advances in off-line handwriting segmentation. Two benchmarking datasets. one for text line and one for word segmentation. were created in order to test and compare all submitted algorithms as well as some state-of-the-art methods for handwritten document image segmentation in realistic circumstances. Handwritten document images were produced by many writers in two Latin based languages (English and Greek) and in one Indian language (Bangla. the second most popular language in India). These images were manually annotated in order to produce the ground truth which corresponds to the correct text line and word segmentation results. The datasets of …,True,0bNXadoAAAAJ:wvYxNZNCP7wC,176,https://ieeexplore.ieee.org/abstract/document/6628844/,16783471256985435664,/scholar?cites=16783471256985435664,,,https://www.academia.edu/download/42525350/ICDAR_2013_Handwriting_Segmentation_Cont20160209-11614-hu1c35.pdf,0,0,0
1277618,ICDAR2009 handwriting segmentation contest,2011,Basilios Gatos and Nikolaos Stamatopoulos and Georgios Louloudis,14,International Journal on Document Analysis and Recognition (IJDAR),1,25-33,Springer-Verlag,ICDAR 2009 Handwriting Segmentation Contest was organized in the context of ICDAR2009 conference in order to record recent advances in off-line handwriting segmentation. The contest includes handwritten document images produced by many writers in several languages (English. French. German and Greek). These images are manually annotated in order to produce the ground truth which corresponds to the correct text line and word segmentation result. For the evaluation. a well-established approach is used based on counting the number of matches between the entities detected by the segmentation algorithm and the entities in the ground truth. This paper describes the contest details including the dataset. the ground truth and the evaluation criteria and presents the results of the 12 participating methods as well as of two state-of-the-art algorithms. A description of the winning algorithms is also given.,True,0bNXadoAAAAJ:7H_MAutzIkAC,161,https://link.springer.com/content/pdf/10.1007/s10032-010-0122-8.pdf,3467467913261062484,/scholar?cites=3467467913261062484,,,https://users.iit.demokritos.gr/~bgat/ICDAR2009HandRecCont.pdf,0,0,0
1277619,Text line detection in handwritten documents,2008,Georgios Louloudis and Basilios Gatos and Ioannis Pratikakis and Constantin Halatsis,41,Pattern Recognition,12,3758-3772,Pergamon,In this paper. we present a new text line detection method for handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes image binarization and enhancement. connected component extraction. partitioning of the connected component domain into three spatial sub-domains and average character height estimation. In the second step. a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible splitting. to detect text lines that the previous step did not reveal and. finally. to separate vertically connected characters and assign them to text lines. The performance evaluation of the proposed approach is based on a consistent and concrete evaluation methodology.,True,0bNXadoAAAAJ:eQOLeE2rZwMC,153,https://www.sciencedirect.com/science/article/pii/S0031320308001775,16399655465827235250,/scholar?cites=16399655465827235250,,,https://www.academia.edu/download/38302263/Louloud2008.pdf,0,0,0
1277620,Functional engraftment of human ES cell–derived dopaminergic neurons enriched by coculture with telomerase-immortalized midbrain astrocytes,2006,Neeta S Roy and Carine Cleren and Shashi K Singh and Lichuan Yang and M Flint Beal and Steven A Goldman,12,Nature medicine,11,1259-1268,Nature Publishing Group,To direct human embryonic stem (HES) cells to a dopaminergic neuronal fate. we cocultured HES cells that were exposed to both sonic hedgehog and fibroblast growth factor 8 with telomerase-immortalized human fetal midbrain astrocytes. These astrocytes substantially potentiated dopaminergic neurogenesis by both WA09 and WA01 HES cells. biasing them to the A9 nigrostriatal phenotype. When transplanted into the neostriata of 6-hydroxydopamine–lesioned parkinsonian rats. the dopaminergic implants yielded a significant. substantial and long-lasting restitution of motor function. However. although rich in donor-derived tyrosine hydroxylase–expressing neurons. the grafts exhibited expanding cores of undifferentiated mitotic neuroepithelial cells. which can be tumorigenic. These results show the utility of recreating the cellular environment of the developing human midbrain while driving dopaminergic …,True,_40wBy8AAAAJ:xyKys1DtkaQC,893,https://www.nature.com/articles/nm1495,759998613498146986,/scholar?cites=759998613498146986,,,https://www.researchgate.net/profile/M_Beal/publication/6737727_Corrigendum_Functional_engraftment_of_human_ES_cell-derived_dopaminergic_neurons_enriched_by_coculture_with_telomerase-immortalized_midbrain_astrocytes/links/00463515af41a8f263000000/Corrigendum-Functional-engraftment-of-human-ES-cell-derived-dopaminergic-neurons-enriched-by-coculture-with-telomerase-immortalized-midbrain-astrocytes.pdf,0,0,0
1277621,Measuring arthropod biodiversity in the tropical forest canopy.,1995,Terry L Erwin,,Forest canopies.,,109-127,Academic Press,A historical review of what has been achieved with arthropod diversity sampling sampling Subject Category: Techniques. Methodologies and Equipment,True,_40wBy8AAAAJ:yIkSIh5mphAC,156,https://www.cabdirect.org/cabdirect/abstract/19960603745,11090231147645294103,/scholar?cites=11090231147645294103,,,,0,0,0
1277622,EIS support for the strategic management process,2002,Sanjay K Singh and Hugh J Watson and Richard T Watson,33,Decision Support Systems,1,71-85,North-Holland,The success of an executive information system (EIS) depends upon many factors. including providing support for the strategic management process (SMP). The SMP is comprised of five phases: organizational objectives. environmental scanning. strategy formulation. strategy implementation. and strategic control. The study empirically investigated (1) the support of EISs for the phases of the SMP and (2) the relationship between the amount of support provided and EIS success. Data were collected from EIS professionals and executive users in 51 organizations. Descriptive statistics were calculated and correlation analysis was used to test the hypothesized relationships. It was found that the success of an EIS is related to its support for operational objectives and strategy implementation. The findings can be understood by considering the conditions that surround the development of an EIS and revisiting the …,True,_40wBy8AAAAJ:iC1Mcd5kvfwC,119,https://www.sciencedirect.com/science/article/pii/S0167923601001294,17463597653150053381,/scholar?cites=17463597653150053381,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.3046&rep=rep1&type=pdf,0,0,0
1277623,Assessment of genetic variability for yield and its component characters in rice (Oryza sativa L.),2011,Sangam Kumar Singh and Chandra Mohan Singh and GM Lal,1,Research in Plant Biology,4,,,Eighty one rice (Oryza sativa L.) genotypes were evaluated during kharif 2010 for thirteen quantitative traits to examine the nature and magnitude of variability. heritability (broad sense) and genetic advance. Analysis of variance revealed that the differences among eighty one genotypes were significant for all the characters except flag leaf width. Among the all traits number of spikelets per panicle exhibited high estimates of genotypic coefficient of variation (GCV) and phenotypic coefficient of variation (PCV) followed by harvest index. grain yield per hill and number of panicles per hill. Broad sense heritability was highest for biological yield per hill. which suggested that this trait would respond to selection owing their high genetic variability and transmissibility. Maximum genetic advance as per cent of mean was recorded for number of spikelets per panicle with high value of heritability.,True,_40wBy8AAAAJ:vytXtR8tOLIC,110,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.863.3827&rep=rep1&type=pdf,11211054032471508964,/scholar?cites=11211054032471508964,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.863.3827&rep=rep1&type=pdf,0,0,0
1277624,Anthropometric characteristics. somatotyping and body composition of volleyball and basketball players,2010,Vishaw Gaurav and Sukhdev Singh,1,Journal of Physical Education and Sport Management,3,28-32,Academic Journals,The purpose of the study was to compare the anthropometric characteristics and somatotype of the Guru Nanak Dev University. Amritsar’s male basketball players and volleyball players. Sixty three sportspersons (volleyball= 36 and basketball= 27) of age group 18-25 years were selected from different colleges affiliated to Guru Nanak Dev University. Amritsar. Punjab. India. All the participants were assessed for height. weight. breadths. girths and skin fold thickness. An independent samples t-test revealed that basketball players had significantly higher height (p< 0.01). weight (p< 0.01) and body surface area (p< 0.01) as compared to volleyball players. The basketball players were also found to have significantly greater biceps (p< 0.01) and suprailliac (p< 0.01) skin fold thicknesses. calf circumference (p< 0.05). percent body fat (p< 0.01). total body fat (p< 0.01). fat free mass (p< 0.05) and endomorphic component (p< 0.05) as compared to volleyball players. Volleyball players had significantly greater body density (p< 0.01) as compared to basketball players. The basketball and volleyball players of this study were found to have higher percentage body fat with lower body height and body weight than their international counterparts. Further investigations are needed on the above studied variables along with fitness and physiological variables to assess relationships among them and with performances in volleyball and basketball.,True,_40wBy8AAAAJ:Liyi5BL3lGIC,103,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.955.342&rep=rep1&type=pdf,1938720554625874579,/scholar?cites=1938720554625874579,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.955.342&rep=rep1&type=pdf,0,0,0
1277625,Vital role of nanopolymers in drilling and stimulations fluid applications,2010,Subodh Kumar Singh and Ramadan Mohammed Ahmed and Fred Growcock,,,,,Society of Petroleum Engineers,Production of hydrocarbons from conventional as well as unconventional resources is becoming increasingly more difficult and expensive. Drilling fluid stability and performance in deeper. high-pressure high-temperature (HPHT) formations is still problematic. even for environmentally safer synthetic fluids.,True,_40wBy8AAAAJ:_elGeoH1qXkC,84,https://onepetro.org/conference-paper/SPE-130413-MS,2954143694438717527,/scholar?cites=2954143694438717527,,,https://www.researchgate.net/profile/Subodh_Singh/publication/254531584_Vital_Role_of_Nanopolymers_in_Drilling_and_Stimulations_Fluid_Applications/links/577e7fe508aed807ae7b1bfd.pdf,0,0,0
1277626,Review of human-elephant conflict mitigation measures practiced in South Asia,2008,Prithiviraj Fernando and M Ananda Kumar and A Christy Williams and Eric Wikramanayake and Tariq Aziz and Sameer M Singh,,,,,WWF,Objective:Guarding of crops is conducted by farmers with different levels of organization ranging from guarding isolated fields by individual farmers to guarding the peripheries of contiguous fields by farmer or village societies. Farmers individually or collectively scare away elephants relying on the fear elephants. especially herds of females and young have of people. The mere presence of people in huts located within the fields may discourage elephants from raiding crops. Elevating huts on trees provides a vantage from which to observe the fields and also offers a degree of safety as well. The on-site presence of farmers also allows them to respond immediately to raiding elephants. thus minimizing damage.,True,_40wBy8AAAAJ:cMFi1P4_O6YC,80,http://sa.indiaenvironmentportal.org.in/files/review_of_human_elephant_final_reduced_01.pdf,11425100014149582381,/scholar?cites=11425100014149582381,,,http://sa.indiaenvironmentportal.org.in/files/review_of_human_elephant_final_reduced_01.pdf,0,0,0
1277627,Structure and biogenesis of the cell envelope of gram‐negative bacteria,1974,MJ Osborn and PD Rick and V Lehmann and E Rupprecht and M Singh,235,,1,52-65,Blackwell Publishing Ltd,The cell envelope of gram-negative enteric bacteria is a complex structure that differs from the wall of gram-positive bacteria. both in composition and in supramolecular organization. Morphological and biochemical studies over the past several years 27 have defined three distinct layers (FIGURE 1): an inner. cytoplasmic membrane. similar to that of gram-positive bacteria; a thin peptidoglycan or murein layer. which corresponds to the cell wall proper of gram-positive cells; and. in addition. a second membranous layer. the so-called outer membrane at the external surface. It is the outer membrane that contains the lipopolysaccharide characteristic of the gram-negative envelope and that appears to confer on these organisms their relatively high levels of resistance to many antibiotics. detergents. and other agents. Furthermore. it seems that this barrier function of the outer membrane is at least in part related to its …,True,_40wBy8AAAAJ:t13vp6B-Zw8C,78,https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1974.tb43256.x,11448295200864993070,/scholar?cites=11448295200864993070,,,,0,0,0
1277628,Diseases of poverty and lifestyle. well-being and human development,2008,Ajai R Singh and Shakuntala A Singh,6,Mens sana monographs,1,187,Wolters Kluwer--Medknow Publications,The problems of the haves differ substantially from those of the have-nots. Individuals in developing societies have to fight mainly against infectious and communicable diseases. while in the developed world the battles are mainly against lifestyle diseases. Yet. at a very fundamental level. the problems are the same-the fight is against distress. disability. and premature death; against human exploitation and for human development and self-actualisation; against the callousness to critical concerns in regimes and scientific power centres.,True,_40wBy8AAAAJ:uy1uh4dpqf0C,76,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3190550/,2068867757677001095,/scholar?cites=2068867757677001095,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3190550/,0,0,0
1277629,Anti-inflammatory activity of lupeol,1997,S Singh and S Bani and GB Singh and BD Gupta and SK Banerjee,68,Fitoterapia (Milano),1,9-16,,Sauf mention contraire ci-dessus. le contenu de cette notice bibliographique peut être utilisé dans le cadre d’une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above. the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya señalado antes. el contenido de este registro bibliográfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS,True,_40wBy8AAAAJ:lAvqOWfki2wC,76,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=2623873,1970481538723796261,/scholar?cites=1970481538723796261,,,,0,0,0
1277630,Technical feasibility study of butanol–gasoline blends for powering medium-duty transportation spark ignition engine,2015,Suraj Bhan Singh and Atul Dhar and Avinash Kumar Agarwal,76,Renewable Energy,,706-716,Pergamon,Amongst primary alcohols. butanol is considered as the most promising alternative fuel candidate because of its favourable chemical and physical properties. which are quite similar to gasoline. Butanol is completely miscible with gasoline in any proportion and forms a stable blend. It is not hygroscopic in nature therefore does not absorb moisture from the atmosphere similar to ethanol and methanol. which makes it a superior alternate fuel. Experiments are conducted on 5. 10. 20. 50 and 75% butanol–gasoline blends for evaluating their engine performance. emissions and combustion characteristics in a medium-duty transportation spark ignition (SI) engine. The engine was suitably instrument for the experiments. Engine performance was evaluated by finding performance parameters such as brake specific fuel consumption (BSFC). power output and torque. thermal efficiency and exhaust gas temperature of …,True,_40wBy8AAAAJ:lIeuKFitLToC,67,https://www.sciencedirect.com/science/article/pii/S096014811400826X,6673022100000906633,/scholar?cites=6673022100000906633,,,,0,0,0
1277631,The FERET evaluation methodology for face-recognition algorithms,2000,P Jonathon Phillips and Hyeonjoon Moon and Syed A Rizvi and Patrick J Rauss,22,IEEE Transactions on pattern analysis and machine intelligence,10,1090-1104,IEEE,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date. 14.126 images from 1.199 individuals are included in the FERET database. which is divided into development and sequestered portions of the database. In September 1996. the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to 1) assess the state of the art. 2) identify future areas of research. and 3) measure algorithm performance.,True,eFKUKPwAAAAJ:u5HHmVD_uO8C,6158,https://ieeexplore.ieee.org/abstract/document/879790/,13683523000892554956,/scholar?cites=13683523000892554956,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.9852&rep=rep1&type=pdf,0,0,0
1277632,Computational and performance aspects of PCA-based face-recognition algorithms,2001,Hyeonjoon Moon and P Jonathon Phillips,30,Perception,3,303-321,SAGE Publications,Algorithms based on principal component analysis (PCA) form the basis of numerous studies in the psychological and algorithmic face-recognition literature. PCA is a statistical technique and its incorporation into a face-recognition algorithm requires numerous design decisions. We explicitly state the design decisions by introducing a generic modular PCA-algorithm. This allows us to investigate these decisions. including those not documented in the literature. We experimented with different implementations of each module. and evaluated the different implementations using the September 1996 FERET evaluation protocol (the de facto standard for evaluating face-recognition algorithms). We experimented with (i) changing the illumination normalization procedure; (ii) studying effects on algorithm performance of compressing images with JPEG and wavelet compression algorithms; (iii) varying the number of …,True,eFKUKPwAAAAJ:u-x6o8ySG0sC,644,https://journals.sagepub.com/doi/abs/10.1068/p2896,9772620086368522753,/scholar?cites=9772620086368522753,,,https://www.jordaanelectronics.com/pdfonline/face%20recognition/moon_perception.pdf,0,0,0
1277633,The FERET verification testing protocol for face recognition algorithms,1998,Syed A Rizvi and P Jonathon Phillips and Hyeonjoon Moon,,,,48-53,IEEE,Two critical performance characterizations of biometric algorithms. including face recognition. are identification and verification. Identification performance of face recognition algorithms on the FERET tests has been previously reported. We report on verification performance obtained from the Sept96 FERET test. The databases used to develop and test algorithms are usually smaller than the databases that will be encountered in applications. We examine the effects of size of the database on performance for both identification and verification.,True,eFKUKPwAAAAJ:_xSYboBqXhAC,229,https://ieeexplore.ieee.org/abstract/document/670924/,10742989652514992207,/scholar?cites=10742989652514992207,,,https://www.researchgate.net/profile/Syed_Rizvi22/publication/221292063_The_FERET_Verification_Testing_Protocol_for_Face_Recognition_Algorithms/links/02e7e527789c6cbd67000000.pdf,0,0,0
1277634,Analysis of PCA-based face recognition algorithms,1998,Hyeonjoon Moon,,"Empirical Evaluation Techniques in Computer Vision, 1998",,57-71,,"CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 … 
",True,eFKUKPwAAAAJ:d1gkVwhDpl0C,122,https://ci.nii.ac.jp/naid/10029468914/,12312154524873774614,/scholar?cites=12312154524873774614,,,,0,0,0
1277635,A survey on internet of things and cloud computing for healthcare,2019,L Minh Dang and Md Piran and Dongil Han and Kyungbok Min and Hyeonjoon Moon,8,,7,768,Multidisciplinary Digital Publishing Institute,The fast development of the Internet of Things (IoT) technology in recent years has supported connections of numerous smart things along with sensors and established seamless data exchange between them. so it leads to a stringy requirement for data analysis and data storage platform such as cloud computing and fog computing. Healthcare is one of the application domains in IoT that draws enormous interest from industry. the research community. and the public sector. The development of IoT and cloud computing is improving patient safety. staff satisfaction. and operational efficiency in the medical industry. This survey is conducted to analyze the latest IoT components. applications. and market trends of IoT in healthcare. as well as study current development in IoT and cloud computing-based healthcare applications since 2015. We also consider how promising technologies such as cloud computing. ambient assisted living. big data. and wearables are being applied in the healthcare industry and discover various IoT. e-health regulations and policies worldwide to determine how they assist the sustainable development of IoT and cloud computing in the healthcare industry. Moreover. an in-depth review of IoT privacy and security issues. including potential threats. attack types. and security setups from a healthcare viewpoint is conducted. Finally. this paper analyzes previous well-known security models to deal with security risks and provides trends. highlighted opportunities. and challenges for the IoT-based healthcare future development. View Full-Text,True,eFKUKPwAAAAJ:_Ybze24A_UAC,107,https://www.mdpi.com/2079-9292/8/7/768,16818324551750141064,/scholar?cites=16818324551750141064,,,https://www.mdpi.com/2079-9292/8/7/768/pdf,0,0,0
1277636,The feret evaluation,1998,P Jonathon Phillips and Hyeonjoon Moon and Syed Rizvi and Patrick Rauss,,,,244-261,Springer. Berlin. Heidelberg,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. The FERET database is divided into two portions. The development portion is provided to researchers for algorithm development and the sequestered portion provides a set of images not seen by the researchers to test algorithms. The set of test is the third in a sequence of FERET tests. This test was administered in September 1996 and March 1997. The Sept96 test provided a detailed assesment of the state of the art. measurement of algorithm performance on large databases. and a comparison among face recognition algorithms.,True,eFKUKPwAAAAJ:R3hNpaxXUhUC,92,https://link.springer.com/chapter/10.1007/978-3-642-72201-1_13,10134669659830934081,/scholar?cites=10134669659830934081,,,,0,0,0
1277637,The FERET september 1996 database and evaluation procedure,1997,P Jonathon Phillips and Hyeonjoon Moon and Patrick Rauss and Syed A Rizvi,,,,395-402,Springer. Berlin. Heidelberg,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. In this paper. we report on the FERET database and the September 1996 FERET test. This test is the third in a series of supervised face-recognition test administered under the FERET program.,True,eFKUKPwAAAAJ:9yKSN-GCB0IC,77,https://link.springer.com/chapter/10.1007/BFb0016020,7044335849705722211,/scholar?cites=7044335849705722211,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.6994&rep=rep1&type=pdf,0,0,0
1277638,Leukocytes classification and segmentation in microscopic blood smear: a resource-aware healthcare service in smart cities,2016,Muhammad Sajjad and Siraj Khan and Zahoor Jan and Khan Muhammad and Hyeonjoon Moon and Jin Tae Kwak and Seungmin Rho and Sung Wook Baik and Irfan Mehmood,5,IEEE Access,,3475-3489,IEEE,Smart cities are a future reality for municipalities around the world. Healthcare services play a vital role in the transformation of traditional cities into smart cities. In this paper. we present a ubiquitous and quality computer-aided blood analysis service for the detection and counting of white blood cells (WBCs) in blood samples. WBCs also called leukocytes or leucocytes are the cells of the immune system that are involved in protecting the body against both infectious disease and foreign invaders. Analysis of leukocytes provides valuable information to medical specialists. helping them in diagnosing different important hematic diseases. such as AIDS and blood cancer (Leukaemia). However. this task is prone to errors and can be time-consuming. A mobile-cloud-assisted detection and classification of leukocytes from blood smear images can enhance accuracy and speed up the detection of WBCs. In this paper. we …,True,eFKUKPwAAAAJ:eMMeJKvmdy0C,76,https://ieeexplore.ieee.org/abstract/document/7782368/,11727985420316526652,/scholar?cites=11727985420316526652,,,https://ieeexplore.ieee.org/iel7/6287639/7859429/07782368.pdf,0,0,0
1277639,Deep learning approach for short-term stock trends prediction based on two-stream gated recurrent unit network,2018,Dang Lien Minh and Abolghasem Sadeghi-Niaraki and Huynh Duc Huy and Kyungbok Min and Hyeonjoon Moon,6,Ieee Access,,55392-55404,IEEE,Financial news has been proven to be a crucial factor which causes fluctuations in stock prices. However. previous studies heavily relied on analyzing shallow features and ignored the structural relation among words in a sentence. Several sentiment analysis studies have tried to point out the relationship between investors' reaction and news events. However. the sentiment dataset was usually constructed from the lingual dataset which is unrelated to the financial sector and led to poor performance. This paper proposes a novel framework to predict the directions of stock prices by using both financial news and sentiment dictionary. The original contributions of this paper include the proposal of a novel two-stream gated recurrent unit network and Stock2Vec-a sentiment word embedding trained on financial news dataset and Harvard IV-4. Two main experiments are conducted: the first experiment predicts S&P 500 …,True,eFKUKPwAAAAJ:VL0QpB8kHFEC,73,https://ieeexplore.ieee.org/abstract/document/8456512/,17981444587356388369,/scholar?cites=17981444587356388369,,,https://ieeexplore.ieee.org/iel7/6287639/6514899/08456512.pdf,0,0,0
1277640,A verification protocol and statistical performance analysis for face recognition algorithms,1998,Syed A Rizvi and P Jonathon Phillips and Hyeonjoon Moon,,,,833-838,IEEE,Two key performance characterization of biometric algorithms (face recognition in particular) are (1) verification performance and (2) and performance as a function of database size and composition. This characterization is required for developing robust face recognition algorithms and for successfully transitioning algorithms from the laboratory to real world. In this paper we (1) present a general verification protocol and apply it to the results from the Sep96 FERET test. and (2) discuss and present results on the effects of database size and variability on identification and verification performance.,True,eFKUKPwAAAAJ:2osOgNQ5qMEC,62,https://ieeexplore.ieee.org/abstract/document/698701/,11250396702970326442,/scholar?cites=11250396702970326442,,,https://marathon.cse.usf.edu/~sarkar/biometrics/papers/FERET_CVPR.pdf,0,0,0
1277641,Biometrics person authentication using projection-based face recognition system in verification scenario,2004,Hyeonjoon Moon,,,,207-213,Springer. Berlin. Heidelberg,There are tremendous need for personal verification and identification in internet security. electronic commerce and access control in recent years. Also. as the demands for security in many applications such as data protection and financial transaction become an increasingly relevant issues. the importance of biometrics technology is rapidly increasing. We explored face recognition system for person authentication applications by explicitly state the design decisions by introducing a generic modular PCA face recognition system. We designed implementations of each module. and evaluate the performance variations based on virtual galleries and probe sets. We perform various experiments and report results using equal error rates (EER) for verification scenario. In our experiment. we report performance results on 100 randomly generated image sets (galleries) of the same size.,True,eFKUKPwAAAAJ:Tyk-4Ss8FVUC,50,https://link.springer.com/chapter/10.1007/978-3-540-25948-0_29,6206680961163614192,/scholar?cites=6206680961163614192,,,,0,0,0
1277642,Quantitative evaluation of color image segmentation results,1998,M Borsotti and Paola Campadelli and Raimondo Schettini,19,Pattern recognition letters,8,741-747,North-Holland,In this paper we consider the problem of the automatic evaluation of the results of color image segmentation. Liu and Yang (1994) have proposed an evaluation function. inspired by the qualitative criteria for good image segmentation established by Haralick and Shapiro (1985). that does not require that the user set any parameter or threshold value. We identify some limitations in this evaluation function. and propose two enhanced functions that correspond more closely to visual judgment.,True,O4TctG0AAAAJ:u5HHmVD_uO8C,528,https://www.sciencedirect.com/science/article/pii/S016786559800052X,6533602105007366565,/scholar?cites=6533602105007366565,,,,0,0,0
1277643,Underwater image processing: state of the art of restoration and image enhancement methods,2010,Raimondo Schettini and Silvia Corchs,2010,EURASIP Journal on Advances in Signal Processing,,,Hindawi Publishing Corporation,The underwater image processing area has received considerable attention within the last decades. showing important achievements. In this paper we review some of the most recent methods that have been specifically developed for the underwater environment. These techniques are capable of extending the range of underwater imaging. improving image contrast and resolution. After considering the basic physics of the light propagation in the water medium. we focus on the different algorithms available in the literature. The conditions for which each of them have been originally developed are highlighted as well as the quality assessment methods used to evaluate their performance.,True,O4TctG0AAAAJ:2P1L_qKh6hAC,446,https://link.springer.com/content/pdf/10.1155/2010/746052.pdf,8394705648464776434,/scholar?cites=8394705648464776434,,,https://link.springer.com/content/pdf/10.1155/2010/746052.pdf,0,0,0
1277644,Image annotation using SVM,2003,Claudio Cusano and Gianluigi Ciocca and Raimondo Schettini,5304,,,330-338,International society for optics and photonics,The paper describes an innovative image annotation tool for classifying image regions in one of seven classes - sky. skin. vegetation. snow. water. ground. and buildings - or as unknown. This tool could be productively applied in the management of large image and video databases where a considerable volume of images/frames there must be automatically indexed. The annotation is performed by a classification system based on a multi-class Support Vector Machine. Experimental results on a test set of 200 images are reported and discussed.,True,O4TctG0AAAAJ:u-x6o8ySG0sC,397,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5304/0000/Image-annotation-using-SVM/10.1117/12.526746.short,4499172350510402462,/scholar?cites=4499172350510402462,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.3235&rep=rep1&type=pdf,0,0,0
1277645,3D face detection using curvature analysis,2006,Alessandro Colombo and Claudio Cusano and Raimondo Schettini,39,Pattern recognition,3,444-455,Pergamon,Face detection is a crucial preliminary in many applications. Most of the approaches to face detection have focused on the use of two-dimensional images. We present an innovative method that combines a feature-based approach with a holistic one for three-dimensional (3D) face detection. Salient face features. such as the eyes and nose. are detected through an analysis of the curvature of the surface. Each triplet consisting of a candidate nose and two candidate eyes is processed by a PCA-based classifier trained to discriminate between faces and non-faces. The method has been tested. with good results. on some 150 3D faces acquired by a laser range scanner.,True,O4TctG0AAAAJ:qjMakFHDy7sC,291,https://www.sciencedirect.com/science/article/pii/S0031320305003791,17038594762132608309,/scholar?cites=17038594762132608309,,,http://www.ivl.disco.unimib.it/download/colombo20063d-face.pdf,0,0,0
1277646,Color-based image retrieval using spatial-chromatic histograms,2001,Luigi Cinque and Gianluigi Ciocca and Stefano Levialdi and A Pellicano and Raimondo Schettini,19,Image and Vision Computing,13,979-986,Elsevier,The paper describes a new indexing methodology for image databases integrating color and spatial information for content-based image retrieval. This methodology. called Spatial-Chromatic Histogram (SCH). synthesizing in few values information about the location of pixels having the same color and their arrangement within the image. can be more satisfactory than standard techniques when the user would like to retrieve from the database the images that actually resemble the query image selected in their color distribution characteristics. Experimental trials on a database of about 3000 images are reported and compared with more standard techniques. like Color Coherence Vectors. on the basis of human perceptual judgments.,True,O4TctG0AAAAJ:IjCSPb-OGe4C,244,https://www.sciencedirect.com/science/article/pii/S0262885601000609,16679969077224186592,/scholar?cites=16679969077224186592,,,https://www.academia.edu/download/51363488/Color-based_image_retrieval_using_spatia20170115-16638-1fhuc8g.pdf,0,0,0
1277647,An innovative algorithm for key frame extraction in video summarization,2006,Ciocca Gianluigi and Schettini Raimondo,1,Journal of Real-Time Image Processing,1,69-88,Springer Berlin/Heidelberg,Video summarization. aimed at reducing the amount of data that must be examined in order to retrieve the information desired from information in a video. is an essential task in video analysis and indexing applications. We propose an innovative approach for the selection of representative (key) frames of a video sequence for video summarization. By analyzing the differences between two consecutive frames of a video sequence. the algorithm determines the complexity of the sequence in terms of changes in the visual content expressed by different frame descriptors. The algorithm. which escapes the complexity of existing methods based. for example. on clustering or optimization strategies. dynamically and rapidly selects a variable number of key frames within each sequence. The key frames are extracted by detecting curvature points within the curve of the cumulative frame differences. Another …,True,O4TctG0AAAAJ:5MTHONV0fEkC,224,https://link.springer.com/content/pdf/10.1007/s11554-006-0001-1.pdf,8955728912116796830,/scholar?cites=8955728912116796830,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.3934&rep=rep1&type=pdf,0,0,0
1277648,A survey of methods for colour image indexing and retrieval in image databases,2001,Raimondo Schettini and Gianluigi Ciocca and Silvia Zuffi,,Color Imaging Science: Exploiting Digital Media,,183-211,J. Wiley. New York,Color is a feature of the great majority of content-based image retrieval systems. However the robustness. effectiveness. and efficiency of its use in image indexing are still open issues. This paper provides a comprehensive survey of the methods for color image indexing and retrieval described in the literature. In particular. image preprocessing. the features used to represent color information. and the measures adopted to compute the similarity between the features of two images are critically analyzed.,True,O4TctG0AAAAJ:d1gkVwhDpl0C,187,http://www.ppgia.pucpr.br/~alceu/pdi/Features/color.pdf,2096362079550078122,/scholar?cites=2096362079550078122,,,http://www.ppgia.pucpr.br/~alceu/pdi/Features/color.pdf,0,0,0
1277649,On the use of deep learning for blind image quality assessment,2018,Simone Bianco and Luigi Celona and Paolo Napoletano and Raimondo Schettini,12,"Signal, Image and Video Processing",2,355-362,Springer London,In this work. we investigate the use of deep learning for distortion-generic blind image quality assessment. We report on different design choices. ranging from the use of features extracted from pre-trained convolutional neural networks (CNNs) as a generic image description. to the use of features extracted from a CNN fine-tuned for the image quality task. Our best proposal. named DeepBIQ. estimates the image quality by average-pooling the scores predicted on multiple subregions of the original image. Experimental results on the LIVE In the Wild Image Quality Challenge Database show that DeepBIQ outperforms the state-of-the-art methods compared. having a linear correlation coefficient with human subjective scores of almost 0.91. These results are further confirmed also on four benchmark databases of synthetically distorted images: LIVE. CSIQ. TID2008. and TID2013.,True,O4TctG0AAAAJ:UuEBAcK4md4C,177,https://link.springer.com/article/10.1007/s11760-017-1166-8,3702191187807657775,/scholar?cites=3702191187807657775,,,https://arxiv.org/pdf/1602.05531,0,0,0
1277650,A segmentation algorithm for color images,1993,Raimondo Schettini,14,Pattern Recognition Letters,6,499-506,North-Holland,A method that combines clustering and region merging for color image segmentation is presented. We start with clustering based on recursive one-dimensional histogram analysis. where the parameter that controls the segmentation process has been set to produce an oversegmentation. The resulting regions are then merged on the basis of a criterion that takes into account color similarity and spatial proximity.,True,O4TctG0AAAAJ:2osOgNQ5qMEC,176,https://www.sciencedirect.com/science/article/pii/016786559390030H,863757499741584668,/scholar?cites=863757499741584668,,,,0,0,0
1277651,Color balancing of digital photos using simple image statistics,2004,Francesca Gasparini and Raimondo Schettini,37,Pattern Recognition,6,1201-1217,Pergamon,The great diffusion of digital cameras and the widespread use of the internet have produced a mass of digital images depicting a huge variety of subjects. generally acquired by unknown imaging systems under unknown lighting conditions. This makes color balancing. recovery of the color characteristics of the original scene. increasingly difficult. In this paper. we describe a method for detecting and removing a color cast (i.e. a superimposed color due to lighting conditions. or to the characteristics of the capturing device). from a digital photo without any a priori knowledge of its semantic content. First a cast detector. using simple image statistics. classifies the input images as presenting no cast. evident cast. ambiguous cast. a predominant color that must be preserved (such as in underwater images or single color close-ups) or as unclassifiable. A cast remover. a modified version of the white balance algorithm. is then …,True,O4TctG0AAAAJ:Y0pCki6q_DkC,164,https://www.sciencedirect.com/science/article/pii/S0031320304000068,767858617140337011,/scholar?cites=767858617140337011,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.717.1573&rep=rep1&type=pdf,0,0,0
1277652,Improving color constancy using indoor–outdoor image classification,2008,Simone Bianco and Gianluigi Ciocca and Claudio Cusano and Raimondo Schettini,17,IEEE Transactions on image processing,12,2381-2392,IEEE,In this work. we investigate how illuminant estimation techniques can be improved. taking into account automatically extracted information about the content of the images. We considered indoor/outdoor classification because the images of these classes present different content and are usually taken under different illumination conditions. We have designed different strategies for the selection and the tuning of the most appropriate algorithm (or combination of algorithms) for each class. We also considered the adoption of an uncertainty class which corresponds to the images where the indoor/outdoor classifier is not confident enough. The illuminant estimation algorithms considered here are derived from the framework recently proposed by Van de Weijer and Gevers. We present a procedure to automatically tune the algorithms' parameters. We have tested the proposed strategies on a suitable subset of the widely …,True,O4TctG0AAAAJ:_FxGoFyzp5QC,153,https://ieeexplore.ieee.org/abstract/document/4664624/,1176274410925712033,/scholar?cites=1176274410925712033,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.492.8106&rep=rep1&type=pdf,0,0,0
1277653,Center weighted median filters and their applications to image enhancement,1991,S-J Ko and Yong Hoon Lee,38,IEEE transactions on circuits and systems,9,984-993,IEEE,The center weighted median (CWM) filter. which is a weighted median filter giving more weight only to the central value of each window. is studied. This filter can preserve image details while suppressing additive white and/or impulsive-type noise. The statistical properties of the CWM filter are analyzed. It is shown that the CWM filter can outperform the median filter. Some relationships between CWM and other median-type filters. such as the Winsorizing smoother and the multistage median filter. are derived. In an attempt to improve the performance of CWM filters. an adaptive CWM (ACWM) filter having a space varying central weight is proposed. It is shown that the ACWM filter is an excellent detail preserving smoother that can suppress signal-dependent noise as well as signal-independent noise.< >,True,oLRJMVMAAAAJ:u5HHmVD_uO8C,1588,https://ieeexplore.ieee.org/abstract/document/83870/,2631370964183974777,/scholar?cites=2631370964183974777,,,,0,0,0
1277654,Motion-compensated frame interpolation using bilateral motion estimation and adaptive overlapped block motion compensation,2007,Byeong-Doo Choi and Jong-Woo Han and Chang-Su Kim and Sung-Jea Ko,17,"Circuits and Systems for Video Technology, IEEE Transactions on",4,407-416,IEEE,In this work. we develop a new motion-compe (MC) interpolation algorithm to enhance the temporal resolution of video sequences. First. we propose the bilateral motion estimation scheme to obtain the motion field of an interpolated frame without yielding the hole and overlapping problems. Then. we partition a frame into several object regions by clustering motion vectors. We apply the variable-size block MC (VS-BMC) algorithm to object boundaries in order to reconstruct edge information with a higher quality. Finally. we use the adaptive overlapped block MC (OBMC). which adjusts the coefficients of overlapped windows based on the reliabilities of neighboring motion vectors. The adaptive OBMC (AOBMC) can overcome the limitations of the conventional OBMC. such as over-smoothing and poor de-blocking. Experimental results show that the proposed algorithm provides a better image quality than conventional …,True,oLRJMVMAAAAJ:d1gkVwhDpl0C,393,https://ieeexplore.ieee.org/abstract/document/4162523/,8409776442105373630,/scholar?cites=8409776442105373630,,,,0,0,0
1277655,Fast digital image stabilizer based on gray-coded bit-plane matching,1999,Sung-Jea Ko and Sung-Hee Lee and Seung-Won Jeon and Eui-Sung Kang,45,IEEE Transactions on Consumer Electronics,3,598-603,IEEE,A fast digital image stabilizer based on the Gray-coded bit-plane matching is proposed which is robust to irregular conditions such as moving objects and intentional panning. The proposed digital image stabilization (DIS) system performs motion estimation using the Gray-coded bit-plane of video sequences. greatly reducing the computational load. This motion estimation method can be realized using only binary Boolean functions which have significantly reduced computational complexity. while the accuracy of motion estimation is maintained. In order to further improve the computational efficiency. the Gray-coded bit-plane matching with the three-step search (3SS) is proposed. Experimental results indicate that the proposed digital image stabilizer is a computationally efficient alternative to existing DIS systems.,True,oLRJMVMAAAAJ:u-x6o8ySG0sC,359,https://ieeexplore.ieee.org/abstract/document/793546/,8151907903659756483,/scholar?cites=8151907903659756483,,,,0,0,0
1277656,New frame rate up-conversion using bi-directional motion estimation,2000,Byung-Tae Choi and Sung-Hee Lee and Sung-Jea Ko,46,IEEE Transactions on Consumer Electronics,3,603-609,IEEE,We propose a new frame rate up-conversion algorithm for high quality video. In the proposed scheme. bi-directional motion estimation (ME) is performed to construct the motion vector (MV) field for the frame to be interpolated. Unlike conventional motion-compensated interpolation (MCI) algorithms. the proposed technique does not produce any overlapped pixel and hole region in the interpolated frame. and thus can utilize the overlapped block motion compensation technique to reduce the blocking artifacts. The proposed algorithm is very simple to implement on consumer products when compared to conventional MCI methods. Computer simulation shows a high visual performance of the proposed frame rate up-conversion algorithm.,True,oLRJMVMAAAAJ:9yKSN-GCB0IC,342,https://ieeexplore.ieee.org/abstract/document/883418/,18421985279662597655,/scholar?cites=18421985279662597655,,,https://pdfs.semanticscholar.org/451e/a91afbbc2c5582858be8902d4d6532846b8c.pdf,0,0,0
1277657,New autofocusing technique using the frequency selective weighted median filter for video cameras,1999,Kang-Sun Choi and Jun-Suk Lee and Sung-Jae Ko,45,IEEE transactions on Consumer Electronics,3,820-827,IEEE,Most conventional autofocusing techniques based on the gradient estimator are very sensitive to noise. A new autofocusing technique which is resistive to noise generated by the CCD of video cameras is proposed. In the proposed scheme. the frequency selective weighted median (FSWM) filter is utilized to estimate the degree of focus and the fast hill-climbing search (HCS) strategy is exploited to determine the best focused image. Since the FSWM filter can not only extract high frequency components from the image. but also eliminate impulsive noise. the proposed autofocusing method employing the FSWM criterion function can estimate the degree of focus precisely. Furthermore. the proposed real-time HCS algorithm enables the video camera to continuously focus on dynamic images. Experimental results demonstrate that the proposed technique outperforms existing techniques by enhancing the accuracy of …,True,oLRJMVMAAAAJ:YsrPvlHIBpEC,299,https://ieeexplore.ieee.org/abstract/document/793616/,12791999134722178868,/scholar?cites=12791999134722178868,,,,0,0,0
1277658,Digital image stabilizing algorithms based on bit-plane matching,1998,Sung-Jea Ko and Sung-Hee Lee and Kyung-Hoon Lee,44,IEEE Transactions on Consumer Electronics,3,617-622,IEEE,In this paper. we present a new digital image stabilization (DIS) scheme based on bit-plane matching (BPM). The proposed DIS system performs motion estimation using 1-bit planes which are extracted from a video sequence. This motion estimation technique can be realized using only Boolean functions which have significantly reduced computational complexity. while the accuracy of motion estimation is maintained. In the second part of this paper. a median-based motion correction scheme is proposed which is robust to various irregular conditions such as moving objects and intentional panning. Simulation results show that the proposed DIS algorithm exhibits better performance compared with existing other algorithms when applied to real video signals.,True,oLRJMVMAAAAJ:2osOgNQ5qMEC,281,https://ieeexplore.ieee.org/abstract/document/713172/,14319200459952998596,/scholar?cites=14319200459952998596,,,,0,0,0
1277659,An advanced video camera system with robust AF. AE. and AWB control,2001,June-Sok Lee and You-Young Jung and Byung-Soo Kim and Sung-Jea Ko,47,IEEE Transactions on Consumer Electronics,3,694-699,IEEE,This paper presents an advanced video camera system which has robust automatic focus (AF). automatic exposure (AE). and automatic white-balance (AWB) control. The proposed AF algorithm decides the correct moving direction of the lens and detects the accurate in-focus state even though the scene is interfered with by the high light intensity. Experimental results demonstrate that the proposed system can be an effective alternative to conventional systems using the hill-climbing method.,True,oLRJMVMAAAAJ:UeHWp8X0CEIC,163,https://ieeexplore.ieee.org/abstract/document/964165/,17708096537728899447,/scholar?cites=17708096537728899447,,,,0,0,0
1277660,Selective channel scanning for fast handoff in wireless LAN using neighbor graph,2004,Hye-Soo Kim and Sang-Hee Park and Chun-Su Park and Jae Won Kim and Sung-Jea Ko,4,ITC-CSCC,,,,Handoff at the link layer 2 (L2) consists of three phases including scanning. authentication. and reassociation. Among the three phases. scanning is dominant in terms of time delay. Thus. in this paper. we propose an improved scanning mechanism to minimize the disconnected time while a wireless station (STA) changes the associated access points (APs). According to IEEE 802.11. an STA has to scan all channels in scanning. In this paper. based on the neighbor graph (NG). we introduce a selective channel scanning method with unicast for fast handoff in which an STA scans only channels selected by the NG. Experimental results show that the proposed method reduce the scanning delay drastically.,True,oLRJMVMAAAAJ:1r-w4gtu6w8C,138,https://www.researchgate.net/profile/Chun-Su_Park/publication/221451169_Selective_Channel_Scanning_for_Fast_Handoff_in_Wireless_LAN_Using_Neighbor_Graph/links/00b7d5279d32f7a3ef000000.pdf,6564656467087227268,/scholar?cites=6564656467087227268,,,https://www.researchgate.net/profile/Chun-Su_Park/publication/221451169_Selective_Channel_Scanning_for_Fast_Handoff_in_Wireless_LAN_Using_Neighbor_Graph/links/00b7d5279d32f7a3ef000000.pdf,0,0,0
1277661,A flavone diglycoside from Cirsium japonicum var. ussuriense,1995,Jong Cheol Park and Jong Ho Lee and Jae Sue Choi,39,Phytochemistry,1,261-262,Pergamon,Chromatographic separation of the butanol-soluble part of the methanol extract of whole plants of Cirsium japonicum var. ussuriense resulted in the isolation of a new flavonoid. hispidulin 7-neohesperidoside. together with the known cirsimaritin 4′-glucoside and acacetin 7-rutinoside.,True,oLRJMVMAAAAJ:F2UWTTQJPOcC,129,https://www.sciencedirect.com/science/article/pii/0031942294008973,14047577017598260643,/scholar?cites=14047577017598260643,,,,0,0,0
1277662,A new histogram modification based reversible data hiding algorithm considering the human visual system,2010,Seung-Won Jung and Sung-Jea Ko,18,IEEE Signal Processing Letters,2,95-98,IEEE,In this letter. we propose an improved histogram modification based reversible data hiding technique. In the proposed algorithm. unlike the conventional reversible techniques. a data embedding level is adaptively adjusted for each pixel with a consideration of the human visual system (HVS) characteristics. To this end. an edge and the just noticeable difference (JND) values are estimated for every pixel. and the estimated values are used to determine the embedding level. This pixel level adjustment can effectively reduce the distortion caused by data embedding. The experimental results and performance comparison with other reversible data hiding algorithms are presented to demonstrate the validity of the proposed algorithm.,True,oLRJMVMAAAAJ:eQOLeE2rZwMC,112,https://ieeexplore.ieee.org/abstract/document/5648443/,15848090321477343687,/scholar?cites=15848090321477343687,,,https://www.researchgate.net/profile/Seung_Won_Jung2/publication/260636390_A_New_Histogram_Modification_Based_Reversible_Data_Hiding_Algorithm_Considering_the_Human_Visual_System/links/54e196300cf296663792c053/A-New-Histogram-Modification-Based-Reversible-Data-Hiding-Algorithm-Considering-the-Human-Visual-System.pdf,0,0,0
1277663,Robust digital image stabilization using the Kalman filter,2009,Chuntao Wang and Jin-Hyung Kim and Keun-Yung Byun and Jiangqun Ni and Sung-Jea Ko,55,IEEE Transactions on Consumer Electronics,1,6-14,IEEE,In this paper. we present a new digital image stabilization (DIS) algorithm based on feature point tracking. Feature points well tracked by the Kanade-Lucas-Tomasi (KLT) tracker are used to estimate the global motion between two consecutive image frames. The motion prediction with the Kalman filter (KF) is incorporated into the KLT tracker to further speed up the tracking process. Moreover. we develop an adaptive KF to better handle the intentional motion of the camera. In addition. a new scheme is also proposed to detect the scene change and automatically change the reference frame. Experimental simulation shows that the proposed DIS algorithm has the characteristics of high accuracy. good robustness to different irregular conditions.,True,oLRJMVMAAAAJ:W7OEmFMy1HYC,104,https://ieeexplore.ieee.org/abstract/document/4814407/,1985256661824057532,/scholar?cites=1985256661824057532,,,,0,0,0
1277664,Genetic determinants of bone mass in adults. A twin study.,1987,Nicholas A Pocock and John A Eisman and John L Hopper and Michael G Yeates and Philip N Sambrook and S Eberl,80,The Journal of clinical investigation,3,706-710,American Society for Clinical Investigation,The relative importance of genetic factors in determining bone mass in different parts of the skeleton is poorly understood. Lumbar spine and proximal femur bone mineral density and forearm bone mineral content were measured by photon absorptiometry in 38 monozygotic and 27 dizygotic twin pairs. Bone mineral density was significantly more highly correlated in monozygotic than in dizygotic twins for the spine and proximal femur and in the forearm of premenopausal twin pairs. which is consistent with significant genetic contributions to bone mass at all these sites. The lesser genetic contribution to proximal femur and distal forearm bone mass compared with the spine suggests that environmental factors are of greater importance in the aetiology of osteopenia of the hip and wrist. This is the first demonstration of a genetic contribution to bone mass of the spine and proximal femur in adults and confirms similar …,True,QcvEyooAAAAJ:4MWp96NkSFoC,1544,https://www.jci.org/articles/view/113125,10568742306893804653,/scholar?cites=10568742306893804653,,,https://www.jci.org/articles/view/113125/files/pdf,0,0,0
1277665,Physical fitness is a major determinant of femoral neck and lumbar spine bone mineral density.,1986,Nicholas A Pocock and JA Eisman and MG Yeates and PN Sambrook and S Eberl,78,The Journal of clinical investigation,3,618-621,American Society for Clinical Investigation,The relationship between physical fitness and bone mass in the femoral neck. lumbar spine. and forearm was studied in 84 normal women. Femoral neck and lumbar spine bone mineral density and forearm bone mineral content were estimated by absorptiometry. Fitness was quantitated from predicted maximal oxygen uptake. Femoral neck and lumbar bone mineral density were significantly correlated with fitness as well as age and weight. In the 46 postmenopausal subjects. fitness was the only significant predictor of femoral neck bone mineral density. and both weight and fitness predicted the lumbar bone mineral density. These data represent the first demonstration of a correlation between physical fitness. and. by implication. habitual physical activity. and bone mass in the femoral neck; they also support the previous reported correlation between lumbar bone mass and physical activity. The data suggest that …,True,QcvEyooAAAAJ:RHpTSmoSYBkC,348,https://www.jci.org/articles/view/112618,1708143462207013792,/scholar?cites=1708143462207013792,,,https://www.jci.org/articles/view/112618/files/pdf,0,0,0
1277666,A scanning line source for simultaneous emission and transmission measurements in SPECT.,1993,Patrick Tan and Dale L Bailey and Steven R Meikle and Stefan Eberl and Roger R Fulton and Brian F Hutton,34,"Journal of nuclear medicine: official publication, Society of Nuclear Medicine",10,1752-1760,,DesignThe line sourceis mountedonto the gammacameradetector headin a similarmannerto the floodsourcetechniquedescribed previously (Fig. 1). Initszeroposition. thelinesourceisretracted behind lead shielding built into the housing. thereby rendering it safe to handle when not in use. The radionucide source is sealed in a cylindrical perspex tube with a 1-mm internal diameter. The line source is collimated with lead employing a dual slit design,True,QcvEyooAAAAJ:AvfA0Oy_GE0C,247,https://jnm.snmjournals.org/content/jnumed/34/10/1752.full-text.pdf,10146894000842304677,/scholar?cites=10146894000842304677,,,https://jnm.snmjournals.org/content/jnumed/34/10/1752.full-text.pdf,0,0,0
1277667,Determinants of axial bone loss in rheumatoid arthritis,1987,Philip N Sambrook and John A Eisman and G David Champion and Michael G Yeates and Nicholas A Pocock and Stefan Eberl,30,Arthritis & Rheumatism: Official Journal of the American College of Rheumatology,7,721-728,John Wiley & Sons. Inc.,To assess mechanisms that cause generalized osteoporosis in rheumatoid arthritis (RA). we measured bone mineral density (BMD) by dual photon absorptiometry in the lumbar spine and femoral neck of 111 patients with RA. BMD was significantly reduced at both sites in these patients. Physical activity correlated significantly with BMD in patients with RA. and was found. by multiple regression analysis. to be a significant predictor of femoral bone density in female patients. Multiparity exerted a protective effect on lumbar bone density. Prednisolone (mean dosage 8 mg/day) was not associated with significantly increased bone loss in women. whereas higher dosages in men (mean 10.3 mg/day) were associated with increased lumbar bone loss. Reduced physical activity leading to a form of disuse osteoporosis appears to be an important factor in axial bone loss in RA.,True,QcvEyooAAAAJ:ILKRHgRFtOwC,244,https://onlinelibrary.wiley.com/doi/abs/10.1002/art.1780300701,10953886836564871742,/scholar?cites=10953886836564871742,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/art.1780300701,0,0,0
1277668,Osteoporosis in rheumatoid arthritis: safety of low dose corticosteroids.,1986,PN Sambrook and JA Eisman and MG Yeates and NA Pocock and S Eberl and GD Champion,45,Annals of the Rheumatic Diseases,11,950-953,BMJ Publishing Group Ltd,Fear of inducing generalised osteoporosis is one reason why corticosteroids are withheld in patients with rheumatoid arthritis (RA). No studies. however. have directly measured bone density in such patients at clinically relevant sites. To assess this risk we measured bone mineral density in the lumbar spine and femoral neck by dual photon absorptiometry in 84 patients with RA. 44 of whom had been treated with low dose prednis(ol)one (mean dose +/- SE 8.0 +/- 0.5 mg/day; mean duration of treatment 89.6 +/- 12.0 months). There were significant reductions in bone mineral density in patients treated with corticosteroids (lumbar 9.6%. p less than 0.001; femoral 12.2%. p less than 0.001) and in those who had not received corticosteroids (lumbar 6.9%. p less than 0.01; femoral 8.9%. p less than 0.001). but the differences between the two groups were not significant. We conclude on the basis of these studies that low …,True,QcvEyooAAAAJ:P5F9QuxV20EC,219,https://ard.bmj.com/content/45/11/950.short,5163090555264810272,/scholar?cites=5163090555264810272,,,https://ard.bmj.com/content/annrheumdis/45/11/950.full.pdf,0,0,0
1277669,Inhalation of hypertonic saline aerosol enhances mucociliary clearance in asthmatic and healthy subjects,1996,E Daviskas and SD Anderson and I Gonda and S Eberl and S Meikle and JP Seale and G Bautovich,9,European Respiratory Journal,4,725-732,European Respiratory Society,Hyperosmolarity of the airway surface liquid (ASL) has been proposed as the stimulus for hyperpnoea-induced asthma. We found previously that mucociliary clearance (MCC) was increased after isocapnic hyperventilation (ISH) with dry air. and we proposed that the increase related to transient hyperosmolarity of the ASL. We investigated the effect of increasing the osmolarity of the ASL on MCC. by administering an aerosol of concentrated salt solution. MCC was measured using 99mTc-sulphur colloid. gamma camera and computer analysis in 12 asthmatic and 10 healthy subjects on three separate days. involving administration of each of the following: 1) ultrasonically nebulized 14.4% saline; 2) ultrasonically nebulized 0.9% saline; and 3) no aerosol intervention (control). The (mean +/- SD) volume of nebulized 14.4% saline was 2.2 +/- 1.2 mL for asthmatics and 3.2 +/- 0.7 mL for healthy subjects. This volume …,True,QcvEyooAAAAJ:KUbvn5osdkgC,209,https://erj.ersjournals.com/content/9/4/725.short,11211629321390946443,/scholar?cites=11211629321390946443,,,https://erj.ersjournals.com/content/erj/9/4/725.full.pdf,0,0,0
1277670,Correction for head movements in positron emission tomography using an optical motion-tracking system,2002,Roger R Fulton and Steven R Meikle and Stefan Eberl and Jörg Pfeiffer and Christopher J Constable,49,IEEE Transactions on Nuclear Science,1,116-123,IEEE,Methods capable of correcting for head motion in all six degrees of freedom have been proposed for positron emission tomography (PET) brain imaging but not yet demonstrated in human studies. These methods rely on the accurate measurement of head motion in relation to the reconstruction coordinate frame. We present methodology for the direct calibration of an optical motion-tracking system to the reconstruction coordinate frame using paired coordinate measurements obtained simultaneously from a PET scanner and tracking system. We also describe the implementation of motion correction. based on the multiple acquisition frame method originally described by Picard and Thompson (1997). using data provided by the motion tracking system. Effective compensation for multiple six-degree-of-freedom movements is demonstrated in dynamic PET scans of the Hoffman brain phantom and a normal volunteer …,True,QcvEyooAAAAJ:j8SEvjWlNXcC,195,https://ieeexplore.ieee.org/abstract/document/998691/,9155792068502742884,/scholar?cites=9155792068502742884,,,https://www.imaging.utk.edu/research/burbar/Papers/fulton.pdf,0,0,0
1277671,The effect of inhaled mannitol on bronchial mucus clearance in cystic fibrosis patients: a pilot study,1999,M Robinson and E Daviskas and S Eberl and J Baker and HK Chan and SD Anderson and PT p Bye,14,European Respiratory Journal,3,678-685,European Respiratory Society,It has been postulated that hypertonic saline (HS) might impair the antimicrobial effects of defensins within the airways. Alternative non-ionic osmotic agents such as mannitol may thus be preferable to HS in promoting bronchial mucus clearance (BMC) in patients with cystic fibrosis (CF). This study reports the effect of inhalation of another osmotic agent. dry powder Mannitol (300 mg). compared with its control (empty capsules plus matched voluntary cough) and a 6% solution of HS on BMC in 12 patients with cystic fibrosis (CF). Mucus clearance was measured using a radioaerosol/gamma camera technique. Post-intervention clearance was measured for 60 min. followed by cough clearance for 30 min. Neither mannitol nor HS improved BMC during the actual intervention period compared with their respective controls. However during the post-intervention measurement there was a significant improvement in BMC …,True,QcvEyooAAAAJ:HbR8gkJAVGIC,189,https://erj.ersjournals.com/content/14/3/678.short,12567270321535369662,/scholar?cites=12567270321535369662,,,https://erj.ersjournals.com/content/erj/14/3/678.full.pdf,0,0,0
1277672,Corticosteroid effects on proximal femur bone loss,1990,Philip Sambrook and Joan Birmingham and Susan Kempler and Paul Kelly and Stefan Eberl and Nicholas Pocock and Michael Yeates and John Eisman,5,Journal of Bone and Mineral Research,12,1211-1216,John Wiley and Sons and The American Society for Bone and Mineral Research (ASBMR),Prolonged high‐dose corticosteroid therapy is known to result in an increased risk of osteoporotic fracture. Reductions in bone density have been demonstrated at the distal radius and lumbar spine in patients receiving corticosteroids; however there have been few studies of bone density in the hip (the most important site of osteoporotic fracture) in this context. To examine the effect of corticosteroids on the hip we measured bone mineral density (BMD) by dual‐photon absorptiometry at three sites in the proximal femur as well as the lumbar spine in 32 patients aged 18–77 years who had been treated with corticosteroids (mean daily prednisone dose 12.7 mg) for up to 23 years. BMD was compared with the expected values using age regressions in normal subjects. BMD was significantly reduced in the femoral neck. Ward's triangle. and the trochanteric region (p < 0.001 all sites). In the lumbar spine BMD was also …,True,QcvEyooAAAAJ:5Ul4iDaHHb8C,175,https://asbmr.onlinelibrary.wiley.com/doi/abs/10.1002/jbmr.5650051204,6426570262259433707,/scholar?cites=6426570262259433707,,,,0,0,0
1277673,Optimizing injected dose in clinical PET by accurately modeling the counting-rate response functions specific to individual patient scans,2005,Charles C Watson and Michael E Casey and Bernard Bendriem and Jonathan P Carney and David W Townsend and Stefan Eberl and Steve Meikle and Frank P DiFilippo,46,Journal of Nuclear Medicine,11,1825-1834,Society of Nuclear Medicine,,True,QcvEyooAAAAJ:kz9GbA2Ns4gC,140,https://jnm.snmjournals.org/content/46/11/1825.short,11930353571175656215,/scholar?cites=11930353571175656215,,,https://jnm.snmjournals.org/content/jnumed/46/11/1825.full.pdf,0,0,0
1277674,Inhalation of dry powder mannitol improves clearance of mucus in patients with bronchiectasis,1999,EVANGELIA DAVISKAS and Sandra D Anderson and Stefan Eberl and H-Kim Chan and GEORGE BAUTOVICH,159,American Journal of Respiratory and Critical Care Medicine,6,1843-1848,American Thoracic Society,Bronchiectasis is a disease characterized by hypersecretion and retention of mucus requiring physical  and pharmacologic treatment. Recently we reported that inhalation of dry powder mannitol markedly increases mucociliary clearance (MCC) in asthmatic and in healthy subjects (Daviskas. E.. S. D.  Anderson. J. D. Brannan. H. K. Chan. S. Eberl. and G. Bautovich. 1997. Inhalation of dry-powder mannitol increases mucociliary clearance. Eur. Respir. J. 10:2449–2454). In this study we investigated the  effect of mannitol on MCC in patients with bronchiectasis. Eleven patients 40 to 62 yr of age inhaled  mannitol (approximately 300 mg) from a Dinkihaler. MCC was measured over 90 min. in the supine  position. on three occasions involving: mannitol or control or baseline. using a radioaerosol technique. On the control day patients reproduced the breathing maneuvers and the number of coughs  induced by the …,True,QcvEyooAAAAJ:hMsQuOkrut0C,138,https://www.atsjournals.org/doi/abs/10.1164/ajrccm.159.6.9809074,10973496080681741386,/scholar?cites=10973496080681741386,,,https://www.atsjournals.org/doi/pdf/10.1164/ajrccm.159.6.9809074,0,0,0
1277675,ICDAR 2013 robust reading competition,2013,Dimosthenis Karatzas and Faisal Shafait and Seiichi Uchida and Masakazu Iwamura and Lluis Gomez i Bigorda and Sergi Robles Mestre and Joan Mas and David Fernandez Mota and Jon Almazan Almazan and Lluis Pere De Las Heras,,,,1484-1493,IEEE,This report presents the final results of the ICDAR 2013 Robust Reading Competition. The competition is structured in three Challenges addressing text extraction in different application domains. namely born-digital images. real scene images and real-scene videos. The Challenges are organised around specific tasks covering text localisation. text segmentation and word recognition. The competition took place in the first quarter of 2013. and received a total of 42 submissions over the different tasks offered. This report describes the datasets and ground truth specification. details the performance evaluation protocols used and presents the final results along with a brief summary of the participating methods.,True,o9RCNZYAAAAJ:NhqRSupF_l8C,860,https://ieeexplore.ieee.org/abstract/document/6628859/,10933370092453909086,/scholar?cites=10933370092453909086,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.8415&rep=rep1&type=pdf,0,0,0
1277676,ICDAR 2015 competition on robust reading,2015,Dimosthenis Karatzas and Lluis Gomez-Bigorda and Anguelos Nicolaou and Suman Ghosh and Andrew Bagdanov and Masakazu Iwamura and Jiri Matas and Lukas Neumann and Vijay Ramaseshan Chandrasekhar and Shijian Lu and Faisal Shafait and Seiichi Uchida and Ernest Valveny,,,,1156-1160,IEEE,Results of the ICDAR 2015 Robust Reading Competition are presented. A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images. Focused Scene Images and Video Text. Challenge 4 is run on a newly acquired dataset of 1.670 images evaluating Text Localisation. Word Recognition and End-to-End pipelines. In addition. the dataset for Challenge 3 on Video Text has been substantially updated with more video sequences and more accurate ground truth data. Finally. tasks assessing End-to-End system performance have been introduced to all Challenges. The competition took place in the first quarter of 2015. and received a total of 44 submissions. Only the tasks newly introduced in 2015 are reported on. The datasets. the ground truth specification and the evaluation protocols are presented together with the results and a brief summary of the participating methods.,True,o9RCNZYAAAAJ:WA5NYHcadZ8C,703,https://ieeexplore.ieee.org/abstract/document/7333942/,6546880768753720354,/scholar?cites=6546880768753720354,,,http://human.ait.kyushu-u.ac.jp/publications/ICDAR2015-RRC.pdf,0,0,0
1277677,ICDAR 2011 robust reading competition challenge 2: Reading text in scene images,2011,Asif Shahab and Faisal Shafait and Andreas Dengel,,,,1491-1496,IEEE,Recognition of text in natural scene images is becoming a prominent research area due to the widespread availablity of imaging devices in low-cost consumer products like mobile phones. To evaluate the performance of recent algorithms in detecting and recognizing text from complex images. the ICDAR 2011 Robust Reading Competition was organized. Challenge 2 of the competition dealt specifically with detecting/recognizing text in natural scene images. This paper presents an overview of the approaches that the participants used. the evaluation measure. and the dataset used in the Challenge 2 of the contest. We also report the performance of all participating methods for text localization and word recognition tasks and compare their results using standard methods of area precision/recall and edit distance.,True,o9RCNZYAAAAJ:IWHjjKOFINEC,511,https://ieeexplore.ieee.org/abstract/document/6065556/,7274980291911419991,/scholar?cites=7274980291911419991,,,http://www.iapr-tc11.org/archive/icdar2011/fileup/PDF/4520b491.pdf,0,0,0
1277678,Efficient implementation of local adaptive thresholding techniques using integral images,2008,Faisal Shafait and Daniel Keysers and Thomas M Breuel,6815,,,681510,International Society for Optics and Photonics,Adaptive binarization is an important first step in many document analysis and OCR processes. This paper describes a fast adaptive binarization algorithm that yields the same quality of binarization as the Sauvola method.1 but runs in time close to that of global thresholding methods (like Otsu's method2). independent of the window size. The algorithm combines the statistical constraints of Sauvola's method with integral images.3 Testing on the UW-1 dataset demonstrates a 20-fold speedup compared to the original Sauvola algorithm.,True,o9RCNZYAAAAJ:u5HHmVD_uO8C,370,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/6815/681510/Efficient-implementation-of-local-adaptive-thresholding-techniques-using-integral-images/10.1117/12.767755.short,2289746146619769012,/scholar?cites=2289746146619769012,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.182.5334&rep=rep1&type=pdf,0,0,0
1277679,Performance evaluation and benchmarking of six-page segmentation algorithms,2008,Faisal Shafait and Daniel Keysers and Thomas Breuel,30,IEEE Transactions on Pattern Analysis and Machine Intelligence,6,941-954,IEEE,Informative benchmarks are crucial for optimizing the page segmentation step of an OCR system. frequently the performance limiting step for overall OCR system performance. We show that current evaluation scores are insufficient for diagnosing specific errors in page segmentation and fail to identify some classes of serious segmentation errors altogether. This paper introduces a vectorial score that is sensitive to. and identifies. the most important classes of segmentation errors (over. under. and mis-segmentation) and what page components (lines. blocks. etc.) are affected. Unlike previous schemes. our evaluation method has a canonical representation of ground-truth data and guarantees pixel-accurate evaluation results for arbitrary region shapes. We present the results of evaluating widely used segmentation algorithms (x-y cut. smearing. whitespace analysis. constrained text-line finding. docstrum. and …,True,o9RCNZYAAAAJ:u-x6o8ySG0sC,238,https://ieeexplore.ieee.org/abstract/document/4407728/,7753819038667595975,/scholar?cites=7753819038667595975,,,https://tukl.seecs.nust.edu.pk/members/projects/journals/Performance-Evaluation-and-Benchmarking-of-Six-Page-Segmentation-Algorithms.pdf,0,0,0
1277680,High-performance OCR for printed English and Fraktur using LSTM networks,2013,Thomas M Breuel and Adnan Ul-Hasan and Mayce Ali Al-Azawi and Faisal Shafait,,,,683-687,IEEE,Long Short-Term Memory (LSTM) networks have yielded excellent results on handwriting recognition. This paper describes an application of bidirectional LSTM networks to the problem of machine-printed Latin and Fraktur recognition. Latin and Fraktur recognition differs significantly from handwriting recognition in both the statistical properties of the data. as well as in the required. much higher levels of accuracy. Applications of LSTM networks to handwriting recognition use two-dimensional recurrent networks. since the exact position and baseline of handwritten characters is variable. In contrast. for printed OCR. we used a one-dimensional recurrent network combined with a novel algorithm for baseline and x-height normalization. A number of databases were used for training and testing. including the UW3 database. artificially generated and degraded Fraktur text and scanned pages from a book digitization …,True,o9RCNZYAAAAJ:b0M2c_1WBrUC,219,https://ieeexplore.ieee.org/abstract/document/6628705/,17226816615103084398,/scholar?cites=17226816615103084398,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.433.4006&rep=rep1&type=pdf,0,0,0
1277681,Sparse spatio-spectral representation for hyperspectral image super-resolution,2014,Naveed Akhtar and Faisal Shafait and Ajmal Mian,,,,63-78,Springer. Cham,Existing hyperspectral imaging systems produce low spatial resolution images due to hardware constraints. We propose a sparse representation based approach for hyperspectral image super-resolution. The proposed approach first extracts distinct reflectance spectra of the scene from the available hyperspectral image. Then. the signal sparsity. non-negativity and the spatial structure in the scene are exploited to explain a high-spatial but low-spectral resolution image of the same scene in terms of the extracted spectra. This is done by learning a sparse code with an algorithm G-SOMP+. Finally. the learned sparse code is used with the extracted scene spectra to estimate the super-resolution hyperspectral image. Comparison of the proposed approach with the state-of-the-art methods on both ground-based and remotely-sensed public hyperspectral image databases shows that the presented method …,True,o9RCNZYAAAAJ:8AbLer7MMksC,180,https://link.springer.com/chapter/10.1007/978-3-319-10584-0_5,4532537881043139217,/scholar?cites=4532537881043139217,,,https://link.springer.com/content/pdf/10.1007/978-3-319-10584-0_5.pdf,0,0,0
1277682,Bayesian sparse representation for hyperspectral image super resolution,2015,Naveed Akhtar and Faisal Shafait and Ajmal Mian,,,,3631-3640,,Despite the proven efficacy of hyperspectral imaging in many computer vision tasks. its widespread use is hindered by its low spatial resolution. resulting from hardware limitations. We propose a hyperspectral image super resolution approach that fuses a high resolution image with the low resolution hyperspectral image using non-parametric Bayesian sparse representation. The proposed approach first infers probability distributions for the material spectra in the scene and their proportions. The distributions are then used to compute sparse codes of the high resolution image. To that end. we propose a generic Bayesian sparse coding strategy to be used with Bayesian dictionaries learned with the Beta process. We theoretically analyze the proposed strategy for its accurate performance. The computed codes are used with the estimated scene spectra to construct the super resolution hyperspectral image. Exhaustive experiments on two public databases of ground based hyperspectral images and a remotely sensed image show that the proposed approach outperforms the existing state of the art.,True,o9RCNZYAAAAJ:1qzjygNMrQYC,152,http://openaccess.thecvf.com/content_cvpr_2015/html/Akhtar_Bayesian_Sparse_Representation_2015_CVPR_paper.html,6483893953673669808,/scholar?cites=6483893953673669808,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Akhtar_Bayesian_Sparse_Representation_2015_CVPR_paper.pdf,0,0,0
1277683,Meta-learning for evolutionary parameter optimization of classifiers,2012,Matthias Reif and Faisal Shafait and Andreas Dengel,87,Machine learning,3,357-380,Springer US,The performance of most of the classification algorithms on a particular dataset is highly dependent on the learning parameters used for training them. Different approaches like grid search or genetic algorithms are frequently employed to find suitable parameter values for a given dataset. Grid search has the advantage of finding more accurate solutions in general at the cost of higher computation time. Genetic algorithms. on the other hand. are able to find good solutions in less time. but the accuracy of these solutions is usually lower than those of grid search.This paper uses ideas from meta-learning and case-based reasoning to provide good starting points to the genetic algorithm. The presented approach reaches the accuracy of grid search at a significantly lower computational cost. We performed extensive experiments for optimizing learning parameters of the Support Vector Machine (SVM) and …,True,o9RCNZYAAAAJ:vV6vV6tmYwMC,132,https://link.springer.com/content/pdf/10.1007/s10994-012-5286-7.pdf,12242316192499276333,/scholar?cites=12242316192499276333,,,https://link.springer.com/content/pdf/10.1007/s10994-012-5286-7.pdf,0,0,0
1277684,Automatic classifier selection for non-experts,2014,Matthias Reif and Faisal Shafait and Markus Goldstein and Thomas Breuel and Andreas Dengel,17,Pattern Analysis and Applications,1,83-96,Springer London,Choosing a suitable classifier for a given dataset is an important part of developing a pattern recognition system. Since a large variety of classification algorithms are proposed in literature. non-experts do not know which method should be used in order to obtain good classification results on their data. Meta-learning tries to address this problem by recommending promising classifiers based on meta-features computed from a given dataset. In this paper. we empirically evaluate five different categories of state-of-the-art meta-features for their suitability in predicting classification accuracies of several widely used classifiers (including Support Vector Machines. Neural Networks. Random Forests. Decision Trees. and Logistic Regression). Based on the evaluation results. we have developed the first open source meta-learning system that is capable of accurately predicting accuracies of target classifiers. The …,True,o9RCNZYAAAAJ:ldfaerwXgEUC,124,https://link.springer.com/article/10.1007/s10044-012-0280-z,7841053814849112324,/scholar?cites=7841053814849112324,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.432.9679&rep=rep1&type=pdf,0,0,0
1277685,Prenatal testosterone exposure is related to sexually dimorphic facial morphology in adulthood,2015,Andrew JO Whitehouse and Syed Zulqarnain Gilani and Faisal Shafait and Ajmal Mian and Diana Weiting Tan and Murray T Maybery and Jeffrey A Keelan and Roger Hart and David J Handelsman and Mithran Goonawardene and Peter Eastwood,282,Proceedings of the Royal Society B: Biological Sciences,1816,20151351,The Royal Society,Prenatal testosterone may have a powerful masculinizing effect on postnatal physical characteristics. However. no study has directly tested this hypothesis. Here. we report a 20-year follow-up study that measured testosterone concentrations from the umbilical cord blood of 97 male and 86 female newborns. and procured three-dimensional facial images on these participants in adulthood (range: 21–24 years). Twenty-three Euclidean and geodesic distances were measured from the facial images and an algorithm identified a set of six distances that most effectively distinguished adult males from females. From these distances. a ‘gender score’ was calculated for each face. indicating the degree of masculinity or femininity. Higher cord testosterone levels were associated with masculinized facial features when males and females were analysed together (n = 183; r = −0.59). as well as when males (n = 86; r = −0.55 …,True,o9RCNZYAAAAJ:Mojj43d5GZwC,117,https://royalsocietypublishing.org/doi/abs/10.1098/rspb.2015.1351,18160577454712192286,/scholar?cites=18160577454712192286,,,https://royalsocietypublishing.org/doi/full/10.1098/rspb.2015.1351,0,0,0
1277686,Optimal scheduling for charging and discharging of electric vehicles,2012,Yifeng He and Bala Venkatesh and Ling Guan,3,IEEE transactions on smart grid,3,1095-1105,IEEE,The vehicle electrification will have a significant impact on the power grid due to the increase in electricity consumption. It is important to perform intelligent scheduling for charging and discharging of electric vehicles (EVs). However. there are two major challenges in the scheduling problem. First. it is challenging to find the globally optimal scheduling solution which can minimize the total cost. Second. it is difficult to find a distributed scheduling scheme which can handle a large population and the random arrivals of the EVs. In this paper. we propose a globally optimal scheduling scheme and a locally optimal scheduling scheme for EV charging and discharging. We first formulate a global scheduling optimization problem. in which the charging powers are optimized to minimize the total cost of all EVs which perform charging and discharging during the day. The globally optimal solution provides the globally minimal …,True,dM3_ydMAAAAJ:u-x6o8ySG0sC,672,https://ieeexplore.ieee.org/abstract/document/6244822/,11417762946394181712,/scholar?cites=11417762946394181712,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.461.3190&rep=rep1&type=pdf,0,0,0
1277687,Handbook of neural network signal processing,2002,Yu Hen Hu and Jeng-Neng Hwang,111,,6,2525-2526,Acoustical Society of America,edited by Hu and Hwang aptly demonstrates the effectiveness and wide scope of the neural network paradigm for signal processing. The editors have brought together many leading experts in the neural network and signal processing fields to cover a wide variety of topics and recent developments. While many texts exist describing neural network algorithms. this book is unique in its solid coverage of neural network concepts. approaches to signal processing problems. and applications. The book consists of three parts. The first part of the book describes the various neural network paradigms. The different neural network approaches are described clearly and recent developments outlined. The second part of the book covers neural network approaches to some important signal processing problems. The final part of the book examines some successful neural network based applications and systems.The book …,True,dM3_ydMAAAAJ:DrR-2ekChdkC,613,https://asa.scitation.org/doi/pdf/10.1121/1.1480419,2738143235623692262,/scholar?cites=2738143235623692262,,,https://asa.scitation.org/doi/pdf/10.1121/1.1480419,0,0,0
1277688,A CAD system for the automatic detection of clustered microcalcifications in digitized mammogram films,2000,Songyang Yu and Ling Guan,19,IEEE transactions on medical imaging,2,115-126,IEEE,Clusters of microcalcifications in mammograms are an important early sign of breast cancer. This paper presents a computer-aided diagnosis (CAD) system for the automatic detection of clustered microcalcifications in digitized mammograms. The proposed system consists of two main steps. First. potential microcalcification pixels in the mammograms are segmented out by using mixed features consisting of wavelet features and gray level statistical features. and labeled into potential individual microcalcification objects by their spatial connectivity. Second. individual microcalcifications are detected by using a set of 31 features extracted from the potential individual microcalcification objects. The discriminatory power of these features is analyzed using general regression neural networks via sequential forward and sequential backward selection methods. The classifiers used in these two steps are both multilayer …,True,dM3_ydMAAAAJ:u5HHmVD_uO8C,448,https://ieeexplore.ieee.org/abstract/document/836371/,18179617707829003731,/scholar?cites=18179617707829003731,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.333.3218&rep=rep1&type=pdf,0,0,0
1277689,Recognizing human emotional state from audiovisual signals,2008,Yongjin Wang and Ling Guan,10,IEEE transactions on multimedia,5,936-946,IEEE, Machine recognition of human emotional state is an important component for efficient human-computer interaction. The majority of existing works address this problem by utilizing audio signals alone. or visual information only. In this paper. we explore a systematic approach for recognition of human emotional state from audiovisual signals. The audio characteristics of emotional speech are represented by the extracted prosodic. Mel-frequency Cepstral Coefficient (MFCC). and formant frequency features. A face detection scheme based on HSV color model is used to detect the face from the background. The visual information is represented by Gabor wavelet features. We perform feature selection by using a stepwise method based on Mahalanobis distance. The selected audiovisual features are used to classify the data into their corresponding emotions. Based on a comparative study of different classification …,True,dM3_ydMAAAAJ:d1gkVwhDpl0C,275,https://ieeexplore.ieee.org/abstract/document/4563453/,15132472575197664116,/scholar?cites=15132472575197664116,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.472.627&rep=rep1&type=pdf,0,0,0
1277690,Image retrieval based on energy histograms of the low frequency DCT coefficients,1999,Jose A Lay and Ling Guan,6,,,3009-3012,IEEE,With the increasing popularity of the use of compressed images. an intuitive approach for lowering computational complexity towards a practically efficient image retrieval system is to propose a scheme that is able to perform retrieval computation directly in the compressed domain. In this paper. we investigate the use of energy histograms of the low frequency DCT coefficients as features for the retrieval of DCT compressed images. We propose a feature set that is able to identify similarities on changes of image-representation due to several lossless DCT transformations. We then use the features to construct an image retrieval system based on the real-time image retrieval model. We observe that the proposed features are sufficient for performing high level retrieval on medium size image databases. And by introducing transpositional symmetry. the features can be brought to accommodate several lossless DCT …,True,dM3_ydMAAAAJ:9yKSN-GCB0IC,135,https://ieeexplore.ieee.org/abstract/document/757474/,580734732718238309,/scholar?cites=580734732718238309,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1014.9866&rep=rep1&type=pdf,0,0,0
1277691,An interactive approach for CBIR using a network of radial basis functions,2004,Paisarn Muneesawang and Ling Guan,6,IEEE Transactions on multimedia,5,703-716,IEEE,"An important requirement for constructing effective content-based image retrieval (CBIR) systems is accurate characterization of visual information. Conventional nonadaptive models. which are usually adopted for this task in simple CBIR systems. do not adequately capture all aspects of the characteristics of the human visual system. An effective way of addressing this problem is to adopt a ""human-computer"" interactive approach. where the users directly teach the system about what they regard as being significant image features and their own notions of image similarity. We propose a machine learning approach for this task. which allows users to directly modify query characteristics by specifying their attributes in the form of training examples. Specifically. we apply a radial-basis function (RBF) network for implementing an adaptive metric which progressively models the notion of image similarity through continual …",True,dM3_ydMAAAAJ:UeHWp8X0CEIC,132,https://ieeexplore.ieee.org/abstract/document/1335477/,994681566599656411,/scholar?cites=994681566599656411,,,http://www.ecpe.nu.ac.th/paisarn/Puplications/TM.pdf,0,0,0
1277692,A neural network approach for human emotion recognition in speech,2004,Muhammad Waqas Bhatti and Yongjin Wang and Ling Guan,2,,,II-181,IEEE,In this paper. we present a language-independent emotion recognition system for the identification of human affective state in the speech signal. A corpus of emotional speech from various subjects. speaking different languages is collected for developing and testing the feasibility of the system. The potential prosodic features are first identified and extracted from the speech data. Then we introduce a systematic feature selection approach which involves the application of Sequential Forward Selection (SFS) with a General Regression Neural Network (GRNN) in conjunction with a consistency-based selection method. The selected features are employed as the input to a Modular Neural Network (MNN) to realize the classification of emotions. The proposed system gives quite satisfactory emotion detection performance. yet demonstrates a significant increase in versatility through its propensity for language …,True,dM3_ydMAAAAJ:IjCSPb-OGe4C,132,https://ieeexplore.ieee.org/abstract/document/1329238/,8971949847614595054,/scholar?cites=8971949847614595054,,,,0,0,0
1277693,Optimal resource allocation for multimedia cloud based on queuing model,2011,Xiaoming Nan and Yifeng He and Ling Guan,,,,1-6,IEEE,Multimedia cloud. as a specific cloud paradigm. addresses how cloud can effectively process multimedia services and provide QoS provisioning for multimedia applications. There are two major challenges in multimedia cloud. The first challenge is the service response time in multimedia cloud. and the second challenge is the cost of cloud resources. In this paper. we optimize resource allocation for multimedia cloud based on queuing model. Specifically. we optimize the resource allocation in both single-class service case and multiple-class service case. In each case. we formulate and solve the response time minimization problem and resource cost minimization problem. respectively. Simulation results demonstrate that the proposed optimal allocation scheme can optimally utilize the cloud resources to achieve a minimal mean response time or a minimal resource cost.,True,dM3_ydMAAAAJ:ufrVoPGSRksC,131,https://ieeexplore.ieee.org/abstract/document/6093813/,13613482924097961056,/scholar?cites=13613482924097961056,,,https://www.researchgate.net/profile/Yifeng_He2/publication/221273979_Optimal_resource_allocation_for_multimedia_cloud_based_on_queuing_model/links/550a363b0cf20ed529e2845b.pdf,0,0,0
1277694,Quantifying and recognizing human movement patterns from monocular video images-part i: a new framework for modeling human motion,2004,Richard D Green and Ling Guan,14,IEEE Transactions on Circuits and Systems for Video Technology,2,179-190,IEEE,Research into tracking and recognizing human movement has so far been mostly limited to gait or frontal posing. Part I of this paper presents a continuous human movement recognition (CHMR) framework which forms a basis for the general biometric analysis of continuous human motion as demonstrated through tracking and recognition of hundreds of skills from gait to twisting saltos. Part II of this paper presents CHMR applications to the biometric authentication of gait. anthropometric data. human activities. and movement disorders. In Part I of this paper. a novel three-dimensional color clone-body-model is dynamically sized and texture mapped to each person for more robust tracking of both edges and textured regions. Tracking is further stabilized by estimating the joint angles for the next frame using a forward smoothing particle filter with the search space optimized by utilizing feedback from the CHMR system …,True,dM3_ydMAAAAJ:2osOgNQ5qMEC,126,https://ieeexplore.ieee.org/abstract/document/1269751/,7078592392587479320,/scholar?cites=7078592392587479320,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.451.9828&rep=rep1&type=pdf,0,0,0
1277695,Kernel cross-modal factor analysis for information fusion with application to bimodal emotion recognition,2012,Yongjin Wang and Ling Guan and Anastasios N Venetsanopoulos,14,IEEE Transactions on Multimedia,3,597-607,Ieee,In this paper. we investigate kernel based methods for multimodal information analysis and fusion. We introduce a novel approach. kernel cross-modal factor analysis. which identifies the optimal transformations that are capable of representing the coupled patterns between two different subsets of features by minimizing the Frobenius norm in the transformed domain. The kernel trick is utilized for modeling the nonlinear relationship between two multidimensional variables. We examine and compare with kernel canonical correlation analysis which finds projection directions that maximize the correlation between two modalities. and kernel matrix fusion which integrates the kernel matrices of respective modalities through algebraic operations. The performance of the introduced method is evaluated on an audiovisual based bimodal emotion recognition problem. We first perform feature extraction from the audio and …,True,dM3_ydMAAAAJ:Zph67rFs4hoC,121,https://ieeexplore.ieee.org/abstract/document/6161652/,10953023339061230709,/scholar?cites=10953023339061230709,,,https://www.academia.edu/download/46316929/2012tmm_ywang.pdf,0,0,0
1277696,Modularity in neural computing,1999,Terry Caelli and Ling Guan and Wilson Wen,87,,9,1497-1518,IEEE,This paper considers neural computing models for information processing in terms of collections of subnetwork modules. Two approaches to generating such networks are studied. The first approach includes networks with functionally independent subnetworks. where each subnetwork is designed to have specific functions. communication. and adaptation characteristics. The second approach is based on algorithms that can actually generate network and subnetwork topologies. connections. and weights to satisfy specific constraints. Associated algorithms to attain these goals include evolutionary computation and self-organizing maps. We argue that this modular approach to neural computing is more in line with the neurophysiology of the vertebrate cerebral cortex. particularly with respect to sensation and perception. We also argue that this approach has the potential to aid in solutions to large-scale network …,True,dM3_ydMAAAAJ:qjMakFHDy7sC,121,https://ieeexplore.ieee.org/abstract/document/784227/,12024470276084764110,/scholar?cites=12024470276084764110,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.7238&rep=rep1&type=pdf,0,0,0
1277697,Fast and robust fuzzy c-means clustering algorithms incorporating local information for image segmentation,2007,Weiling Cai and Songcan Chen and Daoqiang Zhang,40,Pattern recognition,3,825-838,Pergamon,Fuzzy c-means (FCM) algorithms with spatial constraints (FCM_S) have been proven effective for image segmentation. However. they still have the following disadvantages:(1) although the introduction of local spatial information to the corresponding objective functions enhances their insensitiveness to noise to some extent. they still lack enough robustness to noise and outliers. especially in absence of prior knowledge of the noise;(2) in their objective functions. there exists a crucial parameter α used to balance between robustness to noise and effectiveness of preserving the details of the image. it is selected generally through experience; and (3) the time of segmenting an image is dependent on the image size. and hence the larger the size of the image. the more the segmentation time. In this paper. by incorporating local spatial and gray information together. a novel fast and robust FCM framework for image …,True,j9x2t78AAAAJ:WJVC3Jt7v1AC,1189,https://www.sciencedirect.com/science/article/pii/S0031320306003451,3646915698998018870,/scholar?cites=3646915698998018870,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.6568&rep=rep1&type=pdf,0,0,0
1277698,Iterative weighted maximum likelihood denoising with probabilistic patch-based weights,2009,Charles-Alban Deledalle and Loïc Denis and Florence Tupin,18,IEEE Transactions on Image Processing,12,2661-2672,IEEE,Image denoising is an important problem in image processing since noise may interfere with visual or automatic interpretation. This paper presents a new approach for image denoising in the case of a known uncorrelated noise model. The proposed filter is an extension of the nonlocal means (NL means) algorithm introduced by Buades. which performs a weighted average of the values of similar pixels. Pixel similarity is defined in NL means as the Euclidean distance between patches (rectangular windows centered on each two pixels). In this paper. a more general and statistically grounded similarity criterion is proposed which depends on the noise distribution model. The denoising process is expressed as a weighted maximum likelihood estimation problem where the weights are derived in a data-driven way. These weights can be iteratively refined based on both the similarity between noisy patches and the …,True,j9x2t78AAAAJ:p__nRnzSRKYC,665,https://ieeexplore.ieee.org/abstract/document/5196737/,12410838019453353168,/scholar?cites=12410838019453353168,,,https://perso.telecom-paristech.fr/tupin/PUB/articleTIP2009.pdf,0,0,0
1277699,Detection of linear features in SAR images: Application to road network extraction,1998,Florence Tupin and Henri Maitre and J-F Mangin and J-M Nicolas and Eugene Pechersky,36,IEEE transactions on geoscience and remote sensing,2,434-453,IEEE,We propose a two-step algorithm for almost unsu-pervised detection of linear structures. in particular. main axes in road networks. as seen in synthetic aperture radar (SAR) images. The first step is local and is used to extract linear features from the speckle radar image. which are treated as roadsegment candidates. We present two local line detectors as well as a method for fusing information from these detectors. In the second global step. we identify the real roads among the segment candidates by defining a Markov random field (MRF) on a set of segments. which introduces contextual knowledge about the shape of road objects. The influence of the parameters on the road detection is studied and results are presented for various real radar images.,True,j9x2t78AAAAJ:M05iB0D1s5AC,662,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4227&rep=rep1&type=pdf,5472932434415609012,/scholar?cites=5472932434415609012,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4227&rep=rep1&type=pdf,0,0,0
1277700,A new statistical model for Markovian classification of urban areas in high-resolution SAR images,2004,Céline Tison and J-M Nicolas and Florence Tupin and Henri Maître,42,IEEE transactions on geoscience and remote sensing,10,2046-2057,IEEE,We propose a classification method suitable for high-resolution synthetic aperture radar (SAR) images over urban areas. When processing SAR images. there is a strong need for statistical models of scattering to take into account multiplicative noise and high dynamics. For instance. the classification process needs to be based on the use of statistics. Our main contribution is the choice of an accurate model for high-resolution SAR images over urban areas and its use in a Markovian classification algorithm. Clutter in SAR images becomes non-Gaussian when the resolution is high or when the area is man-made. Many models have been proposed to fit with non-Gaussian scattering statistics (K. Weibull. Log-normal. Nakagami-Rice. etc.). but none of them is flexible enough to model all kinds of surfaces in our context. As a consequence. we use a mathematical model that relies on the Fisher distribution and the log …,True,j9x2t78AAAAJ:isC4tDSrTZIC,428,https://ieeexplore.ieee.org/abstract/document/1344157/,15398760760699532736,/scholar?cites=15398760760699532736,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.329.3329&rep=rep1&type=pdf,0,0,0
1277701,NL-SAR: A unified nonlocal framework for resolution-preserving (Pol)(In) SAR denoising,2014,Charles-Alban Deledalle and Loïc Denis and Florence Tupin and Andreas Reigber and Marc Jäger,53,IEEE Transactions on Geoscience and Remote Sensing,4,2021-2038,IEEE,Speckle noise is an inherent problem in coherent imaging systems such as synthetic aperture radar. It creates strong intensity fluctuations and hampers the analysis of images and the estimation of local radiometric. polarimetric. or interferometric properties. Synthetic aperture radar (SAR) processing chains thus often include a multilooking (i.e.. averaging) filter for speckle reduction. at the expense of a strong resolution loss. Preservation of point-like and fine structures and textures requires to adapt locally the estimation. Nonlocal (NL)-means successfully adapt smoothing by deriving data-driven weights from the similarity between small image patches. The generalization of nonlocal approaches offers a flexible framework for resolution-preserving speckle reduction. We describe a general method. i.e.. NL-SAR. that builds extended nonlocal neighborhoods for denoising amplitude. polarimetric. and/or interferometric …,True,j9x2t78AAAAJ:OU6Ihb5iCvQC,336,https://ieeexplore.ieee.org/abstract/document/6905794/,16195860779042672572,/scholar?cites=16195860779042672572,,,https://hal.archives-ouvertes.fr/docs/00/84/41/18/PDF/nlsar_hal.pdf,0,0,0
1277702,SAR-SIFT: a SIFT-like algorithm for SAR images,2014,Flora Dellinger and Julie Delon and Yann Gousseau and Julien Michel and Florence Tupin,53,IEEE Transactions on Geoscience and Remote Sensing,1,453-466,IEEE,The scale-invariant feature transform (SIFT) algorithm and its many variants are widely used in computer vision and in remote sensing to match features between images or to localize and recognize objects. However. mostly because of speckle noise. it does not perform well on synthetic aperture radar (SAR) images. In this paper. we introduce a SIFT-like algorithm specifically dedicated to SAR imaging. which is named SAR-SIFT. The algorithm includes both the detection of keypoints and the computation of local descriptors. A new gradient definition. yielding an orientation and a magnitude that are robust to speckle noise. is first introduced. It is then used to adapt several steps of the SIFT algorithm to SAR images. We study the improvement brought by this new algorithm. as compared with existing approaches. We present an application of SAR-SIFT to the registration of SAR images in different configurations …,True,j9x2t78AAAAJ:f2IySw72cVMC,260,https://ieeexplore.ieee.org/abstract/document/6824220/,6497146526686595442,/scholar?cites=6497146526686595442,,,https://hal.archives-ouvertes.fr/hal-00831763/file/preprint_sar_sift_dellinger_hal.pdf,0,0,0
1277703,NL-InSAR: Nonlocal interferogram estimation,2010,Charles-Alban Deledalle and Loïc Denis and Florence Tupin,49,IEEE Transactions on Geoscience and Remote Sensing,4,1441-1452,IEEE,Interferometric synthetic aperture radar (SAR) data provide reflectivity. interferometric phase. and coherence images. which are paramount to scene interpretation or low-level processing tasks such as segmentation and 3-D reconstruction. These images are estimated in practice from a Hermitian product on local windows. These windows lead to biases and resolution losses due to the local heterogeneity caused by edges and textures. This paper proposes a nonlocal approach for the joint estimation of the reflectivity. the interferometric phase. and the coherence images from an interferometric pair of coregistered single-look complex (SLC) SAR images. Nonlocal techniques are known to efficiently reduce noise while preserving structures by performing the weighted averaging of similar pixels. Two pixels are considered similar if the surrounding image patches are “resembling.” Patch similarity is usually defined as …,True,j9x2t78AAAAJ:pyW8ca7W8N0C,225,https://ieeexplore.ieee.org/abstract/document/5617267/,15155944013838403613,/scholar?cites=15155944013838403613,,,https://www.charles-deledalle.fr/pages/files/articleTGRS2010.pdf,0,0,0
1277704,Time series analysis of Mexico City subsidence constrained by radar interferometry,2009,Penélope López-Quiroz and Marie-Pierre Doin and Florence Tupin and Pierre Briole and Jean-Marie Nicolas,69,Journal of Applied Geophysics,1,1-15,Elsevier,In Mexico City. subsidence rates reach up to 40 cm/yr mainly due to soil compaction led by the over exploitation of the Mexico Basin aquifer. In this paper. we map the spatial and temporal patterns of the Mexico City subsidence by differential radar interferometry. using 38 ENVISAT images acquired between end of 2002 and beginning of 2007. We present the severe interferogram unwrapping problems partly due to the coherence loss but mostly due to the high fringe rates. These difficulties are overcome by designing a new methodology that helps the unwrapping step. Our approach is based on the fact that the deformation shape is stable for similar time intervals during the studied period. As a result. a stack of the five best interferograms can be used to compute an average deformation rate for a fixed time interval. Before unwrapping. the number of fringes is then decreased in wrapped interferograms using a scaled …,True,j9x2t78AAAAJ:d1gkVwhDpl0C,196,https://www.sciencedirect.com/science/article/pii/S0926985109000251,12245436238326799510,/scholar?cites=12245436238326799510,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.660.9083&rep=rep1&type=pdf,0,0,0
1277705,Unsupervised classification of radar images using hidden Markov chains and hidden Markov random fields,2003,Roger Fjortoft and Yves Delignon and Wojciech Pieczynski and Marc Sigelle and Florence Tupin,41,IEEE Transactions on geoscience and remote sensing,3,675-686,IEEE,Due to the enormous quantity of radar images acquired by satellites and through shuttle missions. there is an evident need for efficient automatic analysis tools. This paper describes unsupervised classification of radar images in the framework of hidden Markov models and generalized mixture estimation. Hidden Markov chain models. applied to a Hilbert-Peano scan of the image. constitute a fast and robust alternative to hidden Markov random field models for spatial regularization of image analysis problems. even though the latter provide a finer and more intuitive modeling of spatial relationships. We here compare the two approaches and show that they can be combined in a way that conserves their respective advantages. We also describe how the distribution families and parameters of classes with constant or textured radar reflectivity can be determined through generalized mixture estimation. Sample results …,True,j9x2t78AAAAJ:wbdj-CoPYUoC,161,https://ieeexplore.ieee.org/abstract/document/1198658/,11143926259025408486,/scholar?cites=11143926259025408486,,,,0,0,0
1277706,Detection of building outlines based on the fusion of SAR and optical features,2003,Florence Tupin and Michel Roux,58,ISPRS Journal of Photogrammetry and Remote Sensing,1-2,71-82,Elsevier,This paper deals with the automatic extraction of building outlines using a pair of optical and synthetic aperture radar (SAR) images. The aim is to define areas of interest for building height reconstruction in radargrammetric or interferometric applications. Since high resolution optical satellite images are now easily available. such methods merging SAR and optical information could be useful to improve 3D SAR reconstruction (the optical image giving only information on the scene organization). Both SAR and optical data bring complementary information about the building presence and shape. The proposed method is divided into two main steps: first. extraction of partial potential building footprints on the SAR image. and then shape detection on the optical one using the previously extracted primitives (lines). Two methods of shape detection have been developed. the simplest one finding the “best” rectangular …,True,j9x2t78AAAAJ:5ugPr518TE4C,147,https://www.sciencedirect.com/science/article/pii/S0924271603000182,7357591295634340063,/scholar?cites=7357591295634340063,,,https://perso.telecom-paristech.fr/tupin/PUB/isprs03.pdf,0,0,0
1277707,Exploiting patch similarity for SAR image processing: The nonlocal paradigm,2014,Charles-Alban Deledalle and Loic Denis and Giovanni Poggi and Florence Tupin and Luisa Verdoliva,31,IEEE Signal Processing Magazine,4,69-78,IEEE,Most current synthetic aperture radar (SAR) systems offer high-resolution images featuring polarimetric. interferometric. multifrequency. multiangle. or multidate information. SAR images. however. suffer from strong fluctuations due to the speckle phenomenon inherent to coherent imagery. Hence. all derived parameters display strong signal-dependent variance. preventing the full exploitation of such a wealth of information. Even with the abundance of despeckling techniques proposed over the last three decades. there is still a pressing need for new methods that can handle this variety of SAR products and efficiently eliminate speckle without sacrificing the spatial resolution. Recently. patch-based filtering has emerged as a highly successful concept in image processing. By exploiting the redundancy between similar patches. it succeeds in suppressing most of the noise with good preservation of texture and thin …,True,j9x2t78AAAAJ:VLnqNzywnoUC,140,https://ieeexplore.ieee.org/abstract/document/6832893/,2882045013232826642,/scholar?cites=2882045013232826642,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.635.2028&rep=rep1&type=pdf,0,0,0
1277708,Fuzzy connectedness and object definition: Theory. algorithms. and applications in image segmentation,1996,Jayaram K Udupa and Supun Samarasekera,58,Graphical models and image processing,3,246-261,Academic Press,Images are by nature fuzzy. Approaches to object information extraction from images should attempt to use this fact and retain fuzziness as realistically as possible. In past image segmentation research. the notion of “hanging togetherness” of image elements specified by their fuzzy connectedness has been lacking. We present a theory of fuzzy objects forn-dimensional digital spaces based on a notion of fuzzy connectedness of image elements. Although our definitions lead to problems of enormous combinatorial complexity. the theoretical results allow us to reduce this dramatically. leading us to practical algorithms for fuzzy object extraction. We present algorithms for extracting a specified fuzzy object and for identifying all fuzzy objects present in the image data. We demonstrate the utility of the theory and algorithms in image segmentation based on several practical examples all drawn from medical imaging.,True,IQt4hvoAAAAJ:d1gkVwhDpl0C,1287,https://www.sciencedirect.com/science/article/pii/S1077316996900210,1265201801976403635,/scholar?cites=1265201801976403635,,,https://pdfs.semanticscholar.org/4a3e/9fcfc88d53cdf0b7633fbc914f98d1e92225.pdf,0,0,0
1277709,Hands-on morphological image processing,2003,Edward R Dougherty and Roberto A Lotufo,59,,,,SPIE press,Morphological image processing. a standard part of the imaging scientist's toolbox. can be applied to a wide range of industrial applications. Concentrating on applications. this text shows how to analyse the problems and then develop successful algorithms to solve them.,True,IQt4hvoAAAAJ:u5HHmVD_uO8C,823,http://books.google.com/books?hl=en&lr=&id=-ch3fZTh08EC&oi=fnd&pg=PR11&dq=info:GA_277l7G1QJ:scholar.google.com&ots=obSK_Xk_G0&sig=Vepwq9E2aHYUDhXfUtmYutIgEnc,6060573762082180888,/scholar?cites=6060573762082180888,,,,0,0,0
1277710,The image foresting transform: Theory. algorithms. and applications,2004,Alexandre X Falcão and Jorge Stolfi and Roberto de Alencar Lotufo,26,IEEE transactions on pattern analysis and machine intelligence,1,19-29,IEEE,The image foresting transform (IFT) is a graph-based approach to the design of image processing operators based on connectivity. It naturally leads to correct and efficient implementations and to a better understanding of how different operators relate to each other. We give here a precise definition of the IFT. and a procedure to compute it-a generalization of Dijkstra's algorithm-with a proof of correctness. We also discuss implementation issues and illustrate the use of the IFT in a few applications.,True,IQt4hvoAAAAJ:UHK10RUVsp4C,783,https://ieeexplore.ieee.org/abstract/document/1261076/,16938947297191889037,/scholar?cites=16938947297191889037,,,https://www.academia.edu/download/42987870/IFT_Falcao_PAMI04.pdf,0,0,0
1277711,User-steered image segmentation paradigms: Live wire and live lane,1998,Alexandre X Falcao and Jayaram K Udupa and Supun Samarasekera and Shoba Sharma and Bruce Elliot Hirsch and Roberto de A Lotufo,60,Graphical models and image processing,4,233-260,Academic Press,In multidimensional image analysis. there are. and will continue to be. situations wherein automatic image segmentation methods fail. calling for considerable user assistance in the process. The main goals of segmentation research for such situations ought to be (i) to provideeffective controlto the user on the segmentation processwhileit is being executed. and (ii) to minimize the total user's time required in the process. With these goals in mind. we present in this paper two paradigms. referred to aslive wireandlive lane. for practical image segmentation in large applications. For both approaches. we think of the pixel vertices and oriented edges as forming a graph. assign a set of features to each oriented edge to characterize its ``boundariness.'' and transform feature values to costs. We provide training facilities and automatic optimal feature and transform selection methods so that these assignments can be made …,True,IQt4hvoAAAAJ:mB3voiENLucC,756,https://www.sciencedirect.com/science/article/pii/S1077316998904750,16964695101080516264,/scholar?cites=16964695101080516264,,,,0,0,0
1277712,Fingerprint liveness detection using convolutional neural networks,2016,Rodrigo Frassetto Nogueira and Roberto de Alencar Lotufo and Rubens Campos Machado,11,IEEE transactions on information forensics and security,6,1206-1213,IEEE,With the growing use of biometric authentication systems in the recent years. spoof fingerprint detection has become increasingly important. In this paper. we use convolutional neural networks (CNNs) for fingerprint liveness detection. Our system is evaluated on the data sets used in the liveness detection competition of the years 2009. 2011. and 2013. which comprises almost 50 000 real and fake fingerprints images. We compare four different models: two CNNs pretrained on natural images and fine-tuned with the fingerprint images. CNN with random weights. and a classical local binary pattern approach. We show that pretrained CNNs can yield the state-of-the-art results with no need for architecture or hyperparameter selection. Data set augmentation is used to increase the classifiers performance. not only for deep architectures but also for shallow ones. We also report good accuracy on very small training sets …,True,IQt4hvoAAAAJ:OkrdTXRNpVkC,246,https://ieeexplore.ieee.org/abstract/document/7390065/,205381840540852397,/scholar?cites=205381840540852397,,,,0,0,0
1277713,RNAi microarray analysis in cultured mammalian cells,2003,Spyro Mousses and Natasha J Caplen and Robert Cornelison and Don Weaver and Mark Basik and Sampsa Hautaniemi and Abdel G Elkahloun and Roberto A Lotufo and Ashish Choudary and Edward R Dougherty and Ed Suh and Olli Kallioniemi,13,Genome research,10,2341-2347,Cold Spring Harbor Lab,RNA interference (RNAi) mediated by small interfering RNAs (siRNAs) is a powerful new tool for analyzing gene knockdown phenotypes in living mammalian cells. To facilitate large-scale. high-throughput functional genomics studies using RNAi. we have developed a microarray-based technology for highly parallel analysis. Specifically. siRNAs in a transfection matrix were first arrayed on glass slides. overlaid with a monolayer of adherent cells. incubated to allow reverse transfection. and assessed for the effects of gene silencing by digital image analysis at a single cell level. Validation experiments with HeLa cells stably expressing GFP showed spatially confined. sequence-specific. time- and dose-dependent inhibition of green fluorescence for those cells growing directly on microspots containing siRNA targeting the GFP sequence. Microarray-based siRNA transfections analyzed with a custom-made quantitative …,True,IQt4hvoAAAAJ:u-x6o8ySG0sC,233,https://genome.cshlp.org/content/13/10/2341.short,16739686307188096044,/scholar?cites=16739686307188096044,,,https://genome.cshlp.org/content/13/10/2341.full.pdf,0,0,0
1277714,Automatic estimation of crowd density using texture,1998,A NSAV Marana and Sergio A Velastin and L da F Costa and RA Lotufo,28,Safety Science,3,165-175,Elsevier,This paper considers the role of automatic estimation of crowd density and its importance for the automatic monitoring of areas where crowds are expected to be present. A new technique is proposed which is able to estimate densities ranging from very low to very high concentration of people. which is a difficult problem because in a crowd only parts of people's body appear. The new technique is based on the differences of texture patterns of the images of crowds. Images of low density crowds tend to present coarse textures. while images of dense crowds tend to present fine textures. The image pixels are classified in different texture classes and statistics of such classes are used to estimate the number of people. The texture classification and the estimation of people density are carried out by means of self organising neural networks. Results obtained respectively to the estimation of the number of people in a …,True,IQt4hvoAAAAJ:HDshCWvjkbEC,209,https://www.sciencedirect.com/science/article/pii/S0925753597000817,14368715926740803073,/scholar?cites=14368715926740803073,,,https://www.academia.edu/download/47052516/Automatic_estimation_of_crowd_density_us20160706-2281-846s3b.pdf,0,0,0
1277715,Estimating crowd density with Minkowski fractal dimension,1999,Aparecido Nilceu Marana and L Da Fontoura Costa and RA Lotufo and Sergio A Velastin,6,,,3521-3524,IEEE,The estimation of the number of people in an area under surveillance is very important for the problem of crowd monitoring. When an area reaches an occupation level greater than the projected one. people's safety can be in danger. This paper describes a new technique for crowd density estimation based on Minkowski fractal dimension. The fractal dimension has been widely used to characterize data texture in a large number of physical and biological sciences. The results of our experiments show that fractal dimension can also be used to characterize levels of people congestion in images of crowds. The proposed technique is compared with a statistical and a spectral technique. in a test study of nearly 300 images of a specific area of the Liverpool Street Railway Station. London. UK. Results obtained in this test study are presented.,True,IQt4hvoAAAAJ:TQgYirikUcIC,205,https://ieeexplore.ieee.org/abstract/document/757602/,16664331636694974057,/scholar?cites=16664331636694974057,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.1287&rep=rep1&type=pdf,0,0,0
1277716,Estimation of crowd density using image processing,1997,Aparecido Nilceu Marana and SA Velastin and LF Costa and RA Lotufo,,,,11-11,IET Digital Library,Human beings perceive images through their properties. like colour. shape. size. and texture. Texture is a fertile source of information about the physical environment. Images of low density crowds tend to present coarse textures. while images of dense crowds tend to present fine textures. The paper describes a technique for automatic estimation of crowd density. which is a part of the problem of automatic crowd monitoring. using texture information based on grey level transition probabilities on digitised images. Crowd density feature vectors are extracted from such images and used by a self organising neural network which is responsible for the crowd density estimation. Results obtained respectively to the estimation of the number of people in a specific area of Liverpool Street Railway Station in London (UK) are presented. (8 pages),True,IQt4hvoAAAAJ:R3hNpaxXUhUC,202,https://digital-library.theiet.org/content/conferences/10.1049/ic_19970387,16134434644617238723,/scholar?cites=16134434644617238723,,,,0,0,0
1277717,The ordered queue and the optimality of the watershed approaches,2002,Roberto Lotufo and Alexandre Falcao,,,,341-350,Springer. Boston. MA,This work reviews the watershed in the graph framework of a shortest-path forest problem using a lexicographic path cost formulation. This formulation reflects the behavior of the ordered queue-based watershed algorithm. This algorithm is compared with our proposed shortest-path forest (IFT-Image Foresting Transform). concluding that the watershed is a special case of that. Recently many different watershed approaches are being used. We point out that in some cases the watershed algorithm does not keep the optimality of the shortest-path forest solution unless the IFT algorithm is used. The main difference between the algorithms is related to permanently labeling a pixel when inserting or removing it from the queue. The watershed based on the pixel dissimilarity using IFT can segment one-pixel width regions while keeping the optimality of the shortest-path forest solution.,True,IQt4hvoAAAAJ:dfsIfKJdRG4C,184,https://link.springer.com/chapter/10.1007/0-306-47025-X_37,9299604611263408614,/scholar?cites=9299604611263408614,,,http://ndl.ethernet.edu.et/bitstream/123456789/61026/1/34.pdf#page=352,0,0,0
1277718,On the efficacy of texture analysis for crowd monitoring,1998,AN Marana and L da F Costa and RA Lotufo and SA Velastin,,,,354-361,IEEE,The goal of this work is to assess the efficacy of texture measures for estimating levels of crowd densities in images. This estimation is crucial for the problem of crowd monitoring and control. The assessment is carried out on a set of nearly 300 real images captured from Liverpool Street Train Station. London. UK. using texture measures extracted from the images through the following four different methods: gray level dependence matrices. straight line segments. Fourier analysis. and fractal dimensions. The estimations of crowd densities are given in terms of the classification of the input images in five classes of densities (very low. low. moderate. high and very high). Three types of classifiers are used: neural (implemented according to the Kohonen model). Bayesian. and an approach based on fitting functions. The results obtained by these three classifiers. using the four texture measures. allowed the conclusion …,True,IQt4hvoAAAAJ:_Qo2XoVZTnwC,184,https://ieeexplore.ieee.org/abstract/document/722773/,11673415961385156229,/scholar?cites=11673415961385156229,,,,0,0,0
1277719,Image Retrieval using Color-Texture Features from DCT on VQ Codevectors obtained by Kekre’s Fast Codebook Generation,2009,HB Kekre and Ms Tanuja K Sarode and D Thepade Sudeep,9,"ICGST-International Journal on Graphics, Vision and Image Processing (GVIP)",5,1-8,,The novel technique for image retrieval using the colortexture features extracted from images based on vector quantization with Kekre’s fast codebook generation is proposed. This gives better discrimination capability for Content Based Image Retrieval (CBIR). Here the database image is divided into 2x2 pixel windows to obtain 12 color descriptors per window (Red. Green and Blue per pixel) to form a vector. Collection of all such vectors is a training set. Then the Kekre’s Fast Codebook Generation (KFCG) is applied on this set to get 16 codevectors. The Discrete Cosine Transform (DCT) is applied on these codevectors by converting them to column vector. This transform vector is used as the image signature (feature vector) for image retrieval. The method takes lesser computations as compared to conventional DCT applied on complete image. The method gives the color-texture features of the image database at reduced feature set size. Proposed method avoids resizing of images which is required for any transform based feature extraction method.,True,oiVHiwcAAAAJ:u5HHmVD_uO8C,154,https://www.researchgate.net/profile/Ashraf_Aboshosha/publication/284305672_GVIP-Volume9-Issue5-P1151547448/links/56514f0308aefe619b15920c.pdf#page=5,8890491884122953885,/scholar?cites=8890491884122953885,,,https://www.researchgate.net/profile/Ashraf_Aboshosha/publication/284305672_GVIP-Volume9-Issue5-P1151547448/links/56514f0308aefe619b15920c.pdf#page=5,0,0,0
1277720,Image Retrieval using Augmented Block Truncation Coding Techniques,2009,HB Kekre and Sudeep D Thepade,,,,384-390,ACM,With the tremendous growth of ICT (Information and Communication Technology). we are able to generate. store. share and transfer enormous amount of information. World Wide Web have further made is easy to access the information anytime. anywhere in the world. With the advent of high capacity communication links and storage devices even most of the information generated is of multimedia in nature. Images have major share in this information and the number of image achieves are growing with the jet speed Just having the tremendous amount of information is not useful unless we do not have the methodologies to effectively search the related data from it in minimum possible duration. The relativity of the image data is application specific. Here to search and retrieve the expected images from the database we need Content Based Image Retrieval (CBIR) system. CBIR extracts the features of query image …,True,oiVHiwcAAAAJ:zYLM7Y9cAGgC,150,https://dl.acm.org/doi/abs/10.1145/1523103.1523180,11515989196293964029,/scholar?cites=11515989196293964029,,,https://www.researchgate.net/profile/Hemant_Kekre/publication/234785580_Image_retrieval_using_augmented_block_truncation_coding_techniques/links/0deec52cf79a4541eb000000.pdf,0,0,0
1277721,Boosting Block Truncation Coding with Kekre’s LUV Color Space for Image Retrieval,2008,HB Kekre and D Thepade Sudeep,2,"International Journal of Electrical, Computer, and Systems Engineering",3,,,,True,oiVHiwcAAAAJ:9yKSN-GCB0IC,143,,8066474965934081659,/scholar?cites=8066474965934081659,,,,0,0,0
1277722,Image Retrieval using Texture Features extracted from GLCM. LBG and KPE,2010,HB Kekre and Sudeep D Thepade and Tanuja K Sarode and Vashali Suryawanshi,2,International Journal of Computer Theory and Engineering,5,695,IACSIT Press,In this paper a novel method for image retrieval based on texture feature extraction using Vector Quantization (VQ) is proposed. We have used Linde-Buzo-Gray (LBG) and Kekre’s Proportionate Error (KPE) algorithms for texture feature extraction. The image is first divided into pixel blocks of size 2X2. each pixel with red. green and blue component. A training vector of dimensions 12 is created using this block. Collection of such training vectors is a training set. To generate the texture feature vector (size of codebook 16X12) of the image. popular LBG and KPE algorithms are applied on the initial training set. Results are compared with the Gray Level Co-occurance Matrix (GLCM) method. The proposed method requires 89.10% less computations compared to the GLCM method. The LBG and KPE based image retrieval techniques give higher precision and recall values than GLCM based method. which concludes that the proposed techniques give better texture feature discrimination capability than GLCM.,True,oiVHiwcAAAAJ:QyXJ3EUuO1IC,139,http://www.ijcte.org/papers/227-G310.pdf,2794552922922259264,/scholar?cites=2794552922922259264,,,http://www.ijcte.org/papers/227-G310.pdf,0,0,0
1277723,Color traits transfer to grayscale images,2008,Hemant B Kekre and Sudeep D Thepade,,,,82-85,IEEE,Here we are presenting some novel techniques for squirting colors in grayscale images. The problem of coloring grayscale images has no exact solution. Here we are attempting to minimize the human efforts needed in manually coloring the grayscale images. We need human interaction only to find a reference color image. then the job of transferring color traits from reference color image to grayscale image is done by proposed techniques. In these techniques. the color palette is prepared using pixel windows of some degrees taken from reference color image. Then the grayscale image is divided into pixel windows with same degrees. For every window of grayscale image the palette is searched for equivalent color values. which could be used to color grayscale window. In the whole process the luminance values of reference color image and target grayscale image are only matched and based on best possible …,True,oiVHiwcAAAAJ:IjCSPb-OGe4C,119,https://ieeexplore.ieee.org/abstract/document/4579871/,4187942138256009338,/scholar?cites=4187942138256009338,,,,0,0,0
1277724,Using YUV Color Space to Hoist the Performance of Block Truncation Coding for Image Retrieval,2009,HB Kekre and D Thepade Sudeep,,IEEE International Advanced Computing Conference,,,,,True,oiVHiwcAAAAJ:Tyk-4Ss8FVUC,110,http://scholar.google.com/scholar?cluster=17973662459632626586&hl=en&oi=scholarr,17973662459632626586,/scholar?cites=17973662459632626586,,,,0,0,0
1277725,DCT Applied to Row Mean and Column Vectors in Fingerprint Identification,2008,HB Kekre and Tanuja Sarode and D Thepade Sudeep,,Proceedings of International Conference on Computer Networks and Security (ICCNS),,27-28,,,True,oiVHiwcAAAAJ:u-x6o8ySG0sC,107,http://scholar.google.com/scholar?cluster=3036568897365046395&hl=en&oi=scholarr,3036568897365046395,/scholar?cites=3036568897365046395,,,,0,0,0
1277726,Color-Texture Feature based Image Retrieval using DCT applied on Kekre? s Median Codebook,2009,HB Kekre and Tanuja K Sarode,2,,,55-65,INTERNATIONAL JOURNAL ON IMAGING,"Use Online Translation Powered By. Click Here Trajomyar Trajomyar. www.SID.ir. Home;
Journals; Authors; ISI Iranian Journals; Updated Journals; JCR; About Us; Contact Us; Help;
Others Scientific Information Databases: بانک نشریات فارسی ایران; بانک همایش های علمی فارسی
ایران; بانک طرح های پژوهشی فارسی ایران; مراکز علمی تخصصی ایران; English Journals Database
of Iran; English Seminars Database of Iran. امروز: 24/08/1398. Papers Advanced Search Papers ...
English; فارسی. Paper Information. Journal: INTERNATIONAL JOURNAL ON IMAGING 2009 .
Volume 2 . Number -; Page(s) 55 To 65. Paper: COLOR-TEXTURE FEATURE BASED IMAGE
RETRIEVAL USING DCT APPLIED ON KEKRE?S MEDIAN CODEBOOK. Author(s): KEKRE
HB. SARODE TK. *. * There is no information … 
",True,oiVHiwcAAAAJ:qjMakFHDy7sC,97,https://www.sid.ir/en/Journal/ViewPaper.aspx?ID=429113,4477245348650406246,/scholar?cites=4477245348650406246,,,,0,0,0
1277727,Image Blending in Vista Creation using Kekre's LUV Color Space,2008,HB Kekre and D Thepade Sudeep,,"SPIT-IEEE Colloquium and International Conference, Sardar Patel Institute of Technology, Andheri, Mumbai",,04-05,,Vista creation (Panorama construction) is used to construct an image with a large field of view than that could be obtained with a single photograph. It refers to transforming and stitching multiple images into a new aggregate image without any visible seam or distortion in the overlapping areas. This seam indicates where one image ends and the other image begins. These images should be combined in such a way that the final image does not have any spurious artificial edges. But if the partial images are differing in brightness. seam becomes visible in final panoramic view. To minimize this visibility of seam. here we are giving Image blending technique for panoramic view construction. In the proposed algorithm we are using Dr. Kekre’s LUV color space for Image blending.,True,oiVHiwcAAAAJ:2osOgNQ5qMEC,97,https://etrx.spit.ac.in/wp-content/blogs.dir/19/files/2012/ieee_colloquium/Image_Processing/spit-40.pdf,9400974737253288403,/scholar?cites=9400974737253288403,,,https://etrx.spit.ac.in/wp-content/blogs.dir/19/files/2012/ieee_colloquium/Image_Processing/spit-40.pdf,0,0,0
1277728,Image retrieval using fractional coefficients of transformed image using DCT and Walsh transform,2010,HB Kekre and Sudeep D Thepade and Akshay Maloo,2,International Journal of Engineering Science and Technology,4,362-371,,The paper presents innovative content based image retrieval (CBIR) techniques based on feature vectors as fractional coefficients of transformed images using DCT and Walsh transforms. Here the feature vector size per image is greatly reduced by taking fractional coefficients of transformed image. The feature vectors are extracted in fourteen different ways from the transformed image. Along with the first being all the coefficients of transformed image. seven reduced coefficients sets (as 50%. 25%. 12.5%. 6.25%. 3.125%. 1.5625%. 0.7813%. 0.39%. 0.195%. 0.097%. 0.048%. 0.024%. 0.012% and 0.06% of complete transformed image) are considered as feature vectors. The two transforms are applied on gray image equivalents and the colour components of images to extract Gray and RGB feature sets respectively. Instead of using all coefficients of transformed images as feature vector for image retrieval. these fourteen reduced coefficients sets for gray as well as RGB feature vectors are used. resulting into better performance and lower computations. The proposed CBIR techniques are implemented on a database having 1000 images spread across 11 categories. For each proposed CBIR technique 55 queries (5 per category) are fired on the database and net average precision and recall are computed for all feature sets per transform. The results have shown the performance improvement (higher precision and recall values) with fractional coefficients compared to complete transform of image at reduced computations resulting in faster retrieval. Finally Walsh transform surpasses DCT transforms in performance with highest precision and recall …,True,oiVHiwcAAAAJ:ZeXyd9-uunAC,93,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.9025&rep=rep1&type=pdf,9707913127966970706,/scholar?cites=9707913127966970706,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.188.9025&rep=rep1&type=pdf,0,0,0
1277729,Improving the Performance of Image Retrieval using Partial Coefficients of Transformed Image,2009,HB Kekre and D Thepade Sudeep,2,"International Journal of Information Retrieval, Serials Publications",1,72-79,,,True,oiVHiwcAAAAJ:UeHWp8X0CEIC,92,http://scholar.google.com/scholar?cluster=7448140352519140294&hl=en&oi=scholarr,7448140352519140294,/scholar?cites=7448140352519140294,,,,0,0,0
1277730,MicroRNA therapeutics: discovering novel targets and developing specific therapy,2016,Ajay Francis Christopher and Raman Preet Kaur and Gunpreet Kaur and Amandeep Kaur and Vikas Gupta and Parveen Bansal,7,,2,68,Wolters Kluwer--Medknow Publications,MicroRNAs (miRNAs) are small non-coding RNA molecules that regulate gene expression in diverse biological process. They act as intracellular mediators that are necessary for various biological processes. MicroRNAs targeting pathways of human disease provide a new and potential powerful candidate for therapeutic intervention against various pathological conditions. Even though. the information about miRNA biology has significantly enriched but we still do not completely understand the mechanism of miRNA gene regulation. Various groups across the globe and pharmaceutical companies are conducting research and developments to explore miRNA based therapy and build a whole new area of miroRNA therapeutics. Consequently. few miRNAs have entered the preclinical and clinical stage and soon might be available in the market for use in humans.,True,cPTGRvkAAAAJ:ae0xyBWlIcIC,329,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4840794/,13603574885392888908,/scholar?cites=13603574885392888908,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4840794/,0,0,0
1277731,Strategies for characterizing sildenafil. vardenafil. tadalafil and their analogues in herbal dietary supplements. and detecting counterfeit products containing these drugs,2009,Saranjit Singh and Bhagwat Prasad and Akash A Savaliya and Ravi P Shah and Vikrantsinh M Gohil and Amandeep Kaur,28,,1,13-28,Elsevier,The success of synthetic phosphodiesterase type-5 (PDE-5)-inhibitor drugs (viz sildenafil. vardenafil and tadalafil). which are constituents of popular brands (viz Viagra. Levitra and Cialis. respectively) for the treatment of erectile dysfunction in males. has led to their widespread use as adulterants in herbal dietary supplements (HDSs). There have been reports that not only these three approved drugs but also their unapproved analogues have been found in HDSs. The problem is becoming more complex. as concealed. structurally modified analogues are increasingly being used. Also. counterfeits of the popular brands have emerged.Fortunately. it has become possible to detect these drugs and their derivatives as adulterants and counterfeits by using modern sensitive and selective analytical techniques [e.g.. liquid chromatography with tandem mass spectrometry. Fourier transform (FT) with near infrared …,True,cPTGRvkAAAAJ:GYcXSSpN504C,168,https://www.sciencedirect.com/science/article/pii/S0165993608002045,17092254065329249054,/scholar?cites=17092254065329249054,,,,0,0,0
1277732,A review on microgrid central controller,2016,Amandeep Kaur and Jitender Kaushal and Prasenjit Basak,55,,,338-345,Pergamon,The microgrid central controller has most important role for satisfactory automated operation and control of microgrid while working in grid connected and islanded modes. The central controller has several features for proper coordination of distributed energy resources as per their power generation capacity to serve the critical and non-critical loads. It also initiates the protection techniques at the time of occurrence of severe short circuit fault at the grid end or in microgrid thus ensuring stability and reliability. This paper presents a comprehensive literature review on microgrid central controller. The evolution and advancement of microgrid central controller technology is explored and presented in a compact form. The classification of microgrid central controllers is proposed based on the outcomes found in the process of review. The role of central controller in the domains of microgrid protection. stability and power …,True,cPTGRvkAAAAJ:P5F9QuxV20EC,166,https://www.sciencedirect.com/science/article/pii/S1364032115012204,15085880236387388907,/scholar?cites=15085880236387388907,,,,0,0,0
1277733,Hough transform based fast skew detection and accurate skew correction methods,2008,Chandan Singh and Nitin Bhatia and Amandeep Kaur,41,Pattern Recognition,12,3528-3546,Pergamon,The Hough transform provides a robust technique for skew detection in document images. but suffers from high time complexity which becomes prohibitive for detecting skew in large documents. Analysis of time complexity on various stages of skew detection process is carried out in this paper. A complete skew detection and correction process is divided into three parts: a preprocessing stage using a simplified form of block adjacency graph (BAG). voting process using the Hough transform and de-skewing the image using rotation. Skew correction phase. which is hitherto a neglected area. is analysed for the quality of de-skewed images with respect to the type of rotation. Fast algorithms for all the three stages are presented and exhaustive analysis on time complexity is conducted. It is shown that the overall time taken for the whole process is less than one second even for very large documents. It is also observed …,True,cPTGRvkAAAAJ:b9WrW9Envh0C,142,https://www.sciencedirect.com/science/article/pii/S0031320308002173,4847246215920737568,/scholar?cites=4847246215920737568,,,https://www.academia.edu/download/47614169/j.patcog.2008.06.00220160729-18866-d4cfed.pdf,0,0,0
1277734,Apomixis may be widespread among trees of the climax rain forest,1978,A Kaur and CO Ha and K Jong and VE Sands and HT Chan and E Soepadmo and PS Ashton,271,Nature,5644,440-442,Nature Publishing Group,THE exceptional species diversity of tropical rain forests is well known; of these the lowland forests of the Malay Peninsula are among the richest 1. This. and the size of the trees. pose obvious difficulties for the maintenance of pan-mixis. and tempt speculation on the processes by which such diversity has evolved and may now be favoured. Fedorov 2 suggested that natural selection is low and self-pollination prevalent. favouring random genetic drift. Prevalence of random drift. or apomixis—agamospermy—would contradict Ashton's 3 view that. given a stable environment. evolution proceeds through ecotypic differentiation while diversity accrues through ever increasing niche specialisation; for this view to be correct. maintenance of genetic variability within breeding groups would be essential. Solid evidence has been meagre but there is evidence 4 that genetic polymorphism. and hence heterozygosity. is common …,True,cPTGRvkAAAAJ:Nw_I7GeUguwC,141,https://www.nature.com/articles/271440a0,9692250940351907641,/scholar?cites=9692250940351907641,,,,0,0,0
1277735,Bi2WO6 nanocuboids: an efficient visible light active photocatalyst for the degradation of levofloxacin drug in aqueous phase,2016,Amandeep Kaur and Sushil Kumar Kansal,302,Chemical engineering journal,,194-203,Elsevier,This study presents an efficient approach for the photocatalytic removal of pharmaceutical compound under visible light. In this study Bi2WO6 nanocuboids have been synthesized using a facile ultrasonic assisted hydrothermal method. Phase identification. chemical. morphological and photo-luminescent properties of the as synthesized nanostructures have been investigated by different techniques such as XRD. FTIR. TEM. FE-SEM. UV–vis DRS. XPS and BET surface area analysis. Further. the photocatalytic activity of the prepared catalyst was evaluated for the degradation of levofloxacin in aqueous phase under visible light. Approximately 80% degradation of the drug was achieved in 150 min. The kinetic studies revealed that photo-degradation of levofloxacin follows pseudo-first order reaction kinetic model and rate constant was found to be 0.00847 min−1. A terephthalic acid photoluminescence technique was …,True,cPTGRvkAAAAJ:0kLwNjf3oFwC,132,https://www.sciencedirect.com/science/article/pii/S1385894716306325,14775698981133374239,/scholar?cites=14775698981133374239,,,,0,0,0
1277736,Microbial fuel cell type biosensor for specific volatile fatty acids using acclimated bacterial communities,2013,Amandeep Kaur and Jung Rae Kim and Iain Michie and Richard M Dinsdale and Alan J Guwy and Giuliano C Premier and Sustainable Environment Research Centre,47,Biosensors and Bioelectronics,,50-55,Elsevier,Volatile fatty acid (VFA) concentration is one of the most important parameters for monitoring bio-processes such as anaerobic digestion and microbial fuel cells. In this study the correlation between VFA concentration and current/voltage responses and electrochemical properties by using the MFC technology was evaluated. The discrimination between different species of VFA by using two methods i.e.. coulombic efficiency and cyclic voltammetry was investigated. Columbic efficiency gave a slow response of greater than 20 h. particularly at concentration levels of 20 mg l−1. By using cyclic voltammetry to measure the oxidation peak at a consistent scan rate showed linear correlation to VFA concentration and peak current produced. up to <40 mg l−1) in a rapid response time of 1–2 min. The results presented showed good correlations between the individual VFA species concentration and charge. and also current …,True,cPTGRvkAAAAJ:GiYFt9mpioMC,128,https://www.sciencedirect.com/science/article/pii/S0956566313001310,12667385507282571936,/scholar?cites=12667385507282571936,,,,0,0,0
1277737,Revisiting cellulase production and redefining current strategies based on major challenges,2016,Ramesh Chander Kuhad and Deepa Deswal and Sonia Sharma and Abhishek Bhattacharya and Kavish Kumar Jain and Amandeep Kaur and Brett I Pletschke and Ajay Singh and Matti Karp,55,,,249-272,Pergamon,Lignocellulosic biomass has been considered as an important and sustainable source of renewable energy. Cellulose constitutes the major component of the lignocellulosic biomass and also offers maximum recalcitrance towards its fullest utilization. The enzymatic breakdown of cellulose is achieved through cellulases. Diverse forms of microbes including fungi. bacteria. actinomycetes and yeast are known to produce cellulases that have found extensive application in various industries. Due to the current global political unrest over oil prices and the threat of global warming following combustion of fossil fuels. the paradigm of research is now focused on biofuel production from plant biomass. Conventional approaches have not been economically feasible for meeting the demands of the industry. This review provides an update regarding the status of present microbial cellulase production technologies and …,True,cPTGRvkAAAAJ:I-2NeQpV75MC,125,https://www.sciencedirect.com/science/article/pii/S1364032115012113,8397773607225031736,/scholar?cites=8397773607225031736,,,,0,0,0
1277738,Steganographic approach for hiding image in DCT domain,2011,Blossom Kaur and Amandeep Kaur and Jasdeep Singh,1,International Journal of Advances in Engineering & Technology,3,72,IAET Publishing Company,Since all the multimedia products are released via internet so it’s an urgent need today to protect the data from malicious attacks. This lead to the research in the area of Digital watermarking which intends to protect the copyright information of the intellectuals. In this paper a DCT based watermarking scheme is proposed which provides higher resistance to image processing attacks such as JPEG compression. noise. rotation. translation etc. In this approach. the watermark is embedded in the mid frequency band of the DCT blocks carrying low frequency components and the high frequency sub band components remain unused. Watermark is inserted by adjusting the DCT coefficients of the image and by using the private key. Watermark can then be extracted using the same private key without resorting to the original image. Performance analysis shows that the watermark is robust.,True,cPTGRvkAAAAJ:zmHQPunddckC,123,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.904&rep=rep1&type=pdf,10948666370813612167,/scholar?cites=10948666370813612167,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.904&rep=rep1&type=pdf,0,0,0
1277739,Pharmacological actions of Opuntia ficus indica: A Review,2012,Manpreet Kaur and Amandeep Kaur and Ramica Sharma,2,Journal of Applied Pharmaceutical Science,7,15-18,MediPOEIA Publications,Cactus (Opuntia ficus-indica) belongs to the family Cactaceae. Family Cactaceae is reported to contain about 130 genera and nearly 1500 species. This plant is native of Mexico and it is widely distributed in Mexico and in all American hemispheres as well as in Africa and in the Mediterranean basin. It has been used in traditional folk medicine because of its role in treating a number of diseases and conditions. including anti-inflammatory effects hypoglycemic effects inhibition of stomach ulceration. neuroprotective effects Through antioxidant actions and also used for treating diabetes. burns. bronchial. asthma and indigestion in many countries over the world. It is also used in Pharma industry as a pharmaceutical agent. The fruit. as well as cactus stem are used to prepare value-added products. such as jam. squash. wine. pickle. body lotions. shampoo. creams. etc. It also has several medicinal and industrial uses. Its seeds can be used as flavouring agents. Due to the remarkable biological activity of Opuntia and its constituents. it will be appropriate to develop them as a medicine.,True,cPTGRvkAAAAJ:H-3wYkpcA84C,120,http://www.japsonline.com/admin/php/uploads/541_pdf.pdf,8569371664503295303,/scholar?cites=8569371664503295303,,,http://www.japsonline.com/admin/php/uploads/541_pdf.pdf,0,0,0
1277740,A survey on sentiment analysis and opinion mining techniques,2013,Amandeep Kaur and Vishal Gupta,5,Journal of Emerging Technologies in Web Intelligence,4,367-371,Academy Publisher,Natural Language processing (NLP). has been witnessed a blooming interest over the past decade. It is also known as opinion mining. mood extraction and emotion analysis. The basic in opinion mining is classifying the polarity of text in terms of positive (good). negative (bad) or neutral (surprise). Mood Extraction automates the decision making performed by human. It is the important aspect for capturing public opinion about product preferences. marketing campaigns. political movements. social events and company strategies. In addition to sentiment analysis for English and other European languages. this task is applied on various Indian languages like Bengali. Hindi. Telugu and Malayalam. This paper describes the survey on main approaches for performing sentiment extraction.,True,cPTGRvkAAAAJ:uDGL6kOW6j0C,111,https://pdfs.semanticscholar.org/81ac/64634d9db9e5691273da87ad2578d78249bc.pdf,6264539716033252529,/scholar?cites=6264539716033252529,,,https://pdfs.semanticscholar.org/81ac/64634d9db9e5691273da87ad2578d78249bc.pdf,0,0,0
1277741,2016 update of the PRIDE database and its related tools,2016,Juan Antonio Vizcaíno and Attila Csordas and Noemi Del-Toro and José A Dianes and Johannes Griss and Ilias Lavidas and Gerhard Mayer and Yasset Perez-Riverol and Florian Reisinger and Tobias Ternent and Qing-Wei Xu and Rui Wang and Henning Hermjakob,44,Nucleic acids research,D1,D447-D456,Oxford University Press,The PRoteomics IDEntifications (PRIDE) database is one of the world-leading data repositories of mass spectrometry (MS)-based proteomics data. Since the beginning of 2014. PRIDE Archive (http://www.ebi.ac.uk/pride/archive/) is the new PRIDE archival system. replacing the original PRIDE database. Here we summarize the developments in PRIDE resources and related tools since the previous update manuscript in the Database Issue in 2013. PRIDE Archive constitutes a complete redevelopment of the original PRIDE. comprising a new storage backend. data submission system and web interface. among other components. PRIDE Archive supports the most-widely used PSI (Proteomics Standards Initiative) data standard formats (mzML and mzIdentML) and implements the data requirements and guidelines of the ProteomeXchange Consortium. The wide adoption of ProteomeXchange within the …,True,QdZ-ZlUAAAAJ:RYcK_YlVTxYC,3129,https://academic.oup.com/nar/article-abstract/44/D1/D447/2502640,18210177577620841301,/scholar?cites=18210177577620841301,,,https://academic.oup.com/nar/article/44/D1/D447/2502640,0,0,0
1277742,The PRIDE database and related tools and resources in 2019: improving support for quantification data,2019,Yasset Perez-Riverol and Attila Csordas and Jingwen Bai and Manuel Bernal-Llinares and Suresh Hewapathirana and Deepti J Kundu and Avinash Inuganti and Johannes Griss and Gerhard Mayer and Martin Eisenacher and Enrique Pérez and Julian Uszkoreit and Julianus Pfeuffer and Timo Sachsenberg and Şule Yılmaz and Shivani Tiwary and Jürgen Cox and Enrique Audain and Mathias Walzer and Andrew F Jarnuczak and Tobias Ternent and Alvis Brazma and Juan Antonio Vizcaíno,47,Nucleic acids research,D1,D442-D450,Oxford University Press,The PRoteomics IDEntifications (PRIDE) database (https://www.ebi.ac.uk/pride/) is the world’s largest data repository of mass spectrometry-based proteomics data. and is one of the founding members of the global ProteomeXchange (PX) consortium. In this manuscript. we summarize the developments in PRIDE resources and related tools since the previous update manuscript was published in Nucleic Acids Research in 2016. In the last 3 years. public data sharing through PRIDE (as part of PX) has definitely become the norm in the field. In parallel. data re-use of public proteomics data has increased enormously. with multiple applications. We first describe the new architecture of PRIDE Archive. the archival component of PRIDE. PRIDE Archive and the related data submission framework have been further developed to support the increase in submitted data volumes and additional data types. A new scalable …,True,QdZ-ZlUAAAAJ:Wp0gIr-vW9MC,2539,https://academic.oup.com/nar/article-abstract/47/D1/D442/5160986,13426799914812680695,/scholar?cites=13426799914812680695,,,https://academic.oup.com/nar/article/47/D1/D442/5160986,0,0,0
1277743,ProteomeXchange provides globally coordinated proteomics data submission and dissemination,2014,Juan A Vizcaíno and Eric W Deutsch and Rui Wang and Attila Csordas and Florian Reisinger and Daniel Ríos and José A Dianes and Zhi Sun and Terry Farrah and Nuno Bandeira and Pierre-Alain Binz and Ioannis Xenarios and Martin Eisenacher and Gerhard Mayer and Laurent Gatto and Alex Campos and Robert J Chalkley and Hans-Joachim Kraus and Juan Pablo Albar and Salvador Martinez-Bartolome and Rolf Apweiler and Gilbert S Omenn and Lennart Martens and Andrew R Jones and Henning Hermjakob,32,Nature biotechnology,3,223-226,Nature Publishing Group,Individual resources can join ProteomeXchange by implementing the ProteomeXchange data submission and dissemination guidelines. and metadata requirements. In the current version (http://www. proteomexchange. org/concept). the mandatory information includes the following: first. mass spectrometer output files (raw data. either in a binary format. or in a standard open format such as mzML); second. processed identification results (two submission modes are available. see below); and third. sufficient metadata to provide a suitable biological and technological background. including method information such as transition lists in the case of SRM data. Other types of information. such as peak list files (processed versions of mass spectra most often used in the identification process) and quantification results can also be provided.,True,QdZ-ZlUAAAAJ:9yKSN-GCB0IC,2160,https://www.nature.com/nbt/journal/v32/n3/full/nbt.2839.html,12114884311681221167,/scholar?cites=12114884311681221167,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3986813/,0,0,0
1277744,The mzIdentML data standard for mass spectrometry-based proteomics results,2012,Andrew R Jones and Martin Eisenacher and Gerhard Mayer and Oliver Kohlbacher and Jennifer Siepen and Simon J Hubbard and Julian N Selley and Brian C Searle and James Shofstahl and Sean L Seymour and Randall Julian and Pierre-Alain Binz and Eric W Deutsch and Henning Hermjakob and Florian Reisinger and Johannes Griss and Juan Antonio Vizcaíno and Matthew Chambers and Angel Pizarro and David Creasy,11,Molecular & Cellular Proteomics,7,M111. 014381-1-M111. 014381-10,Elsevier,We report the release of mzIdentML. an exchange standard for peptide and protein identification data. designed by the Proteomics Standards Initiative. The format was developed by the Proteomics Standards Initiative in collaboration with instrument and software vendors. and the developers of the major open-source projects in proteomics. Software implementations have been developed to enable conversion from most popular proprietary and open-source formats. and mzIdentML will soon be supported by the major public repositories. These developments enable proteomics scientists to start working with the standard for exchanging and publishing data sets in support of publications and they provide a stable platform for bioinformatics groups and commercial software vendors to work with a single file format for identification data.,True,QdZ-ZlUAAAAJ:u5HHmVD_uO8C,189,https://www.sciencedirect.com/science/article/pii/S1535947620330127,6565769187941895427,/scholar?cites=6565769187941895427,,,https://www.sciencedirect.com/science/article/pii/S1535947620330127,0,0,0
1277745,The HUPO proteomics standards initiative-mass spectrometry controlled vocabulary,2013,Gerhard Mayer and Luisa Montecchi-Palazzi and David Ovelleiro and Andrew R Jones and Pierre-Alain Binz and Eric W Deutsch and Matthew Chambers and Marius Kallhardt and Fredrik Levander and James Shofstahl and Sandra Orchard and Juan Antonio Vizcaíno and Henning Hermjakob and Christian Stephan and Helmut E Meyer and Martin Eisenacher,2013,Database,,,Oxford Academic,Controlled vocabularies (CVs). i.e. a collection of predefined terms describing a modeling domain. used for the semantic annotation of data. and ontologies are used in structured data formats and databases to avoid inconsistencies in annotation. to have a unique (and preferably short) accession number and to give researchers and computer algorithms the possibility for more expressive semantic annotation of data. The Human Proteome Organization (HUPO)–Proteomics Standards Initiative (PSI) makes extensive use of ontologies/CVs in their data formats. The PSI-Mass Spectrometry (MS) CV contains all the terms used in the PSI MS–related data standards. The CV contains a logical hierarchical structure to ensure ease of maintenance and the development of software that makes use of complex semantics. The CV contains terms required for a complete description of an MS analysis pipeline used in …,True,QdZ-ZlUAAAAJ:u-x6o8ySG0sC,67,https://academic.oup.com/database/article-abstract/doi/10.1093/database/bat009/330446,16144379932865268319,/scholar?cites=16144379932865268319,,,https://academic.oup.com/database/article/doi/10.1093/database/bat009/330446,0,0,0
1277746,The mzquantml data standard for mass spectrometry–based quantitative studies in proteomics,2013,Mathias Walzer and Da Qi and Gerhard Mayer and Julian Uszkoreit and Martin Eisenacher and Timo Sachsenberg and Faviel F Gonzalez-Galarza and Jun Fan and Conrad Bessant and Eric W Deutsch and Florian Reisinger and Juan Antonio Vizcaíno and J Alberto Medina-Aunon and Juan Pablo Albar and Oliver Kohlbacher and Andrew R Jones,12,Molecular & Cellular Proteomics,8,2332-2340,Elsevier,The range of heterogeneous approaches available for quantifying protein abundance via mass spectrometry (MS)1  leads to considerable challenges in modeling. archiving. exchanging. or submitting experimental data sets as supplemental material to journals. To date. there has been no widely accepted format for capturing the evidence trail of how quantitative analysis has been performed by software. for transferring data between software packages. or for submitting to public databases. In the context of the Proteomics Standards Initiative. we have developed the mzQuantML data standard. The standard can represent quantitative data about regions in two-dimensional retention time versus mass/charge space (called features). peptides. and proteins and protein groups (where there is ambiguity regarding peptide-to-protein inference). and it offers limited support for small molecule (metabolomic) data. The format …,True,QdZ-ZlUAAAAJ:d1gkVwhDpl0C,64,https://www.sciencedirect.com/science/article/pii/S153594762032541X,8334888704337587485,/scholar?cites=8334888704337587485,,,https://www.sciencedirect.com/science/article/pii/S153594762032541X,0,0,0
1277747,Development of data representation standards by the human proteome organization proteomics standards initiative,2015,Eric W Deutsch and Juan Pablo Albar and Pierre-Alain Binz and Martin Eisenacher and Andrew R Jones and Gerhard Mayer and Gilbert S Omenn and Sandra Orchard and Juan Antonio Vizcaíno and Henning Hermjakob,22,,3,495-506,Oxford University Press, Objective To describe the goals of the Proteomics Standards Initiative (PSI) of the Human Proteome Organization. the methods that the PSI has employed to create data standards. the resulting output of the PSI. lessons learned from the PSI’s evolution. and future directions and synergies for the group. Materials and Methods The PSI has 5 categories of deliverables that have guided the group. These are minimum information guidelines. data formats. controlled vocabularies. resources and software tools. and dissemination activities. These deliverables are produced via the leadership and working group organization of the initiative. driven by frequent workshops and ongoing communication within the working groups. Official standards are subjected to a rigorous document process that includes several levels of peer review prior to release. Results We have produced and published …,True,QdZ-ZlUAAAAJ:WF5omc3nYNoC,57,https://academic.oup.com/jamia/article-abstract/22/3/495/778560,11481208445551681136,/scholar?cites=11481208445551681136,,,https://academic.oup.com/jamia/article-pdf/22/3/495/5247861/ocv001.pdf,0,0,0
1277748,Proteomics standards initiative: fifteen years of progress and future work,2017,Eric W Deutsch and Sandra Orchard and Pierre-Alain Binz and Wout Bittremieux and Martin Eisenacher and Henning Hermjakob and Shin Kawano and Henry Lam and Gerhard Mayer and Gerben Menschaert and Yasset Perez-Riverol and Reza M Salek and David L Tabb and Stefan Tenzer and Juan Antonio Vizcaíno and Mathias Walzer and Andrew R Jones,16,,12,4288-4298,American Chemical Society, The Proteomics Standards Initiative (PSI) of the Human Proteome Organization (HUPO) has now been developing and promoting open community standards and software tools in the field of proteomics for 15 years. Under the guidance of the chair. cochairs. and other leadership positions. the PSI working groups are tasked with the development and maintenance of community standards via special workshops and ongoing work. Among the existing ratified standards. the PSI working groups continue to update PSI-MI XML. MITAB. mzML. mzIdentML. mzQuantML. mzTab. and the MIAPE (Minimum Information About a Proteomics Experiment) guidelines with the advance of new technologies and techniques. Furthermore. new standards are currently either in the final stages of completion (proBed and proBAM for proteogenomics results as well as PEFF) or in early stages of design (a spectral library standard format. a …,True,QdZ-ZlUAAAAJ:qxL8FJ1GzNcC,52,https://pubs.acs.org/doi/abs/10.1021/acs.jproteome.7b00370,13329118863498362080,/scholar?cites=13329118863498362080,,,https://pubs.acs.org/doi/pdf/10.1021/acs.jproteome.7b00370,0,0,0
1277749,Guidelines for reporting quantitative mass spectrometry based experiments in proteomics,2013,Salvador Martínez-Bartolomé and Eric W Deutsch and Pierre-Alain Binz and Andrew R Jones and Martin Eisenacher and Gerhard Mayer and Alex Campos and Francesc Canals and Joan-Josep Bech-Serra and Montserrat Carrascal and Marina Gay and Alberto Paradela and Rosana Navajas and Miguel Marcilla and María Luisa Hernáez and María Dolores Gutiérrez-Blázquez and Luis Felipe Clemente Velarde and Kerman Aloria and Jabier Beaskoetxea and J Alberto Medina-Aunon and Juan P Albar,95,Journal of proteomics,,84-88,Elsevier,Mass spectrometry is already a well-established protein identification tool and recent methodological and technological developments have also made possible the extraction of quantitative data of protein abundance in large-scale studies. Several strategies for absolute and relative quantitative proteomics and the statistical assessment of quantifications are possible. each having specific measurements and therefore. different data analysis workflows.The guidelines for Mass Spectrometry Quantification allow the description of a wide range of quantitative approaches. including labeled and label-free techniques and also targeted approaches such as Selected Reaction Monitoring (SRM).The HUPO Proteomics Standards Initiative (HUPO-PSI) has invested considerable efforts to improve the standardization of proteomics data handling. representation and sharing through the development of …,True,QdZ-ZlUAAAAJ:2osOgNQ5qMEC,50,https://www.sciencedirect.com/science/article/pii/S1874391913001024,7450151892515807380,/scholar?cites=7450151892515807380,,,https://www.researchgate.net/profile/Gerhard_Mayer/publication/236054533_Guidelines_for_reporting_quantitative_mass_spectrometry_based_experiments_in_proteomics/links/5a0c29a1aca2721a23fa65d0/Guidelines-for-reporting-quantitative-mass-spectrometry-based-experiments-in-proteomics.pdf,0,0,0
1277750,Controlled vocabularies and ontologies in proteomics: overview. principles and practice,2014,Gerhard Mayer and Andrew R Jones and Pierre-Alain Binz and Eric W Deutsch and Sandra Orchard and Luisa Montecchi-Palazzi and Juan Antonio Vizcaíno and Henning Hermjakob and David Oveillero and Randall Julian and Christian Stephan and Helmut E Meyer and Martin Eisenacher,1844,,1,98-107,Elsevier,This paper focuses on the use of controlled vocabularies (CVs) and ontologies especially in the area of proteomics. primarily related to the work of the Proteomics Standards Initiative (PSI). It describes the relevant proteomics standard formats and the ontologies used within them. Software and tools for working with these ontology files are also discussed. The article also examines the “mapping files” used to ensure correct controlled vocabulary terms that are placed within PSI standards and the fulfillment of the MIAPE (Minimum Information about a Proteomics Experiment) requirements. This article is part of a Special Issue entitled: Computational Proteomics in the Post-Identification Era. Guest Editors: Martin Eisenacher and Christian Stephan.,True,QdZ-ZlUAAAAJ:UeHWp8X0CEIC,38,https://www.sciencedirect.com/science/article/pii/S1570963913000800,16268289007997200328,/scholar?cites=16268289007997200328,,,https://www.sciencedirect.com/science/article/pii/S1570963913000800,0,0,0
1277751,The mzIdentML data standard version 1.2. supporting advances in proteome informatics,2017,Juan Antonio Vizcaíno and Gerhard Mayer and Simon Perkins and Harald Barsnes and Marc Vaudel and Yasset Perez-Riverol and Tobias Ternent and Julian Uszkoreit and Martin Eisenacher and Lutz Fischer and Juri Rappsilber and Eugen Netz and Mathias Walzer and Oliver Kohlbacher and Alexander Leitner and Robert J Chalkley and Fawaz Ghali and Salvador Martínez-Bartolomé and Eric W Deutsch and Andrew R Jones,16,Molecular & cellular proteomics,7,1275-1285,Elsevier,The first stable version of the Proteomics Standards Initiative mzIdentML open data standard (version 1.1) was published in 2012—capturing the outputs of peptide and protein identification software. In the intervening years. the standard has become well-supported in both commercial and open software. as well as a submission and download format for public repositories. Here we report a new release of mzIdentML (version 1.2) that is required to keep pace with emerging practice in proteome informatics. New features have been added to support: (1) scores associated with localization of modifications on peptides; (2) statistics performed at the level of peptides; (3) identification of cross-linked peptides; and (4) support for proteogenomics approaches. In addition. there is now improved support for the encoding of de novo sequencing of peptides. spectral library searches. and protein inference. As a key point. the …,True,QdZ-ZlUAAAAJ:roLk4NBRz8UC,37,https://www.sciencedirect.com/science/article/pii/S153594762034189X,12543050370150141422,/scholar?cites=12543050370150141422,,,https://www.sciencedirect.com/science/article/pii/S153594762034189X,0,0,0
1277752,A wavelet-based image fusion tutorial,2004,Gonzalo Pajares and Jesus Manuel De La Cruz,37,Pattern recognition,9,1855-1872,Pergamon,The objective of image fusion is to combine information from multiple images of the same scene. The result of image fusion is a new image which is more suitable for human and machine perception or further image-processing tasks such as segmentation. feature extraction and object recognition. Different fusion methods have been proposed in literature. including multiresolution analysis. This paper is an image fusion tutorial based on wavelet decomposition. i.e. a multiresolution image fusion approach. We can fuse images with the same or different resolution level. i.e. range sensing. visual CCD. infrared. thermal or medical. The tutorial performs a synthesis between the multiscale-decomposition-based image approach (Proc. IEEE 87 (8) (1999) 1315). the ARSIS concept (Photogramm. Eng. Remote Sensing 66 (1) (2000) 49) and a multisensor scheme (Graphical Models Image Process. 57 (3) (1995) 235). Some …,True,iGgOj5oAAAAJ:vRqMK49ujn8C,1580,https://www.sciencedirect.com/science/article/pii/S0031320304001037,18367139361205988561,/scholar?cites=18367139361205988561,,,https://eprints.ucm.es/id/eprint/25355/1/cruzgarcia39.pdf,0,0,0
1277753,Overview and current status of remote sensing applications based on unmanned aerial vehicles (UAVs),2015,Gonzalo Pajares,81,Photogrammetric Engineering & Remote Sensing,4,281-330,American Society for Photogrammetry and Remote Sensing,Remotely Piloted Aircraft (RPA) is presently in continuous development at a rapid pace. Unmanned Aerial Vehicles (UAVs) or more extensively Unmanned Aerial Systems (UAS) are platforms considered under the RPAs paradigm. Simultaneously. the development of sensors and instruments to be installed onboard such platforms is growing exponentially. These two factors together have led to the increasing use of these platforms and sensors for remote sensing applications with new potential. Thus. the overall goal of this paper is to provide a panoramic overview about the current status of remote sensing applications based on unmanned aerial platforms equipped with a set of specific sensors and instruments. First. some examples of typical platforms used in remote sensing are provided. Second. a description of sensors and technologies is explored which are onboard instruments specifically intended to capture …,True,iGgOj5oAAAAJ:kuK5TVdYjLIC,530,https://www.ingentaconnect.com/content/asprs/pers/2015/00000081/00000004/art00015,12591062552918155307,/scholar?cites=12591062552918155307,,,https://www.ingentaconnect.com/content/asprs/pers/2015/00000081/00000004/art00015?crawler=true&mimetype=application/pdf,0,0,0
1277754,Visión por Computador: Imágenes digitales y aplicaciones,2001,Gonzalo Pajares and Jesús M De la Cruz,,"Ra-Ma, Madrid",,,,1. Introducir al alumno en las técnicas de procesamiento de la imagen digital para extraer información subyacente. Aprender las técnicas básicas de análisis para dar solución a problemas del mundo real como el reconocimiento. movimiento. reconstrucción 3D. etc. involucrados en el proceso de visión automática por ordenador.,True,iGgOj5oAAAAJ:YsMSGLbcyi4C,399,http://scholar.google.com/scholar?cluster=1810203508754799363&hl=en&oi=scholarr,1810203508754799363,/scholar?cites=1810203508754799363,,,,0,0,0
1277755,Visión por Computador: Imágenes digitales y aplicaciones,2001,Gonzalo Pajares and Jesús M De la Cruz,,"Ra-Ma, Madrid",,,,1. Introducir al alumno en las técnicas de procesamiento de la imagen digital para extraer información subyacente. Aprender las técnicas básicas de análisis para dar solución a problemas del mundo real como el reconocimiento. movimiento. reconstrucción 3D. etc. involucrados en el proceso de visión automática por ordenador.,True,iGgOj5oAAAAJ:9ZlFYXVOiuMC,339,http://scholar.google.com/scholar?cluster=1810203508754799363&hl=en&oi=scholarr,1810203508754799363,/scholar?cites=1810203508754799363,,,,0,0,0
1277756,Real-time image processing for crop/weed discrimination in maize fields,2011,Xavier P Burgos-Artizzu and Angela Ribeiro and Maria Guijarro and Gonzalo Pajares,75,Computers and Electronics in Agriculture,2,337-346,Elsevier,This paper presents a computer vision system that successfully discriminates between weed patches and crop rows under uncontrolled lighting in real-time. The system consists of two independent subsystems. a fast image processing delivering results in real-time (Fast Image Processing. FIP). and a slower and more accurate processing (Robust Crop Row Detection. RCRD) that is used to correct the first subsystem’s mistakes. This combination produces a system that achieves very good results under a wide variety of conditions. Tested on several maize videos taken of different fields and during different years. the system successfully detects an average of 95% of weeds and 80% of crops under different illumination. soil humidity and weed/crop growth conditions. Moreover. the system has been shown to produce acceptable results even under very difficult conditions. such as in the presence of dramatic sowing …,True,iGgOj5oAAAAJ:qxL8FJ1GzNcC,300,https://www.sciencedirect.com/science/article/pii/S0168169910002620,13181220381440972173,/scholar?cites=13181220381440972173,,,http://people.vision.caltech.edu/~xpburgos/papers/2011%20Burgos-Artizzu%20Compag.pdf,0,0,0
1277757,Automatic segmentation of relevant textures in agricultural images,2011,Marıa Guijarro and Gonzalo Pajares and Isabel Riomoros and PJ Herrera and XP Burgos-Artizzu and Angela Ribeiro,75,Computers and Electronics in Agriculture,1,75-83,Elsevier,One important issue emerging strongly in agriculture is related with the automatization of tasks. where the optical sensors play an important role. They provide images that must be conveniently processed. The most relevant image processing procedures require the identification of green plants. in our experiments they come from barley and corn crops including weeds. so that some types of action can be carried out. including site-specific treatments with chemical products or mechanical manipulations. Also the identification of textures belonging to the soil could be useful to know some variables. such as humidity. smoothness or any others. Finally. from the point of view of the autonomous robot navigation. where the robot is equipped with the imaging system. some times it is convenient to know not only the soil information and the plants growing in the soil but also additional information supplied by global references …,True,iGgOj5oAAAAJ:YOwf2qJgpHMC,280,https://www.sciencedirect.com/science/article/pii/S0168169910001924,15969307118528111430,/scholar?cites=15969307118528111430,,,http://oa.upm.es/13699/2/INVE_MEM_2011_115574.pdf,0,0,0
1277758,Parameter identification of solar cells using artificial bee colony optimization,2014,Diego Oliva and Erik Cuevas and Gonzalo Pajares,72,Energy,,93-102,Pergamon,In order to improve the performance of solar energy systems. accurate modeling of current vs. voltage (I–V) characteristics of solar cells has attracted the attention of various researches. The main drawback in accurate modeling is the lack of information about the precise parameter values which indeed characterize the solar cell. Since such parameters cannot be extracted from the datasheet specifications. an optimization technique is necessary to adjust experimental data to the solar cell model. Considering the I–V characteristics of solar cells. the optimization task involves the solution of complex non-linear and multi-modal objective functions. Several optimization approaches have been proposed to identify the parameters of solar cells. However. most of them obtain sub-optimal solutions due to their premature convergence and their difficulty to overcome local minima in multi-modal problems. This paper proposes …,True,iGgOj5oAAAAJ:Z5m8FVwuT1cC,226,https://www.sciencedirect.com/science/article/pii/S036054421400560X,12988426354693593535,/scholar?cites=12988426354693593535,,,https://www.academia.edu/download/51778996/A53.pdf,0,0,0
1277759,Support vector machines for crop/weeds identification in maize fields,2012,José Miguel Guerrero and Gonzalo Pajares and Martín Montalvo and Juan Romeo and María Guijarro,39,Expert Systems with Applications,12,11149-11155,Pergamon,In Precision Agriculture (PA) automatic image segmentation for plant identification is an important issue to be addressed. Emerging technologies in optical imaging sensors play an important role in PA. In maize fields. site-specific treatments. with chemical products or mechanical manipulations. are applied for weeds elimination. Maize is an irrigated crop. also unprotected from rainfall. After a strong rain. soil materials (particularly clays) mixed with water impregnate the vegetative cover. The green spectral component associated to the plants is masked by the dominant red spectral component coming from soil materials. This makes methods based on the greenness identification fail under such situations. We propose a new method based on Support Vector Machines for identifying plants with green spectral components masked and unmasked. The method is also valid for post-treatment evaluation. where loss of …,True,iGgOj5oAAAAJ:NMxIlDl6LWMC,200,https://www.sciencedirect.com/science/article/pii/S0957417412005635,14599962840424369826,/scholar?cites=14599962840424369826,,,,0,0,0
1277760,A vision-based method for weeds identification through the Bayesian decision theory,2008,Alberto Tellaeche and Xavier P Burgos-Artizzu and Gonzalo Pajares and Angela Ribeiro,41,Pattern Recognition,2,521-530,Pergamon,One of the objectives of precision agriculture is to minimize the volume of herbicides that are applied to the fields through the use of site-specific weed management systems. This paper outlines an automatic computer vision-based approach for the detection and differential spraying of weeds in corn crops. The method is designed for post-emergence herbicide applications where weeds and corn plants display similar spectral signatures and the weeds appear irregularly distributed within the crop's field. The proposed strategy involves two processes: image segmentation and decision making. Image segmentation combines basic suitable image processing techniques in order to extract cells from the image as the low level units. Each cell is described by two area-based measuring relationships between crop and weeds. The decision making determines the cells to be sprayed based on the computation of a posterior …,True,iGgOj5oAAAAJ:3fE2CSJIrl8C,185,https://www.sciencedirect.com/science/article/pii/S0031320307003305,7870720116916216079,/scholar?cites=7870720116916216079,,,https://www.academia.edu/download/49095738/A_vision-based_method_for_weeds_identifi20160924-11630-lpfga1.pdf,0,0,0
1277761,A computer vision approach for weeds identification through Support Vector Machines,2011,Alberto Tellaeche and Gonzalo Pajares and Xavier P Burgos-Artizzu and Angela Ribeiro,11,Applied Soft Computing,1,908-915,Elsevier,This paper outlines an automatic computer vision system for the identification of avena sterilis which is a special weed seed growing in cereal crops. The final goal is to reduce the quantity of herbicide to be sprayed as an important and necessary step for precision agriculture. So. only areas where the presence of weeds is important should be sprayed. The main problems for the identification of this kind of weed are its similar spectral signature with respect the crops and also its irregular distribution in the field. It has been designed a new strategy involving two processes: image segmentation and decision making. The image segmentation combines basic suitable image processing techniques in order to extract cells from the image as the low level units. Each cell is described by two area-based attributes measuring the relations among the crops and weeds. The decision making is based on the Support Vector …,True,iGgOj5oAAAAJ:4TOpqqG69KYC,173,https://www.sciencedirect.com/science/article/pii/S1568494610000165,15215329384861090041,/scholar?cites=15215329384861090041,,,http://oa.upm.es/13714/2/INVE_MEM_2011_115514.pdf,0,0,0
1277762,A new vision-based approach to differential spraying in precision agriculture,2008,Alberto Tellaeche and Xavier P BurgosArtizzu and Gonzalo Pajares and Angela Ribeiro and César Fernández-Quintanilla,60,computers and electronics in agriculture,2,144-155,Elsevier,One of the objectives of precision agriculture is to minimize the volume of herbicides by using site-specific weed management systems. To reach this goal. two major factors need to be considered: (1) the similarity of spectral signatures. shapes. and textures between weeds and crops and (2) irregular distribution of weeds within the crop. This paper outlines an automatic computer vision method for detecting Avena sterilis. a noxious weed growing in cereal crops. and differential spraying to control the weed. The proposed method determines the quantity and distribution of weeds in the crop fields and applies a decision-making strategy for selective spraying. which forms the main focus of the paper. The method consists of two stages: image segmentation and decision-making. The image segmentation process extracts cells from the image as the low-level units. The quantity and distribution of weeds in the cell are …,True,iGgOj5oAAAAJ:8k81kl-MbHgC,172,https://www.sciencedirect.com/science/article/pii/S0168169907001731,17884521004265472232,/scholar?cites=17884521004265472232,,,https://www.academia.edu/download/47579948/A_new_vision-based_approach_to_different20160727-11462-dswf20.pdf,0,0,0
1277763,Imaging the body with diffuse optical tomography,2001,David A Boas and Dana H Brooks and Eric L Miller and Charles A DiMarzio and Misha Kilmer and Richard J Gaudette and Quan Zhang,18,,6,57-75,IEEE,Diffuse optical tomography (DOT) is an ongoing medical imaging modality in which tissue is illuminated by near-infrared light from an array of sources. the multiply-scattered light which emerges is observed with an array of detectors. and then a model of the propagation physics is used to infer the localized optical properties of the illuminated tissue. The three primary absorbers at these wavelengths. water and both oxygenated and deoxygenated hemoglobin. all have relatively weak absorption. This fortuitous fact provides a spectral window through which we can attempt to localize absorption (primarily by the two forms of hemoglobin) and scattering in the tissue. The most important current applications of DOT are detecting tumors in the breast and imaging the brain. We introduce the basic idea of DOT and review the history of optical methods in medicine as relevant to the development of DOT. We then detail the …,True,d1jBsvwAAAAJ:u5HHmVD_uO8C,851,https://ieeexplore.ieee.org/abstract/document/962278/,3774032754762882782,/scholar?cites=3774032754762882782,,,,0,0,0
1277764,A shape reconstruction method for electromagnetic tomography using adjoint fields and level sets,2000,Oliver Dorn and Eric L Miller and Carey M Rappaport,16,Inverse problems,5,1119,IOP Publishing,A two-step shape reconstruction method for electromagnetic (EM) tomography is presented which uses adjoint fields and level sets. The inhomogeneous background permittivity distribution and the values of the permittivities in some penetrable obstacles are assumed to be known. and the number. sizes. shapes. and locations of these obstacles have to be reconstructed given noisy limited-view EM data. The main application we address in the paper is the imaging and monitoring of pollutant plumes in environmental cleanup sites based on cross-borehole EM data. The first step of the reconstruction scheme makes use of an inverse scattering solver which recovers equivalent scattering sources for a number of experiments. and then calculates from these an approximation for the permittivity distribution in the medium. The second step uses this result as an initial guess for solving the shape reconstruction problem. A …,True,d1jBsvwAAAAJ:u-x6o8ySG0sC,294,https://iopscience.iop.org/article/10.1088/0266-5611/16/5/303/meta,17355047040110213450,/scholar?cites=17355047040110213450,,,https://personalpages.manchester.ac.uk/staff/Oliver.Dorn/ResearchProjects/IP00DMR.pdf,0,0,0
1277765,Wavelet domain image restoration with adaptive edge-preserving regularization,2000,Murat Belge and Misha E Kilmer and Eric L Miller,9,IEEE Transactions on Image Processing,4,597-608,IEEE,In this paper. we consider a wavelet based edge-preserving regularization scheme for use in linear image restoration problems. Our efforts build on a collection of mathematical results indicating that wavelets are especially useful for representing functions that contain discontinuities (i.e.. edges in two dimensions or jumps in one dimension). We interpret the resulting theory in a statistical signal processing framework and obtain a highly flexible framework for adapting the degree of regularization to the local structure of the underlying image. In particular. we are able to adapt quite easily to scale-varying and orientation-varying features in the image while simultaneously retaining the edge preservation properties of the regularizer. We demonstrate a half-quadratic algorithm for obtaining the restorations from observed data.,True,d1jBsvwAAAAJ:9yKSN-GCB0IC,254,https://ieeexplore.ieee.org/abstract/document/841937/,7504652016638625886,/scholar?cites=7504652016638625886,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.7022&rep=rep1&type=pdf,0,0,0
1277766,Tomographic optical breast imaging guided by three-dimensional mammography,2003,Ang Li and Eric L Miller and Misha E Kilmer and Thomas J Brukilacchio and Tina Chaves and Jonathan Stott and Quan Zhang and Tao Wu and MaryAnn Chorlton and Richard H Moore and Daniel B Kopans and David A Boas,42,Applied optics,25,5181-5190,Optical Society of America,We introduce a modified Tikhonov regularization method to include three-dimensional x-ray mammography as a prior in the diffuse optical tomography reconstruction. With simulations we show that the optical image reconstruction resolution and contrast are improved by implementing this x-ray-guided spatial constraint. We suggest an approach to find the optimal regularization parameters. The presented preliminary clinical result indicates the utility of the method.,True,d1jBsvwAAAAJ:d1gkVwhDpl0C,253,https://www.osapublishing.org/abstract.cfm?uri=ao-42-25-5181,8669399374693574089,/scholar?cites=8669399374693574089,,,http://rabi.nmr.mgh.harvard.edu/PMI/PDF/2003/Li_AppliedOptics_42_5181_2003.pdf,0,0,0
1277767,Efficient determination of multiple regularization parameters in a generalized L-curve framework,2002,Murat Belge and Misha E Kilmer and Eric L Miller,18,Inverse problems,4,1161,IOP Publishing,The selection of multiple regularization parameters is considered in a generalized L-curve framework. Multiple-dimensional extensions of the L-curve for selecting multiple regularization parameters are introduced. and a minimum distance function (MDF) is developed for approximating the regularization parameters corresponding to the generalized corner of the L-hypersurface. For the single-parameter (ie L-curve) case. it is shown through a model that the regularization parameters minimizing the MDF essentially maximize the curvature of the L-curve. Furthermore. for both the single-and multiple-parameter cases the MDF approach leads to a simple fixed-point iterative algorithm for computing regularization parameters. Examples indicate that the algorithm converges rapidly thereby making the problem of computing parameters according to the generalized corner of the L-hypersurface computationally tractable.,True,d1jBsvwAAAAJ:qjMakFHDy7sC,249,https://iopscience.iop.org/article/10.1088/0266-5611/18/4/314/meta,9387869536633375904,/scholar?cites=9387869536633375904,,,https://www.academia.edu/download/4281454/10.1.1.135.5969.pdf,0,0,0
1277768,Combined optical and X-ray tomosynthesis breast imaging,2011,Qianqian Fang and Juliette Selb and Stefan A Carp and Gregory Boverman and Eric L Miller and Dana H Brooks and Richard H Moore and Daniel B Kopans and David A Boas,258,Radiology,1,89-97,Radiological Society of North America. Inc.,Purpose To explore the optical and physiologic properties of normal and lesion-bearing breasts by using a combined optical and digital breast tomosynthesis (DBT) imaging system. Materials and Methods Institutional review board approval and patient informed consent were obtained for this HIPAA-compliant study. Combined optical and tomosynthesis imaging analysis was performed in 189 breasts from 125 subjects (mean age. 56 years±13 [standard deviation]). including 138 breasts with negative findings and 51 breasts with lesions. Three-dimensional (3D) maps of total hemoglobin concentration (HbT). oxygen saturation (So2). and tissue reduced scattering coefficients were interpreted by using the coregistered DBT images. Paired and unpaired t tests were performed between various tissue types to identify significant differences. Results The estimated average bulk HbT from 138 normal breasts was 19.2 …,True,d1jBsvwAAAAJ:aqlVkmm33-oC,203,https://pubs.rsna.org/doi/abs/10.1148/radiol.10082176,17308103432385578740,/scholar?cites=17308103432385578740,,,https://pubs.rsna.org/doi/full/10.1148/radiol.10082176,0,0,0
1277769,Multiple hypothesis video segmentation from superpixel flows,2010,Amelio Vazquez-Reina and Shai Avidan and Hanspeter Pfister and Eric Miller,,,,268-281,Springer. Berlin. Heidelberg,Multiple Hypothesis Video Segmentation (MHVS) is a method for the unsupervised photometric segmentation of video sequences. MHVS segments arbitrarily long video streams by considering only a few frames at a time. and handles the automatic creation. continuation and termination of labels with no user initialization or supervision. The process begins by generating several pre-segmentations per frame and enumerating multiple possible trajectories of pixel regions within a short time window. After assigning each trajectory a score. we let the trajectories compete with each other to segment the sequence. We determine the solution of this segmentation problem as the MAP labeling of a higher-order random field. This framework allows MHVS to achieve spatial and temporal long-range label consistency while operating in an on-line manner. We test MHVS on several videos of natural scenes with arbitrary …,True,d1jBsvwAAAAJ:b1wdh0AR-JQC,203,https://link.springer.com/chapter/10.1007/978-3-642-15555-0_20,1168923368761980905,/scholar?cites=1168923368761980905,,,https://link.springer.com/content/pdf/10.1007/978-3-642-15555-0_20.pdf,0,0,0
1277770,Tensor-based formulation and nuclear norm regularization for multienergy computed tomography,2014,Oguz Semerci and Ning Hao and Misha E Kilmer and Eric L Miller,23,IEEE Transactions on Image Processing,4,1678-1693,IEEE,The development of energy selective. photon counting X-ray detectors allows for a wide range of new possibilities in the area of computed tomographic image formation. Under the assumption of perfect energy resolution. here we propose a tensor-based iterative algorithm that simultaneously reconstructs the X-ray attenuation distribution for each energy. We use a multilinear image model rather than a more standard stacked vector representation in order to develop novel tensor-based regularizers. In particular. we model the multispectral unknown as a three-way tensor where the first two dimensions are space and the third dimension is energy. This approach allows for the design of tensor nuclear norm regularizers. which like its 2D counterpart. is a convex function of the multispectral unknown. The solution to the resulting convex optimization problem is obtained using an alternating direction method of multipliers …,True,d1jBsvwAAAAJ:HGTzPopzzJcC,197,https://ieeexplore.ieee.org/abstract/document/6737273/,3413242000149167613,/scholar?cites=3413242000149167613,,,https://arxiv.org/pdf/1307.5348,0,0,0
1277771,Nonlocal means denoising of ECG signals,2012,Brian H Tracey and Eric L Miller,59,IEEE transactions on biomedical engineering,9,2383-2386,IEEE,Patch-based methods have attracted significant attention in recent years within the field of image processing for a variety of problems including denoising. inpainting. and super-resolution interpolation. Despite their prevalence for processing 2-D signals. they have received little attention in the 1-D signal processing literature. In this letter. we explore application of one such method. the nonlocal means (NLM) approach. to the denoising of biomedical signals. Using ECG as an example. we demonstrate that a straightforward NLM-based denoising scheme provides signal-to-noise ratio improvements very similar to state of the art wavelet-based methods. while giving   3   or greater reduction in metrics measuring distortion of the denoised waveform.,True,d1jBsvwAAAAJ:4fGpz3EwCPoC,170,https://ieeexplore.ieee.org/abstract/document/6242391/,3310595441292295663,/scholar?cites=3310595441292295663,,,,0,0,0
1277772,Combined optical imaging and mammography of the healthy breast: optical contrast derived from breast structure and compression,2008,Qianqian Fang and Stefan A Carp and Juliette Selb and Greg Boverman and Quan Zhang and Daniel B Kopans and Richard H Moore and Eric L Miller and Dana H Brooks and David A Boas,28,IEEE transactions on medical imaging,1,30-42,IEEE,In this paper. we report new progress in developing the instrument and software platform of a combined X-ray mammography/diffuse optical breast imaging system. Particularly. we focus on system validation using a series of balloon phantom experiments and the optical image analysis of 49 healthy patients. Using the finite-element method for forward modeling and a regularized Gauss-Newton method for parameter reconstruction. we recovered the inclusions inside the phantom and the hemoglobin images of the human breasts. An enhanced coupling coefficient estimation scheme was also incorporated to improve the accuracy and robustness of the reconstructions. The recovered average total hemoglobin concentration (HbT) and oxygen saturation (SO2) from 68 breast measurements are 16.2 mum and 71%. respectively. where the HbT presents a linear trend with breast density. The low HbT value compared to …,True,d1jBsvwAAAAJ:roLk4NBRz8UC,169,https://ieeexplore.ieee.org/abstract/document/4520152/,6506774653110190346,/scholar?cites=6506774653110190346,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2642986/,0,0,0
1277773,Reconstructing chromosphere concentration images directly by continuous-wave diffuse optical tomography,2004,Ang Li and Quan Zhang and Joseph P Culver and Eric L Miller and David A Boas,29,Optics letters,3,256-258,Optical Society of America,We present an algorithm to reconstruct chromosphere concentration images directly rather than following the traditional two-step process of reconstructing wavelength-dependent absorption coefficient images and then calculating chromosphere concentration images. This procedure imposes prior spectral information into the image reconstruction that results in a dramatic improvement in the image contrast-to-noise ratio of better than 100%. We demonstrate this improvement with simulations and a dynamic blood phantom experiment.,True,d1jBsvwAAAAJ:2osOgNQ5qMEC,160,https://www.osapublishing.org/abstract.cfm?uri=OL-29-3-256,12507122513754523411,/scholar?cites=12507122513754523411,,,https://www.nmr.mgh.harvard.edu/optics/PDF/2004/Li_OptLett_29_256_2004.pdf,0,0,0
1277774,Two-dimensional digital image correlation for in-plane displacement and strain measurement: a review,2009,Bing Pan and Kemao Qian and Huimin Xie and Anand Asundi,20,,6,062001,IOP Publishing,As a practical and effective tool for quantitative in-plane deformation measurement of a planar object surface. two-dimensional digital image correlation (2D DIC) is now widely accepted and commonly used in the field of experimental mechanics. It directly provides full-field displacements to sub-pixel accuracy and full-field strains by comparing the digital images of a test object surface acquired before and after deformation. In this review. methodologies of the 2D DIC technique for displacement field measurement and strain field estimation are systematically reviewed and discussed. Detailed analyses of the measurement accuracy considering the influences of both experimental conditions and algorithm details are provided. Measures for achieving high accuracy deformation measurement using the 2D DIC technique are also recommended. Since microscale and nanoscale deformation measurement can easily be …,True,JCehBDoAAAAJ:O3NaXMp0MMsC,2607,https://iopscience.iop.org/article/10.1088/0957-0233/20/6/062001/meta,4745498693167715377,/scholar?cites=4745498693167715377,,,,0,0,0
1277775,Two-dimensional windowed Fourier transform for fringe pattern analysis: principles. applications and implementations,2007,Qian Kemao,45,Optics and Lasers in Engineering,2,304-317,Elsevier,Fringe patterns from optical metrology systems need to be demodulated to get the desired parameters. Two-dimensional windowed Fourier transform is chosen for the determination of phase and phase derivatives. Two algorithms. one based on filtering and the other based on similarity measure. are developed. Some applications based on these two algorithms are explored. including strain determination. phase unwrapping. phase-shifter calibration. fault detection. edge detection and fringe segmentation. Various examples are given to demonstrate the ideas. Finally implementations of these algorithms are addressed. Most of the work has appeared in various papers and its originality is not claimed. Instead. this paper gives an overview and more insights of our work on windowed Fourier transform.,True,JCehBDoAAAAJ:u5HHmVD_uO8C,621,https://www.sciencedirect.com/science/article/pii/S0143816606000455,7568193288275276241,/scholar?cites=7568193288275276241,,,https://files.transtutors.com/cdn/uploadassignments/transtutors005_fyp_fund-wftoverview_1.pdf,0,0,0
1277776,Windowed Fourier transform for fringe pattern analysis,2004,Qian Kemao,43,Applied Optics,13,2695-2702,Optical Society of America,Fringe patterns in optical metrology systems need to be demodulated to yield the desired parameters. Time-frequency analysis is a useful concept for fringe demodulation. and a windowed Fourier transform is chosen for the determination of phase and phase derivative. Two approaches are developed: the first is based on the concept of filtering the fringe patterns. and the second is based on the best match between the fringe pattern and computer-generated windowed exponential elements. I focus on the extraction of phase and phase derivatives from either phase-shifted fringe patterns or a single carrier fringe pattern. Principles as well as examples are given to show the effectiveness of the proposed methods.,True,JCehBDoAAAAJ:u-x6o8ySG0sC,515,https://www.osapublishing.org/abstract.cfm?uri=AO-43-13-2695,18344229305580602875,/scholar?cites=18344229305580602875,,,,0,0,0
1277777,Study on subset size selection in digital image correlation for speckle patterns,2008,Bing Pan and Huimin Xie and Zhaoyang Wang and Kemao Qian and Zhiyong Wang,16,Optics express,10,7037-7048,Optical Society of America,Digital Image Correlation (DIC) is a flexible and effective technique to measure the displacements on specimen surfaces by matching the reference subsets in the undeformed image with the target subsets in the deformed image.  With the existing DIC techniques. the user must rely on experience and intuition to manually define the size of the reference subset. which is found to be critical to the accuracy of measured displacements.  In this paper. the problem of subset size selection in the DIC technique is investigated.  Based on the Sum of Squared Differences (SSD) correlation criterion as well as the assumption that the gray intensity gradients of image noise are much lower than that of speckle image. a theoretical model of the displacement measurement accuracy of DIC is derived.  The theoretical model indicates that the displacement measurement accuracy of DIC can be accurately predicted based on the …,True,JCehBDoAAAAJ:ns9cj8rnVeAC,496,https://www.osapublishing.org/abstract.cfm?uri=oe-16-10-7037,10881677329115423273,/scholar?cites=10881677329115423273,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-16-10-7037&seq=0,0,0,0
1277778,Phase error analysis and compensation for nonsinusoidal waveforms in phase-shifting digital fringe projection profilometry,2009,Bing Pan and Qian Kemao and Lei Huang and Anand Asundi,34,Optics Letters,4,416-418,Optical Society of America,The nonlinear intensity response of a digital fringe projection profilometry (FPP) system causes the captured fringe patterns to be nonsinusoidal waveforms and leads to an additional phase measurement error for commonly used three- and four-step phase-shifting algorithms. We perform theoretical analysis of the phase error owing to the nonsinusoidal waveforms. Based on the derived theoretical model. a novel and simple iterative phase compensation algorithm is proposed to compensate the nonsinusoidal phase error. Experiments show that the proposed algorithm can be used for effective phase error compensation in practical phase-shifting FPP.,True,JCehBDoAAAAJ:d1gkVwhDpl0C,285,https://www.osapublishing.org/abstract.cfm?uri=ol-34-4-416,6453416447100139658,/scholar?cites=6453416447100139658,,,https://www.researchgate.net/profile/Lei_HUANG/publication/24284154_Phase_error_analysis_and_compensation_for_nonsinusoidal_waveforms_in_phase-shifting_digital_fringe_projection_profilometry/links/545a31bf0cf2bccc491326b8.pdf,0,0,0
1277779,Comparison of Fourier transform. windowed Fourier transform. and wavelet transform methods for phase extraction from a single fringe pattern in fringe projection profilometry,2010,Lei Huang and Qian Kemao and Bing Pan and Anand Krishna Asundi,48,Optics and Lasers in Engineering,2,141-148,Elsevier,Fringe projection profilometry is widely used for three-dimensional (3-D) surface shape measurement using phase-shifting (PS) methods with multiple images or transform methods with single projected fringe pattern. In this paper. phase extraction methods from a single fringe pattern using different transform methods are compared using both simulations and experiments. The principles of Fourier transform (FT). windowed Fourier transform (WFT) and wavelet transform (WT) methods for fringe pattern processing are introduced. Implementation of 1-D and 2-D algorithms and phase compensation are discussed. Noisy and non-sinusoidal waveforms are involved into this comparison. The merits and limitations of each of these processing methods are indicated.,True,JCehBDoAAAAJ:9yKSN-GCB0IC,255,https://www.sciencedirect.com/science/article/pii/S0143816609000840,683926352451600188,/scholar?cites=683926352451600188,,,,0,0,0
1277780,Quality-guided phase unwrapping technique: comparison of quality maps and guiding strategies,2011,Ming Zhao and Lei Huang and Qican Zhang and Xianyu Su and Anand Asundi and Qian Kemao,50,Applied optics,33,6214-6224,Optical Society of America,Quality-guided phase unwrapping is a widely used technique with different quality definitions and guiding strategies reported. It is thus necessary to do a detailed comparison of these approaches to choose the optimal quality map and guiding strategy. For quality maps. in the presence of noise. transform-based methods are found to be the best choice. However in the presence of discontinuities. phase unwrapping is itself unresolved and hence quality-guided phase unwrapping is not sufficient. For guiding strategies. classical. two-section. and stack-chain guiding strategies are chosen for comparison. If accuracy is the foremost criterion then the classical guiding strategy with a data structure of indexed interwoven linked list is best. If speed is of essence then the stack-chain guiding strategy is the one to use.,True,JCehBDoAAAAJ:M3ejUd6NZC8C,196,https://www.osapublishing.org/abstract.cfm?uri=ao-50-33-6214,9412212827899634098,/scholar?cites=9412212827899634098,,,https://www.researchgate.net/profile/Lei_HUANG/publication/51822466_Quality-guided_phase_unwrapping_technique_Comparison_of_quality_maps_and_guiding_strategies/links/54ad5a8e0cf24aca1c6f1fc2.pdf,0,0,0
1277781,Windowed Fourier transform for fringe pattern analysis: theoretical analyses,2008,Qian Kemao and Haixia Wang and Wenjing Gao,47,Applied optics,29,5408-5419,Optical Society of America,A windowed Fourier ridges (WFR) algorithm and a windowed Fourier filtering (WFF) algorithm have been proposed for fringe pattern analysis and have been demonstrated to be versatile and effective. Theoretical analyses of their performances are of interest. Local frequency and phase extraction errors by the WFR and WFF algorithms are analyzed in this paper. Effectiveness of the WFR and WFF algorithms will thus be theoretically proven. Consider four phase-shifted fringe patterns with local quadric phase [c_20=c_02=0.005 rad/(pixel)^2]. and assume that the noise in these fringe patterns have mean values of zero and standard deviations the same as the fringe amplitude. If the phase is directly obtained using the four-step phase-shifting algorithm. the phase error has a mean of zero and a standard deviation of 0.7 rad. However. when using the WFR algorithm with a window size of σ_x=σ_y=10 pixels. the local …,True,JCehBDoAAAAJ:2osOgNQ5qMEC,158,https://www.osapublishing.org/abstract.cfm?uri=ao-47-29-5408,11122672908088908662,/scholar?cites=11122672908088908662,,,,0,0,0
1277782,Windowed Fourier-filtered and quality-guided phase-unwrapping algorithm,2008,Qian Kemao and Wenjing Gao and Haixia Wang,47,Applied optics,29,5420-5428,Optical Society of America,We propose a windowed Fourier-filtered and quality-guided phase-unwrapping algorithm that is an extension and improvement of our previous phase-unwrapping algorithm based on windowed Fourier transform [Opt. Laser Technol.37. 458 (2005)OLTCAS0030-399210.1016/j.optlastec.2004.07.007. Key Eng. Mater.326-328. 67 (2006)KEMAEY1013-9826]. First. the filtered amplitude is used as a real-valued quality map. rather than a binary mask. which makes the phase-unwrapping algorithm more tolerant to low-quality regions in a wrapped-phase map. and the process is more automatic. Second. the window size selection is considered. which enables the algorithm to be adapted to tackle different phase-unwrapping problems. A large window size is useful for removing noise. building long barriers along phase discontinuities. and identifying invalid regions. while a small window size is useful for preserving local …,True,JCehBDoAAAAJ:UeHWp8X0CEIC,113,https://www.osapublishing.org/abstract.cfm?uri=ao-47-29-5420,3273055120303513251,/scholar?cites=3273055120303513251,,,,0,0,0
1277783,A simple phase unwrapping approach based on filtering by windowed Fourier transform: a note on the threshold selection,2008,Qian Kemao,40,Optics & Laser Technology,8,1091-1098,Elsevier,A simple phase unwrapping approach based on windowed Fourier filtering was proposed recently [K. Qian et al. A simple phase unwrapping approach based on filtering by windowed Fourier transform. Opt Laser Technol 2005;37:458–62]. The windowed Fourier filtering algorithm is an essential ingredient that suppresses the noise effectively and makes the phase unwrapping trivial. This paper adds a note on the threshold selection in the windowed Fourier filtering algorithm. A large interval can be selected as the threshold to obtain almost optimal filtering results. Once the selected threshold is suitable. it is almost optimal. This makes the threshold selection in the windowed Fourier filtering algorithm extremely easy.,True,JCehBDoAAAAJ:0iM-huCvmk0C,87,https://www.sciencedirect.com/science/article/pii/S0030399208000479,16622979930774361048,/scholar?cites=16622979930774361048,,,,0,0,0
1277784,Path-independent digital image correlation with high accuracy. speed and robustness,2015,Zhenyu Jiang and Qian Kemao and Hong Miao and Jinglei Yang and Liqun Tang,65,Optics and Lasers in Engineering,,93-102,Elsevier,The initial guess transferring mechanism is widely used in iterative DIC algorithms and leads to path-dependence. Using the known deformation at a processed point to estimate the initial guess at its neighboring points could save considerable computation time. and a cogitatively-selected processing path contributes to the improved robustness. In this work. our experimental study demonstrates that a path-independent DIC method is capable to achieve high accuracy. efficiency and robustness in full-field measurement of deformation. by combining an inverse compositional Gauss–Newton (IC-GN) algorithm for sub-pixel registration with a fast Fourier transform-based cross correlation (FFT-CC) algorithm to estimate the initial guess. In the proposed DIC method. the determination of initial guess accelerated by well developed software library can be a negligible burden of computation. The path-independence also …,True,JCehBDoAAAAJ:ZYLUaBFA95QC,85,https://www.sciencedirect.com/science/article/pii/S0143816614001560,2507940631870700756,/scholar?cites=2507940631870700756,,,https://dr.ntu.edu.sg/bitstream/10356/81521/1/Path-independent%20digital%20image%20correlation%20with%20high%20accuracy%2C%20speed%20and%20robustness.pdf,0,0,0
1277785,A simple observer for nonlinear systems applications to bioreactors,1992,Jean-Paul Gauthier and Hassan Hammouri and Sami Othman,37,IEEE Transactions on automatic control,6,875-880,,In this note. we construct an observer for nonlinear systems under rather general technical assumptions (the fact that some functions are globally Lipschitz). This observer works either for gutonomous systems or for nonlinear systems that are observable for any input. A tentative application to biological systems is described.-I. INTRobugToN Given a nonlinear system. an observer is a system whose task is state estimation. The inputs of the observer are the inputs and the outputs of the given system. The observer is expected to produce the estimate (t) of the state x (t) of the original system. One usually requires at least that some distance d (k (t). x (t)) goes to zero as t-oo; in some cases. exponential convergence is required. In the case of linear systems. a standard solution is given by the classical Luenberger observer.,True,wsRUAvAAAAAJ:ZuybSZzF8UAC,2098,https://www.researchgate.net/profile/Sami_Othman/publication/3021543_A_simple_observer_for_nonlinear_systems_application_to_bioreactors/links/5601827608aed985182724c0.pdf,3136449755648994453,/scholar?cites=3136449755648994453,,,https://www.researchgate.net/profile/Sami_Othman/publication/3021543_A_simple_observer_for_nonlinear_systems_application_to_bioreactors/links/5601827608aed985182724c0.pdf,0,0,0
1277786,Observability and observers for nonlinear systems,1994,Jean-Paul Gauthier and Ivan AK Kupka,32,SIAM journal on control and optimization,4,975-994,Society for Industrial and Applied Mathematics,This paper deals with observability and observers for general nonlinear systems. In the non-control-affine case. we characterize systems that are observable independently of the inputs. An exponential observer for these systems is also exhibited.,True,wsRUAvAAAAAJ:N5tVd3kTz84C,571,https://epubs.siam.org/doi/abs/10.1137/S0363012991221791,13668649315465110208,/scholar?cites=13668649315465110208,,,,0,0,0
1277787,Observability and observers for nonlinear systems,1994,Jean-Paul Gauthier and Ivan AK Kupka,32,SIAM journal on control and optimization,4,975-994,Society for Industrial and Applied Mathematics,This paper deals with observability and observers for general nonlinear systems. In the non-control-affine case. we characterize systems that are observable independently of the inputs. An exponential observer for these systems is also exhibited.,True,wsRUAvAAAAAJ:u5HHmVD_uO8C,564,https://epubs.siam.org/doi/abs/10.1137/S0363012991221791,13668649315465110208,/scholar?cites=13668649315465110208,,,,0,0,0
1277788,Deterministic observation theory and applications,2001,Jean-Paul Gauthier and Ivan Kupka,,,,,Cambridge university press,This 2001 book presents a general theory as well as a constructive methodology to solve'observation problems'. that is. reconstructing the full information about a dynamical process on the basis of partial observed data. A general methodology to control processes on the basis of the observations is also developed. Illustrative but also practical applications in the chemical and petroleum industries are shown. This book is intended for use by scientists in the areas of automatic control. mathematics. chemical engineering and physics.,True,wsRUAvAAAAAJ:d1gkVwhDpl0C,549,http://books.google.com/books?hl=en&lr=&id=wA92p5YxAycC&oi=fnd&pg=PP1&dq=info:eO_ayrguk40J:scholar.google.com&ots=YMbBzcpm4Q&sig=BpZXd2d9TapUYJ3YMo0te0TkQog,10201548952136511352,/scholar?cites=10201548952136511352,,,https://pdfs.semanticscholar.org/a36c/e16ef73788f8d64342ea5857cad526582791.pdf,0,0,0
1277789,Observability for anyof a class of nonlinear systems,1981,J Gauthier and G Bornard,26,IEEE Transactions on Automatic Control,4,922-926,IEEE,This paper deals with a class of nonlinear systems. which are linear with respect to the inputs. After a necessary and sufficient condition of observability for any input function is obtained. A canonical form is then given.,True,wsRUAvAAAAAJ:u-x6o8ySG0sC,492,https://ieeexplore.ieee.org/abstract/document/1102743/,11075006338665775726,/scholar?cites=11075006338665775726,,,,0,0,0
1277790,High gain estimation for nonlinear systems,1992,F Deza and E Busvelle and JP Gauthier and D Rakotopara,18,Systems & control letters,4,295-299,North-Holland,This work is a continuation of [4] where the third author exhibits a high gain exponential observer for MISO nonlinear systems affine in the input and observable for any input with continuous dynamics and measurements. In this paper. we establish stability results for continuous-continuous and continuous-discrete extended Kalman filters derived from the observer of [4].,True,wsRUAvAAAAAJ:9yKSN-GCB0IC,334,https://www.sciencedirect.com/science/article/pii/0167691192900592,16155409090160459058,/scholar?cites=16155409090160459058,,,,0,0,0
1277791,Optimal control in laser-induced population transfer for two-and three-level quantum systems,2002,Ugo Boscain and Grégoire Charlot and Jean-Paul Gauthier and Stéphane Guérin and Hans-Rudolf Jauslin,43,Journal of Mathematical Physics,5,2107-2132,American Institute of Physics,We apply the techniques of control theory and of sub-Riemannian geometry to laser-induced population transfer in two- and three-level quantum systems. The aim is to induce complete population transfer by one or two laser pulses minimizing the pulse fluences. Sub-Riemannian geometry and singular-Riemannian geometry provide a natural framework for this minimization. where the optimal control is expressed in terms of geodesics. We first show that in two-level systems the well-known technique of “π-pulse transfer” in the rotating wave approximation emerges naturally from this minimization. In three-level systems driven by two resonant fields. we also find the counterpart of the “π-pulse transfer.” This geometrical picture also allows one to analyze the population transfer by adiabatic passage.,True,wsRUAvAAAAAJ:2osOgNQ5qMEC,217,https://aip.scitation.org/doi/abs/10.1063/1.1465516,10191576186021689883,/scholar?cites=10191576186021689883,,,https://www.researchgate.net/profile/Gauthier_Jean-Paul2/publication/228688387_Optimal_Control_in_laser-induced_population_transfer_for_two-_or_three-level_quantum_systems/links/5c6f1bed458515831f6511cb/Optimal-Control-in-laser-induced-population-transfer-for-two-or-three-level-quantum-systems.pdf,0,0,0
1277792,An adaptive high-gain observer for nonlinear systems,2010,Nicolas Boizot and Eric Busvelle and Jean-Paul Gauthier,46,Automatica,9,1483-1488,Pergamon,In this paper the authors provide a solution to the noise sensitivity of high-gain observers. The resulting nonlinear observer possesses simultaneously (1) extended Kalman filter’s good noise filtering properties. and (2) the reactivity of the high-gain extended Kalman filter with respect to large perturbations.The authors introduce innovation as the quantity that drives the gain adaptation. They prove a general convergence result. propose guidelines to practical implementation and show simulation results for an example.,True,wsRUAvAAAAAJ:YsMSGLbcyi4C,200,https://www.sciencedirect.com/science/article/pii/S0005109810002542,12383288680805388385,/scholar?cites=12383288680805388385,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.709.7015&rep=rep1&type=pdf,0,0,0
1277793,The intrinsic hypoelliptic Laplacian and its heat kernel on unimodular Lie groups,2009,Andrei Agrachev and Ugo Boscain and Jean-Paul Gauthier and Francesco Rossi,256,Journal of Functional Analysis,8,2621-2655,Academic Press,We present an invariant definition of the hypoelliptic Laplacian on sub-Riemannian structures with constant growth vector using the Popp's volume form introduced by Montgomery. This definition generalizes the one of the Laplace–Beltrami operator in Riemannian geometry. In the case of left-invariant problems on unimodular Lie groups we prove that it coincides with the usual sum of squares. We then extend a method (first used by Hulanicki on the Heisenberg group) to compute explicitly the kernel of the hypoelliptic heat equation on any unimodular Lie group of type I. The main tool is the noncommutative Fourier transform. We then study some relevant cases: SU (2). SO (3). SL (2)(with the metrics inherited by the Killing form). and the group SE (2) of rototranslations of the plane.,True,wsRUAvAAAAAJ:IjCSPb-OGe4C,150,https://www.sciencedirect.com/science/article/pii/S0022123609000202,15449258071293393097,/scholar?cites=15449258071293393097,,,https://www.sciencedirect.com/science/article/pii/S0022123609000202/pdf?md5=82dacbf2337c999310b56195a6770beb&pid=1-s2.0-S0022123609000202-main.pdf&_valck=1,0,0,0
1277794,A separation principle for bilinear systems with dissipative drift,1992,JP Gauthier and I Kupka,37,IEEE transactions on automatic control,12,1970-1974,IEEE,Input-output stabilization of a class of bilinear systems using a nonlinear stabilizing feedback control law together with an observer. is studied. In some cases. it can be proved that the result is a globally asymptotically stable system.< >,True,wsRUAvAAAAAJ:qjMakFHDy7sC,144,https://ieeexplore.ieee.org/abstract/document/182484/,2173617625492178883,/scholar?cites=2173617625492178883,,,,0,0,0
1277795,The inactivation principle: mathematical solutions minimizing the absolute work and biological implications for the planning of arm movements,2008,Bastien Berret and Christian Darlot and Frédéric Jean and Thierry Pozzo and Charalambos Papaxanthis and Jean Paul Gauthier,4,PLoS Comput Biol,10,e1000194,Public Library of Science,An important question in the literature focusing on motor control is to determine which laws drive biological limb movements. This question has prompted numerous investigations analyzing arm movements in both humans and monkeys. Many theories assume that among all possible movements the one actually performed satisfies an optimality criterion. In the framework of optimal control theory. a first approach is to choose a cost function and test whether the proposed model fits with experimental data. A second approach (generally considered as the more difficult) is to infer the cost function from behavioral data. The cost proposed here includes a term called the absolute work of forces. reflecting the mechanical energy expenditure. Contrary to most investigations studying optimality principles of arm movements. this model has the particularity of using a cost function that is not smooth. First. a mathematical theory related to both direct and inverse optimal control approaches is presented. The first theoretical result is the Inactivation Principle. according to which minimizing a term similar to the absolute work implies simultaneous inactivation of agonistic and antagonistic muscles acting on a single joint. near the time of peak velocity. The second theoretical result is that. conversely. the presence of non-smoothness in the cost function is a necessary condition for the existence of such inactivation. Second. during an experimental study. participants were asked to perform fast vertical arm movements with one. two. and three degrees of freedom. Observed trajectories. velocity profiles. and final postures were accurately simulated by the model. In …,True,wsRUAvAAAAAJ:WF5omc3nYNoC,134,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000194,583003800029672308,/scholar?cites=583003800029672308,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000194,0,0,0
1277796,Comparison and evaluation of retrospective intermodality brain image registration techniques,1997,Jay West and J Michael Fitzpatrick and Matthew Y Wang and Benoit M Dawant and Calvin R Maurer Jr and Robert M Kessler and Robert J Maciunas and Christian Barillot and Didier Lemoine and Andre Collignon and Frederik Maes and Paul Suetens and Dirk Vandermeulen and Petra A Van Den Elsen and Sandy Napel and Thilaka S Sumanaweera and Beth Harkness and Paul F Hemler and Derek LG Hill and David J Hawkes and Colin Studholme and JB Antoine Maintz and Max A Viergever and Gregoire Malandain and Xavier Pennec and Marilyn E Noz and Gerald Q Maguire Jr and Michael Pollack and Charles A Pelizzari and Richard A Robb and Dennis Hanson and Roger P Woods,21,Journal of computer assisted tomography,4,554-568,LWW,Purpose:The primary objective of this study is to perform a blinded evaluation of a group of retrospective image registration techniques using as a gold standard a prospective. marker-based registration method. To ensure blindedness. all retrospective registrations were performed by participants who had no knowledge of the gold standard results until after their results had been submitted. A secondary goal of the project is to evaluate the importance of correcting geometrical distortion in MR images by comparing the retrospective registration error in the rectified images. ie. those that have had the distortion correction applied. with that of the same images before rectification.Method:Image volumes of three modalities (CT. MR. and PET) were obtained from patients undergoing neurosurgery at Vanderbilt University Medical Center on whom bone-implanted fiducial markers were mounted. These volumes had all traces …,True,12qyxi8AAAAJ:u5HHmVD_uO8C,1228,https://journals.lww.com/jcat/fulltext/1997/07000/comparison_and_evaluation_of_retrospective.7.aspx,16533605945087699318,/scholar?cites=16533605945087699318,,,https://dspace.library.uu.nl/bitstream/handle/1874/18920/van_den_elsen_98_comparison.pdf?sequence=2,0,0,0
1277797,Phase space picture of quantum mechanics: group theoretical approach,1991,Young-Suk Kim and Marilyn E Noz,40,,,,World Scientific,This book covers the theory and applications of the Wigner phase space distribution function and its symmetry properties. The book explains why the phase space picture of quantum mechanics is needed. in addition to the conventional Schr dinger or Heisenberg picture. It is shown that the uncertainty relation can be represented more accurately in this picture. In addition. the phase space picture is shown to be the natural representation of quantum mechanics for modern optics and relativistic quantum mechanics of extended objects.,True,12qyxi8AAAAJ:9yKSN-GCB0IC,458,http://books.google.com/books?hl=en&lr=&id=msNYBo6gtH0C&oi=fnd&pg=PA1&dq=info:9YKc23zksHAJ:scholar.google.com&ots=hQdkA_EEk5&sig=4PyHJyGIEOsGshz64Ycr3O89UMk,8120241353060549365,/scholar?cites=8120241353060549365,,,https://www.ysfine.com/home/book91.html,0,0,0
1277798,The radiologic prediction of Alzheimer disease: the atrophic hippocampal formation.,1993,MJ De Leon and J Golomb and AE George and A Convit and CY Tarshish and T McRae and S De Santi and G Smith and SH Ferris and M Noz,14,American Journal of Neuroradiology,4,897-906,American Journal of Neuroradiology,To test the hypothesis that atrophy of the hippocampal formation in nondemented elderly individuals would predict subsequent Alzheimer disease.We studied 86 subjects at two time points. 4 years apart. At baseline all study subjects were nondemented and included 54 control subjects and 32 persons who had memory complaints and minimal cognitive impairments. All subjects received a CT scan using a protocol designed to image the perihippocampal cerebrospinal fluid (HCSF) accumulating in the fissures along the axis of the hippocampal formation. Blind to the clinical evaluations. we subjectively assessed the presence of HCSF at the baseline. Retrospectively. we examined the predicted association between baseline HCSF and clinical decline as determined across the two evaluations.At follow-up 25 of the 86 subjects had deteriorated and received the diagnosis of Alzheimer …,True,12qyxi8AAAAJ:u-x6o8ySG0sC,427,http://www.ajnr.org/content/14/4/897.short,479163184085659592,/scholar?cites=479163184085659592,,,http://www.ajnr.org/content/ajnr/14/4/897.full.pdf,0,0,0
1277799,Bowel obstruction: evaluation with CT.,1991,AJ Megibow and EJ Balthazar and KC Cho and SW Medwid and BA Birnbaum and ME Noz,180,Radiology,2,313-318,,Eighty-four computed tomographic (CT) scans from patients referred for bowel obstruction between January 2. 1988. and December 31. 1989. were retrospectively evaluated. A pair of radiologists without knowledge of patient histories determined the presence or absence of bowel obstruction. Sixty-four patients ultimately proved to have intestinal obstruction. and 20 did not. Diagnosis was established by means of surgery (n = 39). barium studies (n = 17). and clinical course (n = 28). Causes of obstruction included adhesions (n = 37). metastases (n = 6). primary tumor (n = 7). Crohn disease (n = 4). hernia (n = 3). hematoma (n = 2). colonic diverticulitis (n = 2). and other (n = 3). In addition. 83 CT examinations in patients with no history or indication of intestinal obstruction were simultaneously reviewed. The overall sensitivity was 94%. specificity was 96%. and accuracy was 95%. The cause of obstruction was correctly …,True,12qyxi8AAAAJ:d1gkVwhDpl0C,413,https://pubs.rsna.org/doi/abs/10.1148/radiology.180.2.2068291,5355201623041186357,/scholar?cites=5355201623041186357,,,,0,0,0
1277800,Theory and applications of the Poincaré group,2012,Young Suh Kim and Marilyn Noz,17,,,,Springer Science & Business Media,Special relativity and quantum mechanics. formulated early in the twentieth century. are the two most important scientific languages and are likely to remain so for many years to come. In the 1920's. when quantum mechanics was developed. the most pressing theoretical problem was how to make it consistent with special relativity. In the 1980's. this is still the most pressing problem. The only difference is that the situation is more urgent now than before. because of the significant quantity of experimental data which need to be explained in terms of both quantum mechanics and special relativity. In unifying the concepts and algorithms of quantum mechanics and special relativity. it is important to realize that the underlying scientific language for both disciplines is that of group theory. The role of group theory in quantum mechanics is well known. The same is true for special relativity. Therefore. the most effective approach to the problem of unifying these two important theories is to develop a group theory which can accommodate both special relativity and quantum mechanics. As is well known. Eugene P. Wigner is one of the pioneers in developing group theoretical approaches to relativistic quantum mechanics. His 1939 paper on the inhomogeneous Lorentz group laid the foundation for this important research line. It is generally agreed that this paper was somewhat ahead of its time in 1939. and that contemporary physicists must continue to make real efforts to appreciate fully the content of this classic work.,True,12qyxi8AAAAJ:2osOgNQ5qMEC,357,http://books.google.com/books?hl=en&lr=&id=ZdXsCAAAQBAJ&oi=fnd&pg=PR9&dq=info:eqsmmwKh0DwJ:scholar.google.com&ots=6V-PLas0Zn&sig=EV6yizAZSXQwLMEN0aoDkCwhgW0,4382179469996501882,/scholar?cites=4382179469996501882,,,,0,0,0
1277801,Covariant harmonic oscillators and the quark model,1973,YS Kim and Marilyn E Noz,8,Physical Review D,10,3521,American Physical Society,An attempt is made to give a physical interpretation to the phenomenological wave function of Yukawa. which gives a correct nucleon form factor in the symmetric quark model. This wave function is first compared with the Bethe-Salpeter wave function. It is shown that they have similar Lorentz-contraction properties in the high-momentum limit. A hyperplane harmonic oscillator is then introduced. It is shown that the Yukawa wave function. which is defined over the entire four-dimensional Euclidean space. can be interpreted in terms of the three-dimensional hyperplane oscillators. It is shown further that this wave function satisfies a Lorentz-invariant differential equation from which excited harmonic-oscillator states can be constructed. and from which a gauge-invariant electromagnetic interaction can be generated.,True,12qyxi8AAAAJ:IjCSPb-OGe4C,199,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.8.3521,13290757012436768972,/scholar?cites=13290757012436768972,,,,0,0,0
1277802,Graphics applied to medical image registration,1991,Gerald Q Maguire Jr and Marilyn E Noz and Henry Rusinek and Judith Jaeger and Elissa L Kramer and Joseph J Sanger and Gwenn Smith,11,IEEE Annals of the History of Computing,02,20-28,IEEE Computer Society,MethodsFigure 1. PET slice at the level of the basal ganglia (upper right). The cross hair indicates the (x. y) values of the pivot point. which determine the selection of the coronal and sag&al views. The upper left shows the coronal section at the z level of the pivot point for the choice of the xz angle. The lower right shows the sagittal section with the same z level as the pivot point for the choice of the yz angle. a stereotactic frame fixed to the head. In each case. the head holder is specifically adapted to the subject’s head. 4. The analytical approach using an anatomic atlas relies on transformation of the atlas to fit images such as those obtained from CT or MR. 4 Once the anatomic structures are well defined. it should be possible to overlay the CT/MR image onto the functional image. However. calculation of the atlas-to-CT/MR transformation presents significant difficulties. Since the CT/MR slices are unlikely to match …,True,12qyxi8AAAAJ:qjMakFHDy7sC,175,https://www.computer.org/csdl/api/v1/periodical/mags/cg/1991/02/mcg1991020020/13rRUwhpBGk/download-article/pdf,7218935953128690020,/scholar?cites=7218935953128690020,,,,0,0,0
1277803,Dynamic three-dimensional MR renography for the measurement of single kidney function: initial experience,2003,Vivian S Lee and Henry Rusinek and Marilyn E Noz and Peter Lee and Meera Raghavan and Elissa L Kramer,227,Radiology,1,289-294,Radiological Society of North America,A three-dimensional magnetic resonance (MR) renographic method to measure single kidney glomerular filtration rate (GFR) and split renal function was developed that is based on renal signal intensity measurements during 2–3 minutes after intravenous injection of a low dose (2 mL or 0.01 mmol/kg) of gadopentetate dimeglumine. In nine subjects. single kidney MR GFR indices correlated well with technetium 99m (99mTc) diethylenetriaminepentaacetic acid (DTPA) clearance (r = 0.7–0.8) for GFR values of 7–48 mL/min. MR right kidney split renal function values (range. 32%–59%) also correlated well with 99mTc-DTPA radionuclide measurements (r = 0.76); differences between the two methods averaged 0.8% ± 8. MR renography was performed along with contrast material–enhanced MR imaging of the kidneys and renal arteries and added 8 minutes or less to the total examination time.© RSNA. 2003,True,12qyxi8AAAAJ:zYLM7Y9cAGgC,150,https://pubs.rsna.org/doi/abs/10.1148/radiol.2271020383,9174742542168445435,/scholar?cites=9174742542168445435,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.6074&rep=rep1&type=pdf,0,0,0
1277804,Hepatocellular tumors: characterization with Mn-DPDP-enhanced MR imaging.,1993,Neil M Rofsky and Jeffrey C Weinreb and Michael E Bernardino and Stuart W Young and JK Lee and Marilyn E Noz,188,Radiology,1,53-59,,Fifty-eight patients suspected of having focal hepatic disease were studied prior to and following the intravenous administration of manganese (II) N.N'-dipyridoxylethylenediamine-N.N'-diacetate 5.5'-bis(phosphate) (DPDP). a hepatobiliary magnetic resonance (MR) contrast agent. Four doses (3. 5. 8. or 10 mumol/kg) of Mn-DPDP were used to test the hypothesis that Mn-DPDP-enhanced MR imaging would display enhancement in tumors of hepatocellular origin. A total of 203 lesions were evaluated. Histologic proof was available in 32 cases. and in 26 cases lesions were evaluated on the basis of characteristic imaging findings. Statistical calculations for distinction of tumors of hepatocellular origin yielded a sensitivity of 100%. a specificity of 92.0%. an accuracy of 93.6%. a positive predictive value of 75.9%. and a negative predictive value of 100%. The authors conclude that the presence and patterns of …,True,12qyxi8AAAAJ:UeHWp8X0CEIC,145,https://pubs.rsna.org/doi/abs/10.1148/radiology.188.1.8390072,9701024022554842249,/scholar?cites=9701024022554842249,,,,0,0,0
1277805,Definitive diagnosis of hepatic hemangiomas: MR imaging versus Tc-99m-labeled red blood cell SPECT.,1990,BA Birnbaum and JC Weinreb and AJ Megibow and JJ Sanger and E Lubat and H Kanamuller and ME Noz and MA Bosniak,176,Radiology,1,95-101,,"Thirty-seven patients with 69 suspected hemangiomas found by means of computed tomography (CT) and/or ultrasound were studied with both 0.5-T magnetic resonance (MR) imaging and single photon emission CT (SPECT) with technetium-99m-labeled red blood cells. Using a criterion of ""perfusion-blood pool mismatch."" SPECT readers diagnosed 50 of 64 hemangiomas and all five ""nonhemangiomas"" (sensitivity. 78% [95% confidence interval. 0.664 - 0.864]; accuracy. 80% [0.69 - 0.877]). Qualitative analysis of lesion signal intensity on T2-weighted spin-echo MR images allowed readers to diagnose 58 of 64 hemangiomas and four of five nonhemangiomas (sensitivity. 91% [0.814 - 0.96]; accuracy. 90% [0.807 - 0.951]). Because of the significantly higher cost of MR imaging and its inability to categorically differentiate hemangiomas from hypervascular metastases. the authors consider SPECT to be the method …",True,12qyxi8AAAAJ:Tyk-4Ss8FVUC,137,https://pubs.rsna.org/doi/abs/10.1148/radiology.176.1.2191377,17500573495665943806,/scholar?cites=17500573495665943806,,,,0,0,0
1277806,A new CT method for measuring cup orientation after total hip arthroplasty a study of 10 patients,2004,Henrik Olivecrona and Lars Weidenhielm and Lotta Olivecrona and Mats Beckman and André Stark and Marilyn Noz and Gerald Maguire and Michael Zeleznik and Lars Svensson and Torbjörn Jonson,75,Acta Orthopaedica Scandinavica,3,252-260,Taylor & Francis,Background It is difficult to assess the orientation of the acetabular component on routine radiographs. We present a method for determining the spatial orientation of the acetabular component after total hip arthroplasty (THA) using computed tomography.Patients and methods Two CT-scans. 10 min apart. were obtained from each of 10 patients after THA. Using locally developed software. two independent examiners measured the orientation of the acetabular component in relation to the pelvis. The measurements were repeated after one week. To be independent of the patient position during scanning. the method involved two steps. Firstly. a 3D volumetric image of the pelvis was brought into a standard pelvic orientation. then the orientation of the acetabular component was measured. The orientation of the acetabular component was expressed as operative anteversion and inclination relative to an internal …,True,12qyxi8AAAAJ:hqOjcs7Dif8C,121,https://www.tandfonline.com/doi/abs/10.1080/00016470410001169,3654902751696146172,/scholar?cites=3654902751696146172,,,https://www.tandfonline.com/doi/pdf/10.1080/00016470410001169,0,0,0
1277807,Isogeometric fluid-structure interaction: theory. algorithms. and computations,2008,Yuri Bazilevs and Victor M Calo and Thomas JR Hughes and Yongjie Zhang,43,Computational mechanics,1,3-37,Springer-Verlag,We present a fully-coupled monolithic formulation of the fluid-structure interaction of an incompressible fluid on a moving domain with a nonlinear hyperelastic solid. The arbitrary Lagrangian–Eulerian description is utilized for the fluid subdomain and the Lagrangian description is utilized for the solid subdomain. Particular attention is paid to the derivation of various forms of the conservation equations; the conservation properties of the semi-discrete and fully discretized systems; a unified presentation of the generalized-α time integration method for fluid-structure interaction; and the derivation of the tangent matrix. including the calculation of shape derivatives. A NURBS-based isogeometric analysis methodology is used for the spatial discretization and three numerical examples are presented which demonstrate the good behavior of the methodology.,True,dzHYBKcAAAAJ:LkGwnXOMwfcC,949,https://link.springer.com/article/10.1007/s00466-008-0315-x,6836096355997525341,/scholar?cites=6836096355997525341,,,https://www.researchgate.net/profile/Victor_Calo/publication/225905824_Isogeometric_fluid-structure_interaction_Theory_algorithms_and_computations/links/0deec52d0143174256000000/Isogeometric-fluid-structure-interaction-Theory-algorithms-and-computations.pdf,0,0,0
1277808,Isogeometric fluid–structure interaction analysis with applications to arterial blood flow,2006,Yuri Bazilevs and Victor M Calo and Yongjie Zhang and Thomas JR Hughes,38,Computational Mechanics,4,310-322,Springer-Verlag,A NURBS (non-uniform rational B-splines)-based isogeometric fluid–structure interaction formulation. coupling incompressible fluids with non-linear elastic solids. and allowing for large structural displacements. is developed. This methodology. encompassing a very general class of applications. is applied to problems of arterial blood flow modeling and simulation. In addition. a set of procedures enabling the construction of analysis-suitable NURBS geometries directly from patient-specific imaging data is outlined. The approach is compared with representative benchmark problems. yielding very good results. Computation of a patient-specific abdominal aorta is also performed. giving qualitative agreement with computations by other researchers using similar models.,True,dzHYBKcAAAAJ:W7OEmFMy1HYC,771,https://link.springer.com/article/10.1007/s00466-006-0084-3,1017761387436190873,/scholar?cites=1017761387436190873,,,https://www.researchgate.net/profile/Victor_Calo/publication/225736347_Isogeometric_Fluid-structure_Interaction_Analysis_with_Applications_to_Arterial_Blood_Flow/links/0046352715fed0ffb0000000.pdf,0,0,0
1277809,Patient-specific vascular NURBS modeling for isogeometric analysis of blood flow,2007,Yongjie Zhang and Yuri Bazilevs and Samrat Goswami and Chandrajit L Bajaj and Thomas JR Hughes,196,Computer methods in applied mechanics and engineering,29-30,2943-2959,North-Holland,We describe an approach to construct hexahedral solid NURBS (Non-Uniform Rational B-Splines) meshes for patient-specific vascular geometric models from imaging data for use in isogeometric analysis. First. image processing techniques. such as contrast enhancement. filtering. classification. and segmentation. are used to improve the quality of the input imaging data. Then. luminal surfaces are extracted by isocontouring the preprocessed data. followed by the extraction of vascular skeleton via Voronoi and Delaunay diagrams. Next. the skeleton-based sweeping method is used to construct hexahedral control meshes. Templates are designed for various branching configurations to decompose the geometry into mapped meshable patches. Each patch is then meshed using one-to-one sweeping techniques. and boundary vertices are projected to the luminal surface. Finally. hexahedral solid NURBS are …,True,dzHYBKcAAAAJ:6ZxmRoH8BuwC,440,https://www.sciencedirect.com/science/article/pii/S0045782507000801,12218734058520444243,/scholar?cites=12218734058520444243,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2839408/,0,0,0
1277810,Patient-specific isogeometric fluid–structure interaction analysis of thoracic aortic blood flow due to implantation of the Jarvik 2000 left ventricular assist device,2009,Y Bazilevs and JR Gohean and TJR Hughes and RD Moser and Y Zhang,198,Computer Methods in Applied Mechanics and Engineering,45-46,3534-3550,North-Holland,Left ventricular assist devices (LVADs) are continuous flow pumps that are employed in patients with severe heart failure. Although their emergence has significantly improved therapeutic options for patients with heart failure. detailed studies of the impact of LVADs on hemodynamics are notably lacking. To this end we initiate a computational study of the Jarvik 2000 LVAD model employing isogeometric fluid–structure interaction analysis. We focus on a patient-specific configuration in which the LVAD is implanted in the descending thoracic aorta. We perform computations for three pump settings and report our observations for several quantities of hemodynamic interest. It should be noted that this paper presents the first three-dimensional. patient-specific fluid–structure interaction simulation of LVADs.,True,dzHYBKcAAAAJ:YOwf2qJgpHMC,419,https://www.sciencedirect.com/science/article/pii/S0045782509001674,14681096646840058471,/scholar?cites=14681096646840058471,,,https://www.oden.utexas.edu/media/reports/2008/0814.pdf,0,0,0
1277811,Immersed finite element method and its applications to biological systems,2006,Wing Kam Liu and Yaling Liu and David Farrell and Lucy Zhang and X Sheldon Wang and Yoshio Fukui and Neelesh Patankar and Yongjie Zhang and Chandrajit Bajaj and Junghoon Lee and Juhee Hong and Xinyu Chen and Huayi Hsu,195,Computer methods in applied mechanics and engineering,13-16,1722-1749,North-Holland,This paper summarizes the newly developed immersed finite element method (IFEM) and its applications to the modeling of biological systems. This work was inspired by the pioneering work of Professor T.J.R. Hughes in solving fluid–structure interaction problems. In IFEM. a Lagrangian solid mesh moves on top of a background Eulerian fluid mesh which spans the entire computational domain. Hence. mesh generation is greatly simplified. Moreover. both fluid and solid domains are modeled with the finite element method and the continuity between the fluid and solid sub-domains is enforced via the interpolation of the velocities and the distribution of the forces with the reproducing Kernel particle method (RKPM) delta function. The proposed method is used to study the fluid–structure interaction problems encountered in human cardiovascular systems. Currently. the heart modeling is being constructed and the …,True,dzHYBKcAAAAJ:hqOjcs7Dif8C,300,https://www.sciencedirect.com/science/article/pii/S004578250500304X,12495808597488742950,/scholar?cites=12495808597488742950,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2830735/,0,0,0
1277812,Adaptive and quality quadrilateral/hexahedral meshing from volumetric data,2006,Yongjie Zhang and Chandrajit Bajaj,195,Computer methods in applied mechanics and engineering,9-12,942-960,North-Holland,This paper describes an algorithm to extract adaptive and quality quadrilateral/hexahedral meshes directly from volumetric data. First. a bottom-up surface topology preserving octree-based algorithm is applied to select a starting octree level. Then the dual contouring method is used to extract a preliminary uniform quad/hex mesh. which is decomposed into finer quads/hexes adaptively without introducing any hanging nodes. The positions of all boundary vertices are recalculated to approximate the boundary surface more accurately. Mesh adaptivity can be controlled by a feature sensitive error function. the regions that users are interested in. or finite element calculation results. Finally. a relaxation based technique is deployed to improve mesh quality. Several demonstration examples are provided from a wide variety of application domains. Some extracted meshes have been extensively used in finite element …,True,dzHYBKcAAAAJ:5nxA0vEk-isC,253,https://www.sciencedirect.com/science/article/pii/S0045782505001374,17004933752007245444,/scholar?cites=17004933752007245444,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2740490/,0,0,0
1277813,Computational vascular fluid–structure interaction: methodology and application to cerebral aneurysms,2010,Y Bazilevs and M-C Hsu and Y Zhang and W Wang and T Kvamsdal and S Hentschel and JG Isaksen,9,Biomechanics and modeling in mechanobiology,4,481-498,Springer-Verlag,A computational vascular fluid–structure interaction framework for the simulation of patient-specific cerebral aneurysm configurations is presented. A new approach for the computation of the blood vessel tissue prestress is also described. Simulations of four patient-specific models are carried out. and quantities of hemodynamic interest such as wall shear stress and wall tension are studied to examine the relevance of fluid–structure interaction modeling when compared to the rigid arterial wall assumption. We demonstrate that flexible wall modeling plays an important role in accurate prediction of patient-specific hemodynamics. Discussion of the clinical relevance of our methods and results is provided.,True,dzHYBKcAAAAJ:M3NEmzRMIkIC,233,https://link.springer.com/article/10.1007/s10237-010-0189-7,4500201782376976961,/scholar?cites=4500201782376976961,,,https://link.springer.com/content/pdf/10.1007/s10237-010-0189-7.pdf,0,0,0
1277814,A fully-coupled fluid-structure interaction simulation of cerebral aneurysms,2010,Yuri Bazilevs and M-C Hsu and Y Zhang and W Wang and X Liang and T Kvamsdal and R Brekken and JG Isaksen,46,Computational Mechanics,1,3-16,Springer-Verlag,This paper presents a computational vascular fluid-structure interaction (FSI) methodology and its application to patient-specific aneurysm models of the middle cerebral artery bifurcation. A fully coupled fluid-structural simulation approach is reviewed. and main aspects of mesh generation in support of patient-specific vascular FSI analyses are presented. Quantities of hemodynamic interest such as wall shear stress and wall tension are studied to examine the relevance of FSI modeling as compared to the rigid arterial wall assumption. We demonstrate the importance of including the flexible wall modeling in vascular blood flow simulations by performing a comparison study that involves four patient-specific models of cerebral aneurysms varying in shape and size.,True,dzHYBKcAAAAJ:maZDTaKrznsC,231,https://link.springer.com/article/10.1007/s00466-009-0421-4,13482072673179865599,/scholar?cites=13482072673179865599,,,https://link.springer.com/content/pdf/10.1007/s00466-009-0421-4.pdf,0,0,0
1277815,3D finite element meshing from imaging data,2005,Yongjie Zhang and Chandrajit Bajaj and Bong-Soo Sohn,194,Computer methods in applied mechanics and engineering,48,5083-5106,North-Holland,This paper describes an algorithm to extract adaptive and quality 3D meshes directly from volumetric imaging data. The extracted tetrahedral and hexahedral meshes are extensively used in the finite element method (FEM). A top-down octree subdivision coupled with a dual contouring method is used to rapidly extract adaptive 3D finite element meshes with correct topology from volumetric imaging data. The edge contraction and smoothing methods are used to improve mesh quality. The main contribution is extending the dual contouring method to crack-free interval volume 3D meshing with boundary feature sensitive adaptation. Compared to other tetrahedral extraction methods from imaging data. our method generates adaptive and quality 3D meshes without introducing any hanging nodes. The algorithm has been successfully applied to constructing quality meshes for finite element calculations.,True,dzHYBKcAAAAJ:0EnyYjriUFMC,213,https://www.sciencedirect.com/science/article/pii/S0045782505000800,13078792942909380308,/scholar?cites=13078792942909380308,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2748876/,0,0,0
1277816,An automatic 3D mesh generation method for domains with multiple materials,2010,Yongjie Zhang and Thomas JR Hughes and Chandrajit L Bajaj,199,Computer methods in applied mechanics and engineering,5,405-415,North-Holland,This paper describes an automatic and efficient approach to construct unstructured tetrahedral and hexahedral meshes for a composite domain made up of heterogeneous materials. The boundaries of these material regions form non-manifold surfaces. In earlier papers. we developed an octree-based isocontouring method to construct unstructured 3D meshes for a single material (homogeneous) domain with manifold boundary. In this paper. we introduce the notion of a material change edge and use it to identify the interface between two or several different materials. A novel method to calculate the minimizer point for a cell shared by more than two materials is provided. which forms a non-manifold node on the boundary. We then mesh all the material regions simultaneously and automatically while conforming to their boundaries directly from volumetric data. Both material change edges and interior edges are …,True,dzHYBKcAAAAJ:NMxIlDl6LWMC,206,https://www.sciencedirect.com/science/article/pii/S004578250900214X,17335386583725032779,/scholar?cites=17335386583725032779,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2805160/,0,0,0
1277817,Determination of wall tension in cerebral artery aneurysms by numerical simulation,2008,Jørgen Gjernes Isaksen and Yuri Bazilevs and Trond Kvamsdal and Yongjie Zhang and Jon H Kaspersen and Knut Waterloo and Bertil Romner and Tor Ingebrigtsen,39,,12,3172-3178,Lippincott Williams & Wilkins,Background and Purpose— Cerebral artery aneurysms rupture when wall tension exceeds the strength of the wall tissue. At present. risk-assessment of unruptured aneurysms does not include evaluation of the lesions shape. yet clinical experience suggests that this is of importance. We aimed to develop a computational model for simulation of fluid-structure interaction in cerebral aneurysms based on patient specific lesion geometry. with special emphasis on wall tension.Methods— An advanced isogeometric fluid-structure analysis model incorporating flexible aneurysm wall based on patient specific computed tomography angiogram images was developed. Variables used in the simulation model were retrieved from a literature review.Results— The simulation results exposed areas of high wall tension and wall displacement located where aneurysms usually rupture.Conclusion— We suggest that …,True,dzHYBKcAAAAJ:9ZlFYXVOiuMC,178,https://www.ahajournals.org/doi/abs/10.1161/STROKEAHA.107.503698,11523922950901588252,/scholar?cites=11523922950901588252,,,https://www.ahajournals.org/doi/full/10.1161/strokeaha.107.503698,0,0,0
1277818,Salt-and-pepper noise removal by median-type noise detectors and detail-preserving regularization,2005,Raymond H Chan and Chung-Wa Ho and Mila Nikolova,14,IEEE Transactions on image processing,10,1479-1485,IEEE,This paper proposes a two-phase scheme for removing salt-and-pepper impulse noise. In the first phase. an adaptive median filter is used to identify pixels which are likely to be contaminated by noise (noise candidates). In the second phase. the image is restored using a specialized regularization method that applies only to those selected noise candidates. In terms of edge preservation and noise suppression. our restored images show a significant improvement compared to those restored by using just nonlinear filters or regularization methods only. Our scheme can remove salt-and-pepper-noise with a noise level as high as 90%.,True,DPG_Dv4AAAAJ:u-x6o8ySG0sC,1310,https://ieeexplore.ieee.org/abstract/document/1510683/,13540232167887041735,/scholar?cites=13540232167887041735,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.7031&rep=rep1&type=pdf,0,0,0
1277819,Algorithms for finding global minimizers of image segmentation and denoising models,2006,Tony F Chan and Selim Esedoglu and Mila Nikolova,66,SIAM journal on applied mathematics,5,1632-1648,Society for Industrial and Applied Mathematics,We show how certain nonconvex optimization problems that arise in image processing and computer vision can be restated as convex minimization problems. This allows. in particular. the finding of global minimizers via standard convex minimization schemes.,True,DPG_Dv4AAAAJ:u5HHmVD_uO8C,1229,https://epubs.siam.org/doi/abs/10.1137/040615286,8026592597604143326,/scholar?cites=8026592597604143326,,,ftp://128.97.4.253/pub/camreport/cam04-54.pdf,0,0,0
1277820,A variational approach to remove outliers and impulse noise,2004,Mila Nikolova,20,Journal of Mathematical Imaging and Vision,1,99-120,Kluwer Academic Publishers,We consider signal and image restoration using convex cost-functions composed of a non-smooth data-fidelity term and a smooth regularization term. We provide a convergent method to minimize such cost-functions. In order to restore data corrupted with outliers and impulsive noise. we focus on cost-functions composed of an ℓ1 data-fidelity term and an edge-preserving regularization term. The analysis of the minimizers of these cost-functions provides a natural justification of the method. It is shown that. because of the ℓ1 data-fidelity. these minimizers involve an implicit detection of outliers. Uncorrupted (regular) data entries are fitted exactly while outliers are replaced by estimates determined by the regularization term. independently of the exact value of the outliers. The resultant method is accurate and stable. as demonstrated by the experiments. A crucial advantage over alternative filtering methods is …,True,DPG_Dv4AAAAJ:d1gkVwhDpl0C,746,https://link.springer.com/article/10.1023/B:JMIV.0000011326.88682.e5,780860593118294084,/scholar?cites=780860593118294084,,,https://www.researchgate.net/profile/Mila_Nikolova/publication/263069716_A_Variational_Approach_to_Remove_Outliers_and_Impulse_Noise/links/02e7e51a3b9b2865a8000000/A-Variational-Approach-to-Remove-Outliers-and-Impulse-Noise.pdf,0,0,0
1277821,Minimizers of cost-functions involving nonsmooth data-fidelity terms. Application to the processing of outliers,2002,Mila Nikolova,40,SIAM Journal on Numerical Analysis,3,965-994,Society for Industrial and Applied Mathematics,We present a theoretical study of the recovery of an unknown vector  (such as a signal or an image) from noisy data  by minimizing with respect to x a regularized cost-function . where  is a data-fidelity term.  is a smooth regularization term. and  is a parameter. Typically. . where A is a linear operator. The data-fidelity terms  involved in regularized cost-functions are generally smooth functions; only a few papers make an exception to this and they consider restricted situations. Nonsmooth data-fidelity terms are avoided in image processing. In spite of this. we consider both smooth and nonsmooth data-fidelity terms. Our goal is to capture essential features exhibited by the local minimizers of regularized cost-functions in relation to the smoothness of the data-fidelity term.In order to fix the context of our study. we consider . where  are the rows of A and  is  on . We show that …,True,DPG_Dv4AAAAJ:9yKSN-GCB0IC,384,https://epubs.siam.org/doi/abs/10.1137/S0036142901389165,5569556270939657748,/scholar?cites=5569556270939657748,,,http://mnikolova.perso.math.cnrs.fr/SiamNA02.pdf,0,0,0
1277822,Analysis of half-quadratic minimization methods for signal and image recovery,2005,Mila Nikolova and Michael K Ng,27,SIAM Journal on Scientific computing,3,937-966,Society for Industrial and Applied Mathematics,We address the minimization of regularized convex cost functions which are customarily used for edge-preserving restoration and reconstruction of signals and images. In order to accelerate computation. the multiplicative and the additive half-quadratic reformulation of the original cost-function have been pioneered in Geman and Reynolds [IEEE Trans. Pattern Anal. Machine Intelligence. 14 (1992). pp. 367--383] and Geman and Yang IEEE Trans. Image Process.. 4 (1995). pp. 932--946]. The alternate minimization of the resultant (augmented) cost-functions has a simple explicit form. The goal of this paper is to provide a systematic analysis of the convergence rate achieved by these methods. For the multiplicative and additive half-quadratic regularizations. we determine their upper bounds for their root-convergence factors. The bound for the multiplicative form is seen to be always smaller than the bound for the …,True,DPG_Dv4AAAAJ:zYLM7Y9cAGgC,376,https://epubs.siam.org/doi/abs/10.1137/030600862,12305794943229031284,/scholar?cites=12305794943229031284,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.330&rep=rep1&type=pdf,0,0,0
1277823,Local strong homogeneity of a regularized estimator,2000,Mila Nikolova,61,SIAM Journal on Applied Mathematics,2,633-658,Society for Industrial and Applied Mathematics,This paper deals with regularized pointwise estimation of discrete signals which contain large strongly homogeneous zones. where typically they are constant. or linear. or more generally satisfy a linear equation. The estimate is defined as the minimizer of an objective function combining a quadratic data-fidelity term and a regularization prior term. The latter term is the sum of the values obtained by applying a potential function (PF) to each component. called a difference. of a linear transform of the signal. Minimizers of functions of this form arise in various settings in statistics and optimization.The features exhibited by such an estimate are closely related to the shape of the PF. Our goal is to determine estimators providing solutions which involve large strongly homogeneous zones--where more precisely the differences are null--in spite of the noise corrupting the data. To this end. we require that the strongly …,True,DPG_Dv4AAAAJ:2osOgNQ5qMEC,298,https://epubs.siam.org/doi/abs/10.1137/S0036139997327794,17626658793341298064,/scholar?cites=17626658793341298064,,,http://mnikolova.disque.math.cnrs.fr/Hom.pdf,0,0,0
1277824,An iterative procedure for removing random-valued impulse noise,2004,Raymond H Chan and Chen Hu and Mila Nikolova,11,IEEE signal processing letters,12,921-924,IEEE,This work proposes a two-stage iterative method for removing random-valued impulse noise. In the first phase. we use the adaptive center-weighted median filter to identify pixels which are likely to be corrupted by noise (noise candidates). In the second phase. these noise candidates are restored using a detail-preserving regularization method which allows edges and noise-free pixels to be preserved. These two phases are applied alternatively. Simulation results indicate that the proposed method is significantly better than those using just nonlinear filters or regularization only.,True,DPG_Dv4AAAAJ:qjMakFHDy7sC,251,https://ieeexplore.ieee.org/abstract/document/1359902/,2340768847668655863,/scholar?cites=2340768847668655863,,,http://mnikolova.perso.math.cnrs.fr/ChanHuNikoSPL04.pdf,0,0,0
1277825,Fast nonconvex nonsmooth minimization methods for image restoration and reconstruction,2010,Mila Nikolova and Michael K Ng and Chi-Pan Tam,19,IEEE Transactions on Image Processing,12,3073-3088,IEEE,Nonconvex nonsmooth regularization has advantages over convex regularization for restoring images with neat edges. However. its practical interest used to be limited by the difficulty of the computational stage which requires a nonconvex nonsmooth minimization. In this paper. we deal with nonconvex nonsmooth minimization methods for image restoration and reconstruction. Our theoretical results show that the solution of the nonconvex nonsmooth minimization problem is composed of constant regions surrounded by closed contours and neat edges. The main goal of this paper is to develop fast minimization algorithms to solve the nonconvex nonsmooth minimization problem. Our experimental results show that the effectiveness and efficiency of the proposed algorithms.,True,DPG_Dv4AAAAJ:Zph67rFs4hoC,237,https://ieeexplore.ieee.org/abstract/document/5483167/,12213977493244638637,/scholar?cites=12213977493244638637,,,http://mnikolova.perso.math.cnrs.fr/fastnonconvexTV.pdf,0,0,0
1277826,Two-phase approach for deblurring images corrupted by impulse plus Gaussian noise,2008,Jian-Feng Cai and Raymond H Chan and Mila Nikolova,2,Inverse Problems & Imaging,2,187,American Institute of Mathematical Sciences,The restoration of blurred images corrupted with impulse noise is a difficult problem which has been considered in a series of recent papers. These papers tackle the problem by using variational methods involving an L1-shaped data-fidelity term. Because of this term. the relevant methods exhibit systematic errors at the corrupted pixel locations and require a cumbersome optimization stage. In this work we propose and justify a much simpler alternative approach which overcomes the above-mentioned systematic errors and leads to much better results. Following a theoretical derivation based on a simple model. we decouple the problem into two phases. First. we identify the outlier candidates—the pixels that are likely to be corrupted by the impulse noise. and we remove them from our data set. In a second phase. the image is deblurred and denoised simultaneously using essentially the outlier-free data. The resultant optimization stage is much simpler in comparison with the current full variational methods and the outlier contamination is more accurately corrected. The experiments show that we obtain a 2 to 6 dB improvement in PSNR. We emphasize that our method can be adapted to deblur images corrupted with mixed impulse plus Gaussian noise. and hence it can address a much wider class of practical problems.1. Introduction. Image deblurring [9] from noisy data is a fundamental problem in image processing. Let the true image x belong to a proper function space S (Ω) on Ω=[0. 1] 2. and the observed digital image y be a matrix in Rm× m indexed by A={1. 2.···. m} 2. Image deblurring usually is modeled by y= Hx+ σn where H: S (Ω)→ Rm× …,True,DPG_Dv4AAAAJ:eQOLeE2rZwMC,192,https://www.aimsciences.org/article/doi/10.3934/ipi.2008.2.187,5942853337403411783,/scholar?cites=5942853337403411783,,,https://www.aimsciences.org/article/exportPdf?id=d5a4b138-a697-45e8-8c6b-d50f6c2decb6,0,0,0
1277827,Efficient minimization methods of mixed l2-l1 and l1-l1 norms for image restoration,2006,Haoying Fu and Michael K Ng and Mila Nikolova and Jesse L Barlow,27,SIAM Journal on Scientific computing,6,1881-1902,Society for Industrial and Applied Mathematics,Image restoration problems are often solved by finding the minimizer of a suitable objective function. Usually this function consists of a data-fitting term and a regularization term. For the least squares solution. both the data-fitting and the regularization terms are in the 2 norm. In this paper. we consider the least absolute deviation (LAD) solution and the least mixed norm (LMN) solution. For the LAD solution. both the data-fitting and the regularization terms are in the 1 norm. For the LMN solution. the regularization term is in the 1 norm but the data-fitting term is in the 2 norm. Since images often have nonnegative intensity values. the proposed algorithms provide the option of taking into account the nonnegativity constraint. The LMN and LAD solutions are formulated as the solution to a linear or quadratic programming problem which is solved by interior point methods. At each iteration of the interior point method. a structured linear …,True,DPG_Dv4AAAAJ:UeHWp8X0CEIC,190,https://epubs.siam.org/doi/abs/10.1137/040615079,15539404960908752335,/scholar?cites=15539404960908752335,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.387&rep=rep1&type=pdf,0,0,0
1277828,Efficient reconstruction of piecewise constant images using nonsmooth nonconvex minimization,2008,Mila Nikolova and Michael K Ng and Shuqin Zhang and Wai-Ki Ching,1,SIAM journal on Imaging Sciences,1,2-25,Society for Industrial and Applied Mathematics,We consider the restoration of piecewise constant images where the number of the regions and their values are not fixed in advance. with a good difference of piecewise constant values between neighboring regions. from noisy data obtained at the output of a linear operator (e.g.. a blurring kernel or a Radon transform). Thus we also address the generic problem of unsupervised segmentation in the context of linear inverse problems. The segmentation and the restoration tasks are solved jointly by minimizing an objective function (an energy) composed of a quadratic data-fidelity term and a nonsmooth nonconvex regularization term. The pertinence of such an energy is ensured by the analytical properties of its minimizers. However. its practical interest used to be limited by the difficulty of the computational stage which requires a nonsmooth nonconvex minimization. Indeed. the existing methods are unsatisfactory since …,True,DPG_Dv4AAAAJ:YsMSGLbcyi4C,178,https://epubs.siam.org/doi/abs/10.1137/070692285,13966883541447569378,/scholar?cites=13966883541447569378,,,https://epubs.siam.org/doi/pdf/10.1137/070692285,0,0,0
1277829,Overview of the face recognition grand challenge,2005,P Jonathon Phillips and Patrick J Flynn and Todd Scruggs and Kevin W Bowyer and Jin Chang and Kevin Hoffman and Joe Marques and Jaesik Min and William Worek,1,,,947-954,IEEE,Over the last couple of years. face recognition researchers have been developing new techniques. These developments are being fueled by advances in computer vision techniques. computer design. sensor design. and interest in fielding face recognition systems. Such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over Face Recognition Vendor Test (FRVT) 2002 results. The face recognition grand challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50.000 images. The data consists of 3D scans and high resolution still imagery taken under controlled and uncontrolled conditions. This paper describes the challenge problem. data corpus. and presents baseline performance and preliminary results on natural statistics of facial imagery.,True,dUSM2-0AAAAJ:mVmsd5A6BfQC,2709,https://ieeexplore.ieee.org/abstract/document/1467368/,2813144765362533273,/scholar?cites=2813144765362533273,,,https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=150264,0,0,0
1277830,A survey of approaches and challenges in 3D and multi-modal 3D+ 2D face recognition,2006,Kevin W Bowyer and Kyong Chang and Patrick Flynn,101,Computer vision and image understanding,1,1-15,Academic Press,This survey focuses on recognition performed by matching models of the three-dimensional shape of the face. either alone or in combination with matching corresponding two-dimensional intensity images. Research trends to date are summarized. and challenges confronting the development of more accurate three-dimensional face recognition are identified. These challenges include the need for better sensors. improved recognition algorithms. and more rigorous experimental methodology.,True,dUSM2-0AAAAJ:u5HHmVD_uO8C,1287,https://www.sciencedirect.com/science/article/pii/S1077314205000822,17930918364390868734,/scholar?cites=17930918364390868734,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1049.162&rep=rep1&type=pdf,0,0,0
1277831,Comparison and combination of ear and face images in appearance-based biometrics,2003,Kyong Chang and Kevin W Bowyer and Sudeep Sarkar and Barnabas Victor,25,IEEE Transactions on pattern analysis and machine intelligence,9,1160-1165,IEEE,Researchers have suggested that the ear may have advantages over the face for biometric recognition. Our previous experiments with ear and face recognition. using the standard principal component analysis approach. showed lower recognition performance using ear images. We report results of similar experiments on larger data sets that are more rigorously controlled for relative quality of face and ear images. We find that recognition performance is not significantly different between the face and the ear. for example. 70.5 percent versus 71.6 percent. respectively. in one experiment. We also find that multimodal recognition using both the ear and face results in statistically significant improvement over either individual biometric. for example. 90.9 percent in the analogous experiment.,True,dUSM2-0AAAAJ:d1gkVwhDpl0C,762,https://ieeexplore.ieee.org/abstract/document/1227990/,6846044794943149320,/scholar?cites=6846044794943149320,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.500&rep=rep1&type=pdf,0,0,0
1277832,An evaluation of multimodal 2D+ 3D face biometrics,2005,Kyong I Chang and Kevin W Bowyer and Patrick J Flynn,27,IEEE transactions on pattern analysis and machine intelligence,4,619-624,IEEE,We report on the largest experimental study to date in multimodal 2D+3D face recognition. involving 198 persons in the gallery and either 198 or 670 time-lapse probe images. PCA-based methods are used separately for each modality and match scores in the separate face spaces are combined for multimodal recognition. Major conclusions are: 1) 2D and 3D have similar recognition performance when considered individually. 2) combining 2D and 3D results using a simple weighting scheme outperforms either 2D or 3D alone. 3) combining results from two or more 2D images using a similar weighting scheme also outperforms a single 2D image. and 4) combined 2D+3D outperforms the multi-image 2D result. This is the first (so far. only) work to present such an experimental control to substantiate multimodal performance improvement.,True,dUSM2-0AAAAJ:u-x6o8ySG0sC,587,https://ieeexplore.ieee.org/abstract/document/1401913/,13351206382751473427,/scholar?cites=13351206382751473427,,,http://www.cse.msu.edu/~rossarun/BiometricsTextBook/Papers/Multibiometrics/ChangBowyerFlynn_MultiEval_PAMI05.pdf,0,0,0
1277833,Multiple nose region matching for 3D face recognition under varying facial expression,2006,Kyong I Chang and Kevin W Bowyer and Patrick J Flynn,28,IEEE Transactions on Pattern Analysis and Machine Intelligence,10,1695-1700,IEEE,An algorithm is proposed for 3D face recognition in the presence of varied facial expressions. It is based on combining the match scores from matching multiple overlapping regions around the nose. Experimental results are presented using the largest database employed to date in 3D face recognition studies. over 4.000 scans of 449 subjects. Results show substantial improvement over matching the shape of a single larger frontal face region. This is the first approach to use multiple overlapping regions around the nose to handle the problem of expression variation,True,dUSM2-0AAAAJ:9yKSN-GCB0IC,472,https://ieeexplore.ieee.org/abstract/document/1677524/,17054052249865222295,/scholar?cites=17054052249865222295,,,,0,0,0
1277834,Face recognition using 2D and 3D facial data,2003,Kyong I Chang and Kevin W Bowyer and Patrick J Flynn,,Workshop in Multidimonal User Authentication pp25-32,,,,Results are presented for the largest experimental study to date that investigates the comparison and combination of 2D and 3D face recognition. To our knowledge. this is also the only such study to incorporate significant time lapse between gallery and probe image acquisition. and to look at the effect of depth resolution. Recognition results are obtained in (1) single gallery and a single probe study. and (2) a single gallery and multiple probe study. A total of 275 subjects participated in one or more data acquisition sessions. Results are presented for gallery and probe datasets of 200 subjects imaged in both 2D and 3D. with one to thirteen weeks time lapse between gallery and probe images of a given subject yielding 951 pairs of 2D and 3D images. Using a PCA-based approach tuned separately for 2D and for 3D. we find that 3D outperforms 2D. However. we also find a multi-modal rank-one recognition rate of 98.5% in a single probe study and 98.8% in multi-probe study. which is statistically significantly greater than either 2D or 3D alone.,True,dUSM2-0AAAAJ:QIV2ME_5wuYC,435,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.697.3724&rep=rep1&type=pdf#page=25,9472307799622071910,/scholar?cites=9472307799622071910,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.697.3724&rep=rep1&type=pdf#page=25,0,0,0
1277835,Does colorspace transformation make any difference on skin detection?,2002,Min C Shin and Kyong I Chang and Leonid V Tsap,,,,275-279,IEEE,Skin detection is an important process in many of computer vision algorithms. It usually is a process that starts at a pixel-level. and that involves a pre-process of colorspace transformation followed by a classification process. A colorspace transformation is assumed to increase separability between skin and non-skin classes. to increase similarity among different skin tones. and to bring a robust performance under varying illumination conditions. without any sound reasonings. In this work. we examine if the colorspace transformation does bring those benefits by measuring four separability measurements on a large dataset of 805 images with different skin tones and illumination. Surprising results indicate that most of the colorspace transformations do not bring the benefits which have been assumed.,True,dUSM2-0AAAAJ:qjMakFHDy7sC,278,https://ieeexplore.ieee.org/abstract/document/1182194/,15313510331187169208,/scholar?cites=15313510331187169208,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.9133&rep=rep1&type=pdf,0,0,0
1277836,A survey of approaches to three-dimensional face recognition,2004,Kevin W Bowyer and Kyong Chang and Patrick Flynn,1,,,358-361,IEEE,The vast majority of face recognition research has focused on the use of two-dimensional intensity images. and is covered in existing survey papers. This survey focuses on face recognition using three-dimensional data. either alone or in combination with two-dimensional intensity images. Challenges involved in developing more accurate three-dimensional face recognition are identified.,True,dUSM2-0AAAAJ:2osOgNQ5qMEC,195,https://ieeexplore.ieee.org/abstract/document/1334126/,16941025101343751503,/scholar?cites=16941025101343751503,,,https://www.academia.edu/download/46677983/A_Survey_Of_Approaches_To_Three-Dimensio20160621-29204-1h1a157.pdf,0,0,0
1277837,Jaesik Min. and William Worek. Overview of the face recognition grand challenge,2005,P Jonathon Phillips and Patrick J Flynn and Todd Scruggs and Kevin W Bowyer and Jin Chang and Kevin Hoffman and Joe Marques,1,CVPR’05: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05),,947-954,,,True,dUSM2-0AAAAJ:ZeXyd9-uunAC,175,http://scholar.google.com/scholar?cluster=9569779033344813256&hl=en&oi=scholarr,9569779033344813256,/scholar?cites=9569779033344813256,,,,0,0,0
1277838,Adaptive rigid multi-region selection for handling expression variation in 3D face recognition,2005,Kyong I Chang and Kevin W Bowyer and Patrick J Flynn,,,,157-157,IEEE,"We present a new algorithm for 3D face recognition. and compare its performance to that of previous approaches. We focus especially on the case of facial expression change between gallery and probe images. We first establish performance comparisons using a PCA (""eigenface"") algorithm and an ICP (iterative closest point) algorithm similar to ones reported in the literature. Experimental results show that the performance of either approach degrades substantially in the case Then we introduce a new algorithm. Adaptive Rigid Multi-region Selection. is introduced to independently matches multiple facial regions and creates a fused result. This algorithm is fully automated and used no manually selected landmark points. Experimental results show that our new algorithm substantially improves performance in the case of varying facial expression. Our experimental results are based on the largest 3D face dataset to …",True,dUSM2-0AAAAJ:UeHWp8X0CEIC,160,https://ieeexplore.ieee.org/abstract/document/1565475/,18227849361607814386,/scholar?cites=18227849361607814386,,,,0,0,0
1277839,Multimodal 2D and 3D biometrics for face recognition,2003,Kyong I Chang and Kevin W Bowyer and Patrick J Flynn,,,,187-194,IEEE,Results are presented for the largest experimental study to date that investigates the comparison and combination of 2D and 3D face data for biometric recognition. To our knowledge. this is also the only such study to incorporate significant time lapse between gallery and probe image acquisition. Recognition results are presented for gallery and probe datasets of 166 subjects imaged in both 2D and 3D. with six to thirteen weeks time lapse between gallery and probe images of a given subject. Using a PCA-based approach tuned separately for 2D and for 3D. we find no statistically significant difference between the rank-one recognition rates of 83.1% for 2D and 83.7% for 3D. Using a certainty-weighted sum-of-distance approach to combining 2D and 3D. we find a multimodal rank-one recognition rate of 92.8%. which is statistically significantly greater than either 2D or 3D alone.,True,dUSM2-0AAAAJ:IjCSPb-OGe4C,144,https://ieeexplore.ieee.org/abstract/document/1240842/,13511072736293140885,/scholar?cites=13511072736293140885,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.475.2323&rep=rep1&type=pdf,0,0,0
1277840,CD-HIT: accelerated for clustering the next-generation sequencing data,2012,Limin Fu and Beifang Niu and Zhengwei Zhu and Sitao Wu and Weizhong Li,28,Bioinformatics,23,3150-3152,Oxford University Press, Summary: CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other sequence analyses. In response to the rapid increase in the amount of sequencing data produced by the next-generation sequencing technologies. we have developed a new CD-HIT program accelerated with a novel parallelization strategy and some other techniques to allow efficient clustering of such datasets. Our tests demonstrated very good speedup derived from the parallelization for up to ∼24 cores and a quasi-linear speedup for up to ∼8 cores. The enhanced CD-HIT is capable of handling very large datasets in much shorter time than previous versions. Availability:           http://cd-hit.org. Contact:           liwz@sdsc.edu          Supplementary information:           Supplementary data are available at Bioinformatics online.,True,3Plo5AYAAAAJ:V3AGJWp-ZtQC,3512,https://academic.oup.com/bioinformatics/article-abstract/28/23/3150/192160,13696469829062093231,/scholar?cites=13696469829062093231,,,https://academic.oup.com/bioinformatics/article/28/23/3150/192160,0,0,0
1277841,LOMETS: a local meta-threading-server for protein structure prediction,2007,Sitao Wu and Yang Zhang,35,Nucleic acids research,10,3375-3382,Oxford University Press,We developed LOMETS. a local threading meta-server. for quick and automated predictions of protein tertiary structures and spatial constraints. Nine state-of-the-art threading programs are installed and run in a local computer cluster. which ensure the quick generation of initial threading alignments compared with traditional remote-server-based meta-servers. Consensus models are generated from the top predictions of the component-threading servers. which are at least 7% more accurate than the best individual servers based on TM-score at a t-test significance level of 0.1%. Moreover. side-chain and C-alpha (Cα) contacts of 42 and 61% accuracy respectively. as well as long- and short-range distant maps. are automatically constructed from the threading alignments. These data can be easily used as constraints to guide the ab initio procedures such as TASSER for further protein tertiary structure modeling …,True,3Plo5AYAAAAJ:O3NaXMp0MMsC,789,https://academic.oup.com/nar/article-abstract/35/10/3375/1100889,7256335933861101100,/scholar?cites=7256335933861101100,,,https://academic.oup.com/nar/article/35/10/3375/1100889,0,0,0
1277842,Ab initio modeling of small proteins by iterative TASSER simulations,2007,Sitao Wu and Jeffrey Skolnick and Yang Zhang,5,BMC biology,1,1-10,BioMed Central,Predicting 3-dimensional protein structures from amino-acid sequences is an important unsolved problem in computational structural biology. The problem becomes relatively easier if close homologous proteins have been solved. as high-resolution models can be built by aligning target sequences to the solved homologous structures. However. for sequences without similar folds in the Protein Data Bank (PDB) library. the models have to be predicted from scratch. Progress in the ab initio structure modeling is slow. The aim of this study was to extend the TASSER (threading/assembly/refinement) method for the ab initio modeling and examine systemically its ability to fold small single-domain proteins. We developed I-TASSER by iteratively implementing the TASSER method. which is used in the folding test of three benchmarks of small proteins. First. data on 16 small proteins (< 90 residues) were used to generate I …,True,3Plo5AYAAAAJ:GnPB-g6toBAC,570,https://link.springer.com/article/10.1186/1741-7007-5-17,11632310246966530671,/scholar?cites=11632310246966530671,,,https://link.springer.com/article/10.1186/1741-7007-5-17,0,0,0
1277843,WebMGA: a customizable web server for fast metagenomic sequence analysis,2011,Sitao Wu and Zhengwei Zhu and Liming Fu and Beifang Niu and Weizhong Li,12,BMC genomics,1,1-9,BioMed Central,The new field of metagenomics studies microorganism communities by culture-independent sequencing. With the advances in next-generation sequencing techniques. researchers are facing tremendous challenges in metagenomic data analysis due to huge quantity and high complexity of sequence data. Analyzing large datasets is extremely time-consuming; also metagenomic annotation involves a wide range of computational tools. which are difficult to be installed and maintained by common users. The tools provided by the few available web servers are also limited and have various constraints such as login requirement. long waiting time. inability to configure pipelines etc. We developed WebMGA. a customizable web server for fast metagenomic analysis. WebMGA includes over 20 commonly used tools such as ORF calling. sequence clustering. quality control of raw reads. removal of sequencing artifacts …,True,3Plo5AYAAAAJ:35N4QoGY0k4C,478,https://link.springer.com/article/10.1186/1471-2164-12-444,6477536281400894883,/scholar?cites=6477536281400894883,,,https://link.springer.com/article/10.1186/1471-2164-12-444,0,0,0
1277844,MUSTER: improving protein sequence profile–profile alignments by using multiple sources of structure information,2008,Sitao Wu and Yang Zhang,72,"Proteins: Structure, Function, and Bioinformatics",2,547-556,Wiley Subscription Services. Inc.. A Wiley Company,We develop a new threading algorithm MUSTER by extending the previous sequence profile–profile alignment method. PPA. It combines various sequence and structure information into single‐body terms which can be conveniently used in dynamic programming search: (1) sequence profiles; (2) secondary structures; (3) structure fragment profiles; (4) solvent accessibility; (5) dihedral torsion angles; (6) hydrophobic scoring matrix. The balance of the weighting parameters is optimized by a grading search based on the average TM‐score of 111 training proteins which shows a better performance than using the conventional optimization methods based on the PROSUP database. The algorithm is tested on 500 nonhomologous proteins independent of the training sets. After removing the homologous templates with a sequence identity to the target >30%. in 224 cases. the first template alignment has the correct …,True,3Plo5AYAAAAJ:ns9cj8rnVeAC,387,https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.21945,14819922785446298867,/scholar?cites=14819922785446298867,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2666101/,0,0,0
1277845,Ultrafast clustering algorithms for metagenomic sequence analysis,2012,Weizhong Li and Limin Fu and Beifang Niu and Sitao Wu and John Wooley,13,Briefings in bioinformatics,6,656-668,Oxford University Press,The rapid advances of high-throughput sequencing technologies dramatically prompted metagenomic studies of microbial communities that exist at various environments. Fundamental questions in metagenomics include the identities. composition and dynamics of microbial populations and their functions and interactions. However. the massive quantity and the comprehensive complexity of these sequence data pose tremendous challenges in data analysis. These challenges include but are not limited to ever-increasing computational demand. biased sequence sampling. sequence errors. sequence artifacts and novel sequences. Sequence clustering methods can directly answer many of the fundamental questions by grouping similar sequences into families. In addition. clustering analysis also addresses the challenges in metagenomics. Thus. a large redundant data set can be represented with a small non …,True,3Plo5AYAAAAJ:l7t_Zn2s7bgC,310,https://academic.oup.com/bib/article-abstract/13/6/656/193286,9837504513011790023,/scholar?cites=9837504513011790023,,,https://academic.oup.com/bib/article/13/6/656/193286,0,0,0
1277846,Induction machine fault detection using SOM-based RBF neural networks,2004,Sitao Wu and Tommy WS Chow,51,IEEE Transactions on Industrial Electronics,1,183-194,IEEE,A radial-basis-function (RBF) neural-network-based fault detection system is developed for performing induction machine fault detection and analysis. Four feature vectors are extracted from power spectra of machine vibration signals. The extracted features are inputs of an RBF-type neural network for fault identification and classification. The optimal network architecture of the RBF network is determined automatically by our proposed cell-splitting grid algorithm. This facilitates the conventional laborious trial-and-error procedure in establishing an optimal architecture. In this paper. the proposed RBF machine fault diagnostic system has been intensively tested with unbalanced electrical faults and mechanical faults operating at different rotating speeds. The proposed system is not only able to detect electrical and mechanical faults. but the system is also able to estimate the extent of faults.,True,3Plo5AYAAAAJ:g5m5HwL7SMYC,190,https://ieeexplore.ieee.org/abstract/document/1265797/,16383494991587224714,/scholar?cites=16383494991587224714,,,,0,0,0
1277847,Clustering of the self-organizing map using a clustering validity index based on inter-cluster and intra-cluster density,2004,Sitao Wu and Tommy WS Chow,37,Pattern Recognition,2,175-188,Pergamon,The self-organizing map (SOM) has been widely used in many industrial applications. Classical clustering methods based on the SOM often fail to deliver satisfactory results. specially when clusters have arbitrary shapes. In this paper. through some preprocessing techniques for filtering out noises and outliers. we propose a new two-level SOM-based clustering algorithm using a clustering validity index based on inter-cluster and intra-cluster density. Experimental results on synthetic and real data sets demonstrate that the proposed clustering algorithm is able to cluster data better than the classical clustering algorithms based on the SOM. and find an optimal number of clusters.,True,3Plo5AYAAAAJ:M05iB0D1s5AC,180,https://www.sciencedirect.com/science/article/pii/S0031320303002371,1878421604104625142,/scholar?cites=1878421604104625142,,,,0,0,0
1277848,A comprehensive assessment of sequence-based and template-based methods for protein contact prediction,2008,Sitao Wu and Yang Zhang,24,Bioinformatics,7,924-931,Oxford University Press, Motivation: Pair-wise residue-residue contacts in proteins can be predicted from both threading templates and sequence-based machine learning. However. most structure modeling approaches only use the template-based contact predictions in guiding the simulations; this is partly because the sequence-based contact predictions are usually considered to be less accurate than that by threading. With the rapid progress in sequence databases and machine-learning techniques. it is necessary to have a detailed and comprehensive assessment of the contact-prediction methods in different template conditions. Results: We develop two methods for protein-contact predictions: SVM-SEQ is a sequence-based machine learning approach which trains a variety of sequence-derived features on contact maps; SVM-LOMETS collects consensus contact predictions from multiple threading templates. We …,True,3Plo5AYAAAAJ:RGFaLdJalmkC,175,https://academic.oup.com/bioinformatics/article-abstract/24/7/924/297720,10821597358166173423,/scholar?cites=10821597358166173423,,,https://academic.oup.com/bioinformatics/article/24/7/924/297720,0,0,0
1277849,De novo variants in neurodevelopmental disorders with epilepsy,2018,Henrike O Heyne and Tarjinder Singh and Hannah Stamberger and Rami Abou Jamra and Hande Caglayan and Dana Craiu and Peter De Jonghe and Renzo Guerrini and Katherine L Helbig and Bobby PC Koeleman and Jack A Kosmicki and Tarja Linnankivi and Patrick May and Hiltrud Muhle and Rikke S Møller and Bernd A Neubauer and Aarno Palotie and Manuela Pendziwiat and Pasquale Striano and Sha Tang and Sitao Wu and Annapurna Poduri and Yvonne G Weber and Sarah Weckhuysen and Sanjay M Sisodiya and Mark J Daly and Ingo Helbig and Dennis Lal and Johannes R Lemke,50,Nature genetics,7,1048-1053,Nature Publishing Group,Epilepsy is a frequent feature of neurodevelopmental disorders (NDDs). but little is known about genetic differences between NDDs with and without epilepsy. We analyzed de novo variants (DNVs) in 6.753 parent–offspring trios ascertained to have different NDDs. In the subset of 1.942 individuals with NDDs with epilepsy. we identified 33 genes with a significant excess of DNVs. of which SNAP25 and GABRB2 had previously only limited evidence of disease association. Joint analysis of all individuals with NDDs also implicated CACNA1E as a novel disease-associated gene. Comparing NDDs with and without epilepsy. we found missense DNVs. DNVs in specific genes. age of recruitment. and severity of intellectual disability to be associated with epilepsy. We further demonstrate the extent to which our results affect current genetic testing as well as treatment. emphasizing the benefit of accurate genetic diagnosis …,True,3Plo5AYAAAAJ:bVQMTfhMCi4C,131,https://www.nature.com/articles/s41588-018-0143-7,14673293106012326008,/scholar?cites=14673293106012326008,,,https://pure.mpg.de/rest/items/item_2617920_3/component/file_2617918/content,0,0,0
1277850,Worm burden-dependent disruption of the porcine colon microbiota by Trichuris suis infection,2012,Sitao Wu and Robert W Li and Weizhong Li and Ethiopia Beshah and Harry D Dawson and Joseph F Urban Jr,7,PloS one,4,e35470,Public Library of Science,Helminth infection in pigs serves as an excellent model for the study of the interaction between human malnutrition and parasitic infection and could have important implications in human health. We had observed that pigs infected with Trichuris suis for 21 days showed significant changes in the proximal colon microbiota. In this study. interactions between worm burden and severity of disruptions to the microbial composition and metabolic potentials in the porcine proximal colon microbiota were investigated using metagenomic tools. Pigs were infected by a single dose of T. suis eggs for 53 days. Among infected pigs. two cohorts were differentiated that either had adult worms or were worm-free. Infection resulted in a significant change in the abundance of approximately 13% of genera detected in the proximal colon microbiota regardless of worm status. suggesting a relatively persistent change over time in the microbiota due to the initial infection. A significant reduction in the abundance of Fibrobacter and Ruminococcus indicated a change in the fibrolytic capacity of the colon microbiota in T. suis infected pigs. In addition. ∼10% of identified KEGG pathways were affected by infection. including ABC transporters. peptidoglycan biosynthesis. and lipopolysaccharide biosynthesis as well as α-linolenic acid metabolism. Trichuris suis infection modulated host immunity to Campylobacter because there was a 3-fold increase in the relative abundance in the colon microbiota of infected pigs with worms compared to naïve controls. but a 3-fold reduction in worm-free infected pigs compared to controls. The level of pathology observed in infected pigs with …,True,3Plo5AYAAAAJ:SP6oXDckpogC,124,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0035470,11013306458063130205,/scholar?cites=11013306458063130205,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0035470,0,0,0
1277851,Optimal Gabor filters for texture segmentation,1995,Dennis Dunn and William E Higgins,4,IEEE Transactions on image processing,7,947-964,IEEE,Texture segmentation involves subdividing an image into differently textured regions. Many texture segmentation schemes are based on a filter-bank model. where the filters. called Gabor filters. are derived from Gabor elementary functions. The goal is to transform texture differences into detectable filter-output discontinuities at texture boundaries. By locating these discontinuities. one can segment the image into differently textured regions. Distinct discontinuities occur. however. only if the Gabor filter parameters are suitably chosen. Some previous analysis has shown how to design filters for discriminating simple textures. Designing filters for more general natural textures. though. has largely been done ad hoc. We have devised a more rigorously based method for designing Gabor filters. It assumes that an image contains two different textures and that prototype samples of the textures are given a priori. We argue …,True,ggm5orgAAAAJ:u5HHmVD_uO8C,692,https://ieeexplore.ieee.org/abstract/document/392336/,11784761638824935770,/scholar?cites=11784761638824935770,,,,0,0,0
1277852,Texture segmentation using 2-D Gabor elementary functions,1994,Dennis Dunn and William E.  Higgins and Joseph Wakeley,16,IEEE Transactions on Pattern Analysis and Machine Intelligence,2,130-149,IEEE,Many texture-segmentation schemes use an elaborate bank of filters to decompose a textured image into a joint space/spatial-frequency representation. Although these schemes show promise. and although some analytical work has been done. the relationship between texture differences and the filter configurations required to distinguish them remain largely unknown. This paper examines the issue of designing individual filters. Using a 2-D texture model. we show analytically that applying a properly configured bandpass filter to a textured image produces distinct output discontinuities at texture boundaries; the analysis is based on Gabor elementary functions. but it is the bandpass nature of the filter that is essential. Depending on the type of texture difference. these discontinuities form one of four characteristic signatures: a step. ridge. valley. or a step change in average local output variation. Accompanying …,True,ggm5orgAAAAJ:u-x6o8ySG0sC,535,https://ieeexplore.ieee.org/abstract/document/273736/,4477926417099947065,/scholar?cites=4477926417099947065,,,https://pdfs.semanticscholar.org/43fb/5db9a456b2526e58afb12f1c09dad49e2421.pdf,0,0,0
1277853,Efficient Gabor filter design for texture segmentation,1996,Thomas P Weldon and William E Higgins and Dennis F Dunn,29,Pattern recognition,12,2005-2015,Pergamon,Gabor filters have been successfully applied to a broad range of image processing tasks. The present paper considers the design of a single filter to segment a two-texture image. A new efficient algorithm for Gabor-filter design is presented. along with methods for estimating filter output statistics. The algorithm draws upon previous results that showed that the output of a Gabor-filtered texture is modeled well by a Rician distribution. A measure of the total output power is used to select the center frequency of the filter and is used to estimate the Rician statistics of the Gabor-filtered image. The method is further generalized to include the statistics of postfiltered outputs that are generated by a Gaussian filtering operation following the Gabor filter. The new method typically requires an order of magnitude less computation to design a filter than a previously proposed method. Experimental results demonstrate the efficacy of …,True,ggm5orgAAAAJ:d1gkVwhDpl0C,419,https://www.sciencedirect.com/science/article/pii/S0031320396000477,11763150565413936187,/scholar?cites=11763150565413936187,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.3950&rep=rep1&type=pdf,0,0,0
1277854,Symmetric region growing,2003,S-Y Wan and William E Higgins,12,IEEE Transactions on Image processing,9,1007-1015,IEEE,Of the many proposed image segmentation methods. region growing has been one of the most popular. Research on region growing. however. has focused primarily on the design of feature measures and on growing and merging criteria. Most of these methods have an inherent dependence on the order in which the points and regions are examined. This weakness implies that a desired segmented result is sensitive to the selection of the initial growing points. We define a set of theoretical criteria for a subclass of region-growing algorithms that are insensitive to the selection of the initial growing points. This class of algorithms. referred to as symmetric region growing algorithms. leads to a single-pass region-growing algorithm applicable to any dimensionality of images. Furthermore. they lead to region-growing algorithms that are both memory- and computation-efficient. Results illustrate the method's efficiency and …,True,ggm5orgAAAAJ:2osOgNQ5qMEC,277,https://ieeexplore.ieee.org/abstract/document/1221755/,6068024711156894279,/scholar?cites=6068024711156894279,,,https://pdfs.semanticscholar.org/a118/7d3d47e79559480bef47624bdcbf54213c2f.pdf,0,0,0
1277855,Three-dimensional human airway segmentation methods for clinical virtual bronchoscopy,2002,Atilla P Kiraly and William E Higgins and Geoffrey McLennan and Eric A Hoffman and Joseph M Reinhardt,9,Academic radiology,10,1153-1168,Elsevier,The segmentation of airways from CT images is a critical first step for numerous virtual bronchoscopic (VB) applications. Automatic or semiautomatic methods are necessary. since manual segmentation is prohibitively time consuming. The methods must be robust and operate within a reasonable time frame to be useful for clinical VB use. The authors developed an integrated airway segmentation system and demonstrated its effectiveness on a series of human images.The authors' airway segmentation system draws on two segmentation algorithms: (a) an adaptive region-growing algorithm and (b) a new hybrid algorithm that uses both region growing and mathematical morphology. Images from an ongoing VB study were segmented by means of both the adaptive region-growing and the new hybrid methods. The segmentation volume. branch number estimate. and …,True,ggm5orgAAAAJ:qjMakFHDy7sC,228,https://www.sciencedirect.com/science/article/pii/S1076633203805172,14911746427894904252,/scholar?cites=14911746427894904252,,,https://core.ac.uk/download/pdf/207954697.pdf,0,0,0
1277856,Virtual bronchoscopy for three--dimensional pulmonary image assessment: state of the art and future needs.,1998,William E Higgins and Krisnan Ramaswamy and Roderick D Swift and Geoffrey McLennan and Eric A Hoffman,18,,3,761-778,,Virtual bronchoscopy is emerging as a useful approach for assessment of three-dimensional (3D) computed tomographic (CT) pulmonary images. A protocol for virtual bronchoscopic assessment of a 3D CT pulmonary image would have two main stages: (a) preprocessing of image data. which involves extracting objects of interest. defining paths through major airways. and preparing the extracted objects for 3D rendering; and (b) interactive image assessment. which involves use of graphics-based software tools such as surface-rendered views. projection images. virtual endoscopic views. tube views. oblique section images. measurement data. global two-dimensional section images. and cross-sectional views. Although a virtual bronchoscope offers a unique opportunity for exploration and quantitation. it cannot replace a real bronchoscope. Limitations of current virtual endoscopy systems include high cost. lack of …,True,ggm5orgAAAAJ:9yKSN-GCB0IC,213,https://pubs.rsna.org/doi/abs/10.1148/radiographics.18.3.9599397,5951799306815756795,/scholar?cites=5951799306815756795,,,https://pubs.rsna.org/doi/pdf/10.1148/radiographics.18.3.9599397,0,0,0
1277857,Method and apparatus for continuous guidance of endoscopy,2014,William E Higgins and Scott A Merritt and Lav Rai and Jason D Gibbs and Kun-Chang Yu,,,,,,Methods and apparatus provide continuous guidance of endoscopy during a live procedure. A data-set based on 3D image data is pre-computed including reference information representative of a predefined route through a body organ to a final destination. A plurality of live real endoscopic (RE) images are displayed as an operator maneuvers an endoscope within the body organ. A registration and tracking algorithm registers the data-set to one or more of the RE images and continuously maintains the registration as the endoscope is locally maneuvered. Additional information related to the final destination is then presented enabling the endoscope operator to decide on a final maneuver for the procedure. The reference information may include 3D organ surfaces. 3D routes through an organ system. or 3D regions of interest (ROIs). as well as a virtual endoscopic (VE) image generated from the precomputed data …,True,ggm5orgAAAAJ:1yQoGdGgb4wC,190,https://patents.google.com/patent/US8672836B2/en,1053640144907737220,/scholar?cites=1053640144907737220,,,https://patentimages.storage.googleapis.com/98/3b/fc/73503c8f66b01d/US8672836.pdf,0,0,0
1277858,Three-dimensional path planning for virtual bronchoscopy,2004,Atilla P Kiraly and James P Helferty and Eric A Hoffman and Geoffrey McLennan and William E Higgins,23,IEEE Transactions on Medical Imaging,11,1365-1379,IEEE,Multidetector computed-tomography (MDCT) scanners provide large high-resolution three-dimensional (3-D) images of the chest. MDCT scanning. when used in tandem with bronchoscopy. provides a state-of-the-art approach for lung-cancer assessment. We have been building and validating a lung-cancer assessment system. which enables virtual-bronchoscopic 3-D MDCT image analysis and follow-on image-guided bronchoscopy. A suitable path planning method is needed. however. for using this system. We describe a rapid. robust method for computing a set of 3-D airway-tree paths from MDCT images. The method first defines the skeleton of a given segmented 3-D chest image and then performs a multistage refinement of the skeleton to arrive at a final tree structure. The tree consists of a series of paths and branch structural data. suitable for quantitative airway analysis and smooth virtual navigation. A …,True,ggm5orgAAAAJ:zYLM7Y9cAGgC,164,https://ieeexplore.ieee.org/abstract/document/1350895/,11346890199119172868,/scholar?cites=11346890199119172868,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.661.4028&rep=rep1&type=pdf,0,0,0
1277859,Videoendoscopic distortion correction and its application to virtual guidance of endoscopy,2001,James P Helferty and Chao Zhang and Geoffrey McLennan and William E Higgins,20,IEEE transactions on medical imaging,7,605-617,IEEE,Modern video based endoscopes offer physicians a wide-angle field of view (FOV) for minimally invasive procedures. Unfortunately. inherent barrel distortion prevents accurate perception of range. This makes measurement and distance judgment difficult and causes difficulties in emerging applications. such as virtual guidance of endoscopic procedures. Such distortion also arises in other wide FOV camera circumstances. This paper presents a distortion correction technique that can automatically calculate correction parameters. without precise knowledge of horizontal and vertical orientation. The method is applicable to any camera-distortion correction situation. Based on a least-squares estimation. the authors' proposed algorithm considers line fits in both FOV directions and gives a globally consistent set of expansion coefficients and an optimal image center. The method is insensitive to the initial orientation of …,True,ggm5orgAAAAJ:UeHWp8X0CEIC,150,https://ieeexplore.ieee.org/abstract/document/932745/,11817393710674238234,/scholar?cites=11817393710674238234,,,,0,0,0
1277860,Gabor filter design for multiple texture segmentation,1996,Thomas P Weldon and William E Higgins and Dennis F Dunn,35,Optical Engineering,10,2852-2863,International Society for Optics and Photonics,A method is presented for the design of a single Gabor filter for the segmentation of multitextured images. Earlier methods were limited to filters designed for one or two textures or to filters selected from a predetermined filter bank. Our proposed method yields new insight into the design of Gabor filters for segmenting multitextured images and lays an essential foundation for the design of multiple Gabor filters. In the method. Rician statistics of filtered textures at two different Gabor-filter envelope scales are used to efficiently generate probability density estimates for each filtered texture over an extensive set of candidate filter parameters. Variable degrees of postfiltering and the accompanying effect on postfilter output statistics are also included in the design procedure. The result is a unified framework that analytically relates the texture power spectra. Gabor-filter parameters. postfiltering effects. and image …,True,ggm5orgAAAAJ:IjCSPb-OGe4C,146,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-35/issue-10/0000/Gabor-filter-design-for-multiple-texture-segmentation/10.1117/1.600971.short,3513915658104789562,/scholar?cites=3513915658104789562,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.27.21&rep=rep1&type=pdf,0,0,0
1277861,Fast 3D-2D image registration method with application to continuously guided endoscopy,2011,William E Higgins and Scott A Merritt and Lav Rai,,,,,,A novel framework for fast and continuous registration between two imaging modalities is disclosed. The approach makes it possible to completely determine the rigid transformation between multiple sources at real-time or near real-time frame-rates in order to localize the cameras and register the two sources. A disclosed example includes computing or capturing a set of reference images within a known environment. complete with corresponding depth maps and image gradients. The collection of these images and depth maps constitutes the reference source. The second source is a real-time or near-real time source which may include a live video feed. Given one frame from this video feed. and starting from an initial guess of viewpoint. the real-time video frame is warped to the nearest viewing site of the reference source. An image difference is computed between the warped video frame and the reference image …,True,ggm5orgAAAAJ:eJXPG6dFmWUC,145,https://patents.google.com/patent/US7889905B2/en,469637223361642399,/scholar?cites=469637223361642399,,,https://patentimages.storage.googleapis.com/pdfs/US7889905.pdf,0,0,0
1277862,Recent advances in visual and infrared face recognition—a review,2005,Seong G Kong and Jingu Heo and Besma R Abidi and Joonki Paik and Mongi A Abidi,97,,1,103-135,Academic Press,Face recognition is a rapidly growing research area due to increasing demands for security in commercial and law enforcement applications. This paper provides an up-to-date review of research efforts in face recognition techniques based on two-dimensional (2D) images in the visual and infrared (IR) spectra. Face recognition systems based on visual images have reached a significant level of maturity with some practical success. However. the performance of visual face recognition may degrade under poor illumination conditions or for subjects of various skin colors. IR imagery represents a viable alternative to visible imaging in the search for a robust and practical identification system. While visual face recognition systems perform relatively reliably under controlled illumination conditions. thermal IR face recognition systems are advantageous when there is no control over illumination or for detecting disguised …,True,PQtd7-UAAAAJ:u5HHmVD_uO8C,736,https://www.sciencedirect.com/science/article/pii/S1077314204000451,14155954080425415029,/scholar?cites=14155954080425415029,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.535.6616&rep=rep1&type=pdf,0,0,0
1277863,Contrast enhancement system using spatially adaptive histogram equalization with temporal filtering,1998,Tae Keun Kim and Joon Ki Paik and Bong Soon Kang,44,IEEE Transactions on Consumer Electronics,1,82-87,IEEE,In this paper we propose a block-overlapped histogram equalization system for enhancing contrast of image sequences. The proposed system has various applications such as video door phone. security video cameras. in addition to the original target video camcorders.,True,PQtd7-UAAAAJ:d1gkVwhDpl0C,500,https://ieeexplore.ieee.org/abstract/document/663733/,6692157953650110299,/scholar?cites=6692157953650110299,,,https://www.researchgate.net/profile/Joonki_Paik/publication/3179871_Contrast_enhancement_system_using_spatially_adaptive_histogram_equalization_with_temporal_filtering/links/552fada30cf2acd38cbc4eae.pdf,0,0,0
1277864,Image restoration using a modified Hopfield network,1992,Joon Ki Paik and Aggelos K Katsaggelos,1,IEEE Transactions on image processing,1,49-63,IEEE,A modified Hopfield neural network model for regularized image restoration is presented. The proposed network allows negative autoconnections for each neuron. A set of algorithms using the proposed neural network model is presented. with various updating modes: sequential updates; n-simultaneous updates; and partially asynchronous updates. The sequential algorithm is shown to converge to a local minimum of the energy function after a finite number of iterations. Since an algorithm which updates all n neurons simultaneously is not guaranteed to converge. a modified algorithm is presented. which is called a greedy algorithm. Although the greedy algorithm is not guaranteed to converge to a local minimum. the l/sub 1/ norm of the residual at a fixed point is bounded. A partially asynchronous algorithm is presented. which allows a neuron to have a bounded time delay to communicate with other neurons …,True,PQtd7-UAAAAJ:u-x6o8ySG0sC,307,https://ieeexplore.ieee.org/abstract/document/128030/,9092540402283485569,/scholar?cites=9092540402283485569,,,,0,0,0
1277865,Adaptive contrast enhancement using gain-controllable clipped histogram equalization,2008,Taekyung Kim and Joonki Paik,54,IEEE Transactions on Consumer Electronics,4,1803-1810,IEEE,Histogram equalization is a simple and effective method for contrast enhancement as it can automatically define the intensity transformation function based on statistical characteristics of the image. However. it tends to alter the brightness of the entire image. which it is not suitable for consumer electronic products. where preservation of the original brightness is essential to avoid annoying artifacts. This paper presents a new contrast enhancement method for generalization of the existing bihistogram equalization (BHE) and recursive mean-separate histogram equalization (RMSHE) methods. The proposed method is referred to gain-controllable clipped histogram equalization (GC-CHE) to provide both histogram equalization and brightness preservation. More specifically adaptive contrast enhancement is realized by using clipped histogram equalization with controllable gain. The clipping rate is determined based …,True,PQtd7-UAAAAJ:KlAtU1dfN6UC,212,https://ieeexplore.ieee.org/abstract/document/4711238/,12560975413684609827,/scholar?cites=12560975413684609827,,,https://www.researchgate.net/profile/Joonki_Paik/publication/224358780_Adaptive_Contrast_Enhancement_Using_Gain-Controllable_Clipped_Histogram_Equalization/links/5566ab9c08aeccd77735a5e2.pdf,0,0,0
1277866,An adaptive motion decision system for digital image stabilizer based on edge pattern matching,1992,Joon ki Paik and Yong Chul Park and Dong Wook Kim,38,IEEE Transactions on Consumer Electronics,3,607-616,IEEE,The effects of various environmental conditions which degrade the performance of a digital image stabilization (DIS) system in a video camera are analyzed. On the basis of the analysis. a new DIS system with an adaptive motion decision system is proposed. The DIS system is composed of (i) a local motion vector generation unit. (ii) a field motion vector generation unit. (iii) an accumulated motion vector generation unit. and (iv) field memory address control and a digital zooming unit.< >,True,PQtd7-UAAAAJ:L1USKYWJimsC,207,https://ieeexplore.ieee.org/abstract/document/156744/,7747884591876410576,/scholar?cites=7747884591876410576,,,https://www.researchgate.net/profile/Joonki_Paik/publication/3562850_An_Adaptive_Motion_Decision_System_For_Digital_Image_Stabilizer_Based_On_Edge_Pattern_Matching/links/57ede79008ae711da939a1f0/An-Adaptive-Motion-Decision-System-For-Digital-Image-Stabilizer-Based-On-Edge-Pattern-Matching.pdf,0,0,0
1277867,Normal vector voting: crease detection and curvature estimation on large. noisy meshes,2002,David L Page and Yiyong Sun and Andreas F Koschan and Joonki Paik and Mongi A Abidi,64,Graphical models,3-4,199-229,Academic Press,This paper describes a robust method for crease detection and curvature estimation on large. noisy triangle meshes. We assume that these meshes are approximations of piecewise-smooth surfaces derived from range or medical imaging systems and thus may exhibit measurement or even registration noise. The proposed algorithm. which we call normal vector voting. uses an ensemble of triangles in the geodesic neighborhood of a vertex—instead of its simple umbrella neighborhood—to estimate the orientation and curvature of the original surface at that point. With the orientation information. we designate a vertex as either lying on a smooth surface. following a crease discontinuity. or having no preferred orientation. For vertices on a smooth surface. the curvature estimation yields both principal curvatures and principal directions while for vertices on a discontinuity we estimate only the curvature along the crease …,True,PQtd7-UAAAAJ:2osOgNQ5qMEC,195,https://www.sciencedirect.com/science/article/pii/S1524070302905746,5066754629681746359,/scholar?cites=5066754629681746359,,,https://imaging.utk.edu/publications/papers/2002/page_gm02.pdf,0,0,0
1277868,Real-time video tracking using PTZ cameras,2003,Sangkyu Kang and Joon-Ki Paik and Andreas Koschan and Besma R Abidi and Mongi A Abidi,5132,,,103-111,International Society for Optics and Photonics,Automatic tracking is essential for a 24 hours intruder-detection and. more generally. a surveillance system. This paper presents an adaptive background generation and the corresponding moving region detection techniques for a Pan-Tilt-Zoom (PTZ) camera using a geometric transform-based mosaicing method. A complete system including adaptive background generation. moving regions extraction and tracking is evaluated using realistic experimental results. More specifically. experimental results include generated background images. a moving region. and input video with bounding boxes around moving objects. This experiment shows that the proposed system can be used to monitor moving targets in widely open areas by automatic panning and tilting in real-time.,True,PQtd7-UAAAAJ:eQOLeE2rZwMC,156,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5132/0000/Real-time-video-tracking-using-PTZ-cameras/10.1117/12.514945.short,2517209200441330176,/scholar?cites=2517209200441330176,,,https://www.researchgate.net/profile/Sangkyu_Kang/publication/228598087_Real-time_video_tracking_using_PTZ_cameras/links/0c96052085dbbac714000000.pdf,0,0,0
1277869,Adaptive mode decision for H. 264 encoder,2004,Y-H Kim and J-W Yoo and S-W Lee and J Shin and J Paik and H-K Jung,40,Electronics letters,19,1172-1173,IET Digital Library,An adaptive mode decision algorithm is presented. with rate-distortion optimisation that reduces complexity of the H.264 encoder without loss of image quality and compression ratio. The proposed algorithm uses the property of an all-zero coefficients block that is produced by quantisation and coefficient thresholding to effectively skip unnecessary modes. Experimental results show that the speed of the adaptive mode decision algorithm is two times faster than the full-mode decision algorithm of the JM72 reference encoder. without any coding loss.,True,PQtd7-UAAAAJ:9yKSN-GCB0IC,149,https://digital-library.theiet.org/content/journals/10.1049/el_20046155,3399122448435291188,/scholar?cites=3399122448435291188,,,,0,0,0
1277870,Optical flow-based real-time object tracking using non-prior training active feature model,2005,Jeongho Shin and Sangjin Kim and Sangkyu Kang and Seong-Won Lee and Joonki Paik and Besma Abidi and Mongi Abidi,11,Real-Time Imaging,3,204-218,Academic Press,This paper presents a feature-based object tracking algorithm using optical flow under the non-prior training (NPT) active feature model (AFM) framework. The proposed tracking procedure can be divided into three steps: (i) localization of an object-of-interest. (ii) prediction and correction of the object's position by utilizing spatio-temporal information. and (iii) restoration of occlusion using NPT-AFM. The proposed algorithm can track both rigid and deformable objects. and is robust against the object's sudden motion because both a feature point and the corresponding motion direction are tracked at the same time. Tracking performance is not degraded even with complicated background because feature points inside an object are completely separated from background. Finally. the AFM enables stable tracking of occluded objects with maximum 60% occlusion. NPT-AFM. which is one of the major contributions of this …,True,PQtd7-UAAAAJ:Se3iqnhoufwC,118,https://www.sciencedirect.com/science/article/pii/S1077201405000215,1329920123432634894,/scholar?cites=1329920123432634894,,,https://www.academia.edu/download/50046077/Optical_flow-based_real-time_object_trac20161101-1706-16f2i09.pdf,0,0,0
1277871,Simple and efficient algorithm for part decomposition of 3-D triangulated models based on curvature analysis,2002,Yan Zhang and J Paik and Andreas Koschan and Mongi A Abidi and David Gorsich,3,,,III-III,IEEE,This paper presents a simple and efficient algorithm for part decomposition of compound objects based on Gaussian curvature analysis. The proposed algorithm consists of three major steps. Gaussian curvature estimation. boundary detection. and region growing. Boundaries between two articulated parts are composed of points with highly negative curvature based on the transversality regularity. These boundaries are therefore detected by thresholding estimated Gaussian curvatures for each vertex. A component labeling operation is then performed to grow non-boundary vertices into parts. The original contributions of this paper include: (i) novel. curvature analysis-based decomposition of 3-D models represented by triangle meshes into functional parts instead of surfaces and (ii) large mesh (over 100.000 triangles) handling capability with low computational cost and easy implementation. Experiments were …,True,PQtd7-UAAAAJ:Y0pCki6q_DkC,118,https://ieeexplore.ieee.org/abstract/document/1038958/,10290792390906679966,/scholar?cites=10290792390906679966,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.6660&rep=rep1&type=pdf,0,0,0
1277872,Image interpolation using adaptive fast B-spline filtering,1993,Seong-Won Lee and Joon Ki Paik,5,,,177-180,IEEE,An adaptive version of a B-spline interpolation algorithm is proposed. Adaptivity is used in two different phases: (1) adaptive zero order interpolation is realized by considering directional edge information. and (2) adaptive length of the moving average filter in four directions is obtained by computing the local image statistics. The proposed algorithm exhibits significant improvements in image quality compared with the conventional B-spline type for algorithm. especially with high magnification ratio. such as four times or more. Another advantage of the proposed algorithm is its simplicity in both computation and implementations.< >,True,PQtd7-UAAAAJ:qjMakFHDy7sC,116,https://ieeexplore.ieee.org/abstract/document/319776/,2750100782796556414,/scholar?cites=2750100782796556414,,,https://www.researchgate.net/profile/Joonki_Paik/publication/3568086_Image_Interpolation_Using_Adaptive_Fast_B-Spline_Filtering/links/5833958908aef19cb81cb509/Image-Interpolation-Using-Adaptive-Fast-B-Spline-Filtering.pdf,0,0,0
1277873,No-reference image quality assessment in the spatial domain,2012,Anish Mittal and Anush Krishna Moorthy and Alan Conrad Bovik,21,IEEE Transactions on image processing,12,4695-4708,IEEE,We propose a natural scene statistic-based distortion-generic blind/no-reference (NR) image quality assessment (IQA) model that operates in the spatial domain. The new model. dubbed blind/referenceless image spatial quality evaluator (BRISQUE) does not compute distortion-specific features. such as ringing. blur. or blocking. but instead uses scene statistics of locally normalized luminance coefficients to quantify possible losses of “naturalness” in the image due to the presence of distortions. thereby leading to a holistic measure of quality. The underlying features used derive from the empirical distribution of locally normalized luminances and products of locally normalized luminances under a spatial natural scene statistic model. No transformation to another coordinate frame (DCT. wavelet. etc.) is required. distinguishing it from prior NR IQA approaches. Despite its simplicity. we are able to show that BRISQUE is …,True,t9eduncAAAAJ:aqlVkmm33-oC,2510,https://ieeexplore.ieee.org/abstract/document/6272356/,12642184776710443583,/scholar?cites=12642184776710443583,,,http://www.live.ece.utexas.edu/publications/2012/TIP%20BRISQUE.pdf,0,0,0
1277874,Blind image quality assessment: From natural scene statistics to perceptual quality,2011,Anush Krishna Moorthy and Alan Conrad Bovik,20,IEEE transactions on Image Processing,12,3350-3364,IEEE,Our approach to blind image quality assessment (IQA) is based on the hypothesis that natural scenes possess certain statistical properties which are altered in the presence of distortion. rendering them un-natural; and that by characterizing this un-naturalness using scene statistics. one can identify the distortion afflicting the image and perform no-reference (NR) IQA. Based on this theory. we propose an (NR)/blind algorithm-the Distortion Identification-based Image Verity and INtegrity Evaluation (DIIVINE) index-that assesses the quality of a distorted image without need for a reference image. DIIVINE is based on a 2-stage framework involving distortion identification followed by distortion-specific quality assessment. DIIVINE is capable of assessing the quality of a distorted image across multiple distortion categories. as against most NR IQA algorithms that are distortion-specific in nature. DIIVINE is based on natural …,True,t9eduncAAAAJ:Tyk-4Ss8FVUC,1340,https://ieeexplore.ieee.org/abstract/document/5756237/,11404624556505864955,/scholar?cites=11404624556505864955,,,https://www.imaging.utk.edu/research/wcho/references/2011%20TIP%20BLINDS2.pdf,0,0,0
1277875,A two-step framework for constructing blind image quality indices,2010,Anush Krishna Moorthy and Alan Conrad Bovik,17,IEEE Signal processing letters,5,513-516,IEEE,Present day no-reference/no-reference image quality assessment (NR IQA) algorithms usually assume that the distortion affecting the image is known. This is a limiting assumption for practical applications. since in a majority of cases the distortions in the image are unknown. We propose a new two-step framework for no-reference image quality assessment based on natural scene statistics (NSS). Once trained. the framework does not require any knowledge of the distorting process and the framework is modular in that it can be extended to any number of distortions. We describe the framework for blind image quality assessment and a version of this framework-the blind image quality index (BIQI) is evaluated on the LIVE image quality assessment database. A software release of BIQI has been made available online: http://live.ece.utexas.edu/research/quality/BIQI_release.zip.,True,t9eduncAAAAJ:u-x6o8ySG0sC,1028,https://ieeexplore.ieee.org/abstract/document/5432998/,5779172003841051489,/scholar?cites=5779172003841051489,,,http://www.live.ece.utexas.edu/publications/2010/akm_spl_may10.pdf,0,0,0
1277876,Visual importance pooling for image quality assessment,2009,Anush Krishna Moorthy and Alan Conrad Bovik,3,IEEE journal of selected topics in signal processing,2,193-201,IEEE,Recent image quality assessment (IQA) metrics achieve high correlation with human perception of image quality. Naturally. it is of interest to produce even better results. One promising method is to weight image quality measurements by visual importance. To this end. we describe two strategies-visual fixation-based weighting. and quality-based weighting. By contrast with some prior studies we find that these strategies can improve the correlations with subjective judgment significantly. We demonstrate improvements on the SSIM index in both its multiscale and single-scale versions. using the LIVE database as a test-bed.,True,t9eduncAAAAJ:u5HHmVD_uO8C,370,https://ieeexplore.ieee.org/abstract/document/4799310/,8951750861276670763,/scholar?cites=8951750861276670763,,,https://live.ece.utexas.edu/publications/2009/akm_jstsp_april09.pdf,0,0,0
1277877,Video quality assessment on mobile devices: Subjective. behavioral and objective studies,2012,Anush Krishna Moorthy and Lark Kwon Choi and Alan Conrad Bovik and Gustavo De Veciana,6,IEEE Journal of Selected Topics in Signal Processing,6,652-671,IEEE,We introduce a new video quality database that models video distortions in heavily-trafficked wireless networks and that contains measurements of human subjective impressions of the quality of videos. The new LIVE Mobile Video Quality Assessment (VQA) database consists of 200 distorted videos created from 10 RAW HD reference videos. obtained using a RED ONE digital cinematographic camera. While the LIVE Mobile VQA database includes distortions that have been previously studied such as compression and wireless packet-loss. it also incorporates dynamically varying distortions that change as a function of time. such as frame-freezes and temporally varying compression rates. In this article. we describe the construction of the database and detail the human study that was performed on mobile phones and tablets in order to gauge the human perception of quality on mobile devices. The subjective study …,True,t9eduncAAAAJ:4TOpqqG69KYC,290,https://ieeexplore.ieee.org/abstract/document/6263265/,17174501610822624338,/scholar?cites=17174501610822624338,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.666&rep=rep1&type=pdf,0,0,0
1277878,Subjective evaluation of stereoscopic image quality,2013,Anush Krishna Moorthy and Che-Chun Su and Anish Mittal and Alan Conrad Bovik,28,Signal Processing: Image Communication,8,870-883,Elsevier,Stereoscopic/3D image and video quality assessment (IQA/VQA) has become increasing relevant in today's world. owing to the amount of attention that has recently been focused on 3D/stereoscopic cinema. television. gaming. and mobile video. Understanding the quality of experience of human viewers as they watch 3D videos is a complex and multi-disciplinary problem. Toward this end we offer a holistic assessment of the issues that are encountered. survey the progress that has been made towards addressing these issues. discuss ongoing efforts to resolve them. and point up the future challenges that need to be focused on. Important tools in the study of the quality of 3D visual signals are databases of 3D image and video sets. distorted versions of these signals and the results of large-scale studies of human opinions of their quality. We explain the construction of one such tool. the LIVE 3D IQA database …,True,t9eduncAAAAJ:mVmsd5A6BfQC,280,https://www.sciencedirect.com/science/article/pii/S0923596512001658,12644367088154133683,/scholar?cites=12644367088154133683,,,http://live.ece.utexas.edu/publications/2013/Subjective%20Evaluation%20of%20Stereoscopic%20Image%20Quality.pdf,0,0,0
1277879,Objective quality assessment of multiply distorted images,2012,Dinesh Jayaraman and Anish Mittal and Anush K Moorthy and Alan C Bovik,,,,1693-1697,IEEE,Subjective studies have been conducted in the past to obtain human judgments of visual quality on distorted images in order. among other things. to benchmark objective image quality assessment (IQA) algorithms. Existing subjective studies primarily have records of human ratings on images that were corrupted by only one of many possible distortions. However. the majority of images that are available for consumption are corrupted by multiple distortions. Towards broadening the corpora of records of human responses to visual distortions. we recently conducted a study on two types of multiply distorted images to obtain human judgments of the visual quality of such images. Further. we compared the performance of several existing objective image quality measures on the new database and analyze the effects of multiple distortions on commonly used quality-determinant features and on human ratings.,True,t9eduncAAAAJ:7PzlFSSx8tAC,250,https://ieeexplore.ieee.org/abstract/document/6489321/,4595987538046066385,/scholar?cites=4595987538046066385,,,https://www.seas.upenn.edu/~dineshj/publication/jayaraman-2012-objective/jayaraman-2012-objective.pdf,0,0,0
1277880,Toward a practical perceptual video quality metric,2016,Zhi Li and Anne Aaron and Ioannis Katsavounidis and Anush Moorthy and Megha Manohara,6,The Netflix Tech Blog,2,,,,True,t9eduncAAAAJ:ldfaerwXgEUC,230,http://scholar.google.com/scholar?cluster=13264855543837304707&hl=en&oi=scholarr,13264855543837304707,/scholar?cites=13264855543837304707,,,,0,0,0
1277881,Blind/referenceless image spatial quality evaluator,2011,Anish Mittal and Anush K Moorthy and Alan C Bovik,,,,723-727,IEEE,We propose a natural scene statistic based Blind/Referenceless Image Spatial QUality Evaluator (BRISQUE) which extracts the point wise statistics of local normalized luminance signals and measures image naturalness (or lack there of) based on measured deviations from a natural image model. We also model the distribution of pairwise statistics of adjacent normalized luminance signals which provides distortion orientation information. Although multi scale. the model uses easy to compute features making it computationally fast and time efficient. The frame work is shown to perform statistically better than other proposed no reference algorithms and full reference structural similarity index (SSIM).,True,t9eduncAAAAJ:YOwf2qJgpHMC,171,https://ieeexplore.ieee.org/abstract/document/6190099/,13294556098749815548,/scholar?cites=13294556098749815548,,,http://www.live.ece.utexas.edu/publications/2011/am_asilomar_2011.pdf,0,0,0
1277882,Wireless video quality assessment: A study of subjective scores and objective algorithms,2010,Anush Krishna Moorthy and Kalpana Seshadrinathan and Rajiv Soundararajan and Alan Conrad Bovik,20,IEEE transactions on Circuits and Systems for Video Technology,4,587-599,IEEE,Evaluating the perceptual quality of video is of tremendous importance in the design and optimization of wireless video processing and transmission systems. In an endeavor to emulate human perception of quality. various objective video quality assessment (VQA) algorithms have been developed. However. the only subjective video quality database that exists on which these algorithms can be tested is dated and does not accurately reflect distortions introduced by present generation encoders and/or wireless channels. In order to evaluate the performance of VQA algorithms for the specific task of H.264 advanced video coding compressed video transmission over wireless networks. we conducted a subjective study involving 160 distorted videos. Various leading full reference VQA algorithms were tested for their correlation with human perception. The data from the paper has been made available to the research …,True,t9eduncAAAAJ:d1gkVwhDpl0C,158,https://ieeexplore.ieee.org/abstract/document/5401067/,599478784655942979,/scholar?cites=599478784655942979,,,http://live.ece.utexas.edu/publications/2010/akm_tcsvt_apr10.pdf,0,0,0
1277883,Visual quality assessment algorithms: what does the future hold?,2011,Anush Krishna Moorthy and Alan Conrad Bovik,51,Multimedia Tools and Applications,2,675-696,Springer US,Creating algorithms capable of predicting the perceived quality of a visual stimulus defines the field of objective visual quality assessment (QA). The field of objective QA has received tremendous attention in the recent past. with many successful algorithms being proposed for this purpose. Our concern here is not with the past however; in this paper we discuss our vision for the future of visual quality assessment research. We first introduce the area of quality assessment and state its relevance. We describe current standards for gauging algorithmic performance and define terms that we will use through this paper. We then journey through 2D image and video quality assessment. We summarize recent approaches to these problems and discuss in detail our vision for future research on the problems of full-reference and no-reference 2D image and video quality assessment. From there. we move on to the …,True,t9eduncAAAAJ:ufrVoPGSRksC,136,https://link.springer.com/article/10.1007/s11042-010-0640-x,860727315151351267,/scholar?cites=860727315151351267,,,http://dcalab.unipv.it/wp-content/uploads/2015/02/akm_ijmta_jan11.pdf,0,0,0
1277884,Application of affine-invariant Fourier descriptors to recognition of 3-D objects,1990,Klaus Arbter and Wesley E.  Snyder and Hans Burkhardt and Gerd Hirzinger,12,IEEE Transactions on pattern analysis and machine intelligence,7,640-647,IEEE,The method of Fourier descriptors is extended to produce a set of normalized coefficients which are invariant under any affine transformation (translation. rotation. scaling. and shearing). The method is based on a parameterized boundary description which is transformed to the Fourier domain and normalized there to eliminate dependencies on the affine transformation and on the starting point. Invariance to affine transforms allows considerable robustness when applied to images of objects which rotate in all three dimensions. as is demonstrated by processing silhouettes of aircraft maneuvering in three-space.< >,True,wuP9DrEAAAAJ:u-x6o8ySG0sC,608,https://ieeexplore.ieee.org/abstract/document/56206/,6952235163300767628,/scholar?cites=6952235163300767628,,,https://www.academia.edu/download/46524063/ar_bu_pami.pdf,0,0,0
1277885,Online handwriting recognition with support vector machines-a kernel approach,2002,Claus Bahlmann and Bernard Haasdonk and Hans Burkhardt,,,,49-54,IEEE,In this paper we describe a novel classification approach for online handwriting recognition. The technique combines dynamic time warping (DTW) and support vector machines (SVMs) by establishing a new SVM kernel. We call this kernel Gaussian DTW (GDTW) kernel. This kernel approach has a main advantage over common HMM techniques. It does not assume a model for the generative class conditional densities. Instead. it directly addresses the problem of discrimination by creating class boundaries and thus is less sensitive to modeling assumptions. By incorporating DTW in the kernel function. general classification problems with variable-sized sequential data can be handled. In this respect the proposed method can be straightforwardly applied to all classification problems. where DTW gives a reasonable distance measure. e.g.. speech recognition or genome processing. We show experiments with this …,True,wuP9DrEAAAAJ:d1gkVwhDpl0C,510,https://ieeexplore.ieee.org/abstract/document/1030883;,11851621244913521565,/scholar?cites=11851621244913521565,,,https://www.academia.edu/download/30488967/ba_ha_bu_iwfhr02-foils.pdf,0,0,0
1277886,Chemotaxonomic identification of single bacteria by micro-Raman spectroscopy: application to clean-room-relevant biological contaminations,2005,Petra Rösch and Michaela Harz and Michael Schmitt and Klaus-Dieter Peschke and Olaf Ronneberger and Hans Burkhardt and Hans-Walter Motzkus and Markus Lankers and Stefan Hofer and Hans Thiele and Jürgen Popp,71,Applied and environmental microbiology,3,1626-1637,American Society for Microbiology,Microorganisms. such as bacteria. which might be present as contamination inside an industrial food or pharmaceutical clean room process need to be identified on short time scales in order to minimize possible health hazards as well as production downtimes causing financial deficits. Here we describe the first results of single-particle micro-Raman measurements in combination with a classification method. the so-called support vector machine technique. allowing for a fast. reliable. and nondestructive online identification method for single bacteria.,True,wuP9DrEAAAAJ:9yKSN-GCB0IC,330,https://aem.asm.org/content/71/3/1626.short,7438423188876465494,/scholar?cites=7438423188876465494,,,https://aem.asm.org/content/aem/71/3/1626.full.pdf,0,0,0
1277887,Robust vision-based localization by combining an image-retrieval system with Monte Carlo localization,2005,Jürgen Wolf and Wolfram Burgard and Hans Burkhardt,21,IEEE transactions on robotics,2,208-216,IEEE,In this paper. we present a vision-based approach to mobile robot localization that integrates an image-retrieval system with Monte Carlo localization. The image-retrieval process is based on features that are invariant with respect to image translations and limited scale. Since it furthermore uses local features. the system is robust against distortion and occlusions. which is especially important in populated environments. To integrate this approach with the sample-based Monte Carlo localization technique. we extract for each image in the database a set of possible viewpoints using a two-dimensional map of the environment. Our technique has been implemented and tested extensively. We present practical experiments illustrating that our approach is able to globally localize a mobile robot. to reliably keep track of the robot's position. and to recover from localization failures. We furthermore present experiments …,True,wuP9DrEAAAAJ:2osOgNQ5qMEC,303,https://ieeexplore.ieee.org/abstract/document/1416972/,11415898841512036498,/scholar?cites=11415898841512036498,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.9731&rep=rep1&type=pdf,0,0,0
1277888,Micro-Raman spectroscopic identification of bacterial cells of the genus Staphylococcus and dependence on their cultivation conditions,2005,Michaela Harz and Petra Rösch and K-D Peschke and Olaf Ronneberger and Hans Burkhardt and J Popp,130,Analyst,11,1543-1550,Royal Society of Chemistry,Microbial contamination is not only a medical problem. but also plays a large role in pharmaceutical clean room production and food processing technology. Therefore many techniques were developed to achieve differentiation and identification of microorganisms. Among these methods vibrational spectroscopic techniques (IR. Raman and SERS) are useful tools because of their rapidity and sensitivity. Recently we have shown that micro-Raman spectroscopy in combination with a support vector machine is an extremely capable approach for a fast and reliable. non-destructive online identification of single bacteria belonging to different genera. In order to simulate different environmental conditions we analyzed in this contribution different Staphylococcus strains with varying cultivation conditions in order to evaluate our method with a reliable dataset. First. micro-Raman spectra of the bulk material and single …,True,wuP9DrEAAAAJ:zYLM7Y9cAGgC,243,https://pubs.rsc.org/lv/content/articlehtml/2005/an/b507715j,12420574584453845895,/scholar?cites=12420574584453845895,,,https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00016927/Harz/Dissertation.pdf#page=69,0,0,0
1277889,The writer independent online handwriting recognition system frog on hand and cluster generative statistical dynamic time warping,2004,Claus Bahlmann and Hans Burkhardt,26,IEEE Transactions on Pattern Analysis and Machine Intelligence,3,299-310,IEEE,In this paper. we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach. which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general. scalable. HMM-based method for variable-sized. sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data. e.g.. speech recognition. genome processing. robotics. etc. Contrary to previous attempts. clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is …,True,wuP9DrEAAAAJ:qjMakFHDy7sC,241,https://ieeexplore.ieee.org/abstract/document/1262308/,3887878942993129788,/scholar?cites=3887878942993129788,,,,0,0,0
1277890,Object identification with tactile sensors using bag-of-features,2009,Alexander Schneider and Jürgen Sturm and Cyrill Stachniss and Marco Reisert and Hans Burkhardt and Wolfram Burgard,,,,243-248,IEEE,In this paper. we present a novel approach for identifying objects using touch sensors installed in the finger tips of a manipulation robot. Our approach operates on low-resolution intensity images that are obtained when the robot grasps an object. We apply a bag-of-words approach for object identification. By means of unsupervised clustering on training data. our approach learns a vocabulary from tactile observations which is used to generate a histogram codebook. The histogram codebook models distributions over the vocabulary and is the core identification mechanism. As the objects are larger than the sensor. the robot typically needs multiple grasp actions at different positions to uniquely identify an object. To reduce the number of required grasp actions. we apply a decision-theoretic framework that minimizes the entropy of the probabilistic belief about the type of the object. In our experiments carried out with …,True,wuP9DrEAAAAJ:4TOpqqG69KYC,239,https://ieeexplore.ieee.org/abstract/document/5354648/,7665201329766223461,/scholar?cites=7665201329766223461,,,http://ais.informatik.uni-freiburg.de/publications/papers/schneida09iros.pdf,0,0,0
1277891,Using snakes to detect the intimal and adventitial layers of the common carotid artery wall in sonographic images,2002,Da-chuan Cheng and Arno Schmidt-Trucksäss and Kuo-sheng Cheng and Hans Burkhardt,67,Computer methods and programs in biomedicine,1,27-37,Elsevier,This study presents an innovative automatic system for detecting the intima-media complex of the far wall of the common carotid artery by applying the snake techniques. Cohen's snake was modified and some criteria were added for our applications. In addition. the oscillating problem of using snakes was solved by properly choosing the time step from analysis of the frequency response of the filters. A time-diminishing gravity window. external forces. and a cost function assist the snake in selecting the optimal shape of intimal and adventitia layers. We compared the proposed snake and ziplock snake with respect to the manual extraction contour. The results show that the system can automatically detect the intimal and adventitial layers without any manual correction.,True,wuP9DrEAAAAJ:IjCSPb-OGe4C,196,https://www.sciencedirect.com/science/article/pii/S0169260700001498,1761879214101663821,/scholar?cites=1761879214101663821,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.16.5240&rep=rep1&type=pdf,0,0,0
1277892,Robust vision-based localization for mobile robots using an image retrieval system based on invariant features,2002,Jürgen Wolf and Wolfram Burgard and Hans Burkhardt,1,,,359-365,IEEE,We present a vision-based approach to mobile robot localization. that integrates an image retrieval system with Monte-Carlo localization. The image retrieval process is based on features that are invariant with respect to image translations. rotations. and limited scale. Using the local features the system is robust against distortion and occlusions. which is especially important in populated environments. By using the sample-based Monte-Carlo localization technique our robot is able to globally localize itself to reliably keep tracking of its position. and to recover from localization failures. Both techniques are combined by extracting for each image a set of possible view-points using a two-dimensional map of the environment. Our technique was implemented and tested extensively. We present several experiments demonstrating the reliability and robustness of our approach even in the context of dynamics in the …,True,wuP9DrEAAAAJ:UeHWp8X0CEIC,160,https://ieeexplore.ieee.org/abstract/document/1013387/,9816163896542365587,/scholar?cites=9816163896542365587,,,http://ais.informatik.uni-freiburg.de/publications/papers/wolf_icra02.pdf,0,0,0
1277893,4D phase contrast MRI at 3 T: Effect of standard and blood‐pool contrast agents on SNR. PC‐MRA. and blood flow visualization,2010,Jelena Bock and Alex Frydrychowicz and Aurélien F Stalder and Thorsten A Bley and Hans Burkhardt and Jürgen Hennig and Michael Markl,63,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,2,330-338,Wiley Subscription Services. Inc.. A Wiley Company,Time‐resolved phase contrast (PC) MRI with velocity encoding in three directions (flow‐sensitive four‐dimensional MRI) can be employed to assess three‐dimensional blood flow in the entire aortic lumen within a single measurement. These data can be used not only for the visualization of blood flow but also to derive additional information on vascular geometry with three‐dimensional PC MR angiography (MRA). As PC‐MRA is sensitive to available signal‐to‐noise ratio. standard and novel blood pool contrast agents may help to enhance PC‐MRA image quality. In a group of 30 healthy volunteers. the influence of different contrast agents on vascular signal‐to‐noise ratio. PC‐MRA quality. and subsequent three‐dimensional stream‐line visualization in the thoracic aorta was determined. Flow‐sensitive four‐dimensional MRI data acquired with contrast agent provided significantly improved signal‐to‐noise ratio in …,True,wuP9DrEAAAAJ:dhFuZR0502QC,151,https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.22199,1225551359258798785,/scholar?cites=1225551359258798785,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mrm.22199,0,0,0
1277894,State-of-the-art in content-based image and video retrieval,2013,Remco C Veltkamp and Hans Burkhardt and Hans-Peter Kriegel,22,,,,Springer Science & Business Media,Images and video play a crucial role in visual information systems and multimedia. There is an extraordinary number of applications of such systems in entertainment. business. art. engineering. and science. Such applications often involved large image and video collections. and therefore. searching for images and video in large collections is becoming an important operation. Because of the size of such databases. efficiency is crucial. We strongly believe that image and video retrieval need an integrated approach from fields such as image processing. shape processing. perception. database indexing. visualization. and querying. etc. This book contains a selection of results that was presented at the Dagstuhl Seminar on Content-Based Image and Video Retrieval. in December 1999. The purpose of this seminar was to bring together people from the various fields. in order to promote information exchange and interaction among researchers who are interested in various aspects of accessing the content of image and video data. The book provides an overview of the state of the art in content-based image and video retrieval. The topics covered by the chapters are integrated system aspects. as well as techniques from image processing. computer vision. multimedia. databases. graphics. signal processing. and information theory. The book will be of interest to researchers and professionals in the fields of multimedia. visual information (database) systems. computer vision. and information retrieval.,True,wuP9DrEAAAAJ:Y0pCki6q_DkC,144,http://books.google.com/books?hl=en&lr=&id=GvapCAAAQBAJ&oi=fnd&pg=PA20&dq=info:UdEaA2EjNnwJ:scholar.google.com&ots=DGq5QyJ78v&sig=OyL7AZAs_a7g_OnwF2ajmhW-G68,8950380209016328529,/scholar?cites=8950380209016328529,,,,0,0,0
1277895,[8] Singular value decomposition: Application to analysis of experimental data,1992,ER Henry and J Hofrichter,210,,,129-192,Academic Press,This chapter summarizes the properties of the singular value decomposition. which are relevant for data analysis. The chapter describes the way in which the singular value decomposition (SVD) of a noise-free data set for which the spectra. f. and concentration. c. vectors are known can be calculated from consideration of the integrated overlaps of these components. Because data analysis necessarily begins with matrices. which are “noisy” at some level of precision. the chapter describes some of the properties of the SVD of matrices. which contain noise. It describes the SVD of random matrices (that is. matrices containing only noise). The chapter explores the way the random amplitudes are distributed in the SVD output when noise is added to a data matrix by using perturbation theory. The chapter discusses the significant advantages that result from the application of SVD and complementary …,True,vbbwpVtvgYQC:2P1L_qKh6hAC,698,https://www.sciencedirect.com/science/article/pii/007668799210010B,15604302473575660748,/scholar?cites=15604302473575660748,,,http://library.sbu.ac.ir/islandora/object/CDLIBDigitalLibDemo8%3A490/datastream/OBJ/download/Essential_numerical_computer_methods.pdf#page=98,0,0,0
1277896,The role of solvent viscosity in the dynamics of protein conformational changes,1992,Anjum Ansari and Colleen M Jones and Eric R Henry and James Hofrichter and William A Eaton,256,Science,5065,1796-1798,American Association for the Advancement of Science,"Nanosecond lasers were used to measure the rate of conformational changes in myoglobin after ligand dissociation at ambient temperatures. At low solvent viscosities the rate is independent of viscosity. but at high viscosities it depends on approximately the inverse first power of the viscosity. Kramers theory for unimolecular rate processes can be used to explain this result if the friction term is modified to include protein as well as solvent friction. The theory and experiment suggest that the dominant factor in markedly reducing the rate of conformational changes in myoglobin at low temperatures (less than 200 K) is the very high viscosity (greater than 10(7) centipoise) of the glycerol-water solvent. That is. at low temperatures conformational substates may not be ""frozen"" so much as ""stuck.""",True,vbbwpVtvgYQC:2osOgNQ5qMEC,593,https://science.sciencemag.org/content/256/5065/1796.abstract,766182131218280622,/scholar?cites=766182131218280622,,,https://www.researchgate.net/profile/Anjum_Ansari/publication/21541056_The_Role_of_Solvent_Viscosity_in_the_Dynamics_of_Protein_Conformational_Changes/links/00463536bfef5c56b5000000/The-Role-of-Solvent-Viscosity-in-the-Dynamics-of-Protein-Conformational-Changes.pdf,0,0,0
1277897,Mechanisms in protein folding.,2000,WA Eaton and V Munoz and SJ Hagen and GS Jas and LJ Lapidus and ER Henry and A Hofrichter,219,,,U277-U277,AMER CHEMICAL SOC,,True,vbbwpVtvgYQC:9ZlFYXVOiuMC,580,http://scholar.google.com/scholar?cluster=2390348162318416419&hl=en&oi=scholarr,1350168386267832192,/scholar?cites=1350168386267832192,,,,0,0,0
1277898,Fast kinetics and mechanisms in protein folding,2000,William A Eaton and Victor Munoz and Stephen J Hagen and Gouri S Jas and Lisa J Lapidus and Eric R Henry and James Hofrichter,29,,1,327-359,Annual Reviews,This review describes how kinetic experiments using techniques with dramatically improved time resolution have contributed to understanding mechanisms in protein folding. Optical triggering with nanosecond laser pulses has made it possible to study the fastest-folding proteins as well as fundamental processes in folding for the first time. These include formation of α-helices. β-sheets. and contacts between residues distant in sequence. as well as overall collapse of the polypeptide chain. Improvements in the time resolution of mixing experiments and the use of dynamic nuclear magnetic resonance methods have also allowed kinetic studies of proteins that fold too fast (≳ 103 s−1) to be observed by conventional methods. Simple statistical mechanical models have been extremely useful in interpreting the experimental results. One of the surprises is that models originally developed for explaining the …,True,vbbwpVtvgYQC:zYLM7Y9cAGgC,578,https://www.annualreviews.org/doi/full/10.1146/annurev.biophys.29.1.327,1350168386267832192,/scholar?cites=1350168386267832192,,,https://www.ncbi.nlm.nih.gov/books/NBK2232/,0,0,0
1277899,A statistical mechanical model for β-hairpin kinetics,1998,Victor Munoz and Eric R Henry and James Hofrichter and William A Eaton,95,Proceedings of the National Academy of Sciences,11,5872-5879,National Academy of Sciences,Understanding the mechanism of protein secondary structure  formation is an essential part of the protein-folding puzzle. Here. we  describe a simple statistical mechanical model for the formation of a  β-hairpin. the minimal structural element of the antiparallel  β-pleated sheet. The model accurately describes the thermodynamic and  kinetic behavior of a 16-residue. β-hairpin-forming peptide.  successfully explaining its two-state behavior and apparent negative  activation energy for folding. The model classifies structures  according to their backbone conformation. defined by 15 pairs of  dihedral angles. and is further simplified by considering only the 120  structures with contiguous stretches of native pairs of backbone  dihedral angles. This single sequence approximation is tested by  comparison with a more complete model that includes the 215  possible conformations and 15 × 215 possible kinetic  transitions …,True,vbbwpVtvgYQC:4JMBOYKVnBMC,419,https://www.pnas.org/content/95/11/5872.short,12207591666217080357,/scholar?cites=12207591666217080357,,,https://www.pnas.org/content/pnas/95/11/5872.full.pdf,0,0,0
1277900,Fast events in protein folding initiated by nanosecond laser photolysis,1993,Colleen M Jones and Eric R Henry and Yi Hu and Chi-Kin Chan and Stan D Luck and Abani Bhuyan and Heinrich Roder and James Hofrichter and William A Eaton,90,Proceedings of the National Academy of Sciences,24,11860-11864,National Academy of Sciences,Initiation of protein folding by light can dramatically improve the time resolution of kinetic studies. Here we present an example of an optically triggered folding reaction by using nanosecond photodissociation of the heme-carbon monoxide complex of reduced cytochrome c. The optical trigger is based on the observation that under destabilizing conditions cytochrome c can be unfolded by preferential binding of carbon monoxide to the covalently attached heme group in the unfolded state. Photodissociation of the carbon monoxide thus triggers the folding reaction. We used time-resolved absorption spectroscopy to monitor binding at the heme. Before folding begins we observe transient binding of both nonnative and native ligands from the unfolded polypeptide on a microsecond time scale. Kinetic modeling suggests that the intramolecular binding of methionine-65 and -80 is faster than that of histidine-26 and -33 …,True,vbbwpVtvgYQC:u5HHmVD_uO8C,412,https://www.pnas.org/content/90/24/11860.short,23953531905399736,/scholar?cites=23953531905399736,,,https://www.pnas.org/content/pnas/90/24/11860.full.pdf,0,0,0
1277901,Is cooperative oxygen binding by hemoglobin really understood?,1999,William A Eaton and Eric R Henry and James Hofrichter and Andrea Mozzarelli,6,Nature structural biology,4,351-358,Nature Publishing Group,The enormous success of structural biology challenges the physical scientist. Can biophysical studies provide a truly deeper understanding of how a protein works than can be obtained from static structures and qualitative analysis of biochemical data? We address this question in a case study by presenting the key concepts and experimental results that have led to our current understanding of cooperative oxygen binding by hemoglobin. the paradigm of structure function relations in multisubunit proteins. We conclude that the underlying simplicity of the two-state allosteric mechanism could not have been demonstrated without novel physical experiments and a rigorous quantitative analysis.,True,vbbwpVtvgYQC:isC4tDSrTZIC,352,https://www.nature.com/articles/nsb0499_351,12718070264579491531,/scholar?cites=12718070264579491531,,,https://www.researchgate.net/profile/Andrea_Mozzarelli/publication/226660867_Is_cooperative_oxygen_binding_by_hemoglobin_really_understood/links/0912f501006c7e4096000000/Is-cooperative-oxygen-binding-by-hemoglobin-really-understood.pdf,0,0,0
1277902,Molecular dynamics simulations of cooling in laser-excited heme proteins,1986,Eric R Henry and William A Eaton and Robin M Hochstrasser,83,Proceedings of the National Academy of Sciences,23,8982-8986,National Academy of Sciences,In transient optical experiments the absorbed photon raises the vibrational temperature of the chromophore. In heme proteins at room temperature conversion of a 530-nm photon into vibrational energy is estimated to raise the temperature of the heme by 500-700 K. Cooling of the heme is expected to occur mainly by interacting with the surrounding protein. We report molecular dynamics simulations for myoglobin and cytochrome c in vacuo that predict that this cooling occurs on the ps time scale. The decay of the vibrational temperature is nonexponential with about 50% loss occurring in 1-4 ps and with the remainder in 20-40 ps. These results predict the presence of nonequilibrium vibrational populations that would introduce ambiguity into the interpretation of transient ps absorption and Raman spectra and influence the kinetics of sub-ns geminate recombination.,True,vbbwpVtvgYQC:YsMSGLbcyi4C,330,https://www.pnas.org/content/83/23/8982.short,17019119952865824653,/scholar?cites=17019119952865824653,,,https://www.pnas.org/content/pnas/83/23/8982.full.pdf,0,0,0
1277903,Geminate recombination of carbon monoxide to myoglobin,1983,Eric R Henry and Joseph H Sommer and James Hofrichter and William A Eaton and M Gellert,166,Journal of molecular biology,3,443-451,Academic Press,Transient absorption spectra of myoglobin. following photolysis of the carbon monoxide complex at room temperature. were measured using a newly developed. sensitive nanosecond absorption spectrometer. The Soret spectrum of the immediate photoproduct is almost identical to that of deoxymyoglobin at equilibrium. suggesting that the heme group has changed from a planar to a domed structure in less than about 3 ns. About 4% of the photodissociated carbon monoxide molecules rebind to the hemes to which they were initially bound. with a relaxation time of 180 ns. Duddell et al. (1980) observed a geminate yield of 27% and a relaxation time of ≈55 ns for the photolysis of oxymyoglobin. Comparison of the two results using the simplest kinetic model suggests that the 30-fold more rapid overall association rate for the reaction of oxygen with myoglobin compared to carbon monoxide results mainly from faster …,True,vbbwpVtvgYQC:RHpTSmoSYBkC,286,https://www.sciencedirect.com/science/article/pii/S0022283683800941,11690496391381481700,/scholar?cites=11690496391381481700,,,,0,0,0
1277904,Nanosecond absorption spectroscopy of hemoglobin: elementary processes in kinetic cooperativity,1983,James Hofrichter and Joseph H Sommer and Eric R Henry and William A Eaton,80,Proceedings of the National Academy of Sciences,8,2235-2239,National Academy of Sciences,A nanosecond absorption spectrometer has been used to measure the optical spectra of hemoglobin between 3 ns and 100 ms after photolysis of the CO complex. The data from a single experiment comprise a surface. defined by the time-ordered set of 50-100 spectra. Singular value decomposition is used to represent the observed spectra in terms of a minimal set of basis spectra and the time course of their amplitudes. Both CO rebinding and conformational changes are found to be multiphasic. Prior to the quaternary structural change. two relaxations are observed that are assigned to geminate recombination followed by a tertiary structural change. These relaxations are interpreted in terms of a kinetic model that points out their potential role in kinetic cooperativity. The rapid escape of CO from the heme pocket compared with the rate of rebinding observed for both R and T quaternary states shows that the …,True,vbbwpVtvgYQC:7PzlFSSx8tAC,268,https://www.pnas.org/content/80/8/2235.short,9195710524818824761,/scholar?cites=9195710524818824761,,,https://www.pnas.org/content/pnas/80/8/2235.full.pdf,0,0,0
1277905,Influence of vibrational motion on solid state line shapes and NMR relaxation,1985,Eric R Henry and Attila Szabo,82,The Journal of chemical physics,11,4753-4761,American Institute of Physics,The influence of vibrational motion on bond lengths and quadrupole constants obtained from dipolar and quadrupolar solid state line shapes is considered. It is shown that such motions average both the magnitude and the orientation of the intrinsic interaction tensor. Explicit expressions for the effective coupling constants that can be conveniently evaluated using the results of a normal mode analysis are derived. When the vibrationally averaged interaction tensor is axially symmetric. it is shown that the effect of vibrational motion on relaxation can be rigorously incorporated into an effective coupling constant which is formally identical to the one that determines the line shape. Illustrative calculations for several alkanes. in both the gas and solid phases. are presented. The relative contributions of stretching and bending vibrations and the effect of anharmonicity on the effective C–H bond lengths and deuterium …,True,vbbwpVtvgYQC:dhFuZR0502QC,254,https://aip.scitation.org/doi/abs/10.1063/1.448692,9083606643436845118,/scholar?cites=9083606643436845118,,,,0,0,0
1277906,Multi-fractal texture estimation for detection and segmentation of brain tumors,2013,Atiq Islam and Syed Reza and K Iftekharuddin,60,IEEE Transaction on Biomedical Engineering,11,3204 - 3215,IEEE,A stochastic model for characterizing tumor texture in brain magnetic resonance (MR) images is proposed. The efficacy of the model is demonstrated in patient-independent brain tumor texture feature extraction and tumor segmentation in magnetic resonance images (MRIs). Due to complex appearance in MRI. brain tumor texture is formulated using a multiresolution-fractal model known as multifractional Brownian motion (mBm). Detailed mathematical derivation for mBm model and corresponding novel algorithm to extract spatially varying multifractal features are proposed. A multifractal feature-based brain tumor segmentation method is developed next. To evaluate efficacy. tumor segmentation performance using proposed multifractal feature is compared with that using Gabor-like multiscale texton feature. Furthermore. novel patient-independent tumor segmentation scheme is proposed by extending the well …,True,xKYIkOsAAAAJ:kNdYIx-mwKoC,254,https://ieeexplore.ieee.org/abstract/document/6548065/,9846925192319439846,/scholar?cites=9846925192319439846,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5126980/,0,0,0
1277907,Fractal-based brain tumor detection in multimodal MRI,2009,Khan M Iftekharuddin and Jing Zheng and Mohammad A Islam and Robert J Ogg,207,Applied Mathematics and Computation,1,23-41,Elsevier,In this work. we investigate the effectiveness of fusing two novel texture features along with intensity in multimodal magnetic resonance (MR) images for pediatric brain tumor segmentation and classification. One of the two texture features involves our Piecewise-Triangular-Prism-Surface-Area (PTPSA) algorithm for fractal feature extraction. The other texture feature exploits our novel fractional Brownian motion (fBm) framework that combines both fractal and wavelet analyses for fractalwavelet feature extraction. We exploit three MR image modalities such as T1 (gadolinium-enhanced). T2 and FLuid-Attenuated Inversion-Recovery (FLAIR). respectively. The extracted features from these multimodality MR images are fused using Self-Organizing Map (SOM). For a total of 204 T1 contrast-enhanced. T2 and FLAIR MR images obtained from nine different pediatric patients. our successful tumor segmentation is 100%. Our …,True,xKYIkOsAAAAJ:YOwf2qJgpHMC,167,https://www.sciencedirect.com/science/article/pii/S0096300308000179,7076484782370873476,/scholar?cites=7076484782370873476,,,http://www.fractal.org/Life-Science-Technology/Publications/Fractal-based-brain-tumor-detection.pdf,0,0,0
1277908,A machine learning approach to predict autism spectrum disorder,2019,Kazi Shahrukh Omar and Prodipta Mondal and Nabila Shahnaz Khan and Md Rezaul Karim Rizvi and Md Nazrul Islam,,,,1-6,IEEE,In present day Autism Spectrum Disorder (ASD) is gaining its momentum faster than ever. Detecting autism traits through screening tests is very expensive and time consuming. With the advancement of artificial intelligence and machine learning (ML). autism can be predicted at quite early stage. Though number of studies have been carried out using different techniques. these studies didn't provide any definitive conclusion about predicting autism traits in terms of different age groups. Therefore this paper aims to propose an effective prediction model based on ML technique and to develop a mobile application for predicting ASD for people of any age. As outcomes of this research. an autism prediction model was developed by merging Random Forest-CART (Classification and Regression Trees) and Random Forest-Id3(Iterative Dichotomiser 3) and also a mobile application was developed based on the proposed …,True,xKYIkOsAAAAJ:RiW20FJDrgsC,39,https://ieeexplore.ieee.org/abstract/document/8679454/,1066895743465298652,/scholar?cites=1066895743465298652,,,https://www.researchgate.net/profile/Muhammad_Nazrul_Islam2/publication/331315353_A_Machine_Learning_Approach_to_Predict_Autism_Spectrum_Disorder/links/5cae46b5299bf120975d6041/A-Machine-Learning-Approach-to-Predict-Autism-Spectrum-Disorder.pdf,0,0,0
1277909,Automatic brain tumor detection in MRI: methodology and statistical validation,2005,Khan M Iftekharuddin and Mohammad A Islam and Jahangheer Shaik and Carlos Parra and Robert Ogg,5747,,,2012-2022,International Society for Optics and Photonics,Automated brain tumor segmentation and detection are immensely important in medical diagnostics because it provides information associated to anatomical structures as well as potential abnormal tissue necessary to delineate appropriate surgical planning. In this work. we propose a novel automated brain tumor segmentation technique based on multiresolution texture information that combines fractal Brownian motion (fBm) and wavelet multiresolution analysis. Our wavelet-fractal technique combines the excellent multiresolution localization property of wavelets to texture extraction of fractal. We prove the efficacy of our technique by successfully segmenting pediatric brain MR images (MRIs) from St. Jude Children’s Research Hospital. We use self-organizing map (SOM) as our clustering tool wherein we exploit both pixel intensity and multiresolution texture features to obtain segmented tumor. Our test results …,True,xKYIkOsAAAAJ:_kc_bZDykSQC,35,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5747/0000/Automatic-brain-tumor-detection-in-MRI--methodology-and-statistical/10.1117/12.595931.short,11071595348059535326,/scholar?cites=11071595348059535326,,,,0,0,0
1277910,Learning people annotation from the web via consistency learning,2007,Jay Yagnik and Atiq Islam,,,,285-290,,The phenomenal growth of Image/Video on the web and the increasing sparseness of meta information to go along with forces us to look for signals from the Image/Video content for Search/Information Retrieval and Browsing based corpus exploration. One of the prominent type of information that users look for while searching/browsing through such corpora is information around the people present in the Image/Video. While face recognition has matured to some extent over the past few years. this problem remains a hard one due to a) absence of labelled data for such a large set of celebrities that users look for and b) the variability of age/makeup/expressions/pose in the target corpus. We propose a learning paradigm which we refer to as consistency learning to address both these issues by posing the problem of learning from weakly labelled training set. We use the text-image co-occurrence on the web as a weak …,True,xKYIkOsAAAAJ:W7OEmFMy1HYC,34,https://dl.acm.org/doi/abs/10.1145/1290082.1290121,11865643148036798816,/scholar?cites=11865643148036798816,,,,0,0,0
1277911,Brain tumor detection in MRI: technique and statistical validation,2006,KM Iftekharuddin and J Zheng and MA Islam and RJ Ogg and F Lanningham,,,,1983-1987,IEEE,Two novel fractal-based texture features are exploited for pediatric brain tumor segmentation and classification in MRI. One of the two texture features uses piecewise-triangular-prism-surface-area (PTPSA) algorithm for fractal feature extraction. The other texture feature exploits our novel fractional Brownian motion (fBm) framework that combines both fractal and wavelet analyses for fractal wavelet feature extraction. Three MRI modalities such as Tl (gadolinium-enhanced). T2 and fluid-attenuated inversion-recovery (FLAIR) are exploited in this work. The self-organizing map (SOM) algorithm is used for tumor segmentation. For a total of 204 Tl contrast-enhanced. T2 and FLAIR MR images obtained from nine different pediatric patients. the successful tumor segmentation rate is 100%. Two classification methods. multi-layer feedforward neural network and support vector machine (SVM). are used to classify the tumor …,True,xKYIkOsAAAAJ:4TOpqqG69KYC,26,https://ieeexplore.ieee.org/abstract/document/4176922/,18375383906890051874,/scholar?cites=18375383906890051874,,,,0,0,0
1277912,Automatic tracking of people and bodies in video,2009,Alex David Holub and Atiq Islam and Andrei Peter Makhanov and Pierre Moreels and Rui Yang,,,,,,A facial detection module detects faces in any frame in a video by applying at least two rectangles between the eyes of a face and other regions and calculating a difference in intensity between those regions. The intensities are used to generate face detections. A tracking module predicts the location of faces in frames across time and compares the predicted location to the face detections. The face detection that is closest to the predicted location is selected. provided that it exceeds a threshold of overlap with the predicted location. A tracking module determines shot boundaries by comparing the similarities between frames. A clustering module groups the face tracks in the shots. as demarcated by the shot boundaries. for individuals within the video. A body detection module attaches a body outline to each of the face tracks to increase the clickable area for the individuals.,True,xKYIkOsAAAAJ:ufrVoPGSRksC,25,https://patents.google.com/patent/US20090290791A1/en,16120185366643361250,/scholar?cites=16120185366643361250,,,https://patentimages.storage.googleapis.com/4e/16/e1/323876e6869137/US20090290791A1.pdf,0,0,0
1277913,Automatic tracking of people and bodies in video,2009,Alex David Holub and Atiq Islam and Andrei Peter Makhanov and Pierre Moreels and Rui Yang,,,,,,A facial detection module detects faces in any frame in a video by applying at least two rectangles between the eyes of a face and other regions and calculating a difference in intensity between those regions. The intensities are used to generate face detections. A tracking module predicts the location of faces in frames across time and compares the predicted location to the face detections. The face detection that is closest to the predicted location is selected. provided that it exceeds a threshold of overlap with the predicted location. A tracking module determines shot boundaries by comparing the similarities between frames. A clustering module groups the face tracks in the shots. as demarcated by the shot boundaries. for individuals within the video. A body detection module attaches a body outline to each of the face tracks to increase the clickable area for the individuals.,True,xKYIkOsAAAAJ:WF5omc3nYNoC,25,https://patents.google.com/patent/US20090290791A1/en,16120185366643361250,/scholar?cites=16120185366643361250,,,https://patentimages.storage.googleapis.com/4e/16/e1/323876e6869137/US20090290791A1.pdf,0,0,0
1277914,Automatic tracking of people and bodies in video,2009,Alex David Holub and Atiq Islam and Andrei Peter Makhanov and Pierre Moreels and Rui Yang,,,,,,A facial detection module detects faces in any frame in a video by applying at least two rectangles between the eyes of a face and other regions and calculating a difference in intensity between those regions. The intensities are used to generate face detections. A tracking module predicts the location of faces in frames across time and compares the predicted location to the face detections. The face detection that is closest to the predicted location is selected. provided that it exceeds a threshold of overlap with the predicted location. A tracking module determines shot boundaries by comparing the similarities between frames. A clustering module groups the face tracks in the shots. as demarcated by the shot boundaries. for individuals within the video. A body detection module attaches a body outline to each of the face tracks to increase the clickable area for the individuals.,True,xKYIkOsAAAAJ:eQOLeE2rZwMC,25,https://patents.google.com/patent/US20090290791A1/en,16120185366643361250,/scholar?cites=16120185366643361250,,,https://patentimages.storage.googleapis.com/4e/16/e1/323876e6869137/US20090290791A1.pdf,0,0,0
1277915,Multifractal modeling. segmentation. prediction. and statistical validation of posterior fossa tumors,2008,Atiq Islam and Khan M Iftekharuddin and Robert J Ogg and Fred H Laningham and Bhuvaneswari Sivakumar,6915,,,69153C,International Society for Optics and Photonics,In this paper. we characterize the tumor texture in pediatric brain magnetic resonance images (MRIs) and exploit these features for automatic segmentation of posterior fossa (PF) tumors. We focus on PF tumor because of the prevalence of such tumor in pediatric patients. Due to varying appearance in MRI. we propose to model the tumor texture with a multi-fractal process. such as a multi-fractional Brownian motion (mBm). In mBm. the time-varying Holder exponent provides flexibility in modeling irregular tumor texture. We develop a detailed mathematical framework for mBm in two-dimension and propose a novel algorithm to estimate the multi-fractal structure of tissue texture in brain MRI based on wavelet coefficients. This wavelet based multi-fractal feature along with MR image intensity and a regular fractal feature obtained using our existing piecewise-triangular-prism-surface-area (PTPSA) method. are fused in …,True,xKYIkOsAAAAJ:UebtZRa9Y70C,25,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/6915/69153C/Multifractal-modeling-segmentation-prediction-and-statistical-validation-of-posterior-fossa/10.1117/12.770902.short,6044724889303070171,/scholar?cites=6044724889303070171,,,https://www.researchgate.net/profile/Khan_Iftekharuddin/publication/253874339_Multifractal_modeling_segmentation_prediction_and_statistical_validation_of_posterior_fossa_tumors/links/546cbecd0cf2a7492c55a817/Multifractal-modeling-segmentation-prediction-and-statistical-validation-of-posterior-fossa-tumors.pdf,0,0,0
1277916,Core–shell drug carrier from folate conjugated chitosan obtained from prawn shell for targeted doxorubicin delivery,2017,Md Sazedul Islam and Papia Haque and Taslim U Rashid and M Nuruzzaman Khan and Abul K Mallik and M Nazrul I Khan and Mala Khan and Mohammed Mizanur Rahman,28,Journal of Materials Science: Materials in Medicine,4,55,Springer US,A multifunctional drug carrier with dual targeting (magnetic and folate-receptor) and pH sensitive core-shell hybrid nanomaterial has been developed to carry an anticancer drug doxorubicin.Superparamagnetic iron oxide nanoparticles (IONPs) were used as core of the carrier and cross-linked folate conjugated chitosan (FA-CS) was acted as shell in which doxorubicin was physically entrapped. Transmission electron microscopy (TEM) analysis confirmed the average particle size of IONPs and FA-CS coated IONPs 8.2 and 15.4 nm respectively. Magnetic measurement indicated that both the IONPs and FA-CS coated IONPs were superparamagnetic at room temperature with a magnetization value 57.72 and 37.44 emu/g respectively. At pH 5.8 (malignant tissue) showed a burst release of 30.05% of the doxorubicin in the first 4 h followed by a sustained release of 88.26% of drug over 72 …,True,xKYIkOsAAAAJ:YW9K3tL-BTUC,24,https://link.springer.com/content/pdf/10.1007/s10856-017-5859-x.pdf,6505204417533864845,/scholar?cites=6505204417533864845,,,https://www.researchgate.net/profile/Mala-Khan/publication/313810405_Core-shell_drug_carrier_from_folate_conjugated_chitosan_obtained_from_prawn_shell_for_targeted_doxorubicin_delivery/links/6016a17445851517ef2b3630/Core-shell-drug-carrier-from-folate-conjugated-chitosan-obtained-from-prawn-shell-for-targeted-doxorubicin-delivery.pdf,0,0,0
1277917,Motion capture using joint skeleton tracking and surface estimation,2009,Juergen Gall and Carsten Stoll and Edilson De Aguiar and Christian Theobalt and Bodo Rosenhahn and Hans-Peter Seidel,,,,1746-1753,IEEE,This paper proposes a method for capturing the performance of a human or an animal from a multi-view video sequence. Given an articulated template model and silhouettes from a multi-view image sequence. our approach recovers not only the movement of the skeleton. but also the possibly non-rigid temporal deformation of the 3D surface. While large scale deformations or fast movements are captured by the skeleton pose and approximate surface skinning. true small scale deformations or non-rigid garment motion are captured by fitting the surface to the silhouette. We further propose a novel optimization scheme for skeleton-based pose estimation that exploits the skeleton's tree structure to split the optimization problem into a local one and a lower dimensional global one. We show on various sequences that our approach can capture the 3D motion of animals and humans accurately even in the case of rapid …,True,qq3TxtcAAAAJ:9yKSN-GCB0IC,442,https://ieeexplore.ieee.org/abstract/document/5206755/,5951796682546559191,/scholar?cites=5951796682546559191,,,http://www.tnt.uni-hannover.de/papers/data/773/773_1.pdf,0,0,0
1277918,A statistical model of human pose and body shape,2009,Nils Hasler and Carsten Stoll and Martin Sunkel and Bodo Rosenhahn and H‐P Seidel,28,Computer graphics forum,2,337-346,Blackwell Publishing Ltd,Generation and animation of realistic humans is an essential part of many projects in today's media industry. Especially. the games and special effects industry heavily depend on realistic human animation. In this work a unified model that describes both. human pose and body shape is introduced which allows us to accurately model muscle deformations not only as a function of pose but also dependent on the physique of the subject. Coupled with the model's ability to generate arbitrary human body shapes. it severely simplifies the generation of highly realistic character animations. A learning based approach is trained on approximately 550 full body 3D laser scans taken of 114 subjects. Scan registration is performed using a non‐rigid deformation technique. Then. a rotation invariant encoding of the acquired exemplars permits the computation of a statistical model that simultaneously encodes pose and body …,True,qq3TxtcAAAAJ:IjCSPb-OGe4C,427,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01373.x,10239605762278802375,/scholar?cites=10239605762278802375,,,http://www.tnt.uni-hannover.de/papers/data/737/737_1.pdf,0,0,0
1277919,Optimization and filtering for human motion capture,2010,Juergen Gall and Bodo Rosenhahn and Thomas Brox and Hans-Peter Seidel,87,International journal of computer vision,1-2,75,Springer US,Local optimization and filtering have been widely applied to model-based 3D human motion capture. Global stochastic optimization has recently been proposed as promising alternative solution for tracking and initialization. In order to benefit from optimization and filtering. we introduce a multi-layer framework that combines stochastic optimization. filtering. and local optimization. While the first layer relies on interacting simulated annealing and some weak prior information on physical constraints. the second layer refines the estimates by filtering and local optimization such that the accuracy is increased and ambiguities are resolved over time without imposing restrictions on the dynamics. In our experimental evaluation. we demonstrate the significant improvements of the multi-layer framework and provide quantitative 3D pose tracking results for the complete HumanEva-II dataset. The paper further …,True,qq3TxtcAAAAJ:d1gkVwhDpl0C,300,https://link.springer.com/content/pdf/10.1007/s11263-008-0173-1.pdf,677391469445567173,/scholar?cites=677391469445567173,,,https://link.springer.com/content/pdf/10.1007/s11263-008-0173-1.pdf,0,0,0
1277920,Markerless motion capture with unsynchronized moving cameras,2009,Nils Hasler and Bodo Rosenhahn and Thorsten Thormahlen and Michael Wand and Jürgen Gall and Hans-Peter Seidel,,,,224-231,IEEE,In this work we present an approach for markerless motion capture (MoCap) of articulated objects. which are recorded with multiple unsynchronized moving cameras. Instead of using fixed (and expensive) hardware synchronized cameras. this approach allows us to track people with off-the-shelf handheld video cameras. To prepare a sequence for motion capture. we first reconstruct the static background and the position of each camera using Structure-from-Motion (SfM). Then the cameras are registered to each other using the reconstructed static background geometry. Camera synchronization is achieved via the audio streams recorded by the cameras in parallel. Finally. a markerless MoCap approach is applied to recover positions and joint configurations of subjects. Feature tracks and dense background geometry are further used to stabilize the MoCap. The experiments show examples with highly challenging …,True,qq3TxtcAAAAJ:qjMakFHDy7sC,228,https://ieeexplore.ieee.org/abstract/document/5206859/,7953488208240613775,/scholar?cites=7953488208240613775,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.5397&rep=rep1&type=pdf,0,0,0
1277921,Everybody needs somebody: Modeling social and grouping behavior on a linear programming multiple people tracker,2011,Laura Leal-Taixé and Gerard Pons-Moll and Bodo Rosenhahn,,,,120-127,IEEE,Multiple people tracking consists in detecting the subjects at each frame and matching these detections to obtain full trajectories. In semi-crowded environments. pedestrians often occlude each other. making tracking a challenging task. Most tracking methods make the assumption that each pedestrian's motion is independent. thereby ignoring the complex and important interaction between subjects. In this paper. we present an approach which includes the interaction between pedestrians in two ways: first. considering social and grouping behavior. and second. using a global optimization scheme to solve the data association problem. Results on three challenging publicly available datasets show our method outperforms state-of-the-art tracking systems.,True,qq3TxtcAAAAJ:ye4kPcJQO24C,207,https://ieeexplore.ieee.org/abstract/document/6130233/,18255859219262288253,/scholar?cites=18255859219262288253,,,https://core.ac.uk/download/pdf/205625811.pdf,0,0,0
1277922,Learning an image-based motion context for multiple people tracking,2014,Laura Leal-Taixé and Michele Fenzi and Alina Kuznetsova and Bodo Rosenhahn and Silvio Savarese,,,,3542-3549,,We present a novel method for multiple people tracking that leverages a generalized model for capturing interactions among individuals. At the core of our model lies a learned dictionary of interaction feature strings which capture relationships between the motions of targets. These feature strings. created from low-level image features. lead to a much richer representation of the physical interactions between targets compared to hand-specified social force models that previous works have introduced for tracking. One disadvantage of using social forces is that all pedestrians must be detected in order for the forces to be applied. while our method is able to encode the effect of undetected targets. making the tracker more robust to partial occlusions. The interaction feature strings are used in a Random Forest framework to track targets according to the features surrounding them. Results on six publicly available sequences show that our method outperforms state-of-the-art approaches in multiple people tracking.,True,qq3TxtcAAAAJ:PoWvk5oyLR8C,194,http://openaccess.thecvf.com/content_cvpr_2014/html/Leal-Taixe_Learning_an_Image-based_2014_CVPR_paper.html,90559932415684917,/scholar?cites=90559932415684917,,,https://openaccess.thecvf.com/content_cvpr_2014/papers/Leal-Taixe_Learning_an_Image-based_2014_CVPR_paper.pdf,0,0,0
1277923,Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics): Preface,2006,Masayuki Abe and Kazumaro Aoki and Giuseppe Ateniese and Roberto Avanzi and Zuzana Beerliová and Olivier Billet and Alex Biryukov and Ian Blake and Colin Boyd and Eric Brier and Aniello Castiglione and Juyoung Cha and Aldar Chan and Liqun Chen and Kookrae Cho and Scott Contini and Paolo D'Arco and Jintai Ding and Christophe Doche and Orr Dunkelman and Matthias Fitzi and Pierre Alain Fouque and Jacques JA Fournier and Kouichi Fujisaki and Eiichiro Fujisaki and Jun Furukawa and David Galindo and Shai Halevi and Helena Handschuh and Chris Heneghan and Thomas Holenstein and Fumitaka Hoshino and Yong Ho Hwang and Toshiyuki Isshiki and Ellen Jochemsz and Antoine Joux and Ari Juels and Charanjit Jutla and Aggelos Kiayias and Hiroaki Kikuchi and Tetsutarou Kobayashi and Tadayoshi Kohno and Hugo Krawczyk and Sandeep Kumar and Tanja Lange and Jung Wook Lee and Barbara Masucci and Alexander May and Miodrag Mihaljevic and Kazuhiko Minematsu and Fabian Monrose and Paul Montague and Steve Myers and David Naccache and Antonio Nicolosi and Satoshi Obana and Satomi Okazaki and Katsuyuki Okeya and Francis Olivier and Roger Oyono and Dan Page and Jung Hyung Park and Kun Peng and Krzysztof Pietrzak and Dominik Raub and Yasuyuki Sakai and Kouichi Sakurai and Werner Schindler and Jae Woo Seo and Jong Hoon Shin and Igor Shparlinski and Ron Steinfeld and Mike Szydlo and Yael Tauman Kalai and Isamu Teranishi and Toshio Tokita and Michael Tunstall and Frederik Vercauteren and Karine Villegas and Shabsi Walfish and Huaxiong Wang and Xiaofeng Wang and Bogdan Warinschi and Benne De Weger and Christopher Wolf and Alex Yampolskiy and Yeon Hyeong Yang and Yiqun Lisa Yin and Jeong Yoon and David Pointcheval,3960,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),,VI,Springer. Springer Nature,"Abe. Masayuki ; Aoki. Kazumaro ; Ateniese. Giuseppe ; Avanzi. Roberto ; Beerliová. Zuzana 
; Billet. Olivier ; Biryukov. Alex ; Blake. Ian ; Boyd. Colin ; Brier. Eric ; Castiglione. Aniello ; 
Cha. Juyoung ; Chan. Aldar ; Chen. Liqun ; Cho. Kookrae ; Contini. Scott ; D'Arco. Paolo ; 
Ding. Jintai ; Doche. Christophe ; Dunkelman. Orr ; Fitzi. Matthias ; Fouque. Pierre Alain ; 
Fournier. Jacques JA ; Fujisaki. Kouichi ; Fujisaki. Eiichiro ; Furukawa. Jun ; Galindo. David ; 
Halevi. Shai ; Handschuh. Helena ; Heneghan. Chris ; Holenstein. Thomas ; Hoshino. Fumitaka 
; Hwang. Yong Ho ; Isshiki. Toshiyuki ; Jochemsz. Ellen ; Joux. Antoine ; Juels. Ari ; Jutla. Charanjit 
; Kiayias. Aggelos ; Kikuchi. Hiroaki ; Kobayashi. Tetsutarou ; Kohno. Tadayoshi ; Krawczyk. Hugo 
; Kumar. Sandeep ; Lange. Tanja ; Lee. Jung Wook ; Masucci. Barbara ; May. Alexander ; 
Mihaljevic … Abe. M. Aoki. K. Ateniese. G. Avanzi. R. Beerliová. Z. Billet. O … ",True,qq3TxtcAAAAJ:AHdEip9mkN0C,177,https://researchers.mq.edu.au/en/publications/lecture-notes-in-computer-science-including-subseries-lecture-not-9,891504898664092026,/scholar?cites=891504898664092026,,,https://researchers.mq.edu.au/en/publications/lecture-notes-in-computer-science-including-subseries-lecture-not-9,0,0,0
1277924,Recovering accurate 3d human pose in the wild using imus and a moving camera,2018,Timo von Marcard and Roberto Henschel and Michael J Black and Bodo Rosenhahn and Gerard Pons-Moll,,,,601-617,,In this work. we propose a method that combines a single hand-held camera and a set of Inertial Measurement Units (IMUs) attached at the body limbs to estimate accurate 3D poses in the wild. This poses many new challenges: the moving camera. heading drift. cluttered background. occlusions and many people visible in the video. We associate 2D pose detections in each image to the corresponding IMU-equipped persons by solving a novel graph based optimization problem that forces 3D to 2D coherency within a frame and across long range frames. Given associations. we jointly optimize the pose of a statistical body model. the camera pose and heading drift using a continuous optimization framework. We validated our method on the TotalCapture dataset. which provides video and IMU synchronized with ground truth. We obtain an accuracy of 26mm. which makes it accurate enough to serve as a benchmark for image-based 3D pose estimation in the wild. Using our method. we recorded 3D Poses in the Wild (3DPW). a new dataset consisting of more than 51; 000 frames with accurate 3D pose in challenging sequences. including walking in the city. going up-stairs. having coffee or taking the bus. We make the reconstructed 3D poses. video. IMU and 3D models available for research purposes at http://virtualhumans. mpi-inf. mpg. de/3DPW.,True,qq3TxtcAAAAJ:PyEswDtIyv0C,173,http://openaccess.thecvf.com/content_ECCV_2018/html/Timo_von_Marcard_Recovering_Accurate_3D_ECCV_2018_paper.html,3991334045511862131,/scholar?cites=3991334045511862131,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Timo_von_Marcard_Recovering_Accurate_3D_ECCV_2018_paper.pdf,0,0,0
1277925,Complementary optic flow,2009,Henning Zimmer and Andrés Bruhn and Joachim Weickert and Levi Valgaerts and Agustín Salgado and Bodo Rosenhahn and Hans-Peter Seidel,,,,207-220,Springer. Berlin. Heidelberg,We introduce the concept of complementarity between data and smoothness term in modern variational optic flow methods. First we design a sophisticated data term that incorporates HSV colour representation with higher order constancy assumptions. completely separate robust penalisation. and constraint normalisation. Our anisotropic smoothness term reduces smoothing in the data constraint direction instead of the image edge direction. while enforcing a strong filling-in effect orthogonal to it. This allows optimal complementarity between both terms and avoids undesirable interference. The high quality of our complementary optic flow (COF) approach is demonstrated by the current top ranking result at the Middlebury benchmark.,True,qq3TxtcAAAAJ:Y0pCki6q_DkC,160,https://link.springer.com/chapter/10.1007/978-3-642-03641-5_16,14842514606388207564,/scholar?cites=14842514606388207564,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.399.1601&rep=rep1&type=pdf,0,0,0
1277926,Combined region and motion-based 3D tracking of rigid and articulated objects,2009,Thomas Brox and Bodo Rosenhahn and Juergen Gall and Daniel Cremers,32,IEEE transactions on pattern analysis and machine intelligence,3,402-415,IEEE,In this paper. we propose the combined use of complementary concepts for 3D tracking: region fitting on one side and dense optical flow as well as tracked SIFT features on the other. Both concepts are chosen such that they can compensate for the shortcomings of each other. While tracking by the object region can prevent the accumulation of errors. optical flow and SIFT can handle larger transformations. Whereas segmentation works best in case of homogeneous objects. optical flow computation and SIFT tracking rely on sufficiently structured objects. We show that a sensible combination yields a general tracking system that can be applied in a large variety of scenarios without the need to manually adjust weighting parameters.,True,qq3TxtcAAAAJ:kNdYIx-mwKoC,145,https://ieeexplore.ieee.org/abstract/document/4775902/,16061984026330107219,/scholar?cites=16061984026330107219,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.338.2220&rep=rep1&type=pdf,0,0,0
1277927,Three-dimensional shape knowledge for joint image segmentation and pose tracking,2007,Bodo Rosenhahn and Thomas Brox and Joachim Weickert,73,International Journal of Computer Vision,3,243-262,Kluwer Academic Publishers,In this article we present the integration of 3-D shape knowledge into a variational model for level set based image segmentation and contour based 3-D pose tracking. Given the surface model of an object that is visible in the image of one or multiple cameras calibrated to the same world coordinate system. the object contour extracted by the segmentation method is applied to estimate the 3-D pose parameters of the object. Vice-versa. the surface model projected to the image plane helps in a top-down manner to improve the extraction of the contour. While common alternative segmentation approaches. which integrate 2-D shape knowledge. face the problem that an object can look very differently from various viewpoints. a 3-D free form model ensures that for each view the model can fit the data in the image very well. Moreover. one additionally solves the problem of determining the object’s pose in 3-D …,True,qq3TxtcAAAAJ:u5HHmVD_uO8C,145,https://link.springer.com/content/pdf/10.1007/s11263-006-9965-3.pdf,3565594043807897692,/scholar?cites=3565594043807897692,,,https://researchspace.auckland.ac.nz/bitstream/handle/2292/2808/CITR-TR-163.pdf?sequence=1&isAllowed=y,0,0,0
1277928,XMIPP: a new generation of an open-source image processing package for electron microscopy,2004,COS Sorzano and Roberto Marabini and Javier Velázquez-Muriel and José Román Bilbao-Castro and Sjors HW Scheres and José M Carazo and Alberto Pascual-Montano,148,Journal of structural biology,2,194-204,Academic Press,X-windows based microscopy image processing package (Xmipp) is a specialized suit of image processing programs. primarily aimed at obtaining the 3D reconstruction of biological specimens from large sets of projection images acquired by transmission electron microscopy. This public-domain software package was introduced to the electron microscopy field eight years ago. and since then it has changed drastically. New methodologies for the analysis of single-particle projection images have been added to classification. contrast transfer function correction. angular assignment. 3D reconstruction. reconstruction of crystals. etc. In addition. the package has been extended with functionalities for 2D crystal and electron tomography data. Furthermore. its current implementation in C++. with a highly modular design of well-documented data structures and functions. offers a convenient environment for the …,True,mBOfiXwAAAAJ:NMxIlDl6LWMC,483,https://www.sciencedirect.com/science/article/pii/S1047847704001261,5374789044941436492,/scholar?cites=5374789044941436492,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.7851&rep=rep1&type=pdf,0,0,0
1277929,Image processing for electron microscopy single-particle analysis using XMIPP,2008,Sjors HW Scheres and Rafael Núñez-Ramírez and Carlos OS Sorzano and José María Carazo and Roberto Marabini,3,Nature protocols,6,977-990,Nature Publishing Group,We describe a collection of standardized image processing protocols for electron microscopy single-particle analysis using the XMIPP software package. These protocols allow performing the entire processing workflow starting from digitized micrographs up to the final refinement and evaluation of 3D models. A particular emphasis has been placed on the treatment of structurally heterogeneous data through maximum-likelihood refinements and self-organizing maps as well as the generation of initial 3D models for such data sets through random conical tilt reconstruction methods. All protocols presented have been implemented as stand-alone. executable python scripts. for which a dedicated graphical user interface has been developed. Thereby. they may provide novice users with a convenient tool to quickly obtain useful results with minimum efforts in learning about the details of this comprehensive package …,True,mBOfiXwAAAAJ:GnPB-g6toBAC,347,https://www.nature.com/nprot/journal/v3/n6/abs/nprot.2008.62.html,4882469946110875511,/scholar?cites=4882469946110875511,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2778070/,0,0,0
1277930,Elastic registration of biological images using vector-spline regularization,2005,Carlos Oscar Sánchez Sorzano and Philippe Thévenaz and Michael Unser,52,IEEE Transactions on Biomedical Engineering,4,652-663,IEEE,We present an elastic registration algorithm for the alignment of biological images. Our method combines and extends some of the best techniques available in the context of medical imaging. We express the deformation field as a B-spline model. which allows us to deal with a rich variety of deformations. We solve the registration problem by minimizing a pixelwise mean-square distance measure between the target image and the warped source. The problem is further constrained by way of a vector-spline regularization which provides some control over two independent quantities that are intrinsic to the deformation: its divergence. and its curl. Our algorithm is also able to handle soft landmark constraints. which is particularly useful when parts of the images contain very little information or when its repartition is uneven. We provide an optimal analytical solution in the case when only landmarks and smoothness …,True,mBOfiXwAAAAJ:YFjsv_pBGBYC,335,https://ieeexplore.ieee.org/abstract/document/1408122/,15090321215587048314,/scholar?cites=15090321215587048314,,,https://infoscience.epfl.ch/record/63130/files/sorzano0501.pdf,0,0,0
1277931,TomoJ: tomography software for three-dimensional reconstruction in transmission electron microscopy,2007,Cédric MessaoudiI and Thomas Boudier and Carlos Oscar Sanchez Sorzano and Sergio Marco,8,BMC bioinformatics,1,1-9,BioMed Central,Transmission electron tomography is an increasingly common three-dimensional electron microscopy approach that can provide new insights into the structure of subcellular components. Transmission electron tomography fills the gap between high resolution structural methods (X-ray diffraction or nuclear magnetic resonance) and optical microscopy. We developed new software for transmission electron tomography. TomoJ. TomoJ is a plug-in for the now standard image analysis and processing software for optical microscopy. ImageJ. TomoJ provides a user-friendly interface for alignment. reconstruction. and combination of multiple tomographic volumes and includes the most recent algorithms for volume reconstructions used in three-dimensional electron microscopy (the algebraic reconstruction technique and simultaneous iterative reconstruction technique) as well as the commonly used approach of weighted …,True,mBOfiXwAAAAJ:2osOgNQ5qMEC,299,https://link.springer.com/article/10.1186/1471-2105-8-288,11175713590441460836,/scholar?cites=11175713590441460836,,,https://link.springer.com/article/10.1186/1471-2105-8-288,0,0,0
1277932,Consistent and elastic registration of histological sections using vector-spline regularization,2006,Ignacio Arganda-Carreras and Carlos OS Sorzano and Roberto Marabini and José María Carazo and Carlos Ortiz-de-Solorzano and Jan Kybic,,,,85-95,Springer. Berlin. Heidelberg,Here we present a new image registration algorithm for the alignment of histological sections that combines the ideas of B-spline based elastic registration and consistent image registration. to allow simultaneous registration of images in two directions (direct and inverse). In principle. deformations based on B-splines are not invertible. The consistency term overcomes this limitation and allows registration of two images in a completely symmetric way. This extension of the elastic registration method simplifies the search for the optimum deformation and allows registering with no information about landmarks or deformation regularization. This approach can also be used as the first step to solve the problem of group-wise registration.,True,mBOfiXwAAAAJ:O3NaXMp0MMsC,285,https://link.springer.com/chapter/10.1007/11889762_8,2032846152273746634,/scholar?cites=2032846152273746634,,,https://repositorio.uam.es/bitstream/handle/10486/666430/consistent_arganda-carreras_LNCS_2006_ps.pdf?sequence=1,0,0,0
1277933,Maximum-likelihood multi-reference refinement for electron microscopy images,2005,Sjors HW Scheres and Mikel Valle and Rafael Nuñez and Carlos OS Sorzano and Roberto Marabini and Gabor T Herman and Jose-Maria Carazo,348,Journal of molecular biology,1,139-149,Academic Press,A maximum-likelihood approach to multi-reference image refinement is presented. In contrast to conventional cross-correlation refinement. the new approach includes a formal description of the noise. implying that it is especially suited to cases with low signal-to-noise ratios. Application of this approach to a cryo-electron microscopy dataset revealed two major classes for projections of simian virus 40 large T-antigen in complex with an asymmetric DNA-probe. containing the origin of simian virus 40 replication. Strongly bent projections of dodecamers showed density that may be attributed to the complexed double-stranded DNA. while almost straight projections revealed a twist in the relative orientation of the hexameric subunits. This new level of detail for large T-antigen projections was not detected using conventional techniques. For a negative stain dataset. maximum-likelihood refinement yielded results that …,True,mBOfiXwAAAAJ:BqipwSGYUEgC,279,https://www.sciencedirect.com/science/article/pii/S0022283605001932,5231725084156822741,/scholar?cites=5231725084156822741,,,https://www.academia.edu/download/42892774/Scheres2005b.pdf,0,0,0
1277934,Scipion: A software framework toward integration. reproducibility and validation in 3D electron microscopy,2016,JM De la Rosa-Trevín and A Quintana and L Del Cano and A Zaldívar and I Foche and J Gutiérrez and J Gómez-Blanco and J Burguet-Castell and J Cuenca-Alba and V Abrishami and J Vargas and J Otón and G Sharov and JL Vilas and J Navas and P Conesa and M Kazemi and R Marabini and COS Sorzano and JM Carazo,195,Journal of structural biology,1,93-99,Academic Press,In the past few years. 3D electron microscopy (3DEM) has undergone a revolution in instrumentation and methodology. One of the central players in this wide-reaching change is the continuous development of image processing software. Here we present Scipion. a software framework for integrating several 3DEM software packages through a workflow-based approach. Scipion allows the execution of reusable. standardized. traceable and reproducible image-processing protocols. These protocols incorporate tools from different programs while providing full interoperability among them. Scipion is an open-source project that can be downloaded from http://scipion.cnb.csic.es.,True,mBOfiXwAAAAJ:t_XbbNNkFXoC,261,https://www.sciencedirect.com/science/article/pii/S104784771630079X,9188076317205685217,/scholar?cites=9188076317205685217,,,https://repositorio.uam.es/bitstream/handle/10486/681439/rosa_trevi_jose_miguel_de_la.pdf?sequence=1,0,0,0
1277935,A survey of dimensionality reduction techniques,2014,Carlos Oscar Sánchez Sorzano and Javier Vargas and A Pascual Montano,,,,,,Experimental life sciences like biology or chemistry have seen in the recent decades an explosion of the data available from experiments. Laboratory instruments become more and more complex and report hundreds or thousands measurements for a single experiment and therefore the statistical methods face challenging tasks when dealing with such high dimensional data. However. much of the data is highly redundant and can be efficiently brought down to a much smaller number of variables without a significant loss of information. The mathematical procedures making possible this reduction are called dimensionality reduction techniques; they have widely been developed by fields like Statistics or Machine Learning. and are currently a hot research topic. In this review we categorize the plethora of dimension reduction techniques available and give the mathematical insight behind them.,True,mBOfiXwAAAAJ:_B80troHkn4C,230,https://arxiv.org/abs/1403.2877,12552891726953371223,/scholar?cites=12552891726953371223,,,https://arxiv.org/pdf/1403.2877,0,0,0
1277936,Xmipp 3.0: an improved software suite for image processing in electron microscopy,2013,JM De la Rosa-Trevín and J Otón and R Marabini and A Zaldivar and J Vargas and JM Carazo and COS Sorzano,184,Journal of structural biology,2,321-328,Academic Press,Xmipp is a specialized software package for image processing in electron microscopy. and that is mainly focused on 3D reconstruction of macromolecules through single-particles analysis. In this article we present Xmipp 3.0. a major release which introduces several improvements and new developments over the previous version. A central improvement is the concept of a project that stores the entire processing workflow from data import to final results. It is now possible to monitor. reproduce and restart all computing tasks as well as graphically explore the complete set of interrelated tasks associated to a given project. Other graphical tools have also been improved such as data visualization. particle picking and parameter “wizards” that allow the visual selection of some key parameters. Many standard image formats are transparently supported for input/output from all programs. Additionally. results have been …,True,mBOfiXwAAAAJ:mvPsJ3kp5DgC,207,https://www.sciencedirect.com/science/article/pii/S1047847713002566,17991157118165312584,/scholar?cites=17991157118165312584,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.473.9318&rep=rep1&type=pdf,0,0,0
1277937,A clustering approach to multireference alignment of single-particle projections in electron microscopy,2010,Carlos Oscar S Sorzano and JR Bilbao-Castro and Y Shkolnisky and M Alcorlo and R Melero and G Caffarena-Fernández and M Li and G Xu and R Marabini and JM Carazo,171,Journal of structural biology,2,197-206,Academic Press,Two-dimensional analysis of projections of single-particles acquired by an electron microscope is a useful tool to help identifying the different kinds of projections present in a dataset and their different projection directions. Such analysis is also useful to distinguish between different kinds of particles or different particle conformations. In this paper we introduce a new algorithm for performing two-dimensional multireference alignment and classification that is based on a Hierarchical clustering approach using correntropy (instead of the more traditional correlation) and a modified criterion for the definition of the clusters specially suited for cases in which the Signal-to-Noise Ratio of the differences between classes is low. We show that our algorithm offers an improved sensitivity over current methods in use for distinguishing between different projection orientations and different particle conformations. This algorithm is …,True,mBOfiXwAAAAJ:qxL8FJ1GzNcC,195,https://www.sciencedirect.com/science/article/pii/S1047847710000882,10113841089811165535,/scholar?cites=10113841089811165535,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2893300/,0,0,0
1277938,BRANCHED1 promotes axillary bud dormancy in response to shade in Arabidopsis,2013,Eduardo González-Grandío and César Poza-Carrión and Carlos Oscar S Sorzano and Pilar Cubas,25,The Plant Cell,3,834-850,American Society of Plant Biologists,Plants interpret a decrease in the red to far-red light ratio (R:FR) as a sign of impending shading by neighboring vegetation. This triggers a set of developmental responses known as shade avoidance syndrome. One of these responses is reduced branching through suppression of axillary bud outgrowth. The Arabidopsis thaliana gene BRANCHED1 (BRC1). expressed in axillary buds. is required for branch suppression in response to shade. Unlike wild-type plants. brc1 mutants develop several branches after a shade treatment. BRC1 transcription is positively regulated 4 h after exposure to low R:FR. Consistently. BRC1 is negatively regulated by phytochrome B. Transcriptional profiling of wild-type and brc1 buds of plants treated with simulated shade has revealed groups of genes whose mRNA levels are dependent on BRC1. among them a set of upregulated abscisic acid response genes and two networks of cell …,True,mBOfiXwAAAAJ:tOudhMTPpwUC,161,http://www.plantcell.org/content/25/3/834.short,922511903317730956,/scholar?cites=922511903317730956,,,http://www.plantcell.org/content/plantcell/25/3/834.full.pdf,0,0,0
1277939,Guidelines for the use and interpretation of assays for monitoring autophagy (4th edition)1,2021,Daniel J Klionsky and Amal Kamal Abdel-Aziz and Sara Abdelfatah and Mahmoud Abdellatif and Asghar Abdoli and Steffen Abel and Hagai Abeliovich and Marie H Abildgaard and Yakubu Princely Abudu and Abraham Acevedo-Arozena and Iannis E Adamopoulos and Khosrow Adeli and Timon E Adolph and Annagrazia Adornetto and Elma Aflaki and Galila Agam and Anupam Agarwal and Bharat B Aggarwal and Maria Agnello and Patrizia Agostinis and Javed N Agrewala and Alexander Agrotis and Patricia V Aguilar and S Tariq Ahmad and Zubair M Ahmed and Ulises Ahumada-Castro and Sonja Aits and Shu Aizawa and Yunus Akkoc and Tonia Akoumianaki and Hafize Aysin Akpinar and Ahmed M Al-Abd and Lina Al-Akra and Abeer Al-Gharaibeh and Moulay A Alaoui-Jamali and Simon Alberti and Elísabet Alcocer-Gómez and Cristiano Alessandri and Muhammad Ali and M Abdul Alim Al-Bari and Saeb Aliwaini and Javad Alizadeh and Eugènia Almacellas and Alexandru Almasan and Alicia Alonso and Guillermo D Alonso and Nihal Altan-Bonnet and Dario C Altieri and Élida MC Álvarez and Sara Alves and Cristine Alves da Costa and Mazen M Alzaharna and Marialaura Amadio and Consuelo Amantini and Cristina Amaral and Susanna Ambrosio and Amal O Amer and Veena Ammanathan and Zhenyi An and Stig U Andersen and Shaida A Andrabi and Magaiver Andrade-Silva and Allen M Andres and Sabrina Angelini and David Ann and Uche C Anozie and Mohammad Y Ansari and Pedro Antas and Adam Antebi and Zuriñe Antón and Tahira Anwar and Lionel Apetoh and Nadezda Apostolova and Toshiyuki Araki and Yasuhiro Araki and Kohei Arasaki and Wagner L Araújo and Jun Araya and Catherine Arden and Maria-Angeles Arévalo and Sandro Arguelles and Esperanza Arias and Jyothi Arikkath and Hirokazu Arimoto and Aileen R Ariosa and Darius Armstrong-James and Laetitia Arnauné-Pelloquin and Angeles Aroca and Daniela S Arroyo and Ivica Arsov and Rubén Artero and Dalia Maria Lucia Asaro and Michael Aschner and Milad Ashrafizadeh and Osnat Ashur-Fabian and Atanas G Atanasov and Alicia K Au and Patrick Auberger and Holger W Auner and Laure Aurelian and Riccardo Autelli and Laura Avagliano and Yenniffer Ávalos and Sanja Aveic and Célia Alexandra Aveleira and Tamar Avin-Wittenberg and Yucel Aydin and Scott Ayton and Srinivas Ayyadevara and Maria Azzopardi and Misuzu Baba and Jonathan M Backer and Steven K Backues and Dong-Hun Bae and Ok-Nam Bae and Soo Han Bae and Eric H Baehrecke and Ahruem Baek and Seung-Hoon Baek and Sung Hee Baek and Giacinto Bagetta and Agnieszka Bagniewska-Zadworna and Hua Bai and Jie Bai and Xiyuan Bai and Yidong Bai and Nandadulal Bairagi and Shounak Baksi and Teresa Balbi and Cosima T Baldari and Walter Balduini and Andrea Ballabio and Maria Ballester and Salma Balazadeh and Rena Balzan and Rina Bandopadhyay and Sreeparna Banerjee and Sulagna Banerjee and Ágnes Bánréti and Yan Bao and Mauricio S Baptista and Alessandra Baracca and Cristiana Barbati and Ariadna Bargiela and Daniela Barilà and Peter G Barlow and Sami J Barmada and Esther Barreiro and George E Barreto and Jiri Bartek,17,,1,1-382,Taylor & Francis,In 2008. we published the first set of guidelines for standardizing research in autophagy. Since then. this topic has received increasing attention. and many scientists have entered the field. Our knowledge base and relevant new technologies have also been expanding. Thus. it is important to formulate on a regular basis updated guidelines for monitoring autophagy in different organisms. Despite numerous reviews. there continues to be confusion regarding acceptable methods to evaluate autophagy. especially in multicellular eukaryotes. Here. we present a set of guidelines for investigators to select and interpret methods to examine autophagy and related processes. and for reviewers to provide realistic and reasonable critiques of reports that are focused on these processes. These guidelines are not meant to be a dogmatic set of rules. because the appropriateness of any assay largely depends on the question …,True,A74U1LwAAAAJ:1taIhTC69MYC,7373,https://www.tandfonline.com/doi/abs/10.1080/15548627.2020.1797280,5466665393835199140,/scholar?cites=5466665393835199140,,,https://www.tandfonline.com/doi/pdf/10.1080/15548627.2015.1100356?needAccess=true&,0,0,0
1277940,Kinetochore-localized PP1–Sds22 couples chromosome segregation to polar relaxation,2015,Nelio TL Rodrigues and Sergey Lekomtsev and Silvana Jananji and Janos Kriston-Vizi and Gilles RX Hickson and Buzz Baum,524,Nature,7566,489-492,Nature Publishing Group,Cell division requires the precise coordination of chromosome segregation and cytokinesis. This coordination is achieved by the recruitment of an actomyosin regulator. Ect2. to overlapping microtubules at the centre of the elongating anaphase spindle 1. Ect2 then signals to the overlying cortex to promote the assembly and constriction of an actomyosin ring between segregating chromosomes 1. Here. by studying division in proliferating Drosophila and human cells. we demonstrate the existence of a second. parallel signalling pathway. which triggers the relaxation of the polar cell cortex at mid anaphase. This is independent of furrow formation. centrosomes and microtubules and. instead. depends on PP1 phosphatase and its regulatory subunit Sds22 (refs 2. 3). As separating chromosomes move towards the polar cortex at mid anaphase. kinetochore-localized PP1–Sds22 helps to break cortical symmetry by …,True,A74U1LwAAAAJ:gKiMpY-AVTkC,81,https://www.nature.com/articles/nature14496,6530339520239595603,/scholar?cites=6530339520239595603,,,https://discovery.ucl.ac.uk/id/eprint/1470483/1/Baum_AAM.pdf,0,0,0
1277941,A two-tier Golgi-based control of organelle size underpins the functional plasticity of endothelial cells,2014,Francesco Ferraro and Janos Kriston-Vizi and Daniel J Metcalf and Belen Martin-Martin and Jamie Freeman and Jemima J Burden and David Westmoreland and Clare E Dyer and Alex E Knight and Robin Ketteler and Daniel F Cutler,29,Developmental cell,3,292-304,Cell Press,Weibel-Palade bodies (WPBs). endothelial-specific secretory granules that are central to primary hemostasis and inflammation. occur in dimensions ranging between 0.5 and 5 μm. How their size is determined and whether it has a functional relevance are at present unknown. Here. we provide evidence for a dual role of the Golgi apparatus in controlling the size of these secretory carriers. At the ministack level. cisternae constrain the size of nanostructures (“quanta”) of von Willebrand factor (vWF). the main WPB cargo. The ribbon architecture of the Golgi then allows copackaging of a variable number of vWF quanta within the continuous lumen of the trans-Golgi network. thereby generating organelles of different sizes. Reducing the WPB size abates endothelial cell hemostatic function by drastically diminishing platelet recruitment. but. strikingly. the inflammatory response (the endothelial capacity to engage …,True,A74U1LwAAAAJ:3fE2CSJIrl8C,66,https://www.sciencedirect.com/science/article/pii/S1534580714001956,9186012706291476128,/scholar?cites=9186012706291476128,,,https://www.sciencedirect.com/science/article/pii/S1534580714001956,0,0,0
1277942,Aberrant α-adrenergic hypertrophic response in cardiomyocytes from human induced pluripotent cells,2014,Gabor Földes and Elena Matsa and János Kriston-Vizi and Thomas Leja and Stefan Amisten and Ljudmila Kolker and Thusharika Kodagoda and Nazanin F Dolatshad and Maxime Mioulane and Karine Vauchez and Tamás Arányi and Robin Ketteler and Michael D Schneider and Chris Denning and Sian E Harding,3,Stem cell reports,5,905-914,Cell Press,Cardiomyocytes from human embryonic stem cells (hESC-CMs) and induced pluripotent stem cells (hiPSC-CMs) represent new models for drug discovery. Although hypertrophy is a high-priority target. we found that hiPSC-CMs were systematically unresponsive to hypertrophic signals such as the α-adrenoceptor (αAR) agonist phenylephrine (PE) compared to hESC-CMs. We investigated signaling at multiple levels to understand the underlying mechanism of this differential responsiveness. The expression of the normal α1AR gene. ADRA1A. was reversibly silenced during differentiation. accompanied by ADRA1B upregulation in either cell type. ADRA1B signaling was intact in hESC-CMs. but not in hiPSC-CMs. We observed an increased tonic activity of inhibitory kinase pathways in hiPSC-CMs. and inhibition of antihypertrophic kinases revealed hypertrophic increases. There is tonic suppression of cell growth in …,True,A74U1LwAAAAJ:gVv57TyPmFsC,42,https://www.sciencedirect.com/science/article/pii/S2213671114002872,15724008648012374540,/scholar?cites=15724008648012374540,,,https://www.sciencedirect.com/science/article/pii/S2213671114002872,0,0,0
1277943,Sustained E2F-dependent transcription is a key mechanism to prevent replication-stress-induced DNA damage,2016,Cosetta Bertoli and Anna E Herlihy and Betheney R Pennycook and Janos Kriston-Vizi and Robertus AM de Bruin,15,Cell reports,7,1412-1422,Cell Press,Recent work established DNA replication stress as a crucial driver of genomic instability and a key event at the onset of cancer. Post-translational modifications play an important role in the cellular response to replication stress by regulating the activity of key components to prevent replication-stress-induced DNA damage. Here. we establish a far greater role for transcriptional control in determining the outcome of replication-stress-induced events than previously suspected. Sustained E2F-dependent transcription is both required and sufficient for many crucial checkpoint functions. including fork stalling. stabilization. and resolution. Importantly. we also find that. in the context of oncogene-induced replication stress. where increased E2F activity is thought to cause replication stress. E2F activity is required to limit levels of DNA damage. These data suggest a model in which cells experiencing oncogene-induced …,True,A74U1LwAAAAJ:F1b5ZUV5XREC,41,https://www.sciencedirect.com/science/article/pii/S2211124716304636,904378714140111583,/scholar?cites=904378714140111583,,,https://www.sciencedirect.com/science/article/pii/S2211124716304636,0,0,0
1277944,Regulation of post-Golgi LH3 trafficking is essential for collagen homeostasis,2016,Blerida Banushi and Federico Forneris and Anna Straatman-Iwanowska and Adam Strange and Anne-Marie Lyne and Clare Rogerson and Jemima J Burden and Wendy E Heywood and Joanna Hanley and Ivan Doykov and Kornelis R Straatman and Holly Smith and Danai Bem and Janos Kriston-Vizi and Gema Ariceta and Maija Risteli and Chunguang Wang and Rosalyn E Ardill and Marcin Zaniew and Julita Latka-Grot and Simon N Waddington and SJ Howe and Francesco Ferraro and Asllan Gjinovci and Scott Lawrence and Mark Marsh and Mark Girolami and Laurent Bozec and Kevin Mills and Paul Gissen,7,Nature communications,1,1-14,Nature Publishing Group,Post-translational modifications are necessary for collagen precursor molecules (procollagens) to acquire final shape and function. However. the mechanism and contribution of collagen modifications that occur outside the endoplasmic reticulum and Golgi are not understood. We discovered that VIPAR. with its partner proteins. regulate sorting of lysyl hydroxylase 3 (LH3. also known as PLOD3) into newly identified post-Golgi collagen IV carriers and that VIPAR-dependent sorting is essential for modification of lysines in multiple collagen types. Identification of structural and functional collagen abnormalities in cells and tissues from patients and murine models of the autosomal recessive multisystem disorder Arthrogryposis. Renal dysfunction and Cholestasis syndrome caused by VIPAR and VPS33B deficiencies confirmed our findings. Thus. regulation of post-Golgi LH3 trafficking is essential for collagen …,True,A74U1LwAAAAJ:2tRrZ1ZAMYUC,40,https://www.nature.com/articles/ncomms12111,1738987665551686403,/scholar?cites=1738987665551686403,,,https://www.nature.com/articles/ncomms12111,0,0,0
1277945,Molecular signatures of regression of the canine transmissible venereal tumor,2018,Dan Frampton and Hagen Schwenzer and Gabriele Marino and Lee M Butcher and Gabriele Pollara and Janos Kriston-Vizi and Cristina Venturini and Rachel Austin and Karina Ferreira de Castro and Robin Ketteler and Benjamin Chain and Richard A Goldstein and Robin A Weiss and Stephan Beck and Ariberto Fassati,33,Cancer cell,4,620-633. e6,Cell Press,The canine transmissible venereal tumor (CTVT) is a clonally transmissible cancer that regresses spontaneously or after treatment with vincristine. but we know little about the regression mechanisms. We performed global transcriptional. methylation. and functional pathway analyses on serial biopsies of vincristine-treated CTVTs and found that regression occurs in sequential steps; activation of the innate immune system and host epithelial tissue remodeling followed by immune infiltration of the tumor. arrest in the cell cycle. and repair of tissue damage. We identified CCL5 as a possible driver of CTVT regression. Changes in gene expression are associated with methylation changes at specific intragenic sites. Our results underscore the critical role of host innate immunity in triggering cancer regression.,True,A74U1LwAAAAJ:jgBuDB5drN8C,35,https://www.sciencedirect.com/science/article/pii/S1535610818300710,14896221479259146281,/scholar?cites=14896221479259146281,,,https://www.sciencedirect.com/science/article/pii/S1535610818300710,0,0,0
1277946,Assessment of the water status of mandarin and peach canopies using visible multispectral imagery,2008,János Kriston-Vizi and Mikio Umeda and Kumi Miyamoto,100,Biosystems Engineering,3,338-345,Academic Press,The production of high-quality mandarin or peach fruits depends on the ability to maintain an optimal level of water stress in the plant during the sugar accumulation period. This study investigates the use of visible imaging for monitoring water stress. Experiments were conducted on satsuma mandarin (Citrus unshiu Marc. var. Satsuma) and peach (Persica vulgaris Mill.) in south-western Japan. Water stress was induced using plastic mulching at the field scale. Images of crop leaves as well as orchard canopy were taken in near-infrared (760–900 nm). red (580–680 nm) and green (490–580 nm) spectral channels for 6 days. Neutral Grey Card was used as the reflectance standard and leaf water potential was the monitored crop parameter. A reflectance difference was found between water-stressed and non-water-stressed mandarin and peach plants in red and green spectral channels both at the individual leaf level …,True,A74U1LwAAAAJ:u5HHmVD_uO8C,27,https://www.sciencedirect.com/science/article/pii/S1537511008001128,6518179768960687174,/scholar?cites=6518179768960687174,,,https://discovery.ucl.ac.uk/id/eprint/1338367/1/manuscript.pdf,0,0,0
1277947,Weibel-Palade body size modulates the adhesive activity of its von Willebrand Factor cargo in cultured endothelial cells,2016,Francesco Ferraro and Mafalda Lopes Da Silva and William Grimes and Hwee Kuan Lee and Robin Ketteler and Janos Kriston-Vizi and Daniel F Cutler,6,Scientific reports,1,1-15,Nature Publishing Group,Changes in the size of cellular organelles are often linked to modifications in their function. Endothelial cells store von Willebrand Factor (vWF). a glycoprotein essential to haemostasis in Weibel-Palade bodies (WPBs). cigar-shaped secretory granules that are generated in a wide range of sizes. We recently showed that forcing changes in the size of WPBs modifies the activity of this cargo. We now find that endothelial cells treated with statins produce shorter WPBs and that the vWF they release at exocytosis displays a reduced capability to recruit platelets to the endothelial cell surface. Investigating other functional consequences of size changes of WPBs. we also report that the endothelial surface-associated vWF formed at exocytosis recruits soluble plasma vWF and that this process is reduced by treatments that shorten WPBs. statins included. These results indicate that the post-exocytic adhesive activity of vWF …,True,A74U1LwAAAAJ:sJsF-0ZLhtgC,26,https://www.nature.com/articles/srep32473?origin=ppub,7456584978478991854,/scholar?cites=7456584978478991854,,,https://www.nature.com/articles/srep32473?origin=ppub,0,0,0
1277948,A single cell high content assay detects mitochondrial dysfunction in iPSC-derived neurons with mutations in SNCA,2018,Daniel Little and Christin Luft and Olukunbi Mosaku and Maëlle Lorvellec and Zhi Yao and Sébastien Paillusson and Janos Kriston-Vizi and Sonia Gandhi and Andrey Y Abramov and Robin Ketteler and Michael J Devine and Paul Gissen,8,Scientific reports,1,1-16,Nature Publishing Group,Mitochondrial dysfunction is implicated in many neurodegenerative diseases including Parkinson’s disease (PD). Induced pluripotent stem cells (iPSCs) provide a unique cell model for studying neurological diseases. We have established a high-content assay that can simultaneously measure mitochondrial function. morphology and cell viability in iPSC-derived dopaminergic neurons. iPSCs from PD patients with mutations in SNCA and unaffected controls were differentiated into dopaminergic neurons. seeded in 384-well plates and stained with the mitochondrial membrane potential dependent dye TMRM. alongside Hoechst-33342 and Calcein-AM. Images were acquired using an automated confocal screening microscope and single cells were analysed using automated image analysis software. PD neurons displayed reduced mitochondrial membrane potential and altered mitochondrial morphology compared …,True,A74U1LwAAAAJ:zCSUwVk65WsC,25,https://www.nature.com/articles/s41598-018-27058-0,12214035635438313049,/scholar?cites=12214035635438313049,,,https://www.nature.com/articles/s41598-018-27058-0,0,0,0
1277949,Salmonella exploits HLA-B27 and host unfolded protein responses to promote intracellular replication,2019,Antony Nicodemus Antoniou and Izabela Lenart and Janos Kriston-Vizi and Takao Iwawaki and Mark Turmaine and Kirsty McHugh and Sadfer Ali and Neil Blake and Paul Bowness and Mona Bajaj-Elliott and Keith Gould and Darren Nesbeth and Simon J Powis,78,Annals of the rheumatic diseases,1,74-82,BMJ Publishing Group Ltd,Salmonella enterica infections can lead to Reactive Arthritis (ReA). which can exhibit an association with human leucocyte antigen (HLA)-B*27:05. a molecule prone to misfolding and initiation of the unfolded protein response (UPR). This study examined how HLA-B*27:05 expression and the UPR affect the Salmonella life-cycle within epithelial cells.Isogenic epithelial cell lines expressing two copies of either HLA-B*27:05 and a control HLA-B*35:01 heavy chain (HC) were generated to determine the effect on the Salmonella infection life-cycle. A cell line expressing HLA-B*27:05.HC physically linked to the light chain beta-2-microglobulin and a specific peptide (referred to as a single chain trimer. SCT) was also generated to determine the effects of HLA-B27 folding status on S.enterica life-cycle. XBP-1 venus and AMP dependent Transcription Factor (ATF6)-FLAG reporters were used to monitor …,True,A74U1LwAAAAJ:BzfGm06jWhQC,23,https://ard.bmj.com/content/78/1/74.abstract,7309241869289718492,/scholar?cites=7309241869289718492,,,https://ard.bmj.com/content/78/1/74.abstract,0,0,0
1277950,Digital image warping,1990,George Wolberg,10662,,,90720-1264,IEEE computer society press,The text also describes various common formulas for spatial information. discusses sampling theory and filtering problems. explores image resampling along with several common interpolation kernels. investigates antialiasing. and presents fast warping techniques that are based on scanline algorithms. In addition. Digital¡ mage Warping includes 36 color photographs and contains informative sections on image reconstruction. real-time texture mapping. separable algorithms. 2-pass transforms. mesh warping. and special effects.340 pages. July 1990. Hardbound. Color. ISBN 0-8186-8944-7. Catalog# 1944.,True,KyXgRdQAAAAJ:d1gkVwhDpl0C,2395,https://ieeexplore.ieee.org/iel1/38/3878/x0339023.pdf,16945839113757741988,/scholar?cites=16945839113757741988,,,,0,0,0
1277951,Scattered data interpolation with multilevel B-splines,1997,Seungyong Lee and George Wolberg and Sung Yong  Shin,3,IEEE transactions on visualization and computer graphics,3,228-244,IEEE,The paper describes a fast algorithm for scattered data interpolation and approximation. Multilevel B-splines are introduced to compute a C/sup 2/ continuous surface through a set of irregularly spaced points. The algorithm makes use of a coarse to fine hierarchy of control lattices to generate a sequence of bicubic B-spline functions whose sum approaches the desired interpolation function. Large performance gains are realized by using B-spline refinement to reduce the sum of these functions into one equivalent B-spline function. Experimental results demonstrate that high fidelity reconstruction is possible from a selected set of sparse and irregular samples.,True,KyXgRdQAAAAJ:9yKSN-GCB0IC,1255,https://ieeexplore.ieee.org/abstract/document/620490/,2363114116898670348,/scholar?cites=2363114116898670348,,,https://www.researchgate.net/profile/George_Wolberg/publication/3410822_Scattered_Data_Interpolation_with_Multilevel_B-Splines/links/00b49518719ac9f08a000000/Scattered-Data-Interpolation-with-Multilevel-B-Splines.pdf,0,0,0
1277952,Image morphing: a survey,1998,George Wolberg,14,,8,360-372,Springer-Verlag,Image morphing has received much attention in recent years. It has proven to be a powerful tool for visual effects in film and television. enabling the fluid transformation of one digital image into another. This paper surveys the growth of this field and describes recent advances in image morphing in terms of feature specification. warp generation methods. and transition control. These areas relate to the ease of use and quality of results. We describe the role of radial basis functions. thin plate splines. energy minimization. and multilevel free-form deformations in advancing the state-of-the-art in image morphing. Recent work on a generalized framework for morphing among multiple images is described.,True,KyXgRdQAAAAJ:2osOgNQ5qMEC,576,http://jeremybolton.georgetown.domains/courses/cv/papers/imageMorphing.pdf,12869551526527590536,/scholar?cites=12869551526527590536,,,http://jeremybolton.georgetown.domains/courses/cv/papers/imageMorphing.pdf,0,0,0
1277953,Robust image registration using log-polar transform,2000,George Wolberg and Siavash Zokai,1,,,493-496,IEEE,This paper describes a hierarchical image registration algorithm for affine motion recovery. The algorithm estimates the affine transformation parameters necessary to register any two digital images misaligned due to rotation. scale. shear. and translation. The parameters are computed iteratively in a coarse-to-fine hierarchical framework using a variation of the Levenberg-Marquadt nonlinear least squares optimization method. This approach yields a robust solution that precisely registers images with subpixel accuracy. A log-polar registration module is introduced to accommodate arbitrary rotation angles and a wide range of scale changes. This serves to furnish a good initial estimate for the optimization-based affine registration stage. We demonstrate the hybrid algorithm on pairs of digital images subjected to large affine motion.,True,KyXgRdQAAAAJ:u-x6o8ySG0sC,402,https://ieeexplore.ieee.org/abstract/document/901003/,1567712833021240980,/scholar?cites=1567712833021240980,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.1451&rep=rep1&type=pdf,0,0,0
1277954,Image metamorphosis using snakes and free-form deformations,1995,Seung-Yong Lee and Kyung-Yong Chwa and Sung Yong Shin,,,,439-448,,This paper presents new solutions to the following three problems in image morphing: feature specification. warp generation. and transition control. To reduce the burden of feature specification. we first adopt a computer vision technique called snakes. We next propose the use of multilevel free-form deformations (MFFD) to achieve,True,KyXgRdQAAAAJ:XiSMed-E-HIC,340,https://dl.acm.org/doi/pdf/10.1145/218380.218501,16626782729997549151,/scholar?cites=16626782729997549151,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.3522&rep=rep1&type=pdf,0,0,0
1277955,Fourier transforms,1995,Klas Nordberg,,,,117-197,Kluver,This chapter is on Fourier methods. with a particularemphasis on definitions and theorems essential to the understanding offiltering procedures in multi-dimensional spaces. This is a centralissue in computer vision.,True,KyXgRdQAAAAJ:_xSYboBqXhAC,307,https://www.diva-portal.org/smash/record.jsf?pid=diva2:405398,7891545872830465914,/scholar?cites=7891545872830465914,,,,0,0,0
1277956,Image metamorphosis with scattered feature constraints,1996,Seungyong Lee and George Wolberg and Kyung-Yong Chwa and Sung Yong Shin,2,IEEE transactions on visualization and computer graphics,4,337-354,IEEE,This paper describes an image metamorphosis technique to handle scattered feature constraints specified with points. polylines. and splines. Solutions to the following three problems are presented: feature specification. warp generation. and transition control. We demonstrate the use of snakes to reduce the burden of feature specification. Next. we propose the use of multilevel free-form deformations (MFFD) to compute C/sup 2/-continuous and one-to-one mapping functions among the specified features. The resulting technique. based on B-spline approximation. is simpler and faster than previous warp generation methods. Furthermore. it produces smooth image transformations without undesirable ripples and foldovers. Finally. we simplify the MFFD algorithm to derive transition functions to control geometry and color blending. Implementation details are furnished and comparisons among various metamorphosis …,True,KyXgRdQAAAAJ:qjMakFHDy7sC,298,https://ieeexplore.ieee.org/abstract/document/556502/,793406517608076366,/scholar?cites=793406517608076366,,,https://www.researchgate.net/profile/George_Wolberg/publication/3410802_Image_Metamorphosis_with_Scattered_Feature_Constraints/links/00b49518719ad1bbb8000000/Image-Metamorphosis-with-Scattered-Feature-Constraints.pdf,0,0,0
1277957,Image registration using log-polar mappings for recovery of large-scale similarity and projective transformations,2005,Siavash Zokai and George Wolberg,14,IEEE Transactions on Image Processing,10,1422-1434,IEEE,This paper describes a novel technique to recover large similarity transformations (rotation/scale/translation) and moderate perspective deformations among image pairs. We introduce a hybrid algorithm that features log-polar mappings and nonlinear least squares optimization. The use of log-polar techniques in the spatial domain is introduced as a preprocessing module to recover large scale changes (e.g.. at least four-fold) and arbitrary rotations. Although log-polar techniques are used in the Fourier-Mellin transform to accommodate rotation and scale in the frequency domain. its use in registering images subjected to very large scale changes has not yet been exploited in the spatial domain. In this paper. we demonstrate the superior performance of the log-polar transform in featureless image registration in the spatial domain. We achieve subpixel accuracy through the use of nonlinear least squares optimization …,True,KyXgRdQAAAAJ:u5HHmVD_uO8C,288,https://ieeexplore.ieee.org/abstract/document/1510678/,11657910900311773928,/scholar?cites=11657910900311773928,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.3062&rep=rep1&type=pdf,0,0,0
1277958,Separable image warping methods and systems using spatial lookup tables,1993,George Wolberg and Terrance E Boult,,,,,,A two-dimensional image is subjected to a three-dimensional effect. such as folding. twisting or rotation. and transformed or warped into a modified output image. By successive one-dimensional resampling along two coordinates and parallel channel processing of transposed input image data with rejection of distorted pixel value data. bottleneck. shear and other distortions are addressed. Complete warping systems. resampling subsystems and related methods are disclosed.,True,KyXgRdQAAAAJ:IjCSPb-OGe4C,170,https://patents.google.com/patent/US5204944A/en,9148516322366973809,/scholar?cites=9148516322366973809,,,https://patentimages.storage.googleapis.com/4a/e5/aa/e44b9462df2081/US5204944.pdf,0,0,0
1277959,Integrating automated range registration with multiview geometry for the photorealistic modeling of large-scale scenes,2008,Ioannis Stamos and Lingyun Liu and Chao Chen and George Wolberg and Gene Yu and Siavash Zokai,78,International Journal of Computer Vision,2-3,237-260,Springer US, The photorealistic modeling of large-scale scenes. such as urban structures. requires a fusion of range sensing technology and traditional digital photography. This paper presents a system that integrates automated 3D-to-3D and 2D-to-3D registration techniques. with multiview geometry for the photorealistic modeling of urban scenes. The 3D range scans are registered using our automated 3D-to-3D registration method that matches 3D features (linear or circular) in the range images. A subset of the 2D photographs are then aligned with the 3D model using our automated 2D-to-3D registration algorithm that matches linear features between the range scans and the photographs. Finally. the 2D photographs are used to generate a second 3D model of the scene that consists of a sparse 3D point cloud. produced by applying a multiview geometry (structure-from-motion) algorithm directly on a sequence of …,True,KyXgRdQAAAAJ:YsMSGLbcyi4C,132,https://link.springer.com/content/pdf/10.1007/s11263-007-0089-1.pdf,12997353347456606205,/scholar?cites=12997353347456606205,,,https://www.researchgate.net/profile/George_Wolberg/publication/220660396_Integrating_Automated_Range_Registration_with_Multiview_Geometry_for_the_Photorealistic_Modeling_of_Large-Scale_Scenes/links/0912f51116de85130c000000.pdf,0,0,0
1277960,Polymorph: Morphing among multiple images,1998,Seungyong Lee and George Wolberg and Sung Yong Shin,18,IEEE Computer Graphics and Applications,1,58-71,IEEE,Polymorph extends conventional morphing to derive morphed images from more than two images at once. effectively integrating geometric manipulations and color blending. We present a general framework for polymorphing by extending the traditional image morphing paradigm that applies to two images. The authors formulate each input image as a vertex of an (n-1)-dimensional simplex. where n equals the number of input images. They look at the mathematical framework for polymorph. followed by warp function generation and propagation. blending function generation. and the implemented polymorph system. Metamorphosis examples demonstrate the use of polymorph for image composition.,True,KyXgRdQAAAAJ:UeHWp8X0CEIC,129,https://ieeexplore.ieee.org/abstract/document/637304/,7169350980451390022,/scholar?cites=7169350980451390022,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.9147&rep=rep1&type=pdf,0,0,0
1277961,Fingerprint minutiae matching based on the local and global structures,2000,Xudong Jiang and Wei-Yun Yau,2,,,1038-1041,IEEE,Proposes a fingerprint minutia matching technique. which matches the fingerprint minutiae by using both the local and global structures of minutiae. The local structure of a minutia describes a rotation and translation invariant feature of the minutia in its neighborhood. It is used to find the correspondence of two minutiae sets and increase the reliability of the global matching. The global structure of minutiae reliably determines the uniqueness of fingerprint. Therefore. the local and global structures of minutiae together provide a solid basis for reliable and robust minutiae matching. The proposed minutiae matching scheme is suitable for an online processing due to its high processing speed. Experimental results show the performance of the proposed technique.,True,IL3mSioAAAAJ:dQJM2trw0wsC,743,https://ieeexplore.ieee.org/abstract/document/906252/,13538147531070664171,/scholar?cites=13538147531070664171,,,,0,0,0
1277962,Eigenfeature regularization and extraction in face recognition,2008,Xudong Jiang and Bappaditya Mandal and Alex Kot,30,IEEE Transactions on Pattern Analysis and Machine Intelligence,3,383-394,IEEE,This work proposes a subspace approach that regularizes and extracts eigenfeatures from the face image. Eigenspace of the within-class scatter matrix is decomposed into three subspaces: a reliable subspace spanned mainly by the facial variation. an unstable subspace due to noise and finite number of training samples. and a null subspace. Eigenfeatures are regularized differently in these three subspaces based on an eigenspectrum model to alleviate problems of instability. overfitting. or poor generalization. This also enables the discriminant evaluation performed in the whole space. Feature extraction or dimensionality reduction occurs only at the final stage after the discriminant assessment. These efforts facilitate a discriminative and a stable low-dimensional feature representation of the face image. Experiments comparing the proposed approach with some other popular subspace methods on the FERET …,True,IL3mSioAAAAJ:9yKSN-GCB0IC,372,https://ieeexplore.ieee.org/abstract/document/4359331/,9116543216313675840,/scholar?cites=9116543216313675840,,,,0,0,0
1277963,Two-dimensional polar harmonic transforms for invariant image representation,2010,Pew-Thian Yap and Xudong Jiang and Alex Chichung Kot,32,IEEE Transactions on Pattern Analysis and Machine Intelligence,7,1259-1270,IEEE,This paper introduces a set of 2D transforms. based on a set of orthogonal projection bases. to generate a set of features which are invariant to rotation. We call these transforms Polar Harmonic Transforms (PHTs). Unlike the well-known Zernike and pseudo-Zernike moments. the kernel computation of PHTs is extremely simple and has no numerical stability issue whatsoever. This implies that PHTs encompass the orthogonality and invariance advantages of Zernike and pseudo-Zernike moments. but are free from their inherent limitations. This also means that PHTs are well suited for application where maximal discriminant information is needed. Furthermore. PHTs make available a large set of features for further feature selection in the process of seeking for the best discriminative or representative features for a particular application.,True,IL3mSioAAAAJ:hqOjcs7Dif8C,262,https://ieeexplore.ieee.org/abstract/document/4967611/,10028332624106068087,/scholar?cites=10028332624106068087,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.505.6533&rep=rep1&type=pdf,0,0,0
1277964,Fingerprint quality and validity analysis,2002,Eyung Lim and Xudong Jiang and Weiyun Yau,1,,,I-I,IEEE,Discusses methods to estimate the quality as well as validity of a fingerprint image. Orientation certainty is used to certify the localized texture pattern of the fingerprint images while ridge to valley structure is analyzed to detect invalid images. Global uniformity and continuity ensures that the image is valid as a whole. 150 images with various qualities are evaluated using the proposed algorithm and quality benchmark we defined. A monotonic relationship is found indicating that the proposed algorithm is feasible in detecting low quality as well as invalid fingerprint images.,True,IL3mSioAAAAJ:d1gkVwhDpl0C,256,https://ieeexplore.ieee.org/abstract/document/1038062/,14183585838762907320,/scholar?cites=14183585838762907320,,,,0,0,0
1277965,Face recognition using sift features,2009,Cong Geng and Xudong Jiang,,,,3313-3316,IEEE,Scale Invariant Feature Transform (SIFT) has shown to be a powerful technique for general object recognition/detection. In this paper. we propose two new approaches: Volume-SIFT (VSIFT) and Partial-Descriptor-SIFT (PDSIFT) for face recognition based on the original SIFT algorithm. We compare holistic approaches: Fisherface (FLDA). the null space approach (NLDA) and Eigenfeature Regularization and Extraction (ERE) with feature based approaches: SIFT and PDSIFT. Experiments on the ORL and AR databases show that the performance of PDSIFT is significantly better than the original SIFT approach. Moreover. PDSIFT can achieve comparable performance as the most successful holistic approach ERE and significantly outperforms FLDA and NLDA.,True,IL3mSioAAAAJ:KlAtU1dfN6UC,229,https://ieeexplore.ieee.org/abstract/document/5413956/,1788503784636722609,/scholar?cites=1788503784636722609,,,https://www.academia.edu/download/53915896/Face_recognition_using_sift_features20170719-2855-18x1x5h.pdf,0,0,0
1277966,LBP Based Edge-Texture Features for Object Recognition,2014,Amit Satpathy and Xudong Jiang and H Eng,23,IEEE Transactions on Image Processing,5,1953-1964,IEEE,This paper proposes two sets of novel edge-texture features. Discriminative Robust Local Binary Pattern (DRLBP) and Ternary Pattern (DRLTP). for object recognition. By investigating the limitations of Local Binary Pattern (LBP). Local Ternary Pattern (LTP) and Robust LBP (RLBP). DRLBP and DRLTP are proposed as new features. They solve the problem of discrimination between a bright object against a dark background and vice-versa inherent in LBP and LTP. DRLBP also resolves the problem of RLBP whereby LBP codes and their complements in the same block are mapped to the same code. Furthermore. the proposed features retain contrast information necessary for proper representation of object contours that LBP. LTP. and RLBP discard. Our proposed features are tested on seven challenging data sets: INRIA Human. Caltech Pedestrian. UIUC Car. Caltech 101. Caltech 256. Brodatz. and KTH-TIPS2-a …,True,IL3mSioAAAAJ:k8Z6L05lTy4C,228,https://ieeexplore.ieee.org/abstract/document/6763097/,10886972849131193500,/scholar?cites=10886972849131193500,,,http://oar.a-star.edu.sg/jspui/bitstream/123456789/629/1/double_rev.pdf,0,0,0
1277967,Noise-Resistant Local Binary Pattern with an Embedded Error-Correction Mechanism,2013,Jianfeng Ren and Xudong Jiang and Junsong Yuan,22,IEEE Transactions on Image Processing,10,4049-4060,IEEE,Local binary pattern (LBP) is sensitive to noise. Local ternary pattern (LTP) partially solves this problem. Both LBP and LTP. however. treat the corrupted image patterns as they are. In view of this. we propose a noise-resistant LBP (NRLBP) to preserve the image local structures in presence of noise. The small pixel difference is vulnerable to noise. Thus. we encode it as an uncertain state first. and then determine its value based on the other bits of the LBP code. It is widely accepted that most of the image local structures are represented by uniform codes and noise patterns most likely fall into the non-uniform codes. Therefore. we assign the value of an uncertain bit hence as to form possible uniform codes. Thus. we develop an error-correction mechanism to recover the distorted image patterns. In addition. we find that some image patterns such as lines are not captured in uniform codes. Those line patterns may …,True,IL3mSioAAAAJ:hMsQuOkrut0C,224,https://ieeexplore.ieee.org/abstract/document/6542010/,5021214654753641474,/scholar?cites=5021214654753641474,,,https://www.academia.edu/download/53915851/Noise-Resistant_Local_Binary_Pattern_Wit20170719-2853-p74n54.pdf,0,0,0
1277968,Detecting the fingerprint minutiae by adaptive tracing the gray-level ridge,2001,Xudong Jiang and Wei-Yun Yau and Wee Ser,34,Pattern Recognition,5,999-1013,Pergamon,This paper presents a minutiae detection procedure based on adaptive tracing the gray-level ridge of the fingerprint image with piecewise linear lines of different length. The original fingerprint image is smoothed with an adaptive-oriented smoothing filter only at some selected points. This will greatly reduce the computational time. Each ridge in the skeleton is labeled with a number so that each detected minutia is associated with one or two ridge numbers. which is useful for post processing. We objectively assess the performance of this approach by using two large fingerprint databases.,True,IL3mSioAAAAJ:u-x6o8ySG0sC,219,https://www.sciencedirect.com/science/article/pii/S0031320300000509,18429273365880586335,/scholar?cites=18429273365880586335,,,https://www.academia.edu/download/53915862/Detecting_the_fingerprint_minutiae_by_ad20170719-2855-13awac3.pdf,0,0,0
1277969,Context contrasted feature and gated multi-scale aggregation for scene segmentation,2018,Henghui Ding and Xudong Jiang and Bing Shuai and Ai Qun Liu and Gang Wang,,,,2393-2402,,Scene segmentation is a challenging task as it need label every pixel in the image. It is crucial to exploit discriminative context and aggregate multi-scale features to achieve better segmentation. In this paper. we first propose a novel context contrasted local feature that not only leverages the informative context but also spotlights the local information in contrast to the context. The proposed context contrasted local feature greatly improves the parsing performance. especially for inconspicuous objects and background stuff. Furthermore. we propose a scheme of gated sum to selectively aggregate multi-scale features for each spatial position. The gates in this scheme control the information flow of different scale features. Their values are generated from the testing image by the proposed network learnt from the training data so that they are adaptive not only to the training data. but also to the specific testing image. Without bells and whistles. the proposed approach achieves the state-of-the-arts consistently on the three popular scene segmentation datasets. Pascal Context. SUN-RGBD and COCO Stuff.,True,IL3mSioAAAAJ:SEmTV4UfSqwC,182,http://openaccess.thecvf.com/content_cvpr_2018/html/Ding_Context_Contrasted_Feature_CVPR_2018_paper.html,7505736612303917972,/scholar?cites=7505736612303917972,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Ding_Context_Contrasted_Feature_CVPR_2018_paper.pdf,0,0,0
1277970,Linear subspace learning-based dimensionality reduction,2011,Xudong Jiang,28,IEEE Signal Processing Magazine,2,16-26,IEEE,The ultimate goal of pattern recognition is to discriminate the class membership of the observed novel objects with the minimum misclassification rate. An observed object is often represented by a high dimensional real-valued vector after some preprocessing while its class membership can be represented by a much lower dimensional binary vector. Thus. in the discriminating process. a pattern recognition system intrinsically reduces the dimensionality of the input data into the number of classes.,True,IL3mSioAAAAJ:aqlVkmm33-oC,163,https://ieeexplore.ieee.org/abstract/document/5714391/,16097701939716394768,/scholar?cites=16097701939716394768,,,,0,0,0
1277971,Sparse And Dense Hybrid Representation via Dictionary Decomposition for Face Recognition,2015,X Jiang and J Lai,37,IEEE Transactions on Pattern Analysis and Machine Intelligence,5,1067-1079,IEEE,Sparse representation provides an effective tool for classification under the conditions that every class has sufficient representative training samples and the training data are uncorrupted. These conditions may not hold true in many practical applications. Face identification is an example where we have a large number of identities but sufficient representative and uncorrupted training images cannot be guaranteed for every identity. A violation of the two conditions leads to a poor performance of the sparse representation-based classification (SRC). This paper addresses this critic issue by analyzing the merits and limitations of SRC. A sparse- and dense-hybrid representation (SDR) framework is proposed in this paper to alleviate the problems of SRC. We further propose a procedure of supervised low-rank (SLR) dictionary decomposition to facilitate the proposed SDR framework. In addition. the problem of the …,True,IL3mSioAAAAJ:-FonjvnnhkoC,147,https://ieeexplore.ieee.org/abstract/document/6905839/,1854226660541845017,/scholar?cites=1854226660541845017,,,,0,0,0
1277972,Error analysis and detection procedures for a hardware implementation of the advanced encryption standard,2003,Guido Bertoni and Luca Breveglieri and Israel Koren and Paolo Maistri and Vincenzo Piuri,52,IEEE transactions on Computers,4,492-505,IEEE,The goal of the Advanced Encryption Standard (AES) is to achieve secure communication. The use of AES does not. however. guarantee reliable communication. Prior work has shown that even a single transient error occurring during the AES encryption (or decryption) process will very likely result in a large number of errors in the encrypted/decrypted data. Such faults must be detected before sending to avoid the transmission and use of erroneous data. Concurrent fault detection is important not only to protect the encryption/decryption process from random faults. It will also protect the encryption/decryption circuitry from an attacker who may maliciously inject faults in order to find the encryption secret key. In this paper. we first describe some studies of the effects that faults may have on a hardware implementation of AES by analyzing the propagation of such faults to the outputs. We then present two fault detection …,True,cAaTvfcAAAAJ:u5HHmVD_uO8C,410,https://ieeexplore.ieee.org/abstract/document/1190590/,13539694649239026826,/scholar?cites=13539694649239026826,,,,0,0,0
1277973,All-IDB: The acute lymphoblastic leukemia image database for image processing,2011,Ruggero Donida Labati and Vincenzo Piuri and Fabio Scotti,,,,2045-2048,IEEE,The visual analysis of peripheral blood samples is an important test in the procedures for the diagnosis of leukemia. Automated systems based on artificial vision methods can speed up this operation and increase the accuracy and homogeneity of the response also in telemedicine applications. Unfortunately. there are not available public image datasets to test and compare such algorithms. In this paper. we propose a new public dataset of blood samples. specifically designed for the evaluation and the comparison of algorithms for segmentation and classification. For each image in the dataset. the classification of the cells is given. as well as a specific set of figures of merits to fairly compare the performances of different algorithms. This initiative aims to offer a new test tool to the image processing and pattern matching communities. direct to stimulating new studies in this important field of research.,True,cAaTvfcAAAAJ:lmc2jWPfTJgC,291,https://ieeexplore.ieee.org/abstract/document/6115881/,14609825745019859202,/scholar?cites=14609825745019859202,,,https://air.unimi.it/bitstream/2434/168333/8/icip_2011.pdf,0,0,0
1277974,A Web-based distributed virtual educational laboratory,2000,Luigino Benetazzo and Matteo Bertocco and Franco Ferraris and Alessandro Ferrero and Carlo Offelli and Marco Parvis and Vincenzo Piuri,49,IEEE Transactions on Instrumentation and Measurement,2,349-356,IEEE,Evolution and cost of measurement equipment. continuous training. and distance learning make it difficult to provide a complete set of updated workbenches to every student. For a preliminary familiarization and experimentation with instrumentation and measurement procedures. the use of virtual equipment is often considered more than sufficient from the didactic point of view. while the hands-on approach with real instrumentation and measurement systems still remains necessary to complete and refine the student's practical expertise. Creation and distribution of workbenches in networked computer laboratories therefore becomes attractive and convenient. This paper describes specification and design of a geographically distributed system based on commercially standard components.,True,cAaTvfcAAAAJ:u-x6o8ySG0sC,245,https://ieeexplore.ieee.org/abstract/document/843077/,3833695430709671994,/scholar?cites=3833695430709671994,,,https://www.academia.edu/download/55638987/A_Web-Based_Distributed_Virtual_Educatio20180126-17419-19wl1oq.pdf,0,0,0
1277975,Privacy-preserving fingercode authentication,2010,Mauro Barni and Tiziano Bianchi and Dario Catalano and Mario Di Raimondo and Ruggero Donida Labati and Pierluigi Failla and Dario Fiore and Riccardo Lazzeretti and Vincenzo Piuri and Fabio Scotti and Alessandro Piva,,,,231-240,,We present a privacy preserving protocol for fingerprint-based authentication. We consider a scenario where a client equipped with a fingerprint reader is interested into learning if the acquired fingerprint belongs to the database of authorized entities managed by a server. For security. it is required that the client does not learn anything on the database and the server should not get any information about the requested biometry and the outcome of the matching process. The proposed protocol follows a multi-party computation approach and makes extensive use of homomorphic encryption as underlying cryptographic primitive. To keep the protocol complexity as low as possible. a particular representation of fingerprint images. named Fingercode. is adopted. Although the previous works on privacy-preserving biometric identification focus on selecting the best matching identity in the database. our main solution is a …,True,cAaTvfcAAAAJ:YOwf2qJgpHMC,228,https://dl.acm.org/doi/abs/10.1145/1854229.1854270,2857093376166874711,/scholar?cites=2857093376166874711,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.709.4481&rep=rep1&type=pdf,0,0,0
1277976,Morphological classification of blood leucocytes by microscope images,2004,Vincenzo Piuri and Fabio Scotti,,,,103-108,IEEE,The classification and the count of white blood cells in microscopy images allows the in vivo assessment of a wide range of important hematic pathologies (i.e.. from presence of infections to leukemia). Nowadays. the morphological cell classification is typically made by experienced operators. Such a procedure presents undesirable drawbacks: slowness and it presents a not standardized accuracy since it depends on the operator's capabilities and tiredness. Only few attempts of partial/full automated systems based on image-processing systems are present in literature and they are still at prototype stage. This paper presents a methodology to achieve an automated detection and classification of leucocytes by microscope color images. The proposed system firstly individuates in the blood image the leucocytes from the others blood cells. then it extracts morphological indexes and finally it classifies the leucocytes by …,True,cAaTvfcAAAAJ:roLk4NBRz8UC,220,https://ieeexplore.ieee.org/abstract/document/1397242/,13037980385332192284,/scholar?cites=13037980385332192284,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.5942&rep=rep1&type=pdf,0,0,0
1277977,Fault tolerance management in cloud computing: A system-level perspective,2012,Ravi Jhawar and Vincenzo Piuri and Marco Santambrogio,7,IEEE Systems Journal,2,288-297,IEEE,The increasing popularity of Cloud computing as an attractive alternative to classic information processing systems has increased the importance of its correct and continuous operation even in the presence of faulty components. In this paper. we introduce an innovative. system-level. modular perspective on creating and managing fault tolerance in Clouds. We propose a comprehensive high-level approach to shading the implementation details of the fault tolerance techniques to application developers and users by means of a dedicated service layer. In particular. the service layer allows the user to specify and apply the desired level of fault tolerance. and does not require knowledge about the fault tolerance techniques that are available in the envisioned Cloud and their implementations.,True,cAaTvfcAAAAJ:MIg0yeAD4ggC,215,https://ieeexplore.ieee.org/abstract/document/6363517/,3234095533117863442,/scholar?cites=3234095533117863442,,,https://www.researchgate.net/profile/Marco_Santambrogio/publication/258792178_Fault_Tolerance_Management_in_Cloud_Computing_A_System-Level_Perspective/links/554895790cf2e2031b38880b.pdf,0,0,0
1277978,A simulation tool for virtual laboratory experiments in a WWW environment,1999,Alessandro Ferrero and Vincenzo Piuri,48,IEEE Transactions on Instrumentation and Measurement,3,741-746,IEEE,Virtual instruments and distributed systems are of great interest to create advanced and flexible teaching and experimentation environments for measurement technologies at limited costs. Availability of simple and efficient technological supports to dissemination and remote use of virtual systems becomes attractive to increase the access to experimental practice without regard to the number of students and their location as well as the variety of instruments and measurement procedures directly available for experimentation.,True,cAaTvfcAAAAJ:d1gkVwhDpl0C,159,https://ieeexplore.ieee.org/abstract/document/772214/,2927167288995400360,/scholar?cites=2927167288995400360,,,https://www.researchgate.net/profile/Alessandro_Ferrero/publication/3089540_A_simulation_tool_for_virtual_laboratory_experiments_in_a_WWW_environment/links/547592ae0cf29afed6127fb1/A-simulation-tool-for-virtual-laboratory-experiments-in-a-WWW-environment.pdf,0,0,0
1277979,Hybrid CORDIC algorithms,1997,Shaoyun Wang and Vincenzo Piuri and EE Wartzlander,46,IEEE Transactions on Computers,11,1202-1207,IEEE,Each coordinate rotation digital computer iteration selects the rotation direction by analyzing the results of the previous iteration. In this paper. we introduce two arctangent radices and show that about 2/3 of the rotation directions can be derived in parallel without any error. Some architectures exploiting these strategies are proposed.,True,cAaTvfcAAAAJ:9yKSN-GCB0IC,156,https://ieeexplore.ieee.org/abstract/document/644295/,15861700293783741082,/scholar?cites=15861700293783741082,,,,0,0,0
1277980,Composite real-time image processing for railways track profile measurement,2000,Cesare Alippi and Ettore Casagrande and Fabio Scotti and Vincenzo Piuri,49,IEEE Transactions on instrumentation and measurement,3,559-564,IEEE,Checking railway status is critical to guarantee high operating safety. proper maintenance schedule. and low maintenance and operating costs. This operation consists of the analysis of the rail profile and level as well as overall geometry and undulation. Traditional detection systems are based on mechanical devices in contact with the track. Innovative approaches are based on laser scanning and image analysis. This paper presents an efficient composite technique for track profile extraction with real-time image processing. High throughput is obtained by algorithmic prefiltering to restrict the image area containing the track profile. while high accuracy is achieved by neural reconstruction of the profile itself.,True,cAaTvfcAAAAJ:W7OEmFMy1HYC,131,https://ieeexplore.ieee.org/abstract/document/850395/,2188529542250357875,/scholar?cites=2188529542250357875,,,https://pdfs.semanticscholar.org/6058/ee56ae1ffc33df0f9e93d0df8d3fd65db1c7.pdf,0,0,0
1277981,Deep-ECG: Convolutional neural networks for ECG biometric recognition,2019,Ruggero Donida Labati and Enrique Muñoz and Vincenzo Piuri and Roberto Sassi and Fabio Scotti,126,Pattern Recognition Letters,,78-85,North-Holland,Electrocardiographic (ECG) signals have been successfully used to perform biometric recognition in a wide range of applications. However. ECG-based biometric systems are usually less accurate than technologies based on other physiological traits. To increase their performance. it is necessary to study novel approaches. Deep learning methods. like Convolutional Neural Networks (CNNs). can automatically extract distinctive features. and have demonstrated their effectiveness for other biometric systems. In this paper. we present Deep-ECG. a CNN-based biometric approach for ECG signals. To the best of our knowledge. this is the first study in the literature that uses a CNN for ECG biometrics. Deep-ECG extracts significant features from one or more leads using a deep CNN and compares biometric templates by computing simple and fast distance functions. obtaining remarkable accuracy for identification …,True,cAaTvfcAAAAJ:1_W9tMSvGuwC,123,https://www.sciencedirect.com/science/article/pii/S0167865518301077,3929317204073605244,/scholar?cites=3929317204073605244,,,http://piurilabs.di.unimi.it/Papers/PRL_2018_web.pdf,0,0,0
1277982,A privacy-compliant fingerprint recognition system based on homomorphic encryption and fingercode templates,2010,Mauro Barni and Tiziano Bianchi and Dario Catalano and Mario Di Raimondo and Ruggero Donida Labati and Pierluigi Failla and Dario Fiore and Riccardo Lazzeretti and Vincenzo Piuri and Alessandro Piva and Fabio Scotti,,,,1-7,IEEE,The privacy protection of the biometric data is an important research topic. especially in the case of distributed biometric systems. In this scenario. it is very important to guarantee that biometric data cannot be steeled by anyone. and that the biometric clients are unable to gather any information different from the single user verification/identification. In a biométrie system with high level of privacy compliance. also the server that processes the biométrie matching should not learn anything on the database and it should be impossible for the server to exploit the resulting matching values in order to extract any knowledge about the user presence or behavior. Within this conceptual framework. in this paper we propose a novel complete demonstrator based on a distributed biométrie system that is capable to protect the privacy of the individuals by exploiting cryptosystems. The implemented system computes the matching …,True,cAaTvfcAAAAJ:M05iB0D1s5AC,119,https://ieeexplore.ieee.org/abstract/document/5634527/,142747420395009000,/scholar?cites=142747420395009000,,,https://core.ac.uk/download/pdf/192415469.pdf,0,0,0
1277983,Efficient use of MPEG‐7 edge histogram descriptor,2002,Chee Sun Won and Dong Kwon Park and Soo‐Jun Park,24,ETRI journal,1,23-30,,MPEG‐7 Visual Standard specifies a set of descriptors that can be used to measure similarity in images or video. Among them. the Edge Histogram Descriptor describes edge distribution with a histogram based on local edge distribution in an image. Since the Edge Histogram Descriptor recommended for the MPEG‐7 standard represents only local edge distribution in the image. the matching performance for image retrieval may not be satisfactory. This paper proposes the use of global and semi‐local edge histograms generated directly from the local histogram bins to increase the matching performance. Then. the global. semiglobal. and local histograms of images are combined to measure the image similarity and are compared with the MPEG‐7 descriptor of the local‐only histogram. Since we exploit the absolute location of the edge in the image as well as its global composition. the proposed matching method …,True,x2GPMQoAAAAJ:u5HHmVD_uO8C,468,https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.02.0102.0103,8772872021198535354,/scholar?cites=8772872021198535354,,,https://onlinelibrary.wiley.com/doi/pdf/10.4218/etrij.02.0102.0103,0,0,0
1277984,Efficient use of local edge histogram descriptor,2000,Dong Kwon Park and Yoon Seok Jeon and Chee Sun Won,,,,51-54,,The purpose of this paper is to show how the edge histogram descriptor for MPEG-7 can be efficiently utilized for image matching. Since the edge histogram descriptor recommended for the MPEG-7 standard represents only local edge distribution in an image. the matching performance for image retrieval may not be satisfactory. In this paper. to increase the matching performance. we propose to use the global and semi-local edge histograms generated directly from the local histogram bins. Then. the global. semi-global. and local histograms of two images are compared to evaluate the similarity measure. Since we exploit the absolute locations of edge in the image as well as its global composition. the proposed matching method is considered to be a more image content-based retrieval. Experimental results support this claim. Experiments on test images for MPEG-7 core experiment show that the proposed method …,True,x2GPMQoAAAAJ:H1wcazwC3NUC,367,https://dl.acm.org/doi/abs/10.1145/357744.357758,11558119073824517494,/scholar?cites=11558119073824517494,,,https://www.dcc.fc.up.pt/~mcoimbra/lectures/VC_1718/VC_1718_P8_LEH.pdf,0,0,0
1277985,3D printed complex tissue construct using stem cell-laden decellularized extracellular matrix bioinks for cardiac repair,2017,Jinah Jang and Hun-Jun Park and Seok-Won Kim and Heejin Kim and Ju Young Park and Soo Jin Na and Hyeon Ji Kim and Moon Nyeo Park and Seung Hyun Choi and Sun Hwa Park and Sung Won Kim and Sang-Mo Kwon and Pum-Joon Kim and Dong-Woo Cho,112,Biomaterials,,264-274,Elsevier,Stem cell therapy is a promising therapeutic method for the treatment of ischemic heart diseases; however. some challenges prohibit the efficacy after cell delivery due to hostile microenvironment of the injured myocardium. 3D printed pre-vascularized stem cell patch can enhance the therapeutic efficacy for cardiac repair through promotion of rapid vascularization after patch transplantation. In this study. stem cell-laden decellularized extracellular matrix bioinks are used in 3D printing of pre-vascularized and functional multi-material structures. The printed structure composed of spatial patterning of dual stem cells improves cell-to-cell interactions and differentiation capability and promotes functionality for tissue regeneration. The developed stem cell patch promoted strong vascularization and tissue matrix formation in vivo. The patterned patch exhibited enhanced cardiac functions. reduced cardiac hypertrophy and …,True,x2GPMQoAAAAJ:8bEfNjzhQ0EC,309,https://www.sciencedirect.com/science/article/pii/S0142961216305695,6766593104155490279,/scholar?cites=6766593104155490279,,,,0,0,0
1277986,Nanotechnology platforms and physiological challenges for cancer therapeutics,2007,Kelly Y Kim,3,,2,103-110,Elsevier,Nanotechnology is considered to be an emerging. disruptive technology that will have significant impact in all industrial sectors and across-the-board applications in cancer research. There has been tremendous investment in this area and an explosion of research and development efforts in recent years. particularly in the area of cancer research. At the National Institutes of Health. nanomedicine is one of the priority areas under its Roadmap Initiatives. Moreover. in 2005 the National Cancer Institute alone committed $144.3 million over 5 years for its Alliance for Nanotechnology in Cancer program. Much research and development is progressing in the areas of cancer diagnostics. devices. biosensors. and microfluidics. but this review will focus on therapeutics. Current nanotechnology platforms for cancer therapeutics encompass a vast array of nanomaterials and nanodevices. This review will focus on six of the …,True,x2GPMQoAAAAJ:XUvXOeBm_78C,236,https://www.sciencedirect.com/science/article/pii/S1549963407000445,12388763532630291000,/scholar?cites=12388763532630291000,,,http://nanobiotec.iqm.unicamp.br/download/nano-cancer-review.pdf,0,0,0
1277987,Garment for measuring physiological signals and method of fabricating the same,2010,Seung-chul Shin and Yong-Won Jang and In-Bum Lee and Seung-hwan Kim and Seon-hee Park,,,,,,Provided is a garment for measuring physiological signals. The garment includes at least one electrode sensor. a signal connection line. a snap structure. and a measurement unit. The electrode sensor is coupled to an inner surface of the garment to make contact with a skin for detecting physiological signals. The signal connection line transmits the physiological signals detected by the electrode sensor. The signal connection line is finished against the inner surface of the garment. The snap structure is coupled to a portion of the garment where the electrode sensor is not overlapped and is electrically connected to the signal connection line. The measurement unit is mounted on the snap structure for measuring the physiological signals. The signal connection line has elasticity.,True,x2GPMQoAAAAJ:uk0w_JccWH8C,219,https://patents.google.com/patent/US20100234715A1/en,12028235266690553081,/scholar?cites=12028235266690553081,,,https://patentimages.storage.googleapis.com/a8/5d/8b/289345a47ab1ee/US20100234715A1.pdf,0,0,0
1277988,Fermentative production of chemicals that can be used for polymer synthesis,2004,Sang Y Lee and Soon H Hong and Seung H Lee and Si J Park,4,,3,157-164,WILEY‐VCH Verlag,Summary: The fermentative production of chemicals that can be used as monomers for the synthesis of polymers has become an important topic in biotechnology research because of the limited nature of petroleum and environmental issues. In particular. the fermentative production of metabolites such as dicarboxylic acids. amino acids. and diols. which are suitable as building blocks for subsequent polymerization. has attracted much attention. Various wild‐type and metabolically engineered microorganisms have been developed for the efficient production of these chemicals from renewable resources. In addition. the development of fermentation strategies to achieve the highest possible productivities has been another focus of research. considering that these monomers should be produced at costs low enough to compete with petroleum‐derived ones. In this paper. the metabolic pathways leading to the …,True,x2GPMQoAAAAJ:X8aq8RHJ9bUC,149,https://onlinelibrary.wiley.com/doi/abs/10.1002/mabi.200300096,6288266330715133354,/scholar?cites=6288266330715133354,,,,0,0,0
1277989,Restoration of peri-implant defects in immediate implant installations by Choukroun platelet-rich fibrin and silk fibroin powder combination graft,2010,Eun-Sik Jang and Jun-Woo Park and HaeYong Kweon and Kwang-Gill Lee and Seok-Woo Kang and Dong-Heon Baek and Je-Yong Choi and Seong-Gon Kim,109,"Oral Surgery, Oral Medicine, Oral Pathology, Oral Radiology, and Endodontology",6,831-836,Mosby,The objective of this study was to determine the capability of silk fibroin powder as a biomaterial template for the restoration of peri-implant defects when mixed with Choukroun platelet-rich fibrin (PRF) in vivo.Ten New Zealand white rabbits were used for this study. Using a trephine bur (diameter 7.0 mm). 2 monocortical defects were prepared. Subsequently. 2 dental implants were installed into the tibia (diameter 3.0 mm. length 10.0 mm). In the experimental group. the peri-implant defect was filled with a combination graft of silk fibroin powder and Choukroun PRF. The control was left in an unfilled state. The animals were killed at 8 weeks. Subsequently. a removal torque test and a histomorphometric analysis were done.The removal torque for the experimental group was 30.34 ± 5.06 N·cm. whereas it was 21.86 ± 3.39 N·cm for the control. The difference between the 2 groups was …,True,x2GPMQoAAAAJ:pKq9KLJfUZEC,148,https://www.sciencedirect.com/science/article/pii/S1079210409008245,6122738610650811218,/scholar?cites=6122738610650811218,,,https://www.academia.edu/download/42032173/Restoration_of_peri-implant_defects_in_i20160204-24962-i6p7wc.pdf,0,0,0
1277990,Three-dimensional bioprinting of multilayered constructs containing human mesenchymal stromal cells for osteochondral tissue regeneration in the rabbit knee joint,2016,Jin-Hyung Shim and Ki-Mo Jang and Sei Kwang Hahn and Ju Young Park and Hyuntae Jung and Kyunghoon Oh and Kyeng Min Park and Junseok Yeom and Sun Hwa Park and Sung Won Kim and Joon Ho Wang and Kimoon Kim and Dong-Woo Cho,8,Biofabrication,1,014102,IOP Publishing,The use of cell-rich hydrogels for three-dimensional (3D) cell culture has shown great potential for a variety of biomedical applications. However. the fabrication of appropriate constructs has been challenging. In this study. we describe a 3D printing process for the preparation of a multilayered 3D construct containing human mesenchymal stromal cells with a hydrogel comprised of atelocollagen and supramolecular hyaluronic acid (HA). This construct showed outstanding regenerative ability for the reconstruction of an osteochondral tissue in the knee joints of rabbits. We found that the use of a mechanically stable. host-guest chemistry-based hydrogel was essential and allowed two different types of extracellular matrix (ECM) hydrogels to be easily printed and stacked into one multilayered construct without requiring the use of potentially harmful chemical reagents or physical stimuli for post-crosslinking. To the best …,True,x2GPMQoAAAAJ:47CO7rCGma4C,145,https://iopscience.iop.org/article/10.1088/1758-5090/8/1/014102/meta,7774820605226074796,/scholar?cites=7774820605226074796,,,,0,0,0
1277991,Apparatus and method for detecting biomolecules,2013,Chil-seong Ah and Ansoon Kim and Chan-woo Park and Chang-geun Ahn and Jong-heon Yang and In-bok Baek and Taeyoub Kim and Hyekyoung Yang and Gun-yong Sung and Seon-hee Park and Han-young Yu and Moon-gyu Jang,,,,,,Provided are an apparatus and method for detecting biomolecules. The apparatus includes a FET having a substrate. a source electrode. a drain electrode. a channel region between the source and drain electrodes. and probe molecules fixed to the channel region. wherein the source and drain electrodes are separated on the substrate. a microfluid supplier selectively supplying one of a reference buffer solution of low ionic concentration and a reaction solution of high ionic concentration containing target molecules. to the channel region of the FET to which the probe molecules are fixed. and a biomolecule detector detecting the target molecules by measuring a first current value of the channel region of the FET. and a second current value of the channel region of the FET to which the target molecules and the probe molecules that bind to each other in the reaction solution of high ionic concentration are fixed.,True,x2GPMQoAAAAJ:kkE12xK_jI8C,134,https://patents.google.com/patent/US8529750B2/en,13931757086506335798,/scholar?cites=13931757086506335798,,,https://patentimages.storage.googleapis.com/5e/d0/4d/216c3115aa57f0/US8529750.pdf,0,0,0
1277992,Mobile phone,2012,Dae-Yoeb Park,,,,,,FIG. 1 is a front perspective view of a mobile phone: FIG. 2 is a front view of the mobile phone of FIG. 1; FIG. 3 is a rear view of the mobile phone of FIG. 1; FIG. 4 is a left-side view of the mobile phone of FIG. 1; FIG. 5 is a right-side view of the mobile phone of FIG. 1; FIG. 6 is a top plan view of the mobile phone of FIG. 1; and. FIG. 7 is a bottom plan view of the mobile phone of FIG. 1.,True,x2GPMQoAAAAJ:jU7OWUQzBzMC,130,https://patents.google.com/patent/USD653645S1/en,11115171450615502322,/scholar?cites=11115171450615502322,,,,0,0,0
1277993,Mobile phone,2004,Yi-nung Lee,,,,,,Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.) 2003-09-29,True,x2GPMQoAAAAJ:oE_QS-WwsdAC,130,https://patents.google.com/patent/USD490792S1/en,17168582758803645809,/scholar?cites=17168582758803645809,,,,0,0,0
1277994,On mining scientific datasets,2001,Chandrika Kamath,,,,1-21,Springer. Boston. MA,Data mining techniques have gained acceptance as a viable means of finding useful information in data. While the techniques can be applied to any kind of data. a brief survey of the work presented at recent conferences in data mining and knowledge discovery might lead one to believe that these techniques are being applied mainly to commercial data sets. to address problems such as customer relationship management. market basket analysis. credit card fraud. etc. Often overlooked is the fact that data mining techniques have long been applied to scientific datasets. with fields such as remote sensing. astronomy. biology. physics. and chemistry. providing a rich environment for the practice of these techniques. In this paper. I describe the various scientific and engineering areas in which data mining is playing an important role and discuss some of the issues that make scientific data mining different from its …,True,PB82ll0AAAAJ:FPJr55Dyh1AC,1369,https://link.springer.com/chapter/10.1007/978-1-4615-1733-7_1,7426620267001903139,/scholar?cites=7426620267001903139,,,https://link.springer.com/content/pdf/10.1186/gb-2000-2-1-research0002.pdf,0,0,0
1277995,Robust techniques for background subtraction in urban traffic video,2004,S Cheung Sen-Ching and Chandrika Kamath,5308,,,881-892,International Society for Optics and Photonics,Identifying moving objects from a video sequence is a fundamental and  critical task in many computer-vision applications. A common approach is to perform background subtraction. which identifies moving objects from the portion of a video frame that differs significantly from a  background model. There are many challenges in developing a good background subtraction algorithm. First. it must be robust against changes in illumination. Second. it should avoid detecting non-stationary background objects such as swinging leaves. rain. snow. and shadow cast by moving objects. Finally. its internal background model should react quickly to changes in background such as starting and stopping of vehicles. In this paper. we compare various background  subtraction algorithms for detecting moving vehicles and pedestrians in urban traffic video sequences. We consider approaches varying from simple techniques such as …,True,PB82ll0AAAAJ:IWHjjKOFINEC,1046,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5308/0000/Robust-techniques-for-background-subtraction-in-urban-traffic-video/10.1117/12.526886.short,11610619655653227148,/scholar?cites=11610619655653227148,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.214.6703&rep=rep1&type=pdf,0,0,0
1277996,Observation of keyhole-mode laser melting in laser powder-bed fusion additive manufacturing,2014,Wayne E King and Holly D Barth and Victor M Castillo and Gilbert F Gallegos and John W Gibbs and Douglas E Hahn and Chandrika Kamath and Alexander M Rubenchik,214,Journal of Materials Processing Technology,12,2915-2925,Elsevier,Laser powder-bed fusion additive manufacturing of metals employs high-power focused laser beams. Typically. the depth of the molten pool is controlled by conduction of heat in the underlying solid material. But. under certain conditions. the mechanism of melting can change from conduction to so-called “keyhole-mode” laser melting. In this mode. the depth of the molten pool is controlled by evaporation of the metal. Keyhole-mode laser melting results in melt pool depths that can be much deeper than observed in conduction mode. In addition. the collapse of the vapor cavity that is formed by the evaporation of the metal can result in a trail of voids in the wake of the laser beam. In this paper. the experimental observation of keyhole-mode laser melting in a laser powder-bed fusion additive manufacturing setting for 316L stainless steel is presented. The conditions required to transition from conduction controlled …,True,PB82ll0AAAAJ:JoZmwDi-zQgC,652,https://www.sciencedirect.com/science/article/pii/S0924013614002283,3414296330468885853,/scholar?cites=3414296330468885853,,,https://www.osti.gov/servlets/purl/1502044,0,0,0
1277997,Laser powder bed fusion additive manufacturing of metals; physics. computational. and materials challenges,2015,Wayne E King and Andrew T Anderson and Robert M Ferencz and Neil E Hodge and Chandrika Kamath and Saad A Khairallah and Alexander M Rubenchik,2,,4,041304,AIP Publishing LLC,The production of metal parts via laser powder bed fusion additive manufacturing is growing exponentially. However. the transition of this technology from production of prototypes to production of critical parts is hindered by a lack of confidence in the quality of the part. Confidence can be established via a fundamental understanding of the physics of the process. It is generally accepted that this understanding will be increasingly achieved through modeling and simulation. However. there are significant physics. computational. and materials challenges stemming from the broad range of length and time scales and temperature ranges associated with the process. In this paper. we review the current state of the art and describe the challenges that need to be met to achieve the desired fundamental understanding of the physics of the process.,True,PB82ll0AAAAJ:JQOojiI6XY0C,551,https://aip.scitation.org/doi/abs/10.1063/1.4937809,12937035320949897781,/scholar?cites=12937035320949897781,,,,0,0,0
1277998,Robust background subtraction with foreground validation for urban traffic video,2005,Sen-Ching S Cheung and Chandrika Kamath,2005,EURASIP Journal on Advances in Signal Processing,14,1-11,SpringerOpen,Identifying moving objects in a video sequence is a fundamental and critical task in many computer-vision applications. Background subtraction techniques are commonly used to separate foreground moving objects from the background. Most background subtraction techniques assume a single rate of adaptation. which is inadequate for complex scenes such as a traffic intersection where objects are moving at different and varying speeds. In this paper. we propose a foreground validation algorithm that first builds a foreground mask using a slow-adapting Kalman filter. and then validates individual foreground pixels by a simple moving object model built using both the foreground and background statistics as well as the frame difference. Ground-truth experiments with urban traffic sequences show that our proposed algorithm significantly improves upon results using only Kalman filter or frame-differencing. and …,True,PB82ll0AAAAJ:qUcmZB5y_30C,355,https://link.springer.com/article/10.1155/ASP.2005.2330,9587305792361169016,/scholar?cites=9587305792361169016,,,https://link.springer.com/content/pdf/10.1155/ASP.2005.2330.pdf,0,0,0
1277999,Density of additively-manufactured. 316L SS parts using laser powder-bed fusion at powers up to 400 W,2014,C Kamath and B El-dasher and GF Gallegos and WE King and A Sisto,74,The International Journal of Advanced Manufacturing,1,65-78,Springer,Selective laser melting is a powder-based. additive-manufacturing process where a three-dimensional part is produced. layer by layer. by using a high-energy laser beam to fuse the metallic powder particles. A particular challenge in this process is the selection of appropriate process parameters that result in parts with desired properties. In this study. we describe an approach to selecting parameters for high-density (>99 %) parts using 316L stainless steel. Though there has been significant success in achieving near-full density for 316L parts. this work has been limited to laser powers <225 W. We discuss how we can exploit prior knowledge. design of computational experiments using a simple model of laser melting. and single-track experiments to determine the process parameters for use at laser powers up to 400 W. Our results show that. at higher power values. there is a large range of scan speeds …,True,PB82ll0AAAAJ:35r97b3x0nAC,280,https://link.springer.com/article/10.1007/s00170-014-5954-9?no-access%3Dtrue,8817589535977469517,/scholar?cites=8817589535977469517,,,,0,0,0
1278000,Denoising through wavelet shrinkage: an empirical study,2003,Imola K Fodor and Chandrika Kamath,12,Journal of Electronic Imaging,1,151-160,International Society for Optics and Photonics,Techniques based on thresholding of wavelet coefficients are gaining popularity for denoising data. The idea is to transform the data into the wavelet basis. where the ‘‘large’’coefficients are mainly the signal. and the ‘‘smaller’’ones represent the noise. By suitably modifying these coefficients. the noise can be removed from the data. We evaluate several 2-D denoising procedures using test images corrupted with additive Gaussian noise. We consider global. level-dependent. and subband-dependent implementations of these techniques. Our results. using the mean squared error as a measure of the quality of denoising. show that the SureShrink and the BayesShrink methods consistently outperform the other wavelet-based techniques. In contrast. we found that a combination of simple spatial filters lead to images that were grainier with smoother edges. though the error was smaller than in the waveletbased …,True,PB82ll0AAAAJ:hC7cP41nSMkC,256,https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-12/issue-1/0000/Denoising-through-wavelet-shrinkage-an-empirical-study/10.1117/1.1525793.short,10932937906924284672,/scholar?cites=10932937906924284672,,,,0,0,0
1278001,Data mining for scientific and engineering applications,2013,Robert L Grossman and Chandrika Kamath and Philip Kegelmeyer and Vipin Kumar and Raju Namburu,2,,,,Springer Science & Business Media,Advances in technology are making massive data sets common in many scientific disciplines. such as astronomy. medical imaging. bio-informatics. combinatorial chemistry. remote sensing. and physics. To find useful information in these data sets. scientists and engineers are turning to data mining techniques. This book is a collection of papers based on the first two in a series of workshops on mining scientific datasets. It illustrates the diversity of problems and application areas that can benefit from data mining. as well as the issues and challenges that differentiate scientific data mining from its commercial counterpart. While the focus of the book is on mining scientific data. the work is of broader interest as many of the techniques can be applied equally well to data arising in business and web applications. Audience: This work would be an excellent text for students and researchers who are familiar with the basic principles of data mining and want to learn more about the application of data mining to their problem in science or engineering.,True,PB82ll0AAAAJ:SdhP9T11ey4C,232,http://books.google.com/books?hl=en&lr=&id=h1zmBwAAQBAJ&oi=fnd&pg=PR11&dq=info:_ndijLF2VTwJ:scholar.google.com&ots=0T3-qtnD91&sig=u1GWUWgaLMwMS2HHHh4r0OHKAiE,4347511520232634366,/scholar?cites=4347511520232634366,,,,0,0,0
1278002,Overview of modelling and simulation of metal powder bed fusion process at Lawrence Livermore National Laboratory,2015,Wayne King and Andrew T Anderson and Robert M Ferencz and Neil E Hodge and Chandrika Kamath and Saad A Khairallah,31,Materials Science and Technology,8,957-968,Taylor & Francis,The metal laser powder bed fusion additive manufacturing process uses high power lasers to build parts layer upon layer by melting fine metal powders. Qualification of parts produced using this technology is broadly recognised as a significant challenge. Physics based process models have been identified as being foundational to qualification of additively manufactured metal parts. In the present article. a multiscale modelling strategy is described that will serve as the foundation upon which process control and part qualification can be built. This includes a model at the scale of the powder that simulates single track/single multilayer builds and provides powder bed and melt pool thermal data. A second model computationally builds a complete part and predicts manufactured properties (residual stress. dimensional accuracy) in three dimensions. Modelling is tied to experiment through data mining.,True,PB82ll0AAAAJ:_B80troHkn4C,222,https://www.tandfonline.com/doi/abs/10.1179/1743284714Y.0000000728,8517683717802378309,/scholar?cites=8517683717802378309,,,https://www.osti.gov/pages/servlets/purl/1502045,0,0,0
1278003,Inducing oblique decision trees with evolutionary algorithms,2003,Erick Cantu-Paz and Chandrika Kamath,7,IEEE Transactions on Evolutionary Computation,1,54-68,IEEE,This paper illustrates the application of evolutionary algorithms (EAs) to the problem of oblique decision-tree (DT) induction. The objectives are to demonstrate that EAs can find classifiers whose accuracy is competitive with other oblique tree construction methods. and that. at least in some cases. this can be accomplished in a shorter time. We performed experiments with a (1+1) evolution strategy and a simple genetic algorithm on public domain and artificial data sets. and compared the results with three other oblique and one axis-parallel DT algorithms. The empirical results suggest that the EAs quickly find competitive classifiers. and that EAs scale up better than traditional methods to the dimensionality of the domain and the number of instances used in training. In addition. we show that the classification accuracy improves when the trees obtained with the EAs are combined in ensembles. and that sometimes it is …,True,PB82ll0AAAAJ:-f6ydRqryjwC,197,https://ieeexplore.ieee.org/abstract/document/1179908/,4448567311457763334,/scholar?cites=4448567311457763334,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.7358&rep=rep1&type=pdf,0,0,0
1278004,An empirical comparison of combinations of evolutionary algorithms and neural networks for classification problems,2005,Erick Cantú-Paz and Chandrika Kamath,35,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",5,915-927,IEEE,There are numerous combinations of neural networks (NNs) and evolutionary algorithms (EAs) used in classification problems. EAs have been used to train the networks. design their architecture. and select feature subsets. However. most of these combinations have been tested on only a few data sets and many comparisons are done inappropriately measuring the performance on training data or without using proper statistical tests to support the conclusions. This paper presents an empirical evaluation of eight combinations of EAs and NNs on 15 public-domain and artificial data sets. Our objective is to identify the methods that consistently produce accurate classifiers that generalize well. In most cases. the combinations of EAs and NNs perform equally well on the data sets we tried and were not more accurate than hand-designed neural networks trained with simple backpropagation.,True,PB82ll0AAAAJ:mB3voiENLucC,185,https://ieeexplore.ieee.org/abstract/document/1510768/,4072164630512487702,/scholar?cites=4072164630512487702,,,http://ckamath.org/yahoo_site_admin/assets/docs/UCRL-JC-151936.364205932.pdf,0,0,0
1278005,Modeling. control and simulation of a PV/FC/UC based hybrid power generation system for stand-alone applications,2009,Mehmet Uzunoglu and OC Onar and MS Alam,34,Renewable energy,3,509-520,Pergamon,Different energy sources and converters need to be integrated to meet sustained load demands while accommodating various natural conditions. This paper focuses on the integration of photovoltaic (PV). fuel cell (FC) and ultra-capacitor (UC) systems for sustained power generation. In the proposed system. during adequate insolation. the PV system feeds the electrolyzer to produce hydrogen for future use and transfers energy to the load side if possible. Whenever the PV system cannot completely meet load demands. the FC system provides power to meet the remaining load. If the rate of load demand increases the outside limits of FC capability. the UC bank meets the load demand above that which is provided by PV and FC systems. The main contribution of this work is the hybridization of alternate energy sources with FC systems using long and short-term storage strategies with appropriate power controllers …,True,yaZDhAMAAAAJ:d1gkVwhDpl0C,374,https://www.sciencedirect.com/science/article/pii/S0960148108002498,13698559790311208725,/scholar?cites=13698559790311208725,,,https://www.academia.edu/download/50826023/Modeling_control_and_simulation_of_a_PVF20161210-3100-o1trj.pdf,0,0,0
1278006,A dynamic model for a stand-alone PEM fuel cell power plant for residential applications,2004,MY El-Sharkh and A Rahman and MS Alam and PC Byrne and AA Sakla and T Thomas,138,Journal of Power Sources,1-2,199-204,Elsevier,A dynamic electrochemical simulation model of a grid independent proton exchange membrane (PEM) fuel cell power plant is presented. The model includes the methanol reformer. the PEM stack. and the power conditioning unit. The model is then used to predict the output voltage and study the transient response of a PEM power plant when subjected to rapid changes in a residential load connected to it. The results show the fast response capabilities of the PEM power plant in following changes in the load.,True,yaZDhAMAAAAJ:u-x6o8ySG0sC,355,https://www.sciencedirect.com/science/article/pii/S0378775304006925,12010027447077106702,/scholar?cites=12010027447077106702,,,,0,0,0
1278007,Dynamic modeling. design. and simulation of a combined PEM fuel cell and ultracapacitor system for stand-alone residential applications,2006,Mehmet Uzunoglu and MS Alam,21,IEEE Transactions on Energy Conversion,3,767-775,IEEE,The available power generated from a fuel cell (FC) power plant may not be sufficient to meet sustained load demands. especially during peak demand or transient events encountered in stationary power plant applications. An ultracapacitor (UC) bank can supply a large burst of power. but it cannot store a significant amount of energy. The combined use of FC and UC has the potential for better energy efficiency. reducing the cost of FC technology. and improved fuel usage. In this paper. we present an FC that operates in parallel with a UC bank. A new dynamic model and design methodology for an FCand UC-based energy source for stand-alone residential applications has been developed. Simulation results are presented using MATLAB. Simulink. and SimPowerSystems environments based on the mathematical and dynamic electrical models developed for the proposed system,True,yaZDhAMAAAAJ:9yKSN-GCB0IC,340,https://ieeexplore.ieee.org/abstract/document/1677668/,18203803114189419572,/scholar?cites=18203803114189419572,,,https://www.researchgate.net/profile/Mehmet_Uzunoglu2/publication/261245732_Dynamic_modeling_design_and_simulation_of_a_combined_PEM_fuel_cell_and_ultra-capacitor_system_for_stand-alone_residential_applications/links/02e7e534431f5f0ed2000000/Dynamic-modeling-design-and-simulation-of-a-combined-PEM-fuel-cell-and-ultra-capacitor-system-for-stand-alone-residential-applications.pdf,0,0,0
1278008,Dynamic modeling. design and simulation of a wind/fuel cell/ultra-capacitor-based hybrid power generation system,2006,OC Onar and M Uzunoglu and MS Alam,161,Journal of power sources,1,707-722,Elsevier,Recent research and development of alternative energy sources have shown excellent potential as a form of contribution to conventional power generation systems. In order to meet sustained load demands during varying natural conditions. different energy sources and converters need to be integrated with each other for extended usage of alternative energy. The paper focuses on the combination of wind. fuel cell (FC) and ultra-capacitor (UC) systems for sustained power generation. As the wind turbine output power varies with the wind speed: an FC system with a UC bank can be integrated with the wind turbine to ensure that the system performs under all conditions. We propose herein a dynamic model. design and simulation of a wind/FC/UC hybrid power generation system with power flow controllers. In the proposed system. when the wind speed is sufficient. the wind turbine can meet the load demand while …,True,yaZDhAMAAAAJ:qjMakFHDy7sC,295,https://www.sciencedirect.com/science/article/pii/S0378775306006100,9258773905232169614,/scholar?cites=9258773905232169614,,,https://www.academia.edu/download/43364171/Dynamic_modeling_design_and_simulation_o20160304-28196-1axpmoz.pdf,0,0,0
1278009,Fringe-adjusted joint transform correlation,1993,Mohammad S Alam and Mohammad A Karim,32,Applied Optics,23,4344-4350,Optical Society of America,Improved correlation discrimination is achieved by using a fringe-adjusted joint transform correlator (JTC). This technique is found to yield significantly better correlation output than the classical and binary JTC’s for input scenes involving single as well as multiple objects. It also avoids the computation-intensive Fourier-plane joint power spectrum binarization processing of a binary JTC. Two optical implementations for the proposed technique are also suggested.,True,yaZDhAMAAAAJ:u5HHmVD_uO8C,288,https://www.osapublishing.org/abstract.cfm?uri=ao-32-23-4344,3090245896939258015,/scholar?cites=3090245896939258015,,,https://www.academia.edu/download/49116794/AO.32.00434420160925-3681-1uk1j2l.pdf,0,0,0
1278010,Modeling. control and simulation of an autonomous wind turbine/photovoltaic/fuel cell/ultra-capacitor hybrid power system,2008,Omer C Onar and Mehmet Uzunoglu and Mohammad S Alam,185,Journal of Power Sources,2,1273-1283,Elsevier,This paper focuses on the combination of wind turbine (WT). photovoltaic (PV). fuel cell (FC) and ultra-capacitor (UC) systems for grid-independent applications. The dynamic behavior of the proposed hybrid system is tested under various wind speed. solar radiation and load demand conditions. The developed model and its control strategy exhibit excellent performance for the simulation of a complete day. In the simulation. the solar radiation and power demand data are based on real world measurements. while the wind speed data are quasi-real because it is simulated based on special wind speed generation algorithms.,True,yaZDhAMAAAAJ:UeHWp8X0CEIC,256,https://www.sciencedirect.com/science/article/pii/S0378775308017497,7546271981996121513,/scholar?cites=7546271981996121513,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.726.8488&rep=rep1&type=pdf,0,0,0
1278011,Infrared image registration and high-resolution reconstruction using multiple translationally shifted aliased video frames,2000,Mohammad S Alam and John G Bognar and Russell C Hardie and Brian J Yasuda,49,IEEE Transactions on instrumentation and measurement,5,915-923,IEEE,Forward looking infrared (FLIR) detector arrays generally produce spatially undersampled images because the FLIR arrays cannot be made dense enough to yield a sufficiently high spatial sampling frequency. Multi-frame techniques. such as microscanning. are an effective means of reducing aliasing and increasing resolution in images produced by staring imaging systems. These techniques involve interlacing a set of image frames that have been shifted with respect to each other during acquisition. The FLIR system is mounted on a moving platform. such as an aircraft. and the vibrations associated with the platform are used to generate the shifts. Since a fixed number of image frames is required. and the shifts are random. the acquired frames will not fall on a uniformly spaced grid. Furthermore. some of the acquired frames may have almost similar shifts thus making them unusable for high-resolution image …,True,yaZDhAMAAAAJ:2osOgNQ5qMEC,246,https://ieeexplore.ieee.org/abstract/document/872908/,1397595129428476806,/scholar?cites=1397595129428476806,,,https://pdfs.semanticscholar.org/ab8e/17fabd9f664dd3c2bdbd74de01539f688a70.pdf,0,0,0
1278012,Dynamic modeling. design and simulation of a PEM fuel cell/ultra-capacitor hybrid system for vehicular applications,2007,Mehmet Uzunoglu and MS Alam,48,Energy Conversion and Management,5,1544-1553,Pergamon,Fuel cell (FC) technologies are expected to become a viable solution for vehicular applications because they use alternative fuel converters and are environmentally friendly. However. a stand alone FC system may not be sufficient to satisfy the load demands. especially during cold start. peak demand periods or transient events. for vehicular applications. In addition. the FC system is not capable of being reversed for regenerative energy. An ultra-capacitor (UC) bank can supply a large burst of power but cannot store much energy. By operating the FC and UC in parallel. both steady state and peak power demands can be satisfied. Use of a FC/UC hybrid model provides a potential solution for better energy efficiency while reducing the cost of FC power technology. This paper describes a new modeling and design methodology for FC/UC hybrid vehicular power systems. A feasible design and a dynamic model have …,True,yaZDhAMAAAAJ:IjCSPb-OGe4C,202,https://www.sciencedirect.com/science/article/pii/S0196890406003633,10132215588679295527,/scholar?cites=10132215588679295527,,,https://www.academia.edu/download/43364153/Dynamic_modeling_design_and_simulation_o20160304-1332-1tubelp.pdf,0,0,0
1278013,Load sharing using fuzzy logic control in a fuel cell/ultracapacitor hybrid vehicle,2009,MC Kisacikoglu and M Uzunoglu and MS Alam,34,International journal of hydrogen energy,3,1497-1507,Pergamon,Fuel cell (FC) and ultracapacitor (UC) based hybrid power systems appear to be very promising for satisfying high energy and high power requirements of vehicular applications. The improvement in control strategies enhances dynamic response of the FC/UC hybrid vehicular power system under various load conditions. In this study. FC system and UC bank supply power demand using a current-fed full bridge dc–dc converter and a bidirectional dc–dc converter. respectively. We focus on a novel fuzzy logic control algorithm integrated into the power conditioning unit (PCU) for the hybrid system. The control strategy is capable of determining the desired FC power and keeps the dc voltage around its nominal value by supplying propulsion power and recuperating braking energy. Simulation results obtained using MATLAB® & Simulink® and ADVISOR® are presented to verify the effectiveness of the proposed control …,True,yaZDhAMAAAAJ:Tyk-4Ss8FVUC,175,https://www.sciencedirect.com/science/article/pii/S036031990801505X,9209466360714025110,/scholar?cites=9209466360714025110,,,https://www.academia.edu/download/43364172/Load_sharing_using_fuzzy_logic_control_i20160304-9571-4bm065.pdf,0,0,0
1278014,Modeling and analysis of an FC/UC hybrid vehicular power system using a novel-wavelet-based load sharing algorithm,2008,M Uzunoglu and MS Alam,23,IEEE Transactions on Energy Conversion,1,263-272,IEEE,The most critical attribute of a power control strategy for a fuel cell (FC) and ultracapacitor (UC) based hybrid vehicular power system is the sharing of load demand between available power sources. Transients and rapid changes of the power demand may cause drying of the FC membrane resulting in degradation of FC lifetime. The load demand profile of a hybrid electric vehicle (HEV) is a nonstationary fluctuating signal and consists of transients. Wavelet transforms are suitable for analyzing and evaluating such signals for dynamic systems. This paper focuses on the integration of a developed novel-wavelet-based load sharing algorithm and dynamic model of the FC/UC hybrid vehicular power system in order to ensure efficient power flow control strategy.,True,yaZDhAMAAAAJ:YsMSGLbcyi4C,173,https://ieeexplore.ieee.org/abstract/document/4407746/,13432964055048916809,/scholar?cites=13432964055048916809,,,https://www.academia.edu/download/43364138/Modeling_and_Analysis_of_an_FCUC_Hybrid_20160304-1337-nznyxb.pdf,0,0,0
1278015,Multiple target detection using a modified fringe-adjusted joint transform correlator,1994,Mohammad S Alam Mohammad A Karim,33,Optical engineering,5,1610-1617,,We investigate the performance of a modified fringe-adjusted joint transform correlator for detecting multiple targets present in an input scene. This technique. involving adjustment of the joint power spectrum (JPS) on the basis of the input-scene-only power spectrum. and apodization of the modified JPS on the basis of the reference signal power spectrum. is found to yield good correlation output. Simulation results are presented to verify the performance of the proposed technique.,True,yaZDhAMAAAAJ:zYLM7Y9cAGgC,145,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-33/issue-5/0000/Multiple-target-detection-using-a-modified-fringe-adjusted-joint-transform/10.1117/12.168418.short,3874465291842270781,/scholar?cites=3874465291842270781,,,,0,0,0
1278016,Local features and kernels for classification of texture and object categories: A comprehensive study,2007,Jianguo Zhang and Marcin Marszalek and Svetlana Lazebnik and Cordelia Schmid,73,International Journal of Computer Vision,2,2007,Ieee,Recently. methods based on local image features have shown promise for texture and object recognition tasks. This paper presents a large-scale evaluation of an approach that represents images as distributions (signatures or histograms) of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions. the Earth Mover’s Distance and the χ2 distance. We first evaluate the performance of our approach with different keypoint detectors and descriptors. as well as different kernels and classifiers. We then conduct a comparative evaluation with several state-of-the-art recognition methods on four texture and five object databases. On most of these databases. our implementation exceeds the best reported results and achieves comparable performance on the rest. Finally. we investigate the …,True,ypSmZtIAAAAJ:u5HHmVD_uO8C,2557,https://link.springer.com/content/pdf/10.1007/s11263-006-9794-4.pdf,11724468661015993430,/scholar?cites=11724468661015993430,,,https://hal.archives-ouvertes.fr/docs/00/17/14/12/PDF/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf,0,0,0
1278017,Beyond triplet loss: a deep quadruplet network for person re-identification,2017,Weihua Chen and Xiaotang Chen and Jianguo Zhang and Kaiqi Huang,,CVPR 2017,,,,Person re-identification (ReID) is an important task in wide area video surveillance which focuses on identifying people across different cameras. Recently. deep learning networks with a triplet loss become a common framework for person ReID. However. the triplet loss pays main attentions on obtaining correct orders on the training set. It still suffers from a weaker generalization capability from the training set to the testing set. thus resulting in inferior performance. In this paper. we design a quadruplet loss. which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result. our model has a better generalization ability and can achieve a higher performance on the testing set. In particular. a quadruplet deep network using a margin-based online hard negative mining is proposed based on the quadruplet loss for the person ReID. In extensive experiments. the proposed network outperforms most of the state-of-the-art algorithms on representative datasets which clearly demonstrates the effectiveness of our proposed method.,True,ypSmZtIAAAAJ:sKr7fXDwJhsC,740,http://openaccess.thecvf.com/content_cvpr_2017/html/Chen_Beyond_Triplet_Loss_CVPR_2017_paper.html,15352923940543802650,/scholar?cites=15352923940543802650,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_Beyond_Triplet_Loss_CVPR_2017_paper.pdf,0,0,0
1278018,Brief review of invariant texture analysis methods,2002,Jianguo Zhang and Tieniu Tan,35,Pattern recognition,3,735-747,Pergamon,This paper considers invariant texture analysis. Texture analysis approaches whose performances are not affected by translation. rotation. affine. and perspective transform are addressed. Existing invariant texture analysis algorithms are carefully studied and classified into three categories: statistical methods. model based methods. and structural methods. The importance of invariant texture analysis is presented first. Each approach is reviewed according to its classification. and its merits and drawbacks are outlined. The focus of possible future work is also suggested.,True,ypSmZtIAAAAJ:u-x6o8ySG0sC,613,https://www.sciencedirect.com/science/article/pii/S0031320301000747,339225468289985740,/scholar?cites=339225468289985740,,,http://thoth.inrialpes.fr/people/zhang/PR_TextureReview_Published.pdf,0,0,0
1278019,Identifying the best machine learning algorithms for brain tumor segmentation. progression assessment. and overall survival prediction in the BRATS challenge,2018,Spyridon Bakas and Mauricio Reyes and Andras Jakab and Stefan Bauer and Markus Rempfler and Alessandro Crimi and Russell Takeshi Shinohara and Christoph Berger and Sung Min Ha and Martin Rozycki and Marcel Prastawa and Esther Alberts and Jana Lipkova and John Freymann and Justin Kirby and Michel Bilello and Hassan Fathallah-Shaykh and Roland Wiest and Jan Kirschke and Benedikt Wiestler and Rivka Colen and Aikaterini Kotrotsou and Pamela Lamontagne and Daniel Marcus and Mikhail Milchenko and Arash Nazeri and Marc-Andre Weber and Abhishek Mahajan and Ujjwal Baid and Dongjin Kwon and Manu Agarwal and Mahbubul Alam and Alberto Albiol and Antonio Albiol and Varghese Alex and Tuan Anh Tran and Tal Arbel and Aaron Avery and Subhashis Banerjee and Thomas Batchelder and Kayhan Batmanghelich and Enzo Battistella and Martin Bendszus and Eze Benson and Jose Bernal and George Biros and Mariano Cabezas and Siddhartha Chandra and Yi-Ju Chang and Joseph Chazalon and Shengcong Chen and Wei Chen and Jefferson Chen and Kun Cheng and Meinel Christoph and Roger Chylla and Albert Clérigues and Anthony Costa and Xiaomeng Cui and Zhenzhen Dai and Lutao Dai and Eric Deutsch and Changxing Ding and Chao Dong and Wojciech Dudzik and Théo Estienne and Hyung Eun Shin and Richard Everson and Jonathan Fabrizio and Longwei Fang and Xue Feng and Lucas Fidon and Naomi Fridman and Huan Fu and David Fuentes and David G Gering and Yaozong Gao and Evan Gates and Amir Gholami and Mingming Gong and Sandra González-Villá and J Gregory Pauloski and Yuanfang Guan and Sheng Guo and Sudeep Gupta and Meenakshi H Thakur and Klaus H Maier-Hein and Woo-Sup Han and Huiguang He and Aura Hernández-Sabaté and Evelyn Herrmann and Naveen Himthani and Winston Hsu and Cheyu Hsu and Xiaojun Hu and Xiaobin Hu and Yan Hu and Yifan Hu and Rui Hua,,arXiv preprint arXiv:1811.02629,,,,Gliomas are the most common primary brain malignancies. with different degrees of aggressiveness. variable prognosis and various heterogeneous histologic sub-regions. ie. peritumoral edematous/invaded tissue. necrotic core. active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype. as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans. reflecting varying biological properties. Their heterogeneous shape. extent. and location are some of the factors that make these tumors difficult to resect. and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans. when evaluating the apparent tumor for potential diagnosis of progression. Furthermore. there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans. during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge. ie. 2012-2018. Specifically. we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans. ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions. beyond use of the RECIST/RANO criteria. and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally. we investigate the challenge …,True,ypSmZtIAAAAJ:Je7pCM3taV4C,487,https://arxiv.org/abs/1811.02629,7713865873909162489,/scholar?cites=7713865873909162489,,,https://arxiv.org/pdf/1811.02629,0,0,0
1278020,Jointly Learning Heterogeneous Features for RGB-D Activity Recognition,2017,Jianfang Hu and weishi Zheng and Jianhuang Lai and Jianguo Zhang,,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,,In this paper. we focus on heterogeneous feature learning for RGB-D activity recognition. Considering that features from different channels could share some similar hidden structures. we propose a joint learning model to simultaneously explore the shared and feature-specific components as an instance of heterogenous multi-task learning. The proposed model in an unified framework is capable of: 1) jointly mining a set of subspaces with the same dimensionality to enable the multi-task classifier learning. and 2) meanwhile. quantifying the shared and feature-specific components of features in the subspaces. To efficiently train the joint model. a three-step iterative optimization algorithm is proposed. followed by two inference models. Extensive results on three activity datasets have demonstrated the efficacy of the proposed method. In addition. a novel RGB-D activity dataset focusing on human-object interaction is collected for evaluating the proposed method. which will be made available to the community for RGB-D activity benchmarking and analysis.,True,ypSmZtIAAAAJ:0gcXA2g3FJ8C,395,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Hu_Jointly_Learning_Heterogeneous_2015_CVPR_paper.html,16687270898029410787,/scholar?cites=16687270898029410787,,,https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Hu_Jointly_Learning_Heterogeneous_2015_CVPR_paper.pdf,0,0,0
1278021,Pascal visual object classes challenge results,2005,Mark Everingham and Luc Van Gool and Chris Williams and J Winn and A Zisserman,1,Available from www. pascal-network. org,6,7,,The goal of this challenge is to recognize objects from a number of visual object classes in images of realistic scenes. It is fundamentally a supervised learning learning problem in that a training set of labelled images is provided. The object classes are: motorbikes. bicycles. people and cars. Twelve participants entered the challenge. A full description of the challenge including software and image sets is available on the web page http://www. pascal-network. org/challenges/VOC/voc/index. html.,True,ypSmZtIAAAAJ:8yP2RQ87vS4C,384,https://www.researchgate.net/profile/Luc_Van_Gool/publication/244437609_Pascal_Visual_Object_Classes_Challenge_Results/links/57224ce808aee491cb32fd24/Pascal-Visual-Object-Classes-Challenge-Results.pdf,5784516896244010342,/scholar?cites=5784516896244010342,,,https://www.researchgate.net/profile/Luc_Van_Gool/publication/244437609_Pascal_Visual_Object_Classes_Challenge_Results/links/57224ce808aee491cb32fd24/Pascal-Visual-Object-Classes-Challenge-Results.pdf,0,0,0
1278022,The 2005 pascal visual object classes challenge,2006,Mark Everingham and Andrew Zisserman and Christopher KI Williams and Luc Van Gool and Moray Allan and Christopher M Bishop and Olivier Chapelle and Navneet Dalal and Thomas Deselaers and Gyuri Dorkó and Stefan Duffner and Jan Eichhorn and Jason DR Farquhar and Mario Fritz and Christophe Garcia and Tom Griffiths and Frederic Jurie and Daniel Keysers and Markus Koskela and Jorma Laaksonen and Diane Larlus and Bastian Leibe and Hongying Meng and Hermann Ney and Bernt Schiele and Cordelia Schmid and Edgar Seemann and John Shawe-Taylor and Amos Storkey and Sandor Szedmak and Bill Triggs and Ilkay Ulusoy and Ville Viitaniemi and Jianguo Zhang,,,,117-176,Springer Berlin Heidelberg,The PASCAL Visual Object Classes Challenge ran from February to March 2005. The goal of the challenge was to recognize objects from a number of visual object classes in realistic scenes (i.e. not pre-segmented objects). Four object classes were selected: motorbikes. bicycles. cars and people. Twelve teams entered the challenge. In this chapter we provide details of the datasets. algorithms used by the teams. evaluation criteria. and results achieved.,True,ypSmZtIAAAAJ:d1gkVwhDpl0C,300,https://link.springer.com/chapter/10.1007/11736790_8,5784516896244010342,/scholar?cites=5784516896244010342,,,https://hal.inria.fr/inria-00548597/file/EZKVAMCDDDDEDFGGJKKL.pdf,0,0,0
1278023,Dataset issues in object recognition,2006,Jean Ponce and Tamara L Berg and Mark Everingham and David A Forsyth and Martial Hebert and Svetlana Lazebnik and Marcin Marszalek and Cordelia Schmid and Bryan C Russell and Antonio Torralba and Christopher KI Williams and Jianguo Zhang and Andrew Zisserman,,,,29-48,Springer Berlin Heidelberg,Appropriate datasets are required at all stages of object recognition research. including learning visual models of object and scene categories. detecting and localizing instances of these models in images. and evaluating the performance of recognition algorithms. Current datasets are lacking in several respects. and this paper discusses some of the lessons learned from existing efforts. as well as innovative ways to obtain very large and diverse annotated datasets. It also suggests a few criteria for gathering future datasets.,True,ypSmZtIAAAAJ:9yKSN-GCB0IC,268,https://link.springer.com/chapter/10.1007/11957959_2,3020094276534614399,/scholar?cites=3020094276534614399,,,http://w3.cs.huji.ac.il/~daphna/course/CoursePapers/Ponce_etal2006.pdf,0,0,0
1278024,Invariant texture segmentation via circular Gabor filters,2002,Jainguo Zhang and Tieniu Tan and Li Ma,2,,,901-904,IEEE,In this paper. we focus on invariant texture segmentation. and propose a new method using circular Gabor filters (CGF) for rotation invariant texture segmentation. The traditional Gabor function is modified into a circular symmetric version. The rotation invariant texture features are achieved via the channel output of the CGF. A new scheme of the selection of Gabor parameters is also proposed for texture segmentation. Experiments show the efficacy of this method.,True,ypSmZtIAAAAJ:ic8hN12bw4QC,190,https://ieeexplore.ieee.org/abstract/document/1048450/,9516122456919996255,/scholar?cites=9516122456919996255,,,https://hal.inria.fr/docs/00/54/82/47/PDF/ICPR_857.pdf,0,0,0
1278025,A multi-task deep network for person re-identification,2017,Kaiqi Huang Weihua Chen and Xiaotang Chen and Jianguo Zhang,,,,,,,True,ypSmZtIAAAAJ:uyKNayaHYpEC,183,,8761948355560963456,/scholar?cites=8761948355560963456,,,,0,0,0
1278026,A Multi-Task Deep Network for Person Re-Identification.,2017,Weihua Chen and Xiaotang Chen and Jianguo Zhang and Kaiqi Huang,,,,3988-3994,,Person re-identification (ReID) focuses on identifying people across different scenes in video surveillance. which is usually formulated as a binary classification task or a ranking task in current person ReID approaches. In this paper. we take both tasks into account and propose a multi-task deep network (MTDnet) that makes use of their own advantages and jointly optimize the two tasks simultaneously for person ReID. To the best of our knowledge. we are the first to integrate both tasks in one network to solve the person ReID. We show that our proposed architecture significantly boosts the performance. Furthermore. deep architecture in general requires a sufficient dataset for training. which is usually not met in person ReID. To cope with this situation. we further extend the MTDnet and propose a cross-domain architecture that is capable of using an auxiliary set to assist training on small target sets. In the experiments. our approach outperforms most of existing person ReID algorithms on representative datasets including CUHK03. CUHK01. VIPeR. iLIDS and PRID2011. which clearly demonstrates the effectiveness of the proposed approach.,True,ypSmZtIAAAAJ:13w6eF36Lq4C,183,https://ojs.aaai.org/index.php/AAAI/article/view/11201,8761948355560963456,/scholar?cites=8761948355560963456,,,https://ojs.aaai.org/index.php/AAAI/article/download/11201/11060,0,0,0
1278027,CANDELS: the cosmic assembly near-infrared deep extragalactic legacy survey,2011,Norman A Grogin and Dale D Kocevski and SM Faber and Henry C Ferguson and Anton M Koekemoer and Adam G Riess and Viviana Acquaviva and David M Alexander and Omar Almaini and Matthew LN Ashby and Marco Barden and Eric F Bell and Frédéric Bournaud and Thomas M Brown and Karina I Caputi and Stefano Casertano and Paolo Cassata and Marco Castellano and Peter Challis and Ranga-Ram Chary and Edmond Cheung and Michele Cirasuolo and Christopher J Conselice and Asantha Roshan Cooray and Darren J Croton and Emanuele Daddi and Tomas Dahlen and Romeel Davé and Duília F De Mello and Avishai Dekel and Mark Dickinson and Timothy Dolch and Jennifer L Donley and James S Dunlop and Aaron A Dutton and David Elbaz and Giovanni G Fazio and Alexei V Filippenko and Steven L Finkelstein and Adriano Fontana and Jonathan P Gardner and Peter M Garnavich and Eric Gawiser and Mauro Giavalisco and Andrea Grazian and Yicheng Guo and Nimish P Hathi and Boris Häussler and Philip F Hopkins and Jia-Sheng Huang and Kuang-Han Huang and Saurabh W Jha and Jeyhan S Kartaltepe and Robert P Kirshner and David C Koo and Kamson Lai and Kyoung-Soo Lee and Weidong Li and Jennifer M Lotz and Ray A Lucas and Piero Madau and Patrick J McCarthy and Elizabeth J McGrath and Daniel H McIntosh and Ross J McLure and Bahram Mobasher and Leonidas A Moustakas and Mark Mozena and Kirpal Nandra and Jeffrey A Newman and Sami-Matias Niemi and Kai G Noeske and Casey J Papovich and Laura Pentericci and Alexandra Pope and Joel R Primack and Abhijith Rajan and Swara Ravindranath and Naveen A Reddy and Alvio Renzini and Hans-Walter Rix and Aday R Robaina and Steven A Rodney and David J Rosario and Piero Rosati and Sara Salimbeni and Claudia Scarlata and Brian Siana and Luc Simard and Joseph Smidt and Rachel S Somerville and Hyron Spinrad and Amber N Straughn and Louis-Gregory Strolger and Olivia Telford and Harry I Teplitz and Jonathan R Trump and Arjen Van Der Wel and Carolin Villforth and Risa H Wechsler and Benjamin J Weiner and Tommy Wiklind and Vivienne Wild and Grant Wilson and Stijn Wuyts and Hao-Jing Yan and Min S Yun,197,The Astrophysical Journal Supplement Series,2,35,IOP Publishing,The Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS) is designed to document the first third of galactic evolution. over the approximate redshift (z) range 8-1.5. It will image> 250.000 distant galaxies using three separate cameras on the Hubble Space Telescope. from the mid-ultraviolet to the near-infrared. and will find and measure Type Ia supernovae at z> 1.5 to test their accuracy as standardizable candles for cosmology. Five premier multi-wavelength sky regions are selected. each with extensive ancillary data. The use of five widely separated fields mitigates cosmic variance and yields statistically robust and complete samples of galaxies down to a stellar mass of 10 9 M☉ to z≈ 2. reaching the knee of the ultraviolet luminosity function of galaxies to z≈ 8. The survey covers approximately 800 arcmin 2 and is divided into two parts. The CANDELS/Deep survey (5σ point-source limit …,True,o4MuRUEAAAAJ:u5HHmVD_uO8C,1666,https://iopscience.iop.org/article/10.1088/0067-0049/197/2/35/meta,5618508779226196673,/scholar?cites=5618508779226196673,,,https://iopscience.iop.org/article/10.1088/0067-0049/197/2/35/pdf,0,0,0
1278028,CANDELS: the cosmic assembly near-infrared deep extragalactic legacy survey—the Hubble Space Telescope observations. imaging data products. and mosaics,2011,Anton M Koekemoer and SM Faber and Henry C Ferguson and Norman A Grogin and Dale D Kocevski and David C Koo and Kamson Lai and Jennifer M Lotz and Ray A Lucas and Elizabeth J McGrath and Sara Ogaz and Abhijith Rajan and Adam G Riess and Steve A Rodney and Louis Strolger and Stefano Casertano and Marco Castellano and Tomas Dahlen and Mark Dickinson and Timothy Dolch and Adriano Fontana and Mauro Giavalisco and Andrea Grazian and Yicheng Guo and Nimish P Hathi and Kuang-Han Huang and Arjen Van Der Wel and Hao-Jing Yan and Viviana Acquaviva and David M Alexander and Omar Almaini and Matthew LN Ashby and Marco Barden and Eric F Bell and Frédéric Bournaud and Thomas M Brown and Karina I Caputi and Paolo Cassata and Peter J Challis and Ranga-Ram Chary and Edmond Cheung and Michele Cirasuolo and Christopher J Conselice and Asantha Roshan Cooray and Darren J Croton and Emanuele Daddi and Romeel Davé and Duilia F De Mello and Loic De Ravel and Avishai Dekel and Jennifer L Donley and James S Dunlop and Aaron A Dutton and David Elbaz and Giovanni G Fazio and Alexei V Filippenko and Steven L Finkelstein and Chris Frazer and Jonathan P Gardner and Peter M Garnavich and Eric Gawiser and Ruth Gruetzbauch and Will G Hartley and Boris Häussler and Jessica Herrington and Philip F Hopkins and Jia-Sheng Huang and Saurabh W Jha and Andrew Johnson and Jeyhan S Kartaltepe and Ali A Khostovan and Robert P Kirshner and Caterina Lani and Kyoung-Soo Lee and Weidong Li and Piero Madau and Patrick J McCarthy and Daniel H McIntosh and Ross J McLure and Conor McPartland and Bahram Mobasher and Heidi Moreira and Alice Mortlock and Leonidas A Moustakas and Mark Mozena and Kirpal Nandra and Jeffrey A Newman and Jennifer L Nielsen and Sami Niemi and Kai G Noeske and Casey J Papovich and Laura Pentericci and Alexandra Pope and Joel R Primack and Swara Ravindranath and Naveen A Reddy and Alvio Renzini and Hans-Walter Rix and Aday R Robaina and David J Rosario and Piero Rosati and Sara Salimbeni and Claudia Scarlata and Brian Siana and Luc Simard and Joseph Smidt and Diana Snyder and Rachel S Somerville and Hyron Spinrad and Amber N Straughn and Olivia Telford and Harry I Teplitz and Jonathan R Trump and Carlos Vargas and Carolin Villforth and Cory R Wagner and Pat Wandro and Risa H Wechsler and Benjamin J Weiner and Tommy Wiklind and Vivienne Wild and Grant Wilson and Stijn Wuyts and Min S Yun,197,The Astrophysical Journal Supplement Series,2,36,IOP Publishing,This paper describes the Hubble Space Telescope imaging data products and data reduction procedures for the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS). This survey is designed to document the evolution of galaxies and black holes at z≈ 1.5-8. and to study Type Ia supernovae at z> 1.5. Five premier multi-wavelength sky regions are selected. each with extensive multi-wavelength observations. The primary CANDELS data consist of imaging obtained in the Wide Field Camera 3 infrared channel (WFC3/IR) and the WFC3 ultraviolet/optical channel. along with the Advanced Camera for Surveys (ACS). The CANDELS/Deep survey covers~ 125 arcmin 2 within GOODS-N and GOODS-S. while the remainder consists of the CANDELS/Wide survey. achieving a total of~ 800 arcmin 2 across GOODS and three additional fields (Extended Groth Strip. COSMOS. and Ultra-Deep …,True,o4MuRUEAAAAJ:u-x6o8ySG0sC,1589,https://iopscience.iop.org/article/10.1088/0067-0049/197/2/36/meta,2814892824998047865,/scholar?cites=2814892824998047865,,,https://iopscience.iop.org/article/10.1088/0067-0049/197/2/36/pdf,0,0,0
1278029,Galaxy structure and mode of star formation in the SFR-mass plane from z∼ 2.5 to z∼ 0.1,2011,Stijn Wuyts and Natascha M Förster Schreiber and Arjen van der Wel and Benjamin Magnelli and Yicheng Guo and Reinhard Genzel and Dieter Lutz and Hervé Aussel and Guillermo Barro and Stefano Berta and Antonio Cava and Javier Graciá-Carpio and Nimish P Hathi and Kuang-Han Huang and Dale D Kocevski and Anton M Koekemoer and Kyoung-Soo Lee and Emeric Le Floc'h and Elizabeth J McGrath and Raanan Nordon and Paola Popesso and Francesca Pozzi and Laurie Riguccini and Giulia Rodighiero and Amelie Saintonge and Linda Tacconi,742,The Astrophysical Journal,2,96,IOP Publishing,"We analyze the dependence of galaxy structure (size and Sérsic index) and mode of star formation (Σ SFR and SFR IR/SFR UV) on the position of galaxies in the star formation rate (SFR) versus mass diagram. Our sample comprises roughly 640.000 galaxies at z~ 0.1. 130.000 galaxies at z~ 1. and 36.000 galaxies at z~ 2. Structural measurements for all but the z~ 0.1 galaxies are based on Hubble Space Telescope imaging. and SFRs are derived using a Herschel-calibrated ladder of SFR indicators. We find that a correlation between the structure and stellar population of galaxies (ie. a"" Hubble sequence"") is already in place since at least z~ 2.5. At all epochs. typical star-forming galaxies on the main sequence are well approximated by exponential disks. while the profiles of quiescent galaxies are better described by de Vaucouleurs profiles. In the upper envelope of the main sequence. the relation between the …",True,o4MuRUEAAAAJ:hMod-77fHWUC,656,https://iopscience.iop.org/article/10.1088/0004-637X/742/2/96/meta,20532847187323735,/scholar?cites=20532847187323735,,,https://iopscience.iop.org/article/10.1088/0004-637X/742/2/96/pdf,0,0,0
1278030,CANDELS: The progenitors of compact quiescent galaxies at z∼ 2,2013,Guillermo Barro and SM Faber and Pablo G Pérez-González and David C Koo and Christina C Williams and Dale D Kocevski and Jonathan R Trump and Mark Mozena and Elizabeth McGrath and Arjen Van Der Wel and Stijn Wuyts and Eric F Bell and Darren J Croton and Daniel Ceverino and Avishai Dekel and MLN Ashby and Edmond Cheung and Henry C Ferguson and Adriano Fontana and Jerome Fang and Mauro Giavalisco and Norman A Grogin and Yicheng Guo and Nimish P Hathi and Philip F Hopkins and Kuang-Han Huang and Anton M Koekemoer and Jeyhan S Kartaltepe and Kyoung-Soo Lee and Jeffrey A Newman and Lauren A Porter and Joel R Primack and Russell E Ryan and David Rosario and Rachel S Somerville and Mara Salvato and Li-Ting Hsu,765,The Astrophysical Journal,2,104,IOP Publishing,We combine high-resolution Hubble Space Telescope/WFC3 images with multi-wavelength photometry to track the evolution of structure and activity of massive (M sstarf> 10 10 M☉) galaxies at redshifts z= 1.4-3 in two fields of the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey. We detect compact. star-forming galaxies (cSFGs) whose number densities. masses. sizes. and star formation rates (SFRs) qualify them as likely progenitors of compact. quiescent. massive galaxies (cQGs) at z= 1.5-3. At z gsim 2. cSFGs present SFR= 100-200 M☉ yr–1. yet their specific star formation rates (sSFR~ 10–9 yr–1) are typically half that of other massive SFGs at the same epoch. and host X-ray luminous active galactic nuclei (AGNs) 30 times (~ 30%) more frequently. These properties suggest that cSFGs are formed by gas-rich processes (mergers or disk-instabilities) that induce a compact starburst and feed an …,True,o4MuRUEAAAAJ:IjCSPb-OGe4C,415,https://iopscience.iop.org/article/10.1088/0004-637X/765/2/104/meta,13489595632265167239,/scholar?cites=13489595632265167239,,,https://iopscience.iop.org/article/10.1088/0004-637X/765/2/104/pdf,0,0,0
1278031,A critical assessment of photometric redshift methods: a CANDELS investigation,2013,Tomas Dahlen and Bahram Mobasher and Sandra M Faber and Henry C Ferguson and Guillermo Barro and Steven L Finkelstein and Kristian Finlator and Adriano Fontana and Ruth Gruetzbauch and Seth Johnson and Janine Pforr and Mara Salvato and Tommy Wiklind and Stijn Wuyts and Viviana Acquaviva and Mark E Dickinson and Yicheng Guo and Jiasheng Huang and Kuang-Han Huang and Jeffrey A Newman and Eric F Bell and Christopher J Conselice and Audrey Galametz and Eric Gawiser and Mauro Giavalisco and Norman A Grogin and Nimish Hathi and Dale Kocevski and Anton M Koekemoer and David C Koo and Kyoung-Soo Lee and Elizabeth J McGrath and Casey Papovich and Michael Peth and Russell Ryan and Rachel Somerville and Benjamin Weiner and Grant Wilson,775,The Astrophysical Journal,2,93,IOP Publishing,We present results from the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS) photometric redshift methods investigation. In this investigation. the results from 11 participants. each using a different combination of photometric redshift code. template spectral energy distributions (SEDs). and priors. are used to examine the properties of photometric redshifts applied to deep fields with broadband multi-wavelength coverage. The photometry used includes U-band through mid-infrared filters and was derived using the TFIT method. Comparing the results. we find that there is no particular code or set of template SEDs that results in significantly better photometric redshifts compared to others. However. we find that codes producing the lowest scatter and outlier fraction utilize a training sample to optimize photometric redshifts by adding zero-point offsets. template adjusting. or adding extra …,True,o4MuRUEAAAAJ:zYLM7Y9cAGgC,334,https://iopscience.iop.org/article/10.1088/0004-637X/775/2/93/meta,10015229640072712741,/scholar?cites=10015229640072712741,,,https://iopscience.iop.org/article/10.1088/0004-637X/775/2/93/pdf,0,0,0
1278032,Smooth (er) stellar mass maps in CANDELS: constraints on the longevity of clumps in high-redshift star-forming galaxies,2012,Stijn Wuyts and Natascha M Förster Schreiber and Reinhard Genzel and Yicheng Guo and Guillermo Barro and Eric F Bell and Avishai Dekel and Sandra M Faber and Henry C Ferguson and Mauro Giavalisco and Norman A Grogin and Nimish P Hathi and Kuang-Han Huang and Dale D Kocevski and Anton M Koekemoer and David C Koo and Jennifer Lotz and Dieter Lutz and Elizabeth McGrath and Jeffrey A Newman and David Rosario and Amelie Saintonge and Linda J Tacconi and Benjamin J Weiner and Arjen van der Wel,753,The Astrophysical Journal,2,114,IOP Publishing,We perform a detailed analysis of the resolved colors and stellar populations of a complete sample of 323 star-forming galaxies (SFGs) at 0.5< z< 1.5 and 326 SFGs at 1.5< z< 2.5 in the ERS and CANDELS-Deep region of GOODS-South. Galaxies were selected to be more massive than 10 10 M☉ and have specific star formation rates (SFRs) above 1/t H. We model the seven-band optical ACS+ near-IR WFC3 spectral energy distributions of individual bins of pixels. accounting simultaneously for the galaxy-integrated photometric constraints available over a longer wavelength range. We analyze variations in rest-frame color. stellar surface mass density. age. and extinction as a function of galactocentric radius and local surface brightness/density. and measure structural parameters on luminosity and stellar mass maps. We find evidence for redder colors. older stellar ages. and increased dust extinction in the nuclei …,True,o4MuRUEAAAAJ:2osOgNQ5qMEC,302,https://iopscience.iop.org/article/10.1088/0004-637X/753/2/114/meta,9171387855496752094,/scholar?cites=9171387855496752094,,,https://iopscience.iop.org/article/10.1088/0004-637X/753/2/114/pdf,0,0,0
1278033,CANDELS Multiwavelength Catalogs: Source Identification and Photometry in the CANDELS UKIDSS Ultra-deep Survey Field,2013,Audrey Galametz and Andrea Grazian and Adriano Fontana and Henry C Ferguson and MLN Ashby and Guillermo Barro and Marco Castellano and Tomas Dahlen and Jennifer L Donley and Sandy M Faber and Norman Grogin and Yicheng Guo and Kuang-Han Huang and Dale D Kocevski and Anton M Koekemoer and Kyoung-Soo Lee and Elizabeth J McGrath and Michael Peth and SP Willner and Omar Almaini and Michael Cooper and Asantha Cooray and Christopher J Conselice and Mark Dickinson and James S Dunlop and GG Fazio and Sebastien Foucaud and Jonathan P Gardner and Mauro Giavalisco and NP Hathi and Will G Hartley and David C Koo and Kamson Lai and Duilia F de Mello and Ross J McLure and Ray A Lucas and Diego Paris and Laura Pentericci and Paola Santini and Chris Simpson and Veronica Sommariva and Thomas Targett and Benjamin J Weiner and Stijn Wuyts,206,The Astrophysical Journal Supplement Series,2,10,IOP Publishing,We present the multiwavelength—ultraviolet to mid-infrared—catalog of the UKIRT Infrared Deep Sky Survey (UKIDSS) Ultra-Deep Survey field observed as part of the Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey (CANDELS). Based on publicly available data. the catalog includes the CANDELS data from the Hubble Space Telescope (near-infrared WFC3 F125W and F160W data and visible ACS F606W and F814W data); u-band data from CFHT/Megacam; B. V. R c. i'. and z'band data from Subaru/Suprime-Cam; Y and K s band data from VLT/HAWK-I; J. H. and K band data from UKIDSS (Data Release 8); and Spitzer/IRAC data (3.6. 4.5 μm from SEDS; 5.8 and 8.0 μm from SpUDS). The present catalog is F160W-selected and contains 35. 932 sources over an area of 201.7 arcmin 2 and includes radio-and X-ray-detected sources and spectroscopic redshifts available for 210 sources.,True,o4MuRUEAAAAJ:Tyk-4Ss8FVUC,259,https://iopscience.iop.org/article/10.1088/0067-0049/206/2/10/meta,17102290856605335961,/scholar?cites=17102290856605335961,,,https://iopscience.iop.org/article/10.1088/0067-0049/206/2/10,0,0,0
1278034,A CANDELS-3D-HST synergy: resolved star formation patterns at 0.7< z< 1.5,2013,Stijn Wuyts and Natascha M Förster Schreiber and Erica J Nelson and Pieter G van Dokkum and Gabe Brammer and Yu-Yen Chang and Sandra M Faber and Henry C Ferguson and Marijn Franx and Mattia Fumagalli and Reinhard Genzel and Norman A Grogin and Dale D Kocevski and Anton M Koekemoer and Britt Lundgren and Dieter Lutz and Elizabeth J McGrath and Ivelina Momcheva and David Rosario and Rosalind E Skelton and Linda J Tacconi and Arjen van der Wel and Katherine E Whitaker,779,The Astrophysical Journal,2,135,IOP Publishing,We analyze the resolved stellar populations of 473 massive star-forming galaxies at 0.7< z< 1.5. with multi-wavelength broadband imaging from CANDELS and Hα surface brightness profiles at the same kiloparsec resolution from 3D-HST. Together. this unique data set sheds light on how the assembled stellar mass is distributed within galaxies. and where new stars are being formed. We find the Hα morphologies to resemble more closely those observed in the ACS I band than in the WFC3 H band. especially for the larger systems. We next derive a novel prescription for Hα dust corrections. which accounts for extra extinction toward H II regions. The prescription leads to consistent star formation rate (SFR) estimates and reproduces the observed relation between the Hα/UV luminosity ratio and visual extinction. on both a pixel-by-pixel and a galaxy-integrated level. We find the surface density of star formation to …,True,o4MuRUEAAAAJ:d1gkVwhDpl0C,218,https://iopscience.iop.org/article/10.1088/0004-637X/779/2/135/meta,12062878731723131974,/scholar?cites=12062878731723131974,,,https://iopscience.iop.org/article/10.1088/0004-637X/779/2/135/pdf,0,0,0
1278035,The grism lens-amplified survey from space (GLASS). I. Survey overview and first data release,2015,T Treu and KB Schmidt and GBm Brammer and Benedetta Vulcani and X Wang and M Bradač and M Dijkstra and A Dressler and Adriano Fontana and R Gavazzi and AL Henry and A Hoag and K-H Huang and TA Jones and PL Kelly and MA Malkan and C Mason and Laura Pentericci and B Poggianti and M Stiavelli and M Trenti and A Von Der Linden,812,The Astrophysical Journal,2,114,IOP Publishing,We give an overview of the Grism Lens Amplified Survey from Space (GLASS). a large Hubble Space Telescope program aimed at obtaining grism spectroscopy of the fields of 10 massive clusters of galaxies at redshift z= 0.308–0.686. including the Hubble Frontier Fields (HFF). The Wide Field Camera 3 (WFC3) yields near-infrared spectra of the cluster cores covering the wavelength range 0.81–1.69 μm through grisms G102 and G141. while the Advanced Camera for Surveys in parallel mode provides G800L spectra of the infall regions of the clusters. The WFC3 spectra are taken at two almost orthogonal position angles in order to minimize the effects of confusion. After summarizing the scientific drivers of GLASS. we describe the sample selection as well as the observing strategy and data processing pipeline. We then utilize MACS J0717. 5+ 3745. a HFF cluster and the first one observed by GLASS. to illustrate the data …,True,o4MuRUEAAAAJ:hqOjcs7Dif8C,174,https://iopscience.iop.org/article/10.1088/0004-637X/812/2/114/meta,2348812181778519326,/scholar?cites=2348812181778519326,,,https://iopscience.iop.org/article/10.1088/0004-637X/812/2/114/pdf,0,0,0
1278036,Extreme emission-line galaxies in candels: Broadband-selected. starbursting dwarf galaxies at z> 1,2011,Arjen van der Wel and AN Straughn and H-W Rix and SL Finkelstein and AM Koekemoer and BJ Weiner and S Wuyts and EF Bell and SM Faber and JR Trump and DC Koo and HC Ferguson and C Scarlata and NP Hathi and JS Dunlop and JA Newman and M Dickinson and K Jahnke and BW Salmon and DF De Mello and DD Kocevski and K Lai and NA Grogin and SA Rodney and Yicheng Guo and EJ McGrath and K-S Lee and G Barro and K-H Huang and AG Riess and MLN Ashby and SP Willner,742,The Astrophysical Journal,2,111,IOP Publishing,We identify an abundant population of extreme emission-line galaxies (EELGs) at redshift z~ 1.7 in the Cosmic Assembly Near-IR Deep Extragalactic Legacy Survey imaging from Hubble Space Telescope/Wide Field Camera 3 (HST/WFC3). Sixty-nine EELG candidates are selected by the large contribution of exceptionally bright emission lines to their near-infrared broadband magnitudes. Supported by spectroscopic confirmation of strong [O III] emission lines—with rest-frame equivalent widths~ 1000 Å—in the four candidates that have HST/WFC3 grism observations. we conclude that these objects are galaxies with~ 10 8 M☉ in stellar mass. undergoing an enormous starburst phase with  of only~ 15 Myr. These bursts may cause outflows that are strong enough to produce cored dark matter profiles in low-mass galaxies. The individual star formation rates and the comoving number density (3.7× 10–4 Mpc–3 …,True,o4MuRUEAAAAJ:9yKSN-GCB0IC,150,https://iopscience.iop.org/article/10.1088/0004-637X/742/2/111/meta,2362392819566749665,/scholar?cites=2362392819566749665,,,https://iopscience.iop.org/article/10.1088/0004-637X/742/2/111/pdf,0,0,0
1278037,CANDELS/GOODS-S. CDFS. and ECDFS: photometric redshifts for normal and X-ray-detected galaxies,2014,Li-Ting Hsu and Mara Salvato and Kirpal Nandra and Marcella Brusa and Ralf Bender and Johannes Buchner and Jennifer L Donley and Dale D Kocevski and Yicheng Guo and Nimish P Hathi and Cyprian Rangel and SP Willner and Murray Brightman and Antonis Georgakakis and Tamás Budavári and Alexander S Szalay and Matthew LN Ashby and Guillermo Barro and Tomas Dahlen and Sandra M Faber and Henry C Ferguson and Audrey Galametz and Andrea Grazian and Norman A Grogin and Kuang-Han Huang and Anton M Koekemoer and Ray A Lucas and Elizabeth McGrath and Bahram Mobasher and Michael Peth and David J Rosario and Jonathan R Trump,796,The Astrophysical Journal,1,60,IOP Publishing,We present photometric redshifts and associated probability distributions for all detected sources in the Extended Chandra Deep Field South (ECDFS). This work makes use of the most up-to-date data from the Cosmic Assembly Near-IR Deep Legacy Survey (CANDELS) and the Taiwan ECDFS Near-Infrared Survey (TENIS) in addition to other data. We also revisit multi-wavelength counterparts for published X-ray sources from the 4 Ms CDFS and 250 ks ECDFS surveys. finding reliable counterparts for 1207 out of 1259 sources (~ 96%). Data used for photometric redshifts include intermediate-band photometry deblended using the TFIT method. which is used for the first time in this work. Photometric redshifts for X-ray source counterparts are based on a new library of active galactic nuclei/galaxy hybrid templates appropriate for the faint X-ray population in the CDFS. Photometric redshift accuracy for normal …,True,o4MuRUEAAAAJ:LkGwnXOMwfcC,133,https://iopscience.iop.org/article/10.1088/0004-637X/796/1/60/meta,175658419298668061,/scholar?cites=175658419298668061,,,https://iopscience.iop.org/article/10.1088/0004-637X/796/1/60/pdf,0,0,0
1278038,Introducing a new benchmarked dataset for activity monitoring,2012,Attila Reiss and Didier Stricker,,,,108-109,IEEE,This paper addresses the lack of a commonly used. standard dataset and established benchmarking problems for physical activity monitoring. A new dataset - recorded from 18 activities performed by 9 subjects. wearing 3 IMUs and a HR-monitor - is created and made publicly available. Moreover. 4 classification problems are benchmarked on the dataset. using a standard data processing chain and 5 different classifiers. The benchmark shows the difficulty of the classification tasks and exposes new challenges for physical activity monitoring.,True,ImhXfxgAAAAJ:W7OEmFMy1HYC,521,https://ieeexplore.ieee.org/abstract/document/6246152/,2877592364688849656,/scholar?cites=2877592364688849656,,,https://www.researchgate.net/profile/Attila_Reiss/publication/235348485_Introducing_a_New_Benchmarked_Dataset_for_Activity_Monitoring/links/00b7d5309d19ca4346000000/Introducing-a-New-Benchmarked-Dataset-for-Activity-Monitoring.pdf,0,0,0
1278039,Visual computing as a key enabling technology for industrie 4.0 and industrial internet,2015,Jorge Posada and Carlos Toro and Iñigo Barandiaran and David Oyarzun and Didier Stricker and Raffaele De Amicis and Eduardo B Pinto and Peter Eisert and Jürgen Döllner and Ivan Vallarino,35,IEEE computer graphics and applications,2,26-40,IEEE,"A worldwide movement in advanced manufacturing countries is seeking to reinvigorate (and revolutionize) the industrial and manufacturing core competencies with the use of the latest advances in information and communications technology. Visual computing plays an important role as the ""glue factor"" in complete solutions. This article positions visual computing in its intrinsic crucial role for Industrie 4.0 and provides a general. broad overview and points out specific directions and scenarios for future research.",True,ImhXfxgAAAAJ:kRWSkSYxWN8C,519,https://ieeexplore.ieee.org/abstract/document/7064655/,15133096032485134532,/scholar?cites=15133096032485134532,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.706.3852&rep=rep1&type=pdf,0,0,0
1278040,Archeoguide: an augmented reality guide for archaeological sites,2002,Vassilios Vlahakis and M Ioannidis and John Karigiannis and Manolis Tsotros and Michael Gounaris and Didier Stricker and Tim Gleue and Patrick Daehne and Luis Almeida,22,IEEE Computer Graphics and Applications,5,52-60,IEEE,The paper discusses Archeoguide which offers personalized augmented reality tours of archaeological sites. It uses outdoor tracking. mobile computing. 3D visualization and augmented reality techniques to enhance information presentation. reconstruct ruined sites. and simulate ancient life.,True,ImhXfxgAAAAJ:u5HHmVD_uO8C,488,https://ieeexplore.ieee.org/abstract/document/1028726/,1118230972429901967,/scholar?cites=1118230972429901967,,,https://www.researchgate.net/profile/Didier_Stricker/publication/3208993_Archeoguide_An_augmented_reality_guide_for_archaeolog_sites/links/00b7d5228e28a1d238000000/Archeoguide-An-augmented-reality-guide-for-archaeolog-sites.pdf,0,0,0
1278041,Archeoguide: first results of an augmented reality. mobile computing system in cultural heritage sites,2001,Vassilios Vlahakis and John Karigiannis and Manolis Tsotros and Michael Gounaris and Luis Almeida and Didier Stricker and Tim Gleue and Ioannis T Christou and Renzo Carlucci and Nikos Ioannidis,9,"Virtual Reality, Archeology, and Cultural Heritage",10.1145,584993-585015,,(Augmented Reality-based Cultural Heritage On-site GUIDE). ARCHEOGUIDE is an IST project. funded by the EU. aiming at providing a personalized electronic guide and tour assistant to cultural site visitors. The system provides on-site help and Augmented Reality reconstructions of ancient ruins. based on user’s position and orientation in the cultural site. and realtime image rendering. It incorporates a multimedia database of cultural material for on-line access to cultural data. virtual visits. and restoration information. It uses multi-modal user interfaces and personalizes the flow of information to its user’s profile in order to cater for both professional and recreational users. and for applications ranging from archaeological research. to education. multimedia publishing. and cultural tourism. This paper presents the ARCHEOGUIDE system and the experiences gained from the evaluation of an initial prototype by representative user groups at the archeological site of Olympia. Greece.,True,ImhXfxgAAAAJ:d1gkVwhDpl0C,359,https://www.researchgate.net/profile/Didier_Stricker/publication/220955275_ARCHEOGUIDE_first_results_of_an_augmented_reality_mobile_computing_system_in_cultural_heritage_sites/links/0046351acf4b16b746000000/ARCHEOGUIDE-first-results-of-an-augmented-reality-mobile-computing-system-in-cultural-heritage-sites.pdf,13085291909991930622,/scholar?cites=13085291909991930622,,,https://www.researchgate.net/profile/Didier_Stricker/publication/220955275_ARCHEOGUIDE_first_results_of_an_augmented_reality_mobile_computing_system_in_cultural_heritage_sites/links/0046351acf4b16b746000000/ARCHEOGUIDE-first-results-of-an-augmented-reality-mobile-computing-system-in-cultural-heritage-sites.pdf,0,0,0
1278042,Augmented reality for construction tasks: Doorlock assembly,1999,Dirk Reiners and Didier Stricker and Gudrun Klinker and Stefan Müller,98,Proc. Ieee And Acm Iwar,1,31-46,,Augmented reality (AR) is a technology that integrates pictures of virtual objects into images of the real world. This technology will be useful to industry when the technical problems have been solved. and when the benefits clearly outweigh the work required to use it. Furthermore. researchers must answer the important question of how AR might be integrated into the information technology infrastructure of a company. This paper describes an augmented reality demonstrator for the task of doorlock assembly in a car door. The demonstrator was developed as a practical. realistic application that could convey to a casual observer the concepts behind AR. A new. fast. and robust optical tracking algorithm was developed and integrated into a three-dimensional animation and rendering system. thereby creating a real-time fully three-dimensional HMD-based training application that teaches users how to assemble the doorlock into the door. The system was demonstrated to the general public at the Hannover Industrial Fair 1998; this demonstration of AR to a large. non-expert audience generated greater interest in this new area. There are still some technological problems to solve. but in order to get industrial partners interested in investing in this technology. researchers must make clear its possible benefits and its ability to be integrated into the whole company.,True,ImhXfxgAAAAJ:u-x6o8ySG0sC,257,http://books.google.com/books?hl=en&lr=&id=SxK2DwAAQBAJ&oi=fnd&pg=PA31&dq=info:5TVJdjqR5rsJ:scholar.google.com&ots=dALCChu1qt&sig=Epbskq-QbPnV60yXOzzpWvFarOw,13539669010014615013,/scholar?cites=13539669010014615013,,,https://www.academia.edu/download/45777436/reiners1998iwar.pdf,0,0,0
1278043,Flow fields: Dense correspondence fields for highly accurate large displacement optical flow estimation,2015,Christian Bailer and Bertram Taetz and Didier Stricker,,,,4015-4023,,Modern large displacement optical flow algorithms usually use an initialization by either sparse descriptor matching techniques or dense approximate nearest neighbor fields. While the latter have the advantage of being dense. they have the major disadvantage of being very outlier prone as they are not designed to find the optical flow. but the visually most similar correspondence. In this paper we present a dense correspondence field approach that is much less outlier prone and thus much better suited for optical flow estimation than approximate nearest neighbor fields. Our approach is conceptually novel as it does not require explicit regularization. smoothing (like median filtering) or a new data term. but solely our novel purely data based search strategy that finds most inliers (even for small objects). while it effectively avoids finding outliers. Moreover. we present novel enhancements for outlier filtering. We show that our approach is better suited for large displacement optical flow estimation than state-of-the-art descriptor matching techniques. We do so by initializing EpicFlow (so far the best method on MPI-Sintel) with our Flow Fields instead of their originally used state-of-the-art descriptor matching technique. We significantly outperform the original EpicFlow on MPI-Sintel. KITTI and Middlebury.,True,ImhXfxgAAAAJ:HE397vMXCloC,230,http://openaccess.thecvf.com/content_iccv_2015/html/Bailer_Flow_Fields_Dense_ICCV_2015_paper.html,12540170961157454281,/scholar?cites=12540170961157454281,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Bailer_Flow_Fields_Dense_ICCV_2015_paper.pdf,0,0,0
1278044,Advanced tracking through efficient image processing and visual–inertial sensor fusion,2009,Gabriele Bleser and Didier Stricker,33,Computers & Graphics,1,59-72,Pergamon,This article presents a new visual–inertial tracking device for augmented and virtual reality applications and addresses two fundamental issues of such systems. The first one concerns the definition and modelling of the sensor fusion problem. Much work has been conducted in this area and several models for exploiting gyroscopes and linear accelerometers have been proposed. However. the respective advantages of each model and in particular the benefits of the integration of the accelerometer data in the filter are still unclear. A comparison of different models with special investigation of the effects of using accelerometers on the tracking performance is therefore provided. The second contribution is the development of an image processing approach that does not require special landmarks but uses natural features. The solution relies on a 3D model of the scene that is used to predict the appearances of the …,True,ImhXfxgAAAAJ:9yKSN-GCB0IC,208,https://www.sciencedirect.com/science/article/pii/S0097849308001465,13572254559111210182,/scholar?cites=13572254559111210182,,,https://www.researchgate.net/profile/Didier_Stricker/publication/4324879_Advanced_tracking_through_efficient_image_processing_and_visual-inertial_sensor_fusion/links/0046351acf4b48fa0f000000/Advanced-tracking-through-efficient-image-processing-and-visual-inertial-sensor-fusion.pdf,0,0,0
1278045,Creating and benchmarking a new dataset for physical activity monitoring,2012,Attila Reiss and Didier Stricker,,,,1-8,,Physical activity monitoring has recently become an important field in wearable computing research. However. there is a lack of a commonly used. standard dataset and established benchmarking problems. In this work. a new dataset for physical activity monitoring---recorded from 9 subjects. wearing 3 inertial measurement units and a heart rate monitor. and performing 18 different activities---is created and made publicly available. Moreover. 4 classification problems are benchmarked on the dataset. using a standard data processing chain and 5 different classifiers. The benchmark shows the difficulty of the classification tasks and exposes some challenges. defined by eg a high number of activities and personalization.,True,ImhXfxgAAAAJ:kNdYIx-mwKoC,201,https://dl.acm.org/doi/abs/10.1145/2413097.2413148,8803640557782248987,/scholar?cites=8803640557782248987,,,https://www.researchgate.net/profile/Attila_Reiss/publication/235348488_Creating_and_Benchmarking_a_New_Dataset_for_Physical_Activity_Monitoring/links/02e7e5309d183b9836000000.pdf,0,0,0
1278046,Survey of motion tracking methods based on inertial sensors: A focus on upper limb human motion,2017,Alessandro Filippeschi and Norbert Schmitz and Markus Miezal and Gabriele Bleser and Emanuele Ruffaldi and Didier Stricker,17,,6,1257,Multidisciplinary Digital Publishing Institute,Motion tracking based on commercial inertial measurements units (IMUs) has been widely studied in the latter years as it is a cost-effective enabling technology for those applications in which motion tracking based on optical technologies is unsuitable. This measurement method has a high impact in human performance assessment and human-robot interaction. IMU motion tracking systems are indeed self-contained and wearable. allowing for long-lasting tracking of the user motion in situated environments. After a survey on IMU-based human tracking. five techniques for motion reconstruction were selected and compared to reconstruct a human arm motion. IMU based estimation was matched against motion tracking based on the Vicon marker-based motion tracking system considered as ground truth. Results show that all but one of the selected models perform similarly (about 35 mm average position estimation error). View Full-Text,True,ImhXfxgAAAAJ:4MWp96NkSFoC,195,https://www.mdpi.com/200496,8187384226879164313,/scholar?cites=8187384226879164313,,,https://www.mdpi.com/1424-8220/17/6/1257/pdf,0,0,0
1278047,Comparison of kinect v1 and v2 depth images in terms of accuracy and precision,2016,Oliver Wasenmüller and Didier Stricker,,,,34-45,Springer. Cham,RGB-D cameras like the Microsoft Kinect had a huge impact on recent research in Computer Vision as well as Robotics. With the release of the Kinect v2 a new promising device is available. which will – most probably – be used in many future research. In this paper. we present a systematic comparison of the Kinect v1 and Kinect v2. We investigate the accuracy and precision of the devices for their usage in the context of 3D reconstruction. SLAM or visual odometry. For each device we rigorously figure out and quantify influencing factors on the depth images like temperature. the distance of the camera or the scene color. Furthermore. we demonstrate errors like flying pixels and multipath interference. Our insights build the basis for incorporating or modeling the errors of the devices in follow-up algorithms for diverse applications.,True,ImhXfxgAAAAJ:evX43VCCuoAC,189,https://link.springer.com/chapter/10.1007/978-3-319-54427-4_3,7782825851980193820,/scholar?cites=7782825851980193820,,,https://www.academia.edu/download/55433871/wasenmuller2016comparison.pdf,0,0,0
1278048,Adaptive line tracking with multiple hypotheses for augmented reality,2005,Harald Wuest and Florent Vial and Didier Strieker,,,,62-69,IEEE,We present a real-time model-based line tracking approach with adaptive learning of image edge features that can handle partial occlusion and illumination changes. A CAD (VRML) model of the object to track is needed. First. the visible edges of the model with respect to the camera pose estimate are sorted out by a visibility test performed on standard graphics hardware. For every sample point of every projected visible 3D model line a search for gradient maxima in the image is then carried out in a direction perpendicular to that line. Multiple hypotheses of these maxima are considered as putative matches. The camera pose is updated by minimizing the distances between the projection of all sample points of the visible 3D model lines and the most likely matches found in the image. The state of every edge's visual properties is updated after each successful camera pose estimation. We evaluated the algorithm …,True,ImhXfxgAAAAJ:0KyAp5RtaNEC,178,https://ieeexplore.ieee.org/abstract/document/1544665/,5949428513181005665,/scholar?cites=5949428513181005665,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.8127&rep=rep1&type=pdf,0,0,0
1278049,A comparative performance study of several global thresholding techniques for segmentation,1990,Sang Uk Lee and Seok Yoon Chung and Rae Hong Park,52,"Computer Vision, Graphics, and Image Processing",2,171-190,Academic Press,A comparative performance study of five global thresholding algorithms for image segmentation was investigated. An image database with a wide variety of histogram distribution was constructed. The histogram distribution was changed by varying the object size and the mean difference between object and background. The performance of five algorithms was evaluated using the criterion functions such as the probability of error. shape. and uniformity measures Attempts also have been made to evaluate the performance of each algorithm on the noisy image. Computer simulation results reveal that most algorithms perform consistently well on images with a bimodal histogram. However. all algorithms break down for a certain ratio of population of object and background pixels in an image. which in practice may arise quite frequently. Also. our experiments show that the performances of the thresholding algorithms …,True,pRZtuM4AAAAJ:u5HHmVD_uO8C,811,https://www.sciencedirect.com/science/article/pii/0734189X9090053X,572533968159809962,/scholar?cites=572533968159809962,,,,0,0,0
1278050,Object matching algorithms using robust Hausdorff distance measures,1999,Dong-Gyu Sim and Oh-Kyu Kwon and Rae-Hong Park,8,IEEE Transactions on image processing,3,425-429,IEEE,A Hausdorff distance (HD) is one of commonly used measures for object matching. This work analyzes the conventional HD measures and proposes two robust HD measures based on m-estimation and least trimmed square (LTS) which are more efficient than the conventional HD measures. By computer simulation. the matching performance of the conventional and proposed HD measures is compared with synthetic and real images.,True,pRZtuM4AAAAJ:u-x6o8ySG0sC,457,https://ieeexplore.ieee.org/abstract/document/748897/,7833733688159735671,/scholar?cites=7833733688159735671,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.604.7372&rep=rep1&type=pdf,0,0,0
1278051,Block-based noise estimation using adaptive Gaussian filtering,2005,Dong-Hyuk Shin and Rae-Hong Park and Seungjoon Yang and Jae-Han Jung,51,IEEE Transactions on Consumer Electronics,1,218-226,IEEE,This paper proposes a fast noise estimation algorithm using a Gaussian filter. It is based on block-based noise estimation. in which an input image is assumed to be contaminated by the additive white Gaussian noise and a filtering process is performed by an adaptive Gaussian filter. Coefficients of a Gaussian filter are selected as functions of the standard deviation of the Gaussian noise that is estimated from an input noisy image. For estimation of the amount of noise (i.e.. standard deviation of the Gaussian noise). we split an image into a number of blocks and select smooth blocks that are classified by the standard deviation of intensity of a block. where the standard deviation is computed from the difference of the selected block images between the noisy input image and its filtered image. In the experiments. the performance of the proposed algorithm is compared with that of the three conventional (block-based and …,True,pRZtuM4AAAAJ:IjCSPb-OGe4C,249,https://ieeexplore.ieee.org/abstract/document/1405723/,9921582809431549193,/scholar?cites=9921582809431549193,,,,0,0,0
1278052,A fast hierarchical motion vector estimation algorithm using mean pyramid,1995,Kwon Moon Nam and Joon-Seek Kim and Rae-Hong Park and Young Serk Shim,5,IEEE Transactions on Circuits and Systems for Video technology,4,344-351,IEEE,In transmitting moving pictures. interframe coding is shown to be effective for compressing video data. A hierarchical motion vector estimation algorithm using mean pyramid is proposed. Using the same measurement window at each level of a pyramid. the proposed algorithm. based on the tree pruning. reduces the computational complexity greatly with its performance comparable to that of the full search (FS). By varying the number of candidate motion vectors which are to be used as the initial search points for motion vector estimation at the next level. the mean squared error of the proposed algorithm varies. ranging between those of the FS and three step search (TSS) methods. Also. depending on the number of candidate motion vectors. the computational complexity of the proposed hierarchical algorithm ranges from 1/8-1/2 of that of the FS. The computer simulation results of the proposed technique compared …,True,pRZtuM4AAAAJ:9yKSN-GCB0IC,238,https://ieeexplore.ieee.org/abstract/document/465087/,10904559183286033641,/scholar?cites=10904559183286033641,,,,0,0,0
1278053,Robust adaptive segmentation of range images,1998,Kil-Moo Lee and Peter Meer and Rae-Hong Park,20,IEEE Transactions on Pattern Analysis and Machine Intelligence,2,200-205,IEEE,We propose a novel image segmentation technique using the robust. adaptive least kth order squares (ALKS) estimator which minimizes the kth order statistics of the squares of residuals. The optimal value of k is determined from the data. and the procedure detects the homogeneous surface patch representing the relative majority of the pixels. The ALKS shows a better tolerance to structured outliers than other recently proposed similar techniques. The performance of the new. fully autonomous. range image segmentation algorithm is compared to several other methods.,True,pRZtuM4AAAAJ:d1gkVwhDpl0C,191,https://ieeexplore.ieee.org/abstract/document/659940/,14920564195395447728,/scholar?cites=14920564195395447728,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.1057&rep=rep1&type=pdf,0,0,0
1278054,A fast feature-based block matching algorithm using integral projections,1992,J-S Kim and R-H Park,10,IEEE Journal on Selected areas in communications,5,968-971,IEEE,Block-by-block motion compensation algorithms are studied for video-conference/video-telephone television signals. A fast feature-based block matching algorithm using integral projections for the motion vector estimation is proposed. The proposed algorithm reduces the motion estimation computations by a factor of two by calculating the one-dimensional cost functions rather than the two-dimensional ones. Also. the low sensitivity of the proposed algorithm to the presence of additive noise is shown experimentally. Simulation results based on the original and noisy image sequences are presented.< >,True,pRZtuM4AAAAJ:qjMakFHDy7sC,182,https://ieeexplore.ieee.org/abstract/document/139002/,9542838968551012725,/scholar?cites=9542838968551012725,,,,0,0,0
1278055,Wavelet based watermarking method for digital images using the human visual system,1999,Young-Sik Kim and O-Hyung Kwon and Rae-Hong Park,35,Electronics Letters,6,466-468,IET,A wavelet based multiresolution watermarking method using the human visual system (HVS) is proposed. with the number of watermarks embedded proportional to the energy contained in each band. Experiments show that the proposed three-level wavelet based watermarking method is robust to some attacks such as. for example. joint photographic experts group (JPEG) compression. smoothing. cropping and collusion.,True,pRZtuM4AAAAJ:2osOgNQ5qMEC,167,https://ieeexplore.ieee.org/abstract/document/756396/,3232495281413785851,/scholar?cites=3232495281413785851,,,,0,0,0
1278056,Document image binarization based on topographic analysis using a water flow model,2002,In-Kwon Kim and Dong-Wook Jung and Rae-Hong Park,35,Pattern Recognition,1,265-277,Pergamon,This paper proposes a local adaptive thresholding method based on a water flow model. in which an image surface is considered as a three-dimensional (3-D) terrain. To extract characters from backgrounds. we pour water onto the terrain surface. Water flows down to the lower regions of the terrain and fills valleys. Then. the thresholding process is applied to the amount of filled water for character extraction. in which the proposed thresholding method is applied to gray level document images consisting of characters and backgrounds. The proposed method based on a water flow model shows the property of locally adaptive thresholding. Computer simulation with synthetic and real document images shows that the proposed method yields effective adaptive thresholding results for binarization of document images.,True,pRZtuM4AAAAJ:zYLM7Y9cAGgC,166,https://www.sciencedirect.com/science/article/pii/S0031320301000279,14258563044300369576,/scholar?cites=14258563044300369576,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.7472&rep=rep1&type=pdf,0,0,0
1278057,Weighted-adaptive motion-compensated frame rate up-conversion,2003,Sung-Hee Lee and Ohjae Kwon and Rae-Hong Park,49,IEEE Transactions on Consumer Electronics,3,485-492,IEEE,In this paper. we propose a frame rate upconversion algorithm using the weighted-adaptive motion-compensated interpolation (WAMCI) that reduces the block artifacts due to the failure of motion estimation and block-based processing. The proposed method is based on the interpolation scheme by weighted sum of multiple motion-compensated interpolation (MCI) images. Also. in the proposed method. the block artifacts on the block boundaries are reduced by applying a technique similar to the overlapped block motion compensation (OBMC). To reduce the blurring of overlapping processing. the proposed method uses the motion analysis to determine the type of motion and applies the OBMC adaptively. Experimental results indicate good performance of the proposed scheme with significantly reduced block artifacts.,True,pRZtuM4AAAAJ:UeHWp8X0CEIC,161,https://ieeexplore.ieee.org/abstract/document/1233759/,2682176026429414921,/scholar?cites=2682176026429414921,,,https://pdfs.semanticscholar.org/8194/376c6a515792cfe9526c2798784c35632951.pdf,0,0,0
1278058,Integrated position estimation using aerial image sequences,2002,Dong-Gyu Sim and Rae-Hong Park and Rin-Chul Kim and Sang Uk Lee and Ihn-Cheol Kim,24,IEEE transactions on pattern analysis and machine intelligence,1,1-18,IEEE,Presents an integrated system for navigation parameter estimation using sequential aerial images. where the navigation parameters represent the positional and velocity information of an aircraft for autonomous navigation. The proposed integrated system is composed of two parts: relative position estimation and absolute position estimation. Relative position estimation recursively computes the current position of an aircraft by accumulating relative displacement estimates extracted from two successive aerial images. Simple accumulation of parameter values reduces the reliability of the extracted parameter estimates as an aircraft goes on navigating. resulting in a large positional error. Therefore. absolute position estimation is required to compensate for the positional error generated by the relative position estimation. Absolute position estimation algorithms using image matching and digital elevation model (DEM …,True,pRZtuM4AAAAJ:Tyk-4Ss8FVUC,143,https://ieeexplore.ieee.org/abstract/document/982881/,6597054245892546593,/scholar?cites=6597054245892546593,,,https://www.researchgate.net/profile/Dong-Gyu_Sim/publication/3193331_Integrated_position_estimation_using_aerial_image_sequences/links/02bfe50c93c00c23d7000000.pdf,0,0,0
1278059,High-contrast color-stripe pattern for rapid structured-light range imaging,2004,Changsoo Je and Sang Wook Lee and Rae-Hong Park,,,,95-107,Springer. Berlin. Heidelberg,For structured-light range imaging. color stripes can be used for increasing the number of distinguishable light patterns compared to binary BW stripes. Therefore. an appropriate use of color patterns can reduce the number of light projections and range imaging is achievable in single video frame or in “one shot”. On the other hand. the reliability and range resolution attainable from color stripes is generally lower than those from multiply projected binary BW patterns since color contrast is affected by object color reflectance and ambient light. This paper presents new methods for selecting stripe colors and designing multiple-stripe patterns for “one-shot” and “two-shot” imaging. We show that maximizing color contrast between the stripes in one-shot imaging reduces the ambiguities resulting from colored object surfaces and limitations in sensor/projector resolution. Two-shot imaging adds an extra video frame …,True,pRZtuM4AAAAJ:eQOLeE2rZwMC,128,https://link.springer.com/chapter/10.1007/978-3-540-24670-1_8,4354799423187035124,/scholar?cites=4354799423187035124,,,https://link.springer.com/content/pdf/10.1007/978-3-540-24670-1_8.pdf,0,0,0
1278060,QTLNetwork: mapping and visualizing genetic architecture of complex traits in experimental populations,2008,Jian Yang and Chengcheng Hu and Han Hu and Rongdong Yu and Zhen Xia and Xiuzi Ye and Jun Zhu,24,Bioinformatics,5,721-723,Oxford University Press, Summary: QTLNetwork is a software package for mapping and visualizing the genetic architecture underlying complex traits for experimental populations derived from a cross between two inbred lines. It can simultaneously map quantitative trait loci (QTL) with individual effects. epistasis and QTL–environment interaction. Currently. it is able to handle data from F2. backcross. recombinant inbred lines and double-haploid populations. as well as populations from specific mating designs (immortalized F2 and BCnFn populations). The Windows version of QTLNetwork was developed with a graphical user interface. Alternatively. the command-line versions have the facility to be run in other prevalent operating systems. such as Linux. Unix and MacOS. Availability:           http://ibi.zju.edu.cn/software/qtlnetwork          Contact:           jzhu@zju.edu.cn         ,True,6wu3IPgAAAAJ:3DN2I6VP0lQC,407,https://academic.oup.com/bioinformatics/article-abstract/24/5/721/200448,13336058574541022922,/scholar?cites=13336058574541022922,,,https://academic.oup.com/bioinformatics/article/24/5/721/200448,0,0,0
1278061,Mapping the genetic architecture of complex traits in experimental populations,2007,Jian Yang and Jun Zhu and Robert W Williams,23,Bioinformatics,12,1527-1536,Oxford University Press, Summary: Understanding how interactions among set of genes affect diverse phenotypes is having a greater impact on biomedical research. agriculture and evolutionary biology. Mapping and characterizing the isolated effects of single quantitative trait locus (QTL) is a first step. but we also need to assemble networks of QTLs and define non-additive interactions (epistasis) together with a host of potential environmental modulators. In this article. we present a full-QTL model with which to explore the genetic architecture of complex trait in multiple environments. Our model includes the effects of multiple QTLs. epistasis. QTL-by-environment interactions and epistasis-by-environment interactions. A new mapping strategy. including marker interval selection. detection of marker interval interactions and genome scans. is used to evaluate putative locations of multiple QTLs and their interactions. All the mapping …,True,6wu3IPgAAAAJ:ntg98fmFLVcC,332,https://academic.oup.com/bioinformatics/article-abstract/23/12/1527/226879,6808623312489743438,/scholar?cites=6808623312489743438,,,https://academic.oup.com/bioinformatics/article/23/12/1527/226879,0,0,0
1278062,On the robust shortest path problem,1998,Gang Yu and Jian Yang,25,Computers & operations research,6,457-468,Pergamon,The shortest path problem is of great importance to the real world in such areas as transportation. network design. telecommunication. etc. The deterministic version of the problem is easily solved. However. in the real world. uncertainty is frequently encountered and must be dealt with. For instance. in a transportation network. the path that has the least travel time when no traffic is present might be prone to accidents and traffic jams. and thus it may lead to a drastic increase in travel time during rush hours. In situations with significant uncertainty. the deterministic approach can be far from sufficient. New and appropriate criteria and models to handle uncertainties along with efficient solution techniques are in need. In this paper. we take a minimax approach to measure the performance under uncertainties. Under our measure. one path is superior to all others only if its worst case performance is better than that of the …,True,6wu3IPgAAAAJ:rPSSLjQITZsC,269,https://www.sciencedirect.com/science/article/pii/S0305054897000853,7998221481324052625,/scholar?cites=7998221481324052625,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.95.3800&rep=rep1&type=pdf,0,0,0
1278063,Artifact suppressed dictionary learning for low-dose CT image processing,2014,Yang Chen and Luyao Shi and Qianjing Feng and Jian Yang and Huazhong Shu and Limin Luo and Jean-Louis Coatrieux and Wufan Chen,33,IEEE transactions on medical imaging,12,2271-2292,IEEE,Low-dose computed tomography (LDCT) images are often severely degraded by amplified mottle noise and streak artifacts. These artifacts are often hard to suppress without introducing tissue blurring effects. In this paper. we propose to process LDCT images using a novel image-domain algorithm called “artifact suppressed dictionary learning (ASDL).” In this ASDL method. orientation and scale information on artifacts is exploited to train artifact atoms. which are then combined with tissue feature atoms to build three discriminative dictionaries. The streak artifacts are cancelled via a discriminative sparse representation operation based on these dictionaries. Then. a general dictionary learning processing is applied to further reduce the noise and residual artifacts. Qualitative and quantitative evaluations on a large set of abdominal and mediastinum CT images are carried out and the results show that the proposed …,True,6wu3IPgAAAAJ:L8Ckcad2t8MC,237,https://ieeexplore.ieee.org/abstract/document/6851914/,8960449613650846356,/scholar?cites=8960449613650846356,,,https://hal.archives-ouvertes.fr/hal-01096038/file/Artifact-Suppressed-Dictionary%20Paper-final_full.pdf,0,0,0
1278064,Methods for predicting superior genotypes under multiple environments based on QTL effects,2005,Jian Yang and Jun Zhu,110,Theoretical and Applied Genetics,7,1268-1274,Springer-Verlag,Methods were developed for predicting two kinds of superior genotypes (superior line and superior hybrid) based on quantative trait locus (QTL) effects including epistatic and QTL × environment interaction effects. Formulae were derived for predicting the total genetic effect of any individual with known QTLs genotype derived from the mapping population in a specific environment. Two algorithms. enumeration algorithm and stepwise tuning algorithm. were used to select the best multi-locus combination of all the putative QTLs. Grain weight per plant (GW) in rice was analyzed as a working example to demonstrate the proposed methods. Results showed that the predicted superior lines and superior hybrids had great superiorities over the F1 hybrid. indicating large breeding potential remained for further improvement on GW. Results also showed that epistatic effects and their interaction with environments …,True,6wu3IPgAAAAJ:p6f6DfXMsGMC,183,https://link.springer.com/content/pdf/10.1007/s00122-005-1963-2.pdf,15472536884164156836,/scholar?cites=15472536884164156836,,,https://www.researchgate.net/profile/Jian_Yang20/publication/7930527_Predicting_superior_genotypes_in_multiple_environments_based_on_QTL_effects/links/0c96051dce6ba91e05000000.pdf,0,0,0
1278065,Understanding the disharmony between dropout and batch normalization by variance shift,2019,Xiang Li and Shuo Chen and Xiaolin Hu and Jian Yang,,,,2682-2690,,"This paper first answers the question"" why do the two most powerful techniques Dropout and Batch Normalization (BN) often lead to a worse performance when they are combined together in many modern neural networks. but cooperate well sometimes as in Wide ResNet (WRN)?"" in both theoretical and empirical aspects. Theoretically. we find that Dropout shifts the variance of a specific neural unit when we transfer the state of that network from training to test. However. BN maintains its statistical variance. which is accumulated from the entire learning procedure. in the test phase. The inconsistency of variances in Dropout and BN (we name this scheme"" variance shift"") causes the unstable numerical behavior in inference that leads to erroneous predictions finally. Meanwhile. the large feature dimension in WRN further reduces the"" variance shift"" to bring benefits to the overall performance. Thorough experiments on representative modern convolutional networks like DenseNet. ResNet. ResNeXt and Wide ResNet confirm our findings. According to the uncovered mechanism. we get better understandings in the combination of these two techniques and summarize guidelines for better practices.",True,6wu3IPgAAAAJ:1xqo9R7SDZkC,153,http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.html,13502577503907682874,/scholar?cites=13502577503907682874,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.pdf,0,0,0
1278066,Curve-like structure extraction using minimal path propagation with backtracking,2015,Yang Chen and Yudong Zhang and Jian Yang and Qing Cao and Guanyu Yang and Jian Chen and Huazhong Shu and Limin Luo and Jean-Louis Coatrieux and Qianjing Feng,25,IEEE Transactions on image processing,2,988-1003,IEEE,Minimal path techniques can efficiently extract geometrically curve-like structures by finding the path with minimal accumulated cost between two given endpoints. Though having found wide practical applications (e.g.. line identification. crack detection. and vascular centerline extraction). minimal path techniques suffer from some notable problems. The first one is that they require setting two endpoints for each line to be extracted (endpoint problem). The second one is that the connection might fail when the geodesic distance between the two points is much shorter than the desirable minimal path (shortcut problem). In addition. when connecting two distant points. the minimal path connection might become inefficient as the accumulated cost increases over the propagation and results in leakage into some non-feature regions near the starting point (accumulation problem). To address these problems. this paper …,True,6wu3IPgAAAAJ:W7OEmFMy1HYC,102,https://ieeexplore.ieee.org/abstract/document/7314939/,9585931187928009046,/scholar?cites=9585931187928009046,,,https://www.researchgate.net/profile/Jian_Yang25/publication/302992961_Curve-like_structure_extraction_using_minimal_path_propagation_with_backtracing/links/57592da208ae9a9c954a86df.pdf,0,0,0
1278067,Carbon-based materials as adsorbent for antibiotics removal: mechanisms and influencing factors,2019,Yujia Xiang and Zhangyi Xu and Yuyi Wei and Yaoyu Zhou and Xiao Yang and Yuan Yang and Jian Yang and Jiachao Zhang and Lin Luo and Zhi Zhou,237,,,128-138,Academic Press,With the development of the removal of organic pollutants in the soil and water environment. antibiotics have been considered as emerging pollutants and received considerable attention among the scientific community. Thus. there is a need for an effective. economical. fast. operational feasible and environmental-friendly technology to remove antibiotics. Adsorption technology would be one of the most promising option on the basis that it best meets the criteria we set out above. From the most primitive activated carbon to the most innovative modified biochar. carbon-based materials have played a significant role in the adsorption process of antibiotics all the time. This paper reviews the adsorption behavior of some representative antibiotics (e.g.. chloramphenicols. sulfonamides. tetracyclines. flouroquinolones) over various carbonaceous materials (i.e.. activated carbon. carbon nanotubes. graphene. and biochar …,True,6wu3IPgAAAAJ:l0_JBNIuc60C,89,https://www.sciencedirect.com/science/article/pii/S0301479719302191,2754330635075656258,/scholar?cites=2754330635075656258,,,,0,0,0
1278068,Novel approach for 3-D reconstruction of coronary arteries from two uncalibrated angiographic images,2009,Jian Yang and Yongtian Wang and Yue Liu and Songyuan Tang and Wufan Chen,18,Ieee transactions on image processing,7,1563-1572,IEEE,Three-dimensional reconstruction of vessels from digital X-ray angiographic images is a powerful technique that compensates for limitations in angiography. It can provide physicians with the ability to accurately inspect the complex arterial network and to quantitatively assess disease induced vascular alterations in three dimensions. In this paper. both the projection principle of single view angiography and mathematical modeling of two view angiographies are studied in detail. The movement of the table. which commonly occurs during clinical practice. complicates the reconstruction process. On the basis of the pinhole camera model and existing optimization methods. an algorithm is developed for 3-D reconstruction of coronary arteries from two uncalibrated monoplane angiographic images. A simple and effective perspective projection model is proposed for the 3-D reconstruction of coronary arteries. A nonlinear …,True,6wu3IPgAAAAJ:u5HHmVD_uO8C,88,https://ieeexplore.ieee.org/abstract/document/4907221/,13766411209129765678,/scholar?cites=13766411209129765678,,,https://www.researchgate.net/profile/Jian_Yang25/publication/224439687_Novel_Approach_for_3-D_Reconstruction_of_Coronary_Arteries_From_Two_Uncalibrated_Angiographic_Images/links/57590f6b08aed88462068508/Novel-Approach-for-3-D-Reconstruction-of-Coronary-Arteries-From-Two-Uncalibrated-Angiographic-Images.pdf,0,0,0
1278069,3D feature constrained reconstruction for low-dose CT imaging,2016,Jin Liu and Yining Hu and Jian Yang and Yang Chen and Huazhong Shu and Limin Luo and Qianjing Feng and Zhiguo Gui and Gouenou Coatrieux,28,IEEE Transactions on Circuits and Systems for Video Technology,5,1232-1247,IEEE,Low-dose computed tomography (LDCT) images are often highly degraded by amplified mottle noise and streak artifacts. Maintaining image quality under low-dose scan protocols is a well-known challenge. Recently. sparse representation-based techniques have been shown to be efficient in improving such CT images. In this paper. we propose a 3D feature constrained reconstruction (3D-FCR) algorithm for LDCT image reconstruction. The feature information used in the 3D-FCR algorithm relies on a 3D feature dictionary constructed from available high quality standard-dose CT sample. The CT voxels and the sparse coefficients are sequentially updated using an alternating minimization scheme. The performance of the 3D-FCR algorithm was assessed through experiments conducted on phantom simulation data and clinical data. A comparison with previously reported solutions was also performed. Qualitative …,True,6wu3IPgAAAAJ:dBIO0h50nwkC,76,https://ieeexplore.ieee.org/abstract/document/7792613/,3516123308199203409,/scholar?cites=3516123308199203409,,,https://www.researchgate.net/profile/Qianjin_Feng/publication/311863219_3D_Feature_Constrained_Reconstruction_for_Low_Dose_CT_Imaging/links/58f6c3f445851506cd30f748/3D-Feature-Constrained-Reconstruction-for-Low-Dose-CT-Imaging.pdf,0,0,0
1278070,Local statistics and non-local mean filter for speckle noise reduction in medical ultrasound image,2016,Jian Yang and Jingfan Fan and Danni Ai and Xuehu Wang and Yongchang Zheng and Songyuan Tang and Yongtian Wang,195,Neurocomputing,,88-95,Elsevier,Medical ultrasound images are corrupted by speckle noise. which is multiplicative. This noise limits the contrast resolution in these images and complicates image-based quantitative measurement and diagnosis. In this study. the speckle noise in the ultrasound image is modeled by local statistics of the intensity distribution. And the non-local mean (NLM) filter is utilized to filter additional noise by applying the redundancy information in noisy images. A hybrid denoising method is proposed in consideration of the characteristics of both the local statistics of speckle noise and the NLM filter. The study combines local statistics with the NLM filter to reduce speckle in ultrasound images. The local statistics of speckle noise is estimated by local patches. while the intensity of the denoising pixel is computed by the weighted average of all the pixels by using the NLM. The weight is determined according to the similarity …,True,6wu3IPgAAAAJ:LkGwnXOMwfcC,73,https://www.sciencedirect.com/science/article/pii/S0925231216001223,1560469165776302722,/scholar?cites=1560469165776302722,,,https://www.sciencedirect.com/science/article/am/pii/S0925231216001223,0,0,0
1278071,Observation of a new boson with mass near 125 GeV in pp collisions at  and 8 TeV,2013,Serguei Chatrchyan and Vardan Khachatryan and AM Sirunyan and A Tumasyan and Wolfgang Adam and T Bergauer and M Dragicevic and J Erö and C Fabjan and M Friedl and R Fruehwirth and VM Ghete and N Hoermann and J Hrubec and M Jeitler and W Kiesenhofer and V Knuenz and M Krammer and I Kraetschmer and D Liko and I Mikulec and D Rabady and B Rahbaran and C Rohringer and H Rohringer and R Schoefbeck and J Strauss and A Taurok and W Treberer-Treberspurg and W Waltenberger and C-E Wulz and V Mossolov and N Shumeiko and J Suarez Gonzalez and S Alderweireldt and M Bansal and S Bansal and Tom Cornelis and EA De Wolf and X Janssen and A Knutsson and S Luyckx and L Mucibello and S Ochesanu and B Roland and R Rougny and H Van Haevermaet and P Van Mechelen and N Van Remortel and A Van Spilbeeck and F Blekman and S Blyweert and J D’Hondt and A Kalogeropoulos and J Keaveney and M Maes and A Olbrechts and S Tavernier and W Van Doninck and P Van Mulders and GP Van Onsem and I Villella and B Clerbaux and G De Lentdecker and APR Gay and T Hreus and A Leonard and PE Marage and A Mohammadi and T Reis and L Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Leonardo Benucci and Anna Cimmino and Silvia Costantini and Sven Dildick and Guillaume Garcia and Benjamin Klein and Jeremie Lellouch and Andrey Marinov and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and Michael Sigamani and Nadja Strobbe and Filip Thyssen and Michael Tytgat and S Walsh and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and G Bruno and R Castello and A Caudron and L Ceard and C Delaere and T Du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and V Lemaitre and J Liao and O Militaru and C Nuttens and D Pagano and A Pin and K Piotrzkowski and A Popov and M Selvaggi and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins and T Martins and ME Pol and MHG Souza and WL Aldá Júnior and W Carvalho and J Chinellato and A Custodio and EM Da Costa and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and H Malbouisson and M Malek and D Matos Figueiredo and L Mundim and H Nogima and WL Prado Da Silva and A Santoro and L Soares Jorge and A Sznajder and EJ Tonelli Manganote and A Vilela Pereira and TS Anjos and CA Bernardes and FA Dias and TR Fernandez Perez Tomei and EM Gregores and C Lagana and F Marinho,2013,Journal of High Energy Physics,6,81,Springer-Verlag,A detailed description is reported of the analysis used by the CMS Collaboration in the search for the standard model Higgs boson in pp collisions at the LHC. which led to the observation of a new boson. The data sample corresponds to integrated luminosities up to 5.1 fb− 1 at TeV. and up to 5.3 fb− 1 at TeV. The results for five Higgs boson decay modes γγ. ZZ. WW. ττ. and bb. which show a combined local significance of 5 standard deviations near 125 GeV. are reviewed. A fit to the invariant mass of the two high resolution channels. γγ and ZZ→ 4ℓ. gives a mass estimate of 125. 3±0. 4 (stat.)±0. 5 (syst.) GeV. The measurements are interpreted in the context of the standard model Lagrangian for the scalar Higgs field interacting with fermions and vector bosons. The measured values of the corresponding couplings are compared to the standard model predictions. The hypothesis of custodial symmetry is …,True,Gz140swAAAAJ:nRpfm8aw39MC,1879,https://link.springer.com/content/pdf/10.1007/JHEP06(2013)081.pdf,7818861038406050561,/scholar?cites=7818861038406050561,,,https://link.springer.com/content/pdf/10.1007/JHEP06(2013)081.pdf,0,0,0
1278072,Global data sets of vegetation leaf area index (LAI) 3g and fraction of photosynthetically active radiation (FPAR) 3g derived from global inventory modeling and mapping studies …,2013,Zaichun Zhu and Jian Bi and Yaozhong Pan and Sangram Ganguly and Alessandro Anav and Liang Xu and Arindam Samanta and Shilong Piao and Ramakrishna R Nemani and Ranga B Myneni,5,Remote sensing,2,927-948,Multidisciplinary Digital Publishing Institute,Long-term global data sets of vegetation Leaf Area Index (LAI) and Fraction of Photosynthetically Active Radiation absorbed by vegetation (FPAR) are critical to monitoring global vegetation dynamics and for modeling exchanges of energy. mass and momentum between the land surface and planetary boundary layer. LAI and FPAR are also state variables in hydrological. ecological. biogeochemical and crop-yield models. The generation. evaluation and an example case study documenting the utility of 30-year long data sets of LAI and FPAR are described in this article. A neural network algorithm was first developed between the new improved third generation Global Inventory Modeling and Mapping Studies (GIMMS) Normalized Difference Vegetation Index (NDVI3g) and best-quality Terra Moderate Resolution Imaging Spectroradiometer (MODIS) LAI and FPAR products for the overlapping period 2000–2009. The trained neural network algorithm was then used to generate corresponding LAI3g and FPAR3g data sets with the following attributes: 15-day temporal frequency. 1/12 degree spatial resolution and temporal span of July 1981 to December 2011. The quality of these data sets for scientific research in other disciplines was assessed through (a) comparisons with field measurements scaled to the spatial resolution of the data products.(b) comparisons with broadly-used existing alternate satellite data-based products.(c) comparisons to plant growth limiting climatic variables in the northern latitudes and tropical regions. and (d) correlations of dominant modes of interannual variability with large-scale circulation anomalies such as the EI …,True,Gz140swAAAAJ:TIZ-Mc8IlK0C,591,https://www.mdpi.com/2072-4292/5/2/927,15435700383339044342,/scholar?cites=15435700383339044342,,,https://www.mdpi.com/2072-4292/5/2/927/pdf,0,0,0
1278073,Search for dark matter. extra dimensions. and unparticles in monojet events in proton–proton collisions at                                                        s                        =            8 …,2015,Vardan Khachatryan and Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and Thomas Bergauer and Marko Dragicevic and Janos Erö and Christian Fabjan and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Christian Hartl and Natascha Hörmann and Josef Hrubec and Manfred Jeitler and Wolfgang Kiesenhofer and Valentin Knünz and Manfred Krammer and Ilse Krätschmer and Dietrich Liko and Ivan Mikulec and Dinyar Rabady and Babak Rahbaran and Herbert Rohringer and Robert Schöfbeck and Josef Strauss and Anton Taurok and Wolfgang Treberer-Treberspurg and Wolfgang Waltenberger and C-E Wulz and Vladimir Mossolov and Nikolai Shumeiko and Juan SuarezGonzalez and Sara Alderweireldt and Monika Bansal and Sunil Bansal and Tom Cornelis and Eddi A De Wolf and Xavier Janssen and Albert Knutsson and Sten Luyckx and Silvia Ochesanu and Benoit Roland and Romain Rougny and Merijn Van De Klundert and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and Freya Blekman and Stijn Blyweert and Jorgen D’Hondt and Nadir Daci and Natalie Heracleous and Alexis Kalogeropoulos and James Keaveney and Tae Jeong Kim and Steven Lowette and Michael Maes and Annik Olbrechts and Quentin Python and Derek Strom and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Gerrit Patrick Van Onsem and Ilaria Villella and Cécile Caillol and Barbara Clerbaux and Gilles De Lentdecker and Didar Dobur and Laurent Favart and APR Gay and Anastasia Grebenyuk and Alexandre Léonard and Abdollah Mohammadi and Luca Perniè and Thomas Reis and Tomislav Seva and Laurent Thomas and C Vander Velde and P Vanlaer and J Wang and V Adler and K Beernaert and L Benucci and A Cimmino and S Costantini and S Crucy and S Dildick and A Fagot and G Garcia and B Klein and J Mccartin and AA Ocampo Rios and D Ryckbosch and S Salva Diblen and M Sigamani and N Strobbe and F Thyssen and M Tytgat and E Yazgan and N Zaganidis and S Basegmez and C Beluffi and G Bruno and R Castello and A Caudron and L Ceard and GG Da Silveira and C Delaere and T du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and P Jez and M Komm and V Lemaitre and J Liao and C Nuttens and D Pagano and L Perrini and A Pin and K Piotrzkowski and A Popov and L Quertenmont and M Selvaggi and M Vidal Marono and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and WL Aldá Júnior and GA Alves and M CorreaMartins Junior and T Dos Reis Martins and ME Pol and W Carvalho and J Chinellato and A Custódio and EM Da Costa and D De JesusDamiao and C De OliveiraMartins and S Fonseca De Souza and H Malbouisson and M Malek and D MatosFigueiredo and L Mundim,75,The European Physical Journal C,5,1-25,Springer Berlin Heidelberg,Results are presented from a search for particle dark matter (DM). extra dimensions. and unparticles using events containing a jet and an imbalance in transverse momentum. The data were collected by the CMS detector in proton–proton collisions at the LHC and correspond to an integrated luminosity of 19.7 at a centre-of-mass energy of 8. The number of observed events is found to be consistent with the standard model prediction. Limits are placed on the DM-nucleon scattering cross section as a function of the DM particle mass for spin-dependent and spin-independent interactions. Limits are also placed on the scale parameter in the Arkani-Hamed. Dimopoulos. and Dvali (ADD) model of large extra dimensions. and on the unparticle model parameter. The constraints on ADD models and unparticles are the most stringent limits in this channel and those on the DM-nucleon scattering cross section …,True,Gz140swAAAAJ:c_xDhezhKKUC,567,https://link.springer.com/article/10.1140/epjc/s10052-015-3451-4?error=cookies_not_supported&error=cookies_not_supported&code=d965b49a-4223-4b5c-8492-414388c32d4b&code=b6f25daa-e10f-47d7-aff3-97c2cf141fa4,4198326263751004274,/scholar?cites=4198326263751004274,,,https://link.springer.com/article/10.1140/epjc/s10052-015-3451-4?error=cookies_not_supported&error=cookies_not_supported&code=d965b49a-4223-4b5c-8492-414388c32d4b&code=b6f25daa-e10f-47d7-aff3-97c2cf141fa4,0,0,0
1278074,Temperature and vegetation seasonality diminishment over northern lands,2013,L Xu and RB Myneni and FS Chapin Iii and Terry V Callaghan and JE Pinzon and Compton J Tucker and Z Zhu and J Bi and P Ciais and Hans Tømmervik and ES Euskirchen and BC Forbes and SL Piao and BT Anderson and S Ganguly and RR Nemani and SJ Goetz and PSA Beck and AG Bunn and C Cao and JC Stroeve,3,Nature climate change,6,581-586,Nature Publishing Group,Global temperature is increasing. especially over northern lands (> 50 N). owing to positive feedbacks 1. As this increase is most pronounced in winter. temperature seasonality (S T)—conventionally defined as the difference between summer and winter temperatures—is diminishing over time 2. a phenomenon that is analogous to its equatorward decline at an annual scale. The initiation. termination and performance of vegetation photosynthetic activity are tied to threshold temperatures 3. Trends in the timing of these thresholds and cumulative temperatures above them may alter vegetation productivity. or modify vegetation seasonality (S V). over time. The relationship between S T and S V is critically examined here with newly improved ground and satellite data sets. The observed diminishment of S T and S V is equivalent to 4 and 7 (5 and 6) latitudinal shift equatorward during the past 30 years in the Arctic (boreal …,True,Gz140swAAAAJ:b1wdh0AR-JQC,443,https://www.nature.com/articles/nclimate1836,2736525578333501427,/scholar?cites=2736525578333501427,,,https://brage.nina.no/nina-xmlui/bitstream/handle/11250/2561523/T%25C3%25B8mmervik%2BTemperature%2BNature%2BClim%2BChange%2B3%2B6%2B2013%2Bpostprint.pdf?sequence=2&isAllowed=y,0,0,0
1278075,Land surface phenology from MODIS: Characterization of the Collection 5 global land cover dynamics product,2010,Sangram Ganguly and Mark A Friedl and Bin Tan and Xiaoyang Zhang and Manish Verma,114,Remote sensing of environment,8,1805-1816,Elsevier,Information related to land surface phenology is important for a variety of applications. For example. phenology is widely used as a diagnostic of ecosystem response to global change. In addition. phenology influences seasonal scale fluxes of water. energy. and carbon between the land surface and atmosphere. Increasingly. the importance of phenology for studies of habitat and biodiversity is also being recognized. While many data sets related to plant phenology have been collected at specific sites or in networks focused on individual plants or plant species. remote sensing provides the only way to observe and monitor phenology over large scales and at regular intervals. The MODIS Global Land Cover Dynamics Product was developed to support investigations that require regional to global scale information related to spatio-temporal dynamics in land surface phenology. Here we describe the Collection 5 …,True,Gz140swAAAAJ:2osOgNQ5qMEC,398,https://www.sciencedirect.com/science/article/pii/S0034425710001185,17215484094120713687,/scholar?cites=17215484094120713687,,,https://www.academia.edu/download/49291385/j.rse.2010.04.00520161002-4640-10vthok.pdf,0,0,0
1278076,Amazon forests did not green‐up during the 2005 drought,2010,Arindam Samanta and Sangram Ganguly and Hirofumi Hashimoto and Sadashiva Devadiga and Eric Vermote and Yuri Knyazikhin and Ramakrishna R Nemani and Ranga B Myneni,37,Geophysical research letters,5,,,The sensitivity of Amazon rainforests to dry‐season droughts is still poorly understood. with reports of enhanced tree mortality and forest fires on one hand. and excessive forest greening on the other. Here. we report that the previous results of large‐scale greening of the Amazon. obtained from an earlier version of satellite‐derived vegetation greenness data ‐ Collection 4 (C4) Enhanced Vegetation Index (EVI). are irreproducible. with both this earlier version as well as the improved. current version (C5). owing to inclusion of atmosphere‐corrupted data in those results. We find no evidence of large‐scale greening of intact Amazon forests during the 2005 drought ‐ approximately 11%–12% of these drought‐stricken forests display greening. while. 28%–29% show browning or no‐change. and for the rest. the data are not of sufficient quality to characterize any changes. These changes are also not unique …,True,Gz140swAAAAJ:u5HHmVD_uO8C,333,https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2009GL042154,1054393708208919721,/scholar?cites=1054393708208919721,,,https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2009GL042154,0,0,0
1278077,Widespread decline in greenness of Amazonian vegetation due to the 2010 drought,2011,Liang Xu and Arindam Samanta and Marcos H Costa and Sangram Ganguly and Ramakrishna R Nemani and Ranga B Myneni,38,Geophysical Research Letters,7,,John Wiley & Sons. Ltd,During this decade. the Amazon region has suffered two severe droughts in the short span of five years – 2005 and 2010. Studies on the 2005 drought present a complex. and sometimes contradictory. picture of how these forests have responded to the drought. Now. on the heels of the 2005 drought. comes an even stronger drought in 2010. as indicated by record low river levels in the 109 years of bookkeeping. How has the vegetation in this region responded to this record‐breaking drought? Here we report widespread. severe and persistent declines in vegetation greenness. a proxy for photosynthetic carbon fixation. in the Amazon region during the 2010 drought based on analysis of satellite measurements. The 2010 drought. as measured by rainfall deficit. affected an area 1.65 times larger than the 2005 drought – nearly 5 million km2 of vegetated area in Amazonia. The decline in greenness during the 2010 …,True,Gz140swAAAAJ:IjCSPb-OGe4C,243,https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2011GL046824,14395186187400857673,/scholar?cites=14395186187400857673,,,https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2011GL046824,0,0,0
1278078,Deepsat: a learning framework for satellite imagery,2015,Saikat Basu and Sangram Ganguly and Supratik Mukhopadhyay and Robert DiBiano and Manohar Karki and Ramakrishna Nemani,,,,1-10,,Satellite image classification is a challenging problem that lies at the crossroads of remote sensing. computer vision. and machine learning. Due to the high variability inherent in satellite data. most of the current object classification approaches are not suitable for handling satellite datasets. The progress of satellite image analytics has also been inhibited by the lack of a single labeled high-resolution dataset with multiple class labels. The contributions of this paper are twofold--(1) first. we present two new satellite datasets called SAT-4 and SAT-6. and (2) then. we propose a classification framework that extracts features from an input image. normalizes them and feeds the normalized feature vectors to a Deep Belief Network for classification. On the SAT-4 dataset. our best network produces a classification accuracy of 97.95% and outperforms three state-of-the-art object recognition algorithms. namely-Deep Belief …,True,Gz140swAAAAJ:IRz6iEL74y4C,214,https://dl.acm.org/doi/abs/10.1145/2820783.2820816,215596046496498975,/scholar?cites=215596046496498975,,,https://arxiv.org/pdf/1509.03602,0,0,0
1278079,Search for supersymmetry in pp collisions at s= 8 TeV in events with a single lepton. large jet multiplicity. and multiple b jets,2014,Serguei Chatrchyan and Vardan Khachatryan and AM Sirunyan and A Tumasyan and Wolfgang Adam and T Bergauer and M Dragicevic and J Eroe and C Fabjan and M Friedl and R Fruehwirth and VM Ghete and N Hoermann and J Hrubec and M Jeitler and W Kiesenhofer and V Knuenz and M Krammer and I Kraetschmer and D Liko and I Mikulec and D Rabady and B Rahbaran and H Rohringer and R Schoefbeck and J Strauss and A Taurok and W Treberer-Treberspurg and W Waltenberger and C-E Wulz and V Mossolov and N Shumeiko and J Suarez Gonzalez and S Alderweireldt and M Bansal and S Bansal and Tom Cornelis and EA De Wolf and X Janssen and A Knutsson and S Luyckx and L Mucibello and S Ochesanu and B Roland and R Rougny and Z Staykova and H Van Haevermaet and P Van Mechelen and N Van Remortel and A Van Spilbeeck and F Blekman and S Blyweert and J D'Hondt and N Heracleous and A Kalogeropoulos and J Keaveney and S Lowette and M Maes and A Olbrechts and D Strom and S Tavernier and W Van Doninck and P Van Mulders and GP Van Onsem and I Villella and C Caillol and B Clerbaux and G De Lentdecker and L Favart and APR Gay and T Hreus and A Leonard and PE Marage and A Mohammadi and L Pernie and T Reis and T Seva and L Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Leonardo Benucci and Anna Cimmino and Silvia Costantini and Sven Dildick and Guillaume Garcia and Benjamin Klein and Jeremie Lellouch and Andrey Marinov and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and Michael Sigamani and Nadja Strobbe and Filip Thyssen and Michael Tytgat and S Walsh and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and C Beluffi and G Bruno and R Castello and A Caudron and L Ceard and GG Da Silveira and C Delaere and T du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and P Jez and V Lemaitre and J Liao and O Militaru and C Nuttens and D Pagano and A Pin and K Piotrzkowski and A Popov and M Selvaggi and M Vidal Marono and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins Junior and T Martins and ME Pol and MHG Souza and WL Aldá Júnior and W Carvalho and J Chinellato and A Custodio and EM Da Costa and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and H Malbouisson and M Malek and D Matos Figueiredo and L Mundim and H Nogima and WL Prado Da Silva and J Santaolalla,733,Physics Letters B,,328-353,North-Holland,Results are reported from a search for supersymmetry in p p collisions at a center-of-mass energy of 8 TeV. based on events with a single isolated lepton (electron or muon) and multiple jets. at least two of which are identified as b jets. The data sample corresponds to an integrated luminosity of 19.3 fb− 1 recorded by the CMS experiment at the LHC in 2012. The search is motivated by supersymmetric models that involve strong-production processes and cascade decays of new particles. The resulting final states contain multiple jets as well as missing transverse momentum from weakly interacting particles. The event yields. observed across several kinematic regions. are consistent with the expectations from standard model processes. The results are interpreted in the context of simplified supersymmetric scenarios with pair production of gluinos. where each gluino decays to a top quark–antiquark pair and the …,True,Gz140swAAAAJ:jE2MZjpN3IcC,180,https://www.sciencedirect.com/science/article/pii/S037026931400255X,2328848711328238590,/scholar?cites=2328848711328238590,,,https://www.sciencedirect.com/science/article/pii/S037026931400255X,0,0,0
1278080,Changes in growing season duration and productivity of northern vegetation inferred from long-term remote sensing data,2016,Taejin Park and Sangram Ganguly and Hans Tømmervik and Eugénie S Euskirchen and Kjell-Arild Høgda and Stein Rune Karlsen and Victor Brovkin and Ramakrishna R Nemani and Ranga B Myneni,11,Environmental Research Letters,8,084001,IOP Publishing,Monitoring and understanding climate-induced changes in the boreal and arctic vegetation is critical to aid in prognosticating their future. We used a 33 year (1982–2014) long record of satellite observations to robustly assess changes in metrics of growing season (onset: SOS. end: EOS and length: LOS) and seasonal total gross primary productivity. Particular attention was paid to evaluating the accuracy of these metrics by comparing them to multiple independent direct and indirect growing season and productivity measures. These comparisons reveal that the derived metrics capture the spatio-temporal variations and trends with acceptable significance level (generally p< 0.05). We find that LOS has lengthened by 2.60 d dec− 1 (p< 0.05) due to an earlier onset of SOS (− 1.61 d dec− 1. p< 0.05) and a delayed EOS (0.67 d dec− 1. p< 0.1) at the circumpolar scale over the past three decades. Relatively greater rates …,True,Gz140swAAAAJ:bKqednn6t2AC,179,https://iopscience.iop.org/article/10.1088/1748-9326/11/8/084001/meta,4246365942283375090,/scholar?cites=4246365942283375090,,,https://iopscience.iop.org/article/10.1088/1748-9326/11/8/084001/pdf,0,0,0
1278081,A search for a doubly-charged Higgs boson in pp collisions at ,2012,Serguei Chatrchyan and Vardan Khachatryan and Albert M Sirunyan and A Tumasyan and W Adam and T Bergauer and M Dragicevic and J Eroe and C Fabjan and M Friedl and R Fruehwirth and VM Ghete and J Hammer and N Hoermann and J Hrubec and M Jeitler and W Kiesenhofer and V Knuenz and M Krammer and D Liko and I Mikulec and M Pernicka and B Rahbaran and C Rohringer and H Rohringer and R Schoefbeck and J Strauss and A Taurok and P Wagner and W Waltenberger and G Walzel and E Widl and C-E Wulz and V Mossolov and N Shumeiko and J Suarez Gonzalez and S Bansal and Tom Cornelis and EA De Wolf and X Janssen and S Luyckx and T Maes and L Mucibello and S Ochesanu and B Roland and R Rougny and M Selvaggi and Z Staykova and H Van Haevermaet and P Van Mechelen and N Van Remortel and A Van Spilbeeck and F Blekman and S Blyweert and J D’Hondt and R Gonzalez Suarez and A Kalogeropoulos and M Maes and A Olbrechts and W Van Doninck and P Van Mulders and GP Van Onsem and I Villella and O Charaf and B Clerbaux and G De Lentdecker and V Dero and APR Gay and T Hreus and A Leonard and PE Marage and T Reis and L Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Anna Cimmino and Silvia Costantini and Guillaume Garcia and M Grunewald and Benjamin Klein and Jeremie Lellouch and Andrey Marinov and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and Nadja Strobbe and Filip Thyssen and Michael Tytgat and Lukas Vanelderen and Piet Verwilligen and S Walsh and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and G Bruno and R Castello and A Caudron and L Ceard and C Delaere and T du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and V Lemaitre and J Liao and O Militaru and C Nuttens and D Pagano and L Perrini and A Pin and K Piotrzkowski and N Schul and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins Junior and D De Jesus Damiao and T Martins and ME Pol and MHG Souza and WL Aldá Júnior and W Carvalho and A Custodio and EM Da Costa and C De Oliveira Martins and S Fonseca De Souza and D Matos Figueiredo and L Mundim and H Nogima and V Oguri and WL Prado Da Silva and A Santoro and L Soares Jorge and A Sznajder and CA Bernardes and FA Dias and TR Fernandez Perez Tomei and EM Gregores and C Lagana and F Marinho and PG Mercadante and SF Novaes and Sandra S Padula,72,The European Physical Journal C,11,1-26,Springer-Verlag,A search for a doubly-charged Higgs boson in pp collisions at\(\sqrt {s}= 7\\mbox {TeV}\) is presented. The data correspond to an integrated luminosity of 4.9 fb− 1. collected by the CMS experiment at the LHC. The search is performed using events with three or more isolated charged leptons of any flavor. giving sensitivity to the decays of pair-produced triplet components Φ++ Φ−−. and Φ++ Φ− from associated production. No excess is observed compared to the background prediction. and upper limits at the 95% confidence level are set on the Φ++ production cross section. under specific assumptions on its branching fractions. Lower bounds on the Φ++ mass are reported. providing significantly more stringent constraints than previously published limits.,True,Gz140swAAAAJ:unp9ATQDT5gC,153,https://link.springer.com/article/10.1140/epjc/s10052-012-2189-5?error=cookies_not_supported&error=cookies_not_supported&error=cookies_not_supported&error=cookies_not_supported&code=21071af0-6750-4140-80e9-8f2d5beef1d6&code=a79c5aca-cf2c-4c14-b910-5f605dd5efce&code=63550759-4fba-43a8-8cb1-959c0725850a&code=be09e715-3305-48b7-a034-bbdb95b00afb,10113593539819618181,/scholar?cites=10113593539819618181,,,https://link.springer.com/article/10.1140/epjc/s10052-012-2189-5?error=cookies_not_supported&error=cookies_not_supported&error=cookies_not_supported&error=cookies_not_supported&code=1bcc77f4-8430-4d1b-9cec-42ca4383bc52&code=d42c1ca6-7e59-4feb-a1dd-9a9221bd632f&code=bcda8945-9e80-4f40-aa2a-9c3c0ea9f805&code=8844733a-70a2-4f6c-9080-9d40f97a5107,0,0,0
1278082,Classification of seizure and nonseizure EEG signals using empirical mode decomposition,2012,V Bajaj and RB Pachori,16,IEEE Transactions on Information Technology in BioMedicine,6,1135-1142,IEEE,In this paper. we present a new method for classification of electroencephalogram (EEG) signals using empirical mode decomposition (EMD) method. The intrinsic mode functions (IMFs) generated by EMD method can be considered as a set of amplitude and frequency modulated (AM-FM) signals. The Hilbert transformation of IMFs provides an analytic signal representation of the IMFs. The two bandwidths. namely amplitude modulation bandwidth ( B AM ) and frequency modulation bandwidth ( B FM ). computed from the analytic IMFs. have been used as an input to least squares support vector machine (LS-SVM) for classifying seizure and nonseizure EEG signals. The proposed method for classification of EEG signals based on the bandwidth features ( B AM  and  B FM ) and the LS-SVM has provided better classification accuracy than the method adopted by Liang and coworkers in their study published in 2010 …,True,j3iJOWMAAAAJ:Se3iqnhoufwC,419,https://ieeexplore.ieee.org/abstract/document/6111481/,11001629622278047250,/scholar?cites=11001629622278047250,,,https://www.researchgate.net/profile/Anubhav_Sharma5/post/Is_there_anyone_who_can_help_me_in_writing_a_MATLAB_code/attachment/59d620456cda7b8083a19900/AS%3A273638262018048%401442251853439/download/1.pdf,0,0,0
1278083,Classification of epileptic seizures in EEG signals based on phase space representation of intrinsic mode functions,2015,Rajeev Sharma and Ram Bilas Pachori,42,Expert Systems with Applications,03,1106-1117,Pergamon,Epileptic seizure is the most common disorder of human brain. which is generally detected from electroencephalogram (EEG) signals. In this paper. we have proposed the new features based on the phase space representation (PSR) for classification of epileptic seizure and seizure-free EEG signals. The EEG signals are firstly decomposed using empirical mode decomposition (EMD) and phase space has been reconstructed for obtained intrinsic mode functions (IMFs). For the purpose of classification of epileptic seizure and seizure-free EEG signals. two-dimensional (2D) and three-dimensional (3D) PSRs have been used. New features based on the 2D and 3D PSRs of IMFs have been proposed for classification of epileptic seizure and seizure-free EEG signals. Two measures have been defined namely. 95% confidence ellipse area for 2D PSR and interquartile range (IQR) of the Euclidian distances for 3D PSR …,True,j3iJOWMAAAAJ:R3hNpaxXUhUC,312,https://www.sciencedirect.com/science/article/pii/S0957417414005120,15571822744026521437,/scholar?cites=15571822744026521437,,,,0,0,0
1278084,Application of entropy measures on intrinsic mode functions for the automated identification of focal electroencephalogram signals,2015,Rajeev Sharma and Ram Bilas Pachori and U Rajendra Acharya,17,Entropy,2,669-691,Multidisciplinary Digital Publishing Institute,The brain is a complex structure made up of interconnected neurons. and its electrical activities can be evaluated using electroencephalogram (EEG) signals. The characteristics of the brain area affected by partial epilepsy can be studied using focal and non-focal EEG signals. In this work. a method for the classification of focal and non-focal EEG signals is presented using entropy measures. These entropy measures can be useful in assessing the nonlinear interrelation and complexity of focal and non-focal EEG signals. These EEG signals are first decomposed using the empirical mode decomposition (EMD) method to extract intrinsic mode functions (IMFs). The entropy features. namely. average Shannon entropy (ShEn Avg). average Renyi’s entropy (RenEn Avg). average approximate entropy (ApEn Avg). average sample entropy (SpEn Avg) and average phase entropies (S1Avg and S2 Avg). are computed from different IMFs of focal and non-focal EEG signals. These entropies are used as the input feature set for the least squares support vector machine (LS-SVM) classifier to classify into focal and non-focal EEG signals. Experimental results show that our proposed method is able to differentiate the focal and non-focal EEG signals with an average classification accuracy of 87% correct. View Full-Text,True,j3iJOWMAAAAJ:M3NEmzRMIkIC,250,https://www.mdpi.com/1099-4300/17/2/669,16446088156484368573,/scholar?cites=16446088156484368573,,,https://www.mdpi.com/1099-4300/17/2/669/pdf,0,0,0
1278085,Epileptic seizure classification in EEG signals using second-order difference plot of intrinsic mode functions,2014,Ram Bilas Pachori and Shivnarayan Patidar,113,Computer Methods and Programs in Biomedicine,2,494-502,Elsevier,Epilepsy is a neurological disorder which is characterized by transient and unexpected electrical disturbance of the brain. The electroencephalogram (EEG) is a commonly used signal for detection of epileptic seizures. This paper presents a new method for classification of ictal and seizure-free EEG signals. The proposed method is based on the empirical mode decomposition (EMD) and the second-order difference plot (SODP). The EMD method decomposes an EEG signal into a set of symmetric and band-limited signals termed as intrinsic mode functions (IMFs). The SODP of IMFs provides elliptical structure. The 95% confidence ellipse area measured from the SODP of IMFs has been used as a feature in order to discriminate seizure-free EEG signals from the epileptic seizure EEG signals. The feature space obtained from the ellipse area parameters of two IMFs has been used for classification of ictal and seizure …,True,j3iJOWMAAAAJ:dhFuZR0502QC,238,https://www.sciencedirect.com/science/article/pii/S0169260713003866,15467728763023551880,/scholar?cites=15467728763023551880,,,,0,0,0
1278086,Discrimination between ictal and seizure-free EEG signals using empirical mode decomposition,2008,R.B. Pachori,2008,Research Letters in Signal Processing,Article ID 293056,1-5,Hindawi Publishing Corp.,A new method for analysis of electroencephalogram (EEG) signals using empirical mode decomposition (EMD) and Fourier-Bessel (FB) expansion has been presented in this paper. The EMD decomposes an EEG signal into a finite set of band-limited signals termed intrinsic mode functions (IMFs). The mean frequency (MF) for each IMF has been computed using FB expansion. The MF measure of the IMFs has been used as a feature in order to identify the difference between ictal and seizure-free intracranial EEG signals. It has been shown that the MF feature of the IMFs has provided statistically significant difference between ictal and seizure-free EEG signals. Simulation results are included to illustrate the effectiveness of the proposed method.,True,j3iJOWMAAAAJ:d1gkVwhDpl0C,238,https://www.hindawi.com/journals/jece/2008/293056/abs/,956720885151851910,/scholar?cites=956720885151851910,,,https://www.hindawi.com/journals/jece/2008/293056/abs/,0,0,0
1278087,A new approach to characterize epileptic seizures using analytic time-frequency flexible wavelet transform and fractal dimension,2017,M Sharma and R.B. Pachori and U.R. Acharya,94,Pattern Recognition Letters,,172-179,,The identification of seizure activities in non-stationary electroencephalography (EEG) is a challenging task. The seizure detection by human inspection of EEG signals is prone to errors. inaccurate as well as time-consuming. Several attempts have been made to develop automatic systems so as to assist neurophysiologists in identifying epileptic seizures accurately. The proposed study brings forth a novel automatic approach to detect epileptic seizures using analytic time-frequency flexible wavelet transform (ATFFWT) and fractal dimension (FD). The ATFFWT has inherent attractive features such as. shift-invariance property. tunable oscillatory attribute and flexible time-frequency covering favorable for the analysis of non-stationary and transient signals. We have used ATFFWT to decompose EEG signals into the desired subbands. Following the ATFFWT decomposition. we calculate FD for each subband. Finally …,True,j3iJOWMAAAAJ:CHSYGLWDkRkC,222,https://www.sciencedirect.com/science/article/pii/S0167865517300995,14457585347367184757,/scholar?cites=14457585347367184757,,,https://www.researchgate.net/profile/Manish_Sharma53/publication/315582822_A_new_approach_to_characterize_epileptic_seizures_using_analytic_time-frequency_flexible_wavelet_transform_and_fractal_dimension/links/59d9f8efa6fdcc2aad128444/A-new-approach-to-characterize-epileptic-seizures-using-analytic-time-frequency-flexible-wavelet-transform-and-fractal-dimension.pdf,0,0,0
1278088,Classification of ictal and seizure-free EEG signals using fractional linear prediction,2014,Varun Joshi and Ram Bilas Pachori and Antony Vijesh,9,Biomedical Signal Processing and Control,,1-5,Elsevier,In this paper. we present a new method for electroencephalogram (EEG) signal classification based on fractional-order calculus. The method. termed fractional linear prediction (FLP). is used to model ictal and seizure-free EEG signals. It is found that the modeling error energy is substantially higher for ictal EEG signals compared to seizure-free EEG signals. Moreover. it is known that ictal EEG signals have higher energy than seizure-free EEG signals. These two parameters are then given as inputs to train a support vector machine (SVM). The trained SVM is then used to classify a set of EEG signals into ictal and seizure-free categories. It is found that the proposed method gives a classification accuracy of 95.33% when the SVM is trained with the radial basis function (RBF) kernel.,True,j3iJOWMAAAAJ:_kc_bZDykSQC,218,https://www.sciencedirect.com/science/article/pii/S1746809413001195,1970584624537022373,/scholar?cites=1970584624537022373,,,,0,0,0
1278089,Analysis of normal and epileptic seizure EEG signals using empirical mode decomposition,2011,Ram Bilas Pachori and Varun Bajaj,104,Computer Methods and Programs in Biomedicine,3,373-381,Elsevier,Epilepsy is one of the most common neurological disorders characterized by transient and unexpected electrical disturbance of the brain. The electroencephalogram (EEG) is an invaluable measurement for the purpose of assessing brain activities. containing information relating to the different physiological states of the brain. It is a very effective tool for understanding the complex dynamical behavior of the brain. This paper presents the application of empirical mode decomposition (EMD) for analysis of EEG signals. The EMD decomposes a EEG signal into a finite set of bandlimited signals termed intrinsic mode functions (IMFs). The Hilbert transformation of IMFs provides analytic signal representation of IMFs. The area measured from the trace of the analytic IMFs. which have circular form in the complex plane. has been used as a feature in order to discriminate normal EEG signals from the epileptic seizure EEG …,True,j3iJOWMAAAAJ:roLk4NBRz8UC,217,https://www.sciencedirect.com/science/article/pii/S0169260711000745,9993893035301946784,/scholar?cites=9993893035301946784,,,,0,0,0
1278090,A multivariate approach for patient specific EEG seizure detection using empirical wavelet transform,2017,Abhijit Bhattacharyya and Ram Bilas Pachori,64,IEEE Transactions on Biomedical Engineering,09,2003-2015,,,True,j3iJOWMAAAAJ:pyW8ca7W8N0C,185,https://ieeexplore.ieee.org/abstract/document/7811263/,11222555601808671140,/scholar?cites=11222555601808671140,,,,0,0,0
1278091,Automated diagnosis of glaucoma using empirical wavelet transform and correntropy features extracted from fundus images,2017,Shishir Maheshwari and Ram Bilas Pachori and U Rajendra Acharya,21,IEEE Journal of Biomedical and Health Informatics,03,803-813,IEEE,Glaucoma is an ocular disorder caused due to increased fluid pressure in the optic nerve. It damages the optic nerve and subsequently causes loss of vision. The available scanning methods are Heidelberg retinal tomography. scanning laser polarimetry. and optical coherence tomography. These methods are expensive and require experienced clinicians to use them. So. there is a need to diagnose glaucoma accurately with low cost. Hence. in this paper. we have presented a new methodology for an automated diagnosis of glaucoma using digital fundus images based on empirical wavelet transform (EWT). The EWT is used to decompose the image. and correntropy features are obtained from decomposed EWT components. These extracted features are ranked based on t value feature selection algorithm. Then. these features are used for the classification of normal and glaucoma images using least-squares …,True,j3iJOWMAAAAJ:ldfaerwXgEUC,166,https://ieeexplore.ieee.org/abstract/document/7438741/,14344061444290215733,/scholar?cites=14344061444290215733,,,https://www.researchgate.net/profile/Ram_Pachori/publication/298787743_Automated_Diagnosis_of_Glaucoma_Using_Empirical_Wavelet_Transform_and_Correntropy_Features_Extracted_From_Fundus_Images/links/5bfaa9a7458515a69e3abbda/Automated-Diagnosis-of-Glaucoma-Using-Empirical-Wavelet-Transform-and-Correntropy-Features-Extracted-From-Fundus-Images.pdf,0,0,0
1278092,Automated diagnosis of epilepsy using key-point based local binary pattern of EEG signals,2017,AK Tiwari and RB Pachori and V Kanhangad and BK Panigrahi,21,IEEE Journal of Biomedical and Health Informatics,4,888-896,,The electroencephalogram (EEG) signals are commonly used for diagnosis of epilepsy. In this paper. we present a new methodology for EEG-based automated diagnosis of epilepsy. Our method involves detection of key points at multiple scales in EEG signals using a pyramid of difference of Gaussian filtered signals. Local binary patterns (LBPs) are computed at these key points and the histogram of these patterns are considered as the feature set. which is fed to the support vector machine (SVM) for the classification of EEG signals. The proposed methodology has been investigated for the four well-known classification problems namely. 1) normal and epileptic seizure. 2) epileptic seizure and seizure free. 3) normal. epileptic seizure. and seizure free. and 4) epileptic seizure and nonseizure EEG signals using publically available university of Bonn EEG database. Our experimental results in terms of classification …,True,j3iJOWMAAAAJ:pqnbT2bcN3wC,155,https://ieeexplore.ieee.org/abstract/document/7508917/,10790462861927028397,/scholar?cites=10790462861927028397,,,,0,0,0
1278093,A review of lithium-ion battery state of charge estimation and management system in electric vehicle applications: Challenges and recommendations,2017,Mohammad A Hannan and MS Hossain Lipu and Aini Hussain and Azah Mohamed,78,,,834-854,Pergamon,Due to increasing concerns about global warming. greenhouse gas emissions. and the depletion of fossil fuels. the electric vehicles (EVs) receive massive popularity due to their performances and efficiencies in recent decades. EVs have already been widely accepted in the automotive industries considering the most promising replacements in reducing CO2 emissions and global environmental issues. Lithium-ion batteries have attained huge attention in EVs application due to their lucrative features such as lightweight. fast charging. high energy density. low self-discharge and long lifespan. This paper comprehensively reviews the lithium-ion battery state of charge (SOC) estimation and its management system towards the sustainable future EV applications. The significance of battery management system (BMS) employing lithium-ion batteries is presented. which can guarantee a reliable and safe operation and …,True,gk4jJwUAAAAJ:L7CI7m0gUJcC,691,https://www.sciencedirect.com/science/article/pii/S1364032117306275,7219148890613774787,/scholar?cites=7219148890613774787,,,,0,0,0
1278094,State-of-the-art and energy management system of lithium-ion batteries in electric vehicle applications: Issues and recommendations,2018,Mahammad A Hannan and Md Murshadul Hoque and Aini Hussain and Yushaizad Yusof and Pin Jern Ker,6,,,19362-19378,IEEE,A variety of rechargeable batteries are now available in world markets for powering electric vehicles (EVs). The lithium-ion (Li-ion) battery is considered the best among all battery types and cells because of its superior characteristics and performance. The positive environmental impacts and recycling potential of lithium batteries have influenced the development of new research for improving Li-ion battery technologies. However. the cost reduction. safe operation. and mitigation of negative ecological impacts are now a common concern for advancement. This paper provides a comprehensive study on the state of the art of Li-ion batteries including the fundamentals. structures. and overall performance evaluations of different types of lithium batteries. A study on a battery management system for Li-ion battery storage in EV applications is demonstrated. which includes a cell condition monitoring. charge. and …,True,gk4jJwUAAAAJ:Ri6SYOTghG4C,256,https://ieeexplore.ieee.org/abstract/document/8320763/,8692650983257999678,/scholar?cites=8692650983257999678,,,https://ieeexplore.ieee.org/iel7/6287639/6514899/08320763.pdf,0,0,0
1278095,Energy harvesting for the implantable biomedical devices: issues and challenges,2014,Mahammad A Hannan and Saad Mutashar and Salina A Samad and Aini Hussain,13,,1,1-23,BioMed Central,The development of implanted devices is essential because of their direct effect on the lives and safety of humanity. This paper presents the current issues and challenges related to all methods used to harvest energy for implantable biomedical devices. The advantages. disadvantages. and future trends of each method are discussed. The concept of harvesting energy from environmental sources and human body motion for implantable devices has gained a new relevance. In this review. the harvesting kinetic. electromagnetic. thermal and infrared radiant energies are discussed. Current issues and challenges related to the typical applications of these methods for energy harvesting are illustrated. Suggestions and discussion of the progress of research on implantable devices are also provided. This review is expected to increase research efforts to develop the battery-less implantable devices with reduced over hole size. low power. high efficiency. high data rate. and improved reliability and feasibility. Based on current literature. we believe that the inductive coupling link is the suitable method to be used to power the battery-less devices. Therefore. in this study. the power efficiency of the inductive coupling method is validated by MATLAB based on suggested values. By further researching and improvements. in the future the implantable and portable medical devices are expected to be free of batteries.,True,gk4jJwUAAAAJ:LXmCCkuhhTsC,229,https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-13-79,16024292287142976029,/scholar?cites=16024292287142976029,,,https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-13-79,0,0,0
1278096,Review of energy storage system technologies in microgrid applications: Issues and challenges,2018,Mohammad Faisal and Mahammad A Hannan and Pin Jern Ker and Aini Hussain and Muhamad Bin Mansor and Frede Blaabjerg,6,,,35143-35164,IEEE,A microgrid (MG) is a local entity that consists of distributed energy resources (DERs) to achieve local power reliability and sustainable energy utilization. The MG concept or renewable energy technologies integrated with energy storage systems (ESS) have gained increasing interest and popularity because it can store energy at off-peak hours and supply energy at peak hours. However. existing ESS technology faces challenges in storing energy due to various issues. such as charging/discharging. safety. reliability. size. cost. life cycle. and overall management. Thus. an advanced ESS is required with regard to capacity. protection. control interface. energy management. and characteristics to enhance the performance of ESS in MG applications. This paper comprehensively reviews the types of ESS technologies. ESS structures along with their configurations. classifications. features. energy conversion. and …,True,gk4jJwUAAAAJ:kRWSkSYxWN8C,197,https://ieeexplore.ieee.org/abstract/document/8368103/,4566229790617576739,/scholar?cites=4566229790617576739,,,https://ieeexplore.ieee.org/iel7/6287639/6514899/08368103.pdf,0,0,0
1278097,A review of state of health and remaining useful life estimation methods for lithium-ion battery in electric vehicles: Challenges and recommendations,2018,MS Hossain Lipu and MA Hannan and Aini Hussain and MM Hoque and Pin J Ker and MH Md Saad and Afida Ayob,205,,,115-133,Elsevier,Electric vehicles (EVs) have become increasingly popular due to zero carbon emission. reduction of fossil fuel reserve. comfortable and light transport. However. EVs employing lithium-ion battery are facing difficulties in terms of predicting accurate health and remaining useful life states due to various internal and external factors. Currently. very few papers are addressed to summarize the state of health (SOH) and remaining useful life (RUL) estimation approaches. In this regard. the goal of this paper is to comprehensively review the different estimation models to predict SOH. and RUL in a comparative manner. The results identify the classifications. characteristics and evaluation processes with advantages and disadvantages for EV applications. The review also investigates the issues and challenges with possible solutions. Furthermore. the review provides some selective proposals for the further technological …,True,gk4jJwUAAAAJ:lgwcVrK6X84C,170,https://www.sciencedirect.com/science/article/pii/S0959652618327793,11787826883578723906,/scholar?cites=11787826883578723906,,,https://www.researchgate.net/profile/Pin-Jern-Ker/publication/327556039_A_review_of_state_of_health_and_remaining_useful_life_estimation_methods_for_lithium-ion_battery_in_electric_vehicles_Challenges_and_recommendations/links/5b9b5bcd299bf13e602d4c97/A-review-of-state-of-health-and-remaining-useful-life-estimation-methods-for-lithium-ion-battery-in-electric-vehicles-Challenges-and-recommendations.pdf,0,0,0
1278098,A review on technologies and their usage in solid waste monitoring and management systems: Issues and challenges,2015,MA Hannan and Md Abdulla Al Mamun and Aini Hussain and Hassan Basri and Rawshan Ara Begum,43,,,509-523,Pergamon,In the backdrop of prompt advancement. information and communication technology (ICT) has become an inevitable part to plan and design of modern solid waste management (SWM) systems. This study presents a critical review of the existing ICTs and their usage in SWM systems to unfold the issues and challenges towards using integrated technologies based system. To plan. monitor. collect and manage solid waste. the ICTs are divided into four categories such as spatial technologies. identification technologies. data acquisition technologies and data communication technologies. The ICT based SWM systems classified in this paper are based on the first three technologies while the forth one is employed by almost every systems. This review may guide the reader about the basics of available ICTs and their application in SWM to facilitate the search for planning and design of a sustainable new system.,True,gk4jJwUAAAAJ:DyXnQzXoVgIC,125,https://www.sciencedirect.com/science/article/pii/S0956053X15004080,16287171235781317944,/scholar?cites=16287171235781317944,,,,0,0,0
1278099,Daily forecasting of dam water levels: comparing a support vector machine (SVM) model with adaptive neuro fuzzy inference system (ANFIS),2013,Afiq Hipni and Ahmed El-shafie and Ali Najah and Othman Abdul Karim and Aini Hussain and Muhammad Mukhlisin,27,Water resources management,10,3803-3823,Springer Netherlands,Reservoir planning and management are critical to the development of the hydrological field and necessary to Integrated Water Resources Management. The growth of forecasting models has resulted in an excellent model known as the Support Vector Machine (SVM). This model uses linearly separable patterns based on an optimal hyperplane. which are extended to non-linearly separable patterns by transforming the raw data to map into a new space. SVM can find a global optimal solution equipped with Kernel functions. These Kernel functions have high flexibility in the forecasting computation. enabling data to be mapped at a higher and infinite-dimensional space in an implicit manner. This paper presents a new solution to the expert system. using SVM to forecast the daily dam water level of the Klang gate. Four categories are identified to determine the best model: the input scenario. the type of SVM …,True,gk4jJwUAAAAJ:maZDTaKrznsC,118,https://link.springer.com/article/10.1007/s11269-013-0382-4,1709115887829886184,/scholar?cites=1709115887829886184,,,https://www.researchgate.net/profile/Muhammad_Mukhlisin2/publication/257672896_Daily_Forecasting_of_Dam_Water_Levels_Comparing_a_Support_Vector_Machine_SVM_Model_With_Adaptive_Neuro_Fuzzy_Inference_System_ANFIS/links/0f31752f1c278dccb1000000.pdf,0,0,0
1278100,Neural network approach for estimating state of charge of lithium-ion battery using backtracking search algorithm,2018,Mahammad A Hannan and Molla S Hossain Lipu and Aini Hussain and Mohamad H Saad and Afida Ayob,6,Ieee Access,,10069-10079,IEEE,The state of charge (SOC) is a critical evaluation index of battery residual capacity. The significance of an accurate SOC estimation is great for a lithium-ion battery to ensure its safe operation and to prevent from over-charging or over-discharging. However. to estimate an accurate capacity of SOC of the lithium-ion battery has become a major concern for the electric vehicle (EV) industry. Therefore. numerous researches are being conducted to address the challenges and to enhance the battery performance. The main objective of this paper is to develop an accurate SOC estimation approach for a lithium-ion battery by improving back-propagation neural network (BPNN) capability using backtracking search algorithm (BSA). BSA optimization is utilized to improve the accuracy and robustness of BPNN model by finding the optimal value of hidden layer neurons and learning rate. In this paper. Dynamic Stress Test and …,True,gk4jJwUAAAAJ:-yGd096yOn8C,114,https://ieeexplore.ieee.org/abstract/document/8269299/,17517588760963328008,/scholar?cites=17517588760963328008,,,https://ieeexplore.ieee.org/iel7/6287639/6514899/08269299.pdf,0,0,0
1278101,ANN based sediment prediction model utilizing different input scenarios,2015,Haitham Abdulmohsin Afan and Ahmed El-Shafie and Zaher Mundher Yaseen and Mohammed Majeed Hameed and Wan Hanna Melini Wan Mohtar and Aini Hussain,29,Water resources management,4,1231-1245,Springer Netherlands,Modeling sediment load is a significant factor in water resources engineering as it affects directly the design and management of water resources. In this study. artificial neural networks (ANNs) are employed to estimate the daily sediment load. Two different ANN algorithms. the feed forward neural network (FFNN) and radial basis function (RBF) have been used for this purpose. The neural networks are trained and tested using daily sediment and flow data from Rantau Panjang station on Johor River. The results show that combining flow data with sediment load data gives an accurate model to predict sediment load. The comparison of the results indicate that the FFNN model has superior performance than the RB model in estimating daily sediment load.,True,gk4jJwUAAAAJ:LkGwnXOMwfcC,109,https://link.springer.com/article/10.1007/s11269-014-0870-1,381224737330027193,/scholar?cites=381224737330027193,,,,0,0,0
1278102,A new approach to locate the voltage sag source using real current component,2004,Noraliza Hamzah and Azah Mohamed and Aini Hussain,72,Electric Power Systems Research,2,113-123,Elsevier,Voltage sag can cause hours of downtime. substantial loss of product and also can attribute to malfunctions. instabilities and shorter lifetime of the load. Accurate voltage sag source location can help to minimize the loss and problems caused by voltage sag in a power distribution system. This paper proposes a new method to locate the source of voltage sag in a power distribution system. The proposed method uses the polarity of the real current component to determine the sag location relative to the monitoring point. The product of the RMS current and the power factor angle at the monitoring point is employed for the sag source location. A graph of this product against time is plotted. The voltage sag source location is determined by examining the polarity of the RMS current at the beginning of the sag. The proposed method has been verified by simulations and the results are proven to be in agreement when …,True,gk4jJwUAAAAJ:IUKN3-7HHlwC,109,https://www.sciencedirect.com/science/article/pii/S0378779604000896,9459060327898936582,/scholar?cites=9459060327898936582,,,https://www.academia.edu/download/51233074/j.epsr.2004.03.01020170107-15588-1e6f2d0.pdf,0,0,0
1278103,Capacitated vehicle-routing problem model for scheduled solid waste collection and route optimization using PSO algorithm,2018,MA Hannan and Mahmuda Akhtar and RA Begum and H Basri and A Hussain and Edgar Scavino,71,Waste management,,31-41,Pergamon,Waste collection widely depends on the route optimization problem that involves a large amount of expenditure in terms of capital. labor. and variable operational costs. Thus. the more waste collection route is optimized. the more reduction in different costs and environmental effect will be. This study proposes a modified particle swarm optimization (PSO) algorithm in a capacitated vehicle-routing problem (CVRP) model to determine the best waste collection and route optimization solutions. In this study. threshold waste level (TWL) and scheduling concepts are applied in the PSO-based CVRP model under different datasets. The obtained results from different datasets show that the proposed algorithmic CVRP model provides the best waste collection and route optimization in terms of travel distance. total waste. waste collection efficiency. and tightness at 70–75% of TWL. The obtained results for 1 week scheduling …,True,gk4jJwUAAAAJ:FPJr55Dyh1AC,103,https://www.sciencedirect.com/science/article/pii/S0956053X17307675,8505213622277486948,/scholar?cites=8505213622277486948,,,,0,0,0
1278104,Bayesian compressive sensing using Laplace priors,2009,S Derin Babacan and Rafael Molina and Aggelos K Katsaggelos,19,IEEE Transactions on image processing,1,53-63,IEEE,In this paper. we model the components of the compressive sensing (CS) problem. i.e.. the signal acquisition process. the unknown signal coefficients and the model parameters for the signal and noise using the Bayesian framework. We utilize a hierarchical form of the Laplace prior to model the sparsity of the unknown signal. We describe the relationship among a number of sparsity priors proposed in the literature. and show the advantages of the proposed model including its high degree of sparsity. Moreover. we show that some of the existing models are special cases of the proposed model. Using our model. we develop a constructive (greedy) algorithm designed for fast reconstruction useful in practical settings. Unlike most existing CS reconstruction methods. the proposed algorithm is fully automated. i.e.. the unknown signal coefficients and all necessary parameters are estimated solely from the observation …,True,u6K_sU8AAAAJ:WF5omc3nYNoC,686,https://ieeexplore.ieee.org/abstract/document/5256324/,12449638710167087390,/scholar?cites=12449638710167087390,,,https://www.academia.edu/download/30674708/babacan_CS.pdf,0,0,0
1278105,Variational Bayesian super resolution,2010,S Derin Babacan and Rafael Molina and Aggelos K Katsaggelos,20,IEEE Transactions on Image Processing,4,984-999,IEEE,In this paper. we address the super resolution (SR) problem from a set of degraded low resolution (LR) images to obtain a high resolution (HR) image. Accurate estimation of the sub-pixel motion between the LR images significantly affects the performance of the reconstructed HR image. In this paper. we propose novel super resolution methods where the HR image and the motion parameters are estimated simultaneously. Utilizing a Bayesian formulation. we model the unknown HR image. the acquisition process. the motion parameters and the unknown model parameters in a stochastic sense. Employing a variational Bayesian analysis. we develop two novel algorithms which jointly estimate the distributions of all unknowns. The proposed framework has the following advantages: 1) Through the incorporation of uncertainty of the estimates. the algorithms prevent the propagation of errors between the estimates of …,True,u6K_sU8AAAAJ:rO6llkc54NcC,291,https://ieeexplore.ieee.org/abstract/document/5585756/,6969710887412813337,/scholar?cites=6969710887412813337,,,https://www.academia.edu/download/30674938/SR_IP_Derin11.pdf,0,0,0
1278106,A survey of classical methods and new trends in pansharpening of multispectral images,2011,Israa Amro and Javier Mateos and Miguel Vega and Rafael Molina and Aggelos K Katsaggelos,2011,,1,1-22,SpringerOpen,There exist a number of satellites on different earth observation platforms. which provide multispectral images together with a panchromatic image. that is. an image containing reflectance data representative of a wide range of bands and wavelengths. Pansharpening is a pixel-level fusion technique used to increase the spatial resolution of the multispectral image while simultaneously preserving its spectral information. In this paper. we provide a review of the pan-sharpening methods proposed in the literature giving a clear classification of them and a description of their main characteristics. Finally. we analyze how the quality of the pansharpened images can be assessed both visually and quantitatively and examine the different quality measures proposed for that purpose.,True,u6K_sU8AAAAJ:OU6Ihb5iCvQC,272,https://asp-eurasipjournals.springeropen.com/articles/10.1186/1687-6180-2011-79,1605416143052271250,/scholar?cites=1605416143052271250,,,https://asp-eurasipjournals.springeropen.com/articles/10.1186/1687-6180-2011-79,0,0,0
1278107,Blind deconvolution using a variational approach to parameter. image. and blur estimation,2006,Rafael Molina and Javier Mateos and Aggelos K Katsaggelos,15,IEEE Transactions on Image Processing,12,3715-3727,IEEE,Following the hierarchical Bayesian framework for blind deconvolution problems. in this paper. we propose the use of simultaneous autoregressions as prior distributions for both the image and blur. and gamma distributions for the unknown parameters (hyperparameters) of the priors and the image formation noise. We show how the gamma distributions on the unknown hyperparameters can be used to prevent the proposed blind deconvolution method from converging to undesirable image and blur estimates and also how these distributions can be inferred in realistic situations. We apply variational methods to approximate the posterior probability of the unknown image. blur. and hyperparameters and propose two different approximations of the posterior distribution. One of these approximations coincides with a classical blind deconvolution method. The proposed algorithms are tested experimentally and …,True,u6K_sU8AAAAJ:2osOgNQ5qMEC,269,https://ieeexplore.ieee.org/abstract/document/4011964/,17850099087629497814,/scholar?cites=17850099087629497814,,,https://www.imaging.utk.edu/research/traglan4/Fall2008/tasks/task4/References/Blind%20Deconvolution%20Using%20a%20Variational%20Approach%20to%20Parameter%20Image%20and%20Blur%20Estimation.pdf,0,0,0
1278108,Sparse Bayesian methods for low-rank matrix estimation,2012,S Derin Babacan and Martin Luessi and Rafael Molina and Aggelos K Katsaggelos,60,IEEE Transactions on Signal Processing,8,3964-3977,IEEE,Recovery of low-rank matrices has recently seen significant activity in many areas of science and engineering. motivated by recent theoretical results for exact reconstruction guarantees and interesting practical applications. In this paper. we present novel recovery algorithms for estimating low-rank matrices in matrix completion and robust principal component analysis based on sparse Bayesian learning (SBL) principles. Starting from a matrix factorization formulation and enforcing the low-rank constraint in the estimates as a sparsity constraint. we develop an approach that is very effective in determining the correct rank while providing high recovery performance. We provide connections with existing methods in other similar problems and empirical results and comparisons with current state-of-the-art methods that illustrate the effectiveness of this approach.,True,u6K_sU8AAAAJ:bFI3QPDXJZMC,255,https://ieeexplore.ieee.org/abstract/document/6194350/,10062738994680869921,/scholar?cites=10062738994680869921,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.9666&rep=rep1&type=pdf,0,0,0
1278109,Using deep neural networks for inverse problems in imaging: beyond analytical methods,2018,Alice Lucas and Michael Iliadis and Rafael Molina and Aggelos K Katsaggelos,35,IEEE Signal Processing Magazine,1,20-36,IEEE,Traditionally. analytical methods have been used to solve imaging problems such as image restoration. inpainting. and superresolution (SR). In recent years. the fields of machine and deep learning have gained a lot of momentum in solving such imaging problems. often surpassing the performance provided by analytical approaches. Unlike analytical methods for which the problem is explicitly defined and domain-knowledge carefully engineered into the solution. deep neural networks (DNNs) do not benefit from such prior knowledge and instead make use of large data sets to learn the unknown solution to the inverse problem. In this article. we review deep-learning techniques for solving such inverse problems in imaging. More specifically. we review the popular neural network architectures used for imaging tasks. offering some insight as to how these deep-learning tools can solve the inverse problem …,True,u6K_sU8AAAAJ:prvsfHNhuEoC,246,https://ieeexplore.ieee.org/abstract/document/8253590/,5025319881753512399,/scholar?cites=5025319881753512399,,,https://indico.flatironinstitute.org/category/18/attachments/163/39/Lucas2018_IEEE_SPM.pdf,0,0,0
1278110,Variational Bayesian blind deconvolution using a total variation prior,2008,S Derin Babacan and Rafael Molina and Aggelos K Katsaggelos,18,IEEE Transactions on Image Processing,1,12-26,IEEE,In this paper. we present novel algorithms for total variation (TV) based blind deconvolution and parameter estimation utilizing a variational framework. Using a hierarchical Bayesian model. the unknown image. blur. and hyperparameters for the image. blur. and noise priors are estimated simultaneously. A variational inference approach is utilized so that approximations of the posterior distributions of the unknowns are obtained. thus providing a measure of the uncertainty of the estimates. Experimental results demonstrate that the proposed approaches provide higher restoration performance than non-TV-based methods without any assumptions about the unknown hyperparameters.,True,u6K_sU8AAAAJ:Se3iqnhoufwC,245,https://ieeexplore.ieee.org/abstract/document/4689325/,15115515825610213710,/scholar?cites=15115515825610213710,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.344.1415&rep=rep1&type=pdf,0,0,0
1278111,Bayesian and regularization methods for hyperparameter estimation in image restoration,1999,Rafael Molina and Aggelos K Katsaggelos and Javier Mateos,8,IEEE transactions on image processing,2,231-246,IEEE,In this paper. we propose the application of the hierarchical Bayesian paradigm to the image restoration problem. We derive expressions for the iterative evaluation of the two hyperparameters applying the evidence and maximum a posteriori (MAP) analysis within the hierarchical Bayesian paradigm. We show analytically that the analysis provided by the evidence approach is more realistic and appropriate than the MAP approach for the image restoration problem. We furthermore study the relationship between the evidence and an iterative approach resulting from the set theoretic regularization approach for estimating the two hyperparameters. or their ratio. defined as the regularization parameter. Finally the proposed algorithms are tested experimentally.,True,u6K_sU8AAAAJ:u5HHmVD_uO8C,239,https://ieeexplore.ieee.org/abstract/document/743857/,2391141514791992277,/scholar?cites=2391141514791992277,,,https://ivpl.northwestern.edu/wp-content/uploads/2019/02/download-1.pdf,0,0,0
1278112,Super resolution of images and video,2007,Aggelos K Katsaggelos and Rafael Molina and Javier Mateos,1,"Synthesis Lectures on Image, Video, and Multimedia Processing",1,1-134,Morgan & Claypool Publishers,This book focuses on the super resolution of images and video. The authors’ use of the term super resolution (SR) is used to describe the process of obtaining a high resolution (HR) image. or a sequence of HR images. from a set of low resolution (LR) observations. This process has also been referred to in the literature as resolution enhancement (RE). SR has been applied primarily to spatial and temporal RE. but also to hyperspectral image enhancement. This book concentrates on motion based spatial RE. although the authors also describe motion free and hyperspectral image SR problems. Also examined is the very recent research area of SR for compression. which consists of the intentional downsampling. during pre-processing. of a video sequence to be compressed and the application of SR techniques. during post-processing. on the compressed sequence.It is clear that there is a strong interplay between …,True,u6K_sU8AAAAJ:Tyk-4Ss8FVUC,224,https://www.morganclaypool.com/doi/abs/10.2200/S00036ED1V01Y200606IVM007,6656812583390762517,/scholar?cites=6656812583390762517,,,,0,0,0
1278113,Parameter estimation in TV image restoration using variational distribution approximation,2008,S Derin Babacan and Rafael Molina and Aggelos K Katsaggelos,17,IEEE transactions on image processing,3,326-339,IEEE,In this paper. we propose novel algorithms for total variation (TV) based image restoration and parameter estimation utilizing variational distribution approximations. Within the hierarchical Bayesian formulation. the reconstructed image and the unknown hyperparameters for the image prior and the noise are simultaneously estimated. The proposed algorithms provide approximations to the posterior distributions of the latent variables using variational methods. We show that some of the current approaches to TV-based image restoration are special cases of our framework. Experimental results show that the proposed approaches provide competitive performance without any assumptions about unknown hyperparameters and clearly outperform existing methods when additional information is included.,True,u6K_sU8AAAAJ:zYLM7Y9cAGgC,211,https://ieeexplore.ieee.org/abstract/document/4446214/,7281845257882718430,/scholar?cites=7281845257882718430,,,https://www.researchgate.net/profile/Aggelos_Katsaggelos/publication/5582192_Parameter_Estimation_in_TV_Image_Restoration_Using_Variational_Distribution_Approximation/links/54e34a1a0cf2d90c1d9c5699/Parameter-Estimation-in-TV-Image-Restoration-Using-Variational-Distribution-Approximation.pdf,0,0,0
1278114,Bayesian resolution enhancement of compressed video,2004,C Andrew Segall and Aggelos K Katsaggelos and Rafael Molina and Javier Mateos,13,IEEE Transactions on image processing,7,898-911,IEEE,Super-resolution algorithms recover high-frequency information from a sequence of low-resolution observations. In this paper. we consider the impact of video compression on the super-resolution task. Hybrid motion-compensation and transform coding schemes are the focus. as these methods provide observations of the underlying displacement values as well as a variable noise process. We utilize the Bayesian framework to incorporate this information and fuse the super-resolution and post-processing problems. A tractable solution is defined. and relationships between algorithm parameters and information in the compressed bitstream are established. The association between resolution recovery and compression ratio is also explored. Simulations illustrate the performance of the procedure with both synthetic and nonsynthetic sequences.,True,u6K_sU8AAAAJ:d1gkVwhDpl0C,176,https://ieeexplore.ieee.org/abstract/document/1303643/,16397907510069003273,/scholar?cites=16397907510069003273,,,https://www.academia.edu/download/49008672/02ipsuperres.pdf,0,0,0
1278115,Locating and extracting the eye in human face images,1996,Kin-Man Lam and Hong Yan,29,Pattern recognition,5,771-779,Pergamon,Facial feature extraction is an important step in automated visual interpretation and human face recognition. Among the facial features. the eye plays the most important part in the recognition process. The deformable template can be used in extracting the eye boundaries. However. the weaknesses of the deformable template are that the processing time is lengthy and that its success relies on the initial position of the template. In this paper. the head boundary is first located in a head-and-shoulders image. The approximate positions of the eyes are estimated by means of average anthropometric measures. Corners. the salient features of the eyes. are detected and used to set the initial parameters of the eye templates. The corner detection scheme introduced in this paper can provide accurate information about the corners. Based on the corner positions. we can accurately locate the templates in relation to the eye …,True,6yK7bewAAAAJ:f2IySw72cVMC,495,https://www.sciencedirect.com/science/article/pii/0031320395001190,683974882842445776,/scholar?cites=683974882842445776,,,http://www.eie.polyu.edu.hk/~enkmlam/Papers/PR96.pdf,0,0,0
1278116,An analytic-to-holistic approach for face recognition based on a single frontal view,1998,Kin-Man Lam and Hong Yan,20,IEEE Transactions on pattern analysis and machine intelligence,7,673-686,IEEE,We propose an analytic-to-holistic approach which can identify faces at different perspective variations. The database for the test consists of 40 frontal-view faces. The first step is to locate 15 feature points on a face. A head model is proposed. and the rotation of the face can be estimated using geometrical measurements. The positions of the feature points are adjusted so that their corresponding positions for the frontal view are approximated. These feature points are then compared with the feature points of the faces in a database using a similarity transform. In the second step. we set up windows for the eyes. nose. and mouth. These feature windows are compared with those in the database by correlation. Results show that this approach can achieve a similar level of performance from different viewing directions of a face. Under different perspective variations. the overall recognition rates are over 84 percent and …,True,6yK7bewAAAAJ:bFI3QPDXJZMC,357,https://ieeexplore.ieee.org/abstract/document/689299/,14453716877146759379,/scholar?cites=14453716877146759379,,,,0,0,0
1278117,A level set approach to image segmentation with intensity inhomogeneity,2015,Kaihua Zhang and Lei Zhang and Kin-Man Lam and David Zhang,46,IEEE transactions on cybernetics,2,546-557,IEEE,It is often a difficult task to accurately segment images with intensity inhomogeneity. because most of representative algorithms are region-based that depend on intensity homogeneity of the interested object. In this paper. we present a novel level set method for image segmentation in the presence of intensity inhomogeneity. The inhomogeneous objects are modeled as Gaussian distributions of different means and variances in which a sliding window is used to map the original image into another domain. where the intensity distribution of each object is still Gaussian but better separated. The means of the Gaussian distributions in the transformed domain can be adaptively estimated by multiplying a bias field with the original signal within the window. A maximum likelihood energy functional is then defined on the whole image region. which combines the bias field. the level set function. and the piecewise constant …,True,6yK7bewAAAAJ:qE4H1tSSYIIC,300,https://ieeexplore.ieee.org/abstract/document/7059203/,18227489507458213261,/scholar?cites=18227489507458213261,,,http://kaihuazhang.net/J_papers/tcyb2014b.pdf,0,0,0
1278118,An efficient algorithm for human face detection and facial feature extraction under different conditions,2001,Kwok-Wai Wong and Kin-Man Lam and Wan-Chi Siu,34,Pattern Recognition,10,1993-2004,Pergamon,In this paper. an efficient algorithm for human face detection and facial feature extraction is devised. Firstly. the location of the face regions is detected using the genetic algorithm and the eigenface technique. The genetic algorithm is applied to search for possible face regions in an image. while the eigenface technique is used to determine the fitness of the regions. As the genetic algorithm is computationally intensive. the searching space is reduced and limited to the eye regions so that the required timing is greatly reduced. Possible face candidates are then further verified by measuring their symmetries and determining the existence of the different facial features. Furthermore. in order to improve the level of detection reliability in our approach. the lighting effect and orientation of the faces are considered and solved.,True,6yK7bewAAAAJ:EUQCXRtRnyEC,225,https://www.sciencedirect.com/science/article/pii/S0031320300001345,15570086210013768464,/scholar?cites=15570086210013768464,,,https://www.academia.edu/download/31770909/PR01b.pdf,0,0,0
1278119,An efficient illumination normalization method for face recognition,2006,Xudong Xie and Kin-Man Lam,27,Pattern Recognition Letters,6,609-617,North-Holland,In this paper. an efficient representation method insensitive to varying illumination is proposed for human face recognition. Theoretical analysis based on the human face model and the illumination model shows that the effects of varying lighting on a human face image can be modeled by a sequence of multiplicative and additive noises. Instead of computing these noises. which is very difficult for real applications. we aim to reduce or even remove their effect. In our method. a local normalization technique is applied to an image. which can effectively and efficiently eliminate the effect of uneven illuminations while keeping the local statistical properties of the processed image the same as in the corresponding image under normal lighting condition. After processing. the image under varying illumination will have similar pixel values to the corresponding image that is under normal lighting condition. Then. the processed …,True,6yK7bewAAAAJ:b0M2c_1WBrUC,209,https://www.sciencedirect.com/science/article/pii/S0167865505002795,1658934970340339918,/scholar?cites=1658934970340339918,,,,0,0,0
1278120,Pyramid dilated deeper convlstm for video salient object detection,2018,Hongmei Song and Wenguan Wang and Sanyuan Zhao and Jianbing Shen and Kin-Man Lam,,,,715-731,,This paper proposes a fast video salient object detection model. based on a novel recurrent network architecture. named Pyramid Dilated Bidirectional ConvLSTM (PDB-ConvLSTM). A Pyramid Dilated Convolution (PDC) module is first designed for simultaneously extracting spatial features at multiple scales. These spatial features are then concatenated and fed into an extended Deeper Bidirectional ConvLSTM (DB-ConvLSTM) to learn spatiotemporal information. Forward and backward ConvLSTM units are placed in two layers and connected in a cascaded way. encouraging information flow between the bi-directional streams and leading to deeper feature extraction. We further augment DB-ConvLSTM with a PDC-like structure. by adopting several dilated DB-ConvLSTMs to extract multi-scale spatiotemporal information. Extensive experimental results show that our method outperforms previous video saliency models in a large margin. with a real-time speed of 20 fps on a single GPU. With unsupervised video object segmentation as an example application. the proposed model (with a CRF-based post-process) achieves state-of-the-art results on two popular benchmarks. well demonstrating its superior performance and high applicability.,True,6yK7bewAAAAJ:-DxkuPiZhfEC,200,http://openaccess.thecvf.com/content_ECCV_2018/html/Hongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.html,4923326738440851048,/scholar?cites=4923326738440851048,,,http://openaccess.thecvf.com/content_ECCV_2018/papers/Hongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.pdf,0,0,0
1278121,Face recognition under varying illumination based on a 2D face shape model,2005,Xudong Xie and Kin-Man Lam,38,Pattern Recognition,2,221-230,Pergamon,This paper proposes a novel illumination compensation algorithm. which can compensate for the uneven illuminations on human faces and reconstruct face images in normal lighting conditions. A simple yet effective local contrast enhancement method. namely block-based histogram equalization (BHE). is first proposed. The resulting image processed using BHE is then compared with the original face image processed using histogram equalization (HE) to estimate the category of its light source. In our scheme. we divide the light source for a human face into 65 categories. Based on the category identified. a corresponding lighting compensation model is used to reconstruct an image that will visually be under normal illumination. In order to eliminate the influence of uneven illumination while retaining the shape information about a human face. a 2D face shape model is used. Experimental results show that. with the …,True,6yK7bewAAAAJ:_xSYboBqXhAC,199,https://www.sciencedirect.com/science/article/pii/S0031320304002754,11109361932253386361,/scholar?cites=11109361932253386361,,,,0,0,0
1278122,Extraction of the Euclidean skeleton based on a connectivity criterion,2003,Wai-Pak Choi and Kin-Man Lam and Wan-Chi Siu,36,Pattern Recognition,3,721-729,Pergamon,The skeleton is essential for general shape representation. The commonly required properties of a skeletonization algorithm are that the extracted skeleton should be accurate; robust to noise. position and rotation; able to reconstruct the original object; and able to produce a connected skeleton in order to preserve its topological and hierarchical properties. However. the use of a discrete image presents a lot of problems that may influence the extraction of the skeleton. Moreover. most of the methods are memory-intensive and computationally intensive. and require a complex data structure.In this paper. we propose a fast. efficient and accurate skeletonization method for the extraction of a well-connected Euclidean skeleton based on a signed sequential Euclidean distance map. A connectivity criterion is proposed. which can be used to determine whether a given pixel is a skeleton point independently. The criterion …,True,6yK7bewAAAAJ:CHSYGLWDkRkC,185,https://www.sciencedirect.com/science/article/pii/S0031320302000985,3379556933354394536,/scholar?cites=3379556933354394536,,,,0,0,0
1278123,Gabor-based kernel PCA with doubly nonlinear mapping for face recognition with a single face image,2006,Xudong Xie and Kin-Man Lam,15,IEEE Transactions on Image Processing,9,2481-2492,IEEE,In this paper. a novel Gabor-based kernel principal component analysis (PCA) with doubly nonlinear mapping is proposed for human face recognition. In our approach. the Gabor wavelets are used to extract facial features. then a doubly nonlinear mapping kernel PCA (DKPCA) is proposed to perform feature transformation and face recognition. The conventional kernel PCA nonlinearly maps an input image into a high-dimensional feature space in order to make the mapped features linearly separable. However. this method does not consider the structural characteristics of the face images. and it is difficult to determine which nonlinear mapping is more effective for face recognition. In this paper. a new method of nonlinear mapping. which is performed in the original feature space. is defined. The proposed nonlinear mapping not only considers the statistical property of the input features. but also adopts an …,True,6yK7bewAAAAJ:xtRiw3GOFMkC,172,https://ieeexplore.ieee.org/abstract/document/1673431/,8301723310149619127,/scholar?cites=8301723310149619127,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.726&rep=rep1&type=pdf,0,0,0
1278124,Optimal sampling of Gabor features for face recognition,2004,Dang-Hui Liu and Kin-Man Lam and Lan-Sun Shen,25,Pattern Recognition Letters,2,267-276,North-Holland,The Gabor feature is effective for facial image representation. while linear discriminant analysis (LDA) can extract the most discriminant information from the Gabor feature for face recognition. In practice. the dimension of a Gabor feature vector is so high that the computation and memory requirements are prohibitively large. To reduce the dimension. one simple scheme is to extract the Gabor feature at sub-sampled positions. usually in a regular grid. in a face region. However. this scheme is not effective enough and degrades the recognition performance. In this paper. we propose a method to determine the optimal position for extracting the Gabor feature such that the number of feature points is as small as possible while the representation capability of the points is as high as possible. The sub-sampled positions of the feature points are determined by a mask generated from a set of training images by means of …,True,6yK7bewAAAAJ:abG-DnoFyZgC,163,https://www.sciencedirect.com/science/article/pii/S0167865503002290,7111534662967313906,/scholar?cites=7111534662967313906,,,https://www.academia.edu/download/50568402/j.patrec.2003.10.00720161127-20781-1fn5ujf.pdf,0,0,0
1278125,Illumination invariant face recognition,2005,Dang-Hui Liu and Kin-Man Lam and Lan-Sun Shen,38,Pattern Recognition,10,1705-1716,Pergamon,The appearance of a face will vary drastically when the illumination changes. Variations in lighting conditions make face recognition an even more challenging and difficult task. In this paper. we propose a novel approach to handle the illumination problem. Our method can restore a face image captured under arbitrary lighting conditions to one with frontal illumination by using a ratio-image between the face image and a reference face image. both of which are blurred by a Gaussian filter. An iterative algorithm is then used to update the reference image. which is reconstructed from the restored image by means of principal component analysis (PCA). in order to obtain a visually better restored image. Image processing techniques are also used to improve the quality of the restored image. To evaluate the performance of our algorithm. restored images with frontal illumination are used for face recognition by means of …,True,6yK7bewAAAAJ:nb7KW1ujOQ8C,135,https://www.sciencedirect.com/science/article/pii/S0031320305001378,1001849340488255547,/scholar?cites=1001849340488255547,,,https://www.academia.edu/download/46828187/j.patcog.2005.03.00920160627-24012-ykepbr.pdf,0,0,0
1278126,Locating and extracting the eye in human face images,1996,Kin-Man Lam and Hong Yan,29,Pattern recognition,5,771-779,Pergamon,Facial feature extraction is an important step in automated visual interpretation and human face recognition. Among the facial features. the eye plays the most important part in the recognition process. The deformable template can be used in extracting the eye boundaries. However. the weaknesses of the deformable template are that the processing time is lengthy and that its success relies on the initial position of the template. In this paper. the head boundary is first located in a head-and-shoulders image. The approximate positions of the eyes are estimated by means of average anthropometric measures. Corners. the salient features of the eyes. are detected and used to set the initial parameters of the eye templates. The corner detection scheme introduced in this paper can provide accurate information about the corners. Based on the corner positions. we can accurately locate the templates in relation to the eye …,True,c3XRJtEAAAAJ:IjCSPb-OGe4C,495,https://www.sciencedirect.com/science/article/pii/0031320395001190,683974882842445776,/scholar?cites=683974882842445776,,,http://www.eie.polyu.edu.hk/~enkmlam/Papers/PR96.pdf,0,0,0
1278127,An analytic-to-holistic approach for face recognition based on a single frontal view,1998,Kin-Man Lam and Hong Yan,20,IEEE Transactions on pattern analysis and machine intelligence,7,673-686,IEEE,We propose an analytic-to-holistic approach which can identify faces at different perspective variations. The database for the test consists of 40 frontal-view faces. The first step is to locate 15 feature points on a face. A head model is proposed. and the rotation of the face can be estimated using geometrical measurements. The positions of the feature points are adjusted so that their corresponding positions for the frontal view are approximated. These feature points are then compared with the feature points of the faces in a database using a similarity transform. In the second step. we set up windows for the eyes. nose. and mouth. These feature windows are compared with those in the database by correlation. Results show that this approach can achieve a similar level of performance from different viewing directions of a face. Under different perspective variations. the overall recognition rates are over 84 percent and …,True,c3XRJtEAAAAJ:zYLM7Y9cAGgC,357,https://ieeexplore.ieee.org/abstract/document/689299/,14453716877146759379,/scholar?cites=14453716877146759379,,,,0,0,0
1278128,A level set approach to image segmentation with intensity inhomogeneity,2015,Kaihua Zhang and Lei Zhang and Kin-Man Lam and David Zhang,46,IEEE transactions on cybernetics,2,546-557,IEEE,It is often a difficult task to accurately segment images with intensity inhomogeneity. because most of representative algorithms are region-based that depend on intensity homogeneity of the interested object. In this paper. we present a novel level set method for image segmentation in the presence of intensity inhomogeneity. The inhomogeneous objects are modeled as Gaussian distributions of different means and variances in which a sliding window is used to map the original image into another domain. where the intensity distribution of each object is still Gaussian but better separated. The means of the Gaussian distributions in the transformed domain can be adaptively estimated by multiplying a bias field with the original signal within the window. A maximum likelihood energy functional is then defined on the whole image region. which combines the bias field. the level set function. and the piecewise constant …,True,c3XRJtEAAAAJ:vV6vV6tmYwMC,300,https://ieeexplore.ieee.org/abstract/document/7059203/,18227489507458213261,/scholar?cites=18227489507458213261,,,http://kaihuazhang.net/J_papers/tcyb2014b.pdf,0,0,0
1278129,An efficient algorithm for human face detection and facial feature extraction under different conditions,2001,Kwok-Wai Wong and Kin-Man Lam and Wan-Chi Siu,34,Pattern Recognition,10,1993-2004,Pergamon,In this paper. an efficient algorithm for human face detection and facial feature extraction is devised. Firstly. the location of the face regions is detected using the genetic algorithm and the eigenface technique. The genetic algorithm is applied to search for possible face regions in an image. while the eigenface technique is used to determine the fitness of the regions. As the genetic algorithm is computationally intensive. the searching space is reduced and limited to the eye regions so that the required timing is greatly reduced. Possible face candidates are then further verified by measuring their symmetries and determining the existence of the different facial features. Furthermore. in order to improve the level of detection reliability in our approach. the lighting effect and orientation of the faces are considered and solved.,True,c3XRJtEAAAAJ:W7OEmFMy1HYC,225,https://www.sciencedirect.com/science/article/pii/S0031320300001345,15570086210013768464,/scholar?cites=15570086210013768464,,,https://www.academia.edu/download/31770909/PR01b.pdf,0,0,0
1278130,An efficient illumination normalization method for face recognition,2006,Xudong Xie and Kin-Man Lam,27,Pattern Recognition Letters,6,609-617,North-Holland,In this paper. an efficient representation method insensitive to varying illumination is proposed for human face recognition. Theoretical analysis based on the human face model and the illumination model shows that the effects of varying lighting on a human face image can be modeled by a sequence of multiplicative and additive noises. Instead of computing these noises. which is very difficult for real applications. we aim to reduce or even remove their effect. In our method. a local normalization technique is applied to an image. which can effectively and efficiently eliminate the effect of uneven illuminations while keeping the local statistical properties of the processed image the same as in the corresponding image under normal lighting condition. After processing. the image under varying illumination will have similar pixel values to the corresponding image that is under normal lighting condition. Then. the processed …,True,c3XRJtEAAAAJ:Tyk-4Ss8FVUC,209,https://www.sciencedirect.com/science/article/pii/S0167865505002795,1658934970340339918,/scholar?cites=1658934970340339918,,,,0,0,0
1278131,Pyramid dilated deeper convlstm for video salient object detection,2018,Hongmei Song and Wenguan Wang and Sanyuan Zhao and Jianbing Shen and Kin-Man Lam,,,,715-731,,This paper proposes a fast video salient object detection model. based on a novel recurrent network architecture. named Pyramid Dilated Bidirectional ConvLSTM (PDB-ConvLSTM). A Pyramid Dilated Convolution (PDC) module is first designed for simultaneously extracting spatial features at multiple scales. These spatial features are then concatenated and fed into an extended Deeper Bidirectional ConvLSTM (DB-ConvLSTM) to learn spatiotemporal information. Forward and backward ConvLSTM units are placed in two layers and connected in a cascaded way. encouraging information flow between the bi-directional streams and leading to deeper feature extraction. We further augment DB-ConvLSTM with a PDC-like structure. by adopting several dilated DB-ConvLSTMs to extract multi-scale spatiotemporal information. Extensive experimental results show that our method outperforms previous video saliency models in a large margin. with a real-time speed of 20 fps on a single GPU. With unsupervised video object segmentation as an example application. the proposed model (with a CRF-based post-process) achieves state-of-the-art results on two popular benchmarks. well demonstrating its superior performance and high applicability.,True,c3XRJtEAAAAJ:U4n9YNQMCAIC,200,http://openaccess.thecvf.com/content_ECCV_2018/html/Hongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.html,4923326738440851048,/scholar?cites=4923326738440851048,,,http://openaccess.thecvf.com/content_ECCV_2018/papers/Hongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.pdf,0,0,0
1278132,Face recognition under varying illumination based on a 2D face shape model,2005,Xudong Xie and Kin-Man Lam,38,Pattern Recognition,2,221-230,Pergamon,This paper proposes a novel illumination compensation algorithm. which can compensate for the uneven illuminations on human faces and reconstruct face images in normal lighting conditions. A simple yet effective local contrast enhancement method. namely block-based histogram equalization (BHE). is first proposed. The resulting image processed using BHE is then compared with the original face image processed using histogram equalization (HE) to estimate the category of its light source. In our scheme. we divide the light source for a human face into 65 categories. Based on the category identified. a corresponding lighting compensation model is used to reconstruct an image that will visually be under normal illumination. In order to eliminate the influence of uneven illumination while retaining the shape information about a human face. a 2D face shape model is used. Experimental results show that. with the …,True,c3XRJtEAAAAJ:Y0pCki6q_DkC,199,https://www.sciencedirect.com/science/article/pii/S0031320304002754,11109361932253386361,/scholar?cites=11109361932253386361,,,,0,0,0
1278133,Extraction of the Euclidean skeleton based on a connectivity criterion,2003,Wai-Pak Choi and Kin-Man Lam and Wan-Chi Siu,36,Pattern Recognition,3,721-729,Pergamon,The skeleton is essential for general shape representation. The commonly required properties of a skeletonization algorithm are that the extracted skeleton should be accurate; robust to noise. position and rotation; able to reconstruct the original object; and able to produce a connected skeleton in order to preserve its topological and hierarchical properties. However. the use of a discrete image presents a lot of problems that may influence the extraction of the skeleton. Moreover. most of the methods are memory-intensive and computationally intensive. and require a complex data structure.In this paper. we propose a fast. efficient and accurate skeletonization method for the extraction of a well-connected Euclidean skeleton based on a signed sequential Euclidean distance map. A connectivity criterion is proposed. which can be used to determine whether a given pixel is a skeleton point independently. The criterion …,True,c3XRJtEAAAAJ:eQOLeE2rZwMC,185,https://www.sciencedirect.com/science/article/pii/S0031320302000985,3379556933354394536,/scholar?cites=3379556933354394536,,,,0,0,0
1278134,Gabor-based kernel PCA with doubly nonlinear mapping for face recognition with a single face image,2006,Xudong Xie and Kin-Man Lam,15,IEEE Transactions on Image Processing,9,2481-2492,IEEE,In this paper. a novel Gabor-based kernel principal component analysis (PCA) with doubly nonlinear mapping is proposed for human face recognition. In our approach. the Gabor wavelets are used to extract facial features. then a doubly nonlinear mapping kernel PCA (DKPCA) is proposed to perform feature transformation and face recognition. The conventional kernel PCA nonlinearly maps an input image into a high-dimensional feature space in order to make the mapped features linearly separable. However. this method does not consider the structural characteristics of the face images. and it is difficult to determine which nonlinear mapping is more effective for face recognition. In this paper. a new method of nonlinear mapping. which is performed in the original feature space. is defined. The proposed nonlinear mapping not only considers the statistical property of the input features. but also adopts an …,True,c3XRJtEAAAAJ:WF5omc3nYNoC,172,https://ieeexplore.ieee.org/abstract/document/1673431/,8301723310149619127,/scholar?cites=8301723310149619127,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.726&rep=rep1&type=pdf,0,0,0
1278135,Optimal sampling of Gabor features for face recognition,2004,Dang-Hui Liu and Kin-Man Lam and Lan-Sun Shen,25,Pattern Recognition Letters,2,267-276,North-Holland,The Gabor feature is effective for facial image representation. while linear discriminant analysis (LDA) can extract the most discriminant information from the Gabor feature for face recognition. In practice. the dimension of a Gabor feature vector is so high that the computation and memory requirements are prohibitively large. To reduce the dimension. one simple scheme is to extract the Gabor feature at sub-sampled positions. usually in a regular grid. in a face region. However. this scheme is not effective enough and degrades the recognition performance. In this paper. we propose a method to determine the optimal position for extracting the Gabor feature such that the number of feature points is as small as possible while the representation capability of the points is as high as possible. The sub-sampled positions of the feature points are determined by a mask generated from a set of training images by means of …,True,c3XRJtEAAAAJ:YsMSGLbcyi4C,163,https://www.sciencedirect.com/science/article/pii/S0167865503002290,7111534662967313906,/scholar?cites=7111534662967313906,,,https://www.academia.edu/download/50568402/j.patrec.2003.10.00720161127-20781-1fn5ujf.pdf,0,0,0
1278136,Illumination invariant face recognition,2005,Dang-Hui Liu and Kin-Man Lam and Lan-Sun Shen,38,Pattern Recognition,10,1705-1716,Pergamon,The appearance of a face will vary drastically when the illumination changes. Variations in lighting conditions make face recognition an even more challenging and difficult task. In this paper. we propose a novel approach to handle the illumination problem. Our method can restore a face image captured under arbitrary lighting conditions to one with frontal illumination by using a ratio-image between the face image and a reference face image. both of which are blurred by a Gaussian filter. An iterative algorithm is then used to update the reference image. which is reconstructed from the restored image by means of principal component analysis (PCA). in order to obtain a visually better restored image. Image processing techniques are also used to improve the quality of the restored image. To evaluate the performance of our algorithm. restored images with frontal illumination are used for face recognition by means of …,True,c3XRJtEAAAAJ:LkGwnXOMwfcC,135,https://www.sciencedirect.com/science/article/pii/S0031320305001378,1001849340488255547,/scholar?cites=1001849340488255547,,,https://www.academia.edu/download/46828187/j.patcog.2005.03.00920160627-24012-ykepbr.pdf,0,0,0
1278137,Sparse directional image representations using the discrete shearlet transform,2008,Glenn Easley and Demetrio Labate and Wang-Q Lim,25,Applied and Computational Harmonic Analysis,1,25-46,Academic Press,In spite of their remarkable success in signal processing applications. it is now widely acknowledged that traditional wavelets are not very effective in dealing multidimensional signals containing distributed discontinuities such as edges. To overcome this limitation. one has to use basis elements with much higher directional sensitivity and of various shapes. to be able to capture the intrinsic geometrical features of multidimensional phenomena. This paper introduces a new discrete multiscale directional representation called the discrete shearlet transform. This approach. which is based on the shearlet transform. combines the power of multiscale methods with a unique ability to capture the geometry of multidimensional data and is optimally efficient in representing images containing edges. We describe two different methods of implementing the shearlet transform. The numerical experiments presented in this paper …,True,pmC7Ph4AAAAJ:u-x6o8ySG0sC,1099,https://www.sciencedirect.com/science/article/pii/S1063520307000875,16616711504875438698,/scholar?cites=16616711504875438698,,,https://www.sciencedirect.com/science/article/pii/S1063520307000875/pdf?md5=d2d16dc56e0f96d0e802510a67e8c89e&pid=1-s2.0-S1063520307000875-main.pdf,0,0,0
1278138,Optimally sparse multidimensional representation using shearlets,2007,Kanghui Guo and Demetrio Labate,39,SIAM journal on mathematical analysis,1,298-318,Society for Industrial and Applied Mathematics,In this paper we show that shearlets. an affine-like system of functions recently introduced by the authors and their collaborators. are essentially optimal in representing 2-dimensional functions f which are  except for discontinuities along  curves. More specifically. if  is the N-term reconstruction of f obtained by using the N largest coefficients in the shearlet representation. then the asymptotic approximation error decays as $\norm{f-f_N^S}_2^2 \asymp N^{-2} (\log N)^3. N \to \infty.$ which is essentially optimal. and greatly outperforms the corresponding asymptotic approximation rate  associated with wavelet approximations. Unlike curvelets. which have similar sparsity properties. shearlets form an affine-like system and have a simpler mathematical structure. In fact. the elements of this system form a Parseval frame and are generated by applying dilations. shear transformations. and translations to a single …,True,pmC7Ph4AAAAJ:u5HHmVD_uO8C,824,https://epubs.siam.org/doi/abs/10.1137/060649781,2286566080051489335,/scholar?cites=2286566080051489335,,,https://bearworks.missouristate.edu/cgi/viewcontent.cgi?article=1556&context=articles-cnas,0,0,0
1278139,Sparse multidimensional representation using shearlets,2005,Demetrio Labate and Wang-Q Lim and Gitta Kutyniok and Guido Weiss,5914,,,59140U,International Society for Optics and Photonics,In this paper we describe a new class of multidimensional representation systems. called shearlets. They are obtained by applying the actions of dilation. shear transformation and translation to a fixed function. and exhibit the geometric and mathematical properties. e.g.. directionality. elongated shapes. scales. oscillations. recently advocated by many authors for sparse image processing applications. These systems can be studied within the framework of a generalized multiresolution analysis. This approach leads to a recursive algorithm for the implementation of these systems. that generalizes the classical cascade algorithm.,True,pmC7Ph4AAAAJ:d1gkVwhDpl0C,562,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5914/59140U/Sparse-multidimensional-representation-using-shearlets/10.1117/12.613494.short,5424732472786452818,/scholar?cites=5424732472786452818,,,https://www.researchgate.net/profile/Wang-Q_Lim/publication/234020665_Sparse_multidimensional_representation_using_shearlets/links/00b7d52dfc46f4af45000000/Sparse-multidimensional-representation-using-shearlets.pdf,0,0,0
1278140,A shearlet approach to edge analysis and detection,2009,Sheng Yi and Demetrio Labate and Glenn R Easley and Hamid Krim,18,IEEE Transactions on Image Processing,5,929-941,IEEE,It is well known that the wavelet transform provides a very effective framework for analysis of multiscale edges. In this paper. we propose a novel approach based on the shearlet transform: a multiscale directional transform with a greater ability to localize distributed discontinuities such as edges. Indeed. unlike traditional wavelets. shearlets are theoretically optimal in representing images with edges and. in particular. have the ability to fully capture directional and other geometrical features. Numerical examples demonstrate that the shearlet approach is highly effective at detecting both the location and orientation of edges. and outperforms methods based on wavelets as well as other standard methods. Furthermore. the shearlet approach is useful to design simple and effective algorithms for the detection of corners and junctions.,True,pmC7Ph4AAAAJ:qjMakFHDy7sC,402,https://ieeexplore.ieee.org/abstract/document/4804681/,16288358276394340193,/scholar?cites=16288358276394340193,,,https://www.researchgate.net/profile/Hamid_Krim/publication/24248169_A_Shearlet_Approach_to_Edge_Analysis_and_Detection/links/02e7e517d7ff81bd70000000/A-Shearlet-Approach-to-Edge-Analysis-and-Detection.pdf,0,0,0
1278141,Sparse multidimensional representations using anisotropic dilation and shear operators,2006,Kanghui Guo and Gitta Kutyniok and Demetrio Labate,,,,189-201,Wavelets and Splines (Athens. GA. 2005). Nashboro Press. Nashville. TN,Recent advances in applied mathematics and signal processing have shown that. in order to obtain sparse representations of multi-dimensional functions and signals. one has to use representation elements distributed not only at various scales and locations–as in classical wavelet theory–but also at various directions. In this paper. we show that we obtain a construction having exactly these properties by using the framework of affine systems. The representation elements that we obtain are generated by translations. dilations. and shear transformations of a single mother function. and are called shearlets. The shearlets provide optimally sparse representations for 2-D functions that are smooth away from discontinuities along curves. Another benefit of this approach is that. thanks to their mathematical structure. these systems provide a Multiresolution analysis similar to the one associated with classical wavelets. which is very useful for the development of fast algorithmic implementations.,True,pmC7Ph4AAAAJ:UeHWp8X0CEIC,384,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.231.6327&rep=rep1&type=pdf,2192329464960537249,/scholar?cites=2192329464960537249,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.231.6327&rep=rep1&type=pdf,0,0,0
1278142,Shearlets: Multiscale analysis for multivariate data,2012,Gitta Kutyniok and Demetrio Labate,,,,,Springer Science & Business Media,Over the last 20 years. multiscale methods and wavelets have revolutionized the field of applied mathematics by providing an efficient means of encoding isotropic phenomena. Directional multiscale systems. particularly shearlets. are now having the same dramatic impact on the encoding of multidimensional signals. Since its introduction about five years ago. the theory of shearlets has rapidly developed and gained wide recognition as the superior way of achieving a truly unified treatment in both a continuous and a digital setting. By now. it has reached maturity as a research field. with rich mathematics. efficient numerical methods. and various important applications.,True,pmC7Ph4AAAAJ:eq2jaN3J8jMC,372,http://books.google.com/books?hl=en&lr=&id=HpIlSQj7H2cC&oi=fnd&pg=PR3&dq=info:oY1V6lMYOD0J:scholar.google.com&ots=HwROb1rMcK&sig=icvgP9d46XRTPnaxXZEEUezRMc8,4411302583702228385,/scholar?cites=4411302583702228385,,,,0,0,0
1278143,Resolution of the wavefront set using continuous shearlets,2009,Gitta Kutyniok and Demetrio Labate,361,Transactions of the American Mathematical Society,5,2719-2754,,It is known that the Continuous Wavelet Transform of a distribution  decays rapidly near the points where  is smooth. while it decays slowly near the irregular points. This property allows the identification of the singular support of . However. the Continuous Wavelet Transform is unable to describe the geometry of the set of singularities of  and. in particular. identify the wavefront set of a distribution. In this paper. we employ the same framework of affine systems which is at the core of the construction of the wavelet transform to introduce the Continuous Shearlet Transform. This is defined by . where the analyzing elements  are dilated and translated copies of a single generating function . The dilation matrices form a two-parameter matrix group consisting of products of parabolic scaling and shear matrices. We show that the elements  form a system of smooth functions at continuous scales  …,True,pmC7Ph4AAAAJ:9yKSN-GCB0IC,301,https://www.ams.org/tran/2009-361-05/S0002-9947-08-04700-4/,70237497280334482,/scholar?cites=70237497280334482,,,https://www.ams.org/journals/tran/2009-361-05/S0002-9947-08-04700-4/S0002-9947-08-04700-4.pdf,0,0,0
1278144,Wavelets with composite dilations and their MRA properties,2006,Kanghui Guo and Demetrio Labate and Wang-Q Lim and Guido Weiss and Edward Wilson,20,Applied and Computational Harmonic Analysis,2,202-236,Academic Press,Affine systems are reproducing systems of the form A C={D c T k ψ ℓ: 1⩽ ℓ⩽ L. k∈ Z n. c∈ C}. which arise by applying lattice translation operators T k to one or more generators ψ ℓ in L 2 (R n). followed by the application of dilation operators D c. associated with a countable set C of invertible matrices. In the wavelet literature. C is usually taken to be the group consisting of all integer powers of a fixed expanding matrix. In this paper. we develop the properties of much more general systems. for which C={c= a b: a∈ A. b∈ B} where A and B are not necessarily commuting matrix sets. C need not contain a single expanding matrix. Nonetheless. for many choices of A and B. there are wavelet systems with multiresolution properties very similar to those of classical dyadic wavelets. Typically. A expands or contracts only in certain directions. while B acts by volume-preserving maps in transverse directions. Then the resulting …,True,pmC7Ph4AAAAJ:2osOgNQ5qMEC,266,https://www.sciencedirect.com/science/article/pii/S1063520305000680,4708812154896205089,/scholar?cites=4708812154896205089,,,https://www.sciencedirect.com/science/article/pii/S1063520305000680/pdf?md5=70445cbd5b1ab6c99d05ae898f5ee7e7&pid=1-s2.0-S1063520305000680-main.pdf,0,0,0
1278145,Shearlet-based total variation diffusion for denoising,2008,Glenn R Easley and Demetrio Labate and Flavia Colonna,18,IEEE Transactions on Image processing,2,260-268,IEEE,We propose a shearlet formulation of the total variation (TV) method for denoising images. Shearlets have been mathematically proven to represent distributed discontinuities such as edges better than traditional wavelets and are a suitable tool for edge characterization. Common approaches in combining wavelet-like representations such as curvelets with TV or diffusion methods aim at reducing Gibbs-type artifacts after obtaining a nearly optimal estimate. We show that it is possible to obtain much better estimates from a shearlet representation by constraining the residual coefficients using a projected adaptive total variation scheme in the shearlet domain. We also analyze the performance of a shearlet-based diffusion method. Numerical examples demonstrate that these schemes are highly effective at denoising complex images and outperform a related method based on the use of the curvelet transform …,True,pmC7Ph4AAAAJ:Tyk-4Ss8FVUC,259,https://ieeexplore.ieee.org/abstract/document/4717218/,2098935433884579548,/scholar?cites=2098935433884579548,,,https://www.researchgate.net/profile/Glenn_Easley/publication/23676500_Shearlet-Based_Total_Variation_Diffusion_for_Denoising/links/0deec528a43ea6e6eb000000.pdf,0,0,0
1278146,A unified characterization of reproducing systems generated by a finite family. II,2002,Eugenio Hernández and Demetrio Labate and Guido Weiss,12,The Journal of Geometric Analysis,4,615-662,Springer-Verlag,By a “reproducing” method forH =L 2(ℝ n ) we mean the use of two countable families {e α : α ∈A}. {f α : α ∈A}. inH. so that the first “analyzes” a function h ∈H by forming the inner products {<h.e α >: α ∈A} and the second “reconstructs” h from this information:h = Σα∈A <h.e α >:f α.A variety of such systems have been used successfully in both pure and applied mathematics. They have the following feature in common: they are generated by a single or a finite collection of functions by applying to the generators two countable families of operators that consist of two of the following three actions: dilations. modulations. and translations. The Gabor systems. for example. involve a countable collection of modulations and translations; the affine systems (that produce a variety of wavelets) involve translations …,True,pmC7Ph4AAAAJ:IjCSPb-OGe4C,168,https://link.springer.com/article/10.1007/BF02930656,7562658944718527111,/scholar?cites=7562658944718527111,,,https://www.researchgate.net/profile/Eugenio_Hernandez3/publication/225456665_A_unified_characterization_of_reproducing_systems_generated_by_a_finite_family_II/links/0912f50f7d1230ea60000000/A-unified-characterization-of-reproducing-systems-generated-by-a-finite-family-II.pdf,0,0,0
1278147,Edge analysis and identification using the continuous shearlet transform,2009,Kanghui Guo and Demetrio Labate and Wang-Q Lim,27,Applied and Computational Harmonic Analysis,1,24-46,Academic Press,It is well known that the continuous wavelet transform has the ability to identify the set of singularities of a function or distribution f. It was recently shown that certain multidimensional generalizations of the wavelet transform are useful to capture additional information about the geometry of the singularities of f. In this paper. we consider the continuous shearlet transform. which is the mapping f∈ L 2 (R 2)→ SH ψ f (a. s. t)=< f. ψ ast>. where the analyzing elements ψ ast form an affine system of well localized functions at continuous scales a> 0. locations t∈ R 2. and oriented along lines of slope s∈ R in the frequency domain. We show that the continuous shearlet transform allows one to exactly identify the location and orientation of the edges of planar objects. In particular. if f=∑ n= 1 N f n χ Ω n where the functions f n are smooth and the sets Ω n have smooth boundaries. then one can use the asymptotic decay of SH ψ …,True,pmC7Ph4AAAAJ:Y0pCki6q_DkC,161,https://www.sciencedirect.com/science/article/pii/S1063520308001152,15194092542093722308,/scholar?cites=15194092542093722308,,,https://www.sciencedirect.com/science/article/pii/S1063520308001152/pdf?md5=4c403d42a3ebca3918fd11de129d84d3&pid=1-s2.0-S1063520308001152-main.pdf,0,0,0
1278148,The watershed transform: Definitions. algorithms and parallelization strategies,2000,Jos BTM Roerdink and Arnold Meijster,41,,"1, 2",187-228,IOS press,The watershed transform is the method of choice for image segmentation in the field of mathematical morphology. We present a critical review of several definitions of the watershed transform and the associated sequential algorithms. and discuss various issues which often cause confusion in the literature. The need to distinguish between definition. algorithm specification and algorithm implementation is pointed out. Various examples are given which illustrate differences between watershed transforms based on different definitions and/or implementations. The second part of the paper surveys approaches for parallel implementation of sequential watershed algorithms.,True,jCFYHlkAAAAJ:u5HHmVD_uO8C,1788,https://content.iospress.com/articles/fundamenta-informaticae/fi41-1-2-07,14891000834322893736,/scholar?cites=14891000834322893736,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.3852&rep=rep1&type=pdf,0,0,0
1278149,Denoising functional MR images: a comparison of wavelet denoising and Gaussian smoothing,2004,Alle Meije Wink and Jos BTM Roerdink,23,IEEE transactions on medical imaging,3,374-387,IEEE,We present a general wavelet-based denoising scheme for functional magnetic resonance imaging (fMRI) data and compare it to Gaussian smoothing. the traditional denoising method used in fMRI analysis. One-dimensional WaveLab thresholding routines were adapted to two-dimensional (2-D) images. and applied to 2-D wavelet coefficients. To test the effect of these methods on the signal-to-noise ratio (SNR). we compared the SNR of 2-D fMRI images before and after denoising. using both Gaussian smoothing and wavelet-based methods. We simulated a fMRI series with a time signal in an active spot. and tested the methods on noisy copies of it. The denoising methods were evaluated in two ways: by the average temporal SNR inside the original activated spot. and by the shape of the spot detected by thresholding the temporal SNR maps. Denoising methods that introduce much smoothness are better suited …,True,jCFYHlkAAAAJ:u-x6o8ySG0sC,319,https://ieeexplore.ieee.org/abstract/document/1269883/,17250514174124584458,/scholar?cites=17250514174124584458,,,https://perso.telecom-paristech.fr/angelini/MIMED/papers_2010/meije_tmi_2004.pdf,0,0,0
1278150,A general algorithm for computing distance transforms in linear time,2002,Arnold Meijster and Jos BTM Roerdink and Wim H Hesselink,,,,331-340,Springer. Boston. MA,A new general algorithm for computing distance transforms of digital images is presented. The algorithm consists of two phases. Both phases consist of two scans. a forward and a backward scan. The first phase scans the image column-wise. while the second phase scans the image row-wise. Since the computation per row (column) is independent of the computation of other rows (columns). the algorithm can be easily parallelized on shared memory computers. The algorithm can be used for the computation of the exact Euclidean. Manhattan (L  1  norm). and chessboard distance (L  ∞  norm) transforms.,True,jCFYHlkAAAAJ:d1gkVwhDpl0C,309,https://link.springer.com/chapter/10.1007/0-306-47025-X_36,8232926584134730777,/scholar?cites=8232926584134730777,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.476.4863&rep=rep1&type=pdf,0,0,0
1278151,A morphological algorithm for improving radio-frequency interference detection,2012,AR Offringa and JJ Van de Gronde and Jos BTM Roerdink,539,Astronomy & Astrophysics,,A95,EDP Sciences,A technique is described that is used to improve the detection of radio-frequency interference in astronomical radio observatories. It is applied on a two-dimensional interference mask after regular detection in the time-frequency domain with existing techniques. The scale-invariant rank (SIR) operator is defined. which is a one-dimensional mathematical morphology technique that can be used to find adjacent intervals in the time or frequency domain that are likely to be affected by RFI. The technique might also be applicable in other areas in which morphological scale-invariant behaviour is desired. such as source detection. A new algorithm is described. that is shown to perform quite well. has linear time complexity and is fast enough to be applied in modern high resolution observatories. It is used in the default pipeline of the LOFAR observatory.,True,jCFYHlkAAAAJ:uJ-U7cs_P_0C,295,https://www.aanda.org/articles/aa/abs/2012/03/aa18497-11/aa18497-11.html,5382397803358719687,/scholar?cites=5382397803358719687,,,https://www.aanda.org/articles/aa/pdf/2012/03/aa18497-11.pdf,0,0,0
1278152,Connected shape-size pattern spectra for rotation and scale-invariant classification of gray-scale images,2007,Erik R Urbach and Jos BTM Roerdink and Michael HF Wilkinson,29,IEEE Transactions on Pattern Analysis and Machine Intelligence,2,272-285,IEEE,In this paper. we describe a multiscale and multishape morphological method for pattern-based analysis and classification of gray-scale images using connected operators. Compared with existing methods. which use structuring elements. our method has three advantages. First. in our method. the time needed for computing pattern spectra does not depend on the number of scales or shapes used. i.e.. the computation time is independent of the dimensions of the pattern spectrum. Second. size and strict shape attributes can be computed. which we use for the construction of joint 2D shape-size pattern spectra. Third. our method is significantly less sensitive to noise and is rotation-invariant. Although rotation invariance can also be approximated by methods using structuring elements at different angles. this tends to be computationally intensive. The classification performance of these methods is discussed using four …,True,jCFYHlkAAAAJ:9yKSN-GCB0IC,220,https://ieeexplore.ieee.org/abstract/document/4042702/,4876999781343114890,/scholar?cites=4876999781343114890,,,,0,0,0
1278153,Changes in cortical grey matter density associated with long-standing retinal visual field defects,2009,Christine C Boucard and Aditya T Hernowo and R Paul Maguire and Nomdo M Jansonius and Jos BTM Roerdink and Johanna MM Hooymans and Frans W Cornelissen,132,Brain,7,1898-1906,Oxford University Press,Retinal lesions caused by eye diseases such as glaucoma and age-related macular degeneration can. over time. eliminate stimulation of parts of the visual cortex. This could lead to degeneration of inactive cortical neuronal tissue. but this has not been established in humans. Here. we used magnetic resonance imaging to assess the effects of prolonged sensory deprivation in human visual cortex. High-resolution anatomical magnetic resonance images were obtained in subjects with foveal (age-related macular degeneration) and peripheral (glaucoma) retinal lesions as well as age-matched controls. Comparison of grey matter between patient and control groups revealed density reductions in the approximate retinal lesion projection zones in visual cortex. This indicates that long-term cortical deprivation. due to retinal lesions acquired later in life. is associated with retinotopic-specific neuronal degeneration of …,True,jCFYHlkAAAAJ:hqOjcs7Dif8C,181,https://academic.oup.com/brain/article-abstract/132/7/1898/327128,7646984687288833044,/scholar?cites=7646984687288833044,,,https://academic.oup.com/brain/article/132/7/1898/327128,0,0,0
1278154,Depth-dependent halos: Illustrative rendering of dense line data,2009,Maarten H Everts and Henk Bekker and Jos BTM Roerdink and Tobias Isenberg,15,IEEE Transactions on Visualization and Computer Graphics,6,1299-1306,IEEE,We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover. the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception. extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used. in particular. for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.,True,jCFYHlkAAAAJ:roLk4NBRz8UC,164,https://ieeexplore.ieee.org/abstract/document/5290742/,12626457960173289032,/scholar?cites=12626457960173289032,,,https://www.rug.nl/research/portal/files/2696229/2009IEEETVCGEverts.pdf,0,0,0
1278155,The influence of mental fatigue and motivation on neural network dynamics; an EEG coherence study,2009,Monicque M Lorist and Eniko Bezdan and Michael ten Caat and Mark M Span and Jos BTM Roerdink and Natasha M Maurits,1270,Brain research,,95-106,Elsevier,The purpose of the present study is to examine the effects of mental fatigue and motivation on neural network dynamics activated during task switching. Mental fatigue was induced by 2 h of continuous performance; after which subjects were motivated by using social comparison and monetary reward as motivating factors to perform well for an additional 20 min. EEG coherence was used as a measure of synchronization of brain activity. Electrodes of interest were identified using a data-driven pre-processing method (ten Caat. M.. Lorist. M.M.. Bezdan. E.. Roerdink. J.B.T.M.. Maurits. N.M.. 2008a. High-density EEG coherence analysis using functional units applied to mental fatigue. J. Neurosci. Meth. 171. 271–278; ten Caat. M.. Maurits. N.M. and Roerdink. J.B.T.M.. 2008b. Data-driven visualization and group analysis of multichannel EEG coherence with functional units. IEEE T. Vis. Comp. Gr. 14. 756–771 …,True,jCFYHlkAAAAJ:7PzlFSSx8tAC,159,https://www.sciencedirect.com/science/article/pii/S0006899309005162,4080865302073368314,/scholar?cites=4080865302073368314,,,http://www.cs.rug.nl/~roe/publications/Lorist_2009,0,0,0
1278156,A review of wavelet denoising in MRI and ultrasound brain imaging,2006,Aleksandra Pizurica and Alle M Wink and Ewout Vansteenkiste and Wilfried Philips and Jos BTM Roerdink,2,Current medical imaging reviews,2,247-260,Bentham Science Publishers,There is a growing interest in using multiresolution noise filters in a variety of medical imaging applications. We review recent wavelet denoising techniques for medical ultrasound and for magnetic resonance images and discuss some of their potential applications in the clinical investigations of the brain. Our goal is to present and evaluate noise suppression methods based on both image processing and clinical expertise. We analyze two types of filters for magnetic resonance images (MRI): noise suppression in magnitude MRI images and denoising blood oxygen level-dependent (BOLD) response in functional MRI images (fMRI). The noise distribution in magnitude MRI images is Rician. while the noise distribution in BOLD images has been recently shown to follow a Gaussian model well. We evaluate different methods based on signal to noise ratio improvement and based on the preservation of the shape of the …,True,jCFYHlkAAAAJ:t7zJ5fGR-2UC,154,https://www.ingentaconnect.com/content/ben/cmir/2006/00000002/00000002/art00008,6349939042655805198,/scholar?cites=6349939042655805198,,,https://core.ac.uk/download/pdf/232378951.pdf,0,0,0
1278157,CPM: A deformable model for shape recovery and segmentation based on charged particles,2004,Andrei C Jalba and Michael HF Wilkinson and Jos BTM Roerdink,26,IEEE Transactions on Pattern Analysis and Machine Intelligence,10,1320-1335,IEEE,A novel. physically motivated deformable model for shape recovery and segmentation is presented. The model. referred to as the charged-particle model (CPM). is inspired by classical electrodynamics and is based on a simulation of charged particles moving in an electrostatic field. The charges are attracted towards the contours of the objects of interest by an electrostatic field. whose sources are computed based on the gradient-magnitude image. The electric field plays the same role as the potential forces in the snake model. while internal interactions are modeled by repulsive Coulomb forces. We demonstrate the flexibility and potential of the model in a wide variety of settings: shape recovery using manual initialization. automatic segmentation. and skeleton computation. We perform a comparative analysis of the proposed model with the active contour model and show that specific problems of the latter are …,True,jCFYHlkAAAAJ:2osOgNQ5qMEC,134,https://ieeexplore.ieee.org/abstract/document/1323800/,12046486038199033525,/scholar?cites=12046486038199033525,,,,0,0,0
1278158,Volumetric attribute filtering and interactive visualization using the max-tree representation,2007,Michel A Westenberg and Jos BTM Roerdink and Michael HF Wilkinson,16,IEEE Transactions on Image Processing,12,2943-2952,IEEE,The Max-Tree designed for morphological attribute filtering in image processing. is a data structure in which the nodes represent connected components for all threshold levels in a data set. Attribute filters compute some attribute describing the shape or size of each connected component and then decide which components to keep or to discard. In this paper. we augment the basic Max-Tree data structure such that interactive volumetric filtering and visualization becomes possible. We introduce extensions that allow (1) direct. splatting-based. volume rendering; (2) representation of the Max-Tree on graphics hardware; and (3) fast active cell selection for isosurface generation. In all three cases. we can use the Max-Tree representation for visualization directly. without needing to reconstruct the volumetric data explicitly. We show that both filtering and visualization can be performed at interactive frame rates. ranging …,True,jCFYHlkAAAAJ:WF5omc3nYNoC,129,https://ieeexplore.ieee.org/abstract/document/4376245/,17578930291133903446,/scholar?cites=17578930291133903446,,,https://core.ac.uk/download/pdf/232378547.pdf,0,0,0
1278159,A dataset for breast cancer histopathological image classification,2015,Fabio A Spanhol and Luiz S Oliveira and Caroline Petitjean and Laurent Heutte,63,Ieee transactions on biomedical engineering,7,1455-1462,IEEE,Today. medical image analysis papers require solid experiments to prove the usefulness of proposed methods. However. experiments are often performed on data selected by the researchers. which may come from different institutions. scanners. and populations. Different evaluation measures may be used. making it difficult to compare the methods. In this paper. we introduce a dataset of 7909 breast cancer histopathology images acquired on 82 patients. which is now publicly available from http://web.inf.ufpr.br/vri/breast-cancer-database. The dataset includes both benign and malignant images. The task associated with this dataset is the automated classification of these images in two classes. which would be a valuable computer-aided diagnosis tool for the clinician. In order to assess the difficulty of this task. we show some preliminary results obtained with state-of-the-art image classification systems. The …,True,oMgb9jgAAAAJ:OkrdTXRNpVkC,507,https://ieeexplore.ieee.org/abstract/document/7312934/,18103879122965901213,/scholar?cites=18103879122965901213,,,https://www.academia.edu/download/46657457/TBME-00608-2015-R2-preprint.pdf,0,0,0
1278160,Breast cancer histopathological image classification using convolutional neural networks,2016,Fabio Alexandre Spanhol and Luiz S Oliveira and Caroline Petitjean and Laurent Heutte,,,,2560-2567,IEEE,The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering. a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand. deep learning can extract and organize the discriminative information from the data. not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep. feedforward network that have gained attention from research community and industry. achieving empirical successes in tasks such as speech recognition. signal processing. object recognition. natural language processing and transfer learning. In this paper. we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis. a …,True,oMgb9jgAAAAJ:PPrs6GlykQcC,474,https://ieeexplore.ieee.org/abstract/document/7727519/,5692855641568481476,/scholar?cites=5692855641568481476,,,https://www.academia.edu/download/46657492/IJCNN-2016-16315.pdf,0,0,0
1278161,Automatic recognition of handwritten numerical strings: A recognition and verification strategy,2002,Luiz S Oliveira and Robert Sabourin and Flávio Bortolozzi and Ching Y.  Suen,24,IEEE Transactions on Pattern Analysis and Machine Intelligence,11,1438-1454,IEEE,A modular system to recognize handwritten numerical strings is proposed. It uses a segmentation-based recognition approach and a recognition and verification strategy. The approach combines the outputs from different levels such as segmentation. recognition. and postprocessing in a probabilistic model. A new verification scheme which contains two verifiers to deal with the problems of oversegmentation and undersegmentation is presented. A new feature set is also introduced to feed the oversegmentation verifier. A postprocessor based on a deterministic automaton is used and the global decision module makes an accept/reject decision. Finally. experimental results on two databases are presented: numerical amounts on Brazilian bank checks and NIST SD19. The latter aims at validating the concept of modular system and showing the robustness of the system using a well-known database.,True,oMgb9jgAAAAJ:u5HHmVD_uO8C,302,https://ieeexplore.ieee.org/abstract/document/1046154/,5384477137507303855,/scholar?cites=5384477137507303855,,,,0,0,0
1278162,Dynamic selection of classifiers—a comprehensive review,2014,Alceu S Britto Jr and Robert Sabourin and Luiz ES Oliveira,47,,11,3665-3680,Pergamon,This work presents a literature review of multiple classifier systems based on the dynamic selection of classifiers. First. it briefly reviews some basic concepts and definitions related to such a classification approach and then it presents the state of the art organized according to a proposed taxonomy. In addition. a two-step analysis is applied to the results of the main methods reported in the literature. considering different classification problems. The first step is based on statistical analyses of the significance of these results. The idea is to figure out the problems for which a significant contribution can be observed in terms of classification performance by using a dynamic selection approach. The second step. based on data complexity measures. is used to investigate whether or not a relation exists between the possible performance contribution and the complexity of the classification problem. From this comprehensive …,True,oMgb9jgAAAAJ:PuYkdpj8xa4C,255,https://www.sciencedirect.com/science/article/pii/S0031320314001885,2588597849379320527,/scholar?cites=2588597849379320527,,,http://www.inf.ufpr.br/lesoliveira/download/pr2014.pdf,0,0,0
1278163,Reducing forgeries in writer-independent off-line signature verification through ensemble of classifiers,2010,Diego Bertolini and Luiz S Oliveira and Edson Justino and Robert Sabourin,43,Pattern Recognition,1,387-396,Pergamon,In this work we address two important issues of off-line signature verification. The first one regards feature extraction. We introduce a new graphometric feature set that considers the curvature of the most important segments. perceptually speaking. of the signature. The idea is to simulate the shape of the signature by using Bezier curves and then extract features from these curves. The second important aspect is the use of an ensemble of classifiers based on graphometric features to improve the reliability of the classification. hence reducing the false acceptance. The ensemble was built using a standard genetic algorithm and different fitness functions were assessed to drive the search. Two different scenarios were considered in our experiments. In the former. we assume that only genuine signatures and random forgeries are available to guide the search. In the latter. on the other hand. we assume that simple and …,True,oMgb9jgAAAAJ:Tyk-4Ss8FVUC,224,https://www.sciencedirect.com/science/article/pii/S0031320309001976,16958617307425863469,/scholar?cites=16958617307425863469,,,http://www.inf.ufpr.br/lesoliveira/download/PR2010.pdf,0,0,0
1278164,A methodology for feature selection using multiobjective genetic algorithms for handwritten digit string recognition,2003,Luiz S Oliveira and Robert Sabourin and Flavio Bortolozzi and Ching Y Suen,17,International Journal of Pattern Recognition and Artificial Intelligence,06,903-929,World Scientific Publishing Company,In this paper a methodology for feature selection for the handwritten digit string recognition is proposed. Its novelty lies in the use of a multiobjective genetic algorithm where sensitivity analysis and neural network are employed to allow the use of a representative database to evaluate fitness and the use of a validation database to identify the subsets of selected features that provide a good generalization. Some advantages of this approach include the ability to accommodate multiple criteria such as number of features and accuracy of the classifier. as well as the capacity to deal with huge databases in order to adequately represent the pattern recognition problem. Comprehensive experiments on the NIST SD19 demonstrate the feasibility of the proposed methodology.,True,oMgb9jgAAAAJ:u-x6o8ySG0sC,200,https://www.worldscientific.com/doi/abs/10.1142/S021800140300271X,9248472422964300637,/scholar?cites=9248472422964300637,,,https://www.academia.edu/download/1888326/24zqn1x64gsry2m.pdf,0,0,0
1278165,A robust real-time automatic license plate recognition based on the YOLO detector,2018,Rayson Laroca and Evair Severo and Luiz A Zanlorensi and Luiz S Oliveira and Gabriel Resende Gonçalves and William Robson Schwartz and David Menotti,,,,1-10,IEEE,Automatic License Plate Recognition (ALPR) has been a frequent topic of research due to many practical applications. However. many of the current solutions are still not robust in real-world situations. commonly depending on many constraints. This paper presents a robust and efficient ALPR system based on the state-of-the-art YOLO object detector. The Convolutional Neural Networks (CNNs) are trained and finetuned for each ALPR stage so that they are robust under different conditions (e.g.. variations in camera. lighting. and background). Specially for character segmentation and recognition. we design a two-stage approach employing simple data augmentation tricks such as inverted License Plates (LPs) and flipped characters. The resulting ALPR approach achieved impressive results in two datasets. First. in the SSIG dataset. composed of 2.000 frames from 101 vehicle videos. our system achieved a …,True,oMgb9jgAAAAJ:kcGNQN_anIUC,184,https://ieeexplore.ieee.org/abstract/document/8489629/,1627864622376566941,/scholar?cites=1627864622376566941,,,https://arxiv.org/pdf/1802.09567,0,0,0
1278166,PKLot–A robust dataset for parking lot classification,2015,Paulo RL De Almeida and Luiz S Oliveira and Alceu S Britto Jr and Eunelson J Silva Jr and Alessandro L Koerich,42,Expert Systems with Applications,11,4937-4949,Pergamon,Outdoor parking lot vacancy detection systems have attracted a great deal of attention in the last decade due the large number of practical applications. However. a common problem that researchers in this field very often face is the lack of a representative dataset to perform their experiments. To mitigate this difficulty. in this paper we introduce a new parking lot dataset composed of 695.899 images captured from two parking lots with three different camera views. The acquisition protocol allows obtaining static images showing illumination variance related to sunny. overcast and rainy days. We believe that researchers will find this dataset a very useful tool since it allows future benchmarking and evaluation. The dataset is currently available for research purposes upon request. To gain a better insight into this dataset we have evaluated two textural descriptors. Local Binary Patterns and Local Phase Quantization …,True,oMgb9jgAAAAJ:n8FNryW2AHIC,174,https://www.sciencedirect.com/science/article/pii/S0957417415001086,9748225686171293420,/scholar?cites=9748225686171293420,,,https://www.researchgate.net/profile/Alessandro_Koerich/publication/273479425_PKLot_-_A_Robust_Dataset_for_Parking_Lot_Classification/links/5a046a30a6fdcc1c2f6010c4/PKLot-A-Robust-Dataset-for-Parking-Lot-Classification.pdf,0,0,0
1278167,Texture-based descriptors for writer identification and verification,2013,Diego Bertolini and Luiz S Oliveira and E Justino and Robert Sabourin,40,Expert Systems with Applications,6,2069-2080,Pergamon,In this work. we discuss the use of texture descriptors to perform writer verification and identification. We use a classification scheme based on dissimilarity representation. which has been successfully applied to verification problems. Besides assessing two texture descriptors (local binary patterns and local phase quantization). we also address important issues related to the dissimilarity representation. such as the impact of the number of references used for verification and identification. how the framework performs on the problem of writer identification. and how the dissimilarity-based approach compares to other feature-based strategies. In order to meet these objectives. we carry out experiments on two different datasets. the Brazilian forensic letters database and the IAM database. Through a series of comprehensive experiments. we show that both LBP- and LPQ-based classifiers are able to surpass previous …,True,oMgb9jgAAAAJ:abG-DnoFyZgC,166,https://www.sciencedirect.com/science/article/pii/S095741741201130X,4807704999043919278,/scholar?cites=4807704999043919278,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.462.5190&rep=rep1&type=pdf,0,0,0
1278168,Learning features for offline handwritten signature verification using deep convolutional neural networks,2017,Luiz G Hafemann and Robert Sabourin and Luiz S Oliveira,70,Pattern Recognition,,163-176,Pergamon,Verifying the identity of a person using handwritten signatures is challenging in the presence of skilled forgeries. where a forger has access to a person’s signature and deliberately attempt to imitate it. In offline (static) signature verification. the dynamic information of the signature writing process is lost. and it is difficult to design good feature extractors that can distinguish genuine signatures and skilled forgeries. This reflects in a relatively poor performance. with verification errors around 7% in the best systems in the literature. To address both the difficulty of obtaining good features. as well as improve system performance. we propose learning the representations from signature images. in a Writer-Independent format. using Convolutional Neural Networks. In particular. we propose a novel formulation of the problem that includes knowledge of skilled forgeries from a subset of users in the feature learning process. that …,True,oMgb9jgAAAAJ:rrpmhsargb8C,163,https://www.sciencedirect.com/science/article/pii/S0031320317302017,2642364344911095173,/scholar?cites=2642364344911095173,,,https://arxiv.org/pdf/1705.05787,0,0,0
1278169,Offline handwritten signature verification—literature review,2017,Luiz G Hafemann and Robert Sabourin and Luiz S Oliveira,,,,1-8,IEEE,The area of Handwritten Signature Verification has been broadly researched in the last decades. but remains an open research problem. The objective of signature verification systems is to discriminate if a given signature is genuine (produced by the claimed individual). or a forgery (produced by an impostor). This has demonstrated to be a challenging task. in particular in the offline (static) scenario. that uses images of scanned signatures. where the dynamic information about the signing process is not available. Many advancements have been proposed in the literature in the last 5-10 years. most notably the application of Deep Learning methods to learn feature representations from signature images. In this paper. we present how the problem has been handled in the past few decades. analyze the recent advancements in the field. and the potential directions for future research.,True,oMgb9jgAAAAJ:KYgttONoxcsC,159,https://ieeexplore.ieee.org/abstract/document/8310112/,11481843784868879689,/scholar?cites=11481843784868879689,,,https://arxiv.org/pdf/1507.07909,0,0,0
1278170,Computing large deformation metric mappings via geodesic flows of diffeomorphisms,2005,M Faisal Beg and Michael I Miller and Alain Trouvé and Laurent Younes,61,International journal of computer vision,2,139-157,Kluwer Academic Publishers,This paper examine the Euler-Lagrange equations for the solution of the large deformation diffeomorphic metric mapping problem studied in Dupuis et al. (1998) and Trouvé (1995) in which two images I 0. I 1 are given and connected via the diffeomorphic change of coordinates I 0○ϕ−1=I 1 where ϕ=Φ1 is the end point at t= 1 of curve Φ t . t∈[0. 1] satisfying .Φ t =v t (Φ t ). t∈ [0.1] with Φ0=id. The variational problem takes the form  where ‖v t‖ V  is an appropriate Sobolev norm on the velocity field v t(·). and the second term enforces matching of the images with ‖·‖L 2 representing the squared-error norm.In this paper we derive the Euler-Lagrange equations characterizing the minimizing vector fields v t. t∈[0. 1 …,True,dH1oDusAAAAJ:u5HHmVD_uO8C,1520,https://link.springer.com/article/10.1023/B:VISI.0000043755.93987.aa,12525156275408923302,/scholar?cites=12525156275408923302,,,https://www.academia.edu/download/42483116/Computing_Large_Deformation_Metric_Mappi20160209-18329-1x0b6yb.pdf,0,0,0
1278171,On the metrics and Euler-Lagrange equations of computational anatomy,2002,Michael I Miller and Alain Trouvé and Laurent Younes,4,,1,375-405,,Revolutionary advances in the development of digital imaging modalities combined with advances in digital computation are enabling researchers to make major advances in the precise study of the awesome biological variability of human anatomy. This is emerging as the exciting new field of computational anatomy (CA)(1. 2). CA. as first defined in Reference (2). has three principal aspects:(a) automated construction of anatomical manifolds. points. curves. surfaces. and subvolumes;(b) comparison of these manifolds; and (c) the statistical codification of the variability of anatomy via probability measures allowing for inference and hypothesis testing of disease states. This review will focus on aspects (b) and (c). Although the study of structural variability of such manifolds can certainly be traced back to the beginnings of modern science. in his influential treatise “On Growth and Form” in 1917. D’Arcy Thompson had the clearest vision of what lay ahead. namely:In a very large part of morphology. our essential task lies in the comparison of related forms rather than in the precise definition of each; and the deformation of a complicated figure may be a phenomenon easy of comprehension. though the figure itself may have to be left unanalyzed and undefined. This process of comparison. of recognizing in one form a definite permutation or deformation of another. apart altogether from a precise and adequate understanding of the original ‘type’or standard of comparison. lies within the immediate province of mathematics and finds its solution in the elementary use of a certain method of the mathematician. This method is the Method of Coordinates. on …,True,dH1oDusAAAAJ:u-x6o8ySG0sC,503,https://www.researchgate.net/profile/Alain_Trouve/publication/11260601_On_the_metrics_and_Euler-Lagrange_equations_of_computational_anatomy/links/0912f5076f95d2806b000000/On-the-metrics-and-Euler-Lagrange-equations-of-computational-anatomy.pdf,17419639603061318842,/scholar?cites=17419639603061318842,,,https://www.researchgate.net/profile/Alain_Trouve/publication/11260601_On_the_metrics_and_Euler-Lagrange_equations_of_computational_anatomy/links/0912f5076f95d2806b000000/On-the-metrics-and-Euler-Lagrange-equations-of-computational-anatomy.pdf,0,0,0
1278172,Diffeomorphisms groups and pattern matching in image analysis,1998,Alain Trouvé,28,International journal of computer vision,3,213-221,Kluwer Academic Publishers,In a previous paper. it was proposed to see the deformations of a common pattern as the action of an infinite dimensional group. We show in this paper that this approac h can be applied numerically for pattern matching in image analysis of digital images. Using Lie group ideas. we construct a distance between deformations defined through a metric given the cost of infinitesimal deformations. Then we propose a numerical scheme to solve a variational problem involving this distance and leading to a sub-optimal gradient pattern matching. Its links with fluid models are established.,True,dH1oDusAAAAJ:d1gkVwhDpl0C,424,https://link.springer.com/article/10.1023/A:1008001603737,15274074266856941991,/scholar?cites=15274074266856941991,,,,0,0,0
1278173,Geodesic shooting for computational anatomy,2006,Michael I Miller and Alain Trouvé and Laurent Younes,24,Journal of mathematical imaging and vision,2,209-228,Kluwer Academic Publishers,Studying large deformations with a Riemannian approach has been an efficient point of view to generate metrics between deformable objects. and to provide accurate. non ambiguous and smooth matchings between images. In this paper. we study the geodesics of such large deformation diffeomorphisms. and more precisely. introduce a fundamental property that they satisfy. namely the conservation of momentum. This property allows us to generate and store complex deformations with the help of one initial “momentum” which serves as the initial state of a differential equation in the group of diffeomorphisms. Moreover. it is shown that this momentum can be also used for describing a deformation of given visual structures. like points. contours or images. and that. it has the same dimension as the described object. as a consequence of the normal momentum constraint we introduce.,True,dH1oDusAAAAJ:2osOgNQ5qMEC,361,https://link.springer.com/article/10.1007/s10851-005-3624-0,14894254983064108551,/scholar?cites=14894254983064108551,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2897162/,0,0,0
1278174,Statistics on diffeomorphisms via tangent space representations,2004,Marc Vaillant and Michael I Miller and Laurent Younes and Alain Trouvé,23,NeuroImage,,S161-S169,Academic Press,In this paper. we present a linear setting for statistical analysis of shape and an optimization approach based on a recent derivation of a conservation of momentum law for the geodesics of diffeomorphic flow. Once a template is fixed. the space of initial momentum becomes an appropriate space for studying shape via geodesic flow since the flow at any point along the geodesic is completely determined by the momentum at the origin through geodesic shooting equations. The space of initial momentum provides a linear representation of the nonlinear diffeomorphic shape space in which linear statistical analysis can be applied. Specializing to the landmark matching problem of Computational Anatomy. we derive an algorithm for solving the variational problem with respect to the initial momentum and demonstrate principal component analysis (PCA) in this setting with three-dimensional face and hippocampus …,True,dH1oDusAAAAJ:9yKSN-GCB0IC,267,https://www.sciencedirect.com/science/article/pii/S1053811904003957,15922403285881312954,/scholar?cites=15922403285881312954,,,https://www.academia.edu/download/49029890/Statistics_on_diffeomorphisms_via_tangen20160922-30744-gkbbyv.pdf,0,0,0
1278175,Towards a coherent statistical framework for dense deformable template estimation,2007,Stéphanie Allassonnière and Yali Amit and Alain Trouvé,69,Journal of the Royal Statistical Society: Series B (Statistical Methodology),1,3-29,Blackwell Publishing Ltd, The problem of estimating probabilistic deformable template models in the field of computer vision or of probabilistic atlases in the field of computational anatomy has not yet received a coherent statistical formulation and remains a challenge. We provide a careful definition and analysis of a well‐defined statistical model based on dense deformable templates for grey level images of deformable objects. We propose a rigorous Bayesian framework for which we prove asymptotic consistency of the maximum a posteriori estimate and which leads to an effective iterative estimation algorithm of the geometric and photometric parameters in the small sample setting. The model is extended to mixtures of finite numbers of such components leading to a fine description of the photometric and geometric variations of an object class. We illustrate some of the ideas with images of handwritten digits and apply the estimated …,True,dH1oDusAAAAJ:qjMakFHDy7sC,256,https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2007.00574.x,17424706261764768230,/scholar?cites=17424706261764768230,,,https://www.academia.edu/download/38998234/em2.6.3.pdf,0,0,0
1278176,Diffeomorphic matching of distributions: A new approach for unlabelled point-sets and sub-manifolds matching,2004,Joan Glaunes and Alain Trouvé and Laurent Younes,2,,,II-II,IEEE,In the paper. we study the problem of optimal matching of two generalized functions (distributions) via a diffeomorphic transformation of the ambient space. In the particular case of discrete distributions (weighted sums of Dirac measures). we provide a new algorithm to compare two arbitrary unlabelled sets of points. and show that it behaves properly in limit of continuous distributions on sub-manifolds. As a consequence. the algorithm may apply to various matching problems. such as curve or surface matching (via a sub-sampling). or mixings of landmark and curve data. As the solution forbids high energy solutions. it is also robust towards addition of noise and the technique can be used for nonlinear projection of datasets. We present 2D and 3D experiments.,True,dH1oDusAAAAJ:UeHWp8X0CEIC,224,https://ieeexplore.ieee.org/abstract/document/1315234/,1060573490938730497,/scholar?cites=1060573490938730497,,,,0,0,0
1278177,Metamorphoses through lie group action,2005,Alain Trouvé and Laurent Younes,5,Foundations of computational mathematics,2,173-198,Springer-Verlag,We formally analyze a computational problem which has important applications in image understanding and shape analysis. The problem can be summarized as follows. Starting from a group action on a Riemannian manifold M. we   introduce a modification of the metric by partly expressing   displacements on M as an effect of the action of some  group   element. The study of   this new structure relates to evolutions on M under the combined   effect of the action and of residual displacements. called   metamorphoses. This can and has been applied to image processing   problems. providing in particular diffeomorphic matching algorithms   for pattern recognition.,True,dH1oDusAAAAJ:IjCSPb-OGe4C,206,https://link.springer.com/article/10.1007/s10208-004-0128-z,502311506374855078,/scholar?cites=502311506374855078,,,https://www.researchgate.net/profile/Alain_Trouve/publication/220104320_Metamorphoses_Through_Lie_Group_Action/links/0912f5076f95aa54d7000000.pdf,0,0,0
1278178,Morphometry of anatomical shape complexes with dense deformations and sparse parameters,2014,Stanley Durrleman and Marcel Prastawa and Nicolas Charon and Julie R Korenberg and Sarang Joshi and Guido Gerig and Alain Trouvé,101,NeuroImage,,35-49,Academic Press,We propose a generic method for the statistical analysis of collections of anatomical shape complexes. namely sets of surfaces that were previously segmented and labeled in a group of subjects. The method estimates an anatomical model. the template complex. that is representative of the population under study. Its shape reflects anatomical invariants within the dataset. In addition. the method automatically places control points near the most variable parts of the template complex. Vectors attached to these points are parameters of deformations of the ambient 3D space. These deformations warp the template to each subject's complex in a way that preserves the organization of the anatomical structures. Multivariate statistical analysis is applied to these deformation parameters to test for group differences. Results of the statistical analysis are then expressed in terms of deformation patterns of the template complex …,True,dH1oDusAAAAJ:dshw04ExmUIC,188,https://www.sciencedirect.com/science/article/pii/S1053811914005205,15067694646624431955,/scholar?cites=15067694646624431955,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4871626/,0,0,0
1278179,Statistical models of sets of curves and surfaces based on currents,2009,Stanley Durrleman and Xavier Pennec and Alain Trouvé and Nicholas Ayache,13,Medical image analysis,5,793-808,Elsevier,Computing. visualizing and interpreting statistics on shapes like curves or surfaces is a real challenge with many applications ranging from medical image analysis to computer graphics. Modeling such geometrical primitives with currents avoids to base the comparison between primitives either on a selection of geometrical measures (like length. area or curvature) or on the assumption of point-correspondence. This framework has been used relevantly to register brain surfaces or to measure geometrical invariants. However. while the state-of-the-art methods efficiently perform pairwise registrations. new numerical schemes are required to process groupwise statistics due to an increasing complexity when the size of the database is growing.In this paper. we propose a Matching Pursuit Algorithm for currents. which allows us to approximate. at any desired accuracy. the mean and modes of a population of geometrical …,True,dH1oDusAAAAJ:ufrVoPGSRksC,175,https://www.sciencedirect.com/science/article/pii/S1361841509000620,11752034524971362053,/scholar?cites=11752034524971362053,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.5224&rep=rep1&type=pdf,0,0,0
1278180,Pop: Patchwork of parts models for object recognition,2007,Yali Amit and Alain Trouvé,75,International Journal of Computer Vision,2,267-282,Springer US,We formulate a deformable template model for objects with an efficient mechanism for computation and parameter estimation. The data consists of binary oriented edge features. robust to photometric variation and small local deformations. The template is defined in terms of probability arrays for each edge type. A primary contribution of this paper is the definition of the instantiation of an object in terms of shifts of a moderate number local submodels—parts—which are subsequently recombined using a patchwork operation. to define a coherent statistical model of the data. Object classes are modeled as mixtures of patchwork of parts POP models that are discovered sequentially as more class data is observed. We define the notion of the support associated to an instantiation. and use this to formulate statistical models for multi-object configurations including possible occlusions. All decisions on the labeling of …,True,dH1oDusAAAAJ:zYLM7Y9cAGgC,174,https://link.springer.com/content/pdf/10.1007/s11263-006-0033-9.pdf,13446760455291668581,/scholar?cites=13446760455291668581,,,https://www.researchgate.net/profile/Alain_Trouve/publication/220659585_POP_Patchwork_of_Parts_Models_for_Object_Recognition/links/0912f5076f95a37ac7000000.pdf,0,0,0
1278181,Quicktime VR: An image-based approach to virtual environment navigation,1995,Shenchang Eric Chen,,,,29-38,,"Traditionally. virtual reality systems use 3D computer graphics to model and render virtual environments in real-time. This approach usually requires laborious modeling and expensive special purpose rendering hardware. The rendering quality and scene complexity are often limited because of the real-time constraint. This paper presents a new approach which uses 360-degree cylindrical panoramic images to compose a virtual environment. The panoramic image is digitally warped on-the-fly to simulate camera panning and zooming. The panoramic images can be created with computer rendering. specialized panoramic cameras or by"" stitching"" together overlapping photographs taken with a regular camera. Walking in a space is currently accomplished by"" hopping"" to different panoramic points. The image-based approach has been used in the commercial product QuickTime VR. a virtual reality extension to …",True,4NbvaEQAAAAJ:IjCSPb-OGe4C,2259,https://dl.acm.org/doi/pdf/10.1145/218380.218395,4541645535516360902,/scholar?cites=4541645535516360902,,,https://www.cs.drexel.edu/~david/Classes/Papers/p29-chen.pdf,0,0,0
1278182,View interpolation for image synthesis,1993,Shenchang Eric Chen and Lance Williams,,,,279-288,,Image-space simplifications have been used to accelerate the calculation of computer graphic images since the dawn of visual simulation. Texture mapping has been used to provide a means by which images may themselves be used as display primitives. The work reported by this paper endeavors to carry this concept to its logical extreme by using interpolated images to portray three-dimensional scenes. The special-effects technique of morphing. which combines interpolation of texture maps and their shape. is applied to computing arbitrary intermediate frames from an array of prestored images. If the images are a structured set of views of a 3D object or scene. intermediate frames derived by morphing can be used to approximate intermediate 3D transformations of the object or scene. Using the view interpolation approach to synthesize 3D scenes has two main advantages. First. the 3D representation of the …,True,4NbvaEQAAAAJ:qjMakFHDy7sC,1709,https://dl.acm.org/doi/pdf/10.1145/166117.166153,3004969609627417306,/scholar?cites=3004969609627417306,,,https://www.cs.uaf.edu/users/olawlor/public_html/academic/thesis/ref/chen93interpolation.pdf,0,0,0
1278183,A progressive refinement approach to fast radiosity image generation,1988,Michael F Cohen and Shenchang Eric Chen and John R Wallace and Donald P Greenberg,,,,75-84,,A reformulated radiosity algorithm is presented that produces initial images in time linear to the number of patches. The enormous memory costs of the radiosity algorithm are also eliminated by computing form-factors on-the-fly. The technique is based on the approach of rendering by progressive refinement. The algorithm provides a useful solution almost immediately which progresses gracefully and continuously to the complete radiosity solution. In this way the competing demands of realism and interactivity are accommodated. The technique brings the use of radiosity for interactive rendering within reach and has implications for the use and development of current and future graphics workstations.,True,4NbvaEQAAAAJ:Se3iqnhoufwC,974,https://dl.acm.org/doi/abs/10.1145/54852.378487,13574312987196952766,/scholar?cites=13574312987196952766,,,http://gec.di.uminho.pt/DISCIP/MCGAV/ifr0304/Artigos/Cohen88-ProgressiveRadiosity.pdf,0,0,0
1278184,A progressive multi-pass method for global illumination,1991,Shenchang Eric Chen and Holly E Rushmeier and Gavin Miller and Douglass Turner,,,,165-174,,A new progressive global illumination method is presented which produces approximate images quickly. and then continues to systematically produce more accurate images. The method combines the existing methods of progressive refinement radiosity. Monte Carlo path tracing and light ray tracing. The method does not place any limitation on surface properties such as ideal Lambertian or mirror-like. To increase efficiency and accuracy. the new concepts of light source reclassification. caustics reconstruction. Monte Carlo path tracing with a radiosity preprocess and an interruptible radiosity solution are introduced. The method presents the user with most useful information about the scene as early as possible by reorganizing the method into a radiosity pass. a high frequency refinement pass and a low frequency refinement pass. The implementation of the method is demonstrated. and sample images are presented.,True,4NbvaEQAAAAJ:5nxA0vEk-isC,269,https://dl.acm.org/doi/abs/10.1145/122718.122737,14778283896777227473,/scholar?cites=14778283896777227473,,,https://www.academia.edu/download/8572455/10.1.1.119.1306.pdf,0,0,0
1278185,Virtual reality camera,2003,Shenchang Eric Chen,,,,,,A method and apparatus for creating and rendering multiple-view images. A camera includes an image sensor to receive images. sampling logic to digitize the images and a processor programmed to combine the images based upon a spatial relationship between the images.,True,4NbvaEQAAAAJ:W7OEmFMy1HYC,222,https://patents.google.com/patent/US6552744B2/en,5663166145298970946,/scholar?cites=5663166145298970946,,,https://patentimages.storage.googleapis.com/e6/5e/77/c94c9f92136f4d/US6552744.pdf,0,0,0
1278186,Extracting a time-sequence of slides from video,2003,Jonathan Worthen Brandt and Shenchang Eric Chen,,,,,,An apparatus and method for generating a slide from a video. A slide is automatically identified in video frames of a video input stream. A digitized representation of the slide is generated based on the video frames of the video input stream.,True,4NbvaEQAAAAJ:MXK_kJrjxJIC,190,https://patents.google.com/patent/US6646655/en,16338885847811593738,/scholar?cites=16338885847811593738,,,https://patentimages.storage.googleapis.com/5b/34/d9/85d03446afff7d/US6646655.pdf,0,0,0
1278187,Incremental radiosity: An extension of progressive radiosity to an interactive image synthesis system,1990,Shenchang Eric Chen,,,,135-144,,"Traditional radiosity methods can compute the illumination for a scene independent of the view position. However. if any part of the scene geometry is changed. the radiosity process will need to be repeated from scratch. Since the radiosity methods are generally expensive computationally. the traditional methods do not lend themselves to interactive uses where the geometry is constantly changing. This paper presents a new radiosity algorithm to incrementally render scenes with changing geometry and surface attributes. In other words. the question to be asked is"" What is the minimum recomputation I need to do if I turn off a light source. change the color of a surface. add or move an object?"" Because a modeling change generally exhibits some coherence and affects only parts of an image. the proposed method may drastically reduce the rendering time and therefore allow interactive manipulation. In addition …",True,4NbvaEQAAAAJ:zYLM7Y9cAGgC,172,https://dl.acm.org/doi/abs/10.1145/97879.97894,4958615453612398234,/scholar?cites=4958615453612398234,,,http://www0.cs.ucl.ac.uk/research/vr/Projects/VLF/vlfpapers/radiosity/Chen_S_E__Incremental_Radiosity_An_Extension_of_Progressive_Radiosity_to_an_Interactive_Image_Synthesis_System.pdf,0,0,0
1278188,Cylindrical to planar image mapping using scanline coherence,1995,Shenchang E Chen and Gavin SP Miller,,,,,,A method and apparatus for generating perspective views of a scene. With a viewing position at the center of to be cylindrical environment map. different views can be obtained by rotating the viewing direction either horizontally or vertically. The horizontal construction method of the present invention generally involves the steps of: determining the portion of the cylindrical map to be viewed; vertically interpolating pixel values in the portion of the cylindrical map to be viewed and mapping to a viewing plane; and displaying the viewing plane. The vertical construction method of the present invention generally involves the steps of: determining the portion of the cylindrical map to be viewed; vertically interpolating pixel values in the portion of the cylindrical map robe viewed and mapping to a vertical plane; horizontally interpolating pixel values in the vertical plane and mapping to the viewing plane; and displaying the …,True,4NbvaEQAAAAJ:kNdYIx-mwKoC,167,https://patents.google.com/patent/US5396583A/en,17673301162304378088,/scholar?cites=17673301162304378088,,,https://patentimages.storage.googleapis.com/74/82/23/744b4091f6a2c0/US5396583.pdf,0,0,0
1278189,Creating animation from a video,2001,Shenchang Eric Chen,,,,,,An apparatus and method for creating an animation. A sequence of video images is inspected to identify a first transformation of a scene depicted in the sequence of video images. A first image and a second image are obtained from the sequence of video images. the first image representing the scene before the first transformation and the second image representing the scene after the first transformation. Information is generated that indicates the first transformation and that can be used to interpolate between the first image and the second image to produce a video effect that approximates display of the sequence of video images.,True,4NbvaEQAAAAJ:LkGwnXOMwfcC,165,https://patents.google.com/patent/US6278466B1/en,12026463414857503923,/scholar?cites=12026463414857503923,,,https://patentimages.storage.googleapis.com/f8/b1/aa/86acae5bc8d343/US6278466.pdf,0,0,0
1278190,On-demand presentation graphical user interface,2001,Shenchang Eric Chen and Chris Schoeneman,,,,,,A graphical user interface (“GUI”) is described comprising: a video region for displaying a video of a presenter giving a presentation; a primary slide region for displaying slides used by the presenter during the presentation; and a thumbnail region containing thumbnails representing slides in the presentation. the thumbnails selectable by a user via a cursor control device.,True,4NbvaEQAAAAJ:Y0pCki6q_DkC,164,https://patents.google.com/patent/US6249281B1/en,5632130247025729706,/scholar?cites=5632130247025729706,,,https://patentimages.storage.googleapis.com/24/21/56/1153580759e323/US6249281.pdf,0,0,0
1278191,Shape averaging and its applications to industrial design,1989,Shenchang Eric Chen and Richard E Parent,9,IEEE Computer Graphics and Applications,1,47-54,IEEE,A computer-assisted technique called shape averaging is presented. Shape averaging produces an abstraction of the typical representation from a set of shapes. Since the averaging is assumed to preserve the characteristics of the original shapes. the result is useful in predicting trends in form or extracting stereotypes from a group of related shapes. The technique can be used to create new forms by blending global features of existing unrelated shapes. The syntactic averaging of shapes consisting of 2-D planar polygons or of 3-D objects represented by planar contours is examined. An algorithm is presented to determine the correspondence between polygons defined by arbitrary numbers of vertices. Algorithms to extract the mean. the median. and the mode from the shapes are also introduced. Potential applications of shape averaging in design are illustrated.< >,True,4NbvaEQAAAAJ:9yKSN-GCB0IC,163,https://ieeexplore.ieee.org/abstract/document/20333/,731187997370770729,/scholar?cites=731187997370770729,,,,0,0,0
1278192,A survey of advances in vision-based human motion capture and analysis,2006,Thomas B Moeslund and Adrian Hilton and Volker Krüger,104,,2-3,90-126,Academic Press,This survey reviews advances in human motion capture and analysis from 2000 to 2006. following a previous survey of papers up to 2000 [T.B. Moeslund. E. Granum. A survey of computer vision-based human motion capture. Computer Vision and Image Understanding. 81(3) (2001) 231–268.]. Human motion capture continues to be an increasingly active research area in computer vision with over 350 publications over this period. A number of significant research advances are identified together with novel methodologies for automatic initialization. tracking. pose estimation. and movement recognition. Recent research has addressed reliable tracking and pose estimation in natural scenes. Progress has also been made towards automatic understanding of human actions and behavior. This survey reviews recent trends in video-based human capture and analysis. as well as discussing open problems for future …,True,tClxJM4AAAAJ:pqnbT2bcN3wC,3232,https://www.sciencedirect.com/science/article/pii/S1077314206001263,8370408689417986539,/scholar?cites=8370408689417986539,,,http://www.ee.surrey.ac.uk/CVSSP/VMRG/Publications/moeslund06cviu.pdf,0,0,0
1278193,Identification of humans using gait,2004,Amit Kale and Aravind Sundaresan and AN Rajagopalan and Naresh P Cuntoor and Amit K Roy-Chowdhury and Volker Kruger and Rama Chellappa,13,IEEE Transactions on image processing,9,1163-1173,IEEE,We propose a view-based approach to recognize humans from their gait. Two different image features have been considered: the width of the outer contour of the binarized silhouette of the walking person and the entire binary silhouette itself. To obtain the observation vector from the image features. we employ two different methods. In the first method. referred to as the indirect approach. the high-dimensional image feature is transformed to a lower dimensional space by generating what we call the frame to exemplar (FED) distance. The FED vector captures both structural and dynamic traits of each individual. For compact and effective gait representation and recognition. the gait information in the FED vector sequences is captured in a hidden Markov model (HMM). In the second method. referred to as the direct approach. we work with the feature vector directly (as opposed to computing the FED) and train an HMM …,True,tClxJM4AAAAJ:YFjsv_pBGBYC,763,https://ieeexplore.ieee.org/abstract/document/1323098/,17109856584156890608,/scholar?cites=17109856584156890608,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.2467&rep=rep1&type=pdf,0,0,0
1278194,Probabilistic recognition of human faces from video,2003,Shaohua Zhou and Volker Krueger and Rama Chellappa,91,Computer vision and image understanding,1-2,214-245,Academic Press,Recognition of human faces using a gallery of still or video images and a probe set of videos is systematically investigated using a probabilistic framework. In still-to-video recognition. where the gallery consists of still images. a time series state space model is proposed to fuse temporal information in a probe video. which simultaneously characterizes the kinematics and identity using a motion vector and an identity variable. respectively. The joint posterior distribution of the motion vector and the identity variable is estimated at each time instant and then propagated to the next time instant. Marginalization over the motion vector yields a robust estimate of the posterior distribution of the identity variable. A computationally efficient sequential importance sampling (SIS) algorithm is developed to estimate the posterior distribution. Empirical results demonstrate that. due to the propagation of the identity variable over time. a …,True,tClxJM4AAAAJ:HoB7MX3m0LUC,370,https://www.sciencedirect.com/science/article/pii/S1077314203000808,11757329385718214858,/scholar?cites=11757329385718214858,,,https://www.researchgate.net/profile/S_Kevin_Zhou/publication/3970063_Probabilistic_recognition_of_human_faces_from_video/links/004635331c5922ab34000000/Probabilistic-recognition-of-human-faces-from-video.pdf,0,0,0
1278195,Gait-based recognition of humans using continuous HMMs,2002,Amit Kale and AN Rajagopalan and Naresh Cuntoor and Volker Kruger,,,,336-341,IEEE,Gait is a spatio-temporal phenomenon that typifies the motion characteristics of an individual. In this paper. we propose a view-based approach to recognize humans through gait. The width of the outer contour of the binarized silhouette of a walking person is chosen as the image feature. A set of stances or key frames that occur during the walk cycle of an individual is chosen. Euclidean distances of a given image from this stance set are computed and a lower-dimensional observation vector is generated. A continuous hidden Markov model (HMM) is trained using several such lower-dimensional vector sequences extracted from the video. This methodology serves to compactly capture structural and transitional features that are unique to an individual. The statistical nature of the HMM renders overall robustness to gait representation and recognition. The human identification performance of the proposed scheme is …,True,tClxJM4AAAAJ:BqipwSGYUEgC,274,https://ieeexplore.ieee.org/abstract/document/1004176/,11608114456122702667,/scholar?cites=11608114456122702667,,,http://www.cs.cmu.edu/~./dgovinda/pdf/recog/01004176.pdf,0,0,0
1278196,Robot skills for manufacturing: From concept to industrial deployment,2016,Mikkel Rath Pedersen and Lazaros Nalpantidis and Rasmus Skovgaard Andersen and Casper Schou and Simon Bøgh and Volker Krüger and Ole Madsen,37,Robotics and Computer-Integrated Manufacturing,,282-291,Pergamon,Due to a general shift in manufacturing paradigm from mass production towards mass customization. reconfigurable automation technologies. such as robots. are required. However. current industrial robot solutions are notoriously difficult to program. leading to high changeover times when new products are introduced by manufacturers. In order to compete on global markets. the factories of tomorrow need complete production lines. including automation technologies that can effortlessly be reconfigured or repurposed. when the need arises. In this paper we present the concept of general. self-asserting robot skills for manufacturing. We show how a relatively small set of skills are derived from current factory worker instructions. and how these can be transferred to industrial mobile manipulators. General robot skills can not only be implemented on these robots. but also be intuitively concatenated to program the …,True,tClxJM4AAAAJ:7T2F9Uy0os0C,232,https://www.sciencedirect.com/science/article/pii/S0736584515000575,13603582235865531669,/scholar?cites=13603582235865531669,,,https://www.researchgate.net/profile/Lazaros_Nalpantidis/publication/275671457_Robot_skills_for_manufacturing_From_concept_to_industrial_deployment/links/5dd6b01d92851c1feda55b89/Robot-skills-for-manufacturing-From-concept-to-industrial-deployment.pdf,0,0,0
1278197,The meaning of action: A review on action recognition and mapping,2007,Volker Krüger and Danica Kragic and Aleš Ude and Christopher Geib,21,,13,1473-1501,Taylor & Francis Group,    In this paper. we analyze the different approaches taken to date within the computer vision. robotics and artificial intelligence communities for the representation. recognition. synthesis and understanding of action. We deal with action at different levels of complexity and provide  the reader with the necessary related literature references. We put the literature references further into context and outline a possible interpretation of action by taking into account the different aspects of action recognition. action synthesis and task-level planning.   ,True,tClxJM4AAAAJ:ZHo1McVdvXMC,202,https://www.tandfonline.com/doi/abs/10.1163/156855307782148578,229022742664895678,/scholar?cites=229022742664895678,,,http://www-hcr.ijs.si/resources/papers/ar07a.pdf,0,0,0
1278198,Gabor wavelet networks for object representation,2001,Volker Krüger and Gerald Sommer,,,,115-128,Springer. Berlin. Heidelberg,In this article we want to introduce first the Gabor wavelet network as a model based approach for an effective and efficient object representation. The Gabor wavelet network has several advantages such as invariance to some degree with respect to translation. rotation and dilation. Furthermore. the use of Gabor filters ensured that geometrical and textural object features are encoded. The feasibility of the Gabor filters as a model for local object features ensures a considerable data reduction while at the same time allowing any desired precision of the object representation ranging from a sparse to a photo-realistic representation. In the second part of the paper we will present an approach for the estimation of a head pose that is based on the Gabor wavelet networks.,True,tClxJM4AAAAJ:SeFeTyx0c_EC,161,https://link.springer.com/chapter/10.1007/3-540-45134-X_9,5736314412812246410,/scholar?cites=5736314412812246410,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.5140&rep=rep1&type=pdf,0,0,0
1278199,Hierarchical wavelet networks for facial feature localization,2002,Rogério Schmidt Feris and Jim Gemmell and Kentaro Toyama and Volker Kruger,,,,125-130,IEEE,We present a technique for facial feature localization using a two-level hierarchical wavelet network. The first level wavelet network is used for face matching. and yields an affine transformation used for a rough approximation of feature locations. Second level wavelet networks for each feature are then used to fine-tune the feature locations. Construction of a training database containing hierarchical wavelet networks of many faces allows features to be detected in most faces. Experiments show that facial feature localization benefits significantly from the hierarchical approach. Results compare favorably with existing techniques for feature localization.,True,tClxJM4AAAAJ:GnPB-g6toBAC,156,https://ieeexplore.ieee.org/abstract/document/1004143/,17562267942119659095,/scholar?cites=17562267942119659095,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.6123&rep=rep1&type=pdf,0,0,0
1278200,Visual analysis of humans,2011,Thomas B Moeslund and Adrian Hilton and Volker Krüger and Leonid Sigal,,,,,Springer London,Over the course of the last 10–20 years the field of computer vision has been preoccupied with the problem of looking at people. Hundreds. if not thousands. of papers have been published on the subject that span people and face detection. pose estimation. tracking and activity recognition. This research focus has been motivated by the numerous potential application for visual analysis of people from human–computer interaction to security. assisted living and clinical analysis of movement. A number of specific and general surveys have been published on these topics. but the field is lacking one coherent text that introduces and gives a comprehensive review of progress and open-problems. To provide such an overview is the exact ambition of this book. The target audience is not only graduate students in the computer vision field. but also scholars. researchers and practitioners from other fields who have an …,True,tClxJM4AAAAJ:eMMeJKvmdy0C,152,https://link.springer.com/content/pdf/10.1007/978-0-85729-997-0.pdf,5131635770654254332,/scholar?cites=5131635770654254332,,,,0,0,0
1278201,Learning actions from observations,2010,Volker Kruger and Dennis L Herzog and Sanmohan Baby and Ales Ude and Danica Kragic,17,IEEE robotics & automation magazine,2,30-43,IEEE,In the area of imitation learning. one of the important research problems is action representation. There has been a growing interest in expressing actions as a combination of meaningful subparts called action primitives. Action primitives could be thought of as elementary building blocks for action representation. In this article. we present a complete concept of learning action primitives to recognize and synthesize actions. One of the main novelties in this work is the detection of primitives in a unified framework. which takes into account objects and actions being applied to them. As the first major contribution. we propose an unsupervised learning approach for action primitives that make use of the human movements as well as object state changes. As the second major contribution. we propose using parametric hidden Markov models (PHMMs) for representing the discovered action primitives. PHMMs represent …,True,tClxJM4AAAAJ:RGFaLdJalmkC,127,https://ieeexplore.ieee.org/abstract/document/5481141/,1196321462513335128,/scholar?cites=1196321462513335128,,,http://www-hcr.ijs.si/resources/papers/ram10.pdf,0,0,0
1278202,Exemplar-based face recognition from video,2002,Volker Krueger and Shaohua Zhou,,,,732-746,Springer. Berlin. Heidelberg,A new exemplar-based probabilistic approach for face recognition in video sequences is presented. The approach has two stages: First. Exemplars. which are selected representatives from the raw video. are automatically extracted from gallery videos. The exemplars are used to summarize the gallery video information. In the second part. exemplars are then used as centers for probabilistic mixture distributions for the tracking and recognition process. A particle method is used to compute the posteriori probabilities. Probabilistic methods are attractive in this context as they allow a systematic handling of uncertainty and an elegant way for fusing temporal information.Contrary to some previous video-based approaches. our approach is not limited to a certain image representation. It rather enhances known ones. such as the PCA. with temporal fusion and uncertainty handling. Experiments …,True,tClxJM4AAAAJ:3s1wT3WcHBgC,110,https://link.springer.com/chapter/10.1007/3-540-47979-1_49,16490988563438497297,/scholar?cites=16490988563438497297,,,https://link.springer.com/content/pdf/10.1007/3-540-47979-1_49.pdf,0,0,0
1278203,Multi-Level Partition of Unity Implicits,2003,Y Ohtake and A Belyaev and M Alexa and H.-P. Turk and Seidel,22,ACM Transactions on Graphics,3,463-470,,We present a new shape representation. the multi-level partition of unity implicit surface. that allows us to construct surface models from very large sets of points. There are three key ingredients to our approach: 1) piecewise quadratic functions that capture the local shape of the surface. 2) weighting functions (the partitions of unity) that blend together these local shape functions. and 3) an octree subdivision method that adapts to variations in the complexity of the local shape. Our approach gives us considerable flexibility in the choice of local shape functions. and in particular we can accurately represent sharp features such as edges and corners by selecting appropriate shape functions. An error-controlled subdivision leads to an adaptive approximation whose time and memory consumption depends on the required accuracy. Due to the separation of local approximation and local blending. the representation is not …,True,UgOo39sAAAAJ:HDshCWvjkbEC,1225,https://dl.acm.org/doi/abs/10.1145/1198555.1198649,12697753018216220290,/scholar?cites=12697753018216220290,,,http://kucg.korea.ac.kr/seminar/2009/src/PA-09-02-26.pdf,0,0,0
1278204,Ridge-valley lines on meshes via implicit surface fitting,2004,Yutaka Ohtake and Alexander Belyaev and Hans-Peter Seidel,,,,609-612,,We propose a simple and effective method for detecting view-and scale-independent ridge-valley lines defined via first-and second-order curvature derivatives on shapes approximated by dense triangle meshes. A high-quality estimation of high-order surface derivatives is achieved by combining multi-level implicit surface fitting and finite difference approximations. We demonstrate that the ridges and valleys are geometrically and perceptually salient surface features. and. therefore. can be potentially used for shape recognition. coding. and quality evaluation purposes.,True,UgOo39sAAAAJ:3fE2CSJIrl8C,530,https://dl.acm.org/doi/abs/10.1145/1186562.1015768,1164390437481540513,/scholar?cites=1164390437481540513,,,"https://www.ljll.math.upmc.fr/frey/papers/meshing/Ohtake%20Y.,%20Ridge-valley%20lines%20on%20meshes%20via%20implicit%20surface%20fitting.pdf",0,0,0
1278205,A multi-scale approach to 3D scattered data interpolation with compactly supported basis functions,2003,Yutaka Ohtake and Alexander Belyaev and Hans-Peter Seidel,,,,153-161,IEEE,We propose a hierarchical approach to 3D scattered data interpolation with compactly supported basis functions. Our numerical experiments suggest that the approach integrates the best aspects of scattered data fitting with locally and globally supported basis functions. Employing locally supported functions leads to an efficient computational procedure. while a coarse-to-fine hierarchy makes our method insensitive to the density of scattered data and allows us to restore large parts of missed data. Given a point cloud distributed along a surface. we first use spatial down sampling to construct a coarse-to-fine hierarchy of point sets. Then we interpolate the sets starting from the coarsest level. We interpolate a point set of the hierarchy. as an offsetting of the interpolating function computed at the previous level. An original point set and its coarse-to-fine hierarchy of interpolated sets is presented. According to our …,True,UgOo39sAAAAJ:MXK_kJrjxJIC,294,https://ieeexplore.ieee.org/abstract/document/1199611/,9355003571222306464,/scholar?cites=9355003571222306464,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.2778&rep=rep1&type=pdf,0,0,0
1278206,Mesh smoothing via mean and median filtering applied to face normals,2002,Hirokazu Yagou and Yutaka Ohtake and Alexander Belyaev,,,,124-131,IEEE,This paper presents frameworks to extend the mean and median filtering schemes in image processing to smoothing noisy 3D shapes given by triangle meshes. The frameworks consist of the application of the mean and median filters to face normals on triangle meshes and the editing of mesh vertex positions to make them fit the modified normals. We also give a quantitative evaluation of the proposed mesh filtering schemes and compare them with conventional mesh smoothing methods such as Laplacian smoothing flow and mean curvature flow. The quantitative evaluation is performed in error metrics on mesh vertices and normals. Experimental results demonstrate that our mesh mean and median filtering methods are more stable than conventional Laplacian and mean curvature flows. We propose thee new mesh smoothing methods as one possible solution of the oversmoothing problem.,True,UgOo39sAAAAJ:Zph67rFs4hoC,253,https://ieeexplore.ieee.org/abstract/document/1027503/,1525514844229240459,/scholar?cites=1525514844229240459,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.5959&rep=rep1&type=pdf,0,0,0
1278207,Detection of salient curvature features on polygonal surfaces,2001,Kouki Watanabe and Alexander G Belyaev,20,Computer Graphics Forum,3,385-392,Blackwell Publishers Ltd,We develop an approach for stable detection of perceptually salient curvature features on surfaces approximated by dense triangle meshes. The approach explores an “area degenerating” effect of the focal surface near its singularities and combines together a new approximations of the mean and Gaussian curvatures. nonlinear averaging of curvature maps. histogram‐based curvature extrema filtering. and an image processing skeletonization procedure adapted for triangular meshes. Finally we use perceptually significant curvature extrema triangles to enhance the Garland‐Heckbert mesh decimation method.,True,UgOo39sAAAAJ:L8Ckcad2t8MC,239,https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00531,18058636512755499097,/scholar?cites=18058636512755499097,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.72.9339&rep=rep1&type=pdf,0,0,0
1278208,Fast and robust detection of crest lines on meshes,2005,Shin Yoshizawa and Alexander Belyaev and Hans-Peter Seidel,,,,227-232,,We propose a fast and robust method for detecting crest lines on surfaces approximated by dense triangle meshes. The crest lines. salient surface features defined via first-and second-order curvature derivatives. are widely used for shape matching and interrogation purposes. Their practical extraction is difficult because it requires good estimation of high-order surface derivatives. Our approach to the crest line detection is based on estimating the curvature tensor and curvature derivatives via local polynomial fitting. Since the crest lines are not defined in the surface regions where the surface focal set (caustic) degenerates. we introduce a new thresholding scheme which exploits interesting relationships between curvature extrema. the so-called MVS functional of Moreton and Sequin. and Dupin cyclides. An application of the crest lines to adaptive mesh simplification is also considered.,True,UgOo39sAAAAJ:M3ejUd6NZC8C,219,https://dl.acm.org/doi/abs/10.1145/1060244.1060270,15496916480306408449,/scholar?cites=15496916480306408449,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.3753&rep=rep1&type=pdf,0,0,0
1278209,Mesh regularization and adaptive smoothing,2001,Yutaka Ohtake and Alexander Belyaev and Ilia Bogaevski,33,Computer-Aided Design,11,789-800,Elsevier,The paper presents a set of mesh smoothing tools developed to increase mesh regularity. reduce oversmoothing. and enhance crease lines. Mesh smoothing with simultaneous increasing mesh regularity and reducing oversmoothing is achieved by combining together the Laplacian flow and a mesh evolution by a function of the mean curvature. To enhance salient ridge and ravine structures we use a coupled nonlinear diffusion of the mesh normals and vertices.,True,UgOo39sAAAAJ:KlAtU1dfN6UC,197,https://www.sciencedirect.com/science/article/pii/S0010448501000951,15778637528640614325,/scholar?cites=15778637528640614325,,,,0,0,0
1278210,Polyhedral surface smoothing with simultaneous mesh regularization,2000,Yutaka Ohtake and Alexander G Belyaev and Ilia A Bogaevski,,,,229-237,IEEE,A computer graphics object reconstructed from real-world data often contains undesirable noise and small-scale oscillations. An important problem is how to remove the noise and oscillations while preserving desirable geometric features of the object. We develops methods for polyhedral surface smoothing and denoising with simultaneous increasing mesh regularity. We also propose an adaptive smoothing method allowing to reduce possible oversmoothing. Roughly speaking. our smoothing schemes consist of moving every vertex in the direction defined by the Laplacian flow with speed equal to a properly chosen function of the mean curvature at the vertex.,True,UgOo39sAAAAJ:ULOm3_A8WrAC,168,https://ieeexplore.ieee.org/abstract/document/838255/,2282413119702435591,/scholar?cites=2282413119702435591,,,https://128.148.66.142/en193s08-2003/refs/Ohtake-etal-gmp00.pdf,0,0,0
1278211,A fast and simple stretch-minimizing mesh parameterization,2004,Shin Yoshizawa and Alexander Belyaev and Hans-Peter Seidel,,,,200-208,IEEE,We propose a fast and simple method for generating a low-stretch mesh parameterization. Given a triangle mesh. we start from the floater shape preserving parameterization and then improve the parameterization gradually. At each improvement step. we optimize the parameterization generated at the previous step by minimizing a weighted quadratic energy where the weights are chosen in order to minimize the parameterization stretch. This optimization procedure does not generate triangle flips if the boundary of the parameter domain is a convex polygon. Moreover already the first optimization step produces a high-quality mesh parameterization. We compare our parameterization procedure with several state-of-the-art mesh parameterization methods and demonstrate its speed and high efficiency in parameterizing large and geometrically complex models.,True,UgOo39sAAAAJ:qxL8FJ1GzNcC,165,https://ieeexplore.ieee.org/abstract/document/1314507/,2400792013640982049,/scholar?cites=2400792013640982049,,,https://www.researchgate.net/profile/Alexander_Belyaev5/publication/47861414_A_fast_and_simple_stretch-minimizing_mesh_parameterization/links/5b962a6292851c78c40c0c3f/A-fast-and-simple-stretch-minimizing-mesh-parameterization.pdf,0,0,0
1278212,Image compression with anisotropic diffusion,2008,Irena Galić and Joachim Weickert and Martin Welk and Andrés Bruhn and Alexander Belyaev and Hans-Peter Seidel,31,Journal of Mathematical Imaging and Vision,2,255-269,Springer Netherlands,Compression is an important field of digital image processing where well-engineered methods with high performance exist. Partial differential equations (PDEs). however. have not much been explored in this context so far. In our paper we introduce a novel framework for image compression that makes use of the interpolation qualities of edge-enhancing diffusion. Although this anisotropic diffusion equation with a diffusion tensor was originally proposed for image denoising. we show that it outperforms many other PDEs when sparse scattered data must be interpolated. To exploit this property for image compression. we consider an adaptive triangulation method for removing less significant pixels from the image. The remaining points serve as scattered interpolation data for the diffusion process. They can be coded in a compact way that reflects the B-tree structure of the triangulation. We supplement the …,True,UgOo39sAAAAJ:e5wmG9Sq2KIC,162,https://link.springer.com/article/10.1007/s10851-008-0087-0,6687651545538648551,/scholar?cites=6687651545538648551,,,https://link.springer.com/content/pdf/10.1007/s10851-008-0087-0.pdf,0,0,0
1278213,3D scattered data approximation with adaptive compactly supported radial basis functions,2004,Yutaka Ohtake and Alexander Belyaev and H-P Seidel,,,,31-39,IEEE,We develop an adaptive RBF fitting procedure for a high quality approximation of a set of points scattered over a piecewise smooth surface. We use compactly supported RBFs whose centers are randomly chosen from the points. The randomness is controlled by the point density and surface geometry. For each RBF. its support size is chosen adoptively according to surface geometry at a vicinity of the RBF center. All these lead to a noise-robust high quality approximation of the set. We also adapt our basic technique for shape reconstruction from registered range scans by taking into account measurement confidences. Finally. an interesting link between our RBF fitting procedure and partition of unity approximations is established and discussed.,True,UgOo39sAAAAJ:kNdYIx-mwKoC,156,https://ieeexplore.ieee.org/abstract/document/1314491/,11215464813662059508,/scholar?cites=11215464813662059508,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.61.3544&rep=rep1&type=pdf,0,0,0
1278214,Pattern recognition with moment invariants: a comparative study and new results,1991,Saeid O Belkasim and Malayappan Shridhar and Majid Ahmadi,24,Pattern recognition,12,1117-1138,Pergamon,Moment invariants have been proposed as pattern sensitive features in classification and recognition applications. In this paper. the authors present a comprehensive study of the effectiveness of different moment invariants in pattern recognition applications by considering two sets of data: handwritten numerals and aircrafts.The authors also present a detailed study of Zernike and pseudo Zernike moment invariants including a new procedure for deriving the moment invariants. In addition. the authors introduce a new normalization scheme that reduces the large dynamic range of these invariants as well as implicit redundancies in these invariants.Based on a comprehensive study with both handwritten numerals and aircraft data. the authors show that the new method of deriving Zernike moment invariants along with the new normalization scheme yield the best overall performance even when the data are degraded …,True,OJjCnWgAAAAJ:u5HHmVD_uO8C,736,https://www.sciencedirect.com/science/article/pii/003132039190140Z,16366419252832453621,/scholar?cites=16366419252832453621,,,,0,0,0
1278215,A closed-form model for the pull-in voltage of electrostatically actuated cantilever beams,2005,S Chowdhury and M Ahmadi and WC Miller,15,Journal of Micromechanics and Microengineering,4,756,IOP Publishing,A simple computationally efficient closed-form model has been developed to determine the pull-in voltage of a cantilever beam actuated by electrostatic force. The approach is based on a linearized uniform approximate model of the nonlinear electrostatic pressure and the load deflection model of a cantilever beam under uniform pressure. The linearized electrostatic pressure includes the electrostatic pressure due to the fringing field capacitances and has been derived from Meijs and Fokkema's highly accurate empirical expression for the capacitance of a VLSI on-chip interconnect. The model has been verified by comparing the results with published experimentally verified 3D finite element analysis results and also with results from similar closed-form models. The new model can evaluate the pull-in voltage for a cantilever beam with a maximum deviation of±2% from the finite element analysis results for wide …,True,OJjCnWgAAAAJ:u-x6o8ySG0sC,237,https://iopscience.iop.org/article/10.1088/0960-1317/15/4/012/meta,1504982583151758636,/scholar?cites=1504982583151758636,,,,0,0,0
1278216,Investigating the performance of naive-bayes classifiers and k-nearest neighbor classifiers,2007,Mohammed J Islam and QM Jonathan Wu and Majid Ahmadi and Maher A Sid-Ahmed,,,,1541-1546,IEEE,"Probability theory is the framework for making decision under uncertainty. In classification. Bayes' rule is used to calculate the probabilities of the classes and it is a big issue how to classify raw data rationally to minimize expected risk. Bayesian theory can roughly be boiled down to one principle: to see the future. one must look at the past. Naive Bayes classifier is one of the mostly used practical Bayesian learning methods. K-nearest neighbor is a supervised learning algorithm where the result of new instance query is classified based on majority of k-nearest neighbor category. The classifiers do not use any model to fit and only based on memory/training data. In this paper. after reviewing Bayesian theory. the naive Bayes classifier and k-nearest neighbor classifier is implemented and applied to a dataset ""credit card approval"" application. Eventually the performance of these two classifiers is observed on this …",True,OJjCnWgAAAAJ:QIV2ME_5wuYC,194,https://ieeexplore.ieee.org/abstract/document/4420473/,15713046863945773368,/scholar?cites=15713046863945773368,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.479.8724&rep=rep1&type=pdf,0,0,0
1278217,Handwritten Farsi (Arabic) word recognition: a holistic approach using discrete HMM,2001,Mehdi Dehghan and Karim Faez and Majid Ahmadi and Malayappan Shridhar,34,Pattern Recognition,5,1057-1065,Pergamon,A holistic system for the recognition of handwritten Farsi/Arabic words using right–left discrete hidden Markov models (HMM) and Kohonen self-organizing vector quantization is presented. The histogram of chain-code directions of the image strips. scanned from right to left by a sliding window. is used as feature vectors. The neighborhood information preserved in the self-organizing feature map (SOFM). is used for smoothing the observation probability distributions of trained HMMs. Experiments carried out on test samples show promising performance results.,True,OJjCnWgAAAAJ:qjMakFHDy7sC,186,https://www.sciencedirect.com/science/article/pii/S0031320300000510,5437453286475636529,/scholar?cites=5437453286475636529,,,https://www.academia.edu/download/45789492/Handwritten_Farsi_Arabic_word_recognit20160519-12302-1xluiw7.pdf,0,0,0
1278218,Recognition of handwritten numerals with multiple feature and multistage classifier,1995,Jun Cao and Majid Ahmadi and Malayappan Shridhar,28,Pattern Recognition,2,153-160,Pergamon,Multiple experts system is shown to be a promising strategy for handwritten recognition. This paper presents a multiple experts system using neural networks. In the proposed system. the authors have developed: (1) an incremental clustering neural network algorithm with merging and canceling process. (2) a modified directional histogram feature extraction method. and (3) a subclass method with learning rejection neuron strategy. Our experimental results on a large set of data show the efficiency and robustness of the proposed system.,True,OJjCnWgAAAAJ:d1gkVwhDpl0C,182,https://www.sciencedirect.com/science/article/pii/0031320394000943,12956882111486882085,/scholar?cites=12956882111486882085,,,,0,0,0
1278219,Robust indoor positioning using differential Wi-Fi access points,2010,Ning Chang and Rashid Rashidzadeh and Majid Ahmadi,56,IEEE Transactions on Consumer Electronics,3,1860-1867,IEEE,Location positioning systems using wireless area local network (WLAN) infrastructure are considered cost effective and practical solutions for indoor location tracking and estimation. However. accuracy deterioration due to environmental factors and the need for manual offline calibration limit the application of these systems. In this paper. a new method based on differential operation access points is proposed to eliminate the adverse effects of environmental factors on location estimation. The proposed method is developed based on the operation of conventional differential amplifiers where noise and interference are eliminated through a differential operation. A pair of properly positioned access points is used as a differential node to eliminate the undesired effects of environmental factors. As a result the strength of received signals. which is used to determine the location of a user. remains relatively stable and …,True,OJjCnWgAAAAJ:VOx2b1Wkg3QC,155,https://ieeexplore.ieee.org/abstract/document/5606338/,7042666380436313566,/scholar?cites=7042666380436313566,,,,0,0,0
1278220,Segmentation of touching characters in printed document recognition,1994,Su Liang and Malayappan Shridhar and Majid Ahmadi,27,Pattern recognition,6,825-840,Pergamon,A new discrimination function is presented for segmenting touching characters based on both pixel and profile projections. A dynamic recursive segmentation algorithm is developed for effectively segmenting touching characters. Contextual information and spell checking are used to correct errors caused by incorrect recognition and segmentation. Based on 12 real documents. a maximum 99.85% and a minimum 99.4% recognition accuracy is achieved.,True,OJjCnWgAAAAJ:9yKSN-GCB0IC,139,https://www.sciencedirect.com/science/article/pii/0031320394901678,15039714164741033418,/scholar?cites=15039714164741033418,,,https://deepblue.lib.umich.edu/bitstream/handle/2027.42/31557/0000484.pdf?sequence=1,0,0,0
1278221,An efficient feature extraction method with pseudo-Zernike moment in RBF neural network-based human face recognition system,2003,Javad Haddadnia and Majid Ahmadi and Karim Faez,2003,EURASIP Journal on Advances in Signal Processing,9,1-12,SpringerOpen,This paper introduces a novel method for the recognition of human faces in digital images using a new feature extraction method that combines the global and local information in frontal view of facial images. Radial basis function (RBF) neural network with a hybrid learning algorithm (HLA) has been used as a classifier. The proposed feature extraction method includes human face localization derived from the shape information. An efficient distance measure as facial candidate threshold (FCT) is defined to distinguish between face and nonface images. Pseudo-Zernike moment invariant (PZMI) with an efficient method for selecting moment order has been used. A newly defined parameter named axis correction ratio (ACR) of images for disregarding irrelevant information of face images is introduced. In this paper. the effect of these parameters in disregarding irrelevant information in recognition rate improvement is …,True,OJjCnWgAAAAJ:YsMSGLbcyi4C,124,https://link.springer.com/article/10.1155/S1110865703305128,8101275529297408753,/scholar?cites=8101275529297408753,,,https://link.springer.com/content/pdf/10.1155/S1110865703305128.pdf,0,0,0
1278222,Efficient algorithm for fast computation of Zernike moments,1996,SO Belkasim and M Ahmadi and M Shridhar,333,Journal of the Franklin Institute,4,577-581,Pergamon,Zernike moments have been used as shape descriptors in several object recognition applications. The classical method of computing Zernike moments is dependent on the regular moments which makes them computationally expensive and inefficient. In this paper. we present an efficient and fast algorithm for the direct computation of Zernike moments. This algorithm is based on using some properties of Zernike polynomials.,True,OJjCnWgAAAAJ:2osOgNQ5qMEC,105,https://www.sciencedirect.com/science/article/pii/0016003296000178,8474660958256944617,/scholar?cites=8474660958256944617,,,,0,0,0
1278223,Automatic localization of craniofacial landmarks for assisted cephalometry,2004,Idris El-Feghi and Maher A Sid-Ahmed and Majid Ahmadi,37,Pattern Recognition,3,609-621,Pergamon,In this paper we propose a system for localization of cephalometric landmarks. The process of localization is carried out in two steps: deriving a smaller expectation window for each landmark using a trained neuro-fuzzy system (NFS) then applying a template-matching algorithm to pin point the exact location of the landmark. Four points are located on each image using edge detection. The four points are used to extract more features such as distances. shifts and rotation angles of the skull. Limited numbers of representative groups that will be used for training are selected based on k-means clustering. The most effective features are selected based on a Fisher discriminant for each feature set. Using fuzzy linguistics if-then rules. membership degree is assigned to each of the selected features and fed to the FNS. The FNS is trained. utilizing gradient descent. to learn the relation between the sizes. rotations and …,True,OJjCnWgAAAAJ:roLk4NBRz8UC,104,https://www.sciencedirect.com/science/article/pii/S0031320303003200,7547349771674429662,/scholar?cites=7547349771674429662,,,https://www.researchgate.net/profile/I_El-Feghi/publication/221400466_Automatic_Identification_and_Localization_of_Craniofacial_Landmarks_Using_Multi_Layer_Neural_Network/links/5b2ef719aca2720785dfe167/Automatic-Identification-and-Localization-of-Craniofacial-Landmarks-Using-Multi-Layer-Neural-Network.pdf,0,0,0
1278224,N-feature neural network human face recognition,2004,Javad Haddadnia and Majid Ahmadi,22,Image and Vision Computing,12,1071-1082,Elsevier,This paper introduces an efficient method for human face recognition system. which is called the hybrid N-feature neural network (HNFNN) human face recognition system. The HNFNN employs a set of different kind of features from face images with radial basis function (RBF) neural networks. which are fused together through the majority rule. The proposed method improves the performance of the system by combining RBF neural networks. training with different learning algorithms. in committees. This article also evaluates how the performance can be improved by disregarding irrelevant data from the face images by defining the efficient parameters. Experimental results on the ORL and Yale face databases confirm that the proposed method lends itself to higher classification accuracy relative to existing techniques.,True,OJjCnWgAAAAJ:Y0pCki6q_DkC,96,https://www.sciencedirect.com/science/article/pii/S0262885604000794,787117608568910086,/scholar?cites=787117608568910086,,,https://www.academia.edu/download/48788469/N-feature_neural_network_human_face_reco20160912-5143-xlet1b.pdf,0,0,0
1278225,Genome mapping. molecular markers and marker-assisted selection in crop plants,1997,Madan Mohan and Suresh Nair and A Bhagwat and TG Krishna and Masahiro Yano and CR Bhatia and Takuji Sasaki,3,,2,87-103,Kluwer Academic Publishers,Genetic engineering and biotechnology hold great potential for plant breeding as it promises to expedite the time taken to produce crop varieties with desirable characters. With the use of molecular techniques it would now be possible to hasten the transfer of desirable genes among varieties and to introgress novel genes from related wild species. Polygenic characters which were previously very difficult to analyse using traditional plant breeding methods. would now be easily tagged using molecular markers. It would also be possible to establish genetic relationships between sexually incompatible crop plants. Techniques which are particularly promising in assisting selection for desirable characters involves the use of molecular markers such as random-amplified polymorphic DNAs (RAPDs). restriction fragment length polymorphisms (RFLPs). microsatellites and PCR-based DNA markers such as sequence …,True,fPOKSIAAAAAJ:M0j1y4EgrScC,995,https://link.springer.com/article/10.1023/A:1009651919792,16175586997715017715,/scholar?cites=16175586997715017715,,,,0,0,0
1278226,Mortality and pulmonary complications in patients undergoing surgery with perioperative SARS-CoV-2 infection: an international cohort study,2020,Dmitri Nepogodiev and Aneel Bhangu and James C Glasbey and Elizabeth Li and Omar M Omar and Joana FF Simoes and Tom EF Abbott and Osaid Alser and Alexis P Arnaud and Brittany K Bankhead-Kendall and Kerry A Breen and Miguel F Cunha and Giana H Davidson and Salomone Di Saverio and Gaetano Gallo and Ewen A Griffiths and Rohan R Gujjuri and Peter J Hutchinson and Haytham MA Kaafarani and Hans Lederhuber and Markus W Löffler and Hassan N Mashbari and Ana Minaya-Bravo and Dion G Morton and David Moszkowicz and Francesco Pata and George Tsoulfas and Mary L Venn and Daniel Cox and April C Roslani and Felix Alakaloko and Jean-Paul PM de Vries and Mahmoud A Aaraj and Sarah J Abbott and Mutwakil OM Abdalla and Ahmed S Abdelaal and Adesoji O Ademuyiwa and Thomas M Aherne and Osman M Ali and Ghadah Z Alkadeeki and Ana C Almeida and Mahmoud M Alrahawy and Graeme K Ambler and Ehab Alameer and Stefano M Andreani and Beatriz De Andrés-Asenjo and Leyre Lopez Antonanzas and Salah G Aoun and Fouad M Ashoush and Knut Magne Augestad and Rocio B Avellana and Funbi A Ayeni and John OO Ayorinde and Bheemanakone H Babu and Mirza MAS Baig and Oreoluwa M Bajomo and Olivia J Baker and Markus P Baker and Alexander J Baldwin and Vin Shen Ban and Ryan D Baron and Alberto G Barranquero and Conor P Barry and Alessandro DI Bartolomeo and Gary A Bass and Michael F Bath and H Hunt Batjer and Andrew J Beamish and Ajay P Belgaumkar and Matthew N Bence and Ruth A Benson and Juan Carlos Bernal-Sprekelsen and Anuradha R Bhama and Avi V Bhavaraju and Walter L Biffl and Chris M Blundell and Alexander P Boddy and Alexander BJ Borgstein and David C Bosanquet and Karen D Bosch and Ahmad EM Bouhuwaish and Mehmet A Bozkurt and Collin EM Brathwaite and Benjamin C Brown and Oliver D Brown and Allison K Brown and Igor Lima Buarque and Alejandro D Bueno-Cañones and Mustafa R Bulugma and Joshua R Burke and Matthew HV Byrne and Elima P Cagigal-Ortega and Rachael A Callcut and Francesca DI Candido and Michaela E Canova and William J Carlos and Edward J Caruana and Liam D Cato and Andrew B Catton and Andrea Pisani Ceretti and Thomas JG Chase and Francesco Di Chiara and Abeed H Chowdhury and Eric A Chung and Pierfranco M Cicerchia and Ethan CS Clough and Natasha L Coleman and Chris G Collins and Michelle L Collins and Emily T Colonna and Lara V Comini and Patrick A Coughlin and Laura Fernández-Gomez Cruzado and Brian R Davidson and Richard J Davies and Emma J Davies and Niall F Davis and Brett E Dawson and Benjamin JF Dean and Maria Garcia-Conde Delgado and Jose J Diaz and Kathryn E Dickson and Manuel M Diez-Alonso and Jan R Dixon and Matthew J Doe and Thomas D Drake and Frederick T Drake and John P Duffy and Declan FJ Dunne and Naomi JM Dunne and Virginia M Durán-Muñoz-Cruzado and Alexander ZE Durst and Nicola J Eardley and John G Edwards and Ahmed H Elfallal and Mahmoud MA Elfiky and Jessie A Elliott and Sameh H Emile and Katy M Emslie and Frederick W Endorf and Jamie L Engel and Diego T Enjuto and Eric W Etchill and Jonathan P Evans and Brian A Fahey and Carlos S Faria and Carlo V Feo and Henry JM Ferguson and Beatriz Dieguez Fernandez and Andres Garcia Fernandez,396,The Lancet,10243,27-38,Elsevier,The impact of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) on postoperative recovery needs to be understood to inform clinical decision making during and after the COVID-19 pandemic. This study reports 30-day mortality and pulmonary complication rates in patients with perioperative SARS-CoV-2 infection.This international. multicentre. cohort study at 235 hospitals in 24 countries included all patients undergoing surgery who had SARS-CoV-2 infection confirmed within 7 days before or 30 days after surgery. The primary outcome measure was 30-day postoperative mortality and was assessed in all enrolled patients. The main secondary outcome measure was pulmonary complications. defined as pneumonia. acute respiratory distress syndrome. or unexpected postoperative ventilation.This analysis includes 1128 patients who had surgery between Jan 1 and …,True,fPOKSIAAAAAJ:oYwriLWYh5YC,666,https://www.sciencedirect.com/science/article/pii/S014067362031182X,14511111409029751045,/scholar?cites=14511111409029751045,,,https://www.sciencedirect.com/science/article/pii/S014067362031182X,0,0,0
1278227,Evaluating the ε-domination based multi-objective evolutionary algorithm for a quick computation of Pareto-optimal solutions,2005,Kalyanmoy Deb and Manikanth Mohan and Shikhar Mishra,13,Evolutionary computation,4,501-525,MIT Press,Since the suggestion of a computing procedure of multiple Pareto-optimal solutions in multi-objective optimization problems in the early Nineties. researchers have been on the look out for a procedure which is computationally fast and simultaneously capable of finding a well-converged and well-distributed set of solutions. Most multi-objective evolutionary algorithms (MOEAs) developed in the past decade are either good for achieving a well-distributed solutions at the expense of a large computational effort or computationally fast at the expense of achieving a not-so-good distribution of solutions. For example. although the Strength Pareto Evolutionary Algorithm or SPEA (Zitzler and Thiele. 1999) produces a much better distribution compared to the elitist non-dominated sorting GA or NSGA-II (Deb et al.. 2002a). the computational time needed to run SPEA is much greater. In this paper. we evaluate a recently …,True,fPOKSIAAAAAJ:XeErXHja3Z8C,616,https://www.mitpressjournals.org/doi/abs/10.1162/106365605774666895,10031087337215432326,/scholar?cites=10031087337215432326,,,https://direct.mit.edu/evco/article-pdf/13/4/501/1493615/106365605774666895.pdf,0,0,0
1278228,GRASSES AND GALL MIDGES: Plant Defense and Insect Adaptation,2003,MO Harris and JJ Stuart and M Mohan and S Nair and RJ Lamb and O Rohfritsch,48,,1,549-577,Annual Reviews,The interactions of two economically important gall midge species. the rice gall midge and the Hessian fly. with their host plants. rice and wheat. respectively. are characterized by plant defense via R genes and insect adaptation via avr genes. The interaction of a third gall midge species. the orange wheat blossom midge. with wheat defense R genes has not yet exhibited insect adaptation. Because of the simple genetics underlying important aspects of these gall midge–grass interactions. a unique opportunity exists for integrating plant and insect molecular genetics with coevolutionary ecology. We present an overview of some genetic. physiological. behavioral. and ecological studies that will contribute to this integration and point to areas in need of study.,True,fPOKSIAAAAAJ:hHIA4WEVY-EC,239,https://www.annualreviews.org/doi/abs/10.1146/annurev.ento.48.091801.112559,559023583191178865,/scholar?cites=559023583191178865,,,https://www.researchgate.net/profile/Marion_Harris4/publication/11009574_Grasses_and_Gall_Midges_Plant_Defense_and_Insect_Adaptation/links/5635ef1908aeb786b703a551.pdf,0,0,0
1278229,Towards a quick computation of well-spread pareto-optimal solutions,2003,Kalyanmoy Deb and Manikanth Mohan and Shikhar Mishra,,,,222-236,Springer. Berlin. Heidelberg,The trade-off between obtaining a good distribution of Pareto-optimal solutions and obtaining them in a small computational time is an important issue in evolutionary multi-objective optimization (EMO). It has been well established in the EMO literature that although SPEA produces a better distribution compared to NSGA-II. the computational time needed to run SPEA is much larger. In this paper. we suggest a clustered NSGA-II which uses an identical clustering technique to that used in SPEA for obtaining a better distribution. Moreover. we propose a steady-state MOEA based on ε-dominance concept and effcient parent and archive update strategies. Based on a comparative study on a number of two and three objective test problems. it is observed that the steady-state MOEA achieves a comparable distribution to the clustered NSGA-II with a much less computational time.,True,fPOKSIAAAAAJ:TeJ9juy8vcMC,218,https://link.springer.com/chapter/10.1007/3-540-36970-8_16,5016761777544147014,/scholar?cites=5016761777544147014,,,,0,0,0
1278230,Aspect term extraction for sentiment analysis in large movie reviews using Gini Index feature selection method and SVM classifier,2017,Asha S Manek and P Deepa Shenoy and M Chandra Mohan and KR Venugopal,20,,2,135-154,Springer US,With the rapid development of the World Wide Web. electronic word-of-mouth interaction has made consumers active participants. Nowadays. a large number of reviews posted by the consumers on the Web provide valuable information to other consumers. Such information is highly essential for decision making and hence popular among the internet users. This information is very valuable not only for prospective consumers to make decisions but also for businesses in predicting the success and sustainability. In this paper. a Gini Index based feature selection method with Support Vector Machine (SVM) classifier is proposed for sentiment classification for large movie review data set. The results show that our Gini Index method has better classification performance in terms of reduced error rate and accuracy.,True,fPOKSIAAAAAJ:yeL6HyUMUGUC,191,https://link.springer.com/content/pdf/10.1007/s11280-015-0381-x.pdf,16518047127658766911,/scholar?cites=16518047127658766911,,,https://core.ac.uk/download/pdf/206395297.pdf,0,0,0
1278231,Mortality of emergency abdominal surgery in high‐. middle‐and low‐income countries,2016,JEF Fitzgerald,,,,,John Wiley & Sons. Ltd,Background: Surgical mortality data are collected routinely in high-income countries. yet virtually no low-or middle-income countries have outcome surveillance in place. The aim was prospectively to collect worldwide mortality data following emergency abdominal surgery. comparing findings across countries with a low. middle or high Human Development Index (HDI).Methods: This was a prospective. multicentre. cohort study. Self-selected hospitals performing emergency surgery submitted prespecified data for consecutive patients from at least one 2-week interval during July to December 2014. Postoperative mortality was analysed by hierarchical multivariable logistic regression.Results: Data were obtained for 10 745 patients from 357 centres in 58 countries; 6538 were from high-. 2889 from middle-and 1318 from low-HDI settings. The overall mortality rate was 1⋅ 6 per cent at 24 h (high 1⋅ 1 per cent. middle 1⋅ 9 per cent. low 3⋅ 4 per cent; P< 0⋅ 001). increasing to 5⋅ 4 per cent by 30 days (high 4⋅ 5 per cent. middle 6⋅ 0 per cent. low 8⋅ 6 per cent; P< 0⋅ 001). Of the 578 patients who died. 404 (69⋅ 9 per cent) did so between 24 h and 30 days following surgery (high 74⋅ 2 per cent. middle 68⋅ 8 per cent. low 60⋅ 5 per cent). After adjustment. 30-day mortality remained higher in middle-income (odds ratio (OR) 2⋅ 78. 95 per cent ci 1⋅ 84 to 4⋅ 20) and low-income (OR 2⋅ 97. 1⋅ 84 to 4⋅ 81) countries. Surgical safety checklist use was less frequent in low-and middle-income countries. but when used was associated with reduced mortality at 30 days.Conclusion: Mortality is three times higher in low-compared with high-HDI countries …,True,fPOKSIAAAAAJ:NZNkWSpQBv0C,182,https://deepblue.lib.umich.edu/bitstream/handle/2027.42/146346/bjs10151.pdf?sequence=1,16549410814820020830,/scholar?cites=16549410814820020830,,,https://deepblue.lib.umich.edu/bitstream/handle/2027.42/146346/bjs10151.pdf?sequence=1,0,0,0
1278232,Analysis of genetic diversity and phylogeny in Saccharum and related genera using RAPD markers,1999,N Vijayan Nair and Suresh Nair and TV Sreenivasan and Madan Mohan,46,Genetic Resources and Crop Evolution,1,73-79,Kluwer Academic Publishers,Molecular diversity in Saccharum complex was studied using 195 RAPD markers generated by 12 random primers. Among the Saccharum species. S. officinarum showed a low level of genetic diversity while S. sinense was found to be more diverse. Six taxonomical groups were clearly resolved in the cluster analysis. S. officinarum. S. robustum. S. spontaneum and Erianthus spp. formed discrete groups. S. barberi and S. sinense formed a single cluster. so also Narenga and Sclerostachya. S. officinarum was found to be closer to S. robustum and distant from S. spontaneum. Among the related genera. Sclerostachya was closer to Saccharum while Erianthus was found to be highly divergent from all the Saccharum species. Six of the primers used generated RAPD fragments unique to Erianthus. It is suggested that the Erianthus spp. can contribute substantially towards sugarcane varietal improvement in view …,True,fPOKSIAAAAAJ:Oo1CbQkBAzEC,181,https://link.springer.com/article/10.1023/A:1008696808645,10062031859731996670,/scholar?cites=10062031859731996670,,,https://www.academia.edu/download/49125444/a_3A100869680864520160926-22892-1pgdmou.pdf,0,0,0
1278233,Resistance gene analogues from rice: cloning. sequencing and mapping,1999,R Mago and S Nair and M Mohan,99,Theoretical and applied genetics,1-2,50-57,Springer-Verlag, Degenerate oligonucleotide primers were designed on the basis of nucleotide-binding-site (NBS) motifs conserved between resistance genes of Arabidopsis. flax and tobacco and subsequently used as PCR primers to amplify resistance gene analogues (RGA) in rice. Primers amplified a major band of approximately 500 bp. Restriction analysis of the amplified product revealed that the band was made up of several different fragments. Many of these fragments were cloned. Sixty different cloned fragments were analysed and assigned to 14 categories based on Southern blot analysis. Fourteen clones. each representing one of the 14 categories of RGAs were mapped onto the rice genetic map using a Nipponbare ( japonica)×‘Kasalath’ (indica) mapping population consisting of 186 F2 lines. Of the 14 clones representing each class 12 could be mapped onto five different chromosomes of rice with a major …,True,fPOKSIAAAAAJ:wuD5JclIwkYC,172,https://link.springer.com/content/pdf/10.1007/s001220051207.pdf,11068995540576161453,/scholar?cites=11068995540576161453,,,https://www.researchgate.net/profile/Rohit_Mago/publication/226984808_Mago_R_Nair_S_Mohan_M_Resistance_gene_analogues_from_rice_cloning_sequencing_and_mapping_Theor_Appl_Genet_99_50-57/links/0912f50a424268044c000000.pdf,0,0,0
1278234,RFLP and RAPD mapping of the rice Gm2 gene that confers resistance to biotype 1 of gall midge (Orseolia oryzae),1994,Madan Mohan and S Nair and JS Bentur and U Prasada Rao and J Bennett,87,Theoretical and Applied Genetics,7,782-788,Springer-Verlag, Gm2 is dominant gene conferring resistance to biotype 1 of gall midge (Orseolia oryzae Wood-Mason). the major dipteran pest of rice. The gene was mapped by restriction fragment length polymorphism (RFLP) analysis of a set of 40 recombinant inbred lines derived from a cross between the resistant variety ‘Phalguna’ and the susceptible landrace ‘ARC 6650’. The gene is located on chromosome 4 at a position 1.3 cM from marker RG329 and 3.4 cM from RG476. Since the low (28%) polymorphism of this indica x indica cross hindered full coverage of the genome with RFLP markers. the mapping was checked by random amplified polymorphic DNA (RAPD)/bulked segregant analysis. Through the use of 160 RAPD primers. the number of polymorphic markers was increased from 43 to 231. Two RAPD primers amplified loci that co-segregated with resistance/susceptibility. RFLP mapping of these loci …,True,fPOKSIAAAAAJ:oqD4_j7ulsYC,154,https://link.springer.com/article/10.1007%252FBF00221129,3797787416723014473,/scholar?cites=3797787416723014473,,,,0,0,0
1278235,Restriction fragment length polymorphism analysis of polymerase chain reaction products amplified from mapped loci of rice (Oryza sativa L.) genomic DNA,1991,MNV Williams and N Pande and S Nair and M Mohan and J Bennett,82,Theoretical and Applied Genetics,4,489-498,Springer-Verlag,Thirty mapped Indica rice genomic (RG) clones were partially sequenced from each end. From such sequence data. pairs of oligonucleotides were synthesized to act as primers for polymerase chain reaction (PCR) amplification of the corresponding loci in crude total DNA preparations. The PCR products from DNA of Indica varieties were of the sizes expected from the sizes of the corresponding RG clones. However. size polymorphisms were seen between PCR products from Indica and Japonica varieties. and among wildOryza species. Restriction fragment length polymorphism (RFLP) was observed between PCR products of Indica varieties simply by electrophoretic analysis of restricted products. without the need for Southern hybridization or radiolabelling. The RFLPs noted between varieties ARC6650 and Phalguna were inherited in recombinant inbred lines derived from a cross between them. The …,True,fPOKSIAAAAAJ:yIeBiWEAh44C,127,https://link.springer.com/content/pdf/10.1007/BF00588604.pdf,3647508324086837698,/scholar?cites=3647508324086837698,,,,0,0,0
1278236,Ocular aberrations before and after myopic corneal refractive surgery: LASIK-induced changes measured with laser ray tracing,2001,Esther Moreno-Barriuso and Jesús Merayo Lloves and Susana Marcos and Rafael Navarro and Lourdes Llorente and Sergio Barbero,42,Investigative Ophthalmology & Visual Science,6,1396-1403,The Association for Research in Vision and Ophthalmology,purpose. To determine objectively the changes in the ocular aberrations (3rd order and above) induced by myopic LASIK refractive surgery and its impact on image quality.methods. The ocular aberrations of 22 normal myopic eyes (preoperative refraction ranged from− 13 to− 2 D) were measured before (2.9±4.3 weeks) and after (7.7±3.2 weeks) LASIK refractive surgery using a laser ray tracing technique. A set of laser pencils is sequentially delivered onto the eye through different pupil locations. For each ray. the corresponding retinal image is collected on a CCD camera. The displacement of the image centroid with respect to a reference provides direct information of the ocular aberrations. Root-mean-square (RMS) wavefront error was taken as image quality metric.results. RMS wavefront error increased significantly in all eyes but two after surgery. On average. LASIK induced a significant (P= 0.0003) 1.9-fold increase in the RMS error for a 6.5-mm pupil. The main contribution was due to the increase (fourfold. P< 0.0001) of spherical aberration. The increase in the RMS for a 3-mm pupil (1.7-fold) was also significant (P= 0.02). The modulation transfer (computed for 6.5-mm pupil) decreased on average by a factor of 2 for middle-high spatial frequencies.conclusions.(1) Laser ray tracing is a well-suited. robust. and reliable technique for the evaluation of the change of ocular aberrations with refractive surgery.(2) Refractive surgery induces important amounts of 3rd and higher order aberrations. The largest increase occurs for spherical aberration. Decentration of the ablation pattern seems to generate 3rd order aberrations.(3) This result is …,True,3lx5rbMAAAAJ:hsZV8lGYWTMC,718,http://arvojournals.org/article.aspx?articleID=2162653,15400364577838159244,/scholar?cites=15400364577838159244,,,http://arvojournals.org/article.aspx?articleID=2162653,0,0,0
1278237,Accommodation-dependent model of the human eye with aspherics,1985,Rafael Navarro and Javier Santamaria and J Bescós,2,JOSA A,8,1273-1280,Optical Society of America,We consider a schematic human eye with four centered aspheric surfaces. We show that by introducing recent experimental average measurements of cornea and lens into the Gullstrand–Le Grand model. the average spherical aberration of the actual eye is predicted without any shape fitting. The chromatic dispersions are adjusted to fit the experimentally observed chromatic aberration of the eye. The polychromatic point-spread function and modulation transfer function are calculated for several pupil diameters and show good agreement with previous experimental results. Finally. from this schematic eye an accommodation-dependent model is proposed that reproduces the increment of refractive power of the eye during accommodation. The variation of asphericity with accommodation is also introduced in the model and the resulting optical performance studied.,True,3lx5rbMAAAAJ:lSLTfruPkqcC,531,https://www.osapublishing.org/abstract.cfm?uri=josaa-2-8-1273,3830246046779493466,/scholar?cites=3830246046779493466,,,https://digital.csic.es/bitstream/10261/29930/1/B8EE4D10-F90A-2C11-10FDA691E8D65C1E_59187.pdf,0,0,0
1278238,Off-axis aberrations of a wide-angle schematic eye model,1999,Isabel Escudero-Sanz and Rafael Navarro,16,JOSA A,8,1881-1891,Optical Society of America,A schematic eye model based on anatomical data. which had been previously designed to reproduce image quality on axis. has been transformed into a wide-angle model by simply adding a spherical image surface that plays the role of the retina. This model captures the main features of the wide-angle optical design of the human eye with minimum complexity: four conic optical surfaces plus a spherical image surface. Seidel aberrations (spherical aberration. coma. astigmatism. field curvature. and distortion). longitudinal and transverse chromatic aberrations. and overall monochromatic spot diagrams have been computed for this eye model and for field angles ranging from 0° to 60° by both finite and third-order ray tracing. The modulation transfer function for each field angle has been computed as well. In each case our results have been compared with average experimental data found in the literature. showing a …,True,3lx5rbMAAAAJ:_OXeSy2IsFwC,301,https://www.osapublishing.org/abstract.cfm?uri=JOSAA-16-8-1881,12824505427856371135,/scholar?cites=12824505427856371135,,,https://digital.csic.es/bitstream/10261/29955/1/BD62C6D1-EA2A-2F65-FF8266ABA6B9F49B_1236.pdf,0,0,0
1278239,Effects of aging in retinal image quality,1993,Pablo Artal and Manuel Ferro and Ismael Miranda and Rafael Navarro,10,JOSA A,7,1656-1662,Optical Society of America,The retinal image quality characterized by the modulation-transfer function of the eye was measured for two groups of subjects aged in the late twenties and mid sixties. respectively. In both groups. we obtained modulation transfer functions by using a double-pass method under the same experimental conditions: 4-mm artificial pupil. paralyzed accommodation. and objective control of the refractive state and centering. Results showed lower values of modulation in the retinal image for older subjects compared with the younger subjects. The modulation transfer function ratio is similar to that previously found for contrast-sensitivity measurements with subjects in the same age groups. These results suggest that a significant fraction of the loss in spatial vision with age has an optical origin. Apart from the well-known increase in intraocular scattering. there also appears to be an increment in ocular aberration that causes …,True,3lx5rbMAAAAJ:q-HalDI95KYC,281,https://www.osapublishing.org/abstract.cfm?uri=josaa-10-7-1656,15761239131463058797,/scholar?cites=15761239131463058797,,,"https://digital.csic.es/bitstream/10261/61725/1/Artal,.pdf",0,0,0
1278240,Modulation transfer of the human eye as a function of retinal eccentricity,1993,Rafael Navarro and Pablo Artal and David R Williams,10,JOSA A,2,201-212,Optical Society of America,We measured the monochromatic image quality of the eye across a wide visual field (120°). with natural pupil (4 mm) and accommodation (3 diopters). The method is based on the acquisition and the posterior processing of double-pass aerial images of a point source imaged on the retina. which was kept at a fixed distance from the eye at all retinal eccentricities. The two-dimensional modulation transfer functions (MTF’s) computed from the aerial images show that astigmatism is the dominant monochromatic aberration in both the fovea and the periphery and is also the major cause of variability among individuals. We found a slower decline in optical quality with eccentricity than had been found by previous measurements. Our foveal results are in close agreement with those of Campbell and Gubisch [ J. Physiol. (London)186.  558– 578 ( 1966)]. but off-axis optical quality is much better than found previously by …,True,3lx5rbMAAAAJ:7BrZ7Jt4UNcC,259,https://www.osapublishing.org/abstract.cfm?uri=josaa-10-2-201,14675533907919030026,/scholar?cites=14675533907919030026,,,https://digital.csic.es/bitstream/10261/29802/1/10.1.1.127.2674.pdf,0,0,0
1278241,Odd aberrations and double-pass measurements of retinal image quality,1995,Pablo Artal and Susana Marcos and Rafael Navarro and David R Williams,12,JOSA A,2,195-201,Optical Society of America,We investigated the formation of the aerial image in the double-pass method to measure the optical quality of the human eye. We show theoretically and empirically that the double pass through the eye’s optics forces the light distribution in the aerial image to be an even-symmetric function even if the single-pass point-spread function is asymmetric as a result of odd aberrations in the eye. The reason for this is that the double-pass imaging process is described by the autocorrelation rather than the autoconvolution of the single-pass point-spread functions. as has been previously assumed. This implies that although the modulation transfer function can be computed from the double-pass aerial image. the phase transfer function cannot. We also show that the lateral chromatic aberration of the eye cannot be measured with the double-pass procedure because it is canceled by the second pass through the eye’s optics.,True,3lx5rbMAAAAJ:bEWYMUwI8FkC,242,https://www.osapublishing.org/abstract.cfm?uri=josaa-12-2-195,2962053510716463432,/scholar?cites=2962053510716463432,,,https://www.academia.edu/download/42497169/Odd_aberrations_and_double-pass_measurem20160209-2535-14y0n03.pdf,0,0,0
1278242,The depth-of-field of the human eye from objective and subjective measurements,1999,Susana Marcos and Esther Moreno and Rafael Navarro,39,Vision research,12,2039-2049,Pergamon,The depth-of-field (DOF) measured through psychophysical methods seems to depend on the target’s characteristics. We use objective and subjective methods to determine the DOF of the eye for different pupil diameters and wavelengths in three subjects. Variation of image quality with focus is evaluated with a double-pass technique. Objective DOF is defined as the dioptric range for which the image quality does not change appreciably. based on optical criteria. Subjective DOF is based on the accuracy of focusing a point source. Additional DOFs are obtained by simulation from experimental wavefront aberration data from the same subjects. Objective and subjective measurements of DOF are only slightly affected by pupil size. wavelength and spectral composition. Comparison of DOF from double-pass and wavefront aberration data allows us to evaluate the role of ocular aberrations and Stiles–Crawford effect.,True,3lx5rbMAAAAJ:SeFeTyx0c_EC,236,https://www.sciencedirect.com/science/article/pii/S0042698998003174,4178050208336032406,/scholar?cites=4178050208336032406,,,https://www.sciencedirect.com/science/article/pii/S0042698998003174,0,0,0
1278243,A new approach to the study of ocular chromatic aberrations,1999,Susana Marcos and Stephen A Burns and Esther Moreno-Barriusop and Rafael Navarro,39,Vision Research,26,4309-4323,Pergamon,We measured the ocular wavefront aberration at six different visible wavelengths (between 450 and 650 nm) in three subjects. using a spatially resolved refractometer. In this technique. the angular deviation of light rays entering the pupil at different locations is measured with respect to a target viewed through a centered pupil. Fits of the data at each wavelength to Zernike polynomials were used to estimate the change of defocus with wavelength (longitudinal chromatic aberration. LCA) and the wavelength-dependence of the ocular aberrations. Measured LCA was in good agreement with the literature. In most cases the wavefront aberration increased slightly with wavelength. The angular deviations from the reference stimulus measured using a magenta filter allowed us to estimate the achromatic axis and both optical and perceived transverse chromatic aberration (TCA). (including the effect of aberrations and …,True,3lx5rbMAAAAJ:ZfRJV9d4-WMC,217,https://www.sciencedirect.com/science/article/pii/S0042698999001455,6781632380336455945,/scholar?cites=6781632380336455945,,,https://www.sciencedirect.com/science/article/pii/S0042698999001455,0,0,0
1278244,Double-pass and interferometric measures of the optical quality of the eye,1994,David R Williams and David H Brainard and Matthew J McMahon and Rafael Navarro,11,JOSA A,12,3123-3135,Optical Society of America,We compare two methods for measuring the modulation transfer function (MTF) of the human eye: an interferometric method similar to that of Campbell and Green [ J. Physiol. (London)181.  576 ( 1965)] and a double-pass procedure similar to that of Santamaria et al. [ J. Opt. Soc. Am. A4.  1109 ( 1987)]. We implemented various improvements in both techniques to reduce error in the estimates of the MTF. We used the same observers. refractive state. pupil size (3 mm). and wavelength (632.8 nm) for both methods. In the double-pass method we found close agreement between the plane of subjective best focus for the observer and the plane of objective best focus. suggesting that much of the reflected light is confined within individual cones throughout its double pass through the receptor layer. The double-pass method produced MTF’s that were similar to but slightly lower than those of the interferometric method …,True,3lx5rbMAAAAJ:zLWjf1WUPmwC,209,https://www.osapublishing.org/abstract.cfm?uri=josaa-11-12-3123,8119377342424994192,/scholar?cites=8119377342424994192,,,https://digital.csic.es/bitstream/10261/29804/1/10.1.1.79.7988.pdf,0,0,0
1278245,Efficient spatial-domain implementation of a multiscale image representation based on gabor functions,1998,Oscar Nestares and Rafael Fonolla Navarro and Javier Portilla and Antonio Tabernero,7,Journal of Electronic Imaging,1,166-173,International Society for Optics and Photonics,Gabor schemes of multiscale image representation are useful in many computer vision applications. However. the classic Gabor expansion is computationally expensive due to the lack of orthogonality of Gabor functions. Some alternative schemes. based on the application of a bank of Gabor filters. have important advantages such as computational efficiency and robustness. at the cost of redundancy and lack of completeness. In a previous work we proposed a quasicomplete Gabor transform. suitable for fast implementations in either space or frequency domains. Reconstruction was achieved by simply adding together the even Gabor channels. We develop an optimized spatial-domain implementation. using one-dimensional 11-tap filter masks. that is faster and more flexible than Fourier implementations. The reconstruction method is improved by applying fixed and independent weights to the Gabor channels …,True,3lx5rbMAAAAJ:kWvqk_afx_IC,190,https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-7/issue-1/0000/Efficient-spatial-domain-implementation-of-a-multiscale-image-representation-based/10.1117/1.482638.short,16714258204111145106,/scholar?cites=16714258204111145106,,,https://www.academia.edu/download/40037699/0912f5112186238a5c000000.pdf20151115-68247-l6wady.pdf,0,0,0
1278246,Comparing laser ray tracing. the spatially resolved refractometer. and the Hartmann-Shack sensor to measure the ocular wave aberration,2001,Esther Moreno-Barriuso and Susana Marcos and Rafael Navarro and Stephen A Burns,78,Optometry and Vision Science,3,152-156,LWW,Purpose.To compare quantitatively three techniques to measure the optical aberrations of the human eye: laser ray tracing (LRT). the Hartmann-Shack wavefront sensor (HS). and the spatially resolved refractometer (SRR). LRT and HS are objective imaging techniques. whereas SRR is psychophysical.Methods.Wave aberrations were measured in two normal subjects with all three techniques implemented in two different laboratories.Results.We compared the experimental variability of the results obtained with each technique with the overall variability across the three methods. For the two subjects measured (RMS wavefront error 0.5 μm and 0.9 μm. respectively). we found a close agreement; the average standard deviation of the Zernike coefficients within a given method was 0.07 μm. whereas the average global standard deviation across techniques was 0.09 μm. which is only slightly higher.Conclusions.There …,True,3lx5rbMAAAAJ:g3aElNc5_aQC,186,"https://journals.lww.com/optvissci/Fulltext/2001/03000/Comparing_Laser_Ray_Tracing,_the_Spatially.7.aspx",8770381277125931144,/scholar?cites=8770381277125931144,,,https://digital.csic.es/bitstream/10261/82009/1/Moreno.pdf,0,0,0
1278247,The FERET evaluation methodology for face-recognition algorithms,2000,P Jonathon Phillips and Hyeonjoon Moon and Syed A Rizvi and Patrick J Rauss,22,IEEE Transactions on pattern analysis and machine intelligence,10,1090-1104,IEEE,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date. 14.126 images from 1.199 individuals are included in the FERET database. which is divided into development and sequestered portions of the database. In September 1996. the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to 1) assess the state of the art. 2) identify future areas of research. and 3) measure algorithm performance.,True,sBdriskAAAAJ:u5HHmVD_uO8C,6158,https://ieeexplore.ieee.org/abstract/document/879790/,13683523000892554956,/scholar?cites=13683523000892554956,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.9852&rep=rep1&type=pdf,0,0,0
1278248,The FERET verification testing protocol for face recognition algorithms,1998,Syed A Rizvi and P Jonathon Phillips and Hyeonjoon Moon,,,,48-53,IEEE,Two critical performance characterizations of biometric algorithms. including face recognition. are identification and verification. Identification performance of face recognition algorithms on the FERET tests has been previously reported. We report on verification performance obtained from the Sept96 FERET test. The databases used to develop and test algorithms are usually smaller than the databases that will be encountered in applications. We examine the effects of size of the database on performance for both identification and verification.,True,sBdriskAAAAJ:wKETBy42zhYC,229,https://ieeexplore.ieee.org/abstract/document/670924/,10742989652514992207,/scholar?cites=10742989652514992207,,,https://www.researchgate.net/profile/Syed_Rizvi22/publication/221292063_The_FERET_Verification_Testing_Protocol_for_Face_Recognition_Algorithms/links/02e7e527789c6cbd67000000.pdf,0,0,0
1278249,The FERET verification testing protocol for face recognition algorithms,1998,S.A. Rizvi and P.J. Phillips and H. Moon,,,,48-53,IEEE,,True,sBdriskAAAAJ:7wO8s98CvbsC,229,,10742989652514992207,/scholar?cites=10742989652514992207,,,,0,0,0
1278250,Advances in residual vector quantization: A review,1996,Christopher F Barnes and Syed A Rizvi and Nasser M Nasrabadi,5,IEEE Transactions on Image Processing,2,226-262,IEEE,Advances in residual vector quantization (RVQ) are surveyed. Definitions of joint encoder optimality and joint decoder optimality are discussed. Design techniques for RVQs with large numbers of stages and generally different encoder and decoder codebooks are elaborated and extended. Fixed-rate RVQs. and variable-rate RVQs that employ entropy coding are examined. Predictive and finite state RVQs designed and integrated into neural-network based source coding structures are revisited. Successive approximation RVQs that achieve embedded and refinable coding are reviewed. A new type of successive approximation RVQ that varies the instantaneous block rate by using different numbers of stages on different blocks is introduced and applied to image waveforms. and a scalar version of the new residual quantizer is applied to image subbands in an embedded wavelet transform coding system.,True,sBdriskAAAAJ:u-x6o8ySG0sC,146,https://ieeexplore.ieee.org/abstract/document/480761/,17790978065522130419,/scholar?cites=17790978065522130419,,,,0,0,0
1278251,The feret evaluation,1998,P Jonathon Phillips and Hyeonjoon Moon and Syed Rizvi and Patrick Rauss,,,,244-261,Springer Berlin Heidelberg,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. The FERET database is divided into two portions. The development portion is provided to researchers for algorithm development and the sequestered portion provides a set of images not seen by the researchers to test algorithms. The set of test is the third in a sequence of FERET tests. This test was administered in September 1996 and March 1997. The Sept96 test provided a detailed assesment of the state of the art. measurement of algorithm performance on large databases. and a comparison among face recognition algorithms.,True,sBdriskAAAAJ:d1gkVwhDpl0C,92,https://link.springer.com/chapter/10.1007/978-3-642-72201-1_13,10134669659830934081,/scholar?cites=10134669659830934081,,,,0,0,0
1278252,The FERET september 1996 database and evaluation procedure,1997,P Jonathon Phillips and Hyeonjoon Moon and Patrick Rauss and Syed A Rizvi,,,,395-402,Springer. Berlin. Heidelberg,Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. In this paper. we report on the FERET database and the September 1996 FERET test. This test is the third in a series of supervised face-recognition test administered under the FERET program.,True,sBdriskAAAAJ:9yKSN-GCB0IC,77,https://link.springer.com/chapter/10.1007/BFb0016020,7044335849705722211,/scholar?cites=7044335849705722211,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.6994&rep=rep1&type=pdf,0,0,0
1278253,A verification protocol and statistical performance analysis for face recognition algorithms,1998,Syed A Rizvi and P Jonathon Phillips and Hyeonjoon Moon,,,,833-838,IEEE,Two key performance characterization of biometric algorithms (face recognition in particular) are (1) verification performance and (2) and performance as a function of database size and composition. This characterization is required for developing robust face recognition algorithms and for successfully transitioning algorithms from the laboratory to real world. In this paper we (1) present a general verification protocol and apply it to the results from the Sep96 FERET test. and (2) discuss and present results on the effects of database size and variability on identification and verification performance.,True,sBdriskAAAAJ:2osOgNQ5qMEC,62,https://ieeexplore.ieee.org/abstract/document/698701/,11250396702970326442,/scholar?cites=11250396702970326442,,,https://marathon.cse.usf.edu/~sarkar/biometrics/papers/FERET_CVPR.pdf,0,0,0
1278254,Fusion techniques for automatic target recognition,2003,Syed A Rizvi and Nasser M Nasrabadi,,,,27-32,IEEE,In this paper. we investigate several fusion techniques for designing a composite classifier to improve the performance (probability of correct classification) of FLIR ATR. In this research. we propose to use four ATR algorithms for fusion. The individual performance of the four contributing algorithms ranges from 73.5% to about 77% of probability of correct classification on the testing set. We propose to use Bayes classifier. committee of experts. stacked-generalization. winner-takes-all. and ranking-based fusion techniques for designing the composite classifiers. The experimental results show an improvement of more than 6.5% over the best individual performance.,True,sBdriskAAAAJ:qjMakFHDy7sC,56,https://ieeexplore.ieee.org/abstract/document/1284244/,15123345830194470916,/scholar?cites=15123345830194470916,,,,0,0,0
1278255,Predictive residual vector quantization [image coding],1995,Syed A Rizvi and Nasser M Nasrabadi,4,IEEE transactions on image processing,11,1482-1495,IEEE,This paper presents a new vector quantization technique called predictive residual vector quantization (PRVQ). It combines the concepts of predictive vector quantization (PVQ) and residual vector quantization (RVQ) to implement a high performance VQ scheme with low search complexity. The proposed PRVQ consists of a vector predictor. designed by a multilayer perceptron. and an RVQ that is designed by a multilayer competitive neural network. A major task in our proposed PRVQ design is the joint optimization of the vector predictor and the RVQ codebooks. In order to achieve this. a new design based on the neural network learning algorithm is introduced. This technique is basically a nonlinear constrained optimization where each constituent component of the PRVQ scheme is optimized by minimizing an appropriate stage error function with a constraint on the overall error. This technique makes use of a …,True,sBdriskAAAAJ:UeHWp8X0CEIC,49,https://ieeexplore.ieee.org/abstract/document/469930/,3128128731500065898,/scholar?cites=3128128731500065898,,,,0,0,0
1278256,Predictive vector quantization using a neural network approach,1993,Nader Mohsenian and Syed A Rizvi and Nasser M Nasrabadi,32,Optical Engineering,7,1503-1514,International Society for Optics and Photonics,A new predictive vector quantization (PVQ) technique capable of exploring the nonlinear dependencies in addition to the linear  dependencies that exist between adjacent blocks (vectors) of pixels is introduced. The two components of the PVQ scheme. the vector predictor and the vector quantizer. are implemented by two different classes of neural networks. A multilayer perceptron is used for the predictive cornponent and Kohonen self-organizing feature maps are used to design the codebook for the vector quantizer. The multilayer perceptron uses the nonlinearity condition associated with its processing units to perform a nonlinear vector prediction. The second component of the PVQ scheme vector quantizes the residual vector that is formed by subtracting the output of the perceptron from the original input vector. The joint-optimization task of designing the two components of the PVQ scheme is also achieved …,True,sBdriskAAAAJ:IjCSPb-OGe4C,44,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-32/issue-7/0000/Predictive-vector-quantization-using-a-neural-network-approach/10.1117/12.141678.short,8031234831050635857,/scholar?cites=8031234831050635857,,,,0,0,0
1278257,A clutter rejection technique for FLIR imagery using region based principal component analysis,1931,Syed A Rizvi and Tarek N Saadawi and Nasser M Nasrabadi,33,Pattern Recognit,,,,,True,sBdriskAAAAJ:L1USKYWJimsC,41,,10553098226326489754,/scholar?cites=10553098226326489754,,,,0,0,0
1278258,Encyclopedia of Nanoscience and Nanotechnology; Volume 10,2004,Hari Singh Nalwa,,,,,American scientific publishers,Although there are many books/handbook and journals focused on nanotechnology. no encyclopedic reference work has been published covering all aspects of nanoscale science and technology dealing with materials synthesis. processing. fabrication. probes. spectroscopy. physical properties. electronics. optics. mechanics. biotechnology. devices. etc. The Encyclopedia fills this gap to provide basic information on all fundamental and applied aspects of nanotechnology by drawing on two decades of pioneering research.,True,0tmalKMAAAAJ:ZuSUVyMx-TgC,1450,http://scholar.google.com/scholar?cluster=1818223449015974353&hl=en&oi=scholarr,1818223449015974353,/scholar?cites=1818223449015974353,,,,0,0,0
1278259,Supplemental perioperative oxygen to reduce the incidence of surgical-wound infection,2000,Robert Greif and Ozan Akça and Ernst-Peter Horn and Andrea Kurz and Daniel I Sessler,342,New England Journal of Medicine,3,161-167,Massachusetts Medical Society,Destruction by oxidation. or oxidative killing. is the most important defense against surgical pathogens and depends on the partial pressure of oxygen in contaminated tissue. An easy method of improving oxygen tension in adequately perfused tissue is to increase the concentration of inspired oxygen. We therefore tested the hypothesis that the supplemental administration of oxygen during the perioperative period decreases the incidence of wound infection.We randomly assigned 500 patients undergoing colorectal resection to receive 30 percent or 80 percent inspired oxygen during the operation and for two hours afterward. Anesthetic treatment was standardized. and all patients received prophylactic antibiotic therapy. With use of a double-blind protocol. wounds were evaluated daily until the patient was discharged and then at a clinic visit two weeks after surgery. We considered wounds …,True,0tmalKMAAAAJ:NYu48kWxaQAC,1175,https://www.nejm.org/doi/full/10.1056/nejm200001203420303,13204617192814911094,/scholar?cites=13204617192814911094,,,https://www.nejm.org/doi/full/10.1056/nejm200001203420303,0,0,0
1278260,Encyclopedia of surface and colloid science,2002,Arthur T Hubbard,1,,,,CRC press,This comprehensive reference collects fundamental theories and recent research from a wide range of fields including biology. biochemistry. physics. applied mathematics. and computer. materials. surface. and colloid science-providing key references. tools. and analytical techniques for practical applications in industrial. agricultural. and forensic processes. as well as in the production of natural and synthetic compounds such as foods. minerals. paints. proteins. pharmaceuticals. polymers. and soaps.,True,0tmalKMAAAAJ:Vu1dURnyNv8C,924,http://books.google.com/books?hl=en&lr=&id=GobXwAOZIxcC&oi=fnd&pg=PR21&dq=info:C1Dx_HtxgLsJ:scholar.google.com&ots=9wIyYCuMIj&sig=8gCSyoK8tGR9SN27IU8iq3b9l4o,13510923659450077195,/scholar?cites=13510923659450077195,,,http://sutlib2.sut.ac.th/sut_contents/H72835_v1-v4.pdf,0,0,0
1278261,Seven new loci associated with age-related macular degeneration,2013,AMD Gene Consortium,45,Nature genetics,4,433,NIH Public Access,Age-related macular degeneration (AMD) is a common cause of blindness in older individuals. To accelerate understanding of AMD biology and help design new therapies. we executed a collaborative genomewide association study. examining> 17.100 advanced AMD cases and> 60.000 controls of European and Asian ancestry. We identified 19 genomic loci associated with AMD with p< 5× 10− 8 and enriched for genes involved in regulation of complement activity. lipid metabolism. extracellular matrix remodeling and angiogenesis. Our results include 7 loci reaching p< 5× 10− 8 for the first time. near the genes COL8A1/FILIP1L. IER3/DDR1. SLC16A8. TGFBR1. RAD51B. ADAMTS9/MIR548A2. and B3GALTL. A genetic risk score combining SNPs from all loci displayed similar good ability to distinguish cases and controls in all samples examined. Our findings provide new directions for biological. genetic and …,True,0tmalKMAAAAJ:cnT3a81PI4sC,693,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3739472/,18376698868619877906,/scholar?cites=18376698868619877906,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3739472/,0,0,0
1278262,Measurement of the mass of the τ lepton,1996,JZ Bai and O Bardon and RA Becker-Szendy and I Blum and A Breakstone and T Burnett and GP Chen and HF Chen and J Chen and SJ Chen and SM Chen and Y Chen and YB Chen and YQ Chen and BS Cheng and RF Cowan and HC Cui and XZ Cui and HL Ding and ZZ Du and W Dunwoodie and XL Fan and J Fang and CS Gao and ML Gao and SQ Gao and WX Gao and P Gratton and JH Gu and SD Gu and WX Gu and YF Gu and YN Guo and SW Han and Y Han and FA Harris and M Hatanaka and J He and KR He and M He and DG Hitlin and GY Hu and T Hu and XQ Hu and DQ Huang and YZ Huang and JM Izen and QP Jia and CH Jiang and ZZ Jiang and S Jin and Y Jin and L Jones and SH Kang and ZJ Ke and MH Kelsey and BK Kim and YF Lai and HB Lan and PF Lang and A Lankford and F Li and J Li and PQ Li and Q Li and RB Li and W Li and WD Li and WG Li and XH Li and XN Li and YS Li and SZ Lin and HM Liu and J Liu and JH Liu and Q Liu and RG Liu and Y Liu and ZA Liu and XC Lou and B Lowery and F Lu and JG Lu and Y Luo and AM Ma and DH Ma and EC Ma and JM Ma and HS Mao and ZP Mao and R Malchow and M Mandelkern and H Marsiske and XC Meng and HL Ni and J Nie and SL Olsen and J Oyang and D Paluselli and LJ Pan and J Panetta and F Porter and E Prabhakar and ND Qi and YK Que and J Quigley and G Rong and M Schernau and B Schmid and J Schultz and YY Shao and BW Shen and DL Shen and H Shen and XY Shen and HY Sheng and HZ Shi and XR Shi and A Smith and E Soderstrom and XF Song and J Standifird and D Stoker and F Sun and HS Sun and SJ Sun and J Synodinos and YP Tan and SQ Tang and W Toki and GL Tong and E Torrence and F Wang and LS Wang and LZ Wang and M Wang and P Wang and PL Wang and SM Wang and TJ Wang and YY Wang and CL Wei and S Whittaker and R Wilson and WJ Wisniewski and YG Wu and DM Xi and XM Xia and PP Xie,53,Physical Review D,1,20,American Physical Society,A data-driven energy scan in the immediate vicinity of the τ pair production threshold has been performed using the Beijing Spectrometer at the Beijing Electron-Positron Collider. Approximately 5 pb− 1 of data. distributed over 12 scan points. have been collected. A previous mass value for the τ lepton. obtained using only the eμ final state. has been published. In this paper. the final BES result on the mass measurement is presented. The analysis is based on the combined data from the ee. eμ. eh. μμ. μh. and hh final states. where h denotes a charged π or K. A maximum likelihood fit to the τ pair production cross section data yields the value m τ= 1776. 96− 0.21-0. 17+ 0.18+ 0.25 MeV.© 1995 The American Physical Society.,True,0tmalKMAAAAJ:Dq1jD5C1HUoC,227,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.53.20,8658984270979543098,/scholar?cites=8658984270979543098,,,https://cds.cern.ch/record/290565/files/SCAN-9511018.pdf,0,0,0
1278263,Integrating color and shape-texture features for adaptive real-time object tracking,2008,Junqiu Wang and Yasushi Yagi,17,IEEE Transactions on Image Processing,2,235-240,IEEE,We extend the standard mean-shift tracking algorithm to an adaptive tracker by selecting reliable features from color and shape-texture cues according to their descriptive ability. The target model is updated according to the similarity between the initial and current models. and this makes the tracker more robust. The proposed algorithm has been compared with other trackers using challenging image sequences. and it provides better performance.,True,0tmalKMAAAAJ:u5HHmVD_uO8C,226,https://ieeexplore.ieee.org/abstract/document/4401720/,9009951727293623572,/scholar?cites=9009951727293623572,,,http://www.am.sanken.osaka-u.ac.jp/~wang/pdf/TIPSmallII2008.pdf,0,0,0
1278264,Clothing-invariant gait identification using part-based clothing categorization and adaptive weight control,2010,Md Altab Hossain and Yasushi Makihara and Junqiu Wang and Yasushi Yagi,43,Pattern Recognition,6,2281-2291,Pergamon,Variations in clothing alter an individual's appearance. making the problem of gait identification much more difficult. If the type of clothing differs between the gallery and a probe. certain parts of the silhouettes are likely to change and the ability to discriminate subjects decreases with respect to these parts. A part-based approach. therefore. has the potential of selecting the appropriate parts. This paper proposes a method for part-based gait identification in the light of substantial clothing variations. We divide the human body into eight sections. including four overlapping ones. since the larger parts have a higher discrimination capability. while the smaller parts are more likely to be unaffected by clothing variations. Furthermore. as there are certain clothes that are common to different parts. we present a categorization for items of clothing that groups similar clothes. Next. we exploit the discrimination capability as a …,True,0tmalKMAAAAJ:UeHWp8X0CEIC,181,https://www.sciencedirect.com/science/article/pii/S0031320310000075,3046580142537786240,/scholar?cites=3046580142537786240,,,,0,0,0
1278265,Coarse-to-fine vision-based localization by indexing scale-invariant features,2006,Junqiu Wang and Hongbin Zha and Roberto Cipolla,36,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",2,413-422,IEEE,This paper presents a novel coarse-to-fine global localization approach inspired by object recognition and text retrieval techniques. Harris-Laplace interest points characterized by scale-invariant transformation feature descriptors are used as natural landmarks. They are indexed into two databases: a location vector space model (LVSM) and a location database. The localization process consists of two stages: coarse localization and fine localization. Coarse localization from the LVSM is fast. but not accurate enough. whereas localization from the location database using a voting algorithm is relatively slow. but more accurate. The integration of coarse and fine stages makes fast and reliable localization possible. If necessary. the localization result can be verified by epipolar geometry between the representative view in the database and the view to be localized. In addition. the localization system recovers the position …,True,0tmalKMAAAAJ:u-x6o8ySG0sC,167,https://ieeexplore.ieee.org/abstract/document/1605387/,13294642607453663548,/scholar?cites=13294642607453663548,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.227.4300&rep=rep1&type=pdf,0,0,0
1278266,Activation of the caspase-8/Bid and Bax pathways in aspirin-induced apoptosis in gastric cancer,2005,Qing Gu and Ji De Wang and Harry HX Xia and Marie CM Lin and Hua He and Bing Zou and Shui Ping Tu and Yi Yang and Xin Guang Liu and Shiu Kum Lam and Wai Man Wong and Annie OO Chan and Man Fung Yuen and Hsiang Fu Kung and Benjamin Chun-Yu Wong,26,Carcinogenesis,3,541-546,Oxford University Press,Aspirin-induced apoptosis is one of the important mechanisms for its antitumour effect against gastric cancer. We aimed at investigating the involvement of bcl-2 family members in the apoptotic pathway in gastric cancer. Gastric cancer cell line AGS and MKN-45 were observed as to cell growth inhibition and induction of apoptosis in response to treatment with aspirin. Cell proliferation was measured by MTT assay. Apoptosis was determined by 4′-6-diamidino-2-phenylindole staining. Protein expression was determined by western blotting. We showed that aspirin activated caspase-8. caspase-9 and capase-3. cleaved and translocated Bid. induced a conformational change in and translocation of Bax and cytochrome c release. In addition. suppression of caspase-8 with the specific inhibitor z-IETD-fmk. as well as the pan-caspase inhibitor z-VAD-fmk. prevented Bid cleavage and subsequent apoptosis. The …,True,0tmalKMAAAAJ:XfMaBeGYgSgC,121,https://academic.oup.com/carcin/article-abstract/26/3/541/2390791,16373606303288310920,/scholar?cites=16373606303288310920,,,https://academic.oup.com/carcin/article/26/3/541/2390791,0,0,0
1278267,Different topological organization of human brain functional networks with eyes open versus eyes closed,2014,Pengfei Xu and Ruiwang Huang and Jinhui Wang and Nicholas T Van Dam and Teng Xie and Zhangye Dong and Chunping Chen and Ruolei Gu and Yu-Feng Zang and Yong He and Jin Fan and Yue-Jia Luo,90,Neuroimage,,246-255,Academic Press,Opening and closing the eyes are fundamental behaviors for directing attention to the external versus internal world. However. it remains unclear whether the states of eyes-open (EO) relative to eyes-closed (EC) are associated with different topological organizations of functional neural networks for exteroceptive and interoceptive processing (processing the external world and internal state. respectively). Here. we used resting-state functional magnetic resonance imaging and neural network analysis to investigate the topological properties of functional networks of the human brain when the eyes were open versus closed. The brain networks exhibited higher cliquishness and local efficiency. but lower global efficiency during the EO state compared to the EC state. These properties suggest an increase in specialized information processing along with a decrease in integrated information processing in EO (vs. EC …,True,0tmalKMAAAAJ:q736b1r0g6UC,105,https://www.sciencedirect.com/science/article/pii/S1053811914000056,17112598753322161621,/scholar?cites=17112598753322161621,,,http://statics.scnu.edu.cn/pics/2016/0317/1458208574957758.pdf,0,0,0
1278268,Measurement of the  production cross section in 920 GeV fixed-target proton-nucleus collisions,2003,I Abt,26,The European Physical Journal C-Particles and Fields,3,345-355,Springer-Verlag, Using the HERA - B detector. the  production cross section has been measured in 920 GeV proton collisions on carbon and titanium targets. The  production was tagged via inclusive bottom quark decays into  by exploiting the longitudinal separation of  decay vertices from the primary proton-nucleus interaction. Both e  +  e  -  and  channels have been reconstructed and the combined analysis yields the cross section .,True,0tmalKMAAAAJ:YB4bud6kWLwC,85,https://link.springer.com/article/10.1140/epjc/s2002-01071-8,8998288977031571428,/scholar?cites=8998288977031571428,,,https://cds.cern.ch/record/556841/files/0205106.pdf,0,0,0
1278269,Deep learning for generic object detection: A survey,2020,Li Liu and Wanli Ouyang and Xiaogang Wang and Paul Fieguth and Jie Chen and Xinwang Liu and Matti Pietikäinen,128,International journal of computer vision,2,261-318,Springer US,Object detection. one of the most fundamental and challenging problems in computer vision. seeks to locate object instances from a large number of predefined categories in natural images. Deep learning techniques have emerged as a powerful strategy for learning feature representations directly from data and have led to remarkable breakthroughs in the field of generic object detection. Given this period of rapid evolution. the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought about by deep learning techniques. More than 300 research contributions are included in this survey. covering many aspects of generic object detection: detection frameworks. object feature representation. object proposal generation. context modeling. training strategies. and evaluation metrics. We finish the survey by identifying promising directions for future research. ,True,TObmBfYAAAAJ:Ak0FvsSvgGUC,700,https://link.springer.com/article/10.1007/s11263-019-01247-4,2846334625875347669,/scholar?cites=2846334625875347669,,,https://link.springer.com/article/10.1007/s11263-019-01247-4,0,0,0
1278270,A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure,2015,Christian Koch and Kristina Georgieva and Varun Kasireddy and Burcu Akinci and Paul Fieguth,29,,2,196-210,Elsevier,To ensure the safety and the serviceability of civil infrastructure it is essential to visually inspect and assess its physical and functional condition. This review paper presents the current state of practice of assessing the visual condition of vertical and horizontal civil infrastructure; in particular of reinforced concrete bridges. precast concrete tunnels. underground concrete pipes. and asphalt pavements. Since the rate of creation and deployment of computer vision methods for civil engineering applications has been exponentially increasing. the main part of the paper presents a comprehensive synthesis of the state of the art in computer vision based defect detection and condition assessment related to concrete and asphalt civil infrastructure. Finally. the current achievements and limitations of existing methods as well as open research challenges are outlined to assist both the civil engineering and the computer science …,True,TObmBfYAAAAJ:foquWX3nUaYC,453,https://www.sciencedirect.com/science/article/pii/S1474034615000208,6482585887536527726,/scholar?cites=6482585887536527726,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.701.2095&rep=rep1&type=pdf,0,0,0
1278271,Color-based tracking of heads and other mobile objects at video frame rates,1997,Paul Fieguth and Demetri Terzopoulos,,,,21-27,IEEE,We develop a simple and very fast method for object tracking based exclusively on color information in digitized video images. Running on a Silicon Graphics R4600 Indy system with an IndyCam. our algorithm is capable of simultaneously tracking objects at full frame size (640/spl times/480 pixels) and video frame rate (30 fps). Robustness with respect to occlusion is achieved via can explicit hypothesis-tree model of the occlusion process. We demonstrate the efficacy of our technique in the challenging task of tracking people. especially tracking human heads and hands.,True,TObmBfYAAAAJ:u5HHmVD_uO8C,404,https://ieeexplore.ieee.org/abstract/document/609292/,17874006475137742216,/scholar?cites=17874006475137742216,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.1383&rep=rep1&type=pdf,0,0,0
1278272,Texture classification from random features,2012,Li Liu and Paul Fieguth,34,IEEE transactions on pattern analysis and machine intelligence,3,574-586,IEEE,Inspired by theories of sparse representation and compressed sensing. this paper presents a simple. novel. yet very powerful approach for texture classification based on random projection. suitable for large texture database applications. At the feature extraction stage. a small set of random features is extracted from local image patches. The random features are embedded into a bag--of-words model to perform texture classification; thus. learning and classification are carried out in a compressed domain. The proposed unconventional random feature extraction is simple. yet by leveraging the sparse nature of texture images. our approach outperforms traditional feature extraction methods which involve careful design and complex steps. We have conducted extensive experiments on each of the CUReT. the Brodatz. and the MSRC databases. comparing the proposed approach to four state-of-the-art texture …,True,TObmBfYAAAAJ:4DMP91E08xMC,343,https://ieeexplore.ieee.org/abstract/document/6136524/,8078217970554828108,/scholar?cites=8078217970554828108,,,,0,0,0
1278273,Median robust extended local binary pattern for texture classification,2016,Li Liu and Songyang Lao and Paul W Fieguth and Yulan Guo and Xiaogang Wang and Matti Pietikäinen,25,IEEE Transactions on Image Processing,3,1368-1381,IEEE,Local binary patterns (LBP) are considered among the most computationally efficient high-performance texture features. However. the LBP method is very sensitive to image noise and is unable to capture macrostructure information. To best address these disadvantages. in this paper. we introduce a novel descriptor for texture classification. the median robust extended LBP (MRELBP). Different from the traditional LBP and many LBP variants. MRELBP compares regional image medians rather than raw image intensities. A multiscale LBP type descriptor is computed by efficiently comparing image medians over a novel sampling scheme. which can capture both microstructure and macrostructure texture information. A comprehensive evaluation on benchmark data sets reveals MRELBP's high performance-robust to gray scale variations. rotation changes and noise-but at a low computational cost. MRELBP produces …,True,TObmBfYAAAAJ:bz8QjSJIRt4C,299,https://ieeexplore.ieee.org/abstract/document/7393828/,14349637696059516007,/scholar?cites=14349637696059516007,,,https://www.trustie.net/attachments/download/92455/%282016%29%20TIP_Median%20Robust%20ExtendedLocal%20Binary%20Pattern%20for%20Texture%20Classification.pdf,0,0,0
1278274,Extended local binary patterns for texture classification,2012,Li Liu and Lingjun Zhao and Yunli Long and Gangyao Kuang and Paul Fieguth,30,Image and Vision Computing,2,86-99,Elsevier,This paper presents a novel approach for texture classification. generalizing the well-known local binary pattern (LBP) approach. In the proposed approach. two different and complementary types of features (pixel intensities and differences) are extracted from local patches. The intensity-based features consider the intensity of the central pixel (CI) and those of its neighbors (NI); while for the difference-based feature. two components are computed: the radial-difference (RD) and the angular-difference (AD). Inspired by the LBP approach. two intensity-based descriptors CI-LBP and NI-LBP. and two difference-based descriptors RD-LBP and AD-LBP are developed. All four descriptors are in the same form as conventional LBP codes. so they can be readily combined to form joint histograms to represent textured images. The proposed approach is computationally very simple: it is totally training-free. there is no need to …,True,TObmBfYAAAAJ:3s1wT3WcHBgC,293,https://www.sciencedirect.com/science/article/pii/S0262885612000066,10548881146068180258,/scholar?cites=10548881146068180258,,,,0,0,0
1278275,Local binary features for texture classification: Taxonomy and experimental study,2017,Li Liu and Paul Fieguth and Yulan Guo and Xiaogang Wang and Matti Pietikäinen,62,Pattern Recognition,,135-160,Pergamon,Local Binary Patterns (LBP) have emerged as one of the most prominent and widely studied local texture descriptors. Truly a large number of LBP variants has been proposed. to the point that it can become overwhelming to grasp their respective strengths and weaknesses. and there is a need for a comprehensive study regarding the prominent LBP-related strategies. New types of descriptors based on multistage convolutional networks and deep learning have also emerged. In different papers the performance comparison of the proposed methods to earlier approaches is mainly done with some well-known texture datasets. with differing classifiers and testing protocols. and often not using the best sets of parameter values and multiple scales for the comparative methods. Very important aspects such as computational complexity and effects of poor image quality are often neglected.In this paper. we provide a …,True,TObmBfYAAAAJ:_5tno0g5mFcC,275,https://www.sciencedirect.com/science/article/pii/S003132031630245X,2410385987883201301,/scholar?cites=2410385987883201301,,,http://jultika.oulu.fi/files/nbnfi-fe201902256134.pdf,0,0,0
1278276,Automated detection of cracks in buried concrete pipe images,2006,Sunil K Sinha and Paul W Fieguth,15,Automation in construction,1,58-72,Elsevier,The detection of cracks in concrete infrastructure is a problem of great interest. In particular. the detection of cracks in buried pipes is a crucial step in assessing the degree of pipe deterioration for municipal and utility operators. The key challenge is that whereas joints and laterals have a predictable appearance. the randomness and irregularity of cracks make them difficult to model. Our previous work has led to a segmented pipe image (with holes. joints. and laterals eliminated) obtained by a morphological approach. This paper presents the development of a statistical filter for the detection of cracks in the pipes. We propose a two-step approach. The first step is local and is used to extract crack features from the buried pipe images; we present two such detectors as well as a method for fusing them. The second step is global and defines the cracks among the segment candidates by processes of cleaning and linking …,True,TObmBfYAAAAJ:2osOgNQ5qMEC,272,https://www.sciencedirect.com/science/article/pii/S0926580505000452,8397966149684441762,/scholar?cites=8397966149684441762,,,https://www.academia.edu/download/31051112/Automated_Detection_of_Crack_Defects_in_Buried_Concrete_Pipe_Images.pdf,0,0,0
1278277,Adaptive Wiener filtering of noisy images and image sequences,2003,Fu Jin and Paul Fieguth and Lowell Winger and Edward Jernigan,3,,,III-349,IEEE,In this work. we consider the adaptive Wiener filtering of noisy images and image sequences. We begin by using an adaptive weighted averaging (AWA) approach to estimate the second-order statistics required by the Wiener filter. Experimentally. the resulting Wiener filter is improved by about 1 dB in the sense of peak-to-peak SNR (PSNR). Also. the subjective improvement is significant in that the annoying boundary noise. common with the traditional Wiener filter. has been greatly suppressed. The second. and more substantial. part of this paper extends the AWA concept to the wavelet domain. The proposed AWA wavelet Wiener filter is superior to the traditional wavelet Wiener filter by about 0.5 dB (PSNR). Furthermore. an interesting method to effectively combine the denoising results from both wavelet and spatial domains is shown and discussed. Our experimental results outperform or are comparable to state …,True,TObmBfYAAAAJ:qjMakFHDy7sC,184,https://ieeexplore.ieee.org/abstract/document/1247253/,2352446928940219957,/scholar?cites=2352446928940219957,,,https://www.academia.edu/download/31051116/a_wiener_filter_improvement_combining_wavelet_domains.pdf,0,0,0
1278278,Multiresolution optimal interpolation and statistical analysis of TOPEX/POSEIDON satellite altimetry,1995,Paul W Fieguth and William C Karl and Alan S Willsky and Carl Wunsch,33,IEEE Transactions on Geoscience and Remote Sensing,2,280-292,IEEE,A recently developed multiresolution estimation framework offers the possibility of highly efficient statistical analysis. interpolation. and smoothing of extremely large data sets in a multiscale fashion. This framework enjoys a number of advantages not shared by other statistically-based methods. In particular. the algorithms resulting from this framework have complexity that scales only linearly with problem size. yielding constant complexity load per grid point independent of problem size. Furthermore these algorithms directly provide interpolated estimates at multiple resolutions. accompanying error variance statistics of use in assessing resolutionlaccuracy tradeoffs and in detecting statistically significant anomalies. and maximum likelihood estimates of parameters such as spectral power law coefficients. Moreover. the efficiency of these algorithms is completely insensitive to irregularities in the sampling or spatial …,True,TObmBfYAAAAJ:u-x6o8ySG0sC,182,https://ieeexplore.ieee.org/abstract/document/8746009/,15647208345340942231,/scholar?cites=15647208345340942231,,,https://apps.dtic.mil/sti/pdfs/ADA459844.pdf,0,0,0
1278279,BRINT: binary rotation invariant and noise tolerant texture classification,2014,Li Liu and Yunli Long and Paul W Fieguth and Songyang Lao and Guoying Zhao,23,IEEE transactions on Image Processing,7,3071-3084,IEEE,In this paper. we propose a simple. efficient. yet robust multiresolution approach to texture classification-binary rotation invariant and noise tolerant (BRINT). The proposed approach is very fast to build. very compact while remaining robust to illumination variations. rotation changes. and noise. We develop a novel and simple strategy to compute a local binary descriptor based on the conventional local binary pattern (LBP) approach. preserving the advantageous characteristics of uniform LBP. Points are sampled in a circular neighborhood. but keeping the number of bins in a single-scale LBP histogram constant and small. such that arbitrarily large circular neighborhoods can be sampled and compactly encoded over a number of scales. There is no necessity to learn a texton dictionary. as in methods based on clustering. and no tuning of parameters is required to deal with different data sets. Extensive experimental …,True,TObmBfYAAAAJ:tuHXwOkdijsC,169,https://ieeexplore.ieee.org/abstract/document/6819021/,5279275923091371851,/scholar?cites=5279275923091371851,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.659.4945&rep=rep1&type=pdf,0,0,0
1278280,Minimum mean brightness error bi-histogram equalization in contrast enhancement,2003,Soong-Der Chen and Abd Rahman Ramli,49,IEEE transactions on Consumer Electronics,4,1310-1319,IEEE,Histogram equalization (HE) is widely used for contrast enhancement. However. it tends to change the brightness of an image and hence. not suitable for consumer electronic products. where preserving the original brightness is essential to avoid annoying artifacts. Bi-histogram equalization (BBHE) has been proposed and analyzed mathematically that it can preserve the original brightness to a certain extends. However. there are still cases that are not handled well by BBHE. as they require higher degree of preservation. This paper proposes a novel extension of BBHE referred to as minimum mean brightness error bi-histogram equalization (MMBEBHE) to provide maximum brightness preservation. BBHE separates the input image's histogram into two based on input mean before equalizing them independently. This paper proposes to perform the separation based on the threshold level. which would yield …,True,WldjVB4AAAAJ:prdVHNxh-e8C,976,https://ieeexplore.ieee.org/abstract/document/1261234/,13159558489646620558,/scholar?cites=13159558489646620558,,,,0,0,0
1278281,Minimum mean brightness error bi-histogram equalization in contrast enhancement,2003,Soong-Der Chen and Abd Rahman Ramli,49,IEEE transactions on Consumer Electronics,4,1310-1319,IEEE,Histogram equalization (HE) is widely used for contrast enhancement. However. it tends to change the brightness of an image and hence. not suitable for consumer electronic products. where preserving the original brightness is essential to avoid annoying artifacts. Bi-histogram equalization (BBHE) has been proposed and analyzed mathematically that it can preserve the original brightness to a certain extends. However. there are still cases that are not handled well by BBHE. as they require higher degree of preservation. This paper proposes a novel extension of BBHE referred to as minimum mean brightness error bi-histogram equalization (MMBEBHE) to provide maximum brightness preservation. BBHE separates the input image's histogram into two based on input mean before equalizing them independently. This paper proposes to perform the separation based on the threshold level. which would yield …,True,WldjVB4AAAAJ:u5HHmVD_uO8C,976,https://ieeexplore.ieee.org/abstract/document/1261234/,13159558489646620558,/scholar?cites=13159558489646620558,,,,0,0,0
1278282,Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation,2003,Soong-Der Chen and Abd Rahman Ramli,49,IEEE Transactions on Consumer Electronics,4,1301-1309,IEEE,Histogram equalization (HE) is widely used for contrast enhancement. However. it tends to change the brightness of an image and hence. not suitable for consumer electronic products. where preserving the original brightness is essential to avoid annoying artifacts. Bi-histogram equalization (BBHE) has been proposed and analyzed mathematically that it can preserve the original brightness to a certain extend. However. there are still cases that are not handled well by BBHE. as they require higher degree of preservation. This paper proposes a generalization of BBHE referred to as recursive mean-separate histogram equalization (RMSHE) to provide not only better but also scalable brightness preservation. BBHE separates the input image's histogram into two based on its mean before equalizing them independently. While the separation is done only once in BBHE. this paper proposes to perform the separation …,True,WldjVB4AAAAJ:u-x6o8ySG0sC,930,https://ieeexplore.ieee.org/abstract/document/1261233/,12495227227610917862,/scholar?cites=12495227227610917862,,,https://www.researchgate.net/profile/Soong_Der_Chen/publication/3180782_Contrast_enhancement_using_recursive_mean-separate_histogram_equalization_for_scalable_brightness_preservation/links/02e7e51a660fc20bb9000000/Contrast-enhancement-using-recursive-mean-separate-histogram-equalization-for-scalable-brightness-preservation.pdf,0,0,0
1278283,Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation,2003,Soong Der Chen and Abd Rahman Ramli,49,IEEE Transactions on Consumer Electronics,4,1301-1309,Institute of Electrical and Electronics Engineers Inc.,Histogram equalization (HE) is widely used for contrast enhancement. However. it tends to change the brightness of an image and hence. not suitable for consumer electronic products. where preserving the original brightness is essential to avoid annoying artifacts. Bi-histogram equalization (BBHE) has been proposed and analyzed mathematically that it can preserve the original brightness to a certain extend. However. there are still cases that are not handled well by BBHE. as they require higher degree of preservation. This paper proposes a generalization of BBHE referred to as recursive mean-separate histogram equalization (RMSHE) to provide not only better but also scalable brightness preservation. BBHE separates the input image's histogram into two based on its mean before equalizing them independently. While the separation is done only once in BBHE. this paper proposes to perform the separation …,True,WldjVB4AAAAJ:L1USKYWJimsC,930,https://ieeexplore.ieee.org/abstract/document/1261233/,12495227227610917862,/scholar?cites=12495227227610917862,,,https://www.researchgate.net/profile/Soong_Der_Chen/publication/3180782_Contrast_enhancement_using_recursive_mean-separate_histogram_equalization_for_scalable_brightness_preservation/links/02e7e51a660fc20bb9000000/Contrast-enhancement-using-recursive-mean-separate-histogram-equalization-for-scalable-brightness-preservation.pdf,0,0,0
1278284,Review of brain MRI image segmentation methods,2010,Mohd Ali Balafar and AR Ramli and M Iqbal Saripan and Syamsiah Mashohor,33,Artificial Intelligence Review,3,261-274,Springer Netherlands,Brain image segmentation is one of the most important parts of clinical diagnostic tools. Brain images mostly contain noise. inhomogeneity and sometimes deviation. Therefore. accurate segmentation of brain images is a very difficult task. However. the process of accurate segmentation of these images is very important and crucial for a correct diagnosis by clinical tools. We presented a review of the methods used in brain segmentation. The review covers imaging modalities. magnetic resonance imaging and methods for noise reduction. inhomogeneity correction and segmentation. We conclude with a discussion on the trend of future research in brain segmentation.,True,WldjVB4AAAAJ:9yKSN-GCB0IC,486,https://link.springer.com/content/pdf/10.1007/s10462-010-9155-0.pdf,13920048160338705359,/scholar?cites=13920048160338705359,,,http://tarjomefa.com/wp-content/uploads/2017/11/7980-English-TarjomeFa.pdf,0,0,0
1278285,A new family of optical code sequences for spectral-amplitude-coding optical CDMA systems,2004,Syed Alwee Aljunid and Mahamod Ismail and Abdul Rahman Ramli and Borhanuddin M Ali and Mohamad Khazani Abdullah,16,IEEE photonics technology letters,10,2383-2385,IEEE,A new code structure for spectral-amplitude-coding optical code-division multiple-access system based on double-weight (DW) code families is proposed. The DW code has a fixed weight of two. By using a mapping technique. codes that have a larger number of weights can be developed. Modified double-weight (MDW) code is a DW code family variation that has variable weights of greater than two. The newly proposed code possesses ideal cross-correlation properties and exists for every natural number n. Based on theoretical analysis and simulation. MDW code is shown here to provide a much better performance compared to Hadamard and modified frequency-hopping codes.,True,WldjVB4AAAAJ:d1gkVwhDpl0C,320,https://ieeexplore.ieee.org/abstract/document/1336937/,3686992172676484422,/scholar?cites=3686992172676484422,,,https://www.academia.edu/download/49098580/lpt.2004.83385920160924-13752-zdl7nl.pdf,0,0,0
1278286,Computer-aided detection/diagnosis of breast cancer in mammography and ultrasound: a review,2013,Afsaneh Jalalian and Syamsiah BT Mashohor and Hajjah Rozi Mahmud and M Iqbal B Saripan and Abdul Rahman B Ramli and Babak Karasfi,37,Clinical imaging,3,420-426,Elsevier,Breast cancer is the most common form of cancer among women worldwide. Early detection of breast cancer can increase treatment options and patients' survivability. Mammography is the gold standard for breast imaging and cancer detection. However. due to some limitations of this modality such as low sensitivity especially in dense breasts. other modalities like ultrasound and magnetic resonance imaging are often suggested to achieve additional information.Recently. computer-aided detection or diagnosis (CAD) systems have been developed to help radiologists in order to increase diagnosis accuracy. Generally. a CAD system consists of four stages: (a) preprocessing. (b) segmentation of regions of interest. (c) feature extraction and selection. and finally (d) classification. This paper presents the approaches which are applied to develop CAD systems on mammography and ultrasound images. The …,True,WldjVB4AAAAJ:z_wVstp3MssC,292,https://www.sciencedirect.com/science/article/pii/S0899707112002938,1385951771170412645,/scholar?cites=1385951771170412645,,,https://cdn.manesht.ir/17003___Computer-aided%20detection_diagnosis%20of%20breast%20cancer%20in%20mammography%20and%20ultrasound_%20a%20review.pdf,0,0,0
1278287,A framework for white blood cell segmentation in microscopic blood images using digital image processing,2009,Farnoosh Sadeghian and Zainina Seman and Abdul Rahman Ramli and BH Abdul Kahar and M-Iqbal Saripan,11,Biological procedures online,1,196-206,BioMed Central,Evaluation of blood smear is a commonly clinical test these days. Most of the time. the hematologists are interested on white blood cells (WBCs) only. Digital image processing techniques can help them in their analysis and diagnosis. For example. disease like acute leukemia is detected based on the amount and condition of the WBC. The main objective of this paper is to segment the WBC to its two dominant elements: nucleus and cytoplasm. The segmentation is conducted using a proposed segmentation framework that consists of an integration of several digital image processing algorithms. Twenty microscopic blood images were tested. and the proposed framework managed to obtain 92% accuracy for nucleus segmentation and 78% for cytoplasm segmentation. The results indicate that the proposed framework is able to extract the nucleus and cytoplasm region in a WBC image sample.,True,WldjVB4AAAAJ:vV6vV6tmYwMC,194,https://link.springer.com/article/10.1007/s12575-009-9011-2,11459468238452863229,/scholar?cites=11459468238452863229,,,https://link.springer.com/article/10.1007/s12575-009-9011-2,0,0,0
1278288,Preserving brightness in histogram equalization based contrast enhancement techniques,2004,Soong-Der Chen and Abd Rahman Ramli,14,Digital Signal Processing,5,413-428,Academic Press,Histogram equalization (HE) has been a simple yet effective image enhancement technique. However. it tends to change the brightness of an image significantly. causing annoying artifacts and unnatural contrast enhancement. Brightness preserving bi-histogram equalization (BBHE) and dualistic sub-image histogram equalization (DSIHE) have been proposed to overcome these problems but they may still fail under certain conditions. This paper proposes a novel extension of BBHE referred to as minimum mean brightness error bi-histogram equalization (MMBEBHE). MMBEBHE has the feature of minimizing the difference between input and output image's mean. Simulation results showed that MMBEBHE can preserve brightness better than BBHE and DSIHE. Furthermore. this paper also formulated an efficient. integer-based implementation of MMBEBHE. Nevertheless. MMBEBHE also has its limitation. Hence …,True,WldjVB4AAAAJ:RYcK_YlVTxYC,147,https://www.sciencedirect.com/science/article/pii/S1051200404000387,5727908887061323920,/scholar?cites=5727908887061323920,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.2847&rep=rep1&type=pdf,0,0,0
1278289,Vertical-edge-based car-license-plate detection method,2012,Abbas M Al-Ghaili and Syamsiah Mashohor and Abdul Rahman Ramli and Alyani Ismail,62,IEEE transactions on vehicular technology,1,26-38,IEEE,This paper proposes a fast method for car-license-plate detection (CLPD) and presents three main contributions. The first contribution is that we propose a fast vertical edge detection algorithm (VEDA) based on the contrast between the grayscale values. which enhances the speed of the CLPD method. After binarizing the input image using adaptive thresholding (AT). an unwanted-line elimination algorithm (ULEA) is proposed to enhance the image. and then. the VEDA is applied. The second contribution is that our proposed CLPD method processes very-low-resolution images taken by a web camera. After the vertical edges have been detected by the VEDA. the desired plate details based on color information are highlighted. Then. the candidate region based on statistical and logical operations will be extracted. Finally. an LP is detected. The third contribution is that we compare the VEDA to the Sobel operator in …,True,WldjVB4AAAAJ:tKAzc9rXhukC,129,https://ieeexplore.ieee.org/abstract/document/6320710/,12513772790876618318,/scholar?cites=12513772790876618318,,,,0,0,0
1278290,Survey on liver CT image segmentation methods,2012,Ahmed M Mharib and Abdul Rahman Ramli and Syamsiah Mashohor and Rozi Binti Mahmood,37,Artificial Intelligence Review,2,83-95,Springer Netherlands,The segmentation of liver using computed tomography (CT) data has gained a lot of importance in the medical image processing field. In this paper. we present a survey on liver segmentation methods and techniques using CT images. recent methods presented in the literature to obtain liver segmentation are viewed. Generally. liver segmentation methods are divided into two main classes. semi-automatic and fully automatic methods. under each of these two categories. several methods. approaches. related issues and problems will be defined and explained. The evaluation measurements and scoring for the liver segmentation are shown. followed by the comparative study for liver segmentation methods. pros and cons of methods will be accentuated carefully. In this paper. we concluded that automatic liver segmentation using CT images is still an open problem since various weaknesses and drawbacks …,True,WldjVB4AAAAJ:dQ2og3OwTAUC,100,https://link.springer.com/content/pdf/10.1007/s10462-011-9220-3.pdf,17854492576918048852,/scholar?cites=17854492576918048852,,,,0,0,0
1278291,A probabilistic Hough transform,1991,Nahum Kiryati and Yuval Eldar and Alfred M Bruckstein,24,Pattern recognition,4,303-316,Pergamon,The Hough Transform for straight line detection is considered. It is shown that if just a small subset of the edge points in the image. selected at random. is used as input for the Hough Transform. the performance is often only slightly impaired. thus the execution time can be considerably shortened. The performance of the resulting “Probabilistic Hough Transform” is analysed. The analysis is supported by experimental evidence.,True,9j-xnIUAAAAJ:u5HHmVD_uO8C,830,https://www.sciencedirect.com/science/article/pii/003132039190073E,7604827022638400900,/scholar?cites=7604827022638400900,,,https://freddy.cs.technion.ac.il/wp-content/uploads/2018/01/A-PROBABILISTIC-HOUGH-TRANSFORM.pdf,0,0,0
1278292,Range imaging with adaptive color structured light,1998,Dalit Caspi and Nahum Kiryati and Joseph Shamir,20,IEEE Transactions on Pattern analysis and machine intelligence,5,470-480,IEEE,In range sensing with time-multiplexed structured light. there is a trade-off between accuracy. robustness and the acquisition period. In this paper a novel structured light method is described. Adaptation of the number and form of the projection patterns to the characteristics of the scene takes place as part of the acquisition process. Noise margins are matched to the actual noise level. thus reducing the number of projection patterns to the necessary minimum. Color is used for light plane labeling. The dimension of the pattern space are thus increased without raising the number of projection patterns. It is shown that the color of an impinging light plane can be identified from the image of the illuminated scene. even with colorful scenes. Identification is local and does not rely on spatial color sequences. The suggested approach has been implemented and the theoretical results are supported by experiments.,True,9j-xnIUAAAAJ:u-x6o8ySG0sC,469,https://ieeexplore.ieee.org/abstract/document/682177/,8996128485437614271,/scholar?cites=8996128485437614271,,,https://www.researchgate.net/profile/Nahum_Kiryati/publication/3192841_Range_imaging_with_adaptive_color_structured_light/links/56b4883a08ae8cf9c25b20d8/Range-imaging-with-adaptive-color-structured-light.pdf,0,0,0
1278293,Texture mapping using surface flattening via multidimensional scaling,2002,Gil Zigelman and Ron Kimmel and Nahum Kiryati,8,IEEE Transactions on Visualization and Computer Graphics,2,198-207,IEEE,"Presents a novel technique for texture mapping on arbitrary surfaces with minimal distortion by preserving the local and global structure of the texture. The recent introduction of the fast marching method on triangulated surfaces has made it possible to compute a geodesic distance map from a given surface point in O(n lg n) operations. where n is the number of triangles that represent the surface. We use this method to design a surface flattening approach based on multi-dimensional scaling (MDS). MDS is a family of methods that map a set of points into a finite-dimensional flat (Euclidean) domain. where the only data given is the corresponding distance between every pair of points. The MDS mapping yields minimal changes of the distances between the corresponding points. We then solve an ""inverse"" problem and map a flat texture patch onto a curved surface while preserving the structure of the texture.",True,9j-xnIUAAAAJ:d1gkVwhDpl0C,336,https://ieeexplore.ieee.org/abstract/document/998671/,4142581365472420226,/scholar?cites=4142581365472420226,,,http://www.cs.technion.ac.il/users/wwwb/cgi-bin/tr-get.cgi/2000/CIS/CIS-2000-01.pdf,0,0,0
1278294,Depth from defocus vs. stereo: How different really are they?,2000,Yoav Y Schechner and Nahum Kiryati,39,International Journal of Computer Vision,2,141-162,Kluwer Academic Publishers,Depth from Focus (DFF) and Depth from Defocus (DFD) methods are theoretically unified with the geometric triangulation principle. Fundamentally. the depth sensitivities of DFF and DFD are not different than those of stereo (or motion) based systems having the same physical dimensions. Contrary to common belief. DFD does not inherently avoid the matching (correspondence) problem. Basically. DFD and DFF do not avoid the occlusion problem any more than triangulation techniques. but they are more stable in the presence of such disruptions. The fundamental advantage of DFF and DFD methods is the two-dimensionality of the aperture. allowing more robust estimation. We analyze the effect of noise in different spatial frequencies. and derive the optimal changes of the focus settings in DFD. These results elucidate the limitations of methods based on depth of field and provide a foundation for fair …,True,9j-xnIUAAAAJ:9yKSN-GCB0IC,322,https://link.springer.com/article/10.1023/A:1008175127327,1923575862338688598,/scholar?cites=1923575862338688598,,,http://www.ee.technion.ac.il/~yoav/publications/dfdstereot2a.pdf,0,0,0
1278295,MRI inter-slice reconstruction using super-resolution,2002,Hayit Greenspan and G Oz and N Kiryati and SLBG Peled,20,Magnetic resonance imaging,5,437-446,Elsevier,MRI reconstruction using super-resolution is presented and shown to improve spatial resolution in cases when spatially-selective RF pulses are used for localization. In 2-D multislice MRI. the resolution in the slice direction is often lower than the in-plane resolution. For certain diagnostic imaging applications. isotropic resolution is necessary but true 3-D acquisition methods are not practical. In this case. if the imaging volume is acquired two or more times. with small spatial shifts between acquisitions. combination of the data sets using an iterative super-resolution algorithm gives improved resolution and better edge definition in the slice-select direction. Resolution augmentation in MRI is important for visualization and early diagnosis. The method also improves the signal-to-noise efficiency of the data acquisition.,True,9j-xnIUAAAAJ:UeHWp8X0CEIC,275,https://www.sciencedirect.com/science/article/pii/S0730725X02005118,3976566453597526868,/scholar?cites=3976566453597526868,,,,0,0,0
1278296,Toward optimal structured light patterns,1999,Eli Horn and Nahum Kiryati,17,Image and Vision Computing,2,87-97,Elsevier,A methodology for the optimal design of projection patterns for stereometric structured light systems is presented. It draws on the similarity as well as the difference between the design of projection patterns and the design of optimal signals for digital communication. Seemingly unrelated structured light methods. such as the Gray code scheme and intensity ratio techniques. are unified as special cases within the suggested theoretical framework. The design of K projection patterns for a structured light system with L distinct planes of light turns out to be equivalent to the placement of L points in a K-dimensional space subject to certain constraints. Optimal design in the MSE sense can be defined. but leads to an intractable multi-parameter global optimization problem. Intuitively appealing suboptimal solutions are derived from the family of K-dimensional space-filling Hilbert curves. The theoretical results are supported …,True,9j-xnIUAAAAJ:2osOgNQ5qMEC,231,https://www.sciencedirect.com/science/article/pii/S0262885698001139,12304330190172902049,/scholar?cites=12304330190172902049,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.16.269&rep=rep1&type=pdf,0,0,0
1278297,Skeletonization via distance maps and level sets,1995,Ron Kimmel and Doron Shaked and Nahum Kiryati and Alfred M Bruckstein,62,Computer vision and image understanding,3,382-391,Academic Press,The medial axis transform (MAT) of a shape. better known as its skeleton. is frequently used in shape analysis and related areas. In this paper a new approach for determining the skeleton of an object is presented. The boundary is segmented at points of maximal positive curvature and a distance map from each of the segments is calculated. The skeleton is then located by applying simple rules to the zero sets of distance map differences. A framework is proposed for numerical approximation of distance maps that is consistent with the continuous case and hence does not suffer from digitization bias due to metrication errors of the implementation on the grid. Subpixel accuracy in distance map calculation is obtained by using gray-level information along the boundary of the shape in the numerical scheme. The accuracy of the resulting efficient skeletonization algorithm is demonstrated by several examples.,True,9j-xnIUAAAAJ:qjMakFHDy7sC,222,https://www.sciencedirect.com/science/article/pii/S1077314285710624,5588173808215688932,/scholar?cites=5588173808215688932,,,http://www.cs.technion.ac.il/~ron/PAPERS/skeletonization_CVIU_1995.pdf,0,0,0
1278298,Separation of transparent layers using focus,2000,Yoav Y Schechner and Nahum Kiryati and Ronen Basri,39,International Journal of Computer Vision,1,25-39,Kluwer Academic Publishers,Consider situations where the depth at each point in the scene is multi-valued. due to the presence of a virtual image semi-reflected by a transparent surface. The semi-reflected image is linearly superimposed on the image of an object that is behind the transparent surface. A novel approach is proposed for the separation of the superimposed layers. Focusing on either of the layers yields initial separation. but crosstalk remains. The separation is enhanced by mutual blurring of the perturbing components in the images. However. this blurring requires the estimation of the defocus blur kernels. We thus propose a method for self calibration of the blur kernels. given the raw images. The kernels are sought to minimize the mutual information of the recovered layers. Autofocusing and depth estimation in the presence of semi-reflections are also considered. Experimental results are presented.,True,9j-xnIUAAAAJ:IjCSPb-OGe4C,199,https://link.springer.com/article/10.1023/A:1008166017466,11599175397513102078,/scholar?cites=11599175397513102078,,,https://webee.technion.ac.il/Sites/People/OLD/yoav.new/publications/IJCVtransparent1.pdf,0,0,0
1278299,Multi-view scene flow estimation: A view centered variational approach,2013,Tali Basha and Yael Moses and Nahum Kiryati,101,International journal of computer vision,1,6-21,Springer US,We present a novel method for recovering the 3D structure and scene flow from calibrated multi-view sequences. We propose a 3D point cloud parametrization of the 3D structure and scene flow that allows us to directly estimate the desired unknowns. A unified global energy functional is proposed to incorporate the information from the available sequences and simultaneously recover both depth and scene flow. The functional enforces multi-view geometric consistency and imposes brightness constancy and piecewise smoothness assumptions directly on the 3D unknowns. It inherently handles the challenges of discontinuities. occlusions. and large displacements. The main contribution of this work is the fusion of a 3D representation and an advanced variational framework that directly uses the available multi-view information. This formulation allows us to advantageously bind the 3D unknowns in time and …,True,9j-xnIUAAAAJ:ZeXyd9-uunAC,183,https://link.springer.com/article/10.1007/s11263-012-0542-7,2845765856599316814,/scholar?cites=2845765856599316814,,,https://people.csail.mit.edu/talidekel/papers/MVSF_IJCV13.pdf,0,0,0
1278300,Polarization and statistical analysis of scenes containing a semireflector,2000,Yoav Y Schechner and Joseph Shamir and Nahum Kiryati,17,JOSA A,2,276-284,Optical Society of America,We present an approach to recover scenes deteriorated by reflections off a semireflecting medium (e.g.. a glass window). The method. based on imaging through a polarizer at two or more orientations. separates the reflected and transmitted scenes and determines which is which. We analyze the polarization effects. taking into account internal reflections within the medium. The scene reconstruction requires the estimation of the orientation (inclination and tilt angles) of the transparent (invisible) surface. The inclination angle is estimated by seeking the value that leads to the minimal mutual information of the estimated scenes. The limitations and the consequences of noise and angle error are discussed. including a fundamental ambiguity in the determination of the plane of incidence. Experimental results demonstrate the success of angle estimation and consequent scene separation and labeling.,True,9j-xnIUAAAAJ:Tyk-4Ss8FVUC,171,https://www.osapublishing.org/abstract.cfm?uri=JOSAA-17-2-276,4666421747029665715,/scholar?cites=4666421747029665715,,,https://webee.technion.ac.il/Sites/People/yoav/publications/polarjosa.pdf,0,0,0
1278301,Detecting symmetry in grey level images: The global optimization approach,1998,Nahum Kiryati and Yossi Gofman,29,International Journal of Computer Vision,1,29-45,Kluwer Academic Publishers,The detection of significant local reflectional symmetry in grey level images is considered. Prior segmentation is not assumed. and it is intended that the results could be used for guiding visual attention and for providing side information to segmentation algorithms. A local measure of reflectional symmetry that transforms the symmetry detection problem to a global optimization problem is defined. Reflectional symmetry detection becomes equivalent to finding the global maximum of a complicated multimodal function parameterized by the location of the center of the supporting region. its size. and the orientation of the symmetry axis. Unlike previous approaches. time consuming exhaustive search is avoided. A global optimization algorithm for solving the problem is presented. It is related to genetic algorithms and to adaptive random search techniques. The efficiency of the suggested algorithm is …,True,9j-xnIUAAAAJ:UebtZRa9Y70C,155,https://link.springer.com/article/10.1023/A:1008034529558,14264477457014725034,/scholar?cites=14264477457014725034,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.9796&rep=rep1&type=pdf,0,0,0
1278302,Image inpainting,2000,Marcelo Bertalmio and Guillermo Sapiro and Vincent Caselles and Coloma Ballester,,,,417-424,,Inpainting. the technique of modifying an image in an undetectable form. is as ancient as art itself. The goals and applications of inpainting are numerous. from the restoration of damaged paintings and photographs to the removal/replacement of selected objects. In this paper. we introduce a novel algorithm for digital inpainting of still images that attempts to replicate the basic techniques used by professional restorators. After the user selects the regions to be restored. the algorithm automatically fills-in these regions with information surrounding them. The fill-in is done in such a way that isophote lines arriving at the regions' boundaries are completed inside. In contrast with previous approaches. the technique here introduced does not require the user to specify where the novel information comes from. This is automatically done (and in a fast way). thereby allowing to simultaneously fill-in numerous regions containing …,True,fLNi-SoAAAAJ:u5HHmVD_uO8C,4631,https://dl.acm.org/doi/abs/10.1145/344779.344972,18010932247942108985,/scholar?cites=18010932247942108985,,,https://apps.dtic.mil/sti/pdfs/ADA437378.pdf,0,0,0
1278303,Filling-in by joint interpolation of vector fields and grey levels,2001,C Ballester and M Bertalmio and V Caselles and G Sapiro and J Verdera,10,IEEE Trans. Image Process,8,1200-1211,,A variational approach for filling-in regions of missing data in digital images is introduced. The approach is based on joint interpolation of the image gray levels and gradient/isophotes directions. smoothly extending in an automatic fashion the isophote lines into the holes of missing data. This interpolation is computed by solving the variational problem via its gradient descent flow. which leads to a set of coupled second order partial differential equations. one for the gray-levels and one for the gradient orientations. The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. No limitations are imposed on the topology of the holes. and all regions of missing data can be simultaneously processed. even if they are surrounded by completely different structures. Applications of this technique include the restoration of old photographs and removal of …,True,fLNi-SoAAAAJ:3fE2CSJIrl8C,911,https://ieeexplore.ieee.org/abstract/document/935036/,18096360950404421332,/scholar?cites=18096360950404421332,,,https://conservancy.umn.edu/bitstream/handle/11299/3462/1706.pdf?sequence=1,0,0,0
1278304,Minimizing total variation flow,2001,Fuensanta Andreu and Coloma Ballester and Vicent Caselles and José M Mazón,14,Differential and integral equations,3,321-360,Khayyam Publishing. Inc.,We prove existence and uniqueness of weak solutions for the minimizing total variation flow with initial data in . We prove that the length of the level sets of the solution. ie. the boundaries of the level sets. decreases with time. as one would expect. and the solution converges to the spatial average of the initial datum as . We also prove that local maxima strictly decrease with time; in particular. flat zones immediately decrease their level. We display some numerical experiments illustrating these facts.,True,fLNi-SoAAAAJ:d1gkVwhDpl0C,279,https://projecteuclid.org/euclid.die/1356123331,17324824751499764725,/scholar?cites=17324824751499764725,,,https://projecteuclid.org/download/pdf_1/euclid.die/1356123331,0,0,0
1278305,A variational model for P+ XS image fusion,2006,Coloma Ballester and Vicent Caselles and Laura Igual and Joan Verdera and Bernard Rougé,69,International Journal of Computer Vision,1,43-58,Kluwer Academic Publishers,We propose an algorithm to increase the resolution of multispectral satellite images knowing the panchromatic image at high resolution and the spectral channels at lower resolution. Our algorithm is based on the assumption that. to a large extent. the geometry of the spectral channels is contained in the topographic map of its panchromatic image. This assumption. together with the relation of the panchromatic image to the spectral channels. and the expression of the low-resolution pixel in terms of the high-resolution pixels given by some convolution kernel followed by subsampling. constitute the elements for constructing an energy functional (with several variants) whose minima will give the reconstructed spectral images at higher resolution. We discuss the validity of the above approach and describe our numerical procedure. Finally. some experiments on a set of multispectral satellite images are displayed.,True,fLNi-SoAAAAJ:qjMakFHDy7sC,258,https://link.springer.com/content/pdf/10.1007/s11263-006-6852-x.pdf,15901056040258163472,/scholar?cites=15901056040258163472,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.459.3396&rep=rep1&type=pdf,0,0,0
1278306,The Dirichlet problem for the total variation flow,2001,Fuensanta Andreu and Coloma Ballester and Vicent Caselles and José M Mazón,180,Journal of Functional Analysis,2,347-403,Academic Press,We introduce a new concept of solution for the Dirichlet problem for the total variational flow named entropy solution. Using Kruzhkov's method of doubling variables both in space and in time we prove uniqueness and a comparison principle in L1 for entropy solutions. To prove the existence we use the nonlinear semigroup theory and we show that when the initial and boundary data are nonnegative the semigroup solutions are strong solutions.,True,fLNi-SoAAAAJ:9yKSN-GCB0IC,171,https://www.sciencedirect.com/science/article/pii/S002212360093698X,5207610409917871392,/scholar?cites=5207610409917871392,,,https://www.sciencedirect.com/science/article/pii/S002212360093698X/pdf?md5=62781f55fcf324237147715ef7bf054c&pid=1-s2.0-S002212360093698X-main.pdf&_valck=1,0,0,0
1278307,Air pollution exposure during pregnancy and reduced birth size: a prospective birth cohort study in Valencia. Spain,2010,Ferran Ballester and Marisa Estarlich and Carmen Iñiguez and Sabrina Llop and Rosa Ramón and Ana Esplugues and Marina Lacasaña and Marisa Rebagliato,9,Environmental Health,1,6,BioMed Central,Maternal exposure to air pollution has been related to fetal growth in a number of recent scientific studies. The objective of this study was to assess the association between exposure to air pollution during pregnancy and anthropometric measures at birth in a cohort in Valencia. Spain. Seven hundred and eighty-five pregnant women and their singleton newborns participated in the study. Exposure to ambient nitrogen dioxide (NO2) was estimated by means of land use regression. NO2 spatial estimations were adjusted to correspond to relevant pregnancy periods (whole pregnancy and trimesters) for each woman. Outcome variables were birth weight. length. and head circumference (HC). along with being small for gestational age (SGA). The association between exposure to residential outdoor NO2 and outcomes was assessed controlling for potential confounders and examining the shape of the relationship using generalized additive models (GAM). For continuous anthropometric measures. GAM indicated a change in slope at NO2 concentrations of around 40 μg/m3. NO2 exposure >40 μg/m3 during the first trimester was associated with a change in birth length of -0.27 cm (95% CI: -0.51 to -0.03) and with a change in birth weight of -40.3 grams (-96.3 to 15.6); the same exposure throughout the whole pregnancy was associated with a change in birth HC of -0.17 cm (-0.34 to -0.003). The shape of the relation was seen to be roughly linear for the risk of being SGA. A 10 μg/m3 increase in NO2 during the second trimester was associated with being SGA-weight. odds ratio (OR): 1.37 (1.01-1.85). For SGA-length the estimate for the same comparison …,True,fLNi-SoAAAAJ:Tyk-4Ss8FVUC,170,https://ehjournal.biomedcentral.com/articles/10.1186/1476-069X-9-6,14073093406365277584,/scholar?cites=14073093406365277584,,,https://ehjournal.biomedcentral.com/articles/10.1186/1476-069X-9-6,0,0,0
1278308,A variational model for filling-in gray level and color images,2001,Coloma Ballester and Vicent Caselles and Joan Verdera and Marcelo Bertalmio and Guillermo Sapiro,1,,,10-16,IEEE,A variational approach for filling-in regions of missing data in gray-level and color images is introduced in this paper. The approach is based on joint interpolation of the image gray-levels and gradient/isophores directions. smoothly extending in an automatic fashion the isophote lines into the holes of missing data. This interpolation is computed solving the variational problem via its gradient descent flow. which lends to a set of coupled second order partial differential equations. one for the gray-levels and one for the gradient orientations. The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. No limitations are imposed on the topology of the holes. and all regions of missing data can be simultaneously processed. even if they are surrounded by completely different structures. Applications of this technique include the restoration of old photographs …,True,fLNi-SoAAAAJ:2osOgNQ5qMEC,109,https://ieeexplore.ieee.org/abstract/document/937493/,11460057380095442714,/scholar?cites=11460057380095442714,,,https://www.researchgate.net/profile/C_Ballester/publication/3906027_A_variational_model_for_filling-in_gray_level_and_color_images/links/02e7e52c7c94a754aa000000.pdf,0,0,0
1278309,A TV based restoration model with local constraints,2008,Andrés Almansa and Coloma Ballester and Vicent Caselles and Gloria Haro,34,Journal of Scientific Computing,3,209-236,Springer US, We propose in this paper a total variation based restoration model which incorporates the image acquisition model z=h * U+n (where z represents the observed sampled image. U is the ideal undistorted image. h denotes the blurring kernel and n is a white Gaussian noise) as a set of local constraints. These constraints. one for each pixel of the image. express the fact that the variance of the noise can be estimated from the residuals z−h * U if we use a neighborhood of each pixel. This is motivated by the fact that the usual inclusion of the image acquisition model as a single constraint expressing a bound for the variance of the noise does not give satisfactory results if we wish to simultaneously recover textured regions and obtain a good denoising of the image. We use Uzawa’s algorithm to minimize the total variation subject to the proposed family of local …,True,fLNi-SoAAAAJ:eQOLeE2rZwMC,68,https://link.springer.com/article/10.1007/s10915-007-9160-x,3923289178899410512,/scholar?cites=3923289178899410512,,,https://conservancy.umn.edu/bitstream/handle/11299/4297/2119.pdf?sequence%3D1,0,0,0
1278310,The tree of shapes of an image,2003,Coloma Ballester and Vicent Caselles and Pascal Monasse,9,"ESAIM: Control, Optimisation and Calculus of Variations",,1-18,EDP Sciences,Mathematical morphology is able to deal with contrast invariant objects. the most basic ones being the (upper) level sets [u≥ λ]={x. u (x)≥ λ}. or the level lines∂[u≥ λ] of the image u [32. 40–42. 45. 46]. They are said to be contrast invariant. since. for any increasing continuous function g. the level sets of g◦ u are globally the same as the level sets of u. modulo a change of level. Many tasks can be efficiently addressed,True,fLNi-SoAAAAJ:XiSMed-E-HIC,64,http://www.numdam.org/item/COCV_2003__9__1_0/,17608677244008319381,/scholar?cites=17608677244008319381,,,http://www.numdam.org/article/COCV_2003__9__1_0.pdf,0,0,0
1278311,Disocclusion by joint interpolation of vector fields and gray levels,2003,Coloma Ballester and Vicent Caselles and Joan Verdera,2,Multiscale Modeling & Simulation,1,80-123,Society for Industrial and Applied Mathematics,In this paper we study a variational approach for filling in regions of missing data in two-dimensional and three-dimensional digital images. Applications of this technique include the restoration of old photographs and removal of superimposed text like dates. subtitles. or publicity. or the zooming of images. The approach presented here. initially introduced in [IEEE Trans. Image Process.. 10 (2001). pp. 1200--1211] is based on a joint interpolation of the image gray levels and gradient/isophotes directions. smoothly extending the isophote lines into the holes of missing data. The process underlying this approach can be considered as an interpretation of the Gestaltist's principle of good continuation. We study the existence of minimizers of our functional and its approximation by minima of smoother functionals. Then we present the numerical algorithm used to minimize it and display some numerical experiments.,True,fLNi-SoAAAAJ:zYLM7Y9cAGgC,62,https://epubs.siam.org/doi/abs/10.1137/S1540345903422458,2235927525268122743,/scholar?cites=2235927525268122743,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.580.5464&rep=rep1&type=pdf,0,0,0
1278312,A TV-L1 optical flow method with occlusion detection,2012,Coloma Ballester and Lluis Garrido and Vanel Lazcano and Vicent Caselles,,,,31-40,Springer. Berlin. Heidelberg,In this paper we propose a variational model for joint optical flow and occlusion estimation. Our work stems from the optical flow method based on a TV-L 1 approach and incorporates information that allows to detect occlusions. This information is based on the divergence of the flow and the proposed energy favors the location of occlusions on regions where this divergence is negative. Assuming that occluded pixels are visible in the previous frame. the optical flow on non-occluded pixels is forward estimated whereas is backwards estimated on the occluded ones. We display some experiments showing that the proposed model is able to properly estimate both the optical flow and the occluded regions.,True,fLNi-SoAAAAJ:qxL8FJ1GzNcC,52,https://link.springer.com/chapter/10.1007/978-3-642-32717-9_4,8414747153853770317,/scholar?cites=8414747153853770317,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.352.5056&rep=rep1&type=pdf,0,0,0
1278313,Using imaging spectroscopy to study soil properties,2009,E Ben-Dor and Sabine Chabrillat and J Al M Demattê and GR Taylor and J Hill and ML Whiting and S Sommer,113,Remote sensing of environment,,S38-S55,Elsevier,Imaging Spectroscopy (IS) is a promising tool for studying soil properties in large spatial domains. Going from point to image spectrometry is not only a journey from micro to macro scales. but also a long stage where problems such as dealing with data having a low signal-to-noise level. contamination of the atmosphere. large data sets. the BRDF effect and more are often encountered. In this paper we provide an up-to-date overview of some of the case studies that have used IS technology for soil science applications. Besides a brief discussion on the advantages and disadvantages of IS for studying soils. the following cases are comprehensively discussed: soil degradation (salinity. erosion. and deposition). soil mapping and classification. soil genesis and formation. soil contamination. soil water content. and soil swelling. We review these case studies and suggest that the IS data be provided to the end-users as …,True,Lm4DoLQAAAAJ:u-x6o8ySG0sC,470,https://www.sciencedirect.com/science/article/pii/S0034425709000753,16121362560761666975,/scholar?cites=16121362560761666975,,,https://www.researchgate.net/profile/Eyal_Ben-Dor/publication/223042783_Using_Imaging_Spectroscopy_to_study_soil_properties/links/5a38c7620f7e9b7c487002e4/Using-Imaging-Spectroscopy-to-study-soil-properties.pdf,0,0,0
1278314,Remote sensing of forest biophysical variables using HyMap imaging spectrometer data,2005,Martin Schlerf and Clement Atzberger and Joachim Hill,95,Remote Sensing of Environment,2,177-194,Elsevier,This study systematically evaluated linear predictive models between vegetation indices (VI) derived from radiometrically corrected airborne imaging spectrometer (HyMap) data and field measurements of biophysical forest stand variables (n=40). Ratio-based and soil-line-related broadband VI were calculated after HyMap reflectance had been spectrally resampled to Landsat TM channels. Hyperspectral VI involved all possible types of two-band combinations of ratio VI (RVI) and perpendicular VI (PVI) and the red edge inflection point (REIP) computed from two techniques. inverted Gaussian Model and Lagrange Interpolation. Cross-validation procedure was used to assess the prediction power of the regression models. Analyses were performed on the entire data set or on subsets stratified according to stand age. A PVI based on wavebands at 1088 nm and 1148 nm was linearly related to leaf area index (LAI) (R …,True,Lm4DoLQAAAAJ:u5HHmVD_uO8C,391,https://www.sciencedirect.com/science/article/pii/S0034425705000143,14787545117219608538,/scholar?cites=14787545117219608538,,,,0,0,0
1278315,The EnMAP spaceborne imaging spectroscopy mission for earth observation,2015,Luis Guanter and Hermann Kaufmann and Karl Segl and Saskia Foerster and Christian Rogass and Sabine Chabrillat and Theres Kuester and André Hollstein and Godela Rossner and Christian Chlebek and Christoph Straif and Sebastian Fischer and Stefanie Schrader and Tobias Storch and Uta Heiden and Andreas Mueller and Martin Bachmann and Helmut Mühle and Rupert Müller and Martin Habermeyer and Andreas Ohndorf and Joachim Hill and Henning Buddenbaum and Patrick Hostert and Sebastian Van der Linden and Pedro J Leitao and Andreas Rabe and Roland Doerffer and Hajo Krasemann and Hongyan Xi and Wolfram Mauser and Tobias Hank and Matthias Locherer and Michael Rast and Karl Staenz and Bernhard Sang,7,,7,8830-8857,Multidisciplinary Digital Publishing Institute,Imaging spectroscopy. also known as hyperspectral remote sensing. is based on the characterization of Earth surface materials and processes through spectrally-resolved measurements of the light interacting with matter. The potential of imaging spectroscopy for Earth remote sensing has been demonstrated since the 1980s. However. most of the developments and applications in imaging spectroscopy have largely relied on airborne spectrometers. as the amount and quality of space-based imaging spectroscopy data remain relatively low to date. The upcoming Environmental Mapping and Analysis Program (EnMAP) German imaging spectroscopy mission is intended to fill this gap. An overview of the main characteristics and current status of the mission is provided in this contribution. The core payload of EnMAP consists of a dual-spectrometer instrument measuring in the optical spectral range between 420 and 2450 nm with a spectral sampling distance varying between 5 and 12 nm and a reference signal-to-noise ratio of 400: 1 in the visible and near-infrared and 180: 1 in the shortwave-infrared parts of the spectrum. EnMAP images will cover a 30 km-wide area in the across-track direction with a ground sampling distance of 30 m. An across-track tilted observation capability will enable a target revisit time of up to four days at the Equator and better at high latitudes. EnMAP will contribute to the development and exploitation of spaceborne imaging spectroscopy applications by making high-quality data freely available to scientific users worldwide. View Full-Text,True,Lm4DoLQAAAAJ:UebtZRa9Y70C,372,https://www.mdpi.com/2072-4292/7/7/8830,2887823414929034391,/scholar?cites=2887823414929034391,,,https://www.mdpi.com/2072-4292/7/7/8830/pdf,0,0,0
1278316,Mediterranean desertification and land degradation: mapping related land use change syndromes based on satellite observations,2008,Joachim Hill and Marion Stellmes and Th Udelhoven and Achim Röder and Stefan Sommer,64,,3-4,146-157,Elsevier,In past decades. the European Mediterranean has undergone widespread land use transformations. These are largely driven by changes of socio-economic conditions. such as accession to the European Community. and had strong effects on the way the land is being used. Aiming at a systematic description of such change processes on a global level. the syndrome concept was proposed to describe archetypical. co-evolutionary patterns of human–nature interactions. and has been specifically linked to the desertification issue.In this study. we present an adaptation of the syndrome approach to the Iberian Peninsula. We suggest a data processing and interpretation framework to map the spatial extent of specific syndromes. The mapping approach is based on the time series analysis of satellite data. We have characterized vegetation dynamics using NDVI estimates from the coarse scale. hyper-temporal 1-km …,True,Lm4DoLQAAAAJ:d1gkVwhDpl0C,291,https://www.sciencedirect.com/science/article/pii/S0921818108001252,14133913738885154478,/scholar?cites=14133913738885154478,,,https://ubt.opus.hbz-nrw.de/opus45-ubtr/files/430/Dissertation_Stellmes.pdf#page=66,0,0,0
1278317,Use of coupled canopy structure dynamic and radiative transfer models to estimate biophysical canopy characteristics,2005,Benjamin Koetz and Frédéric Baret and Hervé Poilvé and Joachim Hill,95,Remote Sensing of Environment,1,115-124,Elsevier,Leaf area index (LAI) is a key variable for the understanding of several eco-physiological processes within a vegetation canopy. The LAI could thus provide vital information for the management of the environment and agricultural practices when estimated continuously over time and space thanks to remote sensing sensors.This study proposed a method to estimate LAI spatial and temporal variation based on multi-temporal remote sensing observations processed using a simple semi-mechanistic canopy structure dynamic model (CSDM) coupled with a radiative transfer model (RTM). The CSDM described the temporal evolution of the LAI as function of the accumulated daily air temperature as measured from classical ground meteorological stations.The retrieval performances were evaluated for two different data sets: first. a data set simulated by the RTM but taking into account realistic measurement conditions and …,True,Lm4DoLQAAAAJ:2osOgNQ5qMEC,234,https://www.sciencedirect.com/science/article/pii/S0034425704003736,9453377329880415262,/scholar?cites=9453377329880415262,,,https://www.academia.edu/download/42009359/Use_of_coupled_canopy_structure_dynamic_20160203-30232-fa2kwx.pdf,0,0,0
1278318,Using long time series of Landsat data to monitor fire events and post-fire dynamics and identify driving factors. A case study in the Ayora region (eastern Spain),2008,Achim Röder and Joachim Hill and Beatriz Duguy and José Antonio Alloza and Ramon Vallejo,112,Remote sensing of environment,1,259-273,Elsevier,The Ayora region. situated about 60 km southwest of the city of Valencia/Spain. was chosen to demonstrate pathways of characterizing fire events and post-fire succession in Mediterranean ecosystems using multi-temporal satellite imagery. A corresponding time series of 6 Landsat MSS. 13 Landsat-5 TM and 1 Landsat-7 ETM + images. covering the period 1975—2000. was processed to account for geometric and radiometric distortions as well as sensor calibration. Spectral Mixture Analysis was applied to derive estimates of photosynthetic active green vegetation cover as a primary indicator.A combination of pixel-based linear trend analysis and diachronic thresholding was employed to procure a fire perimeter data base and characterize post-fire dynamics based on a temporally stratified trend analysis. The results were integrated with auxiliary information to evaluate driving factors and further interpreted in …,True,Lm4DoLQAAAAJ:qjMakFHDy7sC,206,https://www.sciencedirect.com/science/article/pii/S0034425707001964,9552841084387215366,/scholar?cites=9552841084387215366,,,https://www.academia.edu/download/45703248/j.rse.2007.05.00120160517-26672-1z9qm.pdf,0,0,0
1278319,Radiometric correction of multitemporal Thematic Mapper data for use in agricultural land-cover classification and vegetation monitoring,1991,Joachim Hill and Boris Sturm,12,International Journal of Remote Sensing,7,1471-1491,Taylor & Francis Group,Many remote sensing applications. especially multitemporal approaches. require radiometric corrections of image data in which radiometric normalization to standard conditions and modelistic atmospheric corrections are often considered as alternative solutions. Successful radiometric normalization depends on the availability of suitable reference targets within the scenes under considerations. which may be critical. It is demonstrated that even simplified atmospheric correction modelling can provide a valuable alternative solution. We present an atmospheric correction approach for Thematic Mapper data. which is based solely on the evaluation of scene information and may therefore be considered operational. The method is based on the determination of aerosol optical thickness from histogram minima and clear water targets. Atmospheric conditions are assumed constant over the scene. but their variation with …,True,Lm4DoLQAAAAJ:9yKSN-GCB0IC,200,https://www.tandfonline.com/doi/abs/10.1080/01431169108955184,2615911799776200536,/scholar?cites=2615911799776200536,,,,0,0,0
1278320,Monitoring and assessment of land degradation and desertification: towards new conceptual and integrated approaches,2011,JV Vogt and Uriel Safriel and Graeme Von Maltitz and Youba Sokona and Robert Zougmore and Gary Bastin and Joachim Hill,22,Land Degradation & Development,2,150-165,John Wiley & Sons. Ltd.,The implementation of the United Nations Convention to Combat Desertification (UNCCD) needs agreed. scientifically sound and practical methodologies for monitoring and assessing the state and trend of land degradation as well as for monitoring the performance of management programmes. The lack of sufficient and integrated monitoring and assessment (M&A) has in the past been identified as a major constraint for combating desertification. Implementing efficient M&A programmes. however. requires careful analysis of the information needs of the different stakeholders. a clear scientific concept of the processes and drivers of land degradation and an analysis of the theoretical and practical possibilities for adequate M&A. This paper briefly analyses the information needs of diverse stakeholders. reviews existing M&A systems. and highlights key aspects for a scientifically sound approach to monitoring and …,True,Lm4DoLQAAAAJ:eQOLeE2rZwMC,194,https://onlinelibrary.wiley.com/doi/abs/10.1002/ldr.1075,1032402766569244576,/scholar?cites=1032402766569244576,,,https://www.academia.edu/download/52494487/Monitoring_and_assessment_of_land_degrad20170405-6005-1bxhoe2.pdf,0,0,0
1278321,Coupling spectral unmixing and trend analysis for monitoring of long-term vegetation dynamics in Mediterranean rangelands,2003,Patrick Hostert and Achim Röder and Joachim Hill,87,Remote sensing of environment,2-3,183-197,Elsevier,The development of vegetation cover is one of the primary indicators for land degradation. stability. or regeneration in regions threatened by overgrazing. This paper addresses the problem how spatially explicit information about degradation processes in European Mediterranean rangelands can be derived from long time series of satellite data. The selected test site in central Crete. Greece. is considered to be representative for the highly heterogeneous character of such landscapes. The monitoring approach comprises the time period between 1977 and 1996. covered by nine Landsat TM and four Landsat MSS images.Special emphasis has hence been put on the evaluation of potentials and drawbacks when coupling Landsat TM and MSS based results. The data sets were geometrically and radiometrically pre-processed in a rigorous fashion. followed by a linear spectral unmixing approach and a time series …,True,Lm4DoLQAAAAJ:UeHWp8X0CEIC,186,https://www.sciencedirect.com/science/article/pii/S0034425703001457,6770012688202026818,/scholar?cites=6770012688202026818,,,,0,0,0
1278322,World atlas of desertification: Rethinking land degradation and sustainable land management,2018,Michael Cherlet and Charles Hutchinson and James Reynolds and Joachim Hill and Stefan Sommer and Graham Von Maltitz,,,,,Publications Office of the European Union,,True,Lm4DoLQAAAAJ:VaXvl8Fpj5cC,185,http://scholar.google.com/scholar?cluster=7926918541754642532&hl=en&oi=scholarr,7926918541754642532,/scholar?cites=7926918541754642532,,,,0,0,0
1278323,Mapping complex patterns of erosion and stability in dry Mediterranean ecosystems,2000,Joachim Hill and Brigitta Schütt,74,Remote sensing of environment,3,557-569,Elsevier,Parametrizing soil reflectance spectra with variables related to specific shape characteristics of the spectral profile permits organic carbon concentrations in soils to be estimated on the basis of regionally validated regression models. An important feature of the approach is that it can not only be applied to continuous spectra but. without notable loss in accuracy. also to the spectral resolution of operational earth observation satellites such as the Landsat-TM or -ETM systems. Using this type of imagery. it can also be shown that soil organic matter is positively correlated to growth conditions for cereal crops in dryland agriculture. Strong correlations with qualitative erosion indicators that can be derived through spectral unmixing approaches demonstrate that soil organic matter is an important indicator for assessing land degradation processes in dry ecosystems from space.,True,Lm4DoLQAAAAJ:IjCSPb-OGe4C,163,https://www.sciencedirect.com/science/article/pii/S0034425700001462,5420094961300292281,/scholar?cites=5420094961300292281,,,https://www.geo.fu-berlin.de/geog/fachrichtungen/physgeog/medien/download/bschuett/hill_schuett-2000.pdf,0,0,0
1278324,First demonstration of airborne SAR tomography using multibaseline L-band data,2000,Andras Reigber and Alberto Moreira,38,"Geoscience and Remote Sensing, IEEE Transactions on",5,2142-2152,IEEE,In synthetic aperture radar (SAR) interferometry. the phase differences between two different sensor positions are used to estimate the terrain topography. Although it is possible in this way to find a three-dimensional (3D) surface representation. the distribution of the different scatterers in the height direction at a fixed range and azimuth position remains unknown. Contrary to this. tomographic techniques enable a real geometric resolution capability in the height direction and introduce new possibilities for many applications and inversion problems. Even misinterpretations in SAR images caused by layover and foreshortening effects can be solved by the tomographic processing. In this paper. the successful experimental realization of polarimetric airborne SAR tomography is demonstrated for the first time. The authors present the concept of aperture synthesis for tomographic imaging for the case of a multibaseline …,True,XeOWbR0AAAAJ:WqliGbK-hY8C,968,https://ieeexplore.ieee.org/abstract/document/868873/,15714752395299106571,/scholar?cites=15714752395299106571,,,https://people.eecs.ku.edu/~callen58/826/Reigber2000GRSpp2142-2152.pdf,0,0,0
1278325,A new technique for noise filtering of SAR interferometric phase images,1998,Jong-Sen Lee and Konstantinos P Papathanassiou and Thomas L Ainsworth and Mitchell R Grunes and Andreas Reigber,36,IEEE Transactions on Geoscience and Remote Sensing,5,1456-1465,IEEE,This paper addresses the noise filtering problem for synthetic aperture radar (SAR) interferometric phase images. The phase noise is characterized by an additive noise model. The model is verified with an L-band shuttle imaging radar (SIR)-C interferogram. An adaptive filtering algorithm based on this noise model is developed. It emphasizes filtering noise adaptively according to the local noise level and filtering along fringes using directionally dependent windows. This algorithm is effective. especially for the tightly packed fringes of X-band interferometry. Using simulated and SIR-C/X-SAR repeat-pass generated interferograms. the effectiveness of this filter is demonstrated by its capabilities in residue reduction. adaptive noise filtering. and its ability to filter areas with high fringe rates. In addition. a scheme of incorporating this filtering algorithm in iterative phase unwrapping using a least-squares method is proposed.,True,XeOWbR0AAAAJ:u5HHmVD_uO8C,449,https://ieeexplore.ieee.org/abstract/document/718849/,5062505879533953980,/scholar?cites=5062505879533953980,,,,0,0,0
1278326,NL-SAR: A unified nonlocal framework for resolution-preserving (Pol)(In) SAR denoising,2014,Charles-Alban Deledalle and Loïc Denis and Florence Tupin and Andreas Reigber and Marc Jäger,53,IEEE Transactions on Geoscience and Remote Sensing,4,2021-2038,IEEE,Speckle noise is an inherent problem in coherent imaging systems such as synthetic aperture radar. It creates strong intensity fluctuations and hampers the analysis of images and the estimation of local radiometric. polarimetric. or interferometric properties. Synthetic aperture radar (SAR) processing chains thus often include a multilooking (i.e.. averaging) filter for speckle reduction. at the expense of a strong resolution loss. Preservation of point-like and fine structures and textures requires to adapt locally the estimation. Nonlocal (NL)-means successfully adapt smoothing by deriving data-driven weights from the similarity between small image patches. The generalization of nonlocal approaches offers a flexible framework for resolution-preserving speckle reduction. We describe a general method. i.e.. NL-SAR. that builds extended nonlocal neighborhoods for denoising amplitude. polarimetric. and/or interferometric …,True,XeOWbR0AAAAJ:4MWp96NkSFoC,336,https://ieeexplore.ieee.org/abstract/document/6905794/,16195860779042672572,/scholar?cites=16195860779042672572,,,https://hal.archives-ouvertes.fr/docs/00/84/41/18/PDF/nlsar_hal.pdf,0,0,0
1278327,Estimation of forest structure. ground. and canopy layer characteristics from multibaseline polarimetric interferometric SAR data,2009,Maxim Neumann and Laurent Ferro-Famil and Andreas Reigber,48,IEEE Transactions on Geoscience and Remote Sensing,3,1086-1104,IEEE,This paper concerns forest parameter retrieval from polarimetric interferometric synthetic aperture radar (PolInSAR) data considering two layers. one for the ground under the vegetation and one for the volumetric canopy. A model is designed to combine a physical model-based polarimetric decomposition with the random-volume-over-ground (RVoG) PolInSAR parameter inversion approach. The combination of a polarimetric scattering media model with a PolInSAR RVoG vertical structure model provides the possibility to separate the ground and the volume coherency matrices based on polarimetric signatures and interferometric coherence diversity. The proposed polarimetric decomposition characterizes volumetric media by the degree of polarization orientation randomness and by the particle scattering anisotropy. Using the full model enhances the estimation of the vertical forest structure parameters by …,True,XeOWbR0AAAAJ:roLk4NBRz8UC,227,https://ieeexplore.ieee.org/abstract/document/5299063/,12405268775017178808,/scholar?cites=12405268775017178808,,,https://elib.dlr.de/54774/1/IEEEXplore.pdf,0,0,0
1278328,Very-high-resolution airborne synthetic aperture radar imaging: Signal processing and applications,2012,Andreas Reigber and Rolf Scheiber and Marc Jager and Pau Prats-Iraola and Irena Hajnsek and Thomas Jagdhuber and Konstantinos P Papathanassiou and Matteo Nannini and Esteban Aguilera and Stefan Baumgartner and Ralf Horn and Anton Nottensteiner and Alberto Moreira,101,Proceedings of the IEEE,3,759-783,IEEE,During the last decade. synthetic aperture radar (SAR) became an indispensable source of information in Earth observation. This has been possible mainly due to the current trend toward higher spatial resolution and novel imaging modes. A major driver for this development has been and still is the airborne SAR technology. which is usually ahead of the capabilities of spaceborne sensors by several years. Today's airborne sensors are capable of delivering high-quality SAR data with decimeter resolution and allow the development of novel approaches in data analysis and information extraction from SAR. In this paper. a review about the abilities and needs of today's very high-resolution airborne SAR sensors is given. based on and summarizing the longtime experience of the German Aerospace Center (DLR) with airborne SAR technology and its applications. A description of the specific requirements of high …,True,XeOWbR0AAAAJ:2KloaMYe4IUC,196,https://ieeexplore.ieee.org/abstract/document/6355595/,9656997569278561385,/scholar?cites=9656997569278561385,,,https://elib.dlr.de/76425/1/Reigber-06355595.pdf,0,0,0
1278329,Extended wavenumber-domain synthetic aperture radar focusing with integrated motion compensation,2006,Andreas Reigber and E Alivizatos and A Potsis and Alberto Moreira,153,"IEE Proceedings-Radar, Sonar and Navigation",3,301-310,IET Digital Library,Modern synthetic aperture radar (SAR) systems are continually developing in the direction of higher spatial resolution. This requires the usage of high range bandwidths combined with long azimuth integration intervals. High-quality SAR processing methods. which are able to deal with such sensor parameters. are necessary for focusing the raw data of such sensors. Wavenumber-domain (ω–k) processing is commonly accepted as the ideal solution to the SAR focusing problem. However. it is only applicable to spaceborne SAR data where a straight sensor trajectory is given. In the case of airborne data. wavenumber-domain processing is limited because of its inability to perform high-precision motion compensation. Here. the extended chirp scaling (ECS) algorithm has proven to be very powerful. although it has certain limitations concerning long aperture syntheses and highly squinted geometries. In the paper. a …,True,XeOWbR0AAAAJ:Tyk-4Ss8FVUC,190,https://digital-library.theiet.org/content/journals/10.1049/ip-rsn_20045087,11238701748371069499,/scholar?cites=11238701748371069499,,,https://www.researchgate.net/profile/Alberto_Moreira/publication/3357927_Extended_wavenumber-domain_synthetic_aperture_radar_focusing_with_integrated_motion_compensation/links/00b4951ccc4bb99e83000000.pdf,0,0,0
1278330,Adaptive spectral estimation for multibaseline SAR tomography with airborne L-band data,2003,Fabrizio Lombardini and Andreas Reigber,3,,,2014-2016,IEEE,In the recent years there has been growing interest in exploiting multibaseline (MB) SAR interferometry in a tomographic framework. to produce full 3D imaging eg of forest layers. However. Fourier-based MB SAR tomography is generally affected by unsatisfactory imaging quality due to a typically low number of baselines and their irregular distribution. In this work. we apply the more modern adaptive Capon spectral estimator to the vertical image reconstruction problem. using real airborne MB data. A first demonstration of possible imaging enhancement in real-world conditions is given.,True,XeOWbR0AAAAJ:u-x6o8ySG0sC,189,https://www.cv.tu-berlin.de/fileadmin/fg140/Adaptive_Spectral_Estimation_for.pdf,15558814031208420835,/scholar?cites=15558814031208420835,,,https://www.cv.tu-berlin.de/fileadmin/fg140/Adaptive_Spectral_Estimation_for.pdf,0,0,0
1278331,TOPS interferometry with TerraSAR-X,2012,Pau Prats-Iraola and Rolf Scheiber and Luca Marotti and Steffen Wollstadt and Andreas Reigber,50,IEEE Transactions on geoscience and remote sensing,8,3179-3188,IEEE,This paper presents results on SAR interferometry for data acquired in the Terrain Observation by Progressive Scans (TOPS) imaging mode. The rationale to retrieve accurate interferometric products in this mode is expounded. emphasizing the critical step of coregistration. Due to the particularities of the TOPS mode. a high Doppler centroid is present at burst edges. demanding a very high azimuth coregistration performance. A coregistration accuracy of around one tenth of a pixel. as it is usually recommended for stripmap interferometric data. could result in large undesired azimuth phase ramps in each TOPS burst. This paper presents two approaches based on the spectral diversity technique to precisely estimate this coregistration offset with the required accuracy and evaluates their performance. The effect of squint at burst edges in terms of an undesired impulse response shift during focusing and the impact on …,True,XeOWbR0AAAAJ:eq2jaN3J8jMC,179,https://ieeexplore.ieee.org/abstract/document/6130599/,16257714392460426877,/scholar?cites=16257714392460426877,,,https://elib.dlr.de/70103/1/prats_TGRS2012_TOPS_InSAR_with_TSX.pdf,0,0,0
1278332,Fully polarimetric high-resolution 3-D imaging with circular SAR at L-band,2013,Octavio Ponce and Pau Prats-Iraola and Muriel Pinheiro and Marc Rodriguez-Cassola and Rolf Scheiber and Andreas Reigber and Alberto Moreira,52,IEEE Transactions on Geoscience and Remote Sensing,6,3074-3090,IEEE,This paper presents the first fully polarimetric high-resolution circular synthetic aperture radar (CSAR) images at L-band (1.3 GHz). The circular data were acquired in 2008 by the Experimental SAR (E-SAR) airborne system of the German Aerospace Center (DLR) over the airport of Kaufbeuren. Germany. The obtained images resulting from the coherent integration of the whole circular flight are investigated and discussed in terms of two of the main CSAR properties. namely. the theoretical subwavelength resolution in the horizontal plane (x. y) and the 3-D imaging capabilities. The 3-D imaging capabilities are of special interest due to the penetration of L-band in vegetated areas. These results were compared with images processed by the incoherent addition of the full synthetic aperture. The coherent approach showed a better performance since scatterers are focused at their maximum resolution. Due to the …,True,XeOWbR0AAAAJ:BwyfMAYsbu0C,152,https://ieeexplore.ieee.org/abstract/document/6557505/,3676468298727193122,/scholar?cites=3676468298727193122,,,https://www.researchgate.net/profile/Alberto_Moreira/publication/257008571_Fully-Polarimetric_High-Resolution_3-D_Imaging_with_Circular_SAR_at_L-Band/links/02e7e52891da3c03bd000000.pdf,0,0,0
1278333,Scene characterization using subaperture polarimetric SAR data,2003,Laurent Ferro-Famil and Andreas Reigber and Eric Pottier and W-M Boerner,41,IEEE Transactions on Geoscience and Remote Sensing,10,2264-2276,IEEE,In synthetic aperture radar (SAR) polarimetry. the measured polarimetric signatures are used to analyze physical scattering properties of the imaged media. It is generally assumed that the sensor has a fixed orientation with respect to the objects. However. SAR sensors operating at lower frequencies. like L- and P-band. have a wide azimuth beamwidth. i.e.. during the formation of the synthetic aperture. multiple squint angles are integrated to build the full-resolution SAR image. Variations in the polarimetric properties with the azimuthal look angle remain unconsidered. In this paper. a fully polarimetric subaperture analysis method is introduced. Using deconvolution. synthesized SAR images are decomposed into subaperture datasets. which correspond to the scene responses under different azimuthal look angles. A statistical analysis of the polarimetric parameters permits to clearly discriminate media showing a …,True,XeOWbR0AAAAJ:d1gkVwhDpl0C,152,https://ieeexplore.ieee.org/abstract/document/1237388/,3819667051810441295,/scholar?cites=3819667051810441295,,,,0,0,0
1278334,Under-foliage object imaging using SAR tomography and polarimetric spectral estimators,2011,Yue Huang and Laurent Ferro-Famil and Andreas Reigber,50,IEEE transactions on geoscience and remote sensing,6,2213-2225,IEEE,This paper addresses the imaging of objects located under a forest cover using polarimetric synthetic aperture radar tomography (POLTOMSAR) at L-band. High-resolution spectral estimators. able to accurately discriminate multiple scattering centers in the vertical direction. are used to separate the response of objects and vehicles embedded in a volumetric background. A new polarimetric spectral analysis technique is introduced and is shown to improve the estimation accuracy of the vertical position of both artificial scatterers and natural environments. This approach provides optimal polarimetric features that may be used to further characterize the objects under analysis. The effectiveness of this novel technique for POLTOMSAR is demonstrated using fully polarimetric L-band airborne data sets acquired by the German Aerospace Center (DLR)'s E-SAR system over the test site in Dornstetten. Germany.,True,XeOWbR0AAAAJ:35N4QoGY0k4C,139,https://ieeexplore.ieee.org/abstract/document/6084739/,1957525676847465222,/scholar?cites=1957525676847465222,,,https://elib.dlr.de/71062/2/Yang-Reigber-06084739.pdf,0,0,0
1278335,Global role and burden of influenza in pediatric respiratory hospitalizations. 1982–2012: a systematic analysis,2016,Kathryn E Lafond and Harish Nair and Mohammad Hafiz Rasooly and Fátima Valente and Robert Booy and Mahmudur Rahman and Paul Kitsutani and Hongjie Yu and Guiselle Guzman and Daouda Coulibaly and Julio Armero and Daddi Jima and Stephen RC Howie and William Ampofo and Ricardo Mena and Mandeep Chadha and Ondri Dwi Sampurno and Gideon O Emukule and Zuridin Nurmatov and Andrew Corwin and Jean Michel Heraud and Daniel E Noyola and Radu Cojocaru and Pagbajabyn Nymadawa and Amal Barakat and Adebayo Adedeji and Marta von Horoch and Remigio Olveda and Thierry Nyatanyi and Marietjie Venter and Vida Mmbaga and Malinee Chittaganpitch and Tran Hien Nguyen and Andros Theo and Melissa Whaley and Eduardo Azziz-Baumgartner and Joseph Bresee and Harry Campbell and Marc-Alain Widdowson and Global Respiratory Hospitalizations—Influenza Proportion Positive (GRIPP) Working Group,13,,3,e1001977,Public Library of Science,Background The global burden of pediatric severe respiratory illness is substantial. and influenza viruses contribute to this burden. Systematic surveillance and testing for influenza among hospitalized children has expanded globally over the past decade. However. only a fraction of the data has been used to estimate influenza burden. In this analysis. we use surveillance data to provide an estimate of influenza-associated hospitalizations among children worldwide.   Methods and Findings We aggregated data from a systematic review (n = 108) and surveillance platforms (n = 37) to calculate a pooled estimate of the proportion of samples collected from children hospitalized with respiratory illnesses and positive for influenza by age group (<6 mo. <1 y. <2 y. <5 y. 5–17 y. and <18 y). We applied this proportion to global estimates of acute lower respiratory infection hospitalizations among children aged <1 y and <5 y. to obtain the number and per capita rate of influenza-associated hospitalizations by geographic region and socio-economic status. Influenza was associated with 10% (95% CI 8%–11%) of respiratory hospitalizations in children <18 y worldwide. ranging from 5% (95% CI 3%–7%) among children <6 mo to 16% (95% CI 14%–20%) among children 5–17 y. On average. we estimated that influenza results in approximately 374.000 (95% CI 264.000 to 539.000) hospitalizations in children <1 y—of which 228.000 (95% CI 150.000 to 344.000) occur in children <6 mo—and 870.000 (95% CI 610.000 to 1.237.000) hospitalizations in children <5 y annually. Influenza-associated hospitalization rates were more than three times higher in …,True,At3n1XMAAAAJ:aKos2Y7kUz0C,222,https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001977,120079397292189510,/scholar?cites=120079397292189510,,,https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001977,0,0,0
1278336,Trapped in statelessness: Rohingya refugees in Bangladesh,2017,Abul Hasnat Milton and Mijanur Rahman and Sumaira Hussain and Charulata Jindal and Sushmita Choudhury and Shahnaz Akter and Shahana Ferdousi and Tafzila Akter Mouly and John Hall and Jimmy T Efird,14,,8,942,Multidisciplinary Digital Publishing Institute,The Rohingya people are one of the most ill-treated and persecuted refugee groups in the world. having lived in a realm of statelessness for over six generations. and who are still doing so. In recent years. more than 500.000 Rohingyas fled from Myanmar (Burma) to neighboring countries. This article addresses the Rohingya refugee crisis in Bangladesh. with special emphasis on the living conditions of this vulnerable population. We reviewed several documents on Rohingya refugees. visited a registered refugee camp (Teknaf). collected case reports. and conducted a series of meetings with stakeholders in the Cox’s Bazar district of Bangladesh. A total of 33.131 registered Rohingya refugees are living in two registered camps in Cox’s Bazar. and up to 80.000 additional refugees are housed in nearby makeshift camps. Overall. the living conditions of Rohingya refugees inside the overcrowded camps remain dismal. Mental health is poor. proper hygiene conditions are lacking. malnutrition is endemic. and physical/sexual abuse is high. A concerted diplomatic effort involving Bangladesh and Myanmar. and international mediators such as the Organization of Islamic Countries and the United Nations. is urgently required to effectively address this complex situation. View Full-Text,True,At3n1XMAAAAJ:FhYITFoLSqsC,100,https://www.mdpi.com/1660-4601/14/8/942,18424097656988825226,/scholar?cites=18424097656988825226,,,https://www.mdpi.com/1660-4601/14/8/942/pdf,0,0,0
1278337,Clustering of non-communicable diseases risk factors in Bangladeshi adults: An analysis of STEPS survey 2013,2015,M Mostafa Zaman and Mahfuzur Rahman Bhuiyan and Md Nazmul Karim and Md Mukhlesur Rahman and Abdul Waheed Akanda and Thushara Fernando,15,BMC public health,1,1-9,BioMed Central,Non-communicable diseases (NCDs) have already become major killers in Bangladesh. Once NCDs are developed. they become chronic health and economic problems. Their primary prevention is linked to their common risk factors. This study was conducted to determine the prevalence of NCD risk factors with a focus on their clustering in Bangladeshi adults. This nationally representative study was done in 4.073 (1.812 men and 2.261 women) adults aged 25 years or older selected from rural and urban households. Multistage cluster sampling design was used. Selected variables were in line with steps I and II of WHO stepwise surveillance except alcohol. Forty-four percent used tobacco in any form. Almost 93 % did not consume adequate fruit and vegetables (5 servings or more). Thirty eight percent had low physical activity level (<600 MET-minutes/week). One-quarter (26 %) were overweight (body mass index > =25 kg/m^2). Twenty-one percent had hypertension (blood pressure > =140/90 mmHg or medication) and about 5 % had documented diabetes. Upon examination of risk factor clustering. we observed that 38 % had at least three risk factors. After this threshold. clustering suddenly dropped down to a fairly low level. Using this threshold as a cut-off. clustering of risk factors was associated with age. male gender. urban residence. educational levels and quality of house in multivariate analysis. Prevalence of NCD risk factors is fairly high in Bangladeshi adults with a tendency of clustering. If a risk factor such as hypertension is detected. a closer look for other risk factors has to be given in both at clinical and public health settings …,True,At3n1XMAAAAJ:IfvCfoBprpQC,91,https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-015-1938-4,12034286546620154579,/scholar?cites=12034286546620154579,,,https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-015-1938-4,0,0,0
1278338,Analysis and prediction of rainfall trends over Bangladesh using Mann–Kendall. Spearman’s rho tests and ARIMA model,2017,Mohammad Atiqur Rahman and Lou Yunsheng and Nahid Sultana,129,Meteorology and Atmospheric Physics,4,409-424,Springer Vienna,In this study. 60-year monthly rainfall data of Bangladesh were analysed to detect trends. Modified Mann–Kendall. Spearman’s rho tests and Sen’s slope estimators were applied to find the long-term annual. dry season and monthly trends. Sequential Mann–Kendall analysis was applied to detect the potential trend turning points. Spatial variations of the trends were examined using inverse distance weighting (IDW) interpolation. AutoRegressive integrated moving average (ARIMA) model was used for the country mean rainfall and for other two stations data which depicted the highest and the lowest trend in the Mann–Kendall and Spearman’s rho tests. Results showed that there is no significant trend in annual rainfall pattern except increasing trends for Cox’s Bazar. Khulna. Satkhira and decreasing trend for Srimagal areas. For the dry season. only Bogra area represented significant decreasing trend. Long …,True,At3n1XMAAAAJ:GO2DTSf4MZMC,88,https://link.springer.com/article/10.1007/s00703-016-0479-4,3233878412977863145,/scholar?cites=3233878412977863145,,,https://www.researchgate.net/profile/Mohammad_Atiqur_Rahman/publication/308325197_Analysis_and_prediction_of_rainfall_trends_over_Bangladesh_using_Mann-Kendall_Spearman%27s_rho_tests_and_ARIMA_model/links/5aa79932a6fdcccdc46ae33f/Analysis-and-prediction-of-rainfall-trends-over-Bangladesh-using-Mann-Kendall-Spearmans-rho-tests-and-ARIMA-model.pdf,0,0,0
1278339,Assessing channel changes of the Ganges-Padma River system in Bangladesh using Landsat and hydrological data,2017,Ashraf Dewan and Robert Corner and Ashty Saleem and Md Masudur Rahman and Md Rafiqul Haider and Md Mostafizur Rahman and Maminul H Sarker,276,Geomorphology,,257-279,Elsevier,The Ganga/Ganges1 is an important river system in South Asia which supports the life and livelihoods of millions of people both in India and Bangladesh. The system has a number of names throughout its length. Below its confluence with the Brahmaputra at Aricha it is known as the Padma. which in turn merges with the Upper Meghna at Chandpur below which the channel is known as the Lower Meghna. There is a growing concern about this large river system because its channels are subject to frequent migration. threatening engineering structures and resulting in various environmental and social consequences which may be compounded by climatic variability. land use change. and agricultural intensification as the basin experiences rapid population growth. Concerns have been expressed that the construction of a barrage just upstream of the Indo–Bangladesh border has adversely affected the Ganges reach …,True,At3n1XMAAAAJ:vkDViGfkvYEC,76,https://www.sciencedirect.com/science/article/pii/S0169555X16309746,17697082046155546204,/scholar?cites=17697082046155546204,,,https://www.researchgate.net/profile/Md_Masudur_Rahman5/publication/309199016_Assessing_channel_changes_of_the_Ganges-Padma_River_system_in_Bangladesh_using_Landsat_and_hydrological_data/links/580eef9508ae7525273d2ded/Assessing-channel-changes-of-the-Ganges-Padma-River-system-in-Bangladesh-using-Landsat-and-hydrological-data.pdf,0,0,0
1278340,Incidence of respiratory virus-associated pneumonia in urban poor young children of Dhaka. Bangladesh. 2009–2011,2012,Nusrat Homaira and Stephen P Luby and William A Petri and Raija Vainionpaa and Mustafizur Rahman and Kamal Hossain and Cynthia B Snider and Mahmudur Rahman and ASM Alamgir and Farzina Zesmin and Masud Alam and Emily S Gurley and Rashid Uz Zaman and Tasnim Azim and Dean D Erdman and Alicia M Fry and Joseph Bresee and Marc-Alain Widdowson and Rashidul Haque and Eduardo Azziz-Baumgartner,7,PloS one,2,e32056,Public Library of Science,Background Pneumonia is the leading cause of childhood death in Bangladesh. We conducted a longitudinal study to estimate the incidence of virus-associated pneumonia in children aged <2 years in a low-income urban community in Dhaka. Bangladesh.   Methods We followed a cohort of children for two years. We collected nasal washes when children presented with respiratory symptoms. Study physicians diagnosed children with cough and age-specific tachypnea and positive lung findings as pneumonia case-patients. We tested respiratory samples for respiratory syncytial virus (RSV). rhinoviruses. human metapneumovirus (HMPV). influenza viruses. human parainfluenza viruses (HPIV 1. 2. 3). and adenoviruses using real-time reverse transcription polymerase chain reaction assays.   Results Between April 2009–March 2011. we followed 515 children for 730 child-years. We identified a total of 378 pneumonia episodes. 77% of the episodes were associated with a respiratory viral pathogen. The overall incidence of pneumonia associated with a respiratory virus infection was 40/100 child-years. The annual incidence of pneumonia/100 child-years associated with a specific respiratory virus in children aged <2years was 12.5 for RSV. 6 for rhinoviruses. 6 for HMPV. 4 for influenza viruses. 3 for HPIV and 2 for adenoviruses.   Conclusion Young children in Dhaka are at high risk of childhood pneumonia and the majority of these episodes are associated with viral pathogens. Developing effective low-cost strategies for prevention are a high priority.,True,At3n1XMAAAAJ:JavbeY_VQWIC,73,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032056,15480062366341842667,/scholar?cites=15480062366341842667,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0032056,0,0,0
1278341,An outbreak of chikungunya in rural Bangladesh. 2011,2015,Selina Khatun and Apurba Chakraborty and Mahmudur Rahman and Nuzhat Nasreen Banu and Mohammad Mostafizur Rahman and SM Murshid Hasan and Stephen P Luby and Emily S Gurley,9,PLoS neglected tropical diseases,7,e0003907,Public Library of Science,Background The first identified Chikungunya outbreak occurred in Bangladesh in 2008. In late October 2011. a local health official from Dohar Sub-district. Dhaka District. reported an outbreak of undiagnosed fever and joint pain. We investigated the outbreak to confirm the etiology. describe the clinical presentation. and identify associated vectors.   Methodology During November 2–21. 2011. we conducted house-to-house surveys to identify suspected cases. defined as any inhabitant of Char Kushai village with fever followed by joint pain in the extremities with onset since August 15. 2011. We collected blood specimens and clinical histories from self-selected suspected cases using a structured questionnaire. Blood samples were tested for IgM antibodies against Chikungunya virus. The village was divided into nine segments and we collected mosquito larvae from water containers in seven randomly selected houses in each segment. We calculated the Breteau index for the village and identified the mosquito species.   Results The attack rate was 29% (1105/3840) and 29% of households surveyed had at least one suspected case: 15% had ≥3. The attack rate was 38% (606/1589) in adult women and 25% in adult men (320/1287). Among the 1105 suspected case-patients. 245 self-selected for testing and 80% of those (196/245) had IgM antibodies. In addition to fever and joint pain. 76% (148/196) of confirmed cases had rash and 38%(75/196) had long-lasting joint pain. The village Breteau index was 35 per 100 and 89%(449/504) of hatched mosquitoes were Aedes albopictus.   Conclusion The evidence suggests that this outbreak was due to …,True,At3n1XMAAAAJ:O6Atq1G1BT4C,68,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0003907,14107970673437334448,/scholar?cites=14107970673437334448,,,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0003907,0,0,0
1278342,Barriers to enter in foreign markets: evidence from SMEs in emerging market,2017,Mahfuzur Rahman and Moshfique Uddin and George Lodorfos,,International Marketing Review,,,Emerald Publishing Limited,PurposeForeign market entry is considered as a key strategy to grow and survive over longer period of time for small and medium enterprises (SMEs). The decision to enter a foreign market is not a straightforward story. Considering resource limitation. SMEs need to analyse the key barriers to entry in foreign markets very carefully. The purpose of this paper is to identify these barriers for the SMEs in a developing country.,True,At3n1XMAAAAJ:lLPirIASiZEC,66,https://www.emerald.com/insight/content/doi/10.1108/IMR-10-2014-0322/full/html?fullSc=1&mbSc=1,7129954215558835213,/scholar?cites=7129954215558835213,,,https://eprints.whiterose.ac.uk/92194/1/Barriers%20to%20Enter%20into%20Foreign%20Markets_9.pdf,0,0,0
1278343,States of biological components in bacteria and bacteriophages during inactivation by atmospheric dielectric barrier discharges,2008,Hachiro Yasuda and Mai Hashimoto and Md Masudur Rahman and Kazunori Takashima and Akira Mizuno,5,Plasma Processes and Polymers,6,615-621,WILEY‐VCH Verlag,Atmospheric DBD has been applied to the wet state of Escherichia coli and bacteriophage‐λ. Upon DBD treatment. both E.coli and λphage were immediately inactivated. The states of different biological components were monitored during the course of inactivation. Only minor and slow degradation of proteins. DNA. and membranes was observed. a remarkable degradation was seen only after the completion of sterilization. Analysis of GFP recombinantly introduced into E.coli cells proved that the DBD has a prominent protein denaturation activity without affecting peptide bonds. The irreversible denaturation of proteins. seen in the early stage of DBD application. may play a central role in inactivation of both the bacteria and bacteriophages. ,True,At3n1XMAAAAJ:gTud6kY3p2wC,66,https://onlinelibrary.wiley.com/doi/abs/10.1002/ppap.200800036,1392436780551602958,/scholar?cites=1392436780551602958,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/ppap.200800036,0,0,0
1278344,Pseudomonas aeruginosa infection in very low birth weight infants: a case-control study.,1995,Leslie Leigh and Barbara J Stoll and Mostafizur Rahman and John McGowan Jr,14,The Pediatric infectious disease journal,5,367-371,,The perinatal histories and hospital courses of all neonates born at Grady Memorial Hospital who developed Pseudomonas aeruginosa sepsis or meningitis in the 5-year period 1989-1993 were reviewed. In addition a case-control study was performed to evaluate selected risk factors for this infection. Twenty-one patients had one or more blood cultures positive for P. aeruginosa. An additional patient had P. aeruginosa meningitis without bacteremia. All infections occurred after 5 days of age. The overall incidence of P. aeruginosa infection was 0.7/1000 live births. All cases occurred in infants< 1500 g at birth. for a birth weight-specific rate of 19.5/1000 livebirths in this weight class. Clinical manifestations of disease did not distinguish P. aeruginosa from other causes of fulminant neonatal sepsis. Fifty percent of cases died. Mortality was inversely related to postnatal age at diagnosis. The 22 cases were compared with 44 controls matched for birth weight. gestational age. sex. duration of hospital stay and admission date. Cases were more likely than controls to have a history of feeding intolerance. interrupted enteral intake and prolonged parenteral hyperalimentation. Case infants received intravenous antibiotics for a significantly longer period of time than did controls. There was an association between P. aeruginosa sepsis and necrotizing enterocolitis (36% cases vs. 7% of controls had prior or concurrent necrotizing enterocolitis. P< 0.01). In summary P. aeruginosa sepsis is primarily a late onset nosocomial infection in very low birth weight infants. The case fatality rate of 50% in this series emphasizes its continued importance.,True,At3n1XMAAAAJ:RcnGPAfZzXkC,66,https://europepmc.org/article/med/7638011,17822830145374448746,/scholar?cites=17822830145374448746,,,,0,0,0
1278345,Improvement of K-means clustering algorithm with better initial centroids based on weighted average,2012,Md Sohrab Mahmud and Md Mostafizer Rahman and Md Nasim Akhtar,,,,647-650,IEEE,Clustering is the process of grouping similar data into a set of clusters. Cluster analysis is one of the major data analysis techniques and k-means one of the most popular partitioning clustering algorithm that is widely used. But the original k-means algorithm is computationally expensive and the resulting set of clusters strongly depends on the selection of initial centroids. Several methods have been proposed to improve the performance of k-means clustering algorithm. In this paper we propose a heuristic method to find better initial centroids as well as more accurate clusters with less computational time. Experimental results show that the proposed algorithm generates clusters with better accuracy thus improve the performance of k-means clustering algorithm.,True,At3n1XMAAAAJ:mOeHfWVqRE4C,64,https://ieeexplore.ieee.org/abstract/document/6471633/,17598176412949948182,/scholar?cites=17598176412949948182,,,https://www.researchgate.net/profile/Md_Sohrab_Mahmud/publication/261233398_Improvement_of_K-means_clustering_algorithm_with_better_initial_centroids_based_on_weighted_average/links/5c3575bca6fdccd6b59d95ed/Improvement-of-K-means-clustering-algorithm-with-better-initial-centroids-based-on-weighted-average.pdf,0,0,0
1278346,A review on ensembles for the class imbalance problem: bagging-. boosting-. and hybrid-based approaches,2011,Mikel Galar and Alberto Fernandez and Edurne Barrenechea and Humberto Bustince and Francisco Herrera,42,,4,463-484,IEEE,Classifier learning with data-sets that suffer from imbalanced class distributions is a challenging problem in data mining community. This issue occurs when the number of examples that represent one class is much lower than the ones of the other classes. Its presence in many real-world applications has brought along a growth of attention from researchers. In machine learning. the ensemble of classifiers are known to increase the accuracy of single classifiers by combining several of them. but neither of these learning techniques alone solve the class imbalance problem. to deal with this issue the ensemble learning algorithms have to be designed specifically. In this paper. our aim is to review the state of the art on ensemble techniques in the framework of imbalanced data-sets. with focus on two-class problems. We propose a taxonomy for ensemble-based methods to address the class imbalance where each …,True,wH3T3FwAAAAJ:L8Ckcad2t8MC,1883,https://ieeexplore.ieee.org/abstract/document/5978225/,16313092636936498754,/scholar?cites=16313092636936498754,,,https://sci2s.ugr.es/sites/default/files/ficherosPublicaciones/1422_2012-IEEE_TSMCc-Review_Ensembles.pdf,0,0,0
1278347,An overview of ensemble methods for binary classifiers in multi-class problems: Experimental study on one-vs-one and one-vs-all schemes,2011,Mikel Galar and Alberto Fernández and Edurne Barrenechea and Humberto Bustince and Francisco Herrera,44,,8,1761-1776,Pergamon,Classification problems involving multiple classes can be addressed in different ways. One of the most popular techniques consists in dividing the original data set into two-class subsets. learning a different binary model for each new subset. These techniques are known as binarization strategies.In this work. we are interested in ensemble methods by binarization techniques; in particular. we focus on the well-known one-vs-one and one-vs-all decomposition strategies. paying special attention to the final step of the ensembles. the combination of the outputs of the binary classifiers. Our aim is to develop an empirical analysis of different aggregations to combine these outputs. To do so. we develop a double study: first. we use different base classifiers in order to observe the suitability and potential of each combination within each classifier. Then. we compare the performance of these ensemble techniques with the …,True,wH3T3FwAAAAJ:KlAtU1dfN6UC,615,https://www.sciencedirect.com/science/article/pii/S0031320311000458,11000412941738625033,/scholar?cites=11000412941738625033,,,,0,0,0
1278348,A historical account of types of fuzzy sets and their relationships,2015,Humberto Bustince and Edurne Barrenechea and Miguel Pagola and Javier Fernandez and Zeshui Xu and Benjamin Bedregal and Javier Montero and Hani Hagras and Francisco Herrera and Bernard De Baets,24,IEEE Transactions on Fuzzy Systems,1,179-194,IEEE,In this paper. we review the definition and basic properties of the different types of fuzzy sets that have appeared up to now in the literature. We also analyze the relationships between them and enumerate some of the applications in which they have been used.,True,wH3T3FwAAAAJ:p2g8aNsByqUC,329,https://ieeexplore.ieee.org/abstract/document/7145399/,8182353575537643466,/scholar?cites=8182353575537643466,,,http://repository.essex.ac.uk/15334/1/history.pdf,0,0,0
1278349,EUSBoost: Enhancing ensembles for highly imbalanced data-sets by evolutionary undersampling,2013,Mikel Galar and Alberto Fernández and Edurne Barrenechea and Francisco Herrera,46,Pattern recognition,12,3460-3471,Pergamon,Classification with imbalanced data-sets has become one of the most challenging problems in Data Mining. Being one class much more represented than the other produces undesirable effects in both the learning and classification processes. mainly regarding the minority class. Such a problem needs accurate tools to be undertaken; lately. ensembles of classifiers have emerged as a possible solution. Among ensemble proposals. the combination of Bagging and Boosting with preprocessing techniques has proved its ability to enhance the classification of the minority class.In this paper. we develop a new ensemble construction algorithm (EUSBoost) based on RUSBoost. one of the simplest and most accurate ensemble. which combines random undersampling with Boosting algorithm. Our methodology aims to improve the existing proposals enhancing the performance of the base classifiers by the usage of the …,True,wH3T3FwAAAAJ:O3NaXMp0MMsC,292,https://www.sciencedirect.com/science/article/pii/S0031320313002100,14838960270951772905,/scholar?cites=14838960270951772905,,,http://150.214.190.154/sites/default/files/ficherosPublicaciones/1641_2013-PR-Galar-EUS-BOOST.pdf,0,0,0
1278350,Interval-valued fuzzy sets constructed from matrices: Application to edge detection,2009,H Bustince and E Barrenechea and Miguel Pagola and Javier Fernández,160,Fuzzy Sets and systems,13,1819-1840,North-Holland,In this paper we present a method to construct interval-valued fuzzy sets (or interval type 2 fuzzy sets) from a matrix (or image). in such a way that we obtain the length of the interval representing the membership of any element to the new set from the differences between the values assigned to that element and its neighbors in the starting matrix. Using the concepts of interval-valued fuzzy t-norm. interval-valued fuzzy t-conorm and interval-valued fuzzy entropy. we are able to detect big enough jumps (edges) between the values of an element and its neighbors in the starting matrix. We also prove that the unique t-representable interval-valued fuzzy t-norms and the unique s-representable interval-valued fuzzy t-conorms that preserve the length zero of the intervals are the ones generated by means of the t-norm minimum and the t-conorm maximum.,True,wH3T3FwAAAAJ:u-x6o8ySG0sC,252,https://www.sciencedirect.com/science/article/pii/S016501140800376X,6642829983875570209,/scholar?cites=6642829983875570209,,,,0,0,0
1278351,New method to assess barley nitrogen nutrition status based on image colour analysis: comparison with SPAD-502,2009,Miguel Pagola and Rubén Ortiz and Ignacio Irigoyen and Humberto Bustince and Edurne Barrenechea and Pedro Aparicio-Tejo and Carmen Lamsfus and Berta Lasa,65,Computers and electronics in agriculture,2,213-218,Elsevier,Measuring the nitrogen nutrition status of plants is useful for nitrogen fertiliser management. As nitrogen is one of the main structural components of chlorophyll. its nutrition status is highly correlated with the greenness of leaves. This paper proposes and evaluates a new low-cost method to estimate the N-nutrition status of plants using digital colour image analysis. A method has been developed in which principal component analysis is applied to digital images to calculate a greenness index using RGB components of the colour image. which yields an estimate of the amount of N in the plant. To evaluate its quality. we calculated the correlation between the index and measurements obtained with a SPAD-502 chlorophyll meter. normally used in decision-making in fertiliser management. The performance of the proposed index is better than that of others previously investigated. Furthermore. the capacity of our index …,True,wH3T3FwAAAAJ:Tyk-4Ss8FVUC,177,https://www.sciencedirect.com/science/article/pii/S0168169908002196,7596929452060614173,/scholar?cites=7596929452060614173,,,https://www.researchgate.net/profile/Berta_Lasa/publication/250719147_New_method_to_assess_barley_nitrogen_nutrition_status_based_on_image_colour_analysis_Comparison_with_SPAD-502/links/5b5adc760f7e9bc79a670d86/New-method-to-assess-barley-nitrogen-nutrition-status-based-on-image-colour-analysis-Comparison-with-SPAD-502.pdf,0,0,0
1278352,Restricted equivalence functions,2006,H Bustince and E Barrenechea and Miguel Pagola,157,Fuzzy Sets and Systems,17,2333-2346,North-Holland,In this paper we present the concept of a restricted equivalence function. This concept arises on the one hand. from the definition of equivalence given by J. Fodor and M. Roubens. and on the other. from the properties usually demanded from the measures used for comparing images. We also study different methods for the construction of restricted equivalence functions from automorphisms and implication operators. Finally we analyze the manner of generating similarity measures of X. Liu and of J. Fan et al. from our restricted equivalence functions.,True,wH3T3FwAAAAJ:IjCSPb-OGe4C,170,https://www.sciencedirect.com/science/article/pii/S0165011406001291,998522732492161755,/scholar?cites=998522732492161755,,,,0,0,0
1278353,Construction of fuzzy indices from fuzzy DI-subsethood measures: application to the global comparison of images,2007,H Bustince and Miguel Pagola and E Barrenechea,177,Information Sciences,3,906-929,Elsevier,Two measures are presented for comparing fuzzy sets. The method for constructing these measures is studied. starting from fuzzy DI-subsethood measures (see [H. Bustince. V. Mohedano. E. Barrenechea. M. Pagola. Definition and construction of fuzzy DI-subsethood measures. Information Sciences 176 (2006) 3190–3231]). We then analyze and compare the properties satisfied by the measures and those satisfied by other classical indices used in the literature on fuzzy sets. The minimal set of conditions are studied that. from our point of view. must be met by any given measure for comparing images. We also prove that only one of the measures identified fulfills such conditions. Finally. all the measures studied are applied to different images and the results are analyzed. indicating that measures constructed from fuzzy DI-subsethood measures provide the best results.,True,wH3T3FwAAAAJ:u5HHmVD_uO8C,169,https://www.sciencedirect.com/science/article/pii/S0020025506002015,6990193561688403795,/scholar?cites=6990193561688403795,,,,0,0,0
1278354,Image thresholding using restricted equivalence functions and maximizing the measures of similarity,2007,H Bustince and E Barrenechea and Miguel Pagola,158,Fuzzy Sets and Systems,5,496-516,North-Holland,In this paper we apply restricted equivalence functions to the computation of the threshold of an image. In the first part we present an algorithm for obtaining the best threshold of a grayscale image with a single object. In the second part we study different algorithms for calculating the optimal threshold. Then we analyze two algorithms for obtaining a sequence of optimal thresholds in images with several objects. Lastly. we compare our results with those obtained with other methods and carry out a study of the time efficiency of the methods we propose.,True,wH3T3FwAAAAJ:2osOgNQ5qMEC,158,https://www.sciencedirect.com/science/article/pii/S0165011406003708,14687197520956517434,/scholar?cites=14687197520956517434,,,,0,0,0
1278355,A survey on fingerprint minutiae-based local matching for verification and identification: Taxonomy and experimental evaluation,2015,Daniel Peralta and Mikel Galar and Isaac Triguero and Daniel Paternain and Salvador García and Edurne Barrenechea and José M Benítez and Humberto Bustince and Francisco Herrera,315,Information Sciences,,67-87,Elsevier,Fingerprint recognition has found a reliable application for verification or identification of people in biometrics. Globally. fingerprints can be viewed as valuable traits due to several perceptions observed by the experts; such as the distinctiveness and the permanence on humans and the performance in real applications. Among the main stages of fingerprint recognition. the automated matching phase has received much attention from the early years up to nowadays. This paper is devoted to review and categorize the vast number of fingerprint matching methods proposed in the specialized literature. In particular. we focus on local minutiae-based matching algorithms. which provide good performance with an excellent trade-off between efficacy and efficiency. We identify the main properties and differences of existing methods. Then. we include an experimental evaluation involving the most representative local …,True,wH3T3FwAAAAJ:1sJd4Hv_s6UC,142,https://www.sciencedirect.com/science/article/pii/S0020025515002819,13008207120448235408,/scholar?cites=13008207120448235408,,,https://academica-e.unavarra.es/bitstream/handle/2454/17645/peralta-reviewMatching-INS-R1.pdf?sequence=1&isAllowed=n,0,0,0
1278356,Interval type-2 fuzzy sets are generalization of interval-valued fuzzy sets: Toward a wider view on their relationship,2014,Humberto Bustince Sola and Javier Fernandez and Hani Hagras and Francisco Herrera and Miguel Pagola and Edurne Barrenechea,23,IEEE Transactions on Fuzzy Systems,5,1876-1882,IEEE,In this paper. we will present a wider view on the relationship between interval-valued fuzzy sets and interval type-2 fuzzy sets. where we will show that interval-valued fuzzy sets are a particular case of the interval type-2 fuzzy sets. For this reason. both concepts should be treated in a different way. In addition. the view presented in this paper will allow a more general perspective of interval type-2 fuzzy sets. which will allow representing concepts that could not be presented by interval-valued fuzzy sets.,True,wH3T3FwAAAAJ:D03iK_w7-QYC,140,https://ieeexplore.ieee.org/abstract/document/6918530/,14235635724542784965,/scholar?cites=14235635724542784965,,,https://academica-e.unavarra.es/bitstream/handle/2454/32793/25_Bustince_IntervalType2.pdf?sequence=1&isAllowed=y,0,0,0
1278357,Image denoising using scale mixtures of Gaussians in the wavelet domain,2003,Javier Portilla and Vasily Strela and Martin J Wainwright and Eero P Simoncelli,12,IEEE Transactions on Image processing,11,1338-1351,IEEE,We describe a method for removing noise from digital images. based on a statistical model of the coefficients of an overcomplete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood. and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model. the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods. both …,True,239ZfwgAAAAJ:u5HHmVD_uO8C,2891,https://ieeexplore.ieee.org/abstract/document/1240101/,3428857642015242156,/scholar?cites=3428857642015242156,,,http://www.cns.nyu.edu/pub/lcv/portilla03-reprint.pdf,0,0,0
1278358,A parametric texture model based on joint statistics of complex wavelet coefficients,2000,Javier Portilla and Eero P Simoncelli,40,International journal of computer vision,1,49-70,Kluwer Academic Publishers,We present a universal statistical model for texture images in the context of an overcomplete complex wavelet transform. The model is parameterized by a set of statistics computed on pairs of coefficients corresponding to basis functions at adjacent spatial locations. orientations. and scales. We develop an efficient algorithm for synthesizing random images subject to these constraints. by iteratively projecting onto the set of images satisfying each constraint. and we use this to test the perceptual validity of the model. In particular. we demonstrate the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set. We also demonstrate the power of our model by successfully synthesizing examples drawn from a diverse collection of artificial and natural textures.,True,239ZfwgAAAAJ:u-x6o8ySG0sC,2033,https://link.springer.com/article/10.1023/A:1026553619983,7018318226772971761,/scholar?cites=7018318226772971761,,,https://www.cns.nyu.edu/pub/lcv/portilla99-reprint.pdf,0,0,0
1278359,Texture characterization via joint statistics of wavelet coefficient magnitudes,1998,Eero P Simoncelli and Javier Portilla,1,,,62-66,IEEE,We present a parametric statistical characterization of texture images in the context of an overcomplete complex wavelet frame. The characterization consists of the local autocorrelation of the coefficients in each subband. the local autocorrelation of the coefficent magnitudes. and the cross-correlation of coefficient magnitudes at all orientations and adjacent spatial scales. We develop an efficient algorithm for sampling from an implicit probability density conforming to these statistics. and demonstrate its effectiveness in synthesizing artificial and natural texture images.,True,239ZfwgAAAAJ:d1gkVwhDpl0C,297,https://ieeexplore.ieee.org/abstract/document/723417/,5725322916038540268,/scholar?cites=5725322916038540268,,,http://www.cns.nyu.edu/pub/eero/simoncelli98b.pdf,0,0,0
1278360,Adaptive Wiener denoising using a Gaussian scale mixture model in the wavelet domain,2001,Javier Portilla and Vasily Strela and Martin J Wainwright and Eero P Simoncelli,2,,,37-40,IEEE,We describe a statistical model for images decomposed in an overcomplete wavelet pyramid. Each coefficient of the pyramid is modeled as the product of two independent random variables: an element of a Gaussian random field. and a hidden multiplier with a marginal log-normal prior. The latter modulates the local variance of the coefficients. We assume subband coefficients are contaminated with additive Gaussian noise of known covariance. and compute a MAP estimate of each multiplier variable based on observation of a local neighborhood of coefficients. Conditioned on this multiplier. we then estimate the subband coefficients with a local Wiener estimator. Unlike previous approaches. we (a) empirically motivate our choice for the prior on the multiplier; (b) use the full covariance of signal and noise in the estimation; (c) include adjacent scales in the conditioning neighborhood. To our knowledge. the results …,True,239ZfwgAAAAJ:9yKSN-GCB0IC,229,https://ieeexplore.ieee.org/abstract/document/958418/,13778248775309532050,/scholar?cites=13778248775309532050,,,https://www.cns.nyu.edu/pub/lcv/portilla01a.pdf,0,0,0
1278361,Efficient spatial-domain implementation of a multiscale image representation based on gabor functions,1998,Oscar Nestares and Rafael Fonolla Navarro and Javier Portilla and Antonio Tabernero,7,Journal of Electronic Imaging,1,166-173,International Society for Optics and Photonics,Gabor schemes of multiscale image representation are useful in many computer vision applications. However. the classic Gabor expansion is computationally expensive due to the lack of orthogonality of Gabor functions. Some alternative schemes. based on the application of a bank of Gabor filters. have important advantages such as computational efficiency and robustness. at the cost of redundancy and lack of completeness. In a previous work we proposed a quasicomplete Gabor transform. suitable for fast implementations in either space or frequency domains. Reconstruction was achieved by simply adding together the even Gabor channels. We develop an optimized spatial-domain implementation. using one-dimensional 11-tap filter masks. that is faster and more flexible than Fourier implementations. The reconstruction method is improved by applying fixed and independent weights to the Gabor channels …,True,239ZfwgAAAAJ:2osOgNQ5qMEC,190,https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-7/issue-1/0000/Efficient-spatial-domain-implementation-of-a-multiscale-image-representation-based/10.1117/1.482638.short,16714258204111145106,/scholar?cites=16714258204111145106,,,https://www.academia.edu/download/40037699/0912f5112186238a5c000000.pdf20151115-68247-l6wady.pdf,0,0,0
1278362,Image restoration using space-variant Gaussian scale mixtures in overcomplete pyramids,2007,Jose A Guerrero-Colón and Luis Mancera and Javier Portilla,17,IEEE Transactions on Image Processing,1,27-41,IEEE,In recent years. Bayes least squares-Gaussian scale mixtures (BLS-GSM) has emerged as one of the most powerful methods for image restoration. Its strength relies on providing a simple and. yet. very effective local statistical description of oriented pyramid coefficient neighborhoods via a GSM vector. This can be viewed as a fine adaptation of the model to the signal variance at each scale. orientation. and spatial location. Here. we present an enhancement of the model by introducing a coarser adaptation level. where a larger neighborhood is used to estimate the local signal covariance within every subband. We formulate our model as a BLS estimator using space-variant GSM. The model can be also applied to image deconvolution. by first performing a global blur compensation. and then doing local adaptive denoising. We demonstrate through simulations that the proposed method. besides being model-based …,True,239ZfwgAAAAJ:UeHWp8X0CEIC,139,https://ieeexplore.ieee.org/abstract/document/4385292/,975594718942390655,/scholar?cites=975594718942390655,,,https://www.academia.edu/download/43859459/Image_restoration_using_space-variant_Ga20160318-6422-2kf36y.pdf,0,0,0
1278363,Image denoising using a local Gaussian scale mixture model in the wavelet domain,2000,Vasily Strela and Javier Portilla and Eero P Simoncelli,4119,,,363-371,International Society for Optics and Photonics,The statistics of photographic images. when decomposed in a multiscale wavelet basis. exhibit striking non-Gaussian behaviors. The joint densities of clusters of wavelet coefficients are well-described as a Gaussian scale mixture: a jointly Gaussian vector multiplied by a hidden scaling variable. We develop a maximum likelihood solution for estimating the hidden variable from an observation of the cluster of coefficients contaminated by additive Gaussian noise. The estimated hidden variable is then used to estimate the original noise-free coefficients. We demonstrate the power of this model through numerical simulations of image denoising.,True,239ZfwgAAAAJ:qjMakFHDy7sC,128,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4119/0000/Image-denoising-using-a-local-Gaussian-scale-mixture-model-in/10.1117/12.408621.short,13605668748619425730,/scholar?cites=13605668748619425730,,,https://www.researchgate.net/profile/Javier_Portilla2/publication/2815339_Image_Denoising_Using_a_Local_Gaussian_Scale_Mixture_Model_in_the_Wavelet_Domain/links/0c960537b1c0f51545000000/Image-Denoising-Using-a-Local-Gaussian-Scale-Mixture-Model-in-the-Wavelet-Domain.pdf,0,0,0
1278364,Texture modeling and synthesis using joint statistics of complex wavelet coefficients,1999,Javier Portilla and Eero P Simoncelli,,IEEE workshop on statistical and computational theories of vision,,,,We present a statistical characterization of texture images in the context of an overcomplete complex wavelet transform. The characterization is based on empirical observations of statistical regularities in such images. and parameterized by (1) the local autocorrelation of the coefficients in each subband;(2) both the local auto-correlation and cross-correlation of coefficient magnitudes at other orientations and spatial scales; and (3) the first few moments of the image pixel histogram. We develop an efficient algorithm for synthesizing random images subject to these constraints using alternated projections. and demonstrate its effectiveness on a wide range of synthetic and natural textures. In particular. we show that many important structural elements in textures (eg. edges. repeated patterns or alternated patches of simpler texture). can be captured through joint second order statistics of the coefficient magnitudes. We also show the flexibility of the representation. by applying to a variety of tasks which can be viewed as constrained image synthesis problems. such as spatial and spectral extrapolation.,True,239ZfwgAAAAJ:IjCSPb-OGe4C,108,http://www.cns.nyu.edu/~lcv/pubs/makeAbs.php?loc=Portilla99a,191197627330196070,/scholar?cites=191197627330196070,,,http://www.cns.nyu.edu/pub/eero/portilla99a.pdf,0,0,0
1278365,Image restoration through l0 analysis-based sparse optimization in tight frames,2009,Javier Portilla,,,,3909-3912,IEEE,Sparse optimization in overcomplete frames has been widely applied in recent years to ill-conditioned inverse problems. In particular. analysis-based sparse optimization consists of achieving a certain trade-off between fidelity to the observation and sparsity in a given linear representation. typically measured by some ¿ p  quasi-norm. Whereas most popular choice for p is 1 (convex optimization case). there is an increasing evidence on both the computational feasibility and higher performance potential of non-convex approaches (0 ¿ p < 1). The extreme p = 0 case is especial. because analysis coefficients of typical images obtained using typical pyramidal frames are not strictly sparse. but rather compressible. Here we model the analysis coefficients as a strictly sparse vector plus a Gaussian correction term. This statistical formulation allows for an elegant iterated marginal optimization. We also show that it provides …,True,239ZfwgAAAAJ:ufrVoPGSRksC,107,https://ieeexplore.ieee.org/abstract/document/5413975/,15861157232210922976,/scholar?cites=15861157232210922976,,,https://www.io.csic.es/PagsPers/JavPortilla/deblur/ICIP_2009_Portilla.pdf,0,0,0
1278366,L0-norm-based sparse representation through alternate projections,2006,Luis Mancera and Javier Portilla,,,,2089-2092,IEEE,We present a simple and robust method for finding sparse representations in overcomplete transforms. based on minimization of the L0-norm. Our method is better than current solutions based on minimization of the L1-norm in terms of energy compaction. These results strongly question the equivalence of minimizing both norms in real conditions. We also show application to in-painting (interpolation of lost pixels).,True,239ZfwgAAAAJ:YsMSGLbcyi4C,87,https://ieeexplore.ieee.org/abstract/document/4106973/,13378453324741614203,/scholar?cites=13378453324741614203,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.80.942&rep=rep1&type=pdf,0,0,0
1278367,Texture synthesis-by-analysis method based on a multiscale early-vision model,1996,Javier Portilla and Rafael Fonolla Navarro and Oscar Nestares and Antonio Tabernero,35,Optical Engineering,8,2403-2417,International Society for Optics and Photonics,A new texture synthesis-by-analysis method. applying a visually based approach that has some important advantages over more traditional texture modeling and synthesis techniques is introduced. The basis of the method is to encode the textural information by sampling both the power spectrum and the histogram of homogeneously textured images. The spectrum is sampled in a log-polar grid using a pyramid Gabor scheme. The input image is split into a set of 16 Gabor channels (using four spatial frequency levels and four orientations). plus a lowpass residual (LPR). The energy and equivalent bandwidths of each channel. as well as the LPR power spectrum and the histogram. are measured and the latter two are compressed. The synthesis process consists of generating 16 Gabor filtered independent noise signals with spectral centers equal to those of the Gabor filters. whose energy and equivalent bandwidths …,True,239ZfwgAAAAJ:Tyk-4Ss8FVUC,74,https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-35/issue-8/0000/Texture-synthesis-by-analysis-method-based-on-a-multiscale-early/10.1117/1.600814.short,4657591828901034346,/scholar?cites=4657591828901034346,,,https://digital.csic.es/bitstream/10261/76029/1/Portilla.pdf,0,0,0
1278368,Three-dimensional data from images,1998,Reinhard Klette and A Koschan and K Schluns,,"Springer-Verlag Singapore Pte. Ltd., Singapore",,,,The projection of light patterns into a scene is called structured lighting. The light patterns are projected onto the objects which lie in the field of view of the camera. The distance of an object to the camera or the location of an object in space can be determined through analyzing the observed light patterns in the images. The active manipulation of the scene by using light patterns simplifies the 3D recon-struction task enormously as described in this chapter. Notice that the location (. y) of a pixel in the image (this is a grid square or grid rectangle) constrains the 3D location of the corresponding object point (X. Y. Z) to a certain sub-space in the scene. This sub-space contains all those scene points which project onto the grid square (x. y) and can be modeled as a four-sided infinite pyramid. If the intrinsic parameters of the camera are known then this sub-space can be described with respect to the camera coordinate …,True,VckVaRIAAAAJ:u5HHmVD_uO8C,628,http://engineering.nyu.edu/~gerig/CS-GY-6643-S2017/Materials/Klette-Chap9-StructuredLight-2.pdf,15760460661088714862,/scholar?cites=15760460661088714862,,,http://engineering.nyu.edu/~gerig/CS-GY-6643-S2017/Materials/Klette-Chap9-StructuredLight-2.pdf,0,0,0
1278369,Colour image segmentation-a survey,1994,Wladyslaw Skarbek and Andreas Koschan and Technischer Bericht and Zur Veroffentlichung,,,,,,Image segmentation. ie. identification of homogeneous regions in the image. has been the subject of considerable research activity over the last three decades. Many algorithms have been elaborated for gray scale images. However. the problem of segmentation for colour images. which convey much more information about objects in scenes. has received much less attention of scientific community. While several surveys of monochrome image segmentation techniques were published. similar comprehensive surveys for colour images. to our knowledge. did not emerge. This report contains: an extensive survey of algorithms for colour image segmentation. a categorization of them according well defined list of attributes. suggestions for their improvements. and descriptions of few novel approaches.,True,VckVaRIAAAAJ:FPJr55Dyh1AC,498,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.1325,6806464001632434315,/scholar?cites=6806464001632434315,,,,0,0,0
1278370,Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining,2012,Daqing Chen and Sai Laing Sain and Kun Guo,19,Journal of Database Marketing & Customer Strategy Management,3,197-208,Palgrave Macmillan UK,Many small online retailers and new entrants to the online retail sector are keen to practice data mining and consumer-centric marketing in their businesses yet technically lack the necessary knowledge and expertise to do so. In this article a case study of using data mining techniques in customer-centric business intelligence for an online retailer is presented. The main purpose of this analysis is to help the business better understand its customers and therefore conduct customer-centric marketing more effectively. On the basis of the Recency. Frequency. and Monetary model. customers of the business have been segmented into various meaningful groups using the k-means clustering algorithm and decision tree induction. and the main characteristics of the consumers in each segment have been clearly identified. Accordingly a set of recommendations is further provided to the business on consumer-centric …,True,VckVaRIAAAAJ:EkHepimYqZsC,364,https://link.springer.com/article/10.1057/dbm.2012.17,5278415376255007212,/scholar?cites=5278415376255007212,,,https://link.springer.com/article/10.1057/dbm.2012.17,0,0,0
1278371,Digital color image processing,2008,Andreas Koschan and Mongi Abidi,,,,,John Wiley & Sons,An introduction to color in three-dimensional image processing and the emerging area of multi-spectral image processing The importance of color information in digital image processing is greater than ever. However. the transition from scalar to vector-valued image functions has not yet been generally covered in most textbooks. Now. Digital Color Image Processing fills this pressing need with a detailed introduction to this important topic. In four comprehensive sections. this book covers: The fundamentals and requirements for color image processing from a vector-valued viewpoint Techniques for preprocessing color images Three-dimensional scene analysis using color information. as well as the emerging area of multi-spectral imaging Applications of color image processing. presented via the examination of two case studies In addition to introducing readers to important new technologies in the field. Digital Color Image Processing also contains novel topics such as: techniques for improving three-dimensional reconstruction. three-dimensional computer vision. and emerging areas of safety and security applications in luggage inspection and video surveillance of high-security facilities. Complete with full-color illustrations and two applications chapters. Digital Color Image Processing is the only book that covers the breadth of the subject under one convenient cover. It is written at a level that is accessible for first-and second-year graduate students in electrical and computer engineering and computer science courses. and that is also appropriate for researchers who wish to extend their knowledge in the area of color image processing.,True,VckVaRIAAAAJ:UeHWp8X0CEIC,359,http://books.google.com/books?hl=en&lr=&id=SlXgTyQ86VsC&oi=fnd&pg=PR1&dq=info:CkvUdQiRIZoJ:scholar.google.com&ots=5xADU7SqGk&sig=RAM-wqJMWfrACwpKC4_JaH9LXxg,11106317621594966794,/scholar?cites=11106317621594966794,,,https://pdfs.semanticscholar.org/3522/097a62ac89c9255426a66e7ebbea05ef3e16.pdf,0,0,0
1278372,Detection and classification of edges in color images,2005,Andreas Koschan and Mongi Abidi,22,IEEE Signal Processing Magazine,1,64-73,IEEE,Up to now. most of the color edge detection methods are monochromatic-based techniques. which produce. in general. better than when traditional gray-value techniques are applied. In this overview. we focus mainly on vector-valued techniques because it is easy to understand how to apply common edge detection schemes to every color component. Opposed to this. vector-valued techniques are new and different. The second part of the article addresses the topic of edge classification. While edges are often classified into step edges and ramp edges. we address the topic of physical edge classification based on their origin into shadow edges. reflectance edges. orientation edges. occlusion edges. and specular edges. In the rest of this article we discuss various vector-valued techniques for detecting discontinuities in color images. Then operators are presented based on vector order statistics. followed by …,True,VckVaRIAAAAJ:2osOgNQ5qMEC,269,https://ieeexplore.ieee.org/abstract/document/1407716/,17613231366206633602,/scholar?cites=17613231366206633602,,,https://www.researchgate.net/profile/Andreas_Koschan/publication/3321604_Detection_and_classification_of_edges_in_color_images/links/554bc7600cf21ed2135b789f.pdf,0,0,0
1278373,Perception-based 3D triangle mesh segmentation using fast marching watersheds,2003,AF Koschan,2,,,II-II,IEEE,In this paper. we describe an algorithm called fast marching watersheds that segments a triangle mesh into visual parts. This computer vision algorithm leverages a human vision theory known as the minima rule. Our implementation computes the principal curvatures and principal directions at each vertex of a mesh. and then our hill-climbing watershed algorithm identifies regions bounded by contours of negative curvature minima. These regions fit the definition of visual parts according to the minima rule. We present evaluation analysis and experimental results for the proposed algorithm.,True,VckVaRIAAAAJ:d1gkVwhDpl0C,259,https://ieeexplore.ieee.org/abstract/document/1211448/,13074766320315457574,/scholar?cites=13074766320315457574,,,https://www.researchgate.net/profile/Andreas_Koschan/publication/221364724_Perception-based_3D_Triangle_Mesh_Segmentation_Using_Fast_Marching_Watersheds/links/554bc7590cf29752ee7eba68.pdf,0,0,0
1278374,Radio frequency identification technology: applications. technical challenges and strategies,2006,Andreas Koschan and Suhong Li and John K Visich and Basheer M Khumawala and Chen Zhang,,Sensor Review,,,Emerald Group Publishing Limited,The purpose of this paper is to discuss the technology behind RFID systems. identify the applications of RFID in various industries. and discuss the technical challenges of RFID implementation and the corresponding strategies to overcome those challenges.,True,VckVaRIAAAAJ:hMsQuOkrut0C,226,https://www.emerald.com/insight/content/doi/10.1108/02602280610675474/full/html?fullSc=1,15341464529066114500,/scholar?cites=15341464529066114500,,,http://digitalcommons.bryant.edu/cgi/viewcontent.cgi?article=1040&context=manjou,0,0,0
1278375,Multiscale fusion of visible and thermal IR images for illumination-invariant face recognition,2007,Seong G Kong and Jingu Heo and Faysal Boughorbel and Yue Zheng and Besma R Abidi and Andreas Koschan and Mingzhong Yi and Mongi A Abidi,71,International Journal of Computer Vision,2,215-233,Kluwer Academic Publishers,This paper describes a new software-based registration and fusion of visible and thermal infrared (IR) image data for face recognition in challenging operating environments that involve illumination variations. The combined use of visible and thermal IR imaging sensors offers a viable means for improving the performance of face recognition techniques based on a single imaging modality. Despite successes in indoor access control applications. imaging in the visible spectrum demonstrates difficulties in recognizing the faces in varying illumination conditions. Thermal IR sensors measure energy radiations from the object. which is less sensitive to illumination changes. and are even operable in darkness. However. thermal images do not provide high-resolution data. Data fusion of visible and thermal images can produce face images robust to illumination variations. However. thermal face images with …,True,VckVaRIAAAAJ:W7OEmFMy1HYC,219,https://link.springer.com/content/pdf/10.1007/s11263-006-6655-0.pdf,8784641110328725310,/scholar?cites=8784641110328725310,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.481.1621&rep=rep1&type=pdf,0,0,0
1278376,A comparative study on color edge detection,1995,Andreas Koschan,3,Proceedings of the 2nd Asian Conference on Computer Vision,,574-578,ACCV Sigapore. Sigapore,Several approaches of different complexity already exist to edge detection in color images. Nevertheless. the question remains of how different are the results when employing computational costly techniques instead of simple ones. This paper presents a comparative study on different approaches to color edge detection. The approaches are based on the Sobel operator. the Laplace operator. the Mexican Hat operator. different realizations of the Cumani operator. and the Alshatti-Lambert operator. Furthermore. we present an efficient algorithm for implementing the Cumani operator. All operators have been applied to several synthetic and real images. The results are presented in this paper. We show that the quality of the results increases if Gaussian masks of larger width are used in the derivation process instead of simple 3 x 3 masks as suggested in the underlying papers. Moreover. multiresolution approaches can be applied to color images when using Gaussian masks with different standard deviations in the edge detection scheme.,True,VckVaRIAAAAJ:9yKSN-GCB0IC,196,https://pdfs.semanticscholar.org/e05e/2eefe335490fa2546e496c685fd07f629e98.pdf,13507520947726809214,/scholar?cites=13507520947726809214,,,https://pdfs.semanticscholar.org/e05e/2eefe335490fa2546e496c685fd07f629e98.pdf,0,0,0
1278377,Normal vector voting: crease detection and curvature estimation on large. noisy meshes,2002,David L Page and Yiyong Sun and Andreas F Koschan and Joonki Paik and Mongi A Abidi,64,Graphical models,3-4,199-229,Academic Press,This paper describes a robust method for crease detection and curvature estimation on large. noisy triangle meshes. We assume that these meshes are approximations of piecewise-smooth surfaces derived from range or medical imaging systems and thus may exhibit measurement or even registration noise. The proposed algorithm. which we call normal vector voting. uses an ensemble of triangles in the geodesic neighborhood of a vertex—instead of its simple umbrella neighborhood—to estimate the orientation and curvature of the original surface at that point. With the orientation information. we designate a vertex as either lying on a smooth surface. following a crease discontinuity. or having no preferred orientation. For vertices on a smooth surface. the curvature estimation yields both principal curvatures and principal directions while for vertices on a discontinuity we estimate only the curvature along the crease …,True,VckVaRIAAAAJ:qjMakFHDy7sC,195,https://www.sciencedirect.com/science/article/pii/S1524070302905746,5066754629681746359,/scholar?cites=5066754629681746359,,,https://imaging.utk.edu/publications/papers/2002/page_gm02.pdf,0,0,0
1278378,Real-time video tracking using PTZ cameras,2003,Sangkyu Kang and Joon-Ki Paik and Andreas Koschan and Besma R Abidi and Mongi A Abidi,5132,,,103-111,International Society for Optics and Photonics,Automatic tracking is essential for a 24 hours intruder-detection and. more generally. a surveillance system. This paper presents an adaptive background generation and the corresponding moving region detection techniques for a Pan-Tilt-Zoom (PTZ) camera using a geometric transform-based mosaicing method. A complete system including adaptive background generation. moving regions extraction and tracking is evaluated using realistic experimental results. More specifically. experimental results include generated background images. a moving region. and input video with bounding boxes around moving objects. This experiment shows that the proposed system can be used to monitor moving targets in widely open areas by automatic panning and tilting in real-time.,True,VckVaRIAAAAJ:ufrVoPGSRksC,156,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5132/0000/Real-time-video-tracking-using-PTZ-cameras/10.1117/12.514945.short,2517209200441330176,/scholar?cites=2517209200441330176,,,https://www.researchgate.net/profile/Sangkyu_Kang/publication/228598087_Real-time_video_tracking_using_PTZ_cameras/links/0c96052085dbbac714000000.pdf,0,0,0
1278379,Secrets of optical flow estimation and their principles,2010,Deqing Sun and Stefan Roth and Michael J Black,,,,2432-2439,IEEE,The accuracy of optical flow estimation algorithms has been improving steadily as evidenced by results on the Middlebury optical flow benchmark. The typical formulation. however. has changed little since the work of Horn and Schunck. We attempt to uncover what has made recent advances possible through a thorough analysis of how the objective function. the optimization method. and modern implementation practices influence accuracy. We discover that “classical” flow formulations perform surprisingly well when combined with modern optimization and implementation techniques. Moreover. we find that while median filtering of intermediate flow fields during optimization is a key to recent performance gains. it leads to higher energy solutions. To understand the principles behind this phenomenon. we derive a new objective that formalizes the median filtering heuristic. This objective includes a nonlocal term that …,True,t4rgICIAAAAJ:u-x6o8ySG0sC,1598,https://ieeexplore.ieee.org/abstract/document/5539939/,5821194254180746892,/scholar?cites=5821194254180746892,,,https://users.soe.ucsc.edu/~pang/200/f18/papers/2018/05539939.pdf,0,0,0
1278380,PWC-Net: CNNs for Optical Flow Using Pyramid. Warping. and Cost Volume,2018,Deqing Sun and Xiaodong Yang and Ming-Yu Liu and Jan Kautz,,,,8934-8943,,We present a compact but effective CNN model for optical flow. called PWC-Net. PWC-Net has been designed according to simple and well-established principles: pyramidal processing. warping. and the use of a cost volume. Cast in a learnable feature pyramid. PWC-Net uses the current optical flow estimate to warp the CNN features of the second image. It then uses the warped features and features of the first image to construct a cost volume. which is processed by a CNN to estimate the optical flow. PWC-Net is 17 times smaller in size and easier to train than the recent FlowNet2 model. Moreover. it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015 benchmarks. running at about 35 fps on Sintel resolution (1024x436) images. Our models are available on our project website.,True,t4rgICIAAAAJ:R3hNpaxXUhUC,866,http://openaccess.thecvf.com/content_cvpr_2018/html/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.html,5637139753418325919,/scholar?cites=5637139753418325919,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.pdf,0,0,0
1278381,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang,,,,114-125,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,t4rgICIAAAAJ:TQgYirikUcIC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1278382,A quantitative analysis of current practices in optical flow estimation and the principles behind them,2014,D Sun and S Roth and MJ Black,106,International Journal of Computer Vision,2,115-137,Springer,The accuracy of optical flow estimation algorithms has been improving steadily as evidenced by results on the Middlebury optical flow benchmark. The typical formulation. however. has changed little since the work of Horn and Schunck. We attempt to uncover what has made recent advances possible through a thorough analysis of how the objective function. the optimization method. and modern implementation practices influence accuracy. We discover that “classical” flow formulations perform surprisingly well when combined with modern optimization and implementation techniques. One key implementation detail is the median filtering of intermediate flow fields during optimization. While this improves the robustness of classical methods it actually leads to higher energy solutions. meaning that these methods are not optimizing the original objective function. To understand the principles behind this …,True,t4rgICIAAAAJ:8k81kl-MbHgC,522,https://link.springer.com/content/pdf/10.1007/s11263-013-0644-x.pdf,6511291691793140015,/scholar?cites=6511291691793140015,,,https://link.springer.com/content/pdf/10.1007/s11263-013-0644-x.pdf,0,0,0
1278383,Blind image deblurring using dark channel prior,2016,Jinshan Pan and Deqing Sun and Hanspeter Pfister and Ming-Hsuan Yang,,,,1628-1636,,We present a simple and effective blind image deblurring method based on the dark channel prior. Our work is inspired by the interesting observation that the dark channel of blurred images is less sparse. While most image patches in the clean image contain some dark pixels. these pixels are not dark when averaged with neighboring high-intensity pixels during the blur process. Our analysis shows that this change in the sparsity of the dark channel is an inherent property of the blur process. both theoretically and empirically. This change in the sparsity of the dark channel is an inherent property of the blur process. which we both prove mathematically and validate using training data. Therefore. enforcing the sparsity of the dark channel helps blind deblurring on various scenarios. including natural. face. text. and low-illumination images. However. sparsity of the dark channel introduces a non-convex non-linear optimization problem. We introduce a linear approximation of the min operator to compute the dark channel. Our look-up-table-based method converges fast in practice and can be directly extended to non-uniform deblurring. Extensive experiments show that our method achieves state-of-the-art results on deblurring natural images and compares favorably methods that are well-engineered for specific scenarios.,True,t4rgICIAAAAJ:hC7cP41nSMkC,416,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Pan_Blind_Image_Deblurring_CVPR_2016_paper.html,9986114152538067874,/scholar?cites=9986114152538067874,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Pan_Blind_Image_Deblurring_CVPR_2016_paper.pdf,0,0,0
1278384,Splatnet: Sparse lattice networks for point cloud processing,2018,Hang Su and Varun Jampani and Deqing Sun and Subhransu Maji and Evangelos Kalogerakis and Ming-Hsuan Yang and Jan Kautz,,,,2530-2539,,We present a network architecture for processing point clouds that directly operates on a collection of points represented as a sparse set of samples in a high-dimensional lattice. Naively applying convolutions on this lattice scales poorly. both in terms of memory and computational cost. as the size of the lattice increases. Instead. our network uses sparse bilateral convolutional layers as building blocks. These layers maintain efficiency by using indexing structures to apply convolutions only on occupied parts of the lattice. and allow flexible specifications of the lattice structure enabling hierarchical and spatially-aware feature learning. as well as joint 2D-3D reasoning. Both point-based and image-based representations can be easily incorporated in a network with such layers and the resulting model can be trained in an end-to-end manner. We present results on 3D segmentation tasks where our approach outperforms existing state-of-the-art techniques.,True,t4rgICIAAAAJ:r0BpntZqJG4C,373,http://openaccess.thecvf.com/content_cvpr_2018/html/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.html,13061080896686849882,/scholar?cites=13061080896686849882,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.pdf,0,0,0
1278385,Learning optical flow,2008,Deqing Sun and Stefan Roth and JP Lewis and Michael Black,,,,,Springer US,Assumptions of brightness constancy and spatial smoothness underlie most optical flow estimation methods. In contrast to standard heuristic formulations. we learn a statistical model of both brightness constancy error and the spatial properties of optical flow using image sequences with associated ground truth flow fields. The result is a complete probabilistic model of optical flow. Specifically. the ground truth enables us to model how the assumption of brightness constancy is violated in naturalistic sequences. resulting in a probabilistic model of “brightness inconstancy”. We also generalize previous high-order constancy assumptions. such as gradient constancy. by modeling the constancy of responses to various linear filters in a high-order random field framework. These filters are free variables that can be learned from training data. Additionally we study the spatial structure of the optical flow and how …,True,t4rgICIAAAAJ:u5HHmVD_uO8C,315,https://link.springer.com/chapter/10.1007/978-3-540-88690-7_7,12628563045908321649,/scholar?cites=12628563045908321649,,,https://link.springer.com/content/pdf/10.1007/978-3-540-88690-7_7.pdf,0,0,0
1278386,Super slomo: High quality estimation of multiple intermediate frames for video interpolation,2018,Huaizu Jiang and Deqing Sun and Varun Jampani and Ming-Hsuan Yang and Erik Learned-Miller and Jan Kautz,,,,9000-9008,,Given two consecutive frames. video interpolation aims at generating intermediate frame (s) to form both spatially and temporally coherent video sequences. While most existing methods focus on single-frame interpolation. we propose an end-to-end convolutional neural network for variable-length multi-frame video interpolation. where the motion interpretation and occlusion reasoning are jointly modeled. We start by computing bi-directional optical flow between the input images using a U-Net architecture. These flows are then linearly combined at each time step to approximate the intermediate bi-directional optical flows. These approximate flows. however. only work well in locally smooth regions and produce artifacts around motion boundaries. To address this shortcoming. we employ another U-Net to refine the approximated flow and also predict soft visibility maps. Finally. the two input images are warped and linearly fused to form each intermediate frame. By applying the visibility maps to the warped images before fusion. we exclude the contribution of occluded pixels to the interpolated intermediate frame to avoid artifacts. Since none of our learned network parameters are time-dependent. our approach is able to produce as many intermediate frames as needed. To train our network. we use 1.132 240-fps video clips. containing 300K individual video frames. Experimental results on several datasets. predicting different numbers of interpolated frames. demonstrate that our approach performs consistently better than existing methods.,True,t4rgICIAAAAJ:_Qo2XoVZTnwC,264,http://openaccess.thecvf.com/content_cvpr_2018/html/Jiang_Super_SloMo_High_CVPR_2018_paper.html,8547871125777074240,/scholar?cites=8547871125777074240,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Jiang_Super_SloMo_High_CVPR_2018_paper.pdf,0,0,0
1278387,On Bayesian adaptive video super resolution,2014,Ce Liu and Deqing Sun,36,"Pattern Analysis and Machine Intelligence, IEEE Transactions on",2,346 - 360,IEEE,Although multiframe super resolution has been extensively studied in past decades. super resolving real-world video sequences still remains challenging. In existing systems. either the motion models are oversimplified or important factors such as blur kernel and noise level are assumed to be known. Such models cannot capture the intrinsic characteristics that may differ from one sequence to another. In this paper. we propose a Bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion. blur kernel. and noise level while reconstructing the original high-resolution frames. As a result. our system not only produces very promising super resolution results outperforming the state of the art. but also adapts to a variety of noise levels and blur kernels. To further analyze the effect of noise and blur kernel. we perform a two-step analysis using the Cramer-Rao bounds. We study …,True,t4rgICIAAAAJ:kNdYIx-mwKoC,244,https://ieeexplore.ieee.org/abstract/document/6549107/,5248228153497691815,/scholar?cites=5248228153497691815,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.707.357&rep=rep1&type=pdf,0,0,0
1278388,A bayesian approach to adaptive video super resolution,2011,Ce Liu and Deqing Sun,,,,209-216,IEEE,Although multi-frame super resolution has been extensively studied in past decades. super resolving real-world video sequences still remains challenging. In existing systems. either the motion models are oversimplified. or important factors such as blur kernel and noise level are assumed to be known. Such models cannot deal with the scene and imaging conditions that vary from one sequence to another. In this paper. we propose a Bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion. blur kernel and noise level while reconstructing the original high-res frames. As a result. our system not only produces very promising super resolution results that outperform the state of the art. but also adapts to a variety of noise levels and blur kernels. Theoretical analysis of the relationship between blur kernel. noise level and frequency-wise reconstruction rate is also provided …,True,t4rgICIAAAAJ:UeHWp8X0CEIC,226,https://ieeexplore.ieee.org/abstract/document/5995614/,14626274825947253738,/scholar?cites=14626274825947253738,,,https://www.academia.edu/download/46030053/Liu2011Video.pdf,0,0,0
1278389,Competitive collaboration: Joint unsupervised learning of depth. camera motion. optical flow and motion segmentation,2019,Anurag Ranjan and Varun Jampani and Lukas Balles and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J Black,,,,12240-12249,,We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction. camera motion estimation. optical flow. and segmentation of a video into the static scene and moving regions. Our key insight is that these four fundamental vision problems are coupled through geometric constraints. Consequently. learning to solve them together simplifies the problem because the solutions can reinforce each other. We go beyond previous work by exploiting geometry more explicitly and segmenting the scene into static and moving regions. To that end. we introduce Competitive Collaboration. a framework that facilitates the coordinated training of multiple specialized neural networks to solve complex problems. Competitive Collaboration works much like expectation-maximization. but with neural networks that act as both competitors to explain pixels that correspond to static or moving regions. and as collaborators through a moderator that assigns pixels to be either static or independently moving. Our novel method integrates all these problems in a common framework and simultaneously reasons about the segmentation of the scene into moving objects and the static background. the camera motion. depth of the static scene structure. and the optical flow of moving objects. Our model is trained without any supervision and achieves state-of-the-art performance among joint unsupervised methods on all sub-problems.,True,t4rgICIAAAAJ:isC4tDSrTZIC,192,http://openaccess.thecvf.com/content_CVPR_2019/html/Ranjan_Competitive_Collaboration_Joint_Unsupervised_Learning_of_Depth_Camera_Motion_Optical_CVPR_2019_paper.html,8899288224036536376,/scholar?cites=8899288224036536376,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Ranjan_Competitive_Collaboration_Joint_Unsupervised_Learning_of_Depth_Camera_Motion_Optical_CVPR_2019_paper.pdf,0,0,0
1278390,RANSAC-based DARCES: A new approach to fast automatic registration of partially overlapping range images,1999,Chu-Song Chen and Yi-Ping Hung and Jen-Bo Cheng,21,IEEE Transactions on Pattern Analysis and Machine Intelligence,11,1229-1234,IEEE,In this paper. we propose a new method. the RANSAC-based DARCES method (data-aligned rigidity-constrained exhaustive search based on random sample consensus). which can solve the partially overlapping 3D registration problem without any initial estimation. For the noiseless case. the basic algorithm of our method can guarantee that the solution it finds is the true one. and its time complexity can be shown to be relatively low. An extra characteristic is that our method can be used even for the case that there are no local features in the 3D data sets.,True,gUYquw0AAAAJ:u5HHmVD_uO8C,440,https://ieeexplore.ieee.org/abstract/document/809117/,15895821643925328995,/scholar?cites=15895821643925328995,,,https://www.academia.edu/download/23647780/chen99_darces.pdf,0,0,0
1278391,Ordinal hyperplanes ranker with cost sensitivities for age estimation,2011,Kuang-Yu Chang and Chu-Song Chen and Yi-Ping Hung,,,,585-592,IEEE,In this paper. we propose an ordinal hyperplane ranking algorithm called OHRank. which estimates human ages via facial images. The design of the algorithm is based on the relative order information among the age labels in a database. Each ordinal hyperplane separates all the facial images into two groups according to the relative order. and a cost-sensitive property is exploited to find better hyperplanes based on the classification costs. Human ages are inferred by aggregating a set of preferences from the ordinal hyperplanes with their cost sensitivities. Our experimental results demonstrate that the proposed approach outperforms conventional multiclass-based and regression-based approaches as well as recently developed ranking-based age estimation approaches.,True,gUYquw0AAAAJ:f2IySw72cVMC,342,https://ieeexplore.ieee.org/abstract/document/5995437/,8313390000088422612,/scholar?cites=8313390000088422612,,,https://homepage.iis.sinica.edu.tw/~kuangyu/OHRank_files/0523.pdf,0,0,0
1278392,Fast block matching algorithm based on the winner-update strategy,2001,Yong-Sheng Chen and Yi-Ping Hung and Chiou-Shann Fuh,10,IEEE Transactions on Image Processing,8,1212-1222,IEEE,Block matching is a widely used method for stereo vision. visual tracking. and video compression. Many fast algorithms for block matching have been proposed in the past. but most of them do not guarantee that the match found is the globally optimal match in a search range. This paper presents a new fast algorithm based on the winner-update strategy which utilizes an ascending lower bound list of the matching error to determine the temporary winner. Two lower bound lists derived by using partial distance and by using Minkowski's inequality are described. The basic idea of the winner-update strategy is to avoid. at each search position. the costly computation of the matching error when there exists a lower bound larger than the global minimum matching error. The proposed algorithm can significantly speed up the computation of the block matching because (1) computational cost of the lower bound we use is less …,True,gUYquw0AAAAJ:u-x6o8ySG0sC,270,https://ieeexplore.ieee.org/abstract/document/935037/,13342443009919782750,/scholar?cites=13342443009919782750,,,https://www.researchgate.net/profile/Chiou-Shann_Fuh/publication/3327415_Fast_block_matching_algorithm_based_on_the_winner-update_strategy/links/00b4951fa27ea079ad000000/Fast-block-matching-algorithm-based-on-the-winner-update-strategy.pdf,0,0,0
1278393,Image registration using a new edge-based approach,1997,Jun-Wei Hsieh and Hong-Yuan Mark Liao and Kuo-Chin Fan and Ming-Tat Ko and Yi-Ping Hung,67,Computer vision and image understanding,2,112-130,Academic Press,A new edge-based approach for efficient image registration is proposed. The proposed approach applies wavelet transform to extract a number of feature points as the basis for registration. Each selected feature point is an edge point whose edge response is the maximum within a neighborhood. By using a line-fitting model. all the edge directions of the feature points are estimated from the edge outputs of a transformed image. In order to estimate the orientation difference between two partially overlapping images. a so-called “angle histogram” is calculated. From the angle histogram. the rotation angle which can be used to compensate for the difference between two target images can be decided by seeking the angle that corresponds to the maximum peak in the histogram. Based on the rotation angle. an initial matching can be performed. During the real matching process. we check each candidate pair in advance …,True,gUYquw0AAAAJ:d1gkVwhDpl0C,225,https://www.sciencedirect.com/science/article/pii/S1077314296905172,13994969292377807547,/scholar?cites=13994969292377807547,,,http://iis.sinica.edu.tw/papers/mtko/249-F.pdf,0,0,0
1278394,Efficient hierarchical method for background subtraction,2007,Yu-Ting Chen and Chu-Song Chen and Chun-Rong Huang and Yi-Ping Hung,40,Pattern Recognition,10,2706-2715,Pergamon,Detecting moving objects by using an adaptive background model is a critical component for many vision-based applications. Most background models were maintained in pixel-based forms. while some approaches began to study block-based representations which are more robust to non-stationary backgrounds. In this paper. we propose a method that combines pixel-based and block-based approaches into a single framework. We show that efficient hierarchical backgrounds can be built by considering that these two approaches are complementary to each other. In addition. a novel descriptor is proposed for block-based background modeling in the coarse level of the hierarchy. Quantitative evaluations show that the proposed hierarchical method can provide better results than existing single-level approaches.,True,gUYquw0AAAAJ:zYLM7Y9cAGgC,205,https://www.sciencedirect.com/science/article/pii/S003132030600495X,14298790769055297216,/scholar?cites=14298790769055297216,,,https://scholars.lib.ntu.edu.tw/bitstream/123456789/117630/1/23.pdf,0,0,0
1278395,Range data acquisition using color structured lighting and stereo vision,1997,Chu-Song Chen and Yi-Ping Hung and Chiann-Chu Chiang and Ja-Ling Wu,15,Image and vision computing,6,445-456,Elsevier,This paper presents a new color-lighting/stereo method for 3D range data acquisition by combining color structured lighting and stereo vision. A major advantage of using stereo vision together with color stripes lighting is that there is no need to solve the problem of finding the correspondence between the color stripes projected by the light source and the color stripes observed in the images. That is. the more difficult problem of finding the correct color stripe correspondence problem between the light source and the image is replaced by an easier image-to-image stereo correspondence — which is not only easier than the above lighting-to-image correspondence problem. but also easier than the traditional stereo correspondence because a good color pattern has been projected onto the object. Another advantage of using stereo vision is that there is no need to calibrate the position and orientation for each of the …,True,gUYquw0AAAAJ:9yKSN-GCB0IC,162,https://www.sciencedirect.com/science/article/pii/S0262885696011481,7110656558669000806,/scholar?cites=7110656558669000806,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.415.4394&rep=rep1&type=pdf,0,0,0
1278396,Panoramic stereo imaging system with automatic disparity warping and seaming,1998,Ho-Chao Huang and Yi-Ping Hung,60,Graphical Models and Image Processing,3,196-208,Academic Press,Two commonly used approaches for building a virtual reality (VR) world are the model-based approach and the image-based approach. Recently. the image-based approach has received much attention for its advantages of being easier to build a VR model and of being able to provide photo-realistic views. However. traditional image-based VR systems cannot produce the stereo views that can give the users the feeling of 3D depth. In this paper. we present a panoramic stereo imaging (PSI) system which can produce stereo panoramas for image-based VR systems. This PSI system is referred to as the PSI-II system. which is an improved system of our previous experimental PSI-I system. The PSI-I system uses a well-calibrated tripod system to acquire a series of stereo image pairs. while the PSI-II system does not require the use of a well-calibrated tripod system and can automatically generate a stereo-pair of …,True,gUYquw0AAAAJ:2osOgNQ5qMEC,137,https://www.sciencedirect.com/science/article/pii/S1077316998904671,4903388837963429231,/scholar?cites=4903388837963429231,,,https://pdfs.semanticscholar.org/9e40/69f6508a436a7be57420f2e363d4d9a30377.pdf,0,0,0
1278397,A ranking approach for human ages estimation based on face images,2010,Kuang-Yu Chang and Chu-Song Chen and Yi-Ping Hung,,,,3396-3399,IEEE,In our daily life. it is much easier to distinguish which person is elder between two persons than how old a person is. When inferring a person's age. we may compare his or her face with many people whose ages are known. resulting in a series of comparative results. and then we conjecture the age based on the comparisons. This process involves numerous pairwise preferences information obtained by a series of queries. where each query compares the target person's face to those faces in a database. In this paper. we propose a ranking-based framework consisting of a set of binary queries. Each query collects a binary-classification-based comparison result. All the query results are then fused to predict the age. Experimental results show that our approach performs better than traditional multi-class-based and regression-based approaches for age estimation.,True,gUYquw0AAAAJ:8AbLer7MMksC,124,https://ieeexplore.ieee.org/abstract/document/5597533/,567498490159559397,/scholar?cites=567498490159559397,,,http://www.iis.sinica.edu.tw/papers/song/10774-F.pdf,0,0,0
1278398,Comparison between immersion-based and toboggan-based watershed image segmentation,2006,Yung-Chieh Lin and Yu-Pao Tsai and Yi-Ping Hung and Zen-Chung Shih,15,IEEE Transactions on image processing,3,632-640,IEEE,"Watershed segmentation has recently become a popular tool for image segmentation. There are two approaches to implementing watershed segmentation: immersion approach and toboggan simulation. Conceptually. the immersion approach can be viewed as an approach that starts from low altitude to high altitude and the toboggan approach as an approach that starts from high altitude to low altitude. The former seemed to be more popular recently (e.g.. Vincent and Soille). but the latter had its own supporters (e.g.. Mortensen and Barrett). It was not clear whether the two approaches could lead to exactly the same segmentation result and which approach was more efficient. In this paper. we present two ""order-invariant"" algorithms for watershed segmentation. one based on the immersion approach and the other on the toboggan approach. By introducing a special RIDGE label to achieve the property of order …",True,gUYquw0AAAAJ:Y0pCki6q_DkC,124,https://ieeexplore.ieee.org/abstract/document/1593667/,3312110431514689349,/scholar?cites=3312110431514689349,,,https://ir.nctu.edu.tw/bitstream/11536/12573/1/000235403100010.pdf,0,0,0
1278399,A fast automatic method for registration of partially-overlapping range images,1998,Chu-Song Chen and Yi-Ping Hung and Jen-Bo Cheng,,,,242-248,IEEE,A popular approach for 3D registration of partially-overlapping range images is the ICP (iterative closest point) method and many of its variations. The major drawback of this type of iterative approaches is that they require a good initial estimate to guarantee that the correct solution can always be found. In this paper. we propose a new method. the RANSAC-based DARCES (data-aligned rigidity-constrained exhaustive search) method. which can solve the partially-overlapping 3D registration problem efficiently and reliably without any initial estimation. Another important characteristic of our method is that it requires no local features in the 3D data set. An extra characteristic is that. for the noiseless case. the basic algorithm of our DARCES method can guarantee that the solution it finds is the true one. due to its exhaustive-search nature. Even with the nature of exhaustive search. its time complexity can be shown to be …,True,gUYquw0AAAAJ:qjMakFHDy7sC,120,https://ieeexplore.ieee.org/abstract/document/710725/,2161255284487414603,/scholar?cites=2161255284487414603,,,http://www.iis.sinica.edu.tw/papers/song/11513-F.pdf,0,0,0
1278400,Why recognition in a statistics-based face recognition system should be based on the pure face portion: a probabilistic decision-based proof,2001,Li-Fen Chen and Hong-Yuan Mark Liao and Ja-Chen Lin and Chin-Chuan Han,34,Pattern recognition,7,1393-1403,Pergamon,It is evident that the process of face recognition. by definition. should be based on the content of a face. The problem is: what is a “face”? Recently. a state-of-the-art statistics-based face recognition system. the PCA plus LDA approach. has been proposed (Swets and Weng. IEEE Trans. Pattern. Anal. Mach. Intell. 18 (8) (1996) 831–836). However. the authors used “face” images that included hair. shoulders. face and background. Our intuition tells us that only a recognition process based on a “pure” face portion can be called face recognition. The mixture of irrelevant data may result in an incorrect set of decision boundaries. In this paper. we propose a statistics-based technique to quantitatively prove our assertion. For the purpose of evaluating how the different portions of a face image will influence the recognition results. a hypothesis testing model is proposed. We then implement the above mentioned face …,True,gUYquw0AAAAJ:DkZNVXde3BIC,116,https://www.sciencedirect.com/science/article/pii/S0031320300000789,3285966377342732834,/scholar?cites=3285966377342732834,,,https://ir.nctu.edu.tw/bitstream/11536/29522/1/000168580100005.pdf,0,0,0
1278401,Fast visibility restoration from a single color or gray level image,2009,Jean-Philippe Tarel and Nicolas Hautiere,,,,2201-2208,IEEE,One source of difficulties when processing outdoor images is the presence of haze. fog or smoke which fades the colors and reduces the contrast of the observed objects. We introduce a novel algorithm and variants for visibility restoration from a single image. The main advantage of the proposed algorithm compared with other is its speed: its complexity is a linear function of the number of image pixels only. This speed allows visibility restoration to be applied for the first time within real-time processing applications such as sign. lane-marking and obstacle detection from an in-vehicle camera. Another advantage is the possibility to handle both color images or gray level images since the ambiguity between the presence of fog and the objects with low color saturation is solved by assuming only small objects can have colors with low saturation. The algorithm is controlled only by a few parameters and consists in …,True,iOzz0lcAAAAJ:8k81kl-MbHgC,1444,https://ieeexplore.ieee.org/abstract/document/5459251/,6632438392896404283,/scholar?cites=6632438392896404283,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.6008&rep=rep1&type=pdf,0,0,0
1278402,Real time obstacle detection in stereovision on non flat road geometry through v-disparity representation,2002,Raphael Labayrade and Didier Aubert and Jean-Philippe Tarel,2,,,"646-651, vol. 2",Ieee,"Presents a road obstacle detection method able to cope with uphill and downhill gradients and dynamic pitching of the vehicle. Our approach is based on the construction and investigation of the ""v-disparity"" image which provides a good representation of the geometric content of the road scene. The advantage of this image is that it provides semi-global matching and is able to perform robust obstacle detection even in the case of partial occlusion or errors committed during the matching process. Furthermore. this detection is performed without any explicit extraction of coherent structures. This paper explains the construction of the ""v-disparity"" image. its main properties. and the obstacle detection method. The longitudinal profile of the road is estimated and the objects located above the road surface are then extracted as potential obstacles; subsequently. the accurate detection of road obstacles. in particular the …",True,iOzz0lcAAAAJ:UebtZRa9Y70C,936,https://ieeexplore.ieee.org/abstract/document/1188024/,15412986095397348711,/scholar?cites=15412986095397348711,,,https://www.researchgate.net/profile/Jean-Philippe_Tarel/publication/241815073_Real_time_obstacle_detection_on_non_flat_road_geometry_through_v-disparity_representation_in_'IEEE_Intelligent_Vehicles_Symposium/links/0deec537c742be73a2000000/Real-time-obstacle-detection-on-non-flat-road-geometry-through-v-disparity-representation-in-IEEE-Intelligent-Vehicles-Symposium.pdf,0,0,0
1278403,Blind contrast restoration assessment by gradient rationing at visible edges,2007,NICOLAS Hautière and JEAN-PHILIPPE Tarel and DIDIER Aubert and E Dumont,,,,,,,True,iOzz0lcAAAAJ:J-pR_7NvFogC,643,http://scholar.google.com/scholar?cluster=12261871804555778166&hl=en&oi=scholarr,15203805690905007714,/scholar?cites=15203805690905007714,,,,0,0,0
1278404,Blind contrast restoration assessment by gradient radioing at visible edges,,N Hautiere and JP Tarel and D Aubert and E Dumont,27,,2,87-95,,,True,iOzz0lcAAAAJ:bnK-pcrLprsC,643,,15203805690905007714,/scholar?cites=15203805690905007714,,,,0,0,0
1278405,Blind contrast enhancement assessment by gradient ratioing at visible edges,2011,Nicolas Hautière and Jean-Philippe Tarel and Didier Aubert and Eric Dumont,27,Image Analysis & Stereology,2,87-95,,The contrast of outdoor images acquired under adverse weather conditions. especially foggy weather. is altered by the scattering of daylight by atmospheric particles. As a consequence. differentmethods have been designed to restore the contrast of these images. However. there is a lack of methodology to assess the performances of the methods or to rate them. Unlike image quality assessment or image restoration areas. there is no easy way to have a reference image. which makes the problem not straightforward to solve. In this paper. an approach is proposed which consists in computing the ratio between the gradient of the visible edges between the image before and after contrast restoration. In this way. an indicator of visibility enhancement is provided based on the concept of visibility level. commonly used in lighting engineering. Finally. the methodology is applied to contrast enhancement assessment and to the comparison of tone-mapping operators.,True,iOzz0lcAAAAJ:XiVPGOgt02cC,640,http://www.ias-iss.org/ojs/IAS/article/view/834,15203805690905007714,/scholar?cites=15203805690905007714,,,http://www.ias-iss.org/ojs/IAS/article/download/834/737,0,0,0
1278406,Blind contrast enhancement assessment by gradient ratioing at visible edges,2008,Nicolas Hautière and Jean-Philippe Tarel and Didier Aubert and Éric Dumont,27,Image Analysis & Stereology Journal,2,87-95,,The contrast of outdoor images acquired under adverse weather conditions. especially foggy weather. is altered by the scattering of daylight by atmospheric particles. As a consequence. differentmethods have been designed to restore the contrast of these images. However. there is a lack of methodology to assess the performances of the methods or to rate them. Unlike image quality assessment or image restoration areas. there is no easy way to have a reference image. which makes the problem not straightforward to solve. In this paper. an approach is proposed which consists in computing the ratio between the gradient of the visible edges between the image before and after contrast restoration. In this way. an indicator of visibility enhancement is provided based on the concept of visibility level. commonly used in lighting engineering. Finally. the methodology is applied to contrast enhancement assessment and to the comparison of tone-mapping operators.,True,iOzz0lcAAAAJ:mB3voiENLucC,640,http://www.ias-iss.org/ojs/IAS/article/view/834,15203805690905007714,/scholar?cites=15203805690905007714,,,http://www.ias-iss.org/ojs/IAS/article/download/834/737,0,0,0
1278407,Vision Enhancement in Homogeneous and Heterogeneous Fog,2012,Jean-Philippe Tarel and Nicolas Hautière and Aurélien Cord and Houssam Halmaoui and Laurent Caraffa and Dominique Gruyer,4,IEEE Intelligent Transportation Systems Magazine,2,6-20,IEEE,One source of accidents when driving a vehicle is the presence of fog. Fog fades the colors and reduces the contrasts in the scene with respect to their distances from the driver. Various camera-based Advanced Driver Assistance Systems (ADAS) can be improved if efficient algorithms are designed for visibility enhancement in road images. The visibility enhancement algorithm proposed in [1] is not optimized for road images. In this paper. we reformulate the problem as the inference of the local atmospheric veil from constraints. The algorithm in [1] thus becomes a particular case. From this new derivation. we propose to better handle road images by introducing an extra constraint taking into account that a large part of the image can be assumed to be a planar road. The advantages of the proposed local algorithm are the speed. the possibility to handle both color and gray-level images. and the small number of …,True,iOzz0lcAAAAJ:1sJd4Hv_s6UC,321,https://ieeexplore.ieee.org/abstract/document/6190796/,9939514907529524530,/scholar?cites=9939514907529524530,,,https://hal.inria.fr/hal-00707039/file/jpt-itsm12.pdf,0,0,0
1278408,Automatic fog detection and estimation of visibility distance through use of an onboard camera,2006,Nicolas Hautière and Jean-Philippe Tarel and Jean Lavenant and Didier Aubert,17,Machine Vision and Applications,1,8-20,Springer-Verlag,In this paper. we will present a technique for measuring visibility distances under foggy weather conditions using a camera mounted onboard a moving vehicle. Our research has focused in particular on the problem of detecting daytime fog and estimating visibility distances; thanks to these efforts. an original method has been developed. tested and patented. The approach consists of dynamically implementing Koschmieder's law. Our method enables computing the meteorological visibility distance. a measure defined by the International Commission on Illumination (CIE) as the distance beyond which a black object of an appropriate dimension is perceived with a contrast of less than 5%. Our proposed solution is an original one. featuring the advantage of utilizing a single camera and necessitating the presence of just the road and sky in the scene. As opposed to other methods that require the explicit …,True,iOzz0lcAAAAJ:0EnyYjriUFMC,305,https://link.springer.com/article/10.1007/s00138-005-0011-1,2683475417728458955,/scholar?cites=2683475417728458955,,,http://perso.lcpc.fr/tarel.jean-philippe/publis/jpt-mva06.pdf,0,0,0
1278409,Rain or snow detection in image sequences through use of a histogram of orientation of streaks,2011,Jérémie Bossu and Nicolas Hautiere and Jean-Philippe Tarel,93,International journal of computer vision,3,348-367,Springer US,The detection of bad weather conditions is crucial for meteorological centers. specially with demand for air. sea and ground traffic management. In this article. a system based on computer vision is presented which detects the presence of rain or snow. To separate the foreground from the background in image sequences. a classical Gaussian Mixture Model is used. The foreground model serves to detect rain and snow. since these are dynamic weather phenomena. Selection rules based on photometry and size are proposed in order to select the potential rain streaks. Then a Histogram of Orientations of rain or snow Streaks (HOS). estimated with the method of geometric moments. is computed. which is assumed to follow a model of Gaussian-uniform mixture. The Gaussian distribution represents the orientation of the rain or the snow whereas the uniform distribution represents the orientation of the noise. An …,True,iOzz0lcAAAAJ:70eg2SAEIzsC,256,https://link.springer.com/article/10.1007/s11263-011-0421-7,2273378667985352773,/scholar?cites=2273378667985352773,,,http://hautiere.nicolas.free.fr/pdf/2011/hautiere-ijcv11.pdf,0,0,0
1278410,Towards fog-free in-vehicle vision systems through contrast restoration,2007,Nicolas Hautière and Jean-Philippe Tarel and Didier Aubert,,,,1-8,IEEE,In foggy weather. the contrast of images grabbed by in-vehicle cameras in the visible light range is drastically degraded. which makes the current applications very sensitive to weather conditions. An onboard vision system should take fog effects into account. The effects of fog varies across the scene and are exponential with respect to the depth of scene points. Because it is not possible in this context to compute the road scene structure beforehand contrary to fixed camera surveillance. a new scheme is proposed. Weather conditions are first estimated and then used to restore the contrast according to a scene structure which is inferred a priori and refined during the restoration process. Based on the aimed application. different algorithms with increasing complexities are proposed. Results are presented using sample road scenes under foggy weather and assessed by computing the contrast before and after …,True,iOzz0lcAAAAJ:ULOm3_A8WrAC,224,https://ieeexplore.ieee.org/abstract/document/4270284/,1835267689511170091,/scholar?cites=1835267689511170091,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.6262&rep=rep1&type=pdf,0,0,0
1278411,Evaluation of road marking feature extraction,2008,Thomas Veit and J-P Tarel and Philippe Nicolle and Pierre Charbonnier,,,,174-181,Ieee,This paper proposes a systematic approach to evaluate algorithms for extracting road marking features from images. This specific topic is seldom addressed in the literature while many road marking detection algorithms have been proposed. Most of them can be decomposed into three steps: extracting road marking features. estimating a geometrical marking model. tracking the parameters of the geometrical model along an image sequence. The present work focuses on the first step. i.e. feature extraction. A reference database containing over 100 images of natural road scenes was built with corresponding manually labeled ground truth images (available at http://www.lcpc.fr/en/produits/ride/). This database enables to evaluate and compare extractors in a systematic way. Different road marking feature extraction algorithm representing different classes of techniques are evaluated: thresholding. gradient analysis …,True,iOzz0lcAAAAJ:M3ejUd6NZC8C,214,https://ieeexplore.ieee.org/abstract/document/4732564/,13328063768574470710,/scholar?cites=13328063768574470710,,,https://www.researchgate.net/profile/Jean-Philippe_Tarel/publication/224364852_Evaluation_of_Road_Marking_Feature_Extraction/links/0fcfd50ae3f2a5d970000000/Evaluation-of-Road-Marking-Feature-Extraction.pdf,0,0,0
1278412,A robust MIMO terminal sliding mode control scheme for rigid robotic manipulators,1994,Man Zhihong and Andrew P Paplinski and Hong Ren Wu,39,IEEE transactions on automatic control,12,2464-2469,IEEE,In this paper. a robust multi-input/multi-output (MIMO) terminal sliding mode control technique is developed for n-link rigid robotic manipulators. It is shown that an MIMO terminal switching plane variable vector is first defined. and the relationship between the terminal switching plane variable vector and system error dynamics is established. By using the MIMO terminal sliding mode technique and a few structural properties of rigid robotic manipulators. a robust controller can then be designed so that the output tracking error can converge to zero in a finite time. and strong robustness with respect to large uncertain dynamics can be guaranteed. It is also shown that the high gain of the terminal sliding mode controllers can be significantly reduced with respect to the one of the linear sliding mode controller where the sampling interval is nonzero.< >,True,SpVtleAAAAAJ:1werCE7_32MC,938,https://ieeexplore.ieee.org/abstract/document/362847/,503560412876528616,/scholar?cites=503560412876528616,,,https://researchbank.swinburne.edu.au/file/8f91167c-04b4-46b4-984c-85aa2dd6096d/1/PDF%20%28Published%20version%29.pdf,0,0,0
1278413,Adaptive impulse detection using center-weighted median filters,2001,Tao Chen and Hong Ren Wu,8,IEEE signal processing letters,1,1-3,IEEE,Previous median-based impulse detection strategies tend to work well for fixed-valued impulses but poorly for random-valued impulse noise. or vice versa. This letter devises a novel adaptive operator. which forms estimates based on the differences between the current pixel and the outputs of center-weighted median (CWM) filters with varied center weights. Extensive simulations show that the proposed scheme consistently works well in suppressing both types of impulses with different noise ratios.,True,SpVtleAAAAAJ:u5HHmVD_uO8C,875,https://ieeexplore.ieee.org/abstract/document/889633/,8936573013134980880,/scholar?cites=8936573013134980880,,,https://www.researchgate.net/profile/Hong_Ren_Wu/publication/3342616_Wu_HR_Adaptive_Impulse_Detection_Using_Center-Weighted_Median_Filters_IEEE_Signal_Processing_Letters_8_1-3/links/53dae09f0cf2a19eee8b3fda/Wu-HR-Adaptive-Impulse-Detection-Using-Center-Weighted-Median-Filters-IEEE-Signal-Processing-Letters-8-1-3.pdf,0,0,0
1278414,Digital video image quality and perceptual coding,2017,Hong Ren Wu and Kamisetty Ramamohan Rao,,,,,CRC press,The hand is quicker than the eye. In many cases. so is digital video. Maintaining image quality in bandwidth-and memory-restricted environments is quickly becoming a reality as thriving research delves ever deeper into perceptual coding techniques. which discard superfluous data that humans cannot process or detect. Surveying the topic from a Human Visual System (HVS)-based approach. Digital Video Image Quality and Perceptual Coding outlines the principles. metrics. and standards associated with perceptual coding. as well as the latest techniques and applications. This book is divided broadly into three parts. First. it introduces the fundamental theory. concepts. principles. and techniques underlying the field. such as the basics of compression. HVS modeling. and coding artifacts associated with current well-known techniques. The next section focuses on picture quality assessment criteria; subjective and objective methods and metrics. including vision model based digital video impairment metrics; testing procedures; and international standards regarding image quality. Finally. practical applications come into focus. including digital image and video coder designs based on the HVS as well as post-filtering. restoration. error correction. and concealment techniques. The permeation of digital images and video throughout the world cannot be understated. Nor can the importance of preserving quality while using minimal storage space. and Digital Video Image Quality and Perceptual Coding provides the tools necessary to accomplish this goal. Instructors and lecturers wishing to make use of this work as a textbook can download a …,True,SpVtleAAAAAJ:2osOgNQ5qMEC,482,http://books.google.com/books?hl=en&lr=&id=JwMqUXzwYpUC&oi=fnd&pg=PR9&dq=info:aofBylcWlEQJ:scholar.google.com&ots=pOyfEqyG-J&sig=yAhjj4R8Yv_VZFSy1y_BpEDXXNE,4941599257451923306,/scholar?cites=4941599257451923306,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.9550&rep=rep1&type=pdf,0,0,0
1278415,Space variant median filters for the restoration of impulse noise corrupted images,2001,Tao Chen and Hong Ren Wu,48,IEEE transactions on circuits and systems II: analog and digital signal processing,8,784-789,IEEE,This brief proposes a generalized framework of median based switching schemes. called multi-state median (MSM) filter. By using a simple thresholding logic. the output of the MSM filter is adaptively switched among those of a group of center weighted median (CWM) filters that have different center weights. As a result. the MSM filter is equivalent to an adaptive CWM filter with a space varying center weight which is dependent on local signal statistics. The efficacy of the proposed filter has been evaluated by extensive simulations.,True,SpVtleAAAAAJ:9yKSN-GCB0IC,477,https://ieeexplore.ieee.org/abstract/document/959870/,16340929778591445126,/scholar?cites=16340929778591445126,,,,0,0,0
1278416,A generalized block-edge impairment metric for video coding,1997,Henry R Wu and Michael Yuen,4,IEEE Signal Processing Letters,11,317-320,IEEE,A mew generalized block-edge impairment metric (GBIM) is presented in this paper as a quantitative distortion measure for blocking artifacts in digital video and image coding. This distortion measure does not require the original image sequence as a comparative reference. and is found to be consistent with subjective evaluation.,True,SpVtleAAAAAJ:u-x6o8ySG0sC,464,https://ieeexplore.ieee.org/abstract/document/641398/,10033782321013913142,/scholar?cites=10033782321013913142,,,https://www.researchgate.net/profile/Hong_Ren_Wu/publication/3342329_A_generalized_block-edge_impairment_metric_for_video_coding/links/53dadf140cf2e38c63397a75/A-generalized-block-edge-impairment-metric-for-video-coding.pdf,0,0,0
1278417,A survey of hybrid MC/DPCM/DCT video coding distortions,1998,Michael Yuen and Hong Ren Wu,70,Signal processing,3,247-278,Elsevier,The motion-compensated hybrid DCT/DPCM algorithm has been successfully adopted in various video coding standards. such as H.261. H.263. MPEG-1 and MPEG-2. However. its robustness is challenged in the face of an inadequate bit allocation. either globally for the whole video sequence. or locally as a result of an inappropriate distribution of the available bits. In either of these situations. the trade-off between quality and the availability of bits results in a deterioration in the quality of the decoded video sequence. both in terms of the loss of information and the introduction of coding artifacts. These distortions are an important factor in the fields of filtering. codec design. and the search for objective psychovisual-based quality metrics; therefore. this paper presents a comprehensive analysis and classification of the numerous coding artifacts which are introduced into the reconstructed video sequence through the …,True,SpVtleAAAAAJ:d1gkVwhDpl0C,366,https://www.sciencedirect.com/science/article/pii/S0165168498001285,8992796201090203734,/scholar?cites=8992796201090203734,,,https://www.researchgate.net/profile/Hong_Ren_Wu/publication/271587900_yuen_wu_1998/links/54cd40e70cf24601c08d3010.pdf,0,0,0
1278418,Adaptive postfiltering of transform coefficients for the reduction of blocking artifacts,2001,Tao Chen and Hong Ren Wu and Bin Qiu,11,IEEE transactions on circuits and systems for video technology,5,594-602,IEEE,This paper proposes a novel postprocessing technique for reducing blocking artifacts in low-bit-rate transform-coded images. The proposed approach works in the transform domain to alleviate the accuracy loss of transform coefficients. which is introduced by the quantization process. The masking effect in the human visual system (HVS) is considered. and an adaptive weighting mechanism is then integrated into the postfiltering. In low-activity areas. since blocking artifacts appear to be perceptually more detectable. a large window is used to efficiently smooth out the artifacts. In order to preserve image details. a small mask. as well as a large central weight. is employed for processing those high-activity blocks. where blocking artifacts are less noticeable due to the masking ability of local background. The quantization constraint is finally applied to the postfiltered coefficients. Experimental results show that the …,True,SpVtleAAAAAJ:qjMakFHDy7sC,222,https://ieeexplore.ieee.org/abstract/document/920189/,10386599235107677454,/scholar?cites=10386599235107677454,,,,0,0,0
1278419,An adaptive tracking controller using neural networks for a class of nonlinear systems,1998,Man Zhihong and Hong Ren Wu and Marimuthu Palaniswami,9,IEEE transactions on neural networks,5,947-955,IEEE,A neural-network-based adaptive tracking control scheme is proposed for a class of nonlinear systems in this paper. It is shown that RBF neural networks are used to adaptively learn system uncertainty bounds in the Lyapunov sense. and the outputs of the neural networks are then used as the parameters of the controller to compensate for the effects of system uncertainties. Using this scheme. not only strong robustness with respect to uncertain dynamics and nonlinearities can be obtained. but also the output tracking error between the plant output and the desired reference output can asymptotically converge to zero. A simulation example is performed in support of the proposed neural control scheme.,True,SpVtleAAAAAJ:KbBQZpvPDL4C,201,https://ieeexplore.ieee.org/abstract/document/712168/,1126679171184306614,/scholar?cites=1126679171184306614,,,https://researchbank.swinburne.edu.au/file/48c7cc15-5435-457c-a0a9-159a2378a620/1/PDF%20(Published%20version).pdf,0,0,0
1278420,Vision-model-based impairment metric to evaluate blocking artifacts in digital video,2002,Zhenghua Yu and Hong Ren Wu and Stefan Winkler and Tao Chen,90,Proceedings of the IEEE,1,154-169,IEEE,In this paper investigations are conducted to simplify and refine a vision-model-based video quality metric without compromising its prediction accuracy. Unlike other vision-model-based quality metrics. the proposed metric is parameterized using subjective quality assessment data recently provided by the Video Quality Experts Group. The quality metric is able to generate a perceptual distortion map for each and every video frame. A perceptual blocking distortion metric (PBDM) is introduced which utilizes this simplified quality metric. The PBDM is formulated based on the observation that blocking artifacts are noticeable only in certain regions of a picture. A method to segment blocking dominant regions is devised. and perceptual distortions in these regions are summed up to form an objective measure of blocking artifacts. Subjective and objective tests are conducted and the performance of the PBDM is assessed …,True,SpVtleAAAAAJ:UeHWp8X0CEIC,177,https://ieeexplore.ieee.org/abstract/document/982412/,7042337891764073116,/scholar?cites=7042337891764073116,,,https://www.researchgate.net/profile/Hong_Ren_Wu/publication/215482747_Vision-model-based_impairment_metric_to_evaluate_blocking_artifacts_in_digital_video/links/53dadf970cf2e38c63397a8a.pdf,0,0,0
1278421,Efficient deinterlacing algorithm using edge-based line average interpolation,2000,Tao Chen and Hong Ren Wu and Zhenghua Yu,39,Optical Engineering,8,2101-2105,International Society for Optics and Photonics,An efficient algorithm is proposed for the interpolation of interlaced images. On the basis of the edge-based line average (ELA) algorithm. tow useful measurements are introduced within the operation window in order to alleviate misleading decisions in determining the direction where the interpolation is to be made. By efficiently estimating the directional spatial correlations of neighboring pixels. increased interpolation accuracy has been achieved. In addition. the new method is simply structured and is therefore easy to implement. Extensive simulations conducted for different images and video sequences have shown the efficacy of the proposed interpolator. with significant improvement over previous ELA-based algorithms.© 2000 Society of Photo-Optical Instrumentation Engineers.[S0091-3286 (00) 02808-7],True,SpVtleAAAAAJ:zYLM7Y9cAGgC,140,https://www.spiedigitallibrary.org/journals/optical-engineering/volume-39/issue-8/0000/Efficient-deinterlacing-algorithm-using-edge-based-line-average-interpolation/10.1117/1.1305262.short,1840729418969581247,/scholar?cites=1840729418969581247,,,,0,0,0
1278422,No-reference quality assessment for networked video via primary analysis of bit stream,2010,Fuzheng Yang and Shuai Wan and Qingpeng Xie and Hong Ren Wu,20,IEEE Transactions on Circuits and Systems for Video Technology,11,1544-1554,IEEE,A no-reference (NR) quality measure for networked video is introduced using information extracted from the compressed bit stream without resorting to complete video decoding. This NR video quality assessment measure accounts for three key factors which affect the overall perceived picture quality of networked video. namely. picture distortion caused by quantization. quality degradation due to packet loss and error propagation. and temporal effects of the human visual system. First. the picture quality in the spatial domain is measured. for each frame. relative to quantization under an error-free transmission condition. Second. picture quality is evaluated with respect to packet loss and the subsequent error propagation. The video frame quality in the spatial domain is. therefore. jointly determined by coding distortion and packet loss. Third. a pooling scheme is devised as the last step of the proposed quality measure …,True,SpVtleAAAAAJ:Se3iqnhoufwC,116,https://ieeexplore.ieee.org/abstract/document/5604300/,4125934842071819321,/scholar?cites=4125934842071819321,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.453.1708&rep=rep1&type=pdf,0,0,0
1278423,Subdiffraction‐resolution fluorescence imaging with conventional fluorescent probes,2008,Mike Heilemann and Sebastian Van De Linde and Mark Schüttpelz and Robert Kasper and Britta Seefeldt and Anindita Mukherjee and Philip Tinnefeld and Markus Sauer,47,Angewandte Chemie International Edition,33,6172-6176,WILEY‐VCH Verlag,Eagle eyes: dSTORM uses conventional photoswitchable fluorescent dyes that can be reversibly cycled between a fluorescent and a dark state by irradiation with light of different wavelengths (see picture). This elegant approach can visualize cellular structures with a resolution of approximately 20 nm. far beyond the diffraction limit of light. without the need of an activator molecule.,True,6wSxphAAAAAJ:R3hNpaxXUhUC,1606,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.200802376,16565583978056574313,/scholar?cites=16565583978056574313,,,https://pub.uni-bielefeld.de/record/1586821,0,0,0
1278424,Direct stochastic optical reconstruction microscopy with standard fluorescent probes,2011,Sebastian Van de Linde and Anna Löschberger and Teresa Klein and Meike Heidbreder and Steve Wolter and Mike Heilemann and Markus Sauer,6,Nature protocols,7,991,Nature Publishing Group,Direct stochastic optical reconstruction microscopy (dSTORM) uses conventional fluorescent probes such as labeled antibodies or chemical tags for subdiffraction resolution fluorescence imaging with a lateral resolution of∼ 20 nm. In contrast to photoactivated localization microscopy (PALM) with photoactivatable fluorescent proteins. dSTORM experiments start with bright fluorescent samples in which the fluorophores have to be transferred to a stable and reversible OFF state. The OFF state has a lifetime in the range of 100 milliseconds to several seconds after irradiation with light intensities low enough to ensure minimal photodestruction. Either spontaneously or photoinduced on irradiation with a second laser wavelength. a sparse subset of fluorophores is reactivated and their positions are precisely determined. Repetitive activation. localization and deactivation allow a temporal separation of spatially …,True,6wSxphAAAAAJ:Se3iqnhoufwC,826,https://www.nature.com/articles/nprot.2011.336.pdf?origin=ppub,5803844903113868596,/scholar?cites=5803844903113868596,,,https://pub.uni-bielefeld.de/record/2444529,0,0,0
1278425,Super‐resolution imaging with small organic fluorophores,2009,Mike Heilemann and Sebastian van de Linde and Anindita Mukherjee and Markus Sauer,48,Angewandte Chemie International Edition,37,6903-6908,WILEY‐VCH Verlag,What's your color? A universal and facile method for reversible photoswitching of commercially available Alexa Fluor and ATTO dyes spanning the entire visible range yields an optical resolution of approximately 20 nm. The intriguing simplicity of the method facilitates applications and opens avenues for multicolor super‐resolution imaging in fixed and living cells.,True,6wSxphAAAAAJ:M3ejUd6NZC8C,423,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.200902073,10590792413052617538,/scholar?cites=10590792413052617538,,,https://pub.uni-bielefeld.de/record/1590854,0,0,0
1278426,Live-cell super-resolution imaging with trimethoprim conjugates,2010,Richard Wombacher and Meike Heidbreder and Sebastian Van De Linde and Michael P Sheetz and Mike Heilemann and Virginia W Cornish and Markus Sauer,7,Nature methods,9,717-719,Nature Publishing Group,The spatiotemporal resolution of subdiffraction fluorescence imaging has been limited by the difficulty of labeling proteins in cells with suitable fluorophores. Here we report a chemical tag that allows proteins to be labeled with an organic fluorophore with high photon flux and fast photoswitching performance in live cells. This label allowed us to image the dynamics of human histone H2B protein in living cells at∼ 20 nm resolution.,True,6wSxphAAAAAJ:hC7cP41nSMkC,328,https://www.nature.com/articles/nmeth.1489,14697713922308600090,/scholar?cites=14697713922308600090,,,https://pub.uni-bielefeld.de/record/1794049,0,0,0
1278427,rapi d STORM: accurate. fast open-source software for localization microscopy,2012,Steve Wolter and Anna Löschberger and Thorge Holm and Sarah Aufmkolk and Marie-Christine Dabauvalle and Sebastian Van De Linde and Markus Sauer,9,Nature methods,11,1040-1041,Nature Publishing Group,In recent years. there has been a dramatic increase in the use of localization microscopy: that is. super-resolution fluorescence imaging by stochastic photoswitching. photoactivation or other fluorescence-generating processes. The evaluation of localization microscopy data with a Gaussian model of the point-spread function (PSF) is a common and cogent technique 1. and Poissonian maximum-likelihood estimator (MLE) fitting of the Gaussian model has been shown to yield optimal precision 2. However. current software support is based on less precise approximations of MLE fitting or is slow. hardware dependent. closed source or unmaintained. Many advances have been made with unpublished or prototypical software packages. leaving established labs with homemade software and new labs with immense technology entry costs. This state has weakened the core strengths of localization microscopy: cost …,True,6wSxphAAAAAJ:-f6ydRqryjwC,323,https://www.nature.com/articles/nmeth.2224?report=reader,15077999579930683959,/scholar?cites=15077999579930683959,,,,0,0,0
1278428,Light-induced cell damage in live-cell super-resolution microscopy,2015,Sina Wäldchen and Julian Lehmann and Teresa Klein and Sebastian Van De Linde and Markus Sauer,5,Scientific reports,1,1-12,Nature Publishing Group,Super-resolution microscopy can unravel previously hidden details of cellular structures but requires high irradiation intensities to use the limited photon budget efficiently. Such high photon densities are likely to induce cellular damage in live-cell experiments. We applied single-molecule localization microscopy conditions and tested the influence of irradiation intensity. illumination-mode. wavelength. light-dose. temperature and fluorescence labeling on the survival probability of different cell lines 20–24 hours after irradiation. In addition. we measured the microtubule growth speed after irradiation. The photo-sensitivity is dramatically increased at lower irradiation wavelength. We observed fixation. plasma membrane permeabilization and cytoskeleton destruction upon irradiation with shorter wavelengths. While cells stand light intensities of~ 1 kW cm− 2 at 640 nm for several minutes. the maximum dose at 405 nm …,True,6wSxphAAAAAJ:_Qo2XoVZTnwC,309,https://www.nature.com/articles/srep15348,17485254115436201915,/scholar?cites=17485254115436201915,,,https://www.nature.com/articles/srep15348,0,0,0
1278429,Live-cell super-resolution imaging with synthetic fluorophores,2012,Sebastian van de Linde and Mike Heilemann and Markus Sauer,63,,,519-540,Annual Reviews,Super-resolution imaging methods now can provide spatial resolution that is well below the diffraction limit approaching virtually molecular resolution. They can be applied to biological samples and provide new and exciting views on the structural organization of cells and the dynamics of biomolecular assemblies on wide timescales. These revolutionary developments come with novel requirements for fluorescent probes. labeling techniques. and data interpretation strategies. Synthetic fluorophores have a small size. are available in many colors spanning the whole spectrum. and can easily be chemically modified and used for stoichiometric labeling of proteins in live cells. Because of their brightness. their photostability. and their ability to be operated as photoswitchable fluorophores even in living cells under physiological conditions. synthetic fluorophores have the potential to substantially accelerate the broad …,True,6wSxphAAAAAJ:2osOgNQ5qMEC,255,https://www.annualreviews.org/doi/abs/10.1146/annurev-physchem-032811-112012,2381461905795588767,/scholar?cites=2381461905795588767,,,,0,0,0
1278430,Live-cell dSTORM with SNAP-tag fusion proteins,2011,Teresa Klein and Anna Löschberger and Sven Proppert and Steve Wolter and Sebastian van de Linde and Markus Sauer,8,Nature methods,1,7-9,Nature Publishing Group,To the Editor: Since the publication of our Correspondence1 and the reply of Joung et al. 2. we improved zinc-finger nuclease (ZFN) modular assembly. ZFNs are artificial restriction enzymes3 composed of tailor-made zinc-finger DNA-binding arrays and the FokI nuclease domain. which can induce site-specific mutations4 and large chromosomal deletions5 in higher eukaryotic cells and organisms. To reduce the number of ZFNs that need to be synthesized to identify a functional enzyme. we previously compared zinc fingers with equivalent DNA-binding specificity and chose ones that are often found in functional ZFNs4. Based on that analysis. we recommended 37 zinc fingers for use in genome editing4. Here we tested 33 of these fingers. which collectively recognize 39 of 64 three–base-pair subsites (15 GNN subsites and 24 non-GNN subsites. where G is guanine and N is any base; Supplementary Table 1). We …,True,6wSxphAAAAAJ:9ZlFYXVOiuMC,253,https://www.nature.com/articles/nmeth0111-7b,11501062712542528141,/scholar?cites=11501062712542528141,,,,0,0,0
1278431,Super-resolution imaging visualizes the eightfold symmetry of gp210 proteins around the nuclear pore complex and resolves the central channel with nanometer resolution,2012,Anna Löschberger and Sebastian van de Linde and Marie-Christine Dabauvalle and Bernd Rieger and Mike Heilemann and Georg Krohne and Markus Sauer,125,Journal of cell science,3,570-575,The Company of Biologists Ltd,One of the most complex molecular machines of cells is the nuclear pore complex (NPC). which controls all trafficking of molecules in and out of the nucleus. Because of their importance for cellular processes such as gene expression and cytoskeleton organization. the structure of NPCs has been studied extensively during the last few decades. mainly by electron microscopy. We have used super-resolution imaging by direct stochastic optical reconstruction microscopy (dSTORM) to investigate the structure of NPCs in isolated Xenopus laevis oocyte nuclear envelopes. with a lateral resolution of ~15 nm. By generating accumulated super-resolved images of hundreds of NPCs we determined the diameter of the central NPC channel to be 41±7 nm and demonstrate that the integral membrane protein gp210 is distributed in an eightfold radial symmetry. Two-color dSTORM experiments emphasize the highly symmetric …,True,6wSxphAAAAAJ:5nxA0vEk-isC,252,https://jcs.biologists.org/content/125/3/570.short,8393797467690304393,/scholar?cites=8393797467690304393,,,https://jcs.biologists.org/content/joces/125/3/570.full.pdf,0,0,0
1278432,Real‐time computation of subdiffraction‐resolution fluorescence images,2010,Steve Wolter and Mark Schüttpelz and Marko Tscherepanow and Sebastian Van de Linde and Mike Heilemann and Markus Sauer,237,Journal of microscopy,1,12-22,Blackwell Publishing Ltd,In the recent past. single‐molecule based localization or photoswitching microscopy methods such as stochastic optical reconstruction microscopy (STORM) or photoactivated localization microscopy (PALM) have been successfully implemented for subdiffraction‐resolution fluorescence imaging. However. the computational effort needed to localize numerous fluorophores is tremendous. causing long data processing times and thereby limiting the applicability of the technique. Here we present a new computational scheme for data processing consisting of noise reduction. detection of likely fluorophore positions. high‐precision fluorophore localization and subsequent visualization of found fluorophore positions in a super‐resolution image. We present and benchmark different algorithms for noise reduction and demonstrate the use of non‐maximum suppression to quickly find likely fluorophore positions in high …,True,6wSxphAAAAAJ:L8Ckcad2t8MC,240,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2818.2009.03287.x,12563092812565313046,/scholar?cites=12563092812565313046,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2818.2009.03287.x,0,0,0
1278433,Photoinduced formation of reversible dye radicals and their impact on super-resolution imaging,2011,Sebastian van de Linde and Ivan Krstić and Thomas Prisner and Sören Doose and Mike Heilemann and Markus Sauer,10,Photochemical & Photobiological Sciences,4,499-506,Royal Society of Chemistry,Radical ions of organic dyes are highly reactive species and have been studied for decades by transient absorption spectroscopy and pulse radiolysis experiments in oxygen-depleted solution. Here we show by continuous wave EPR. absorption. and fluorescence experiments that the triplet state of rhodamine dyes can be photoreduced by thiols to form stable radical anions in aqueous solution with a lifetime of up to several hours. Our data demonstrate that reduction of the triplet state and photoinduced oxidation of reactive intermediates by oxygen represents a general mechanism for reversible photoswitching of dyes in aqueous thiol-containing solutions highlighting the key role of molecular oxygen for super-resolution fluorescence imaging. Since cells contain the thiol glutathione at millimolar concentrations and reactive oxygen species are formed as side products our findings are of consequence for live cell …,True,6wSxphAAAAAJ:Y0pCki6q_DkC,203,https://pubs.rsc.org/en/content/articlehtml/2011/pp/c0pp00317d,3837316314937283531,/scholar?cites=3837316314937283531,,,https://pubs.rsc.org/en/content/articlehtml/2011/pp/c0pp00317d,0,0,0
1278434,GSA: a gravitational search algorithm,2009,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,179,Information sciences,13,2232-2248,Elsevier,In recent years. various heuristic optimization methods have been developed. Many of these methods are inspired by swarm behaviors in nature. In this paper. a new optimization algorithm based on the law of gravity and mass interactions is introduced. In the proposed algorithm. the searcher agents are a collection of masses which interact with each other based on the Newtonian gravity and the laws of motion. The proposed method has been compared with some well-known heuristic search methods. The obtained results confirm the high performance of the proposed method in solving various nonlinear functions.,True,M7o8PXEAAAAJ:u5HHmVD_uO8C,4942,https://www.sciencedirect.com/science/article/pii/S0020025509001200,2991100904893275403,/scholar?cites=2991100904893275403,,,http://matlabtools.com/wp-content/uploads/p717.pdf,0,0,0
1278435,BGSA: binary gravitational search algorithm,2010,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,9,Natural Computing,3,727-745,Springer Netherlands,Gravitational search algorithm is one of the new optimization algorithms that is based on the law of gravity and mass interactions. In this algorithm. the searcher agents are a collection of masses. and their interactions are based on the Newtonian laws of gravity and motion. In this article. a binary version of the algorithm is introduced. To evaluate the performances of the proposed algorithm. several experiments are performed. The experimental results confirm the efficiency of the BGSA in solving various nonlinear benchmark functions.,True,M7o8PXEAAAAJ:u-x6o8ySG0sC,652,https://link.springer.com/content/pdf/10.1007/s11047-009-9175-3.pdf,1180170859742867676,/scholar?cites=1180170859742867676,,,https://www.researchgate.net/profile/Hossein_Nezamabadi-pour/publication/220132723_BGSA_Binary_gravitational_search_algorithm/links/54ce41360cf24601c090242f.pdf,0,0,0
1278436,Filter modeling using gravitational search algorithm,2011,Esmat Rashedi and Hossien Nezamabadi-Pour and Saeid Saryazdi,24,Engineering Applications of Artificial Intelligence,1,117-122,Pergamon,This paper is devoted to the presentation of a new linear and nonlinear filter modeling based on a gravitational search algorithm (GSA). To do this. unknown filter parameters are considered as a vector to be optimized. Examples of infinite impulse response (IIR) filter design. as well as rational nonlinear filter. are given. To verify the effectiveness of the proposed GSA based filter modeling. different sets of initial population with the presence of different measurable noises are given and tested in simulations. Genetic algorithm (GA) and particle swarm optimization (PSO) are also used to model the same examples and some simulation results are compared. Obtained results confirm the efficiency of the proposed method.,True,M7o8PXEAAAAJ:d1gkVwhDpl0C,390,https://www.sciencedirect.com/science/article/pii/S0952197610001120,712081725521365890,/scholar?cites=712081725521365890,,,,0,0,0
1278437,Edge detection using ant algorithms,2006,Hossein Nezamabadi-Pour and Saeid Saryazdi and Esmat Rashedi,10,Soft Computing,7,623-628,Springer-Verlag,In this paper a new algorithm for edge detection using ant colony search is proposed. The problem is represented by a directed graph in which nodes are the pixels of an image. To adapt the problem. some modifications on original ant colony search algorithm (ACSA) are applied. A large number of experiments are employed to determine suitable algorithm parameters. We drive an experimental relationship between the size of the image to be analyzed and algorithm parameters. Several experiments are made and the results suggest the effectiveness of the proposed algorithm.,True,M7o8PXEAAAAJ:9yKSN-GCB0IC,238,https://link.springer.com/content/pdf/10.1007/s00500-005-0511-y.pdf,8735890167345426070,/scholar?cites=8735890167345426070,,,https://www.researchgate.net/profile/Esmat_Rashedi/publication/220176122_Edge_detection_using_ant_algorithms/links/5743d1ab08ae9ace841b4063.pdf,0,0,0
1278438,Disruption: a new operator in gravitational search algorithm,2011,S Sarafrazi and H Nezamabadi-Pour and S Saryazdi,18,,3,539-548,No longer published by Elsevier,To improve the exploration and exploitation abilities of the standard Gravitational Search Algorithm (GSA). a novel operator called “Disruption”. originating from astrophysics. is proposed. The disruption operator is inspired by nature and. with the least computation. has improved the ability of GSA to further explore and exploit the search space. The proposed improved GSA has been evaluated on 23 nonlinear benchmark functions and compared with standard GSA. the genetic algorithm and particle swarm optimization. The obtained results confirm the high performance of the proposed method in solving various nonlinear functions.,True,M7o8PXEAAAAJ:2osOgNQ5qMEC,195,https://www.sciencedirect.com/science/article/pii/S1026309811000411,16627871696188055832,/scholar?cites=16627871696188055832,,,https://www.sciencedirect.com/science/article/pii/S1026309811000411,0,0,0
1278439,A simultaneous feature adaptation and feature selection method for content-based image retrieval systems,2013,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,39,Knowledge-Based Systems,,85-94,Elsevier,In content-based image retrieval (CBIR) applications. each database needs its corresponding parameter setting for feature extraction. However. most of the CBIR systems perform indexing by a set of fixed and pre-specific parameters. On the other hand. feature selection methods have currently gained considerable popularity to reduce semantic gap. In this regard. this paper is devoted to present a hybrid approach to reduce the semantic gap between low level visual features and high level semantics. through simultaneous feature adaptation and feature selection. In the proposed approach. a hybrid meta-heuristic swarm intelligence-based search technique. called mixed gravitational search algorithm (MGSA). is employed. Some feature extraction parameters (i.e. the parameters of a 6-tap parameterized orthogonal mother wavelet in texture features and quantization levels in color histogram) are optimized to reach …,True,M7o8PXEAAAAJ:IjCSPb-OGe4C,131,https://www.sciencedirect.com/science/article/pii/S0950705112002924,7647600714460631897,/scholar?cites=7647600714460631897,,,,0,0,0
1278440,A path optional lossless data hiding scheme based on VQ joint neighboring coding,2009,Jun-Xiang Wang and Zhe-Ming Lu,179,Information Sciences,19,3332-3348,Elsevier,Data hiding is an important technique for covert communication that embeds secret data into a cover image with minimal perceptible degradation. Lossless data hiding is a special type of data hiding technique that guarantees not only the secret data but the cover media can be reconstructed without any distortion. In this paper. a novel path optional lossless data hiding scheme based on the joint neighboring coding (JNC) of the vector quantization (VQ) index table is proposed. The proposed scheme generates a VQ index table based on the cover image first. Next. according to an initial key and secret data content. different adjacent indices may be chosen to perform joint neighboring coding for each index and hide secret data. Finally. an appropriate output codestream is generated based on the minimal length principle. Our main contributions lie in three aspects: (1) the method combines the novel path_based shift …,True,M7o8PXEAAAAJ:NMxIlDl6LWMC,100,https://www.sciencedirect.com/science/article/pii/S0020025509002369,13939697532009910816,/scholar?cites=13939697532009910816,,,,0,0,0
1278441,A novel parallel image encryption with chaotic windows based on logistic map,2017,Mohamad Javad Rostami and Abbas Shahba and Saeid Saryazdi and Hossein Nezamabadi-pour,62,Computers & Electrical Engineering,,384-400,Pergamon,Over the course of the last two decades. secure communication has become a very important issue due to the rapid growth of information technology and the development of public communication networks in which digital images are widely transmitted. In this paper. logistic map was employed for the encryption of gray-scale images. The proposed algorithm. demonstrating a proper performance according to the experimental results. divides the image into blocks and encrypts them with XOR operation and chaotic windows. Moreover. it has a large key space and the resulted encrypted images have homogeneous histograms. The large-enough NPCR and UACI of this algorithm indicate its resistance to differential attacks. not to mention the fact that it is suitable for noisy communication networks and could be made use of in parallel processing.,True,M7o8PXEAAAAJ:maZDTaKrznsC,57,https://www.sciencedirect.com/science/article/pii/S0045790617308091,4499257937530647989,/scholar?cites=4499257937530647989,,,,0,0,0
1278442,Object-based image indexing and retrieval in DCT domain using clustering techniques,2005,Hossein Nezamabadi-Pour and Saeid Saryazdi,3,Proceedings of world academy of science engineering and technology,,207-210,,In this paper. we present a new and effective image indexing technique that extracts features directly from DCT domain. Our proposed approach is an object-based image indexing. For each block of size 8* 8 in DCT domain a feature vector is extracted. Then. feature vectors of all blocks of image using a kmeans algorithm is clustered into groups. Each cluster represents a special object of the image. Then we select some clusters that have largest members after clustering. The centroids of the selected clusters are taken as image feature vectors and indexed into the database.,True,M7o8PXEAAAAJ:qjMakFHDy7sC,56,https://www.academia.edu/download/30607616/10.1.1.192.8342.pdf,7135760897104212258,/scholar?cites=7135760897104212258,,,https://www.academia.edu/download/30607616/10.1.1.192.8342.pdf,0,0,0
1278443,A low power and high linearity UWB low noise amplifier (LNA) for 3.1–10.6 GHz wireless applications in 0.13 μm CMOS process,2013,Habib Rastegar and Saeed Saryazdi and Ahmad Hakimi,44,Microelectronics Journal,3,201-209,Elsevier,In this paper. a low power ultra-wideband (UWB) CMOS LNA was designed exploiting source inductive degeneration technique operating in the frequency range of 3.1–10.6 GHz. In order to achieve low noise figure and high linearity simultaneously. a modified three-stage UWB LNA with inter-stage inductors was proposed. Forward Body-Biased (FBB) technique was used to reduce threshold voltage and power consumption at the first and third stages. The second stage is a push–pull topology exploiting the complementary characteristics of NMOS and PMOS transistors to enhance the linearity performance. The proposed LNA was simulated in standard 0.13 μm CMOS process. A gain of 19.5±1.5 dB within the entire band was exhibited. The simulated noise figure (NF) was 1–3.9 dB within the bandwidth. A maximum simulated third-order input intercept point (IIP3) of 4.56 dBm while consuming 4.1 mW from a 0.6 …,True,M7o8PXEAAAAJ:-f6ydRqryjwC,45,https://www.sciencedirect.com/science/article/pii/S0026269213000050,7275540199740413951,/scholar?cites=7275540199740413951,,,https://tarjomefa.com/wp-content/uploads/2017/04/6408-English-TarjomeFa.pdf,0,0,0
1278444,Optimum design of structures against earthquake by discrete wavelet transform,2005,Eysa Salajegheh and Ali Heidari and Saeid Saryazdi,62,International Journal for Numerical Methods in Engineering,15,2178-2192,John Wiley & Sons. Ltd.,Optimum design of structures is achieved by a modified genetic algorithm. Some features of the simulated annealing are used to control various parameters of the genetic algorithm. The loads are considered as earthquake loads. A time history analysis is carried out for the dynamic analysis. To decrease the computational work of analysis. a discrete wavelet transform is used by which the number of points in the earthquake record is reduced. Then in the optimization process. the structures are analysed with these points. To reconstruct the actual responses of structures from the responses of these points. a reverse wavelet transform is employed. A number of structures are designed for minimum weight and the results are compared with optimal solution using exact dynamic analysis. Copyright © 2005 John Wiley & Sons. Ltd.,True,M7o8PXEAAAAJ:zYLM7Y9cAGgC,31,https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.1279,10496534271899469264,/scholar?cites=10496534271899469264,,,https://www.academia.edu/download/48949454/nme.127920160918-18990-1x9ehov.pdf,0,0,0
1278445,Automatic seeded region growing for color image segmentation,2005,Frank Y Shih and Shouxian Cheng,23,Image and vision computing,10,877-886,Elsevier,In this paper. we present an automatic seeded region growing algorithm for color image segmentation. First. the input RGB color image is transformed into YCbCr color space. Second. the initial seeds are automatically selected. Third. the color image is segmented into regions where each region corresponds to a seed. Finally. region-merging is used to merge similar or small regions. Experimental results show that our algorithm can produce good results as favorably compared to some existing algorithms.,True,uXEp3MIAAAAJ:u5HHmVD_uO8C,531,https://www.sciencedirect.com/science/article/pii/S0262885605000673,16537601159013106248,/scholar?cites=16537601159013106248,,,http://papersim.com/wp-content/uploads/Image_Processing__region_growing_Segmentation_2005.pdf,0,0,0
1278446,Digital watermarking and steganography: fundamentals and techniques,2017,Frank Y Shih,,,,,CRC press,This book intends to provide a comprehensive overview on different aspects of mechanisms and techniques for information security. It is written for students. researchers. and professionals studying in the field of multimedia security and steganography. Multimedia security and steganography is especially relevant due to the global scale of digital multimedia and the rapid growth of the Internet. Digital watermarking technology can be used to guarantee authenticity and can be applied as proof that the content has not been altered since insertion. Updated techniques and advances in watermarking are explored in this new edition. The combinational spatial and frequency domains watermarking technique provides a new concept of enlarging the embedding capacity of watermarks. The genetic algorithm (GA) based watermarking technique solves the rounding error problem and provide an efficient embedding approach. Each chapter provides the reader with a fundamental. theoretical framework. while developing the extensive advanced techniques and considering the essential principles of the digital watermarking and steganographic systems. Several robust algorithms that are presented throughout illustrate the framework and provide assistance and tools in understanding and implementing the fundamental principles.,True,uXEp3MIAAAAJ:2osOgNQ5qMEC,411,http://books.google.com/books?hl=en&lr=&id=j4ujDgAAQBAJ&oi=fnd&pg=PR1&dq=info:ZNjplBSppTcJ:scholar.google.com&ots=aL20rNtCum&sig=_NQs6ht8UrL4lgJzGsnb496-5r0,4009796949106088036,/scholar?cites=4009796949106088036,,,,0,0,0
1278447,Image processing and pattern recognition: fundamentals and techniques,2010,Frank Y Shih,,,,,John Wiley & Sons,A comprehensive guide to the essential principles of image processing and pattern recognition Techniques and applications in the areas of image processing and pattern recognition are growing at an unprecedented rate. Containing the latest state-of-the-art developments in the field. Image Processing and Pattern Recognition presents clear explanations of the fundamentals as well as the most recent applications. It explains the essential principles so readers will not only be able to easily implement the algorithms and techniques. but also lead themselves to discover new problems and applications. Unlike other books on the subject. this volume presents numerous fundamental and advanced image processing algorithms and pattern recognition techniques to illustrate the framework. Scores of graphs and examples. technical assistance. and practical tools illustrate the basic principles and help simplify the problems. allowing students as well as professionals to easily grasp even complicated theories. It also features unique coverage of the most interesting developments and updated techniques. such as image watermarking. digital steganography. document processing and classification. solar image processing and event classification. 3-D Euclidean distance transformation. shortest path planning. soft morphology. recursive morphology. regulated morphology. and sweep morphology. Additional topics include enhancement and segmentation techniques. active learning. feature extraction. neural networks. and fuzzy logic. Featuring supplemental materials for instructors and students. Image Processing and Pattern Recognition is designed for …,True,uXEp3MIAAAAJ:u-x6o8ySG0sC,410,http://books.google.com/books?hl=en&lr=&id=M_Lr8NTfAHcC&oi=fnd&pg=PR5&dq=info:alnC0hrD4N4J:scholar.google.com&ots=hPDz-eWbwR&sig=zUpPT5T9iGWzInKbMzw5-wR7NL0,16060050791175706986,/scholar?cites=16060050791175706986,,,,0,0,0
1278448,Image processing and mathematical morphology: fundamentals and applications,2009,Frank Y Shih,,,,,CRC press,In the development of digital multimedia. the importance and impact of image processing and mathematical morphology are well documented in areas ranging from automated vision detection and inspection to object recognition. image analysis and pattern recognition. Those working in these ever-evolving fields require a solid grasp of basic fundamentals. theory. and related applications—and few books can provide the unique tools for learning contained in this text. Image Processing and Mathematical Morphology: Fundamentals and Applications is a comprehensive. wide-ranging overview of morphological mechanisms and techniques and their relation to image processing. More than merely a tutorial on vital technical information. the book places this knowledge into a theoretical framework. This helps readers analyze key principles and architectures and then use the author’s novel ideas on implementation of advanced algorithms to formulate a practical and detailed plan to develop and foster their own ideas. The book: Presents the history and state-of-the-art techniques related to image morphological processing. with numerous practical examples Gives readers a clear tutorial on complex technology and other tools that rely on their intuition for a clear understanding of the subject Includes an updated bibliography and useful graphs and illustrations Examines several new algorithms in great detail so that readers can adapt them to derive their own solution approaches This invaluable reference helps readers assess and simplify problems and their essential requirements and complexities. giving them all the necessary data and methodology to …,True,uXEp3MIAAAAJ:epqYDVWIO7EC,317,http://books.google.com/books?hl=en&lr=&id=DVpqN_5BYEAC&oi=fnd&pg=PP1&dq=info:n-1qzHiOX_AJ:scholar.google.com&ots=9Ku9Um2-rw&sig=zayCVZA_a9JdkmE7dQ3C_974c8c,17320719341366996383,/scholar?cites=17320719341366996383,,,,0,0,0
1278449,Combinational image watermarking in the spatial and frequency domains,2003,Frank Y Shih and Scott YT Wu,36,Pattern Recognition,4,969-975,Pergamon,In order to provide more watermarks and to minimize the distortion of the watermarked image. a novel technique using the combinational spatial and frequency domains is presented in this paper. The splitting of the watermark image into two parts. respectively. for spatial and frequency insertion relies on the user's preference and data importance. Experimental results provide the comparisons when different sized watermarks are embedded into a grayscale image. The proposed combinational image watermarking possesses the following advantages. More watermark data can be inserted into the host image. so that the capacity is increased. The splitting of the watermark into two parts makes the degree of protection double. The splitting strategy can be designed even more complicated to be unable to compose. Furthermore. to enhance robustness. a random permutation of the watermark is used to defeat the attacks …,True,uXEp3MIAAAAJ:9yKSN-GCB0IC,235,https://www.sciencedirect.com/science/article/pii/S003132030200122X,5610691196154351561,/scholar?cites=5610691196154351561,,,,0,0,0
1278450,Threshold decomposition of gray-scale morphology into binary morphology,1989,Frank Y Shih and Owen Robert  Mitchell,11,IEEE Transactions on Pattern Analysis and Machine Intelligence,1,31-42,IEEE,Recently. a superposition property called threshold decomposition and another property called stacking were introduced and shown to apply successfully to gray-scale morphological operations. This property allows gray-scale signals to be decomposed into multiple binary signals. The signals are processed in parallel. and the results are combined to produce the desired gray-scale result. The authors present the threshold decomposition architecture and the stacking property that allows the implementation of this architecture. Gray-scale operations are decomposed into binary operations. This decomposition allows gray-scale morphological operations to be implemented using only logic gates in VLSI architectures that can significantly improve speed as well as give theoretical insight into the operations.< >,True,uXEp3MIAAAAJ:d1gkVwhDpl0C,215,https://ieeexplore.ieee.org/abstract/document/23111/,1364459298828719583,/scholar?cites=1364459298828719583,,,,0,0,0
1278451,Retinal vessels segmentation based on level set and region growing,2014,Yu Qian Zhao and Xiao Hong Wang and Xiao Fang Wang and Frank Y Shih,47,Pattern Recognition,7,2437-2446,Pergamon,Retinal vessels play an important role in the diagnostic procedure of retinopathy. Accurate segmentation of retinal vessels is crucial for pathological analysis. In this paper. we propose a new retinal vessel segmentation method based on level set and region growing. Firstly. a retinal vessel image is preprocessed by the contrast-limited adaptive histogram equalization and a 2D Gabor wavelet to enhance the vessels. Then. an anisotropic diffusion filter is used to smooth the image and preserve vessel boundaries. Finally. the region growing method and a region-based active contour model with level set implementation are applied to extract retinal vessels. and their results are combined to achieve the final segmentation. Comparisons are conducted on the publicly available DRIVE and STARE databases using three different measurements. Experimental results show that the proposed method reaches an average …,True,uXEp3MIAAAAJ:KlAtU1dfN6UC,213,https://www.sciencedirect.com/science/article/pii/S0031320314000247,16473444091756398701,/scholar?cites=16473444091756398701,,,http://ir.nsfc.gov.cn/paperDownload/1000008954523.pdf,0,0,0
1278452,Automatic extraction of head and face boundaries and facial features,2004,Frank Y Shih and Chao-Fa Chuang,158,Information Sciences,,117-130,Elsevier,This paper presents a novel approach for the extraction of human head. face and facial features. In the double-threshold method. the high-thresholded image is used to trace head boundary and the low-thresholded image is used to scan face boundary. We obtain facial features candidates and eliminate noises. and apply x- and y-projections to extract facial features such as eyes. nostrils and mouth. Because low contrast of chin occurs in some face images. its boundary cannot be completely detected. An elliptic model is used to repair it. Because of noises or clustered facial features candidates. we apply a geometric face model to locate facial features and an elliptic model to trace face boundary. The Gabor filter algorithm is adopted to locate two eyes. We have tested our algorithm on more than 100 FERET face images. Experimental results show that our algorithm can perform the extraction of human head. face and …,True,uXEp3MIAAAAJ:UeHWp8X0CEIC,179,https://www.sciencedirect.com/science/article/pii/S002002550300197X,483634323258401667,/scholar?cites=483634323258401667,,,,0,0,0
1278453,Exact and approximate algorithms for unordered tree matching,1994,Dennis Shasha and JT-L Wang and Kaizhong Zhang and Frank Y Shih,24,"IEEE Transactions on Systems, Man, and Cybernetics",4,668-678,IEEE,We consider the problem of comparison between unordered trees. i.e.. trees for which the order among siblings is unimportant. The criterion for comparison is the distance as measured by a weighted sum of the costs of deletion. insertion and relabel operations on tree nodes. Such comparisons may contribute to pattern recognition efforts in any field (e.g.. genetics) where data can naturally be characterized by unordered trees. In companion work. we have shown this problem to be NP-complete. This paper presents an efficient enumerative algorithm and several heuristics leading to approximate solutions. The algorithms are based on probabilistic hill climbing and bipartite matching techniques. The paper evaluates the accuracy and time efficiency of the heuristics by applying them to a set of trees transformed from industrial parts based on a previously proposed morphological model.< >,True,uXEp3MIAAAAJ:qjMakFHDy7sC,166,https://ieeexplore.ieee.org/abstract/document/286387/,3238319874435413546,/scholar?cites=3238319874435413546,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4078&rep=rep1&type=pdf,0,0,0
1278454,Performance comparisons of facial expression recognition in JAFFE database,2008,Frank Y Shih and Chao-Fa Chuang and Patrick SP Wang,22,International Journal of Pattern Recognition and Artificial Intelligence,03,445-459,World Scientific Publishing Company,Facial expression provides an important behavioral measure for studies of emotion. cognitive processes. and social interaction. Facial expression recognition has recently become a promising research area. Its applications include human-computer interfaces. human emotion analysis. and medical care and cure. In this paper. we investigate various feature representation and expression classification schemes to recognize seven different facial expressions. such as happy. neutral. angry. disgust. sad. fear and surprise. in the JAFFE database. Experimental results show that the method of combining 2D-LDA (Linear Discriminant Analysis) and SVM (Support Vector Machine) outperforms others. The recognition rate of this method is 95.71% by using leave-one-out strategy and 94.13% by using cross-validation strategy. It takes only 0.0357 second to process one image of size 256 × 256.,True,uXEp3MIAAAAJ:Tyk-4Ss8FVUC,160,https://www.worldscientific.com/doi/abs/10.1142/S0218001408006284,14965338028152033502,/scholar?cites=14965338028152033502,,,https://www.researchgate.net/profile/Patrick_Wang3/publication/220359507_Performance_Comparisons_of_Facial_Expression_Recognition_in_Jaffe_Database/links/00b4951a0f2b56b66e000000.pdf,0,0,0
1278455,Robust watermarking and compression for medical images based on genetic algorithms,2005,Frank Y Shih and Yi-Ta Wu,175,Information Sciences,3,200-216,Elsevier,A ROI (region of interest) of a medical image is an area including important information and must be stored without any distortion. In order to achieve optimal compression as well as satisfactory visualization of medical images. we compress the ROI by lossless compression. and the rest by lossy compression. Furthermore. security is an important issue in web-based medical information system. Watermarking skill is often used for protecting medical images. In this paper. we present a robust technique embedding the watermark of signature information or textual data around the ROI of a medical image based on genetic algorithms. A fragile watermark is adopted to detect any unauthorized modification. The embedding of watermark in the frequency domain is more difficult to be pirated than in spatial domain.,True,uXEp3MIAAAAJ:zYLM7Y9cAGgC,142,https://www.sciencedirect.com/science/article/pii/S0020025505000344,9548076192742891277,/scholar?cites=9548076192742891277,,,,0,0,0
1278456,MOEA/D with adaptive weight adjustment,2014,Yutao Qi and Xiaoliang Ma and Fang Liu and Licheng Jiao and Jianyong Sun and Jianshe Wu,22,Evolutionary computation,2,231-264,MIT Press,Recently. MOEA/D (multi-objective evolutionary algorithm based on decomposition) has achieved great success in the field of evolutionary multi-objective optimization and has attracted a lot of attention. It decomposes a multi-objective optimization problem (MOP) into a set of scalar subproblems using uniformly distributed aggregation weight vectors and provides an excellent general algorithmic framework of evolutionary multi-objective optimization. Generally. the uniformity of weight vectors in MOEA/D can ensure the diversity of the Pareto optimal solutions. however. it cannot work as well when the target MOP has a complex Pareto front (PF; ie. discontinuous PF or PF with sharp peak or low tail). To remedy this. we propose an improved MOEA/D with adaptive weight vector adjustment (MOEA/D-AWA). According to the analysis of the geometric relationship between the weight vectors and the optimal solutions …,True,qrQkfxYAAAAJ:4fGpz3EwCPoC,394,https://www.mitpressjournals.org/doi/abs/10.1162/EVCO_a_00109,13950535967834343849,/scholar?cites=13950535967834343849,,,http://repository.essex.ac.uk/15263/1/evco_a_00109.pdf,0,0,0
1278457,Spectral clustering ensemble applied to SAR image segmentation,2008,Xiangrong Zhang and Licheng Jiao and Fang Liu and Liefeng Bo and Maoguo Gong,46,IEEE Transactions on Geoscience and Remote Sensing,7,2126-2136,IEEE,Spectral clustering (SC) has been used with success in the field of computer vision for data clustering. In this paper. a new algorithm named SC ensemble (SCE) is proposed for the segmentation of synthetic aperture radar (SAR) images. The gray-level cooccurrence matrix-based statistic features and the energy features from the undecimated wavelet decomposition extracted for each pixel being the input. our algorithm performs segmentation by combining multiple SC results as opposed to using outcomes of a single clustering process in the existing literature. The random subspace. random scaling parameter. and Nystrom approximation for component SC are applied to construct the SCE. This technique provides necessary diversity as well as high quality of component learners for an efficient ensemble. It also overcomes the shortcomings faced by the SC. such as the selection of scaling parameter. and the …,True,qrQkfxYAAAAJ:eMMeJKvmdy0C,261,https://ieeexplore.ieee.org/abstract/document/4544948/,2212607114794635740,/scholar?cites=2212607114794635740,,,https://www.researchgate.net/profile/Xiangrong_Zhang5/publication/3205816_Spectral_Clustering_Ensemble_Applied_to_SAR_Image_Segmentation/links/0046352fcb72c62618000000.pdf,0,0,0
1278458,压缩感知回顾与展望,2011,焦李成， 杨淑媛， 刘芳， 侯彪,39,,007,1651-1662,,压缩感知是建立在矩阵分析. 统计概率论. 拓扑几何. 优化与运筹学. 泛函分析等基础上的一种全新的信息获取与处理的理论框架. 它基于信号的可压缩性. 通过低维空间. 低分辨率. 欠 Nyquist 采样数据的非相关观测来实现高维信号的感知. 压缩感知不仅让我们重新审视线性问题. 而且丰富了关于信号恢复的优化策略. 极大的促进了数学理论和工程应用的结合. 目前. 压缩感知的研究正从早期的概念理解. 数值仿真. 原理验证. 系统初步设计等阶段. 转入到理论的进一步深化. 以及实际系统的开发与应用阶段. 本文分析了压缩感知的原理与应用. 综述了压缩感知的最新进展及存在的问题. 指出了进一步研究的方向.,True,qrQkfxYAAAAJ:SeFeTyx0c_EC,235,http://www.ejournal.org.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=1197,12234581994857904391,/scholar?cites=12234581994857904391,,,http://www.ejournal.org.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=1197,0,0,0
1278459,A survey of deep learning-based object detection,2019,Licheng Jiao and Fan Zhang and Fang Liu and Shuyuan Yang and Lingling Li and Zhixi Feng and Rong Qu,7,IEEE Access,,128837-128868,IEEE,Object detection is one of the most important and challenging branches of computer vision. which has been widely applied in people's life. such as monitoring security. autonomous driving and so on. with the purpose of locating instances of semantic objects of a certain class. With the rapid development of deep learning algorithms for detection tasks. the performance of object detectors has been greatly improved. In order to understand the main development status of object detection pipeline thoroughly and deeply. in this survey. we analyze the methods of existing typical detection models and describe the benchmark datasets at first. Afterwards and primarily. we provide a comprehensive overview of a variety of object detection methods in a systematic manner. covering the one-stage and two-stage detectors. Moreover. we list the traditional and new applications. Some representative branches of object detection …,True,qrQkfxYAAAAJ:NJ774b8OgUMC,210,https://ieeexplore.ieee.org/abstract/document/8825470/,5669364687087032958,/scholar?cites=5669364687087032958,,,https://ieeexplore.ieee.org/iel7/6287639/8600701/08825470.pdf,0,0,0
1278460,Development and prospect of compressive sensing,2011,Li-Cheng Jiao and Shu-Yuan Yang and Fang Liu and Biao Hou,39,Dianzi Xuebao(Acta Electronica Sinica),7,1651-1662,Chinese Institute of Electronics.| a P. O. Box 165| c Beijing| z 100036| e newjournal. org. cn| u dzxu. chinajournal. net. cn,Compressive Sensing (CS) is a new developed theoretical framework for information acquisition and processing. which is based on matrix analysis. statistical probability theory. topological geometry. optimization and opsearch. functional analysis and so on. The high-dimensional signals can be recovered from the low-dimensional and sub-Nyquist sampling data based on the compressibility of signals. It not only inspires us to survey the linear problem again. but also enriches the optimization approaches for signal recovery to promote the combination of mathematics with engineering application. Nowadays the researches on compressive sensing have developed from the earlier concept understanding. numerical simulation. principle verification. and primary system designation. to the deeper researches on theory. development and application of practical system. In this paper. we introduce the basic idea of compressive sensing. and the development history. current and future challenges.[Fund]: 国家自然科学基金 (No. 61072108 No. 60971112 No. 61072106 No. 60971128 No. 60970067 No. 61072108);; 中央高校基本科研业务费专项资金 (No. JY10000902041 No. J54510020160 No. JY10000902001 No. K50510020001);; 高等学校学科创新引智计划 (111 计划) 基金 (No. B07048),True,qrQkfxYAAAAJ:ML0RJ9NH7IQC,199,https://en.cnki.com.cn/Article_en/CJFDTotal-DZXU201107030.htm,9369623537918567469,/scholar?cites=9369623537918567469,,,,0,0,0
1278461,免疫优化计算. 学习与识别,2006,焦李成， 杜海峰， 刘芳， 公茂果,5,,,770-776,北京: 科学出版社,本书是作者在人工免疫系统领域研究成果的系统总结. 在全面总结国内外人工免疫系统发展现状的基础上. 本书着重介绍作者在这一领域的研究成果. 主要包括: 免疫算法. 免疫克隆选择算法. 量子克隆计算. 人工免疫网络等算法的构造及其在数据聚类. 网络路由. 通信多用户检测. 计算机网络安全等领域中的相关应用. 本书也探讨了人工免疫系统进一步研究的方向.本书可以为计算机科学. 信息科学. 人工智能和自动化技术等领域从事人工免疫系统研究的相关专业技术人员提供参考. 也可以作为相关专业研究生和高年级本科生教材.,True,qrQkfxYAAAAJ:p2g8aNsByqUC,190,http://www.ecsponline.com/yz/B59530E6D62074138A280CFDFBFEC0A36000.pdf,16433496099884005892,/scholar?cites=16433496099884005892,,,http://www.ecsponline.com/yz/B59530E6D62074138A280CFDFBFEC0A36000.pdf,0,0,0
1278462,A multiobjective evolutionary algorithm based on decision variable analyses for multiobjective optimization problems with large-scale variables,2015,Xiaoliang Ma and Fang Liu and Yutao Qi and Xiaodong Wang and Lingling Li and Licheng Jiao and Minglei Yin and Maoguo Gong,20,IEEE Transactions on Evolutionary Computation,2,275-298,IEEE,State-of-the-art multiobjective evolutionary algorithms (MOEAs) treat all the decision variables as a whole to optimize performance. Inspired by the cooperative coevolution and linkage learning methods in the field of single objective optimization. it is interesting to decompose a difficult high-dimensional problem into a set of simpler and low-dimensional subproblems that are easier to solve. However. with no prior knowledge about the objective function. it is not clear how to decompose the objective function. Moreover. it is difficult to use such a decomposition method to solve multiobjective optimization problems (MOPs) because their objective functions are commonly conflicting with one another. That is to say. changing decision variables will generate incomparable solutions. This paper introduces interdependence variable analysis and control variable analysis to deal with the above two difficulties. Thereby. an …,True,qrQkfxYAAAAJ:uJ-U7cs_P_0C,152,https://ieeexplore.ieee.org/abstract/document/7155533/,6902595467334643473,/scholar?cites=6902595467334643473,,,https://www.researchgate.net/profile/Yutao_Qi/publication/282540163_A_Multiobjective_Evolutionary_Algorithm_Based_on_Decision_Variable_Analyses_for_Multiobjective_Optimization_Problems_With_Large-Scale_Variables/links/5716b23808ae377f0bd619fe.pdf,0,0,0
1278463,A novel immune clonal algorithm for MO problems,2011,Ronghua Shang and Licheng Jiao and Fang Liu and Wenping Ma,16,IEEE Transactions on Evolutionary Computation,1,35-50,IEEE,Research on multiobjective optimization (MO) becomes one of the hot points of intelligent computation. Compared with evolutionary algorithm. the artificial immune system used for solving MO problems (MOPs) has shown many good performances in improving the convergence speed and maintaining the diversity of the antibody population. However. the simple clonal selection computation has some difficulties in handling some more complex MOPs. In this paper. the simple clonal selection strategy is improved and a novel immune clonal algorithm (NICA) is proposed. The improvements in NICA are mainly focus on four aspects. 1) Antibodies in the antibody population are divided into dominated ones and nondominated ones. which is suitable for the characteristic of one multiobjective optimization problem has a series Pareto-optimal solutions. 2) The entire cloning is adopted instead of different antibodies having …,True,qrQkfxYAAAAJ:Fu2w8maKXqMC,117,https://ieeexplore.ieee.org/abstract/document/6105568/,5544313618169288319,/scholar?cites=5544313618169288319,,,,0,0,0
1278464,POL-SAR image classification based on Wishart DBN and local spatial information,2016,Fang Liu and Licheng Jiao and Biao Hou and Shuyuan Yang,54,IEEE Transactions on Geoscience and Remote Sensing,6,3292-3308,IEEE,Inspired by a popular deep neural network. i.e.. deep belief network (DBN). a novel method for polarimetric synthetic aperture radar (POL-SAR) image classification is proposed in this paper. For the particularity of POL-SAR data. a new type of restricted Boltzmann machine (RBM) is specially defined. which we name the Wishart-Bernoulli RBM (WBRBM). and is used to form a deep network named as Wishart DBN (W-DBN). Numerous unlabeled POL-SAR pixels are made full use of in the modeling of POL-SAR pixels by W-DBN. In addition. the coherency matrix is used directly to represent a POL-SAR pixel without any manual feature extraction. which is simple and time saving. Local spatial information. together with the confusion matrix. is used in this paper to clean the preliminary classification result obtained by the method based on W-DBN. Making full use of the prior knowledge of POL-SAR data and local spatial …,True,qrQkfxYAAAAJ:D_sINldO8mEC,107,https://ieeexplore.ieee.org/abstract/document/7390251/,278874981130771084,/scholar?cites=278874981130771084,,,,0,0,0
1278465,Learning intrinsic sparse structures within long short-term memory,2017,Wei Wen and Yuxiong He and Samyam Rajbhandari and Minjia Zhang and Wenhan Wang and Fang Liu and Bin Hu and Yiran Chen and Hai Li,,arXiv preprint arXiv:1709.05027,,,,Model compression is significant for the wide adoption of Recurrent Neural Networks (RNNs) in both user devices possessing limited resources and business clusters requiring quick responses to large-scale service requests. This work aims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the sizes of basic structures within LSTM units. including input updates. gates. hidden states. cell states and outputs. Independently reducing the sizes of basic structures can result in inconsistent dimensions among them. and consequently. end up with invalid LSTM units. To overcome the problem. we propose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS will simultaneously decrease the sizes of all basic structures by one and thereby always maintain the dimension consistency. By learning ISS within LSTM units. the obtained LSTMs remain regular while having much smaller basic structures. Based on group Lasso regularization. our method achieves 10.59 x speedup without losing any perplexity of a language modeling of Penn TreeBank dataset. It is also successfully evaluated through a compact model with only 2.69 M weights for machine Question Answering of SQuAD dataset. Our approach is successfully extended to non-LSTM RNNs. like Recurrent Highway Networks (RHNs). Our source code is publicly available at this https URL,True,qrQkfxYAAAAJ:ALROH1vI_8AC,100,https://arxiv.org/abs/1709.05027,9492556084863806404,/scholar?cites=9492556084863806404,,,https://arxiv.org/pdf/1709.05027,0,0,0
1278466,SAR Image segmentation based on convolutional-wavelet neural network and markov random field,2017,Yiping Duan and Fang Liu and Licheng Jiao and Peng Zhao and Lu Zhang,64,Pattern Recognition,,255-267,Pergamon,Synthetic aperture radar (SAR) imaging system is usually an observation of the earths' surface. It means that rich structures exist in SAR images. Convolutional neural network (CNN) is good at learning features from raw data automatically. especially the structural features. Inspired by these. we propose a novel SAR image segmentation method based on convolutional-wavelet neural networks (CWNN) and Markov Random Field (MRF). In this approach. a wavelet constrained pooling layer is designed to replace the conventional pooling in CNN. The new architecture can suppress the noise and is better at keeping the structures of the learned features. which are crucial to the segmentation tasks. CWNN produces the segmentation map by patch-by-patch scanning. The segmentation result of CWNN will be used with two labeling strategies (i.e.. a superpixel approach and a MRF approach) to produce the final …,True,qrQkfxYAAAAJ:olpn-zPbct0C,98,https://www.sciencedirect.com/science/article/pii/S0031320316303727,1444372837479427807,/scholar?cites=1444372837479427807,,,,0,0,0
1278467,Model-based object pose in 25 lines of code,1995,Daniel F DeMenthon and Larry S Davis,15,International journal of computer vision,1-2,123-141,Kluwer Academic Publishers,In this paper. we describe a method for finding the pose of an object from a single image. We assume that we can detect and match in the image four or more noncoplanar feature points of the object. and that we know their relative geometry on the object. The method combines two algorithms; the first algorithm.POS (Pose from Orthography and Scaling) approximates the perspective projection with a scaled orthographic projection and finds the rotation matrix and the translation vector of the object by solving a linear system; the second algorithm.POSIT (POS with ITerations). uses in its iteration loop the approximate pose found by POS in order to compute better scaled orthographic projections of the feature points. then applies POS to these projections instead of the original image projections. POSIT converges to accurate pose measurements in a few iterations. POSIT can be used with many feature points at …,True,3VqC2CEAAAAJ:u5HHmVD_uO8C,1417,https://link.springer.com/content/pdf/10.1007/BF01450852.pdf,1270992904105952414,/scholar?cites=1270992904105952414,,,https://www.researchgate.net/profile/Daniel-Dementhon-2/publication/2736700_Model-Based_Object_Pose_in_25_Lines_of_Code/links/5bfd8266a6fdcc35428c9016/Model-Based-Object-Pose-in-25-Lines-of-Code.pdf,0,0,0
1278468,Computer vision system for position monitoring in three dimensions using non-coplanar light sources attached to a monitored object,1993,Daniel F Dementhon,,,,,,A sensing system for monitoring the position and orientation of a rigid object (20). At least 4 point light sources (24) are mounted on the surface of the object (20) in a noncoplanar arrangement. A single electronic camera (26) captures images (59) of the point light sources (24). Locations of the images (59) of the light sources (24) are detected in each video image. and a computer runs a task using these locations to obtain close approximations of the rotation matrix and translation vector (33) of the object (20) in a camera coordinate system (74) at video rate. The object is held by an operator (90) for three-dimensional cursor (94) control and interaction with virtual reality scenes (96) on computer displays (88). and for remote interactive control of teleoperated mechanisms.,True,3VqC2CEAAAAJ:9yKSN-GCB0IC,430,https://patents.google.com/patent/US5227985A/en,18133415676261426904,/scholar?cites=18133415676261426904,,,https://patentimages.storage.googleapis.com/b9/f9/98/324daf9f20fad8/US5227985.pdf,0,0,0
1278469,Video summarization by curve simplification,1998,Daniel DeMenthon and Vikrant Kobla and David Doermann,,,,211-218,,. 4 video sequence can be reprmented as a trajectory curve in a high dmensiond feature space. This video curve can be an~ yzed by took Mar to those devdoped for planar cnrv=. h partidar. the classic biiary curve sphtting algorithm has been fonnd to be a nseti tool for video analysis. With a spEtting condition that checks the dimension-&@ of the curve szgrnent being spht. the video curve can be recursivdy sirnpMed and repr~ ented as a tree stmcture. and the framm that are fomtd to be junctions betieen curve segments at Merent. lev& of the tree can be used as ke-fiarn~ s to summarize the tideo sequences at Merent levds of detti. The-e keyframes can be combmed in various spatial and tempord configurations for browsing purposes. We describe a simple video player that displays the ke. fiarn~ seqnentifly and lets the user change the summarization level on the fly tith an additiond shder.,True,3VqC2CEAAAAJ:u-x6o8ySG0sC,399,https://dl.acm.org/doi/pdf/10.1145/290747.290773,1346401672233581942,/scholar?cites=1346401672233581942,,,https://apps.dtic.mil/sti/pdfs/ADA459300.pdf,0,0,0
1278470,Iterative pose estimation using coplanar feature points,1996,Denis Oberkampf and Daniel F DeMenthon and Larry S Davis,63,Computer Vision and Image Understanding,3,495-511,Academic Press,This paper presents a new method for the computation of the position and orientation of a camera with respect to a known object. using four or morecoplanarfeature points. Starting with the scaled orthographic projection approximation. this method iteratively refines up to two different pose estimates. and provides an associated quality measure for each pose. When the camera distance is large compared with the object depth. or when the accuracy of feature point extraction is low because of image noise. the quality measures for the two poses are similar. and the two pose estimates are plausible interpretations of the available information. In contrast. known methods using a closed form pose solution for four coplanar points are not robust for distant objects in the presence of image noise because they provide only one of the two possible poses and may choose the wrong pose.,True,3VqC2CEAAAAJ:d1gkVwhDpl0C,357,https://www.sciencedirect.com/science/article/pii/S1077314296900375,6065971239865045367,/scholar?cites=6065971239865045367,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.636.9628&rep=rep1&type=pdf,0,0,0
1278471,Model-based object pose in 25 lines of code,1992,Daniel F DeMenthon and Larry S Davis,,,,335-343,Springer. Berlin. Heidelberg,We find the pose of an object from a single image when the relative geometry of four or more noncoplanar visible feature points is known. We first describe an algorithm. POS (Pose from Orthography and Scaling). that solves for the rotation matrix and the translation vector of the object by a linear algebra technique under the scaled orthographic projection approximation. We then describe an iterative algorithm. POSIT (POS with ITerations). that uses the pose found by POS to remove the “perspective distortions” from the image. then applies POS to the corrected image instead of the original image. POSIT generally converges to accurate pose measurements in a few iterations. Mathematica code is provided in an Appendix.,True,3VqC2CEAAAAJ:2osOgNQ5qMEC,276,https://link.springer.com/chapter/10.1007/3-540-55426-2_38,17131816919175817053,/scholar?cites=17131816919175817053,,,https://link.springer.com/content/pdf/10.1007/3-540-55426-2_38.pdf,0,0,0
1278472,SoftPOSIT: Simultaneous pose and correspondence determination,2004,Philip David and Daniel Dementhon and Ramani Duraiswami and Hanan Samet,59,International Journal of Computer Vision,3,259-284,Kluwer Academic Publishers,The problem of pose estimation arises in many areas of computer vision. including object recognition. object tracking. site inspection and updating. and autonomous navigation when scene models are available. We present a new algorithm. called SoftPOSIT. for determining the pose of a 3D object from a single 2D image when correspondences between object points and image points are not known. The algorithm combines the iterative softassign algorithm (Gold and Rangarajan. 1996; Gold et al.. 1998) for computing correspondences and the iterative POSIT algorithm (DeMenthon and Davis. 1995) for computing object pose under a full-perspective camera model. Our algorithm. unlike most previous algorithms for pose determination. does not have to hypothesize small sets of matches and then verify the remaining image points. Instead. all possible matches are treated identically throughout the search for …,True,3VqC2CEAAAAJ:zYLM7Y9cAGgC,255,https://link.springer.com/article/10.1023/B:VISI.0000025800.10423.1f,1589043219654013642,/scholar?cites=1589043219654013642,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.739.7612&rep=rep1&type=pdf,0,0,0
1278473,Hierarchical part-template matching for human detection and segmentation,2007,Zhe Lin and Larry S Davis and David Doermann and Daniel DeMenthon,,,,1-8,IEEE,Local part-based human detectors are capable of handling partial occlusions efficiently and modeling shape articulations flexibly. while global shape template-based human detectors are capable of detecting and segmenting human shapes simultaneously. We describe a Bayesian approach to human detection and segmentation combining local part-based and global template-based schemes. The approach relies on the key ideas of matching a part-template tree to images hierarchically to generate a reliable set of detection hypotheses and optimizing it under a Bayesian MAP framework through global likelihood re-evaluation and fine occlusion analysis. In addition to detection. our approach is able to obtain human shapes and poses simultaneously. We applied the approach to human detection and segmentation in crowded scenes with and without background subtraction. Experimental results show that our …,True,3VqC2CEAAAAJ:IjCSPb-OGe4C,239,https://ieeexplore.ieee.org/abstract/document/4408975/,5931662843225731788,/scholar?cites=5931662843225731788,,,http://www.ssig.dcc.ufmg.br/wp-content/uploads/2014/11/Hierarchical-part-template-matching-for-human-detection-and-segmentation.pdf,0,0,0
1278474,Spatio-temporal segmentation of video by hierarchical mean shift analysis,2002,Daniel DeMenthon and Remi Megret,,,,,Computer Vision Laboratory. Center for Automation Research. University of Maryland,We describe a simple new technique for spatio-temporal segmentation of video sequences. Each pixel of a 3D space-time video stack is mapped to a 7D feature point whose coordinates include three color components. two motion angle components and two motion position components. The clustering of these feature points provides color segmentation and motion segmentation. as well as a consistent labeling of regions over time which amounts to region tracking. For this task we have adopted a hierarchical clustering method which operates by repeatedly applying mean shift analysis over increasingly large ranges. using at each pass the cluster centers of the previous pass. with weights equal to the counts of the points that contributed to the clusters. This technique has lower complexity for large mean shift radii than ordinary mean shift analysis because it can use binary tree structures more efficiently during range search. In addition. it provides a hierarchical segmentation of the data. Applications include video compression and compact descriptions of video sequences for video indexing and retrieval applications.,True,3VqC2CEAAAAJ:UeHWp8X0CEIC,210,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8958&rep=rep1&type=pdf,1391525460258919958,/scholar?cites=1391525460258919958,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8958&rep=rep1&type=pdf,0,0,0
1278475,Exact and approximate solutions of the perspective-three-point problem,1992,Daniel DeMenthon and Larry S Davis,14,IEEE Transactions on Pattern Analysis and Machine Intelligence,11,1100-1105,,"Model-based pose estimation techniques that match image and model triangles require large numbers of matching operations in realworld applications. We show that by using approximations to perspective. 2-D lookup tables can be built for each of the triangles of the models. An approximation called"" weak perspective"" has been applied previously to this problem; we consider two other perspective approximations: paraperspective and orthoperspective. These approximations produce lower errors for off-center image features than weak perspective.",True,3VqC2CEAAAAJ:qjMakFHDy7sC,198,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.4872&rep=rep1&type=pdf,5484739380723223765,/scholar?cites=5484739380723223765,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.4872&rep=rep1&type=pdf,0,0,0
1278476,Geometric rectification of camera-captured document images,2008,Jian Liang and Daniel DeMenthon and David Doermann,30,IEEE transactions on pattern analysis and machine intelligence,4,591-605,IEEE,Compared to typical scanners. handheld cameras offer convenient. flexible. portable. and noncontact image capture. which enables many new applications and breathes new life into existing ones. However. camera-captured documents may suffer from distortions caused by a nonplanar document shape and perspective projection. which lead to the failure of current optical character recognition (OCR) technologies. We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates the 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many. especially mobile. camera-based document analysis applications. Experiments …,True,3VqC2CEAAAAJ:8k81kl-MbHgC,177,https://ieeexplore.ieee.org/abstract/document/4359339/,992736431496291547,/scholar?cites=992736431496291547,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.5063&rep=rep1&type=pdf,0,0,0
1278477,Three Dimensional Pointing Device Monitored by Computer Vision,1994,Daniel F Dementhon and Yukio Fujii,,,,,,A pointing device (28). comprising light sources (30) and monitored by a computer vision task running in a microcontroller (108) and a computer (24). The computer vision task computes the spatial position and orientation of the pointing device. and enables an operator to control virtual three dimensional objects (73) on the display (22) of the computer. Images (78) are captured by a video camera (20) and digitized. and only image rows that contain bright pixels (80) from the light sources are processed. The light sources are the tips of optic fibers (30) guiding light from a laser diode (32). and an optical filter (46) on the camera is matched to the wavelength of the laser diode.,True,3VqC2CEAAAAJ:W7OEmFMy1HYC,166,https://patents.google.com/patent/US5297061A/en,12658217013987891021,/scholar?cites=12658217013987891021,,,https://patentimages.storage.googleapis.com/30/f3/a7/380fe9aa9a25f0/US5297061.pdf,0,0,0
1278478,Deep learning of binary hash codes for fast image retrieval,2015,Kevin Lin and Huei-Fang Yang and Jen-Hao Hsiao and Chu-Song Chen,,,,27-35,,Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval. Encouraged by the recent advances in convolutional neural networks (CNNs). we propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are available. binary codes can be learned by employing a hidden layer for representing the latent concepts that dominate the class labels. The utilization of the CNN also allows for learning image representations. Unlike other supervised methods that require pair-wised inputs for binary code learning. our method learns hash codes and image representations in a point-wised manner. making it suitable for large-scale datasets. Experimental results show that our method outperforms several state-of-the-art hashing algorithms on the CIFAR-10 and MNIST datasets. We further demonstrate the scalability and efficacy of the proposed approach on the large-scale dataset of 1 million clothing images.,True,WKk6fIQAAAAJ:HLU_K49guOkC,515,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W03/html/Lin_Deep_Learning_of_2015_CVPR_paper.html,15791354256571344299,/scholar?cites=15791354256571344299,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W03/papers/Lin_Deep_Learning_of_2015_CVPR_paper.pdf,0,0,0
1278479,RANSAC-based DARCES: A new approach to fast automatic registration of partially overlapping range images,1999,Chu-Song Chen and Yi-Ping Hung and Jen-Bo Cheng,21,IEEE Transactions on Pattern Analysis and Machine Intelligence,11,1229-1234,IEEE,In this paper. we propose a new method. the RANSAC-based DARCES method (data-aligned rigidity-constrained exhaustive search based on random sample consensus). which can solve the partially overlapping 3D registration problem without any initial estimation. For the noiseless case. the basic algorithm of our method can guarantee that the solution it finds is the true one. and its time complexity can be shown to be relatively low. An extra characteristic is that our method can be used even for the case that there are no local features in the 3D data sets.,True,WKk6fIQAAAAJ:u5HHmVD_uO8C,440,https://ieeexplore.ieee.org/abstract/document/809117/,15895821643925328995,/scholar?cites=15895821643925328995,,,https://www.academia.edu/download/23647780/chen99_darces.pdf,0,0,0
1278480,Ordinal hyperplanes ranker with cost sensitivities for age estimation,2011,Kuang-Yu Chang and Chu-Song Chen and Yi-Ping Hung,,,,585-592,IEEE,In this paper. we propose an ordinal hyperplane ranking algorithm called OHRank. which estimates human ages via facial images. The design of the algorithm is based on the relative order information among the age labels in a database. Each ordinal hyperplane separates all the facial images into two groups according to the relative order. and a cost-sensitive property is exploited to find better hyperplanes based on the classification costs. Human ages are inferred by aggregating a set of preferences from the ordinal hyperplanes with their cost sensitivities. Our experimental results demonstrate that the proposed approach outperforms conventional multiclass-based and regression-based approaches as well as recently developed ranking-based age estimation approaches.,True,WKk6fIQAAAAJ:yD5IFk8b50cC,342,https://ieeexplore.ieee.org/abstract/document/5995437/,8313390000088422612,/scholar?cites=8313390000088422612,,,https://homepage.iis.sinica.edu.tw/~kuangyu/OHRank_files/0523.pdf,0,0,0
1278481,Multiple kernel fuzzy clustering,2011,Hsin-Chien Huang and Yung-Yu Chuang and Chu-Song Chen,20,IEEE Transactions on Fuzzy Systems,1,120-134,IEEE,While fuzzy c-means is a popular soft-clustering method. its effectiveness is largely limited to spherical clusters. By applying kernel tricks. the kernel fuzzy c-means algorithm attempts to address this problem by mapping data with nonlinear relationships to appropriate feature spaces. Kernel combination. or selection. is crucial for effective kernel clustering. Unfortunately. for most applications. it is uneasy to find the right combination. We propose a multiple kernel fuzzy c-means (MKFC) algorithm that extends the fuzzy c-means algorithm with a multiple kernel-learning setting. By incorporating multiple kernels and automatically adjusting the kernel weights. MKFC is more immune to ineffective kernels and irrelevant features. This makes the choice of kernels less crucial. In addition. we show multiple kernel k-means to be a special case of MKFC. Experiments on both synthetic and real-world data demonstrate the …,True,WKk6fIQAAAAJ:K3LRdlH-MEoC,309,https://ieeexplore.ieee.org/abstract/document/6031914/,5400612875566024338,/scholar?cites=5400612875566024338,,,http://www.iis.sinica.edu.tw/papers/song/12972-F.pdf,0,0,0
1278482,Cross-age reference coding for age-invariant face recognition and retrieval,2014,Bor-Chun Chen and Chu-Song Chen and Winston H Hsu,,,,768-783,Springer. Cham,Recently. promising results have been shown on face recognition researches. However. face recognition and retrieval across age is still challenging. Unlike prior methods using complex models with strong parametric assumptions to model the aging process. we use a data-driven method to address this problem. We propose a novel coding framework called Cross-Age Reference Coding (CARC). By leveraging a large-scale image dataset freely available on the Internet as a reference set. CARC is able to encode the low-level feature of a face image with an age-invariant reference space. In the testing phase. the proposed method only requires a linear projection to encode the feature and therefore it is highly scalable. To thoroughly evaluate our work. we introduce a new large-scale dataset for face recognition and retrieval across age called Cross-Age Celebrity Dataset (CACD). The dataset contains more …,True,WKk6fIQAAAAJ:p39txVt3toMC,296,https://link.springer.com/chapter/10.1007/978-3-319-10599-4_49,17233726932630046823,/scholar?cites=17233726932630046823,,,https://link.springer.com/content/pdf/10.1007/978-3-319-10599-4_49.pdf,0,0,0
1278483,Learning compact binary descriptors with unsupervised deep neural networks,2016,Kevin Lin and Jiwen Lu and Chu-Song Chen and Jie Zhou,,,,1183-1192,,In this paper. we propose a new unsupervised deep learning approach called DeepBit to learn compact binary descriptor for efficient visual object matching. Unlike most existing binary descriptors which were designed with random projections or linear hash functions. we develop a deep neural network to learn binary descriptors in a unsupervised manner. We enforce three criterions on binary codes which are learned at the top layer of our network: 1) minimal loss quantization. 2) evenly distributed codes and 3) uncorrelated bits. Then. we learn the parameters of the networks with a back-propagation technique. Experimental results on three different visual analysis tasks including image matching. image retrieval. and object recognition clearly demonstrate the effectiveness of the proposed approach.,True,WKk6fIQAAAAJ:WN7eEiAxqlEC,254,http://openaccess.thecvf.com/content_cvpr_2016/html/Lin_Learning_Compact_Binary_CVPR_2016_paper.html,3415716566019331345,/scholar?cites=3415716566019331345,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Lin_Learning_Compact_Binary_CVPR_2016_paper.pdf,0,0,0
1278484,Supervised learning of semantics-preserving hash via deep convolutional neural networks,2017,Huei-Fang Yang and Kevin Lin and Chu-Song Chen,40,IEEE transactions on pattern analysis and machine intelligence,2,437-451,IEEE,This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off. and classification relies on these attributes. Based on this assumption. our approach. dubbed supervised semantics-preserving deep hashing (SSDH). constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design. SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover. SSDH performs joint learning of image representations. hash codes. and classification in a point-wised manner. and thus is scalable to large-scale datasets. SSDH is simple …,True,WKk6fIQAAAAJ:oP4RMhgCrzQC,222,https://ieeexplore.ieee.org/abstract/document/7849132/,914342533906912610,/scholar?cites=914342533906912610,,,https://arxiv.org/pdf/1507.00101,0,0,0
1278485,Efficient hierarchical method for background subtraction,2007,Yu-Ting Chen and Chu-Song Chen and Chun-Rong Huang and Yi-Ping Hung,40,Pattern Recognition,10,2706-2715,Pergamon,Detecting moving objects by using an adaptive background model is a critical component for many vision-based applications. Most background models were maintained in pixel-based forms. while some approaches began to study block-based representations which are more robust to non-stationary backgrounds. In this paper. we propose a method that combines pixel-based and block-based approaches into a single framework. We show that efficient hierarchical backgrounds can be built by considering that these two approaches are complementary to each other. In addition. a novel descriptor is proposed for block-based background modeling in the coarse level of the hierarchy. Quantitative evaluations show that the proposed hierarchical method can provide better results than existing single-level approaches.,True,WKk6fIQAAAAJ:UeHWp8X0CEIC,205,https://www.sciencedirect.com/science/article/pii/S003132030600495X,14298790769055297216,/scholar?cites=14298790769055297216,,,https://scholars.lib.ntu.edu.tw/bitstream/123456789/117630/1/23.pdf,0,0,0
1278486,Face recognition and retrieval using cross-age reference coding with cross-age celebrity dataset,2015,Bor-Chun Chen and Chu-Song Chen and Winston H Hsu,17,IEEE Transactions on Multimedia,6,804-815,IEEE,This paper introduces a method for face recognition across age and also a dataset containing variations of age in the wild. We use a data-driven method to address the cross-age face recognition problem. called cross-age reference coding (CARC). By leveraging a large-scale image dataset freely available on the Internet as a reference set. CARC can encode the low-level feature of a face image with an age-invariant reference space. In the retrieval phase. our method only requires a linear projection to encode the feature and thus it is highly scalable. To evaluate our method. we introduce a large-scale dataset called cross-age celebrity dataset (CACD). The dataset contains more than 160 000 images of 2.000 celebrities with age ranging from 16 to 62. Experimental results show that our method can achieve state-of-the-art performance on both CACD and the other widely used dataset for face recognition across …,True,WKk6fIQAAAAJ:9EHOSoRxHQgC,202,https://ieeexplore.ieee.org/abstract/document/7080893/,3690310240027080462,/scholar?cites=3690310240027080462,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.707.8032&rep=rep1&type=pdf,0,0,0
1278487,Affinity aggregation for spectral clustering,2012,Hsin-Chien Huang and Yung-Yu Chuang and Chu-Song Chen,,,,773-780,IEEE,Spectral clustering makes use of spectral-graph structure of an affinity matrix to partition data into disjoint meaningful groups. Because of its elegance. efficiency and good performance. spectral clustering has become one of the most popular clustering methods. Traditional spectral clustering assumes a single affinity matrix. However. in many applications. there could be multiple potentially useful features and thereby multiple affinity matrices. To apply spectral clustering for these cases. a possible way is to aggregate the affinity matrices into a single one. Unfortunately. affinity measures constructed from different features could have different characteristics. Careless aggregation might make even worse clustering performance. This paper proposes an affinity aggregation spectral clustering (AASC) algorithm which extends spectral clustering to a setting with multiple affinities available. AASC seeks for an optimal …,True,WKk6fIQAAAAJ:olpn-zPbct0C,166,https://ieeexplore.ieee.org/abstract/document/6247748/,4394595394957610589,/scholar?cites=4394595394957610589,,,https://homepage.iis.sinica.edu.tw/papers/song/13689-F.pdf,0,0,0
1278488,Moving cast shadow detection using physics-based features,2009,Jia-Bin Huang and Chu-Song Chen,,,,2310-2317,IEEE,Cast shadows induced by moving objects often cause serious problems to many vision applications. We present in this paper an online statistical learning approach to model the background appearance variations under cast shadows. Based on the bi-illuminant (i.e. direct light sources and ambient illumination) dichromatic reflection model. we derive physics-based color features under the assumptions of constant ambient illumination and light sources with common spectral power distributions. We first use one Gaussian mixture model (GMM) to learn the color features. which are constant regardless of the background surfaces or illuminant colors in a scene. Then. we build up one pixel based GMM for each pixel to learn the local shadow features. To overcome the slow convergence rate in the conventional GMM learning. we update the pixel-based GMMs through confidence-rated learning. The proposed method …,True,WKk6fIQAAAAJ:Zph67rFs4hoC,165,https://ieeexplore.ieee.org/abstract/document/5206629/,270700132542757895,/scholar?cites=270700132542757895,,,https://www.researchgate.net/profile/Jia_Bin_Huang/publication/221363976_Moving_cast_shadow_detection_using_Physics-based_features/links/553edaac0cf210c0bdaac234/Moving-cast-shadow-detection-using-Physics-based-features.pdf,0,0,0
1278489,An HOG-LBP human detector with partial occlusion handling,2009,Xiaoyu Wang and Tony X Han and Shuicheng Yan,,,,32-39,IEEE,By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set. we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors. i.e.. global detector for whole scanning windows and part detectors for local regions. are learned from the training data using linear SVM. For each ambiguous scanning window. we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window. part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the …,True,MliblMQAAAAJ:u5HHmVD_uO8C,2038,https://ieeexplore.ieee.org/abstract/document/5459207/,17538862825074055756,/scholar?cites=17538862825074055756,,,https://www.researchgate.net/profile/Tony_Han3/publication/224135946_An_HOG-LBP_human_detector_with_partial_occlusion_handling/links/0046351affdef73b37000000.pdf,0,0,0
1278490,Deep speech 2: End-to-end speech recognition in english and mandarin,2016,Dario Amodei and Sundaram Ananthanarayanan and Rishita Anubhai and Jingliang Bai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Qiang Cheng and Guoliang Chen and Jie Chen and Jingdong Chen and Zhijie Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Ke Ding and Niandong Du and Erich Elsen and Jesse Engel and Weiwei Fang and Linxi Fan and Christopher Fougner and Liang Gao and Caixia Gong and Awni Hannun and Tony Han and Lappi Johannes and Bing Jiang and Cai Ju and Billy Jun and Patrick LeGresley and Libby Lin and Junjie Liu and Yang Liu and Weigao Li and Xiangang Li and Dongpeng Ma and Sharan Narang and Andrew Ng and Sherjil Ozair and Yiping Peng and Ryan Prenger and Sheng Qian and Zongfeng Quan and Jonathan Raiman and Vinay Rao and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Kavya Srinet and Anuroop Sriram and Haiyuan Tang and Liliang Tang and Chong Wang and Jidong Wang and Kaifu Wang and Yi Wang and Zhijian Wang and Zhiqian Wang and Shuang Wu and Likai Wei and Bo Xiao and Wen Xie and Yan Xie and Dani Yogatama and Bin Yuan and Jun Zhan and Zhenyao Zhu,,,,173-182,PMLR,We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks. end-to-end learning allows us to handle a diverse variety of speech including noisy environments. accents and different languages. Key to our approach is our application of HPC techniques. enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result. in several cases. our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally. using a technique called Batch Dispatch with GPUs in the data center. we show that our system can be inexpensively deployed in an online setting. delivering low latency when serving users at scale.,True,MliblMQAAAAJ:HoB7MX3m0LUC,2028,http://proceedings.mlr.press/v48/amodei16.html,16030706496972570658,/scholar?cites=16030706496972570658,,,http://proceedings.mlr.press/v48/amodei16.html,0,0,0
1278491,Learning efficient object detection models with knowledge distillation,2017,Guobin Chen and Wongun Choi and Xiang Yu and Tony Han and Manmohan Chandraker,,,,742-751,,Despite significant accuracy improvement in convolutional neural networks (CNN) based object detectors. they often require prohibitive runtimes to process an image for real-time applications. State-of-the-art models often use very deep networks with a large number of floating point operations. Efforts such as model compression learn compact models with fewer number of parameters. but with much reduced accuracy. In this work. we propose a new framework to learn compact and fast object detection networks with improved accuracy using knowledge distillation [20] and hint learning [34]. Although knowledge distillation has demonstrated excellent improvements for simpler classification setups. the complexity of detection poses new challenges in the form of regression. region proposals and less voluminous labels. We address this through several innovations such as a weighted cross-entropy loss to address class imbalance. a teacher bounded loss to handle the regression component and adaptation layers to better learn from intermediate teacher distributions. We conduct comprehensive empirical evaluation with different distillation configurations over multiple datasets including PASCAL. KITTI. ILSVRC and MS-COCO. Our results show consistent improvement in accuracy-speed trade-offs for modern multi-class detection models.,True,MliblMQAAAAJ:xtRiw3GOFMkC,318,http://cseweb.ucsd.edu/~mkchandraker/pdf/nips17_distillationdetection.pdf,9704115036838184098,/scholar?cites=9704115036838184098,,,http://cseweb.ucsd.edu/~mkchandraker/pdf/nips17_distillationdetection.pdf,0,0,0
1278492,Histogram of oriented normal vectors for object recognition with a depth sensor,2012,Shuai Tang and Xiaoyu Wang and Xutao Lv and Tony X Han and James Keller and Zhihai He and Marjorie Skubic and Shihong Lao,,,,525-538,Springer. Berlin. Heidelberg,We propose a feature. the Histogram of Oriented Normal Vectors  (HONV). designed specifically to capture local geometric characteristics for object recognition with a depth sensor. Through our derivation. the normal vector orientation represented as an ordered pair of azimuthal angle and zenith angle can be easily computed from the gradients of the depth image. We form the HONV as a concatenation of local histograms of azimuthal angle and zenith angle. Since the HONV is inherently the local distribution of the tangent plane orientation of an object surface. we use it as a feature for object detection/classification tasks. The object detection experiments on the standard RGB-D dataset [1] and a self-collected Chair-D dataset show that the HONV significantly outperforms traditional features such as HOG on the depth image and HOG on the intensity image. with an improvement of 11.6% in average precision …,True,MliblMQAAAAJ:-f6ydRqryjwC,236,https://link.springer.com/chapter/10.1007/978-3-642-37444-9_41,6507907726380111203,/scholar?cites=6507907726380111203,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.309.2776&rep=rep1&type=pdf,0,0,0
1278493,Contextual Weighting for Vocabulary Tree based Image Retrieval,2011,Xiaoyu Wang and Ming Yang and Timothee Cour and Shenghuo Zhu and Kai Yu and Tony X Han,,,,,,In this paper we address the problem of image retrieval from millions of database images. We improve the vocabulary tree based approach by introducing contextual weighting of local features in both descriptor and spatial domains. Specifically. we propose to incorporate efficient statistics of neighbor descriptors both on the vocabulary tree and in the image spatial domain into the retrieval. These contextual cues substantially enhance the discriminative power of individual local features with very small computational overhead. We have conducted extensive experiments on benchmark datasets. i.e.. the UKbench. Holidays. and our new Mobile dataset. which show that our method reaches state-of-the-art performance with much less computation. Furthermore. the proposed method demonstrates excellent scalability in terms of both retrieval accuracy and efficiency on large-scale experiments using 1.26 million images …,True,MliblMQAAAAJ:_FxGoFyzp5QC,233,https://ieeexplore.ieee.org/abstract/document/6126244/,6840720691785886705,/scholar?cites=6840720691785886705,,,http://www.timotheecour.com/papers/iccv_2011_retrieval.pdf,0,0,0
1278494,Residual networks of residual networks: Multilevel residual networks,2017,Ke Zhang and Miao Sun and Tony X Han and Xingfang Yuan and Liru Guo and Tao Liu,28,IEEE Transactions on Circuits and Systems for Video Technology,6,1303-1314,IEEE,A residual networks family with hundreds or even thousands of layers dominates major image recognition tasks. but building a network by simply stacking residual blocks inevitably limits its optimization ability. This paper proposes a novel residual network architecture. residual networks of residual networks (RoR). to dig the optimization ability of residual networks. RoR substitutes optimizing residual mapping of residual mapping for optimizing original residual mapping. In particular. RoR adds levelwise shortcut connections upon original residual networks to promote the learning capability of residual networks. More importantly. RoR can be applied to various kinds of residual networks (ResNets. Pre-ResNets. and WRN) and significantly boost their performance. Our experiments demonstrate the effectiveness and versatility of RoR. where it achieves the best performance in all residual-network-like structures. Our …,True,MliblMQAAAAJ:yD5IFk8b50cC,166,https://ieeexplore.ieee.org/abstract/document/7820046/,5511051778946176887,/scholar?cites=5511051778946176887,,,https://arxiv.org/pdf/1608.02908,0,0,0
1278495,Activity analysis. summarization. and visualization for indoor human activity monitoring,2008,Zhongna Zhou and Xi Chen and Yu-Chia Chung and Zhihai He and Tony X Han and James M Keller,18,IEEE transactions on circuits and systems for video technology,11,1489-1498,IEEE,In this work. we study how continuous video monitoring and intelligent video processing can be used in eldercare to assist the independent living of elders and to improve the efficiency of eldercare practice. More specifically. we develop an automated activity analysis and summarization for eldercare video monitoring. At the object level. we construct an advanced silhouette extraction. human detection and tracking algorithm for indoor environments. At the feature level. we develop an adaptive learning method to estimate the physical location and moving speed of a person from a single camera view without calibration. At the action level. we explore hierarchical decision tree and dimension reduction methods for human action recognition. We extract important ADL (activities of daily living) statistics for automated functional assessment. To test and evaluate the proposed algorithms and methods. we deploy the camera …,True,MliblMQAAAAJ:9yKSN-GCB0IC,156,https://ieeexplore.ieee.org/abstract/document/4633633/,5217798010118922783,/scholar?cites=5217798010118922783,,,https://mospace.umsystem.edu/xmlui/bitstream/handle/10355/9260/ActivityAnalysisHumanActivityMonitoring.pdf?sequence=1&origin=publication_detail,0,0,0
1278496,VACE multimodal meeting corpus,2005,Lei Chen and R Travis Rose and Ying Qiao and Irene Kimbara and Fey Parrill and Haleema Welji and Tony Xu Han and Jilin Tu and Zhongqiang Huang and Mary Harper and Francis Quek and Yingen Xiong and David McNeill and Ronald Tuttle and Thomas Huang,,,,40-51,Springer. Berlin. Heidelberg,In this paper. we report on the infrastructure we have developed to support our research on multimodal cues for understanding meetings. With our focus on multimodality. we investigate the interaction among speech. gesture. posture. and gaze in meetings. For this purpose. a high quality multimodal corpus is being produced.,True,MliblMQAAAAJ:u-x6o8ySG0sC,131,https://link.springer.com/chapter/10.1007/11677482_4,6818237363064660640,/scholar?cites=6818237363064660640,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.2887&rep=rep1&type=pdf,0,0,0
1278497,Deep convolutional neural network based species recognition for wild animal monitoring,2014,Guobin Chen and Tony X Han and Zhihai He and Roland Kays and Tavis Forrester,,,,858-862,IEEE,We proposed a novel deep convolutional neural network based species recognition algorithm for wild animal classification on very challenging camera-trap imagery data. The imagery data were captured with motion triggered camera trap and were segmented automatically using the state of the art graph-cut algorithm. The moving foreground is selected as the region of interests and is fed to the proposed species recognition algorithm. For the comparison purpose. we use the traditional bag of visual words model as the baseline species recognition algorithm. It is clear that the proposed deep convolutional neural network based species recognition achieves superior performance. To our best knowledge. this is the first attempt to the fully automatic computer vision based species recognition on the real camera-trap images. We also collected and annotated a standard camera-trap dataset of 20 species common in …,True,MliblMQAAAAJ:M05iB0D1s5AC,122,https://ieeexplore.ieee.org/abstract/document/7025172/,9296092158854265428,/scholar?cites=9296092158854265428,,,https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICIP-2014/Papers/1569901009.pdf,0,0,0
1278498,Discriminative tracking by metric learning,2010,Xiaoyu Wang and Gang Hua and Tony X Han,,,,200-214,Springer. Berlin. Heidelberg,We present a discriminative model that casts appearance modeling and visual matching into a single objective for visual tracking. Most previous discriminative models for visual tracking are formulated as supervised learning of binary classifiers. The continuous output of the classification function is then utilized as the cost function for visual tracking. This may be less desirable since the function is optimized for making binary decision. Such a learning objective may make it not to be able to well capture the manifold structure of the discriminative appearances. In contrast. our unified formulation is based on a principled metric learning framework. which seeks for a discriminative embedding for appearance modeling. In our formulation. both appearance modeling and visual matching are performed online by efficient gradient based optimization. Our formulation is also able to deal with multiple targets. where the …,True,MliblMQAAAAJ:IjCSPb-OGe4C,118,https://link.springer.com/chapter/10.1007/978-3-642-15558-1_15,8771141327812445237,/scholar?cites=8771141327812445237,,,https://link.springer.com/content/pdf/10.1007/978-3-642-15558-1_15.pdf,0,0,0
1278499,Detection evolution with multi-order contextual co-occurrence,2013,Guang Chen and Yuanyuan Ding and Jing Xiao and Tony X Han,,,,1798-1805,,Context has been playing an increasingly important role to improve the object detection performance. In this paper we propose an effective representation. Multi-Order Contextual co-Occurrence (MOCO). to implicitly model the high level context using solely detection responses from a baseline object detector. The so-called (1 st-order) context feature is computed as a set of randomized binary comparisons on the response map of the baseline object detector. The statistics of the 1 st-order binary context features are further calculated to construct a high order co-occurrence descriptor. Combining the MOCO feature with the original image feature. we can evolve the baseline object detector to a stronger context aware detector. With the updated detector. we can continue the evolution till the contextual improvements saturate. Using the successful deformable-partmodel detector [13] as the baseline detector. we test the proposed MOCO evolution framework on the PASCAL VOC 2007 dataset [8] and Caltech pedestrian dataset [7]: The proposed MOCO detector outperforms all known state-ofthe-art approaches. contextually boosting deformable part models (ver. 5)[13] by 3.3% in mean average precision on the PASCAL 2007 dataset. For the Caltech pedestrian dataset. our method further reduces the log-average miss rate from 48% to 46% and the miss rate at 1 FPPI from 2atfto m44%% compared with the best prior art [6].,True,MliblMQAAAAJ:M3NEmzRMIkIC,114,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Chen_Detection_Evolution_with_2013_CVPR_paper.html,15610313479683590938,/scholar?cites=15610313479683590938,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Chen_Detection_Evolution_with_2013_CVPR_paper.pdf,0,0,0
1278500,Face detection using quantized skin color regions merging and wavelet packet analysis,1999,Christophe Garcia and George Tziritas,1,IEEE Transactions on multimedia,3,264-277,IEEE,Detecting and recognizing human faces automatically in digital images strongly enhance content-based video indexing systems. In this paper. a novel scheme for human faces detection in color images under nonconstrained scene conditions. such as the presence of a complex background and uncontrolled illumination. is presented. Color clustering and filtering using approximations of the YCbCr and HSV skin color subspaces are applied on the original image. providing quantized skin color regions. A merging stage is then iteratively performed on the set of homogeneous skin color regions in the color quantized image. in order to provide a set of potential face areas. Constraints related to shape and size of faces are applied. and face intensity texture is analyzed by performing a wavelet packet decomposition on each face area candidate in order to detect human faces. The wavelet coefficients of the band filtered …,True,mIh2JWAAAAAJ:vV6vV6tmYwMC,972,https://ieeexplore.ieee.org/abstract/document/784465/,3178573670896004456,/scholar?cites=3178573670896004456,,,https://www.academia.edu/download/40016543/Face_Detection_Using_Quantized_Skin_Colo20151115-2213-8lj37a.pdf,0,0,0
1278501,Dense image registration through MRFs and efficient linear programming,2008,Ben Glocker and Nikos Komodakis and Georgios Tziritas and Nassir Navab and Nikos Paragios,12,Medical image analysis,6,731-741,Elsevier,In this paper. we introduce a novel and efficient approach to dense image registration. which does not require a derivative of the employed cost function. In such a context. the registration problem is formulated using a discrete Markov random field objective function. First. towards dimensionality reduction on the variables we assume that the dense deformation field can be expressed using a small number of control points (registration grid) and an interpolation strategy. Then. the registration cost is expressed using a discrete sum over image costs (using an arbitrary similarity measure) projected on the control points. and a smoothness term that penalizes local deviations on the deformation field according to a neighborhood system on the grid. Towards a discrete approach. the search space is quantized resulting in a fully discrete model. In order to account for large deformations and produce results on a high …,True,mIh2JWAAAAAJ:u5HHmVD_uO8C,507,https://www.sciencedirect.com/science/article/pii/S1361841508000297,15717885180139196933,/scholar?cites=15717885180139196933,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.414.6433&rep=rep1&type=pdf,0,0,0
1278502,Image completion using efficient belief propagation via priority scheduling and dynamic pruning,2007,Nikos Komodakis and Georgios Tziritas,16,IEEE Transactions on Image Processing,11,2649-2661,IEEE,In this paper. a new exemplar-based framework is presented. which treats image completion. texture synthesis. and image inpainting in a unified manner. In order to be able to avoid the occurrence of visually inconsistent results. we pose all of the above image-editing tasks in the form of a discrete global optimization problem. The objective function of this problem is always well-defined. and corresponds to the energy of a discrete Markov random field (MRF). For efficiently optimizing this MRF. a novel optimization scheme. called priority belief propagation (BP). is then proposed. which carries two very important extensions over the standard BP algorithm: ldquopriority-based message schedulingrdquo and ldquodynamic label pruning.rdquo These two extensions work in cooperation to deal with the intolerable computational cost of BP. which is caused by the huge number of labels associated with our MRF. Moreover …,True,mIh2JWAAAAAJ:d1gkVwhDpl0C,437,https://ieeexplore.ieee.org/abstract/document/4337762/,18185849372554001714,/scholar?cites=18185849372554001714,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.1572&rep=rep1&type=pdf,0,0,0
1278503,MRF energy minimization and beyond via dual decomposition,2010,Nikos Komodakis and Nikos Paragios and Georgios Tziritas,33,IEEE transactions on pattern analysis and machine intelligence,3,531-552,IEEE,This paper introduces a new rigorous theoretical framework to address discrete MRF-based optimization in computer vision. Such a framework exploits the powerful technique of Dual Decomposition. It is based on a projected subgradient scheme that attempts to solve an MRF optimization problem by first decomposing it into a set of appropriately chosen subproblems. and then combining their solutions in a principled way. In order to determine the limits of this method. we analyze the conditions that these subproblems have to satisfy and demonstrate the extreme generality and flexibility of such an approach. We thus show that by appropriately choosing what subproblems to use. one can design novel and very powerful MRF optimization algorithms. For instance. in this manner we are able to derive algorithms that: 1) generalize and extend state-of-the-art message-passing methods. 2) optimize very tight LP …,True,mIh2JWAAAAAJ:IjCSPb-OGe4C,394,https://ieeexplore.ieee.org/abstract/document/5467090/,12164590973835786554,/scholar?cites=12164590973835786554,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.301.9577&rep=rep1&type=pdf,0,0,0
1278504,MRF optimization via dual decomposition: Message-passing revisited,2007,Nikos Komodakis and Nikos Paragios and Georgios Tziritas,,,,1-8,IEEE,A new message-passing scheme for MRF optimization is proposed in this paper. This scheme inherits better theoretical properties than all other state-of-the-art message passing methods and in practice performs equally well/outperforms them. It is based on the very powerful technique of Dual Decomposition [1] and leads to an elegant and general framework for understanding/designing message-passing algorithms that can provide new insights into existing techniques. Promising experimental results and comparisons with the state of the art demonstrate the extreme theoretical and practical potentials of our approach.,True,mIh2JWAAAAAJ:u-x6o8ySG0sC,371,https://ieeexplore.ieee.org/abstract/document/4408890/,8210132904402487368,/scholar?cites=8210132904402487368,,,http://vision.mas.ecp.fr/pub/iccv07.pdf,0,0,0
1278505,Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: is the problem solved?,2018,Olivier Bernard and Alain Lalande and Clement Zotti and Frederick Cervenansky and Xin Yang and Pheng-Ann Heng and Irem Cetin and Karim Lekadir and Oscar Camara and Miguel Angel Gonzalez Ballester and Gerard Sanroma and Sandy Napel and Steffen Petersen and Georgios Tziritas and Elias Grinias and Mahendra Khened and Varghese Alex Kollerathu and Ganapathy Krishnamurthi and Marc-Michel Rohe and Xavier Pennec and Maxime Sermesant and Fabian Isensee and Paul Jäger and Klaus H Maier-Hein and Peter M Full and Ivo Wolf and Sandy Engelhardt and Christian F Baumgartner and Lisa M Koch and Jelmer M Wolterink and Ivana Išgum and Yeonggul Jang and Yoonmi Hong and Jay Patravali and Shubham Jain and Olivier Humbert and Pierre-Marc Jodoin,37,IEEE transactions on medical imaging,11,2514-2525,ieee,Delineation of the left ventricular cavity. myocardium. and right ventricle from cardiac magnetic resonance images (multi-slice 2-D cine MRI) is a common clinical task to establish diagnosis. The automation of the corresponding tasks has thus been the subject of intense research over the past decades. In this paper. we introduce the “Automatic Cardiac Diagnosis Challenge” dataset (ACDC). the largest publicly available and fully annotated dataset for the purpose of cardiac MRI (CMR) assessment. The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. The overarching objective of this paper is to measure how far state-of-the-art deep learning methods can go at assessing CMRI. i.e.. segmenting the myocardium and the two ventricles as well as classifying pathologies. In the wake of the 2017 MICCAI-ACDC challenge. we …,True,mIh2JWAAAAAJ:wbdj-CoPYUoC,359,https://ieeexplore.ieee.org/abstract/document/8360453/,13057687697158133435,/scholar?cites=13057687697158133435,,,https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/42264/Bernard%20et%20al_Deep%20learning%20techniques%20automatic%20MRI_2018_Accepted.pdf?sequence=1&isAllowed=y,0,0,0
1278506,Approximate labeling via graph cuts based on linear programming,2007,Nikos Komodakis and Georgios Tziritas,29,IEEE transactions on pattern analysis and machine intelligence,8,1436-1453,IEEE,A new framework is presented for both understanding and developing graph-cut-based combinatorial algorithms suitable for the approximate optimization of a very wide class of Markov random fields (MRFs) that are frequently encountered in computer vision. The proposed framework utilizes tools from the duality theory of linear programming in order to provide an alternative and more general view of state-of-the-art techniques like the alpha-expansion algorithm. which is included merely as a special case. Moreover. contrary to alpha-expansion. the derived algorithms generate solutions with guaranteed optimality properties for a much wider class of problems. for example. even for MRFs with nonmetric potentials. In addition. they are capable of providing per-instance suboptimality bounds in all occasions. including discrete MRFs with an arbitrary potential function. These bounds prove to be very tight in practice …,True,mIh2JWAAAAAJ:qjMakFHDy7sC,310,https://ieeexplore.ieee.org/abstract/document/4250468/,15059400648184693395,/scholar?cites=15059400648184693395,,,http://www.csd.uoc.gr/~tziritas/papers/PAMI-0681-0906.pdf,0,0,0
1278507,A speech/music discriminator based on RMS and zero-crossings,2005,Costas Panagiotakis and Georgios Tziritas,7,IEEE Transactions on multimedia,1,155-166,IEEE,Over the last several years. major efforts have been made to develop methods for extracting information from audiovisual media. in order that they may be stored and retrieved in databases automatically. based on their content. In this work we deal with the characterization of an audio signal. which may be part of a larger audiovisual system or may be autonomous. as for example in the case of an audio recording stored digitally on disk. Our goal was to first develop a system for segmentation of the audio signal. and then classification into one of two main categories: speech or music. Among the system's requirements are its processing speed and its ability to function in a real-time environment with a small responding delay. Because of the restriction to two classes. the characteristics that are extracted are considerably reduced and moreover the required computations are straightforward. Experimental results show …,True,mIh2JWAAAAAJ:2osOgNQ5qMEC,300,https://ieeexplore.ieee.org/abstract/document/1386250/,12713688812389522274,/scholar?cites=12713688812389522274,,,https://www.academia.edu/download/35350136/07tmm01-panagiotakis-proof.pdf,0,0,0
1278508,Fast. approximately optimal solutions for single and dynamic MRFs,2007,Nikos Komodakis and Georgios Tziritas and Nikos Paragios,,,,1-8,IEEE,A new efficient MRF optimization algorithm. called Fast-PD. is proposed. which generalizes α-expansion. One of its main advantages is that it offers a substantial speedup over that method. e.g. it can be at least 3-9 times faster than α-expansion. Its efficiency is a result of the fact that Fast-PD exploits information coming not only from the original MRF problem. but also from a dual problem. Furthermore. besides static MRFs. it can also be used for boosting the performance of dynamic MRFs. i.e. MRFs varying over time. On top of that. Fast-PD makes no compromise about the optimality of its solutions: it can compute exactly the same answer as a-expansion. but. unlike that method. it can also guarantee an almost optimal solution for a much wider class of NP-hard MRF problems. Results on static and dynamic MRFs demonstrate the algorithm's efficiency and power. E.g.. Fast-PD has been able to compute disparity for …,True,mIh2JWAAAAAJ:9yKSN-GCB0IC,266,https://ieeexplore.ieee.org/abstract/document/4270120/,3068507571327755125,/scholar?cites=3068507571327755125,,,http://www.csd.uoc.gr/~tziritas/papers/CVPR07_FastPD.pdf,0,0,0
1278509,Performance vs computational efficiency for optimizing single and dynamic MRFs: Setting the state of the art with primal-dual strategies,2008,Nikos Komodakis and Georgios Tziritas and Nikos Paragios,112,Computer Vision and Image Understanding,1,14-29,Academic Press,In this paper we introduce a novel method to address minimization of static and dynamic MRFs. Our approach is based on principles from linear programming and. in particular. on primal-dual strategies. It generalizes prior state-of-the-art methods such as α-expansion. while it can also be used for efficiently minimizing NP-hard problems with complex pair-wise potential functions. Furthermore. it offers a substantial speedup – of a magnitude 10 – over existing techniques. due to the fact that it exploits information coming not only from the original MRF problem. but also from a dual one. The proposed technique consists of recovering pair of solutions for the primal and the dual such that the gap between them is minimized. Therefore. it can also boost performance of dynamic MRFs. where one should expect that the new pair of primal-dual solutions is closed to the previous one. Promising results in a number of …,True,mIh2JWAAAAAJ:zYLM7Y9cAGgC,246,https://www.sciencedirect.com/science/article/pii/S1077314208000982,8722305367281079633,/scholar?cites=8722305367281079633,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.9138&rep=rep1&type=pdf,0,0,0
1278510,Color and texture image retrieval using chromaticity histograms and wavelet frames,2004,Spyros Liapis and Georgios Tziritas,6,IEEE Transactions on multimedia,5,676-686,IEEE,In this paper. we explore image retrieval mechanisms based on a combination of texture and color features. Texture features are extracted using Discrete Wavelet Frames (DWF) analysis. an over-complete decomposition in scale and orientation. Two-dimensional (2-D) or one-dimensional (1-D) histograms of the CIE Lab chromaticity coordinates are used as color features. The 1-D histograms of the a. b coordinates were modeled according to the generalized Gaussian distribution. The similarity measure defined on the feature distribution is based on the Bhattacharya distance. Retrieval benchmarking is performed over the Brodatz album and on images from natural scenes. obtained from the VisTex database of MIT Media Laboratory and from the Corel Photo Gallery. As a performance indicator recall (relative number of correct images retrieved) is measured on both texture and color separately and in combination …,True,mIh2JWAAAAAJ:UeHWp8X0CEIC,220,https://ieeexplore.ieee.org/abstract/document/1335475/,16651913870349295336,/scholar?cites=16651913870349295336,,,http://bit.csc.lsu.edu/~jianhua/murat.pdf,0,0,0
1278511,Measurement of pseudorapidity distributions of charged particles in proton–proton collisions at                                                        s                        =            8  TeV by …,2014,Serguei Chatrchyan and Vardan Khachatryan and Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and Thomas Bergauer and Marko Dragicevic and Janos Erö and Christian Fabjan and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Christian Hartl and Natascha Hörmann and Josef Hrubec and Manfred Jeitler and Wolfgang Kiesenhofer and Valentin Knünz and Manfred Krammer and Ilse Krätschmer and Dietrich Liko and Ivan Mikulec and Dinyar Rabady and Babak Rahbaran and Herbert Rohringer and Robert Schöfbeck and Josef Strauss and Anton Taurok and Wolfgang Treberer-Treberspurg and Wolfgang Waltenberger and C-E Wulz and Vladimir Mossolov and Nikolai Shumeiko and J Suarez Gonzalez and Sara Alderweireldt and Monika Bansal and Sunil Bansal and Tom Cornelis and Eddi A De Wolf and Xavier Janssen and Albert Knutsson and Sten Luyckx and Luca Mucibello and Silvia Ochesanu and Benoit Roland and Romain Rougny and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and Freya Blekman and Stijn Blyweert and Jorgen D’Hondt and Natalie Heracleous and Alexis Kalogeropoulos and James Keaveney and Tae Jeong Kim and Steven Lowette and Michael Maes and Annik Olbrechts and Derek Strom and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Gerrit Patrick Van Onsem and Ilaria Villella and Cécile Caillol and Barbara Clerbaux and Gilles De Lentdecker and Laurent Favart and APR Gay and Alexandre Léonard and Pierre Edouard Marage and Abdollah Mohammadi and Luca Perniè and Thomas Reis and Tomislav Seva and Laurent Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Leonardo Benucci and Anna Cimmino and Silvia Costantini and Sven Dildick and Guillaume Garcia and Benjamin Klein and Jeremie Lellouch and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and S Salva Diblen and Michael Sigamani and Nadja Strobbe and Filip Thyssen and Michael Tytgat and S Walsh and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and C Beluffi and G Bruno and R Castello and A Caudron and L Ceard and GG Da Silveira and C Delaere and T du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and P Jez and M Komm and V Lemaitre and J Liao and O Militaru and C Nuttens and D Pagano and A Pin and K Piotrzkowski and A Popov and L Quertenmont and M Selvaggi and M Vidal Marono and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins Junior and T Dos Reis Martins and ME Pol and MHG Souza and WL Aldá Júnior and W Carvalho and J Chinellato and A Custodio and EM Da Costa and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and H Malbouisson and M Malek and D Matos Figueiredo and L Mundim and H Nogima,74,The European Physical Journal C,10,1-26,Springer Berlin Heidelberg,Pseudorapidity () distributions of charged particles produced in proton–proton collisions at a centre-of-mass energy of 8 are measured in the ranges  and  covered by the CMS and TOTEM detectors. respectively. The data correspond to an integrated luminosity of  . Measurements are presented for three event categories. The most inclusive category is sensitive to 91–96 % of the total inelastic proton–proton cross section. The other two categories are disjoint subsets of the inclusive sample that are either enhanced or depleted in single diffractive dissociation events. The data are compared to models used to describe high-energy hadronic interactions. None of the models considered provide a consistent description of the measured distributions.,True,IqSr-PYAAAAJ:gKLIUvgTho8C,96,https://link.springer.com/article/10.1140/epjc/s10052-014-3053-6,3753374452424116133,/scholar?cites=3753374452424116133,,,https://link.springer.com/article/10.1140/epjc/s10052-014-3053-6,0,0,0
1278512,Smart garbage monitoring and clearance system using internet of things,2017,S Vinoth Kumar and T Senthil Kumaran and A Krishna Kumar and Mahantesh Mathapati,,,,184-189,IEEE,The increase in population. has led to tremendous degradation in the state of affairs of hygiene with respect to waste management system. The spillover of waste in civic areas generates the polluted condition in the neighboring areas. It may aggravate numerous severe diseases for the nearby people. This will humiliate the appraisal of the affected area. For eliminating or mitigating the garbage's and maintains the cleanness. it requires 'smartness based waste management system. This paper is proposed IOT based smart waste clean management system which checks the waste level over the dustbins by using Sensor systems. Once it detected immediately this system altered to concern authorized through GSM/GPRS. For this system used Microcontroller as an interface between the sensor system and GSM/GPRS system. To monitor and integrate an android application is developed for the desired information …,True,IqSr-PYAAAAJ:pzedKLaGEyUC,65,https://ieeexplore.ieee.org/abstract/document/8089148/,16266549924579839597,/scholar?cites=16266549924579839597,,,https://www.researchgate.net/profile/T_Senthilkumaran/publication/320743091_Smart_garbage_monitoring_and_clearance_system_using_internet_of_things/links/5ee90410a6fdcc73be809472/Smart-garbage-monitoring-and-clearance-system-using-internet-of-things.pdf,0,0,0
1278513,Micropropagation of Rosa damascena Mill. from mature bushes using thidiazuron,2001,Anil Kumar and Anil Sood and Uma Palni and Akshey Gupta and Lok Manlok Palni,76,The Journal of Horticultural Science and Biotechnology,1,30-34,Taylor & Francis,An efficient protocol for micropropagation of Rosa damascena Mill. has been established using single node segments from mature bushes. The effect of thidiazuron has been compared with that of N6-benzyladenine (BA) on in vitro shoot proliferation. The cultures initiated on medium supplemented with thidiazuron (TDZ) and/or cultured continuously on TDZ containing medium for 32–48 weeks exhibited considerably more shoot proliferation and growth during subsequent culture on a medium containing BA. Shoots induced on TDZ containing medium and then sub-cultured (8–12 times) on medium containing BA. attained the capacity to grow and proliferate on a medium free from plant growth regulators (PGR). Microshoots from TDZ induced cultures could be rooted easily on indole-3-butyric acid (IBA) supplemented medium. A short treatment with IBA (100 mM; 12 h) was found to be very effective for root induction …,True,IqSr-PYAAAAJ:qE25ZKhNtbAC,62,https://www.tandfonline.com/doi/abs/10.1080/14620316.2001.11511322,249420329677090626,/scholar?cites=249420329677090626,,,,0,0,0
1278514,Framework for investment decision-making under risk and uncertainty for infrastructure asset management,2004,Noppadol Piyatrapoomi and Arun Kumar and Sujeeva Setunge,8,,,199-214,Elsevier,A study has been conducted to investigate current practices on decision-making under risk and uncertainty for infrastructure project investments. It was found that many European countries including Australia. the U.K.. France. and Germany use scenarios for the investigation of the effects of risk and uncertainty of project investments. Different alternative scenarios are mostly considered during the economic cost-benefit analysis stage. For instance. the World Bank requires an analysis of risks in all project appraisals. Risk in economic evaluation needs to be addressed by calculating the sensitivity of the rate of return for a number of events.Risks and uncertainties of project developments arise from various sources of errors including data. model and forecasting errors. It was found that the most influential factors affecting risk and uncertainty resulted from forecasting errors. Data errors and model errors have trivial …,True,IqSr-PYAAAAJ:OxQqgzTNpSoC,57,https://www.sciencedirect.com/science/article/pii/S0739885904080102,1084620949587695394,/scholar?cites=1084620949587695394,,,https://eprints.qut.edu.au/27401/1/27401.pdf,0,0,0
1278515,Polycyclic aromatic hydrocarbons and their quinones modulate the metabolic profile and induce DNA damage in human alveolar and bronchiolar cells,2013,Deepak Gurbani and Santosh Kumar Bharti and Ashutosh Kumar and Alok K Pandey and Godson REE Ana and Ambrish Verma and Altaf Husain Khan and Devendra K Patel and MKR Mudiam and Swatantra K Jain and Raja Roy and Alok Dhawan,216,International journal of hygiene and environmental health,5,553-565,Urban & Fischer,The release of particulate pollutants into the air through burning of coal. crude oil. diesel. coal tar. etc. raises concerns of potential health hazards to the exposed human population. Polycyclic aromatic hydrocarbons (PAHs) are major toxic constituents of particulate matter (PM). which upon ingestion get metabolized to even more toxic metabolites such as quinones. The PAHs levels were assessed in both respirable particulate matter (RSPM. <10 μM size) and suspended particulate matter (SPM. >10 μM size) of urban ambient air (UAA) and that of major contributors viz. diesel exhaust particles (DEPs) and coal tar combustions emissions (CTCE). Seven US Environmental Protection Agency (USEPA) prioritized PAHs in RSPM and 10 in SPM were detected in UAA. Ten and 15 prioritized PAHs. respectively. were also detected in diesel exhaust particles (DEP) and coal tar combustion emission (CTCE) evidencing their …,True,IqSr-PYAAAAJ:vq25oHwZT-8C,55,https://www.sciencedirect.com/science/article/pii/S1438463913000552,2533457751674161038,/scholar?cites=2533457751674161038,,,https://www.academia.edu/download/32365395/Polycyclic_aromatic_hydrocarbons_and_their_quinones_modulate_the_metabolic_profile_and_induce_DNA_damage_in_human_alveolar_and_bronchiol.pdf,0,0,0
1278516,Search for narrow resonances in the b-tagged dijet mass spectrum in proton-proton collisions at  8 TeV,2018,CMS collaboration,,arXiv preprint arXiv:1802.06149,,,,A search for narrow resonances decaying to bottom quark-antiquark pairs is presented. using a data sample of proton-proton collisions at 8 TeV corresponding to an integrated luminosity of 19.7 fb . The search is extended to masses lower than those reached in typical searches for resonances decaying into jet pairs at the LHC. by taking advantage of triggers that identify jets originating from bottom quarks. No significant excess of events is observed above the background predictions. Limits are set on the product of cross section and branching fraction to bottom quarks for spin 0. 1. and 2 resonances in the mass range of 325-1200 GeV. These results significantly improve on the limits for resonances decaying into jet pairs in the 325-500 GeV mass range.,True,IqSr-PYAAAAJ:sc_hyC0iex0C,49,https://arxiv.org/abs/1802.06149,17078135296193682945,/scholar?cites=17078135296193682945,,,https://arxiv.org/pdf/1802.06149,0,0,0
1278517,Practical handbook of pharmacognosy: preliminary techniques of identification of crude drugs of plant origin,2001,Christophe Wiart and Ashok Kumar,,,,,Pearson Education Malaysia,,True,IqSr-PYAAAAJ:YFIp4goXIpYC,49,http://www.agris.upm.edu.my:8080/dspace/handle/0/13478,5375889151134660875,/scholar?cites=5375889151134660875,,,,0,0,0
1278518,Knowledge and practice of primary school teachers about first aid management of selected minor injuries among children,2014,Shobha Masih and Rajesh Kumar Sharma and Atul Kumar,4,International Journal of Medicine and Public Health,4,,,Introduction: Children spend most of the time in school where they are exposed to various types of minor injuries. which influence their present and future state of health. First aid is the treatment of any injury or illness before availability of professional medical aid. Teacher is the key person who can attend the children for minor injuries in school through complete knowledge regarding first aid management. This study was done among primary school teachers to evaluate the effectiveness of teaching program on knowledge and practice regarding first aid management of selected minor injuries in children. Materials and Methods: A Quasi-experimental study with one group pre-and post-test research design was conducted among the primary school teachers of Dehradun district of Uttarakhand. Fifty primary school teachers were selected by nonprobability convenient sampling. Data were collected by knowledge questionnaire (maximum possible score 42) and self-reporting checklist (maximum possible score 23). Result: Majority (94%) of the teachers were female. Paired sample t-test revealed that the mean posttest knowledge score regarding first aid management of selected minor injuries was significantly higher (34.76±4.35) than that of mean pretest knowledge score (27.32±5.73)(P< 0.005); mean posttest practice score was significantly higher (18.52±2.63) then mean pretest practice score (14.52±2.39)(P< 0.005). There was a significant positive correlation between knowledge score and practice score of participants (r= 0.9; P< 0.001). Conclusion: This concludes that the training program was effective in significant improvement of knowledge and …,True,IqSr-PYAAAAJ:HaiYZdWvYCYC,48,http://www.ijmedph.org/article/368?qt-sidebar_tabs=0,11995181197082499700,/scholar?cites=11995181197082499700,,,http://www.ijmedph.org/sites/default/files/IntJMedPublicHealth_2014_4_4_458_144114.pdf,0,0,0
1278519,Solution of matrix Riccati differential equation for the linear quadratic singular system using neural networks,2006,P Balasubramaniam and J Abdul Samath and N Kumaresan and A Vincent Antony Kumar,182,Applied Mathematics and Computation,2,1832-1839,Elsevier,In this paper. the solution of the matrix Riccati differential equation (MRDE) for the linear quadratic singular system is obtained using neural networks. The goal is to provide optimal control with reduced calculus effort by comparing the solutions of the MRDE obtained from well-known traditional methods like Runge–Kutta. Runge–Kutta Butcher and non-traditional method neural network. The neural training is performed using Levenberg–Marquardt algorithm. Accuracy of the solution of the neural network approach to the problem is qualitatively better. The advantage of the proposed approach is that. once the network is trained. it allows instantaneous evaluation of solution at any desired number of points spending negligible computing time and memory. An illustrative numerical example for the proposed method is given.,True,IqSr-PYAAAAJ:roLk4NBRz8UC,44,https://www.sciencedirect.com/science/article/pii/S0096300306005327,10289595441732991868,/scholar?cites=10289595441732991868,,,,0,0,0
1278520,Control of nonlinear differential algebraic equation systems: an overview,1998,Aditya Kumar and Prodromos Daoutidis,,,,311-344,Springer. Dordrecht,Chemical processes are inherently nonlinear and their dynamics are naturally described by systems of coupled differential and algebraic equations (DAEs); the differential equations arise from the standard dynamic balances of mass. energy and momentum. while the algebraic equations typically include thermodynamic relations. empirical correlations. quasi-steady-state relations etc. In many cases. the algebraic equations in the DAE model can be readily eliminated to obtain an equivalent ordinary differential equation (ODE) model. which can be used as the basis for controller design. On the other hand. there is a broad class of chemical processes for which the algebraic equations in the DAE models are “singular” in nature. and thus. inhibit a direct reduction of the DAE model into an ODE system. Such DAE systems with singular algebraic equations are said to have a high “index” and they are …,True,IqSr-PYAAAAJ:COU-sansr_wC,39,https://link.springer.com/chapter/10.1007/978-94-011-5094-1_11,10027270301155083897,/scholar?cites=10027270301155083897,,,,0,0,0
1278521,STAT-1 mediates the stimulatory effect of IL-10 on CD14 expression in human monocytic cells,2005,Ali Akbar Rahim Rahimi and Katrina Gee and Sasmita Mishra and Wilfred Lim and Ashok Kumar,174,The Journal of Immunology,12,7823-7832,American Association of Immunologists,IL-10. an anti-inflammatory cytokine. has been shown to exhibit stimulatory functions including CD14 up-regulation on human monocytic cells. CD14-mediated signaling following LPS stimulation of monocytic cells results in the synthesis of proinflammatory cytokines. Our results show that LPS-induced CD14 expression on monocytic cells may be mediated by endogenously produced IL-10. To investigate the molecular mechanism by which IL-10 enhances CD14 expression. both human monocytes and the promyelocytic HL-60 cells were used as model systems. IL-10 induced the phosphorylation of PI3K and p42/44 ERK MAPK. By using specific inhibitors for PI3K (LY294002) and ERK MAPKs (PD98059). we demonstrate that LY294002 either alone or in conjunction with PD98059 inhibited IL-10-induced phosphorylation of STAT-1 and consequently CD14 expression. However. IL-10-induced STAT-3 …,True,IqSr-PYAAAAJ:cOP-uZQ6k_YC,37,https://www.jimmunol.org/content/174/12/7823.short,14804553731228176922,/scholar?cites=14804553731228176922,,,https://www.jimmunol.org/content/jimmunol/174/12/7823.full.pdf,0,0,0
1278522,Robust recovery of subspace structures by low-rank representation,2012,Guangcan Liu and Zhouchen Lin and Shuicheng Yan and Ju Sun and Yong Yu and Yi Ma,35,IEEE transactions on pattern analysis and machine intelligence,1,171-184,IEEE,In this paper. we address the subspace clustering problem. Given a set of data samples (vectors) approximately drawn from a union of multiple subspaces. our goal is to cluster the samples into their respective subspaces and remove possible outliers as well. To this end. we propose a novel objective function named Low-Rank Representation (LRR). which seeks the lowest rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary. It is shown that the convex program associated with LRR solves the subspace clustering problem in the following sense: When the data is clean. we prove that LRR exactly recovers the true subspace structures; when the data are contaminated by outliers. we prove that under certain conditions LRR can exactly recover the row space of the original data and detect the outlier as well; for data corrupted by …,True,JIfH-5IAAAAJ:HDshCWvjkbEC,2408,https://ieeexplore.ieee.org/abstract/document/6180173/,16351355550693852272,/scholar?cites=16351355550693852272,,,https://arxiv.org/pdf/1010.2955,0,0,0
1278523,Robust subspace segmentation by low-rank representation.,2010,Guangcan Liu and Zhouchen Lin and Yong Yu,1,Icml,,8,,We propose low-rank representation (LRR) to segment data drawn from a union of multiple linear (or affine) subspaces. Given a set of data vectors. LRR seeks the lowestrank representation among all the candidates that represent all vectors as the linear combination of the bases in a dictionary. Unlike the well-known sparse representation (SR). which computes the sparsest representation of each data vector individually. LRR aims at finding the lowest-rank representation of a collection of vectors jointly. LRR better captures the global structure of data. giving a more effective tool for robust subspace segmentation from corrupted data. Both theoretical and experimental results show that LRR is a promising tool for subspace segmentation.,True,JIfH-5IAAAAJ:Zph67rFs4hoC,1515,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.8022&rep=rep1&type=pdf,7596755873079611319,/scholar?cites=7596755873079611319,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.187.8022&rep=rep1&type=pdf,0,0,0
1278524,Latent low-rank representation for subspace segmentation and feature extraction,2011,Guangcan Liu and Shuicheng Yan,,,,1615-1622,IEEE,Low-Rank Representation (LRR) [16. 17] is an effective method for exploring the multiple subspace structures of data. Usually. the observed data matrix itself is chosen as the dictionary. which is a key aspect of LRR. However. such a strategy may depress the performance. especially when the observations are insufficient and/or grossly corrupted. In this paper we therefore propose to construct the dictionary by using both observed and unobserved. hidden data. We show that the effects of the hidden data can be approximately recovered by solving a nuclear norm minimization problem. which is convex and can be solved efficiently. The formulation of the proposed method. called Latent Low-Rank Representation (LatLRR). seamlessly integrates subspace segmentation and feature extraction into a unified framework. and thus provides us with a solution for both subspace segmentation and feature extraction. As a …,True,JIfH-5IAAAAJ:M3ejUd6NZC8C,503,https://ieeexplore.ieee.org/abstract/document/6126422/,15520735657280080378,/scholar?cites=15520735657280080378,,,http://www2.egr.uh.edu/~zhan2/ECE6111/class/Latent%20Low-Rank%20Representation%20for%20Subspace%20Segmentationpdf.pdf,0,0,0
1278525,Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set,2012,Si Liu and Zheng Song and Guangcan Liu and Changsheng Xu and Hanqing Lu and Shuicheng Yan,,,,3330-3337,IEEE,In this paper. we address a practical problem of cross-scenario clothing retrieval - given a daily human photo captured in general environment. e.g.. on street. finding similar clothing in online shops. where the photos are captured more professionally and with clean background. There are large discrepancies between daily photo scenario and online shopping scenario. We first propose to alleviate the human pose discrepancy by locating 30 human parts detected by a well trained human detector. Then. founded on part features. we propose a two-step calculation to obtain more reliable one-to-many similarities between the query daily photo and online shopping photos: 1) the within-scenario one-to-many similarities between a query daily photo and the auxiliary set are derived by direct sparse reconstruction; and 2) by a cross-scenario many-to-many similarity transfer matrix inferred offline from an extra auxiliary set …,True,JIfH-5IAAAAJ:TQgYirikUcIC,377,https://ieeexplore.ieee.org/abstract/document/6248071/,1896730847529769312,/scholar?cites=1896730847529769312,,,http://www.nlpr.ia.ac.cn/2012papers/gjhy/gh94.pdf,0,0,0
1278526,Multi-task low-rank affinity pursuit for image segmentation,2011,Bin Cheng and Guangcan Liu and Jingdong Wang and Zhongyang Huang and Shuicheng Yan,,,,2439-2446,IEEE,This paper investigates how to boost region-based image segmentation by pursuing a new solution to fuse multiple types of image features. A collaborative image segmentation framework. called multi-task low-rank affinity pursuit. is presented for such a purpose. Given an image described with multiple types of features. we aim at inferring a unified affinity matrix that implicitly encodes the segmentation of the image. This is achieved by seeking the sparsity-consistent low-rank affinities from the joint decompositions of multiple feature matrices into pairs of sparse and low-rank matrices. the latter of which is expressed as the production of the image feature matrix and its corresponding image affinity matrix. The inference process is formulated as a constrained nuclear norm and ℓ 2;1 -norm minimization problem. which is convex and can be solved efficiently with the Augmented Lagrange Multiplier method. Compared to …,True,JIfH-5IAAAAJ:Wp0gIr-vW9MC,223,https://ieeexplore.ieee.org/abstract/document/6126528/,3901060521026750436,/scholar?cites=3901060521026750436,,,http://people.eecs.berkeley.edu/~yima/matrix-rank/Files/Multi_task.pdf,0,0,0
1278527,Low-rank tensor constrained multiview subspace clustering,2015,Changqing Zhang and Huazhu Fu and Si Liu and Guangcan Liu and Xiaochun Cao,,,,1582-1590,,In this paper. we explore the problem of multiview subspace clustering. We introduce a low-rank tensor constraint to explore the complementary information from multiple views and. accordingly. establish a novel method called Low-rank Tensor constrained Multiview Subspace Clustering (LT-MSC). Our method regards the subspace representation matrices of different views as a tensor. which captures dexterously the high order correlations underlying multiview data. Then the tensor is equipped with a low-rank constraint. which models elegantly the cross information among different views. reduces effectually the redundancy of the learned subspace representations. and improves the accuracy of clustering as well. The inference process of the affinity matrix for clustering is formulated as a tensor nuclear norm minimization problem. constrained with an additional L2. 1-norm regularizer and some linear equalities. The minimization problem is convex and thus can be solved efficiently by an Augmented Lagrangian Alternating Direction Minimization (AL-ADM) method. Extensive experimental results on four benchmark datasets show the effectiveness of our proposed LT-MSC method.,True,JIfH-5IAAAAJ:_Ybze24A_UAC,211,http://openaccess.thecvf.com/content_iccv_2015/html/Zhang_Low-Rank_Tensor_Constrained_ICCV_2015_paper.html,5951113005512544590,/scholar?cites=5951113005512544590,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Zhang_Low-Rank_Tensor_Constrained_ICCV_2015_paper.pdf,0,0,0
1278528,Saliency detection by multitask sparsity pursuit,2011,Congyan Lang and Guangcan Liu and Jian Yu and Shuicheng Yan,21,IEEE transactions on image processing,3,1327-1338,IEEE,This paper addresses the problem of detecting salient areas within natural images. We shall mainly study the problem under unsupervised setting. i.e.. saliency detection without learning from labeled images. A solution of multitask sparsity pursuit is proposed to integrate multiple types of features for detecting saliency collaboratively. Given an image described by multiple features. its saliency map is inferred by seeking the consistently sparse elements from the joint decompositions of multiple-feature matrices into pairs of low-rank and sparse matrices. The inference process is formulated as a constrained nuclear norm and as an ℓ 2.1  -norm minimization problem. which is convex and can be solved efficiently with an augmented Lagrange multiplier method. Compared with previous methods. which usually make use of multiple features by combining the saliency maps obtained from individual features. the proposed …,True,JIfH-5IAAAAJ:qxL8FJ1GzNcC,210,https://ieeexplore.ieee.org/abstract/document/6026238/,5889001495547904438,/scholar?cites=5889001495547904438,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.653.1893&rep=rep1&type=pdf,0,0,0
1278529,Practical low-rank matrix approximation under robust L< inf> 1</inf>-norm,2012,Yinqiang Zheng and Guangcan Liu and Shigeki Sugimoto and Shuicheng Yan and Masatoshi Okutomi,,,,1410-1417,IEEE,A great variety of computer vision tasks. such as rigid/nonrigid structure from motion and photometric stereo. can be unified into the problem of approximating a low-rank data matrix in the presence of missing data and outliers. To improve robustness. the L 1 -norm measurement has long been recommended. Unfortunately. existing methods usually fail to minimize the L 1 -based nonconvex objective function sufficiently. In this work. we propose to add a convex trace-norm regularization term to improve convergence. without introducing too much heterogenous information. We also customize a scalable first-order optimization algorithm to solve the regularized formulation on the basis of the augmented Lagrange multiplier (ALM) method. Extensive experimental results verify that our regularized formulation is reasonable. and the solving algorithm is very efficient. insensitive to initialization and robust to high percentage …,True,JIfH-5IAAAAJ:_Qo2XoVZTnwC,187,https://ieeexplore.ieee.org/abstract/document/6247828/,14837485141689038591,/scholar?cites=14837485141689038591,,,https://www.researchgate.net/profile/Mohamed_Mourad_Lafifi/post/How_to_solve_L1_optimization_of_Low-Rank_matrix/attachment/5a4cfaaa4cde266d587fc182/AS%3A578741827260416%401514994212947/download/Practical+Low-Rank+Matrix+Approximation+under+Robust+L1-Norm.pdf,0,0,0
1278530,Inductive robust principal component analysis,2012,Bing-Kun Bao and Guangcan Liu and Changsheng Xu and Shuicheng Yan,21,IEEE transactions on image processing,8,3794-3800,IEEE,In this paper. we address the error correction problem. that is. to uncover the low-dimensional subspace structure from high-dimensional observations. which are possibly corrupted by errors. When the errors are of Gaussian distribution. principal component analysis (PCA) can find the optimal (in terms of least-square error) low-rank approximation to high-dimensional data. However. the canonical PCA method is known to be extremely fragile to the presence of gross corruptions. Recently. Wright established a so-called robust principal component analysis (RPCA) method. which can well handle the grossly corrupted data. However. RPCA is a transductive method and does not handle well the new samples. which are not involved in the training procedure. Given a new datum. RPCA essentially needs to recalculate over all the data. resulting in high computational cost. So. RPCA is inappropriate for the applications …,True,JIfH-5IAAAAJ:-f6ydRqryjwC,151,https://ieeexplore.ieee.org/abstract/document/6177256/,10690197981269187347,/scholar?cites=10690197981269187347,,,http://www.nlpr.ia.ac.cn/2012papers/gjkw/gk53.pdf,0,0,0
1278531,Active subspace: Toward scalable low-rank learning,2012,Guangcan Liu and Shuicheng Yan,24,Neural computation,12,3371-3394,MIT Press,We address the scalability issues in low-rank matrix learning problems. Usually these problems resort to solving nuclear norm regularized optimization problems (NNROPs). which often suffer from high computational complexities if based on existing solvers. especially in large-scale settings. Based on the fact that the optimal solution matrix to an NNROP is often low rank. we revisit the classic mechanism of low-rank matrix factorization. based on which we present an active subspace algorithm for efficiently solving NNROPs by transforming large-scale NNROPs into small-scale problems. The transformation is achieved by factorizing the large solution matrix into the product of a small orthonormal matrix (active subspace) and another small matrix. Although such a transformation generally leads to nonconvex problems. we show that a suboptimal solution can be found by the augmented Lagrange alternating direction …,True,JIfH-5IAAAAJ:R3hNpaxXUhUC,86,https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00369,7724072211278052733,/scholar?cites=7724072211278052733,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.998.3244&rep=rep1&type=pdf,0,0,0
1278532,Exact subspace segmentation and outlier detection by low-rank representation,2012,Guangcan Liu and Huan Xu and Shuicheng Yan,,,,703-711,PMLR,In this work. we address the following matrix recovery problem: suppose we are given a set of data points containing two parts. one part consists of samples drawn from a union of multiple subspaces and the other part consists of outliers. We do not know which data points are outliers. or how many outliers there are. The rank and number of the subspaces are unknown either. Can we detect the outliers and segment the samples into their right subspaces. efficiently and exactly? We utilize a so-called Low-Rank Representation (LRR) method to solve this problem. and prove that under mild technical conditions. any solution to LRR exactly recover the row space of the samples and detect the outliers as well. Since the subspace membership is provably determined by the row space. this further implies that LRR can perform exact subspace segmentation and outlier detection. in an efficient way.,True,JIfH-5IAAAAJ:4DMP91E08xMC,80,http://proceedings.mlr.press/v22/liu12a.html,6667781767921740187,/scholar?cites=6667781767921740187,,,http://proceedings.mlr.press/v22/liu12a/liu12a.pdf,0,0,0
1278533,GSA: a gravitational search algorithm,2009,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,179,Information sciences,13,2232-2248,Elsevier,In recent years. various heuristic optimization methods have been developed. Many of these methods are inspired by swarm behaviors in nature. In this paper. a new optimization algorithm based on the law of gravity and mass interactions is introduced. In the proposed algorithm. the searcher agents are a collection of masses which interact with each other based on the Newtonian gravity and the laws of motion. The proposed method has been compared with some well-known heuristic search methods. The obtained results confirm the high performance of the proposed method in solving various nonlinear functions.,True,c-DE4bwAAAAJ:u5HHmVD_uO8C,4942,https://www.sciencedirect.com/science/article/pii/S0020025509001200,2991100904893275403,/scholar?cites=2991100904893275403,,,http://matlabtools.com/wp-content/uploads/p717.pdf,0,0,0
1278534,BGSA: binary gravitational search algorithm,2010,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,9,Natural Computing,3,727-745,Springer Netherlands,Gravitational search algorithm is one of the new optimization algorithms that is based on the law of gravity and mass interactions. In this algorithm. the searcher agents are a collection of masses. and their interactions are based on the Newtonian laws of gravity and motion. In this article. a binary version of the algorithm is introduced. To evaluate the performances of the proposed algorithm. several experiments are performed. The experimental results confirm the efficiency of the BGSA in solving various nonlinear benchmark functions.,True,c-DE4bwAAAAJ:d1gkVwhDpl0C,652,https://link.springer.com/content/pdf/10.1007/s11047-009-9175-3.pdf,1180170859742867676,/scholar?cites=1180170859742867676,,,https://www.researchgate.net/profile/Hossein_Nezamabadi-pour/publication/220132723_BGSA_Binary_gravitational_search_algorithm/links/54ce41360cf24601c090242f.pdf,0,0,0
1278535,Filter modeling using gravitational search algorithm,2011,Esmat Rashedi and Hossien Nezamabadi-Pour and Saeid Saryazdi,24,Engineering Applications of Artificial Intelligence,1,117-122,Pergamon,This paper is devoted to the presentation of a new linear and nonlinear filter modeling based on a gravitational search algorithm (GSA). To do this. unknown filter parameters are considered as a vector to be optimized. Examples of infinite impulse response (IIR) filter design. as well as rational nonlinear filter. are given. To verify the effectiveness of the proposed GSA based filter modeling. different sets of initial population with the presence of different measurable noises are given and tested in simulations. Genetic algorithm (GA) and particle swarm optimization (PSO) are also used to model the same examples and some simulation results are compared. Obtained results confirm the efficiency of the proposed method.,True,c-DE4bwAAAAJ:9yKSN-GCB0IC,390,https://www.sciencedirect.com/science/article/pii/S0952197610001120,712081725521365890,/scholar?cites=712081725521365890,,,,0,0,0
1278536,Edge detection using ant algorithms,2006,Hossein Nezamabadi-Pour and Saeid Saryazdi and Esmat Rashedi,10,Soft Computing,7,623-628,Springer-Verlag,In this paper a new algorithm for edge detection using ant colony search is proposed. The problem is represented by a directed graph in which nodes are the pixels of an image. To adapt the problem. some modifications on original ant colony search algorithm (ACSA) are applied. A large number of experiments are employed to determine suitable algorithm parameters. We drive an experimental relationship between the size of the image to be analyzed and algorithm parameters. Several experiments are made and the results suggest the effectiveness of the proposed algorithm.,True,c-DE4bwAAAAJ:u-x6o8ySG0sC,238,https://link.springer.com/content/pdf/10.1007/s00500-005-0511-y.pdf,8735890167345426070,/scholar?cites=8735890167345426070,,,https://www.researchgate.net/profile/Esmat_Rashedi/publication/220176122_Edge_detection_using_ant_algorithms/links/5743d1ab08ae9ace841b4063.pdf,0,0,0
1278537,A simultaneous feature adaptation and feature selection method for content-based image retrieval systems,2013,Esmat Rashedi and Hossein Nezamabadi-Pour and Saeid Saryazdi,39,Knowledge-Based Systems,,85-94,Elsevier,In content-based image retrieval (CBIR) applications. each database needs its corresponding parameter setting for feature extraction. However. most of the CBIR systems perform indexing by a set of fixed and pre-specific parameters. On the other hand. feature selection methods have currently gained considerable popularity to reduce semantic gap. In this regard. this paper is devoted to present a hybrid approach to reduce the semantic gap between low level visual features and high level semantics. through simultaneous feature adaptation and feature selection. In the proposed approach. a hybrid meta-heuristic swarm intelligence-based search technique. called mixed gravitational search algorithm (MGSA). is employed. Some feature extraction parameters (i.e. the parameters of a 6-tap parameterized orthogonal mother wavelet in texture features and quantization levels in color histogram) are optimized to reach …,True,c-DE4bwAAAAJ:YsMSGLbcyi4C,131,https://www.sciencedirect.com/science/article/pii/S0950705112002924,7647600714460631897,/scholar?cites=7647600714460631897,,,,0,0,0
1278538,A comprehensive survey on gravitational search algorithm,2018,Esmat Rashedi and Elaheh Rashedi and Hossein Nezamabadi-pour,41,,,141-158,Elsevier,Gravitational Search Algorithm (GSA) is an optimization method inspired by the theory of Newtonian gravity in physics. Till now. many variants of GSA have been introduced. most of them are motivated by gravity-related theories such as relativity and astronomy. On the one hand. to solve different kinds of optimization problems. modified versions of GSA have been presented such as continuous (real). binary. discrete. multimodal. constraint. single-objective. and multi-objective GSA. On the other hand. to tackle the difficulties in real-world problems. the efficiency of GSA has been improved using specialized operators. hybridization. local search. and designing the self-adaptive algorithms. Researchers have utilized GSA to solve various engineering optimization problems in diverse fields of applications ranging from electrical engineering to bioinformatics. Here. we discussed a comprehensive investigation of GSA and …,True,c-DE4bwAAAAJ:TQgYirikUcIC,87,https://www.sciencedirect.com/science/article/pii/S2210650217303577,17159381500294473527,/scholar?cites=17159381500294473527,,,https://www.sciencedirect.com/science/article/am/pii/S2210650217303577,0,0,0
1278539,Prediction of maximum scour depth around piers with debris accumulation using EPR. MT. and GEP models,2016,Mohammad Najafzadeh and Mohammad Rezaie Balf and Esmat Rashedi,18,Journal of Hydroinformatics,5,867-884,IWA Publishing,Pier scour phenomena in the presence of debris accumulation have attracted the attention of engineers to present a precise prediction of the local scour depth. Most experimental studies of pier scour depth with debris accumulation have been performed to find an accurate formula to predict the local scour depth. However. an empirical equation with appropriate capacity of validation is not available to evaluate the local scour depth. In this way. gene-expression programming (GEP). evolutionary polynomial regression (EPR). and model tree (MT) based formulations are used to develop to predict the scour depth around bridge piers with debris effects. Laboratory data sets utilized to perform models are collected from different literature. Effective parameters on the local scour depth include geometric characterizations of bridge piers and debris. physical properties of bed sediment. and approaching flow characteristics …,True,c-DE4bwAAAAJ:9ZlFYXVOiuMC,80,https://iwaponline.com/jh/article-abstract/18/5/867/3583,49421255314426772,/scholar?cites=49421255314426772,,,https://iwa.silverchair.com/jh/article-pdf/18/5/867/390550/jh0180867.pdf,0,0,0
1278540,Feature subset selection using improved binary gravitational search algorithm,2014,Esmat Rashedi and Hossein Nezamabadi-pour,26,Journal of Intelligent & Fuzzy Systems,3,1211-1221,IOS Press,Feature selection is one of the important activities in various fields such as computer vision and pattern recognition. In this paper. an improved version of the binary gravitational search algorithm (BGSA) is proposed and used as a tool to select the best subset of features with the goal of improving classification accuracy. By enhancing the transfer function. we give BGSA the ability to overcome the stagnation situation. This allows the search algorithm to explore a larger group of possibilities and avoid stagnation. To evaluate the proposed improved BGSA (IBGSA). classification of some well known datasets and improving the accuracy of CBIR systems are experienced. Results are compared with those of original BGSA. genetic algorithm (GA). binary particle swarm optimization (BPSO). and electromagnetic-like mechanism. Comparative results confirm the effectiveness of the proposed IBGSA in feature selection.,True,c-DE4bwAAAAJ:LkGwnXOMwfcC,74,https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs807,12253373333101309529,/scholar?cites=12253373333101309529,,,https://www.researchgate.net/profile/Hossein_Nezamabadi-pour/publication/262292117_Feature_subset_selection_using_improved_binary_gravitational_search_algorithm/links/54bd336f0cf27c8f2814b238/Feature-subset-selection-using-improved-binary-gravitational-search-algorithm.pdf,0,0,0
1278541,Automatic channel selection in EEG signals for classification of left or right hand movement in Brain Computer Interfaces using improved binary gravitation search algorithm,2017,Alireza Ghaemi and Esmat Rashedi and Ali Mohammad Pourrahimi and Mehdi Kamandar and Farhad Rahdari,33,Biomedical Signal Processing and Control,,109-118,Elsevier,This paper presents an automatic method for finding optimal channels in Brain Computer Interfaces (BCIs). Detecting the effective channels in BCI systems is an important problem in reducing the complexity of these systems. In this research. Improved Binary Gravitation Search Algorithm (IBGSA) is used to automatically detect the effective electroencephalography (EEG) channels in left or right hand classification. To do this. at first. data is filtered with a bandpass filter in order to reduce the amount of different types of merged noise. Then. the electrooculography (EOG) and electromyography (EMG) artifacts are corrected based on Blind Source Separation (BSS) algorithm. Data is epoched according to the left or right hand motor imageries and central beta frequency band is isolated for Event Related Synchronization (ERS) analysis. Feature extraction process is carried out by analyzing EEG signals in time and …,True,c-DE4bwAAAAJ:QIV2ME_5wuYC,64,https://www.sciencedirect.com/science/article/pii/S1746809416302063,13651406432223487404,/scholar?cites=13651406432223487404,,,https://www.researchgate.net/profile/Mohamed_Mourad_Lafifi/post/How_can_one_use_particle_swarm_optimization_and_genatic_algorithms_for_EEG_EMG_Channels_selection/attachment/59d64e0779197b80779a7726/AS%3A490777966059521%401494021993762/download/Automatic+channel+selection+in+EEG+signals+for+classification+of+left+or+right+hand+movement+in+Brain+Computer+Interfaces+using+improved+binary+gravitation+search+algorithm+Ghaemi2017.pdf,0,0,0
1278542,A stochastic gravitational approach to feature based color image segmentation,2013,Esmat Rashedi and Hossein Nezamabadi-Pour,26,Engineering Applications of Artificial Intelligence,4,1322-1332,Pergamon,In this paper. a novel image segmentation algorithm based on the theory of gravity is presented. which is called as “stochastic feature based gravitational image segmentation algorithm (SGISA)”. The proposed SGISA uses color. texture. and spatial information to partition the image into homogenous and semi-compact segments. The proposed method benefits from the advantages of both clustering and region growing image segmentation techniques. The SGISA is equipped with a new operator called “escape” that is inspired by the concept of escape velocity in physics. Moreover. motivated by heuristic search algorithms. we incorporate a stochastic characteristic with the SGISA. which gives algorithm the ability to search the image for finding the fittest regions (pixels) that are suitable for merging. Several experiments on various standard images as well as Berkley standard image database are reported. Results are …,True,c-DE4bwAAAAJ:IjCSPb-OGe4C,50,https://www.sciencedirect.com/science/article/pii/S0952197612002631,14913688044320376083,/scholar?cites=14913688044320376083,,,,0,0,0
1278543,Improving the precision of CBIR systems by feature selection using binary gravitational search algorithm,2012,Esmat Rashedi and Hossein Nezamabadi-pour,,,,039-042,IEEE,In this paper. feature selection using binary gravitational search algorithm is utilized to improve the precision of CBIR systems. Content-based image retrieval. CBIR. is one of the most challenging problems in the field of pattern recognition. The performance of a CBIR system is hardly depends on the features that are extracted from images. Thus. selecting most relevant features leads to higher accuracy by reducing the semantic gap between high level features and low level features. Gravitational search algorithm is one of the recent heuristic search algorithms that in this paper. its power is compared with genetic algorithm and binary particle swarm optimization in feature selection. The proposed method is examined in Corel database. Results confirm the efficiency of BGSA to increase the precision of CBIR systems.,True,c-DE4bwAAAAJ:zYLM7Y9cAGgC,40,https://ieeexplore.ieee.org/abstract/document/6313714/,17831088278870722200,/scholar?cites=17831088278870722200,,,https://www.academia.edu/download/31379075/14_AISP2012_FS_BGSA.pdf,0,0,0
1278544,Multimodal deep autoencoder for human pose recovery,2015,Chaoqun Hong and Jun Yu and Jian Wan and Dacheng Tao and Meng Wang,24,IEEE Transactions on Image Processing,12,5659-5670,IEEE,Video-based human pose recovery is usually conducted by retrieving relevant poses using image features. In the retrieving process. the mapping between 2D images and 3D poses is assumed to be linear in most of the traditional methods. However. their relationships are inherently non-linear. which limits recovery performance of these methods. In this paper. we propose a novel pose recovery method using non-linear mapping with multi-layered deep neural network. It is based on feature extraction with multimodal fusion and back-propagation deep learning. In multimodal fusion. we construct hypergraph Laplacian with low-rank representation. In this way. we obtain a unified feature description by standard eigen-decomposition of the hypergraph Laplacian matrix. In back-propagation deep learning. we learn a non-linear mapping from 2D images to 3D poses with parameter fine-tuning. The experimental results on …,True,3XTEwtAAAAAJ:WZBGuue-350C,400,https://ieeexplore.ieee.org/abstract/document/7293666/,292986356290237454,/scholar?cites=292986356290237454,,,,0,0,0
1278545,Click prediction for web image reranking using multimodal sparse coding,2014,Jun Yu and Yong Rui and Dacheng Tao,23,IEEE Transactions on Image Processing,5,2019-2032,IEEE,Image reranking is effective for improving the performance of a text-based image search. However. existing reranking algorithms are limited for two main reasons: 1) the textual meta-data associated with images is often mismatched with their actual visual content and 2) the extracted visual features do not accurately describe the semantic similarities between images. Recently. user click information has been used in image reranking. because clicks have been shown to more accurately describe the relevance of retrieved images to search queries. However. a critical problem for click-based methods is the lack of click data. since only a small number of web images have actually been clicked on by users. Therefore. we aim to solve this problem by predicting image clicks. We propose a multimodal hypergraph learning-based sparse coding method for image click prediction. and apply the obtained click data to the …,True,3XTEwtAAAAAJ:D03iK_w7-QYC,399,https://ieeexplore.ieee.org/abstract/document/6762944/,4630949416397344799,/scholar?cites=4630949416397344799,,,http://www.logicsystems.org.in/Base%20Papers/2014%20.Net/LSD1437%20-%20Click%20Prediction%20for%20Web%20Image%20Reranking%20Using%20Multimodal%20Sparse%20Coding.pdf,0,0,0
1278546,Adaptive hypergraph learning and its application in image classification,2012,Jun Yu and Dacheng Tao and Meng Wang,21,IEEE Transactions on Image Processing,7,3262-3272,IEEE,Recent years have witnessed a surge of interest in graph-based transductive image classification. Existing simple graph-based transductive learning methods only model the pairwise relationship of images. however. and they are sensitive to the radius parameter used in similarity calculation. Hypergraph learning has been investigated to solve both difficulties. It models the high-order relationship of samples by using a hyperedge to link multiple samples. Nevertheless. the existing hypergraph learning methods face two problems. i.e.. how to generate hyperedges and how to handle a large set of hyperedges. This paper proposes an adaptive hypergraph learning method for transductive image classification. In our method. we generate hyperedges by linking images and their nearest neighbors. By varying the size of the neighborhood. we are able to generate a set of hyperedges for each image and its visual …,True,3XTEwtAAAAAJ:u-x6o8ySG0sC,344,https://ieeexplore.ieee.org/abstract/document/6165360/,12615322104546368962,/scholar?cites=12615322104546368962,,,,0,0,0
1278547,Deep multimodal distance metric learning using click constraints for image ranking,2016,Jun Yu and Xiaokang Yang and Fei Gao and Dacheng Tao,47,IEEE transactions on cybernetics,12,4014-4024,IEEE,How do we retrieve images accurately? Also. how do we rank a group of images precisely and efficiently for specific queries? These problems are critical for researchers and engineers to generate a novel image searching engine. First. it is important to obtain an appropriate description that effectively represent the images. In this paper. multimodal features are considered for describing images. The images unique properties are reflected by visual features. which are correlated to each other. However. semantic gaps always exist between images visual features and semantics. Therefore. we utilize click feature to reduce the semantic gap. The second key issue is learning an appropriate distance metric to combine these multimodal features. This paper develops a novel deep multimodal distance metric learning (Deep-MDML) method. A structured ranking model is adopted to utilize both visual and click features in …,True,3XTEwtAAAAAJ:HIFyuExEbWQC,310,https://ieeexplore.ieee.org/abstract/document/7529190/,15951051015794159671,/scholar?cites=15951051015794159671,,,,0,0,0
1278548,Multi-modal factorized bilinear pooling with co-attention learning for visual question answering,2017,Zhou Yu and Jun Yu and Jianping Fan and Dacheng Tao,,,,1821-1830,,Visual question answering (VQA) is challenging because it requires a simultaneous understanding of both the visual content of images and the textual content of questions. The approaches used to represent the images and questions in a fine-grained manner and questions and to fuse these multi-modal features play key roles in performance. Bilinear pooling based models have been shown to outperform traditional linear models for VQA. but their high-dimensional representations and high computational complexity may seriously limit their applicability in practice. For multi-modal feature fusion. here we develop a Multi-modal Factorized Bilinear (MFB) pooling approach to efficiently and effectively combine multi-modal features. which results in superior performance for VQA compared with other bilinear pooling approaches. For fine-grained image and question representation. we develop a co-attention mechanism using an end-to-end deep network architecture to jointly learn both the image and question attentions. Combining the proposed MFB approach with co-attention learning in a new network architecture provides a unified model for VQA. Our experimental results demonstrate that the single MFB with co-attention model achieves new state-of-the-art performance on the real-world VQA dataset. Code available at https://github. com/yuzcccc/mfb,True,3XTEwtAAAAAJ:fFSKOagxvKUC,307,http://openaccess.thecvf.com/content_iccv_2017/html/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.html,12567765357636779208,/scholar?cites=12567765357636779208,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.pdf,0,0,0
1278549,Learning to rank using user clicks and visual features for image retrieval,2014,Jun Yu and Dacheng Tao and Meng Wang and Yong Rui,45,IEEE transactions on cybernetics,4,767-779,IEEE,The inconsistency between textual features and visual contents can cause poor image search results. To solve this problem. click features. which are more reliable than textual information in justifying the relevance between a query and clicked images. are adopted in image ranking model. However. the existing ranking model cannot integrate visual features. which are efficient in refining the click-based search results. In this paper. we propose a novel ranking model based on the learning to rank framework. Visual features and click features are simultaneously utilized to obtain the ranking model. Specifically. the proposed approach is based on large margin structured output learning and the visual consistency is integrated with the click features through a hypergraph regularizer term. In accordance with the fast alternating linearization method. we design a novel algorithm to optimize the objective function. This …,True,3XTEwtAAAAAJ:bnK-pcrLprsC,294,https://ieeexplore.ieee.org/abstract/document/6867349/,17018389738119779156,/scholar?cites=17018389738119779156,,,,0,0,0
1278550,High-order distance-based multiview stochastic learning in image classification,2014,Jun Yu and Yong Rui and Yuan Yan Tang and Dacheng Tao,44,IEEE transactions on cybernetics,12,2431-2442,IEEE,How do we find all images in a larger set of images which have a specific content? Or estimate the position of a specific object relative to the camera? Image classification methods. like support vector machine (supervised) and transductive support vector machine (semi-supervised). are invaluable tools for the applications of content-based image retrieval. pose estimation. and optical character recognition. However. these methods only can handle the images represented by single feature. In many cases. different features (or multiview data) can be obtained. and how to efficiently utilize them is a challenge. It is inappropriate for the traditionally concatenating schema to link features of different views into a long vector. The reason is each view has its specific statistical property and physical interpretation. In this paper. we propose a high-order distance-based multiview stochastic learning (HD-MSL) method for image …,True,3XTEwtAAAAAJ:1sJd4Hv_s6UC,237,https://ieeexplore.ieee.org/abstract/document/6774452/,1496328285002391699,/scholar?cites=1496328285002391699,,,,0,0,0
1278551,Semisupervised multiview distance metric learning for cartoon synthesis,2012,Jun Yu and Meng Wang and Dacheng Tao,21,IEEE Transactions on Image Processing,11,4636-4648,IEEE,In image processing. cartoon character classification. retrieval. and synthesis are critical. so that cartoonists can effectively and efficiently make cartoons by reusing existing cartoon data. To successfully achieve these tasks. it is essential to extract visual features that comprehensively represent cartoon characters and to construct an accurate distance metric to precisely measure the dissimilarities between cartoon characters. In this paper. we introduce three visual features. color histogram. shape context. and skeleton. to characterize the color. shape. and action. respectively. of a cartoon character. These three features are complementary to each other. and each feature set is regarded as a single view. However. it is improper to concatenate these three features into a long vector. because they have different physical properties. and simply concatenating them into a high-dimensional feature vector will suffer from the …,True,3XTEwtAAAAAJ:d1gkVwhDpl0C,223,https://ieeexplore.ieee.org/abstract/document/6236161/,10918172572161317217,/scholar?cites=10918172572161317217,,,,0,0,0
1278552,Beyond bilinear: Generalized multimodal factorized high-order pooling for visual question answering,2018,Zhou Yu and Jun Yu and Chenchao Xiang and Jianping Fan and Dacheng Tao,29,IEEE transactions on neural networks and learning systems,12,5947-5959,IEEE,Visual question answering (VQA) is challenging. because it requires a simultaneous understanding of both visual content of images and textual content of questions. To support the VQA task. we need to find good solutions for the following three issues: 1) fine-grained feature representations for both the image and the question; 2) multimodal feature fusion that is able to capture the complex interactions between multimodal features; and 3) automatic answer prediction that is able to consider the complex correlations between multiple diverse answers for the same question. For fine-grained image and question representations. a “coattention” mechanism is developed using a deep neural network (DNN) architecture to jointly learn the attentions for both the image and the question. which can allow us to reduce the irrelevant features effectively and obtain more discriminative features for image and question …,True,3XTEwtAAAAAJ:P7Ujq4OLJYoC,220,https://ieeexplore.ieee.org/abstract/document/8334194/,12743862933043798233,/scholar?cites=12743862933043798233,,,https://arxiv.org/pdf/1708.03619,0,0,0
1278553,iPrivacy: image privacy protection by identifying sensitive objects via deep multi-task learning,2016,Jun Yu and Baopeng Zhang and Zhengzhong Kuang and Dan Lin and Jianping Fan,12,IEEE Transactions on Information Forensics and Security,5,1005-1016,IEEE,To achieve automatic recommendation of privacy settings for image sharing. a new tool called iPrivacy (image privacy) is developed for releasing the burden from users on setting the privacy preferences when they share their images for special moments. Specifically. this paper consists of the following contributions: 1) massive social images and their privacy settings are leveraged to learn the object-privacy relatedness effectively and identify a set of privacy-sensitive object classes automatically; 2) a deep multi-task learning algorithm is developed to jointly learn more representative deep convolutional neural networks and more discriminative tree classifier. so that we can achieve fast and accurate detection of large numbers of privacy-sensitive object classes; 3) automatic recommendation of privacy settings for image sharing can be achieved by detecting the underlying privacy-sensitive objects from the images …,True,3XTEwtAAAAAJ:bKqednn6t2AC,205,https://ieeexplore.ieee.org/abstract/document/7775034/,10540338140362826069,/scholar?cites=10540338140362826069,,,https://par.nsf.gov/servlets/purl/10026310,0,0,0
1278554,Image-based three-dimensional human pose recovery by multiview locality-sensitive sparse retrieval,2014,Chaoqun Hong and Jun Yu and Dacheng Tao and Meng Wang,62,IEEE Transactions on Industrial Electronics,6,3742-3751,IEEE,Image-based 3-D human pose recovery is usually conducted by retrieving relevant poses with image features. However. it suffers from the high dimensionality of image features and the low efficiency of the retrieving process. Particularly for multiview data. the integration of different types of features is difficult. In this paper. a novel approach is proposed to recover 3-D human poses from silhouettes. This approach improves traditional methods by adopting multiview locality-sensitive sparse coding in the retrieving process. First. it incorporates a local similarity preserving term into the objective of sparse coding. which groups similar silhouettes to alleviate the instability of sparse codes. Second. the objective function of sparse coding is improved by integrating multiview data. The experimental results show that the retrieval error has been reduced by 20% to 50%. which demonstrate the effectiveness of the proposed …,True,3XTEwtAAAAAJ:bz8QjSJIRt4C,196,https://ieeexplore.ieee.org/abstract/document/6980090/,7067415906917072791,/scholar?cites=7067415906917072791,,,,0,0,0
1278555,Motion-compensated frame interpolation using bilateral motion estimation and adaptive overlapped block motion compensation,2007,Byeong-Doo Choi and Jong-Woo Han and Chang-Su Kim and Sung-Jea Ko,17,IEEE Transactions on Circuits and Systems for Video Technology,4,407-416,IEEE,In this work. we develop a new motion-compe (MC) interpolation algorithm to enhance the temporal resolution of video sequences. First. we propose the bilateral motion estimation scheme to obtain the motion field of an interpolated frame without yielding the hole and overlapping problems. Then. we partition a frame into several object regions by clustering motion vectors. We apply the variable-size block MC (VS-BMC) algorithm to object boundaries in order to reconstruct edge information with a higher quality. Finally. we use the adaptive overlapped block MC (OBMC). which adjusts the coefficients of overlapped windows based on the reliabilities of neighboring motion vectors. The adaptive OBMC (AOBMC) can overcome the limitations of the conventional OBMC. such as over-smoothing and poor de-blocking. Experimental results show that the proposed algorithm provides a better image quality than conventional …,True,KOdKwNsAAAAJ:u-x6o8ySG0sC,393,https://ieeexplore.ieee.org/abstract/document/4162523/,8409776442105373630,/scholar?cites=8409776442105373630,,,,0,0,0
1278556,Technologies for 3D mesh compression: A survey,2005,Jingliang Peng and Chang-Su Kim and C-C Jay Kuo,16,Journal of Visual Communication and Image Representation,6,688-733,Academic Press,Three-dimensional (3D) meshes have been widely used in graphic applications for the representation of 3D objects. They often require a huge amount of data for storage and/or transmission in the raw data format. Since most applications demand compact storage. fast transmission. and efficient processing of 3D meshes. many algorithms have been proposed to compress 3D meshes efficiently since early 1990s. In this survey paper. we examine 3D mesh compression technologies developed over the last decade. with the main focus on triangular mesh compression technologies. In this effort. we classify various algorithms into classes. describe main ideas behind each class. and compare the advantages and shortcomings of the algorithms in each class. Finally. we address some trends in the 3D mesh compression technology development.,True,KOdKwNsAAAAJ:u5HHmVD_uO8C,388,https://www.sciencedirect.com/science/article/pii/S1047320305000295,13348786149834059816,/scholar?cites=13348786149834059816,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.329.8416&rep=rep1&type=pdf,0,0,0
1278557,Optimized contrast enhancement for real-time image and video dehazing,2013,Jin-Hwan Kim and Won-Dong Jang and Jae-Young Sim and Chang-Su Kim,24,Journal of Visual Communication and Image Representation,3,410-425,Academic Press,A fast and optimized dehazing algorithm for hazy images and videos is proposed in this work. Based on the observation that a hazy image exhibits low contrast in general. we restore the hazy image by enhancing its contrast. However. the overcompensation of the degraded contrast may truncate pixel values and cause information loss. Therefore. we formulate a cost function that consists of the contrast term and the information loss term. By minimizing the cost function. the proposed algorithm enhances the contrast and preserves the information optimally. Moreover. we extend the static image dehazing algorithm to real-time video dehazing. We reduce flickering artifacts in a dehazed video sequence by making transmission values temporally coherent. Experimental results show that the proposed algorithm effectively removes haze and is sufficiently fast for real-time dehazing applications.,True,KOdKwNsAAAAJ:738O_yMBCRsC,374,https://www.sciencedirect.com/science/article/pii/S1047320313000242,6423897689424108184,/scholar?cites=6423897689424108184,,,http://mcl.korea.ac.kr/~dotol1216/Publications/2013_JVCIR_JHKIM.pdf,0,0,0
1278558,Contrast enhancement based on layered difference representation of 2D histograms,2013,Chulwoo Lee and Chul Lee and Chang-Su Kim,22,IEEE Transactions on Image Processing,12,5372-5384,IEEE,A novel contrast enhancement algorithm based on the layered difference representation of 2D histograms is proposed in this paper. We attempt to enhance image contrast by amplifying the gray-level differences between adjacent pixels. To this end. we obtain the 2D histogram h(k. k+l) from an input image. which counts the pairs of adjacent pixels with gray-levels k and k+l. and represent the gray-level differences in a tree-like layered structure. Then. we formulate a constrained optimization problem based on the observation that the gray-level differences. occurring more frequently in the input image. should be more emphasized in the output image. We first solve the optimization problem to derive the transformation function at each layer. We then combine the transformation functions at all layers into the unified transformation function. which is used to map input gray-levels to output gray-levels. Experimental results …,True,KOdKwNsAAAAJ:hCrLmN-GePgC,214,https://ieeexplore.ieee.org/abstract/document/6615961/,815923184415027777,/scholar?cites=815923184415027777,,,,0,0,0
1278559,Single-image deraining using an adaptive nonlocal means filter,2013,Jin-Hwan Kim and Chul Lee and Jae-Young Sim and Chang-Su Kim,,,,914-917,IEEE,An adaptive rain streak removal algorithm for a single image is proposed in this work. We observe that a typical rain streak has an elongated elliptical shape with a vertical orientation. Thus. we first detect rain streak regions by analyzing the rotation angle and the aspect ratio of the elliptical kernel at each pixel location. We then perform the nonlocal means filtering on the detected rain streak regions by selecting nonlocal neighbor pixels and their weights adaptively. Experimental results demonstrate that the proposed algorithm removes rain streaks more efficiently and provides higher restored image qualities than conventional algorithms.,True,KOdKwNsAAAAJ:IUKN3-7HHlwC,185,https://ieeexplore.ieee.org/abstract/document/6738189/,12266204042135606957,/scholar?cites=12266204042135606957,,,,0,0,0
1278560,Spatial and temporal error concealment techniques for video transmission over noisy channels,2006,W-Y Kung and C-S Kim and C-CJ Kuo,16,IEEE transactions on circuits and systems for video technology,7,789-803,IEEE,Two novel error concealment techniques are proposed for video transmission over noisy channels in this work. First. we present a spatial error concealment method to compensate a lost macroblock in intra-coded frames. in which no useful temporal information is available. Based on selective directional interpolation. our method can recover both smooth and edge areas efficiently. Second. we examine a dynamic mode-weighted error concealment method for replenishing missing pixels in a lost macroblock of inter-coded frames. Our method adopts a decoder-based error tracking model and combines several concealment modes adaptively to minimize the mean square error of each pixel. The method is capable of concealing lost packets as well as reducing the error propagation effect. Extensive simulations have been performed to demonstrate the performance of the proposed methods in error-prone environments,True,KOdKwNsAAAAJ:d1gkVwhDpl0C,173,https://ieeexplore.ieee.org/abstract/document/1661656/,11067227936089060427,/scholar?cites=11067227936089060427,,,https://www.researchgate.net/profile/C-C_Jay_Kuo/publication/3308949_Spatial_and_Temporal_Error_Concealment_Techniques_for_Video_Transmission_Over_Noisy_Channels/links/56d5ab0808ae5c281ca44fda.pdf,0,0,0
1278561,Power-constrained contrast enhancement for emissive displays based on histogram equalization.,2012,Chulwoo Lee and Chul Lee and Young-Yoon Lee and Chang-Su Kim,21,IEEE Trans. Image Processing,1,80-93,,A power-constrained contrast-enhancement algorithm for emissive displays based on histogram equalization (HE) is proposed in this paper. We first propose a log-based histogram modification scheme to reduce overstretching artifacts of the conventional HE technique. Then. we develop a power-consumption model for emissive displays and formulate an objective function that consists of the histogram-equalizing term and the power term. By minimizing the objective function based on the convex optimization theory. the proposed algorithm achieves contrast enhancement and power saving simultaneously. Moreover. we extend the proposed algorithm to enhance video sequences. as well as still images. Simulation results demonstrate that the proposed algorithm can reduce power consumption significantly while improving image contrast and perceptual quality.,True,KOdKwNsAAAAJ:4JMBOYKVnBMC,151,https://ieeexplore.ieee.org/abstract/document/5873151/,16021306812448942846,/scholar?cites=16021306812448942846,,,http://kresttechnology.com/krest-academic-projects/krest-mtech-projects/ECE/dspmt/[27].pdf,0,0,0
1278562,Video deraining and desnowing using temporal correlation and low-rank matrix completion,2015,Jin-Hwan Kim and Jae-Young Sim and Chang-Su Kim,24,IEEE Transactions on Image Processing,9,2658-2670,IEEE,A novel algorithm to remove rain or snow streaks from a video sequence using temporal correlation and low-rank matrix completion is proposed in this paper. Based on the observation that rain streaks are too small and move too fast to affect the optical flow estimation between consecutive frames. we obtain an initial rain map by subtracting temporally warped frames from a current frame. Then. we decompose the initial rain map into basis vectors based on the sparse representation. and classify those basis vectors into rain streak ones and outliers with a support vector machine. We then refine the rain map by excluding the outliers. Finally. we remove the detected rain streaks by employing a low-rank matrix completion technique. Furthermore. we extend the proposed algorithm to stereo video deraining. Experimental results demonstrate that the proposed algorithm detects and removes rain or snow streaks efficiently …,True,KOdKwNsAAAAJ:DUooU5lO8OsC,146,https://ieeexplore.ieee.org/abstract/document/7101234/,15797526198445114131,/scholar?cites=15797526198445114131,,,,0,0,0
1278563,Primary object segmentation in videos based on region augmentation and reduction,2017,Yeong Jun Koh and Chang-Su Kim,1,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,5,6,,A novel algorithm to segment a primary object in a video sequence is proposed in this work. First. we generate candidate regions for the primary object using both color and motion edges. Second. we estimate initial primary object regions. by exploiting the recurrence property of the primary object. Third. we augment the initial regions with missing parts or reducing them by excluding noisy parts repeatedly. This augmentation and reduction process (ARP) identifies the primary object region in each frame. Experimental results demonstrate that the proposed algorithm significantly outperforms the state-of-the-art conventional algorithms on recent benchmark datasets.,True,KOdKwNsAAAAJ:Bg7qf7VwUHIC,124,https://ieeexplore.ieee.org/abstract/document/8100267/,6428283019357774066,/scholar?cites=6428283019357774066,,,http://mcl.korea.ac.kr/~koyongjun/research/CVPR2017/1272.pdf,0,0,0
1278564,Spatiotemporal saliency detection for video sequences based on random walk with restart,2015,Hansang Kim and Youngbae Kim and Jae-Young Sim and Chang-Su Kim,24,IEEE Transactions on Image Processing,8,2552-2564,IEEE,A novel saliency detection algorithm for video sequences based on the random walk with restart (RWR) is proposed in this paper. We adopt RWR to detect spatially and temporally salient regions. More specifically. we first find a temporal saliency distribution using the features of motion distinctiveness. temporal consistency. and abrupt change. Among them. the motion distinctiveness is derived by comparing the motion profiles of image patches. Then. we employ the temporal saliency distribution as a restarting distribution of the random walker. In addition. we design the transition probability matrix for the walker using the spatial features of intensity. color. and compactness. Finally. we estimate the spatiotemporal saliency distribution by finding the steady-state distribution of the walker. The proposed algorithm detects foreground salient objects faithfully. while suppressing cluttered backgrounds effectively. by …,True,KOdKwNsAAAAJ:umqufdRvDiIC,116,https://ieeexplore.ieee.org/abstract/document/7091884/,15155933005992287565,/scholar?cites=15155933005992287565,,,,0,0,0
1278565,Multiple description coding of motion fields for robust video transmission,2001,Chang-Su Kim and Sang-Uk Lee,11,IEEE Transactions on Circuits and Systems for Video Technology,9,999-1010,IEEE,In many video-coding standards. the motion vector field is one of the most important data in the compressed bitstream. and its loss can lead to severe degradation in the decoded picture quality. We propose the multiple description motion coding (MDMC) algorithm to enhance the robustness of the motion vector field against transmission errors. In MDMC. the motion vector field is encoded into two descriptions. which are transmitted over distinct channels to the decoder. The decoder is designed to provide an acceptable quality prediction image. even if one of the descriptions is lost during the transmission. Moreover. the decoder can reconstruct a higher quality prediction image. when both the descriptions are received without error. A complete multiple description video coder. based on the MDMC. is implemented by modifying the syntax of the H.263 standard. and tested intensively in a realistic error-prone …,True,KOdKwNsAAAAJ:9yKSN-GCB0IC,103,https://ieeexplore.ieee.org/abstract/document/946517/,17592333804470381215,/scholar?cites=17592333804470381215,,,,0,0,0
1278566,Context-driven fusion of high spatial and spectral resolution images based on oversampled multiresolution analysis,2002,Bruno Aiazzi and Luciano Alparone and Stefano Baronti and Andrea Garzelli,40,IEEE Transactions on geoscience and remote sensing,10,2300-2312,IEEE,This paper compares two general and formal solutions to the problem of fusion of multispectral images with high-resolution panchromatic observations. The former exploits the undecimated discrete wavelet transform. which is an octave bandpass representation achieved from a conventional discrete wavelet transform by omitting all decimators and upsampling the wavelet filter bank. The latter relies on the generalized Laplacian pyramid. which is another oversampled structure obtained by recursively subtracting from an image an expanded decimated lowpass version. Both the methods selectively perform spatial-frequencies spectrum substitution from an image to another. In both schemes. context dependency is exploited by thresholding the local correlation coefficient between the images to be merged. to avoid injection of spatial details that are not likely to occur in the target image. Unlike other multiscale fusion …,True,C61jjN4AAAAJ:u5HHmVD_uO8C,744,https://ieeexplore.ieee.org/abstract/document/1105917/,14175686553794476225,/scholar?cites=14175686553794476225,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/3203007_Context-driven_fusion_of_high_spatial_and_spectral_resolution_data_based_on_oversampled_multiresolution_analysis/links/5804c9ea08ae0b2b3ef4429c.pdf,0,0,0
1278567,A critical comparison among pansharpening algorithms,2014,Gemine Vivone and Luciano Alparone and Jocelyn Chanussot and Mauro Dalla Mura and Andrea Garzelli and Giorgio A Licciardi and Rocco Restaino and Lucien Wald,53,IEEE Transactions on Geoscience and Remote Sensing,5,2565-2586,IEEE,Pansharpening aims at fusing a multispectral and a panchromatic image. featuring the result of the processing with the spectral resolution of the former and the spatial resolution of the latter. In the last decades. many algorithms addressing this task have been presented in the literature. However. the lack of universally recognized evaluation criteria. available image data sets for benchmarking. and standardized implementations of the algorithms makes a thorough evaluation and comparison of the different pansharpening techniques difficult to achieve. In this paper. the authors attempt to fill this gap by providing a critical description and extensive comparisons of some of the main state-of-the-art pansharpening methods. In greater details. several pansharpening algorithms belonging to the component substitution or multiresolution analysis families are considered. Such techniques are evaluated through the two main …,True,C61jjN4AAAAJ:DUFsPKDdMi0C,680,https://ieeexplore.ieee.org/abstract/document/6998089/,14799732814292562398,/scholar?cites=14799732814292562398,,,https://openremotesensing.net/wp-content/uploads/2015/02/IEEE_TGRS_2015_vivone_pansharpening.pdf,0,0,0
1278568,Remote sensing image fusion using the curvelet transform,2007,Filippo Nencini and Andrea Garzelli and Stefano Baronti and Luciano Alparone,8,Information fusion,2,143-156,Elsevier,This paper presents an image fusion method suitable for pan-sharpening of multispectral (MS) bands. based on nonseparable multiresolution analysis (MRA). The low-resolution MS bands are resampled to the fine scale of the panchromatic (Pan) image and sharpened by injecting highpass directional details extracted from the high-resolution Pan image by means of the curvelet transform (CT). CT is a nonseparable MRA. whose basis functions are directional edges with progressively increasing resolution. The advantage of CT with respect to conventional separable MRA. either decimated or not. is twofold. Firstly. directional detail coefficients matching image edges may be preliminarily soft-thresholded to achieve a noise reduction that is better than that obtained in the separable wavelet domain. Secondly. modeling of the relationships between high-resolution detail coefficients of the MS bands and of the Pan …,True,C61jjN4AAAAJ:d1gkVwhDpl0C,604,https://www.sciencedirect.com/science/article/pii/S1566253506000340,10240371414117550501,/scholar?cites=10240371414117550501,,,,0,0,0
1278569,A global quality measurement of pan-sharpened multispectral imagery,2004,Luciano Alparone and Stefano Baronti and Andrea Garzelli and Filippo Nencini,1,IEEE Geoscience and Remote Sensing Letters,4,313-317,IEEE,This letter focuses on quality assessment of fusion of multispectral (MS) images with high-resolution panchromatic (Pan) observations. A new quality index suitable for MS imagery having four spectral bands is defined from the theory of hypercomplex numbers. or quaternions. Both spectral and radiometric distortion measurements are encapsulated in a unique measurement. simultaneously accounting for local mean bias. changes in contrast. and loss of correlation of individual bands. together with spectral distortion. Results are presented and discussed on very high-resolution QuickBird data. through comparisons between state-of-the-art and advanced MS+Pan merge algorithms.,True,C61jjN4AAAAJ:u-x6o8ySG0sC,562,https://ieeexplore.ieee.org/abstract/document/1347130/,10972150802793145515,/scholar?cites=10972150802793145515,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/3449561_A_Global_Quality_Measurement_of_Pan-Sharpened_Multispectral_Imagery/links/58a6bc794585150402ee1b52/A-Global-Quality-Measurement-of-Pan-Sharpened-Multispectral-Imagery.pdf,0,0,0
1278570,MTF-tailored multiscale fusion of high-resolution MS and Pan imagery,2006,B Aiazzi and L Alparone and S Baronti and A Garzelli and M Selva,72,Photogrammetric Engineering & Remote Sensing,5,591-596,American Society for Photogrammetry and Remote Sensing,This work presents a multiresolution framework for merging a multispectral image having an arbitrary number of bands with a higher-resolution panchromatic observation. The fusion method relies on the generalized Laplacian pyramid (GLP). which is a multiscale. oversampled structure. The goal is to selectively perform injection of spatial frequencies from an image to another with the constraint of thoroughly retaining the spectral information of the coarser data. The novel idea is that a model of the modulation transfer functions (MTF) of the multispectral scanner is exploited to design the GLP reduction filter. Thus. the interband structure model (IBSM). which is calculated at the coarser scale. where both MS and PAN data are available. can be extended to the finer scale. without the drawback of the poor enhancement occurring when MTFs are assumed to be ideal filters. Experiments carried out on QuickBird data …,True,C61jjN4AAAAJ:2osOgNQ5qMEC,497,https://www.ingentaconnect.com/content/asprs/pers/2006/00000072/00000005/art00007,2993960246376865325,/scholar?cites=2993960246376865325,,,https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000005/art00007?crawler=true&mimetype=application/pdf,0,0,0
1278571,Multispectral and panchromatic data fusion assessment without reference,2008,Luciano Alparone and Bruno Aiazzi and Stefano Baronti and Andrea Garzelli and Filippo Nencini and Massimo Selva,74,Photogrammetric Engineering & Remote Sensing,2,193-200,American Society for Photogrammetry and Remote Sensing,This paper introduces a novel approach for evaluating the quality of pansharpened multispectral (MS) imagery without resorting to reference originals. Hence. evaluations are feasible at the highest spatial resolution of the panchromatic (PAN) sensor. Wang and Bovik’s image quality index (QI) provides a statistical similarity measurement between two monochrome images. The QI values between any couple of MS bands are calculated before and after fusion and used to define a measurement of spectral distortion. Analogously. QI values between each MS band and the PAN image are calculated before and after fusion to yield a measurement of spatial distortion. The rationale is that such QI values should be unchanged after fusion. i.e.. when the spectral information is translated from the coarse scale of the MS data to the fine scale of the PAN image. Experimental results. carried out on very high-resolution Ikonos …,True,C61jjN4AAAAJ:eQOLeE2rZwMC,446,https://www.ingentaconnect.com/content/asprs/pers/2008/00000074/00000002/art00003,16317041751687196137,/scholar?cites=16317041751687196137,,,https://www.ingentaconnect.com/content/asprs/pers/2008/00000074/00000002/art00003?crawler=true&mimetype=application/pdf,0,0,0
1278572,Optimal MMSE pan sharpening of very high resolution multispectral images,2007,Andrea Garzelli and Filippo Nencini and Luca Capobianco,46,IEEE Transactions on Geoscience and Remote Sensing,1,228-236,IEEE,In this paper. we propose an optimum algorithm. in the minimum mean-square-error (mmse) sense. for panchromatic (Pan) sharpening of very high resolution multispectral (MS) images. The solution minimizes the squared error between the original MS image and the fusion result obtained by spatially enhancing a degraded version of the MS image through a degraded version. by the same scale factor. of the Pan image. The fusion result is also optimal at full scale under the assumption of invariance of the fusion parameters across spatial scales. The following two versions of the algorithm are presented: a local mmse (lmmse) solution and a fast implementation which globally optimizes the fusion parameters with a moderate performance loss with respect to the lmmse version. We show that the proposed method is computationally practical. even in the case of local optimization. and it outperforms the best state-of-the …,True,C61jjN4AAAAJ:Y0pCki6q_DkC,297,https://ieeexplore.ieee.org/abstract/document/4389066/,1998702827315979565,/scholar?cites=1998702827315979565,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/3205691_Optimal_MMSE_Pan_Sharpening_of_Very_High_Resolution_Multispectral_Images/links/577633e008aead7ba0719736/Optimal-MMSE-Pan-Sharpening-of-Very-High-Resolution-Multispectral-Images.pdf,0,0,0
1278573,Landsat ETM+ and SAR image fusion based on generalized intensity modulation,2004,Luciano Alparone and Stefano Baronti and Andrea Garzelli and Filippo Nencini,42,IEEE Transactions on geoscience and remote sensing,12,2832-2839,IEEE,"This work presents a novel multisensor image fusion algorithm. which extends panchrmomatic sharpening of multispectral (MS) data through intensity modulation to the integration of MS and synthetic aperture radar (SAR) imagery. The method relies on SAR texture. extracted by ratioing the despeckled SAR image to its low-pass approximation. SAR texture is used to modulate the generalized intensity (GI) of the MS image. which is given by a linear transform extending intensity-hue-saturation transform to an arbitrary number of bands. Before modulation. the GI is enhanced by injection of high-pass details extracted from the available panchrmomatic image by means of the ""a/spl grave/-trous"" wavelet decomposition. The texture-modulated panchrmomatic-sharpened GI replaces the GI calculated from the resampled original MS data. Then. the inverse transform is applied to obtain the fusion product. Experimental …",True,C61jjN4AAAAJ:9yKSN-GCB0IC,183,https://ieeexplore.ieee.org/abstract/document/1369379/,17288480062992139609,/scholar?cites=17288480062992139609,,,https://www.academia.edu/download/48446836/tgrs.2004.83834420160830-2597-1h6temc.pdf,0,0,0
1278574,Interband structure modeling for pan-sharpening of very high-resolution multispectral images,2005,Andrea Garzelli and Filippo Nencini,6,Information Fusion,3,213-224,Elsevier,This paper addresses the modeling of wavelet coefficients for multispectral (MS) band sharpening based on undecimated multiresolution analysis (MRA). The coarse MS bands are sharpened by injecting highpass details taken from a high-resolution panchromatic (Pan) image. Besides the MRA. crucial point is modeling the relationships between detail coefficients of a generic MS band and the Pan image at the same resolution. Once calculated at the coarser resolution. where both types of data are available. such a model shall be extrapolated to the finer resolution in order to weight the Pan details to be injected. The goal is that the merged MS images are most similar to what the MS sensor would collect if it had the same resolution as the broadband Pan imager. Three injection models embedded in an “à trous” wavelet decomposition will be described and compared on a test set of very high-resolution QuickBird …,True,C61jjN4AAAAJ:qjMakFHDy7sC,130,https://www.sciencedirect.com/science/article/pii/S1566253504000478,9214657954203925731,/scholar?cites=9214657954203925731,,,,0,0,0
1278575,Hypercomplex quality assessment of multi/hyperspectral images,2009,Andrea Garzelli and Filippo Nencini,6,IEEE Geoscience and Remote Sensing Letters,4,662-665,IEEE,This letter presents a novel image quality index which extends the Universal Image Quality Index for monochrome images to multispectral and hyperspectral images through hypercomplex numbers. The proposed index is based on the computation of the hypercomplex correlation coefficient between the reference and tested images. which jointly measures spectral and spatial distortions. Experimental results. both from true and simulated images. are presented on spaceborne and airborne visible/infrared images. The results prove accurate measurements of inter- and intraband distortions even when anomalous pixel values are concentrated on few bands.,True,C61jjN4AAAAJ:M05iB0D1s5AC,129,https://ieeexplore.ieee.org/abstract/document/5159503/,10700909746974310285,/scholar?cites=10700909746974310285,,,https://www.researchgate.net/profile/Andrea_Garzelli/publication/224560382_Hypercomplex_Quality_Assessment_of_MultiHyperspectral_Images/links/0f317538da04c396e5000000.pdf,0,0,0
1278576,A theoretical analysis of the effects of aliasing and misregistration on pansharpened imagery,2011,Stefano Baronti and Bruno Aiazzi and Massimo Selva and Andrea Garzelli and Luciano Alparone,5,IEEE Journal of Selected Topics in Signal Processing,3,446-453,IEEE,In this paper. the characteristics of multispectral (MS) and panchromatic (P) image fusion methods are investigated. Depending on the way spatial details are extracted from P. pansharpening methods can be broadly labeled into two main classes. corresponding to methods based on either component substitution (CS) or multiresolution analysis (MRA). Theoretical investigations and experimental results evidence that CS-based fusion is far less sensitive than MRA-based fusion to: 1) registration errors. i.e.. spatial misalignments between MS and P images. possibly originated by cartographic projection and resampling of individual data sets; 2) aliasing occurring in MS bands and stemming from modulation transfer functions (MTF) of MS channels that are excessively broad for the sampling step. In order to assess the sensitiveness of methods. aliasing is simulated at degraded spatial scale by means of several MTF …,True,C61jjN4AAAAJ:3s1wT3WcHBgC,116,https://ieeexplore.ieee.org/abstract/document/5682379/,16468586195248599405,/scholar?cites=16468586195248599405,,,https://www.researchgate.net/profile/Stefano_Baronti/publication/224210344_A_Theoretical_Analysis_of_the_Effects_of_Aliasing_and_Misregistration_on_Pansharpened_Imagery/links/02e7e52a8a6bed907e000000/A-Theoretical-Analysis-of-the-Effects-of-Aliasing-and-Misregistration-on-Pansharpened-Imagery.pdf,0,0,0
1278577,A reproducible evaluation of ANTs similarity metric performance in brain image registration,2011,Brian B Avants and Nicholas J Tustison and Gang Song and Philip A Cook and Arno Klein and James C Gee,54,Neuroimage,3,2033-2044,Academic Press,The United States National Institutes of Health (NIH) commit significant support to open-source data and software resources in order to foment reproducibility in the biomedical imaging sciences. Here. we report and evaluate a recent product of this commitment: Advanced Neuroimaging Tools (ANTs). which is approaching its 2.0 release. The ANTs open source software library consists of a suite of state-of-the-art image registration. segmentation and template building tools for quantitative morphometric analysis. In this work. we use ANTs to quantify. for the first time. the impact of similarity metrics on the affine and deformable components of a template-based normalization study. We detail the ANTs implementation of three similarity metrics: squared intensity difference. a new and faster cross-correlation. and voxel-wise mutual information. We then use two-fold cross-validation to compare their performance on openly …,True,R5i2QZAAAAAJ:UeHWp8X0CEIC,2338,https://www.sciencedirect.com/science/article/pii/S1053811910012061,15465161913468031622,/scholar?cites=15465161913468031622,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3065962/,0,0,0
1278578,Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration,2009,Arno Klein and Jesper Andersson and Babak A Ardekani and John Ashburner and Brian Avants and Ming-Chang Chiang and Gary E Christensen and D Louis Collins and James Gee and Pierre Hellier and Joo Hyun Song and Mark Jenkinson and Claude Lepage and Daniel Rueckert and Paul Thompson and Tom Vercauteren and Roger P Woods and J John Mann and Ramin V Parsey,46,Neuroimage,3,786-802,Academic Press,All fields of neuroscience that employ brain imaging need to communicate their results with reference to anatomical regions. In particular. comparative morphometry and group analysis of functional and physiological data require coregistration of brains to establish correspondences across brain structures. It is well established that linear registration of one brain to another is inadequate for aligning brain structures. so numerous algorithms have emerged to nonlinearly register brains to one another. This study is the largest evaluation of nonlinear deformation algorithms applied to brain image registration ever conducted. Fourteen algorithms from laboratories around the world are evaluated using 8 different error measures. More than 45.000 registrations between 80 manually labeled brains were performed by algorithms including: AIR. ANIMAL. ART. Diffeomorphic Demons. FNIRT. IRTK. JRD-fluid. ROMEO. SICLE …,True,R5i2QZAAAAAJ:u5HHmVD_uO8C,2143,https://www.sciencedirect.com/science/article/pii/S1053811908012974,3800993754532760613,/scholar?cites=3800993754532760613,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2747506/,0,0,0
1278579,101 labeled brain images and a consistent human cortical labeling protocol,2012,Arno Klein and Jason Tourville,6,Frontiers in neuroscience,,171,Frontiers,We introduce the Mindboggle-101 dataset. the largest and most complete set of free. publicly accessible. manually labeled human brain images. To manually label the macroscopic anatomy in magnetic resonance images of 101 healthy participants. we created a new cortical labeling protocol that relies on robust anatomical landmarks and minimal manual edits after initialization with automated labels. The “Desikan-Killiany-Tourville” (DKT) protocol is intended to improve the ease. consistency. and accuracy of labeling human cortical areas. Given how difficult it is to label brains. the Mindboggle-101 dataset is intended to serve as brain atlases for use in labeling other brains. as a normative dataset to establish morphometric variation in a healthy population for comparison against clinical populations. and contribute to the development. training. testing. and evaluation of automated registration and labeling algorithms. To this end. we also introduce benchmarks for the evaluation of such algorithms by comparing our manual labels with labels automatically generated by probabilistic and multi-atlas registration-based approaches. All data and related software and updated information are available on the http://www.mindboggle.info/data/ website.,True,R5i2QZAAAAAJ:3fE2CSJIrl8C,504,https://www.frontiersin.org/articles/10.3389/fnins.2012.00171/full,1949716158480922450,/scholar?cites=1949716158480922450,,,https://www.frontiersin.org/articles/10.3389/fnins.2012.00171/full,0,0,0
1278580,Large-scale evaluation of ANTs and FreeSurfer cortical thickness measurements,2014,Nicholas J Tustison and Philip A Cook and Arno Klein and Gang Song and Sandhitsu R Das and Jeffrey T Duda and Benjamin M Kandel and Niels van Strien and James R Stone and James C Gee and Brian B Avants,99,Neuroimage,,166-179,Academic Press,Many studies of the human brain have explored the relationship between cortical thickness and cognition. phenotype. or disease. Due to the subjectivity and time requirements in manual measurement of cortical thickness. scientists have relied on robust software tools for automation which facilitate the testing and refinement of neuroscientific hypotheses. The most widely used tool for cortical thickness studies is the publicly available. surface-based FreeSurfer package. Critical to the adoption of such tools is a demonstration of their reproducibility. validity. and the documentation of specific implementations that are robust across large. diverse imaging datasets. To this end. we have developed the automated. volume-based Advanced Normalization Tools (ANTs) cortical thickness pipeline comprising well-vetted components such as SyGN (multivariate template construction). SyN (image registration). N4 (bias …,True,R5i2QZAAAAAJ:bEWYMUwI8FkC,382,https://www.sciencedirect.com/science/article/pii/S1053811914004091,9816678690918329539,/scholar?cites=9816678690918329539,,,https://files.osf.io/v1/resources/zh8bw/providers/osfstorage/572a75f9594d9001e544be84?action=download&version=1&mode=render&direct,0,0,0
1278581,The mPower study. Parkinson disease mobile data collected using ResearchKit,2016,Brian M Bot and Christine Suver and Elias Chaibub Neto and Michael Kellen and Arno Klein and Christopher Bare and Megan Doerr and Abhishek Pratap and John Wilbanks and E Ray Dorsey and Stephen H Friend and Andrew D Trister,3,Scientific data,1,1-9,Nature Publishing Group,Current measures of health and disease are often insensitive. episodic. and subjective. Further. these measures generally are not designed to provide meaningful feedback to individuals. The impact of high-resolution activity data collected from mobile phones is only beginning to be explored. Here we present data from mPower. a clinical observational study about Parkinson disease conducted purely through an iPhone app interface. The study interrogated aspects of this movement disorder through surveys and frequent sensor-based recordings from participants with and without Parkinson disease. Benefitting from large enrollment and repeated measurements on many individuals. these data may help establish baseline variability of real-world activity measurement collected via mobile phones. and ultimately may lead to quantification of the ebbs-and-flows of Parkinson symptoms. App source code for these data …,True,R5i2QZAAAAAJ:zA6iFVUQeVQC,327,https://www.nature.com/articles/sdata201611,14471769769260198336,/scholar?cites=14471769769260198336,,,https://www.nature.com/articles/sdata201611,0,0,0
1278582,Evaluation of volume-based and surface-based brain image registration methods,2010,Arno Klein and Satrajit S Ghosh and Brian Avants and BT Thomas Yeo and Bruce Fischl and Babak Ardekani and James C Gee and J John Mann and Ramin V Parsey,51,Neuroimage,1,214-220,Academic Press,Establishing correspondences across brains for the purposes of comparison and group analysis is almost universally done by registering images to one another either directly or via a template. However. there are many registration algorithms to choose from. A recent evaluation of fully automated nonlinear deformation methods applied to brain image registration was restricted to volume-based methods. The present study is the first that directly compares some of the most accurate of these volume registration methods with surface registration methods. as well as the first study to compare registrations of whole-head and brain-only (de-skulled) images. We used permutation tests to compare the overlap or Hausdorff distance performance for more than 16.000 registrations between 80 manually labeled brain images. We compared every combination of volume-based and surface-based labels. registration. and …,True,R5i2QZAAAAAJ:2osOgNQ5qMEC,254,https://www.sciencedirect.com/science/article/pii/S105381191000114X,10933934396609667214,/scholar?cites=10933934396609667214,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2862732/,0,0,0
1278583,Mindboggling morphometry of human brains,2017,Arno Klein and Satrajit S Ghosh and Forrest S Bao and Joachim Giard and Yrjö Häme and Eliezer Stavsky and Noah Lee and Brian Rossa and Martin Reuter and Elias Chaibub Neto and Anisha Keshavan,13,PLoS computational biology,2,e1005350,Public Library of Science,Mindboggle (http://mindboggle.info) is an open source brain morphometry platform that takes in preprocessed T1-weighted MRI data and outputs volume. surface. and tabular data containing label. feature. and shape information for further analysis. In this article. we document the software and demonstrate its use in studies of shape variation in healthy and diseased humans. The number of different shape measures and the size of the populations make this the largest and most detailed shape analysis of human brains ever conducted. Brain image morphometry shows great potential for providing much-needed biological markers for diagnosing. tracking. and predicting progression of mental health disorders. Very few software algorithms provide more than measures of volume and cortical thickness. while more subtle shape measures may provide more sensitive and specific biomarkers. Mindboggle computes a variety of (primarily surface-based) shapes: area. volume. thickness. curvature. depth. Laplace-Beltrami spectra. Zernike moments. etc. We evaluate Mindboggle’s algorithms using the largest set of manually labeled. publicly available brain images in the world and compare them against state-of-the-art algorithms where they exist. All data. code. and results of these evaluations are publicly available.,True,R5i2QZAAAAAJ:abG-DnoFyZgC,192,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005350,15633303636005040382,/scholar?cites=15633303636005040382,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005350,0,0,0
1278584,An open resource for transdiagnostic research in pediatric mental health and learning disorders,2017,Lindsay M Alexander and Jasmine Escalera and Lei Ai and Charissa Andreotti and Karina Febre and Alexander Mangone and Natan Vega-Potler and Nicolas Langer and Alexis Alexander and Meagan Kovacs and Shannon Litke and Bridget O'hagan and Jennifer Andersen and Batya Bronstein and Anastasia Bui and Marijayne Bushey and Henry Butler and Victoria Castagna and Nicolas Camacho and Elisha Chan and Danielle Citera and Jon Clucas and Samantha Cohen and Sarah Dufek and Megan Eaves and Brian Fradera and Judith Gardner and Natalie Grant-Villegas and Gabriella Green and Camille Gregory and Emily Hart and Shana Harris and Megan Horton and Danielle Kahn and Katherine Kabotyanski and Bernard Karmel and Simon P Kelly and Kayla Kleinman and Bonhwang Koo and Eliza Kramer and Elizabeth Lennon and Catherine Lord and Ginny Mantello and Amy Margolis and Kathleen R Merikangas and Judith Milham and Giuseppe Minniti and Rebecca Neuhaus and Alexandra Levine and Yael Osman and Lucas C Parra and Ken R Pugh and Amy Racanello and Anita Restrepo and Tian Saltzman and Batya Septimus and Russell Tobe and Rachel Waltz and Anna Williams and Anna Yeo and Francisco X Castellanos and Arno Klein and Tomas Paus and Bennett L Leventhal and R Cameron Craddock and Harold S Koplewicz and Michael P Milham,4,Scientific data,1,1-26,Nature Publishing Group,Technological and methodological innovations are equipping researchers with unprecedented capabilities for detecting and characterizing pathologic processes in the developing human brain. As a result. ambitions to achieve clinically useful tools to assist in the diagnosis and management of mental health and learning disorders are gaining momentum. To this end. it is critical to accrue large-scale multimodal datasets that capture a broad range of commonly encountered clinical psychopathology. The Child Mind Institute has launched the Healthy Brain Network (HBN). an ongoing initiative focused on creating and sharing a biobank of data from 10.000 New York area participants (ages 5–21). The HBN Biobank houses data about psychiatric. behavioral. cognitive. and lifestyle phenotypes. as well as multimodal brain imaging (resting and naturalistic viewing fMRI. diffusion MRI. morphometric MRI …,True,R5i2QZAAAAAJ:P5F9QuxV20EC,132,https://www.nature.com/articles/sdata2017181,16151709766958913295,/scholar?cites=16151709766958913295,,,https://www.nature.com/articles/sdata2017181,0,0,0
1278585,Mindboggle: automated brain labeling with multiple atlases,2005,Arno Klein and Brett Mensh and Satrajit Ghosh and Jason Tourville and Joy Hirsch,5,BMC medical imaging,1,1-14,BioMed Central,To make inferences about brain structures or activity across multiple individuals. one first needs to determine the structural correspondences across their image data. We have recently developed Mindboggle as a fully automated. feature-matching approach to assign anatomical labels to cortical structures and activity in human brain MRI data. Label assignment is based on structural correspondences between labeled atlases and unlabeled image data. where an atlas consists of a set of labels manually assigned to a single brain image. In the present work. we study the influence of using variable numbers of individual atlases to nonlinearly label human brain image data. Each brain image voxel of each of 20 human subjects is assigned a label by each of the remaining 19 atlases using Mindboggle. The most common label is selected and is given a confidence rating based on the number of atlases that assigned that label. The automatically assigned labels for each subject brain are compared with the manual labels for that subject (its atlas). Unlike recent approaches that transform subject data to a labeled. probabilistic atlas space (constructed from a database of atlases). Mindboggle labels a subject by each atlas in a database independently. When Mindboggle labels a human subject's brain image with at least four atlases. the resulting label agreement with coregistered manual labels is significantly higher than when only a single atlas is used. Different numbers of atlases provide significantly higher label agreements for individual brain regions. Increasing the number of reference brains used to automatically label a human subject brain improves …,True,R5i2QZAAAAAJ:d1gkVwhDpl0C,115,https://bmcmedimaging.biomedcentral.com/articles/10.1186/1471-2342-5-7,6768776169165176213,/scholar?cites=6768776169165176213,,,https://bmcmedimaging.biomedcentral.com/articles/10.1186/1471-2342-5-7,0,0,0
1278586,Mindboggle: a scatterbrained approach to automate brain labeling,2005,Arno Klein and Joy Hirsch,24,,2,261-280,Academic Press,Mindboggle (http://www.binarybottle.com/mindboggle.html) is a fully automated. feature matching approach to label cortical structures and activity anatomically in human brain MRI data. This approach does not assume that the existence of component structures and their relative spatial relationship is preserved from brain to brain. but instead disassembles a labeled atlas and reassembles its pieces to match corresponding pieces in an unlabeled subject brain before labeling. Mindboggle: (1) converts linearly coregistered subject and atlas MRI data into sulcus pieces. (2) matches each atlas piece with a combination of subject pieces by minimizing a cost function. (3) transforms atlas label boundaries to the matching subject pieces. (4) warps atlas labels to their transformed boundaries. and (5) propagates labels to fill remaining gaps in a mask derived from the subject brain. We compared Mindboggle with four …,True,R5i2QZAAAAAJ:u-x6o8ySG0sC,88,https://www.sciencedirect.com/science/article/pii/S1053811904005415,10158760548438100950,/scholar?cites=10158760548438100950,,,http://www.fmri.org/publications/Klein%20&%20Hirsch%202005.pdf,0,0,0
1278587,Caste-dependent sleep of worker honey bees,2008,Barrett A Klein and Kathryn M Olzsowy and Arno Klein and Katharine M Saunders and Thomas D Seeley,211,Journal of Experimental Biology,18,3028-3040,The Company of Biologists Ltd,Sleep is a dynamic phenomenon that changes throughout an organism9s lifetime. relating to possible age- or task-associated changes in health. learning ability. vigilance and fitness. Sleep has been identified experimentally in many animals. including honey bees (Apis mellifera). As worker bees age they change castes. typically performing a sequence of different task sets (as `cell cleaners9. `nurse bees9. `food storers9 and `foragers9). Belonging to a caste could differentially impact the duration. constitution and periodicity of a bee9s sleep. We observed individually marked bees within observation hives to determine caste dependent patterns of sleep behavior. We conducted three studies to investigate the duration and periodicity of sleep when bees were outside comb cells. as well as duration of potential sleep when bees were immobile inside cells. All four worker castes we examined exhibited a sleep state …,True,R5i2QZAAAAAJ:9yKSN-GCB0IC,68,https://jeb.biologists.org/content/211/18/3028?utm_source=TrendMD&utm_medium=cpc&utm_campaign=J_Exp_Biol_TrendMD_0,17649913453570263482,/scholar?cites=17649913453570263482,,,https://kops.uni-konstanz.de/bitstream/handle/123456789/17272/Klein%20etal.pdf?sequence=2,0,0,0
1278588,Supervised pattern classification based on optimum‐path forest,2009,Joao P Papa and Alexandre X Falcao and Celso TN Suzuki,19,International Journal of Imaging Systems and Technology,2,120-131,Wiley Subscription Services. Inc.. A Wiley Company,We present a supervised classification method which represents each class by one or more optimum‐path trees rooted at some key samples. called prototypes. The training samples are nodes of a complete graph. whose arcs are weighted by the distances between the feature vectors of their nodes. Prototypes are identified in all classes and the minimization of a connectivity function by dynamic programming assigns to each training sample a minimum‐cost path from its most strongly connected prototype. This competition among prototypes partitions the graph into an optimum‐path forest rooted at them. The class of the samples in an optimum‐path tree is assumed to be the same of its root. A test sample is classified similarly. by identifying which tree would contain it. if the sample were part of the training set. By choice of the graph model and connectivity function. one can devise other optimum‐path forest …,True,8hU3dn8AAAAJ:u-x6o8ySG0sC,460,https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.20188,17763487885858384834,/scholar?cites=17763487885858384834,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.324.4169&rep=rep1&type=pdf,0,0,0
1278589,BBA: a binary bat algorithm for feature selection,2012,Rodrigo YM Nakamura and Luis AM Pereira and Kelton A Costa and Douglas Rodrigues and João P Papa and X-S Yang,,,,291-297,IEEE,Feature selection aims to find the most important information from a given set of features. As this task can be seen as an optimization problem. the combinatorial growth of the possible solutions may be in-viable for a exhaustive search. In this paper we propose a new nature-inspired feature selection technique based on the bats behaviour. which has never been applied to this context so far. The wrapper approach combines the power of exploration of the bats together with the speed of the Optimum-Path Forest classifier to find the set of features that maximizes the accuracy in a validating set. Experiments conducted in five public datasets have demonstrated that the proposed approach can outperform some well-known swarm-based techniques.,True,8hU3dn8AAAAJ:artPoR2Yc-kC,347,https://ieeexplore.ieee.org/abstract/document/6382769/,12540465604600286598,/scholar?cites=12540465604600286598,,,https://www.academia.edu/download/46019270/BBA_A_Binary_Bat_Algorithm_for_Feature_S20160528-5925-tvv15j.pdf,0,0,0
1278590,Efficient supervised optimum-path forest classification for large datasets,2012,João P Papa and Alexandre X Falcão and Victor Hugo C De Albuquerque and João Manuel RS Tavares,45,Pattern Recognition,1,512-520,Pergamon,Today data acquisition technologies come up with large datasets with millions of samples for statistical analysis. This creates a tremendous challenge for pattern recognition techniques. which need to be more efficient without losing their effectiveness. We have tried to circumvent the problem by reducing it into the fast computation of an optimum-path forest (OPF) in a graph derived from the training samples. In this forest. each class may be represented by multiple trees rooted at some representative samples. The forest is a classifier that assigns to a new sample the label of its most strongly connected root. The methodology has been successfully used with different graph topologies and learning techniques. In this work. we have focused on one of the supervised approaches. which has offered considerable advantages over Support Vector Machines and Artificial Neural Networks to handle large datasets. We …,True,8hU3dn8AAAAJ:aqlVkmm33-oC,261,https://www.sciencedirect.com/science/article/pii/S0031320311003013,14775919174136080179,/scholar?cites=14775919174136080179,,,https://web.fe.up.pt/~tavares/downloads/publications/artigos/PR-45(1)_512-520_2012.pdf,0,0,0
1278591,A genetic programming framework for content-based image retrieval,2009,Ricardo da S Torres and Alexandre X Falcão and Marcos A Gonçalves and João P Papa and Baoping Zhang and Weiguo Fan and Edward A Fox,42,Pattern Recognition,2,283-292,Pergamon,The effectiveness of content-based image retrieval (CBIR) systems can be improved by combining image features or by weighting image similarities. as computed from multiple feature vectors. However. feature combination do not make sense always and the combined similarity function can be more complex than weight-based functions to better satisfy the users’ expectations. We address this problem by presenting a Genetic Programming framework to the design of combined similarity functions. Our method allows nonlinear combination of image similarities and is validated through several experiments. where the images are retrieved based on the shape of their objects. Experimental results demonstrate that the GP framework is suitable for the design of effective combinations functions.,True,8hU3dn8AAAAJ:u5HHmVD_uO8C,231,https://www.sciencedirect.com/science/article/pii/S0031320308001623,11502225751451488786,/scholar?cites=11502225751451488786,,,https://www.academia.edu/download/43973821/A_genetic_programming_framework_for_cont20160321-26872-13thw83.pdf,0,0,0
1278592,A wrapper approach for feature selection based on bat algorithm and optimum-path forest,2014,Douglas Rodrigues and Luís AM Pereira and Rodrigo YM Nakamura and Kelton AP Costa and Xin-She Yang and André N Souza and João Paulo Papa,41,Expert Systems with Applications,5,2250-2258,Pergamon,Besides optimizing classifier predictive performance and addressing the curse of the dimensionality problem. feature selection techniques support a classification model as simple as possible. In this paper. we present a wrapper feature selection approach based on Bat Algorithm (BA) and Optimum-Path Forest (OPF). in which we model the problem of feature selection as an binary-based optimization technique. guided by BA using the OPF accuracy over a validating set as the fitness function to be maximized. Moreover. we present a methodology to better estimate the quality of the reduced feature set. Experiments conducted over six public datasets demonstrated that the proposed approach provides statistically significant more compact sets and. in some cases. it can indeed improve the classification effectiveness.,True,8hU3dn8AAAAJ:abG-DnoFyZgC,192,https://www.sciencedirect.com/science/article/pii/S0957417413007574,3562789976688345050,/scholar?cites=3562789976688345050,,,,0,0,0
1278593,Computational methods for the image segmentation of pigmented skin lesions: a review,2016,Roberta B Oliveira and E Mercedes Filho and Zhen Ma and João P Papa and Aledir S Pereira and João Manuel RS Tavares,131,,,127-141,Elsevier,Because skin cancer affects millions of people worldwide. computational methods for the segmentation of pigmented skin lesions in images have been developed in order to assist dermatologists in their diagnosis. This paper aims to present a review of the current methods. and outline a comparative analysis with regards to several of the fundamental steps of image processing. such as image acquisition. pre-processing and segmentation.Techniques that have been proposed to achieve these tasks were identified and reviewed. As to the image segmentation task. the techniques were classified according to their principle.The techniques employed in each step are explained. and their strengths and weaknesses are identified. In addition. several of the reviewed techniques are applied to macroscopic and dermoscopy images in order to exemplify their results …,True,8hU3dn8AAAAJ:PR6Y55bgFSsC,150,https://www.sciencedirect.com/science/article/pii/S0169260716303418,15839832762737938934,/scholar?cites=15839832762737938934,,,https://repositorio.unesp.br/bitstream/handle/11449/161573/WOS000377300100012.pdf?sequence=1,0,0,0
1278594,BCS: A binary cuckoo search algorithm for feature selection,2013,Douglas Rodrigues and Luis AM Pereira and TNS Almeida and João Paulo Papa and AN Souza and Caio CO Ramos and Xin-She Yang,,,,465-468,IEEE,Feature selection has been actively pursued in the last years. since to find the most discriminative set of features can enhance the recognition rates and also to make feature extraction faster. In this paper. the propose a new feature selection called Binary Cuckoo Search. which is based on the behavior of cuckoo birds. The experiments were carried out in the context of theft detection in power distribution systems in two datasets obtained from a Brazilian electrical power company. and have demonstrated the robustness of the proposed technique against with several others nature-inspired optimization techniques.,True,8hU3dn8AAAAJ:1sJd4Hv_s6UC,150,https://ieeexplore.ieee.org/abstract/document/6571881/,1464040473261531364,/scholar?cites=1464040473261531364,,,https://www.academia.edu/download/48821397/binary_cuckoo_search.pdf,0,0,0
1278595,ECG arrhythmia classification based on optimum-path forest,2013,Eduardo José da S Luz and Thiago M Nunes and Victor Hugo C De Albuquerque and Joao P Papa and David Menotti,40,Expert Systems with Applications,9,3561-3573,Pergamon,An important tool for the heart disease diagnosis is the analysis of electrocardiogram (ECG) signals. since the non-invasive nature and simplicity of the ECG exam. According to the application. ECG data analysis consists of steps such as preprocessing. segmentation. feature extraction and classification aiming to detect cardiac arrhythmias (i.e.. cardiac rhythm abnormalities). Aiming to made a fast and accurate cardiac arrhythmia signal classification process. we apply and analyze a recent and robust supervised graph-based pattern recognition technique. the optimum-path forest (OPF) classifier. To the best of our knowledge. it is the first time that OPF classifier is used to the ECG heartbeat signal classification task. We then compare the performance (in terms of training and testing time. accuracy. specificity. and sensitivity) of the OPF classifier to the ones of other three well-known expert system classifiers. i.e …,True,8hU3dn8AAAAJ:ZHo1McVdvXMC,120,https://www.sciencedirect.com/science/article/pii/S0957417412013048,13647771709126170501,/scholar?cites=13647771709126170501,,,https://www.repositorio.ufop.br/jspui/bitstream/123456789/4369/1/ARTIGO_ECGArrhythmiaClassification.pdf,0,0,0
1278596,A new approach for nontechnical losses detection based on optimum-path forest,2010,Caio César Oba Ramos and Andrá Nunes de Sousa and Joao Paulo Papa and Alexandre Xavier Falcao,26,IEEE Transactions on Power Systems,1,181-189,IEEE,Nowadays. fraud detection is important to avoid nontechnical energy losses. Various electric companies around the world have been faced with such losses. mainly from industrial and commercial consumers. This problem has traditionally been dealt with using artificial intelligence techniques. although their use can result in difficulties such as a high computational burden in the training phase and problems with parameter optimization. A recently-developed pattern recognition technique called optimum-path forest (OPF). however. has been shown to be superior to state-of-the-art artificial intelligence techniques. In this paper. we proposed to use OPF for nontechnical losses detection. as well as to apply its learning and pruning algorithms to this purpose. Comparisons against neural networks and other techniques demonstrated the robustness of the OPF with respect to commercial losses automatic identification.,True,8hU3dn8AAAAJ:zYLM7Y9cAGgC,119,https://ieeexplore.ieee.org/abstract/document/5530391/,9485380988527947344,/scholar?cites=9485380988527947344,,,,0,0,0
1278597,A novel algorithm for feature selection using harmony search and its application for non-technical losses detection,2011,Caio CO Ramos and André N Souza and Giovani Chiachia and Alexandre X Falcão and João P Papa,37,Computers & Electrical Engineering,6,886-894,Pergamon,Finding an optimal subset of features that maximizes classification accuracy is still an open problem. In this paper. we exploit the speed of the Harmony Search algorithm and the Optimum-Path Forest classifier in order to propose a new fast and accurate approach for feature selection. Comparisons to some other pattern recognition and feature selection techniques showed that the proposed hybrid algorithm for feature selection outperformed them. The experiments were carried out in the context of identifying non-technical losses in power distribution systems.,True,8hU3dn8AAAAJ:0EnyYjriUFMC,118,https://www.sciencedirect.com/science/article/pii/S0045790611001479,13826496050533526185,/scholar?cites=13826496050533526185,,,https://www.academia.edu/download/50120096/A_novel_algorithm_for_feature_selection_20161105-6417-1htdrxv.pdf,0,0,0
1278598,Computational methods for pigmented skin lesion classification in images: review and future trends,2018,Roberta B Oliveira and Joao P Papa and Aledir S Pereira and Joao Manuel RS Tavares,29,,3,613-636,Springer London,Skin cancer is considered as one of the most common types of cancer in several countries. and its incidence rate has increased in recent years. Melanoma cases have caused an increasing number of deaths worldwide. since this type of skin cancer is the most aggressive compared to other types. Computational methods have been developed to assist dermatologists in early diagnosis of skin cancer. An overview of the main and current computational methods that have been proposed for pattern analysis and pigmented skin lesion classification is addressed in this review. In addition. a discussion about the application of such methods. as well as future trends. is also provided. Several methods for feature extraction from both macroscopic and dermoscopic images and models for feature selection are introduced and discussed. Furthermore. classification algorithms and evaluation procedures are described …,True,8hU3dn8AAAAJ:35r97b3x0nAC,115,https://link.springer.com/article/10.1007/s00521-016-2482-6,5498414223764108844,/scholar?cites=5498414223764108844,,,https://repositorio.unesp.br/bitstream/handle/11449/163796/WOS000424058500001.pdf?sequence=1,0,0,0
1278599,Emission tomography: the fundamentals of PET and SPECT,2004,Miles N Wernick and John N Aarsvold,,,,,Elsevier,PET and SPECT are two of today’s most important medical-imaging methods. providing images that reveal subtle information about physiological processes in humans and animals. Emission Tomography: The Fundamentals of PET and SPECT explains the physics and engineering principles of these important functional-imaging methods. The technology of emission tomography is covered in detail. including historical origins. scientific and mathematical foundations. imaging systems and their components. image reconstruction and analysis. simulation techniques. and clinical and laboratory applications. The book describes the state of the art of emission tomography. including all facets of conventional SPECT and PET. as well as contemporary topics such as iterative image reconstruction. small-animal imaging. and PET/CT systems. This book is intended as a textbook and reference resource for graduate students. researchers. medical physicists. biomedical engineers. and professional engineers and physicists in the medical-imaging industry. Thorough tutorials of fundamental and advanced topics are presented by dozens of the leading researchers in PET and SPECT. SPECT has long been a mainstay of clinical imaging. and PET is now one of the world’s fastest growing medical imaging techniques. owing to its dramatic contributions to cancer imaging and other applications. Emission Tomography: The Fundamentals of PET and SPECT is an essential resource for understanding the technology of SPECT and PET. the most widely used forms of molecular imaging.* Contains thorough tutorial treatments. coupled with coverage of advanced …,True,JndBOCoAAAAJ:ZfRJV9d4-WMC,750,http://books.google.com/books?hl=en&lr=&id=R5slur_hdfEC&oi=fnd&pg=PP1&dq=info:Pm3SSD1ceu8J:scholar.google.com&ots=zZ6k4HP4J1&sig=Wuqp9xNaSgXfiiOFzcoIw2-Ggi8,17256206340507987262,/scholar?cites=17256206340507987262,,,,0,0,0
1278600,A support vector machine approach for detection of microcalcifications,2002,Issam El-Naqa and Yongyi Yang and Miles N Wernick and Nikolas P Galatsanos and Robert M Nishikawa,21,IEEE transactions on medical imaging,12,1552-1563,IEEE,We investigate an approach based on support vector machines (SVMs) for detection of microcalcification (MC) clusters in digital mammograms. and propose a successive enhancement learning scheme for improved performance. SVM is a machine-learning method. based on the principle of structural risk minimization. which performs well when applied to data outside the training set. We formulate MC detection as a supervised-learning problem and apply SVM to develop the detection algorithm. We use the SVM to detect at each location in the image whether an MC is present or not. We tested the proposed method using a database of 76 clinical mammograms containing 1120 MCs. We use free-response receiver operating characteristic curves to evaluate detection performance. and compare the proposed algorithm with several existing methods. In our experiments. the proposed SVM framework outperformed all …,True,JndBOCoAAAAJ:tKAzc9rXhukC,658,https://ieeexplore.ieee.org/abstract/document/1176643/,5611008419426458870,/scholar?cites=5611008419426458870,,,https://www.researchgate.net/profile/Robert_Nishikawa/publication/3221466_A_support_vector_machine_approach_for_detection_of_microcalcifications/links/553fa1ab0cf2736761c04061.pdf,0,0,0
1278601,Spatial relationships in early signaling events of flow-mediated endothelial mechanotransduction,1997,Peter F Davies and Kenneth A Barbee and Michael V Volin and Andre Robotewskyj and Jai Chen and Loren Joseph and Melvin L Griem and Miles N Wernick and Elizabeth Jacobs and Denise C Polacek and Natacha DePaola and Abdul I Barakat,59,,1,527-549,Annual Reviews,Blood flow interactions with the vascular endothelium represent a specialized example of mechanical regulation of cell function that has important physiological and pathological cardiovascular consequences. The endothelial monolayer in vivo acts as a signal transduction interface for forces associated with flowing blood (hemodynamic forces) in the acute regulation of artery tone and chronic structural remodeling of arteries. including the pathology of atherosclerosis. Mechanisms related to spatial relationships at the cell surfaces and throughout the cell that influence flow-mediated endothelial mechanotransduction are discussed. In particular. flow-mediated ion channel activation and cytoskeletal dynamics are considered in relation to topographic analyses of the luminal and abluminal surfaces of living endothelial cells.,True,JndBOCoAAAAJ:kzcrU_BdoSEC,386,https://www.annualreviews.org/doi/abs/10.1146/annurev.physiol.59.1.527,15218674699078228006,/scholar?cites=15218674699078228006,,,https://www.academia.edu/download/47616295/Davies_PF_Barbee_KA_Volin_MV_et_al._Spat20160729-32167-qaoh70.pdf,0,0,0
1278602,A similarity learning approach to content-based image retrieval: application to digital mammography,2004,Issam El-Naqa and Yongyi Yang and Nikolas P Galatsanos and Robert M Nishikawa and Miles N Wernick,23,IEEE transactions on medical imaging,10,1233-1244,IEEE,In this paper. we describe an approach to content-based retrieval of medical images from a database. and provide a preliminary demonstration of our approach as applied to retrieval of digital mammograms. Content-based image retrieval (CBIR) refers to the retrieval of images from a database using information derived from the images themselves. rather than solely from accompanying text indices. In the medical-imaging context. the ultimate aim of CBIR is to provide radiologists with a diagnostic aid in the form of a display of relevant past cases. along with proven pathology and other suitable information. CBIR may also be useful as a training tool for medical students and residents. The goal of information retrieval is to recall from a database information that is relevant to the user's query. The most challenging aspect of CBIR is the definition of relevance (similarity). which is used to guide the retrieval machine. In this …,True,JndBOCoAAAAJ:_Re3VWB3Y0AC,339,https://ieeexplore.ieee.org/abstract/document/1339430/,9261138953600811920,/scholar?cites=9261138953600811920,,,https://www.academia.edu/download/38113445/Approach_to_Content-Based.pdf,0,0,0
1278603,Machine learning in medical imaging,2010,Miles N Wernick and Yongyi Yang and Jovan G Brankov and Grigori Yourganov and Stephen C Strother,27,IEEE signal processing magazine,4,25-38,IEEE,This article will discuss very different ways of using machine learning that may be less familiar. and we will demonstrate through examples the role of these concepts in medical imaging. Although the term machine learning is relatively recent. the ideas of machine learning have been applied to medical imaging for decades. perhaps most notably in the areas of computer-aided diagnosis (CAD) and functional brain mapping. We will not attempt in this brief article to survey the rich literature of this field. Instead our goals will be 1) to acquaint the reader with some modern techniques that are now staples of the machine-learning field and 2) to illustrate how these techniques can be employed in various ways in medical imaging.,True,JndBOCoAAAAJ:umqufdRvDiIC,291,https://ieeexplore.ieee.org/abstract/document/5484160/,4720480293885063922,/scholar?cites=4720480293885063922,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4220564/,0,0,0
1278604,Multiple-image radiography,2003,Miles N Wernick and Oliver Wirjadi and Dean Chapman and Zhong Zhong and Nikolas P Galatsanos and Yongyi Yang and Jovan G Brankov and Oral Oltulu and Mark A Anastasio and Carol Muehleman,48,Physics in Medicine & Biology,23,3875,IOP Publishing,Conventional radiography produces a single image of an object by measuring the attenuation of an x-ray beam passing through it. When imaging weakly absorbing tissues. x-ray attenuation may be a suboptimal signature of disease-related information. In this paper we describe a new phase-sensitive imaging method. called multiple-image radiography (MIR). which is an improvement on a prior technique called diffraction-enhanced imaging (DEI). This paper elaborates on our initial presentation of the idea in Wernick et al (2002 Proc. Int. Symp. Biomed. Imaging pp 129–32). MIR simultaneously produces several images from a set of measurements made with a single x-ray beam. Specifically. MIR yields three images depicting separately the effects of refraction. ultra-small-angle scatter and attenuation by the object. All three images have good contrast. in part because they are virtually immune from degradation due …,True,JndBOCoAAAAJ:tzM49s52ZIMC,264,https://iopscience.iop.org/article/10.1088/0031-9155/48/23/006/meta,5276207470326276479,/scholar?cites=5276207470326276479,,,https://pdfs.semanticscholar.org/250d/0270998ce9310eac6b1c1e7c9610afb4587e.pdf,0,0,0
1278605,Relevance vector machine for automatic detection of clustered microcalcifications,2005,Liyang Wei and Yongyi Yang and Robert M Nishikawa and Miles N Wernick and Alexandra Edwards,24,IEEE transactions on medical imaging,10,1278-1285,IEEE,Clustered microcalcifications (MC) in mammograms can be an important early sign of breast cancer in women. Their accurate detection is important in computer-aided detection (CADe). In this paper. we propose the use of a recently developed machine-learning technique - relevance vector machine (RVM) - for detection of MCs in digital mammograms. RVM is based on Bayesian estimation theory. of which a distinctive feature is that it can yield a sparse decision function that is defined by only a very small number of so-called relevance vectors. By exploiting this sparse property of the RVM. we develop computerized detection algorithms that are not only accurate but also computationally efficient for MC detection in mammograms. We formulate MC detection as a supervised-learning problem. and apply RVM as a classifier to determine at each location in the mammogram if an MC object is present or not. To increase …,True,JndBOCoAAAAJ:35r97b3x0nAC,195,https://ieeexplore.ieee.org/abstract/document/1514548/,11711734944971501001,/scholar?cites=11711734944971501001,,,,0,0,0
1278606,Extraction of extinction. refraction and absorption properties in diffraction enhanced imaging,2003,Oral Oltulu and Zhong Zhong and Moumen Hasnah and Miles N Wernick and Dean Chapman,36,Journal of Physics D: Applied Physics,17,2152,IOP Publishing,Diffraction enhanced imaging is a radiographic technique that derives contrast from an object's x-ray absorption. refraction gradient and small angle scatter properties (extinction). In prior work. images obtained using two analyser settings were combined to obtain refraction angle and apparent absorption images. A more general method of determining independently the refraction. absorption and extinction of the object is presented. This approach has been used to model the transmission. refraction and scatter distribution of the sample and to visualize these three physical phenomena separately.,True,JndBOCoAAAAJ:2KloaMYe4IUC,161,https://iopscience.iop.org/article/10.1088/0022-3727/36/17/320/meta,1234994342580241583,/scholar?cites=1234994342580241583,,,https://www.academia.edu/download/48423512/Extraction_of_extinction_refraction_and_20160829-15059-19r5z81.pdf,0,0,0
1278607,Prostate cancer localization with multispectral MRI using cost-sensitive support vector machines and conditional random fields,2010,Yusuf Artan and Masoom A Haider and Deanna L Langer and Theodorus H Van der Kwast and Andrew J Evans and Yongyi Yang and Miles N Wernick and John Trachtenberg and Imam Samil Yetik,19,IEEE Transactions on Image Processing,9,2444-2455,IEEE,Prostate cancer is a leading cause of cancer death for men in the United States. Fortunately. the survival rate for early diagnosed patients is relatively high. Therefore.  in vivo  imaging plays an important role for the detection and treatment of the disease. Accurate prostate cancer localization with noninvasive imaging can be used to guide biopsy. radiotheraphy. and surgery as well as to monitor disease progression. Magnetic resonance imaging (MRI) performed with an endorectal coil provides higher prostate cancer localization accuracy. when compared to transrectal ultrasound (TRUS). However. in general. a single type of MRI is not sufficient for reliable tumor localization. As an alternative. multispectral MRI. i.e.. the use of multiple MRI-derived datasets. has emerged as a promising noninvasive imaging technique for the localization of prostate cancer; however almost all studies are with human readers. There is a …,True,JndBOCoAAAAJ:MLfJN-KU85MC,144,https://ieeexplore.ieee.org/abstract/document/5550479/,15170397567537273310,/scholar?cites=15170397567537273310,,,,0,0,0
1278608,Fast spatio-temporal image reconstruction for dynamic PET,1999,Miles N Wernick and E James Infusino and Milos Milosevic,18,,3,185-195,IEEE,In tomographic imaging. dynamic images are typically obtained by reconstructing the frames of a time sequence independently. one by one. A disadvantage of this frame-by-frame reconstruction approach is that it fails to account. For temporal correlations in the signal. Ideally. one should treat the entire image sequence as a single spatio-temporal signal. However. the resulting reconstruction task becomes computationally intensive. Fortunately. as the authors show in this paper. the spatio-temporal reconstruction problem call be greatly simplified by first applying a temporal Karhunen-Loeve (KL) transformation to the imaging equation. The authors show that if the regularization operator is chosen to be separable into space and time components. penalized weighted least squares reconstruction of the entire image sequence is approximately equivalent to frame-by-frame reconstruction in the space-KL domain. By this …,True,JndBOCoAAAAJ:evX43VCCuoAC,144,https://ieeexplore.ieee.org/abstract/document/764885/,3866107181282265201,/scholar?cites=3866107181282265201,,,https://www.researchgate.net/profile/Miles_Wernick/publication/12934709_Fast_spatio-temporal_image_reconstruction_for_dynamic_PET/links/572f607c08aeb1c73d13a25b.pdf,0,0,0
1278609,Supervised and unsupervised methods for prostate cancer segmentation with multispectral MRI,2010,Sedat Ozer and Deanna L Langer and Xin Liu and Masoom A Haider and Theodorus H Van der Kwast and Andrew J Evans and Yongyi Yang and Miles N Wernick and Imam S Yetik,37,Medical physics,4,1873-1883,American Association of Physicists in Medicine,Magnetic resonance imaging (MRI) has been proposed as a promising alternative to transrectal ultrasound for the detection and localization of prostate cancer and fusing the information from multispectral MR images is currently an active research area. In this study. the goal is to develop automated methods that combine the pharmacokinetic parameters derived from dynamic contrast enhanced (DCE) MRI with quantitative  MRI and diffusion weighted imaging (DWI) in contrast to most of the studies which were performed with human readers. The main advantages of the automated methods are that the observer variability is removed and easily reproducible results can be efficiently obtained when the methods are applied to a test data. The goal is also to compare the performance of automated supervised and unsupervised methods for prostate cancer localization with multispectral MRI.The …,True,JndBOCoAAAAJ:BUYA1_V_uYcC,143,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3359459,10551416742428853636,/scholar?cites=10551416742428853636,,,https://pdfs.semanticscholar.org/65d6/896da3f332b2ec73d17f0c3e4a106f545fac.pdf,0,0,0
1278610,Hyperspectral imaging for food quality analysis and control,2010,Da-Wen Sun,,,,,Elsevier,Based on the integration of computer vision and spectrscopy techniques. hyperspectral imaging is a novel technology for obtaining both spatial and spectral information on a product. Used for nearly 20 years in the aerospace and military industries. more recently hyperspectral imaging has emerged and matured into one of the most powerful and rapidly growing methods of non-destructive food quality analysis and control. Hyperspectral Imaging for Food Quality Analysis and Control provides the core information about how this proven science can be practically applied for food quality assessment. including information on the equipment available and selection of the most appropriate of those instruments. Additionally. real-world food-industry-based examples are included. giving the reader important insights into the actual application of the science in evaluating food products. Presentation of principles and instruments provides core understanding of how this science performs. as well as guideline on selecting the most appropriate equipment for implementation Includes real-world. practical application to demonstrate the viability and challenges of working with this technology Provides necessary information for making correct determination on use of hyperspectral imaging,True,T0NCdtgAAAAJ:NhqRSupF_l8C,474,http://books.google.com/books?hl=en&lr=&id=FVTbineZq54C&oi=fnd&pg=PP1&dq=info:KiX1CyXerckJ:scholar.google.com&ots=HGJbREPJtM&sig=-s3Dgf8gia651-rYAohvccmCqO8,14532515823290230058,/scholar?cites=14532515823290230058,,,,0,0,0
1278611,Machine vision for color inspection of potatoes and apples,1995,Y Tao and PH Heinemann and Z Varghese and CT Morrow and HJ Sommer Iii,38,Transactions of the ASAE,5,1555-1561,American Society of Agricultural and Biological Engineers,A machine vision system was trained to distinguish between good and greened potatoes and yellow and green Golden Delicious apples. The method of using the HSI (Hue. Saturation. and Intensity) color system proved highly effective for color evaluation and image processing. The vision system achieved over 90% accuracy in inspection of potatoes and apples by representing features with hue histograms and applying multivariate discriminant techniques. Reducing the number of hue bins by selecting significant features only or by summing groups of hue bins increased misclassification by the vision system. Color classification represents an important quality feature evaluation method that needs to be integrated into an overall automated quality inspection and grading system.,True,T0NCdtgAAAAJ:Zph67rFs4hoC,310,https://elibrary.asabe.org/abstract.asp?aid=27982,4116829041376732648,/scholar?cites=4116829041376732648,,,,0,0,0
1278612,Enhancement of food processes by ultrasound: a review,2015,Yang Tao and Da-Wen Sun,55,,4,570-594,Taylor & Francis,In food processing. the applications of ultrasound can be divided into two categories. namely replacing traditional technologies and assisting traditional technologies. In the latter case. the processing efficiency is enhanced and the disadvantageous of traditional technologies during processing are improved. These ultrasonic effects can be defined as ultrasonic enhancement of food processes. This review is focused on the use of ultrasound to enhance various food processes. including extraction. freezing. thawing. brining. oxidation. filtration. and drying/dehydration. The major functions of ultrasound in enhancing these processes and the factors which can affect the ultrasonic enhancement are elucidated. In the meantime. the strategies of modeling these processes enhanced by ultrasound are provided. Future studies should pay more attention to elucidate the ultrasonic effects during freezing. thawing. brining …,True,T0NCdtgAAAAJ:fQNAKQ3IYiAC,197,https://www.tandfonline.com/doi/abs/10.1080/10408398.2012.667849,4338444729628669345,/scholar?cites=4338444729628669345,,,https://www.researchgate.net/profile/Yang_Tao16/publication/262976954_Enhancement_of_Food_Processes_by_Ultrasound_A_Review/links/546aa63b0cf2f5eb18077f20/Enhancement-of-Food-Processes-by-Ultrasound-A-Review.pdf,0,0,0
1278613,Antimicrobial effect of acidified sodium chlorite. sodium chlorite. sodium hypochlorite. and citric acid on Escherichia coli O157: H7 and natural microflora of fresh-cut cilantro,2009,Ana Allende and James McEvoy and Yang Tao and Yaguang Luo,20,Food control,3,230-234,Elsevier,Fresh-cut cilantro is particularly susceptible to microbial growth and. therefore. use of an effective sanitizer on this product is of great importance. The objective of this study was to evaluate the efficacy of different sanitizing treatments on reducing Escherichia coli O157:H7 populations. aerobic mesophilic bacterial. yeast and mould counts on fresh-cut cilantro. Cut cilantro was treated with sodium hypochlorite (SH) at 0.2 g L−1 free chlorine and acidified sodium chlorite (ASC) at 0.1. 0.25. 0.5 and 1 g L−1. along with the components of ASC. i.e.. citric acid (CA) at 6 g L−1 and sodium chlorite (SC) at 1 g L−1. In the present study. it was found that SH inactivated. at maximum. 1–1.3 log cfu g−1 of background or pathogenic microflora present on cut cilantro. However. reductions of more than 3 log cfu g−1 were observed after washing with 1 g L−1 of ASC. Moreover. when lower concentrations of ASC were used (0.25 and 0.5 …,True,T0NCdtgAAAAJ:M3ejUd6NZC8C,188,https://www.sciencedirect.com/science/article/pii/S0956713508001291,7751873158096215555,/scholar?cites=7751873158096215555,,,https://pubag.nal.usda.gov/download/49591/PDF,0,0,0
1278614,Fourier-based separation technique for shape grading of potatoes using machine vision,1995,Y Tao and CT Morrow and Paul Heinz Heinemann and Henry Joseph Sommer III,38,Transactions of the ASAE,3,949-957,American Society of Agricultural and Biological Engineers,A Fourier-based shape separation method was developed for shape grading of potatoes using machine vision for automated inspection. The relationship between object shape and its boundary spectrum values in Fourier domain was explored for shape extraction. A new and fast method of using Greens theorem and boundary Fourier coefficients was given for estimating elongation of an object. A shape separator based on harmonics of the transform was defined for potato shape separation. Tests showed the shape separator was effective and efficient for difficult shape separation. The machine vision system developed has a great potential to assist humans for automated potato grading.,True,T0NCdtgAAAAJ:ULOm3_A8WrAC,186,https://elibrary.asabe.org/abstract.asp?aid=27912,17413136855756231973,/scholar?cites=17413136855756231973,,,,0,0,0
1278615,A novel integrated PCA and FLD method on hyperspectral image feature extraction for cucumber chilling damage inspection,2004,Xuemei Cheng and YR Chen and Yang Tao and CY Wang and MS Kim and AM Lefcourt,47,Transactions of the ASAE,4,1313,American Society of Agricultural and Biological Engineers,High-resolution hyperspectral imaging (HSI) provides an abundance of spectral data for feature analysis in imageprocessing. Usually. the amount of information contained in hyperspectral images is excessive and redundant. and data miningfor waveband selection is needed. In applications such as fruit and vegetable defect inspections. effective spectral combinationand data fusing methods are required in order to select a few optimal wavelengths without losing the crucialinformation in the original hyperspectral data. In this article. we present a novel method that combines principal componentanalysis (PCA) and Fishers linear discriminant (FLD) method to show that the hybrid PCA-FLD method maximizes the representationand classification effects on the extracted new feature bands. The method is applied to the detection of chillinginjury on cucumbers. Based on tests on different types of samples. results show …,True,T0NCdtgAAAAJ:_kc_bZDykSQC,172,https://elibrary.asabe.org/abstract.asp?aid=16565,2612408637967275454,/scholar?cites=2612408637967275454,,,https://pubag.nal.usda.gov/download/9711/PDF,0,0,0
1278616,Method and apparatus for sorting objects by color including stable color transformation,1996,Yang Tao,,,,,,A color sorting apparatus has a singulator section. a color sorter and a conveyor which drops the sorted objects into appropriate collection bins. Objects for sorting are transported on an endless conveyor on wheels through the singulation and color sorting section. An independently adjustable speed belt rotates in the same direction as the wheels and operates to provide a view of each of four sides of the object to an imaging device. The imaging device. such as a camera. supplies red. green and blue signals to an image processor which performs a color transformation and obtains a single composite hue value for each object or piece of fruit to be sorted. Based on a comparison of the hue value to user programmed grading criteria. signals are provided to the conveyor so that the objects are ultimately deposited in appropriate sorting bins. The apparatus also provides one or more of color calibration with respect to …,True,T0NCdtgAAAAJ:YOwf2qJgpHMC,170,https://patents.google.com/patent/US5533628A/en,2924641466589309793,/scholar?cites=2924641466589309793,,,https://patentimages.storage.googleapis.com/ee/19/20/bd28b38e8a0e09/US5533628.pdf,0,0,0
1278617,Ultrasound-assisted extraction of phenolics from wine lees: Modeling. optimization and stability of extracts during storage,2014,Yang Tao and Di Wu and Qing-An Zhang and Da-Wen Sun,21,Ultrasonics sonochemistry,2,706-715,Elsevier,The ultrasound-assisted extraction process of phenolics including anthocyanins from wine lees was modeled and optimized in this research. An ultrasound bath system with the frequency of 40 kHz was used and the acoustic energy density during extraction was identified to 48 W/L. The effects of extraction time. extraction temperature. solvent-to-solid ratio and the solvent composition on the extraction yields of total phenolics and total anthocyanins were taken into account. The extraction process was simulated and optimized by means of artificial neural network (ANN) and genetic algorithm (GA). The constructed ANN models were accurate to predict the extraction yields of both total phenolics and total anthocyanins according to the statistical analysis. Meanwhile. the input space of the ANN models was optimized by GA. so as to maximize the extraction yields. Under the optimal conditions. the experimental yields of …,True,T0NCdtgAAAAJ:5Ul4iDaHHb8C,169,https://www.sciencedirect.com/science/article/pii/S1350417713002162,7806757498826597344,/scholar?cites=7806757498826597344,,,https://www.sciencedirect.com/science/article/pii/S1350417713002162,0,0,0
1278618,Microalgae: A potential alternative to health supplementation for humans,2019,Apurav Krishna Koyande and Kit Wayne Chew and Krishnamoorthy Rambabu and Yang Tao and Dinh-Toi Chu and Pau-Loke Show,8,,1,16-24,Elsevier,Microalgae has been consumed in human diet for thousands of years. It is an under-exploited crop for production of dietary foods. Microalgae cultivation does not compete with land and resources required for traditional crops and has a superior yield compared to terrestrial crops. Its high protein content has exhibited a huge potential to meet the dietary requirements of growing population. Apart from being a source of protein. presence of various bio-active components in microalgae provide an added health benefit. This review describes various microalgal sources of proteins and other bio-active components. One of the heavily studied group of bio-active components are pigments due to their anticarcenogenic. antioxidative and antihypertensive properties. Compared to various plant and floral species. microalgae contain higher amounts of pigments. Microalgal derived proteins have complete Essential Amino Acids …,True,T0NCdtgAAAAJ:rHJHxKgnXwkC,154,https://www.sciencedirect.com/science/article/pii/S2213453018301435,13925005844171384305,/scholar?cites=13925005844171384305,,,https://www.sciencedirect.com/science/article/pii/S2213453018301435,0,0,0
1278619,Prospective head‐movement correction for high‐resolution MRI using an in‐bore optical tracking system,2009,Lei Qin and Peter van Gelderen and John Andrew Derbyshire and Fenghua Jin and Jongho Lee and Jacco A de Zwart and Yang Tao and Jeff H Duyn,62,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,4,924-934,Wiley Subscription Services. Inc.. A Wiley Company,In MRI of the human brain. subject motion is a major cause of magnetic resonance image quality degradation. To compensate for the effects of head motion during data acquisition. an in‐bore optical motion tracking system is proposed. The system comprises two MR‐compatible infrared cameras that are fixed on a holder right above and in front of the head coil. The resulting close proximity of the cameras to the object allows precise tracking of its movement. During image acquisition. the MRI scanner uses this tracking information to prospectively compensate for head motion by adjusting the gradient field direction and radio frequency (RF) phases and frequencies. Experiments performed on subjects demonstrate robust system performance with translation and rotation accuracies of 0.1 mm and 0.15°. respectively. Magn Reson Med. 2009. © 2009 Wiley‐Liss. Inc.,True,T0NCdtgAAAAJ:Wp0gIr-vW9MC,153,https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.22076,6506864451263659322,/scholar?cites=6506864451263659322,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.22076,0,0,0
1278620,Advances in wine aging technologies for enhancing wine quality and accelerating wine aging process,2014,Yang Tao and Juan Francisco García and Da-Wen Sun,54,,6,817-835,Taylor & Francis Group,Wine aging is an important process to produce high-quality wines. Traditionally. wines are aged in oak barrel aging systems. However. due to the disadvantages of the traditional aging technology. such as lengthy time needed. high cost. etc.. innovative aging technologies have been developed. These technologies involve aging wines using wood fragments. application of micro-oxygenation. aging on lees. or application of some physical methods. Moreover. wine bottling can be regarded as the second phase of wine aging and is essential for most wines. Each technology can benefit the aging process from different aspects. Traditional oak barrel aging technology is the oldest and widely accepted technology. The application of wood fragments and physical methods are promising in accelerating aging process artificially. while application of micro-oxygenation and lees is reliable to improve wine quality. This paper …,True,T0NCdtgAAAAJ:B3FOqHPlNUQC,125,https://www.tandfonline.com/doi/abs/10.1080/10408398.2011.609949,5950095657548852995,/scholar?cites=5950095657548852995,,,,0,0,0
1278621,Detecting moving objects. ghosts. and shadows in video streams,2003,Rita Cucchiara and Costantino Grana and Massimo Piccardi and Andrea Prati,25,IEEE Transactions on Pattern Analysis and Machine Intelligence,10,1337-1342,IEEE,Background subtraction methods are widely exploited for moving object detection in videos in many applications. such as traffic monitoring. human motion capture. and video surveillance. How to correctly and efficiently model and update the background model and how to deal with shadows are two of the most distinguishing and challenging aspects of such approaches. The article proposes a general-purpose method that combines statistical assumptions with the object-level knowledge of moving objects. apparent objects (ghosts). and shadows acquired in the processing of the previous frames. Pixels belonging to moving objects. ghosts. and shadows are processed differently in order to supply an object-based selective update. The proposed approach exploits color information for both background subtraction and shadow detection to improve object segmentation and background update. The approach proves …,True,MBy-kecAAAAJ:u5HHmVD_uO8C,2079,https://ieeexplore.ieee.org/abstract/document/1233909/,13707903931037071145,/scholar?cites=13707903931037071145,,,https://opus.lib.uts.edu.au/bitstream/10453/5772/3/2003000355.pdf,0,0,0
1278622,Improving shadow suppression in moving object detection with HSV color information,2001,Rita Cucchiara and Costantino Grana and Massimo Piccardi and Andrea Prati and Stefano Sirotti,,,,334-339,IEEE,Video-surveillance and traffic analysis systems can be heavily improved using vision-based techniques able to extract. manage and track objects in the scene. However. problems arise due to shadows. In particular. moving shadows can affect the correct localization. measurements and detection of moving objects. This work aims to present a technique for shadow detection and suppression used in a system for moving visual object detection and tracking. The major novelty of the shadow detection technique is the analysis carried out in the HSV color space to improve the accuracy in detecting shadows. Signal processing and optic motivations of the approach proposed are described. The integration and exploitation of the shadow detection module into the system are outlined and experimental results are shown and evaluated.,True,MBy-kecAAAAJ:u-x6o8ySG0sC,731,https://ieeexplore.ieee.org/abstract/document/948679/,16382601736780867231,/scholar?cites=16382601736780867231,,,https://www.researchgate.net/profile/Costantino_Grana/publication/3913726_Improving_shadow_suppression_in_moving_object_detection_with_HSV_color_information/links/0fcfd508a4f714d975000000/Improving-shadow-suppression-in-moving-object-detection-with-HSV-color-information.pdf,0,0,0
1278623,Probabilistic posture classification for human-behavior analysis,2005,Rita Cucchiara and Costantino Grana and Andrea Prati and Roberto Vezzani,35,"IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans",1,42-54,IEEE,Computer vision and ubiquitous multimedia access nowadays make feasible the development of a mostly automated system for human-behavior analysis. In this context. our proposal is to analyze human behaviors by classifying the posture of the monitored person and. consequently. detecting corresponding events and alarm situations. like a fall. To this aim. our approach can be divided in two phases: for each frame. the projection histograms (Haritaoglu et al.. 1998) of each person are computed and compared with the probabilistic projection maps stored for each posture during the training phase; then. the obtained posture is further validated exploiting the information extracted by a tracking module in order to take into account the reliability of the classification of the first phase. Moreover. the tracking algorithm is used to handle occlusions. making the system particularly robust even in indoors environments …,True,MBy-kecAAAAJ:d1gkVwhDpl0C,245,https://ieeexplore.ieee.org/abstract/document/1369344/,16816592983505560297,/scholar?cites=16816592983505560297,,,ftp://ftp.prip.tuwien.ac.at/pub/outgoing/zamba/fallpapers/Cucchiara05.pdf,0,0,0
1278624,Detecting objects. shadows and ghosts in video streams by exploiting color and motion information,2001,Rita Cucchiara and Constantino Grana and Massimo Piccardi and Andrea Prati,,,,360-365,IEEE,Many approaches to moving object detection for traffic monitoring and video surveillance proposed in the literature are based on background suppression methods. How to correctly and efficiently update the background model and how to deal with shadows are two of the more distinguishing and challenging features of such approaches. This work presents a general-purpose method for segmentation of moving visual objects (MVO) based on an object-level classification in MVO. ghosts and shadows. Background suppression needs the background model to be estimated and updated: we use motion and shadow information to selectively exclude from the background model MVO and their shadows. while retaining ghosts. The color information (in the HSV color space) is exploited to shadow suppression and. consequently. to enhance both MVO segmentation and background update.,True,MBy-kecAAAAJ:f2IySw72cVMC,219,https://ieeexplore.ieee.org/abstract/document/957036/,7945434851629407670,/scholar?cites=7945434851629407670,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.620.5650&rep=rep1&type=pdf,0,0,0
1278625,Shadow detection algorithms for traffic flow analysis: a comparative study,2001,Andrea Prati and Ivana Mikic and Costantino Grana and Mohan M Trivedi,,,,340-345,IEEE,Shadow detection is critical for robust and reliable vision-based systems for traffic flow analysis. In this paper we discuss various shadow detection approaches and compare two critically. The goal of these algorithms is to prevent moving shadows being misclassified as moving objects (or parts of them). thus avoiding the merging of two or more objects into one and improving the accuracy of object localization. The environment considered is an outdoor highway scene with multiple lanes observed by a single fixed camera. The important features of shadow detection algorithms and the parameter set-up are analyzed and discussed. A critical evaluation of the results both in terms of accuracy and in terms of computational complexity are outlined. Finally. possible integration of the two approaches into a robust shadow detector is presented as future direction of our research.,True,MBy-kecAAAAJ:9yKSN-GCB0IC,159,https://ieeexplore.ieee.org/abstract/document/948680/,11498508628224939726,/scholar?cites=11498508628224939726,,,https://www.academia.edu/download/42665541/Shadow_detection_algorithms_for_traffic_20160214-4826-w1oifl.pdf,0,0,0
1278626,Optimized Block-based Connected Components Labeling with Decision Trees,2010,Costantino Grana and Daniele Borghesani and Rita Cucchiara,19,IEEE Transactions on Image Processing,6,1596-1609,IEEE,In this paper. we define a new paradigm for eight-connection labeling. which employes a general approach to improve neighborhood exploration and minimizes the number of memory accesses. First. we exploit and extend the decision table formalism introducing or-decision tables. in which multiple alternative actions are managed. An automatic procedure to synthesize the optimal decision tree from the decision table is used. providing the most effective conditions evaluation order. Second. we propose a new scanning technique that moves on a 2 × 2 pixel grid over the image. which is optimized by the automatically generated decision tree. An extensive comparison with the state of art approaches is proposed. both on synthetic and real datasets. The synthetic dataset is composed of different sizes and densities random images. while the real datasets are an artistic image analysis dataset. a document analysis …,True,MBy-kecAAAAJ:MXK_kJrjxJIC,150,https://ieeexplore.ieee.org/abstract/document/5428863/,9409973834687024215,/scholar?cites=9409973834687024215,,,https://iris.unimore.it/bitstream/11380/630658/1/TIP10.pdf,0,0,0
1278627,Microscopic in vivo description of cellular architecture of dermoscopic pigment network in nevi and melanomas,2005,Giovanni Pellacani and Anna Maria Cesinaro and Caterina Longo and Costantino Grana and Stefania Seidenari,141,Archives of dermatology,2,147-154,American Medical Association,To characterize the microscopic aspects of the dermoscopic pigment network in vivo. by means of confocal scanning laser microscopy.Confocal imaging was performed on melanocytic lesions characterized by pigment network at dermoscopy. Some confocal architectural and cytologic features. as observed at the dermoepidermal junction. were morphologically described and quantified by means of a dedicated program.University medical department.We studied confocal images of 15 melanomas. 15 dermoscopic atypical nevi. and 15 common nevi.Features referring to aspect. size. regularity. homogeneity. and infiltration of dermal papillae and to cellular size. regularity. and atypia were described by 2 observers on confocal images. Mean dermal papillary diameter. mean cell area. and shape irregularity were quantified by drawing papillae and cell …,True,MBy-kecAAAAJ:qjMakFHDy7sC,144,https://jamanetwork.com/journals/jamadermatology/article-abstract/392827,5529543715626558849,/scholar?cites=5529543715626558849,,,https://jamanetwork.com/journals/jamadermatology/fullarticle/392827,0,0,0
1278628,Hierarchical boundary-aware neural encoder for video captioning,2017,Lorenzo Baraldi and Costantino Grana and Rita Cucchiara,,,,1657-1666,,The use of Recurrent Neural Networks for video captioning has recently gained a lot of attention. since they can be used both to encode the input video and to generate the corresponding description. In this paper. we present a recurrent video encoding scheme which can discover and leverage the hierarchical structure of the video. Unlike the classical encoder-decoder approach. in which a video is encoded continuously by a recurrent layer. we propose a novel LSTM cell which can identify discontinuity points between frames or segments and modify the temporal connections of the encoding layer accordingly. We evaluate our approach on three large-scale datasets: the Montreal Video Annotation dataset. the MPII Movie Description dataset and the Microsoft Video Description Corpus. Experiments show that our approach can discover appropriate hierarchical representations of input videos and improve the state of the art results on movie description datasets.,True,MBy-kecAAAAJ:ZfRJV9d4-WMC,142,http://openaccess.thecvf.com/content_cvpr_2017/html/Baraldi_Hierarchical_Boundary-Aware_Neural_CVPR_2017_paper.html,17607393133652506561,/scholar?cites=17607393133652506561,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Baraldi_Hierarchical_Boundary-Aware_Neural_CVPR_2017_paper.pdf,0,0,0
1278629,Statistic and knowledge-based moving object detection in traffic scenes,2000,Rita Cucchiara and Costantino Grana and Metal Piccardi and A Prati,,,,27-32,IEEE,The most common approach used for vision-based traffic surveillance consists of a fast segmentation of moving visual objects (MVOs) in the scene together with an intelligent reasoning module capable of identifying. tracking and classifying the MVOs in dependency of the system goal. In this paper we describe our approach for MVOs segmentation in an unstructured traffic environment. We consider complex situations with moving people. vehicles and infrastructures that have different aspect model and motion model. In this case we define a specific approach based on background subtraction with statistic and knowledge-based background update. We show many results of real-time tracking of traffic MVOs in outdoor traffic scene such as roads. parking area intersections. and entrance with barriers.,True,MBy-kecAAAAJ:bFI3QPDXJZMC,139,https://ieeexplore.ieee.org/abstract/document/881013/,16475778254882796122,/scholar?cites=16475778254882796122,,,https://www.academia.edu/download/42665489/Statistic_and_knowledge-based_moving_obj20160214-27177-2fftpj.pdf,0,0,0
1278630,The Sakbot system for moving object detection and tracking,2001,R Cucchiara and C Grana and G Neri and M Piccardi and A Prati,,Video-Based Surveillance Systems—Computer Vision and Distributed Processing,,145-157,,This paper presents Sakbot. a system for moving object detection in traffic monitoring and video surveillance applications. The system is endowed with robust and efficient detection techniques. which main features are the statistical and knowledge-based background update and the use of HSV color information for shadow suppression. Tracking is provided by a symbolic reasoning module allowing flexible object tracking over a variety of different applications. This system proves effective on many different situations. both from the point of view of the scene appearance and the purpose of the application.,True,MBy-kecAAAAJ:pyW8ca7W8N0C,135,https://link.springer.com/chapter/10.1007/978-1-4615-0913-4_12,5490467510472950347,/scholar?cites=5490467510472950347,,,https://www.academia.edu/download/42665542/The_Sakbot_system_for_moving_object_dete20160214-27539-1fjypbk.pdf,0,0,0
1278631,Dynamic optical coherence tomography in dermatology,2016,Martina Ulrich and Lotte Themstrup and Nathalie de Carvalho and Marco Manfredi and Costantino Grana and Silvana Ciardo and Raphaela Kästle and Jon Holmes and Richard Whitehead and Gregor BE Jemec and Giovanni Pellacani and Julia Welzel,232,,3,298-311,Karger Publishers,Optical coherence tomography (OCT) represents a non-invasive imaging technology. which may be applied to the diagnosis of non-melanoma skin cancer and which has recently been shown to improve the diagnostic accuracy of basal cell carcinoma. Technical developments of OCT continue to expand the applicability of OCT for different neoplastic and inflammatory skin diseases. Of these. dynamic OCT (D-OCT) based on speckle variance OCT is of special interest as it allows the in vivo evaluation of blood vessels and their distribution within specific lesions. providing additional functional information and consequently greater density of data. In an effort to assess the potential of D-OCT for future scientific and clinical studies. we have therefore reviewed the literature and preliminary unpublished data on the visualization of the microvasculature using D-OCT. Information on D-OCT in skin cancers including …,True,MBy-kecAAAAJ:uLbwQdceFCQC,121,https://www.karger.com/Article/Abstract/444706,13080789229880722748,/scholar?cites=13080789229880722748,,,https://www.karger.com/Article/FullText/444706,0,0,0
1278632,Learn++: An incremental learning algorithm for supervised neural networks,2001,Robi Polikar and Lalita Upda and Satish S Upda and Vasant Honavar,31,"IEEE transactions on systems, man, and cybernetics, part C (applications and reviews)",4,497-508,IEEE,We introduce Learn++. an algorithm for incremental training of neural network (NN) pattern classifiers. The proposed algorithm enables supervised NN paradigms. such as the multilayer perceptron (MLP). to accommodate new data. including examples that correspond to previously unseen classes. Furthermore. the algorithm does not require access to previously used data during subsequent incremental learning sessions. yet at the same time. it does not forget previously acquired knowledge. Learn++ utilizes ensemble of classifiers by generating multiple hypotheses using training data sampled according to carefully tailored distributions. The outputs of the resulting classifiers are combined using a weighted majority voting procedure. We present simulation results on several benchmark datasets as well as a real-world classification task. Initial results indicate that the proposed algorithm works rather well in practice …,True,Xw4ceBsAAAAJ:SxCCDk4iOpsC,938,https://ieeexplore.ieee.org/abstract/document/983933/,15793823087172505296,/scholar?cites=15793823087172505296,,,https://www.researchgate.net/profile/Vasant_Honavar/publication/2489080_Learn_An_Incremental_Learning_Algorithm_for_Supervised_Neural_Networks/links/0912f50d151e7d22df000000.pdf,0,0,0
1278633,Electromagnetic NDE signal inversion by function-approximation neural networks,2002,Pradeep Ramuhalli and Lalita Udpa and Satish S Udpa,38,IEEE transactions on magnetics,6,3633-3642,IEEE,In the magnetic flux leakage (MFL) method of nondestructive testing commonly used to inspect ferromagnetic materials. a crucial problem is signal inversion. wherein the defect profiles must be recovered from measured signals. This paper proposes a neural-network-based inversion algorithm to solve the problem. Neural networks (radial-basis function and wavelet-basis function) are first trained to approximate the mapping from the signal to the defect space. The trained networks are then used iteratively in the algorithm to estimate the profile. given the measurement signal. The paper presents the results of applying the algorithm to simulated MFL data.,True,Xw4ceBsAAAAJ:d1gkVwhDpl0C,150,https://ieeexplore.ieee.org/abstract/document/1158952/,8261684082558512232,/scholar?cites=8261684082558512232,,,,0,0,0
1278634,Pulsed eddy-current based giant magnetoresistive system for the inspection of aircraft structures,2009,Guang Yang and Antonello Tamburrino and Lalita Udpa and Satish S Udpa and Zhiwei Zeng and Yiming Deng and Peiwen Que,46,IEEE transactions on magnetics,3,910-917,IEEE,Research in nondestructive evaluation is constantly increasing the sensitivity of detection of small cracks embedded deep in layered aircraft structures. Pulsed eddy-current (PEC) techniques using coil probes have shown considerable promise in detection and characterization of buried cracks in multilayered structures. In this paper. we describe the design and development of a nondestructive inspection system that uses pulse excitation of a planar multiline coil to generate a transient field that is detected via a giant magnetoresistive (GMR) field sensor. An analysis algorithm using features in time and frequency domain processes the experimentally measured signals for automatic detection of small cracks under fasteners in multilayered structures at a depth of up to 10 mm.,True,Xw4ceBsAAAAJ:Tyk-4Ss8FVUC,131,https://ieeexplore.ieee.org/abstract/document/5276854/,5704066811613230365,/scholar?cites=5704066811613230365,,,,0,0,0
1278635,Adaptive wavelets for characterizing magnetic flux leakage signals from pipeline inspection,2006,Ameet Joshi and Lalita Udpa and Satish Udpa and Antonello Tamburrino,42,IEEE transactions on magnetics,10,3168-3170,IEEE,Natural gas transmission pipelines are commonly inspected using magnetic flux leakage (MFL) method for detecting cracks and corrosion in the pipewall. Traditionally the MFL data obtained is processed to estimate an equivalent length (L). width (W). and depth (D) of defects. This information is then used to predict the maximum safe operating pressure (MAOP). In order to obtain a more accurate estimate for the MAOP. it is necessary to invert the MFL signal in terms of the full three-dimensional (3-D) depth profile of defects. This paper proposes a novel iterative method of inversion using adaptive wavelets and radial basis function neural network (RBFNN) that can efficiently reduce the data dimensionality and predict the full 3-D depth profile. Initials results obtained using simulated data are presented,True,Xw4ceBsAAAAJ:W7OEmFMy1HYC,123,https://ieeexplore.ieee.org/abstract/document/1704562/,6206534785415147485,/scholar?cites=6206534785415147485,,,https://www.academia.edu/download/46856011/tmag.2006.88009120160628-981-1ketmr6.pdf,0,0,0
1278636,Frequency invariant classification of ultrasonic weld inspection signals,1998,Robi Polikar and Lalita Udpa and Satish S Udpa and Tom Taylor,45,"IEEE transactions on ultrasonics, ferroelectrics, and frequency control",3,614-625,IEEE,Automated signal classification systems are finding increasing use in many applications for the analysis and interpretation of large volumes of signals. Such systems show consistency of response and help reduce the effect of variabilities associated with human interpretation. This paper deals with the analysis of ultrasonic NDE signals obtained during weld inspection of piping in boiling water reactors. The overall approach consists of three major steps. namely. frequency invariance. multiresolution analysis. and neural network classification. The data are first preprocessed whereby signals obtained using different transducer center frequencies are transformed to an equivalent reference frequency signal. Discriminatory features are then extracted using a multiresolution analysis technique. namely. the discrete wavelet transform (DWT). The compact feature vector obtained using wavelet analysis is classified using a …,True,Xw4ceBsAAAAJ:u5HHmVD_uO8C,120,https://ieeexplore.ieee.org/abstract/document/677606/,2178628463146557647,/scholar?cites=2178628463146557647,,,http://users.rowan.edu/~polikar/RESEARCH/PUBLICATIONS/uffc97.pdf,0,0,0
1278637,Three-dimensional defect reconstruction from eddy-current NDE signals using a genetic local search algorithm,2004,Yue Li and Lalita Udpa and Satish S Udpa,40,IEEE Transactions on Magnetics,2,410-417,IEEE,This paper introduces a model-based approach to reconstruct three-dimensional defect profiles from eddy-current nondestructive evaluation signals. The method casts the defect characterization problem as an exercise in maximization of an appropriate cost function. The method uses an edge-based finite-element forward model to simulate the underlying physical process and a genetic search algorithm to solve the optimization (maximization) problem. The paper presents techniques to reduce the computation cost for evaluating the cost function as well as local search methods to speed the genetic search process. Test results confirm the validity of the approach.,True,Xw4ceBsAAAAJ:2osOgNQ5qMEC,118,https://ieeexplore.ieee.org/abstract/document/1284440/,527519929216857120,/scholar?cites=527519929216857120,,,https://www.academia.edu/download/54240750/TMAG.2004.82411620170825-2862-1qulce6.pdf,0,0,0
1278638,Eddy current defect characterization using neural networks,1990,L Udpa and SS Udpa,48,Materials Evaluation,3,342-347,,Sauf mention contraire ci-dessus. le contenu de cette notice bibliographique peut être utilisé dans le cadre d’une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above. the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya señalado antes. el contenido de este registro bibliográfico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS,True,Xw4ceBsAAAAJ:u-x6o8ySG0sC,114,https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=19245935,6866116136736079084,/scholar?cites=6866116136736079084,,,,0,0,0
1278639,Invariance transformations for magnetic flux leakage signals,1996,Shreekanth Mandayam and L Udpa and SS Udpa and W Lord,32,IEEE Transactions on magnetics,3,1577-1580,IEEE,Magnetic flux leakage (MFL) methods are used extensively for inspecting ferromagnetic materials. The analysis of the MFL signal is however fraught with problems associated with the sensitivity of the signal to a number of factors such as the MFL sensor velocity and variations in the permeability of the test specimen. The interpretation can be simplified if the signals can be processed to attain invariance to these conditions. This paper presents novel methods for obtaining permeability invariant and velocity invariant MFL signals.,True,Xw4ceBsAAAAJ:9yKSN-GCB0IC,110,https://ieeexplore.ieee.org/abstract/document/497553/,16132753199008039970,/scholar?cites=16132753199008039970,,,,0,0,0
1278640,Neural networks for the classification of nondestructive evaluation signals,1991,L Udpa and SS Udpa,138,IEE Proceedings F (Radar and Signal Processing),1,41-45,IET Digital Library,The paper proposes the use of massively parallel learning networks for interpreting signals from electromagnetic transducers used in nondestructive evaluation (NDE) problems. Nondestructive testing techniques are used in a variety of industries for evaluating the structural integrity of critical components in a noninvasive manner. A major aspect of research in nondestructive testing is related to the inverse problem and is commonly referred to as defect characterisation. This involves the classification of the eddy current signals in terms of the shape and size of the underlying defects in the test object. A key contribution of the proposed network is the ability to obtain a rotation and translation-invariant internal representation of the signal. Results showing the merits of this approach as well as a comparison with traditional techniques for the classification of signals are presented.,True,Xw4ceBsAAAAJ:UeHWp8X0CEIC,105,https://digital-library.theiet.org/content/journals/10.1049/ip-f-2.1991.0007,15349549189749009986,/scholar?cites=15349549189749009986,,,,0,0,0
1278641,Characterization of gas pipeline inspection signals using wavelet basis function neural networks,2000,K Hwang and S Mandayam and SS Udpa and L Udpa and W Lord and M Atzal,33,NDT & E International,8,531-545,Elsevier,Magnetic flux leakage techniques are used extensively to detect and characterize defects in natural gas transmission pipelines. This paper presents a novel approach for training a multiresolution. hierarchical wavelet basis function (WBF) neural network for the three-dimensional characterization of defects from magnetic flux leakage signals. Gaussian radial basis functions and Mexican hat wavelet frames are used as scaling functions and wavelets respectively. The centers of the basis functions are calculated using a dyadic expansion scheme and a k-means clustering algorithm. The results indicate that significant advantages over other neural network based defect characterization schemes could be obtained. in that the accuracy of the predicted defect profile can be controlled by the resolution of the network. The feasibility of employing a WBF neural network is demonstrated by predicting defect profiles from both …,True,Xw4ceBsAAAAJ:qjMakFHDy7sC,104,https://www.sciencedirect.com/science/article/pii/S0963869500000086,14936077683563755661,/scholar?cites=14936077683563755661,,,,0,0,0
1278642,Neural network-based inversion algorithms in magnetic flux leakage nondestructive evaluation,2003,Pradeep Ramuhalli and Lalita Udpa and Satish S Udpa,93,Journal of applied physics,10,8274-8276,American Institute of Physics,Magnetic flux leakage (MFL) methods are commonly used in the nondestructive evaluation (NDE) of ferromagnetic materials. An important problem in MFL NDE is the determination of flaw parameters such as the flaw length. depth. and shape (profile) from the measured values of the flux density B. Commonly used methods use a forward model in a loop to determine B for a given set of flaw parameters. This approach iteratively adjusts the flaw parameters to minimize the error between the measured and predicted values of B. This article proposes the use of neural networks as forward models. The proposed approach uses two neural networks in feedback configuration—a forward network and an inverse network. The second network is used to predict the profile given the measured value of B. and acts to constrain the solution space. Results of applying these methods to MFL data obtained from a two-dimensional …,True,Xw4ceBsAAAAJ:IjCSPb-OGe4C,98,https://aip.scitation.org/doi/abs/10.1063/1.1558693,6749877922791972403,/scholar?cites=6749877922791972403,,,,0,0,0
1278643,Hypoglycaemic effect of Artemisia herba alba. II. Effect of a valuable extract on some blood parameters in diabetic animals,1994,Loai Al-Shamaony and Shahba M Al-Khazraji and Husni AA Twaij,43,Journal of ethnopharmacology,3,167-171,Elsevier,Artemisia herba alba is widely used in Iraqi folk medicine for the treatment of diabetes mellitus. However. very few scientific and medical studies were carried out to assess the efficacy and toxicity of A. herba alba. In this study feeding diabetic rats and rabbits with 0.39 g kg body weight of the aqueous extract of the aerial parts of the plant for 2–4 weeks shows a significant reduction in blood glucose level. prevents elevation of glycosylated haemoglobin level and possesses a hypoliposis effect. in addition to the protection against body weight loss of diabetic animals.,True,lFaZNTQAAAAJ:Zx2yaX5tUAoC,485,https://www.sciencedirect.com/science/article/pii/0378874194900388,3312352859764069423,/scholar?cites=3312352859764069423,,,,0,0,0
1278644,Search for maive reonance decaying into pair of booted boon in emi-leptonic final tate at $$\qrt {} $$= 8 TeV,2014,Vardan Khachatryan and Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and Thomas Bergauer and Marko Dragicevic and Janos Erö and Christian Fabjan and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Christian Hartl and Natascha Hörmann and Josef Hrubec and Manfred Jeitler and Wolfgang Kiesenhofer and Valentin Knünz and Manfred Krammer and Ilse Krätschmer and Dietrich Liko and Ivan Mikulec and Dinyar Rabady and Babak Rahbaran and Herbert Rohringer and Robert Schöfbeck and Josef Strauss and Anton Taurok and Wolfgang Treberer-Treberspurg and Wolfgang Waltenberger and C-E Wulz and Vladimir Mossolov and Nikolai Shumeiko and J Suarez Gonzalez and Sara Alderweireldt and Monika Bansal and Sunil Bansal and Tom Cornelis and Eddi A De Wolf and Xavier Janssen and Albert Knutsson and Sten Luyckx and Silvia Ochesanu and Benoit Roland and Romain Rougny and Merijn Van De Klundert and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and Freya Blekman and Stijn Blyweert and Jorgen D’Hondt and Nadir Daci and Natalie Heracleous and Alexis Kalogeropoulos and James Keaveney and Tae Jeong Kim and Steven Lowette and Michael Maes and Annik Olbrechts and Quentin Python and Derek Strom and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Gerrit Patrick Van Onsem and Ilaria Villella and Cécile Caillol and Barbara Clerbaux and Gilles De Lentdecker and Didar Dobur and Laurent Favart and APR Gay and Anastasia Grebenyuk and Alexandre Léonard and Abdollah Mohammadi and Luca Perniè and Thomas Reis and Tomislav Seva and Laurent Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Leonardo Benucci and Anna Cimmino and Silvia Costantini and S Crucy and Sven Dildick and Alexis Fagot and Guillaume Garcia and Benjamin Klein and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and S Salva Diblen and Michael Sigamani and Nadja Strobbe and Filip Thyssen and Michael Tytgat and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and C Beluffi and G Bruno and R Castello and A Caudron and L Ceard and GG Da Silveira and C Delaere and T Du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and P Jez and M Komm and V Lemaitre and J Liao and C Nuttens and D Pagano and A Pin and K Piotrzkowski and A Popov and L Quertenmont and M Selvaggi and M Vidal Marono and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins and T Dos Reis Martins and ME Pol and WL Aldá and W Carvalho and J Chinellato and A Custodio and EM Da Costa and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and H Malbouisson and M Malek and D Matos Figueiredo and L Mundim and H Nogima,2014,Journal of High Energy Physics,8,174,Springer Berlin Heidelberg,A search for new resonances decaying to WW. ZZ. or WZ is presented. Final states are considered in which one of the vector bosons decays leptonically and the other hadronically. Results are based on data corresponding to an integrated luminosity of 19.7 fb− 1 recorded in proton-proton collisions at= 8 TeV with the CMS detector at the CERN LHC. Techniques aiming at identifying jet substructures are used to analyze signal events in which the hadronization products from the decay of highly boosted W or Z bosons are contained within a single reconstructed jet. Upper limits on the production of generic WW. ZZ. or WZ resonances are set as a function of the resonance mass and width. We increase the sensitivity of the analysis by statistically combining the results of this search with a complementary study of the all-hadronic final state. Upper limits at 95% confidence level are set on the bulk graviton production …,True,lFaZNTQAAAAJ:Js6xCJvs_BkC,418,https://link.springer.com/content/pdf/10.1007/JHEP08(2014)174.pdf,15652803878961732914,/scholar?cites=15652803878961732914,,,https://link.springer.com/content/pdf/10.1007/JHEP08(2014)174.pdf,0,0,0
1278645,Towards large-area photovoltaic nanocells: experiences learned from smart window technology,1994,Carl M Lampert,32,Solar Energy Materials and Solar Cells,3,307-321,North-Holland,This investigation covers two technologies which have different applications but have many similar characteristics. One is the nanocell photoelectrochemical solar cell. the other is the electrochromic window. At first it is hard to see what they have in common other then that they both interact with light. Now. I will tell you of a tale of two technologies. First. I will start with nanocells.,True,lFaZNTQAAAAJ:r_T35HE59TsC,209,https://windows.lbl.gov/sites/default/files/39076.pdf,14829252147798168440,/scholar?cites=14829252147798168440,,,https://windows.lbl.gov/sites/default/files/39076.pdf,0,0,0
1278646,Dielectric and piezoelectric properties of PVDF/PZT composites: A review,2015,Anjana Jain and Prashanth KJ and Asheesh Kr Sharma and Arpit Jain and Rashmi PN,55,,7,1589-1616,,Smart materials. which exhibit piezoelectricity. find an eclectic range of applications in the industry. The direct piezoelectric effect has been widely used in sensor design. and the inverse piezoelectric effect has been applied in actuator design. Ever since 1954. PZT and BaTiO3 were widely used for sensor and actuator applications despite their toxicity. brittleness. inflexibility. etc. With the discovery of PVDF in 1969. followed by development of copolymers. a flexible. easy to process. nontoxic. high density alternate with high piezoelectric voltage coefficient was available. In the past 20 years. heterostructural materials like polymer ceramic composites. have received lot of attention. since these materials combine the excellent pyroelectric and piezoelectric properties of ceramics with the flexibility. processing facility. and strength of the polymers resulting in relatively high dielectric permittivity and breakdown strength …,True,lFaZNTQAAAAJ:F-CH8NBHAGkC,172,https://onlinelibrary.wiley.com/doi/abs/10.1002/pen.24088,12841385681124317320,/scholar?cites=12841385681124317320,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/pen.24088,0,0,0
1278647,Measuring arthropod biodiversity in the tropical forest canopy.,1995,Terry L Erwin,,Forest canopies.,,109-127,Academic Press,A historical review of what has been achieved with arthropod diversity sampling sampling Subject Category: Techniques. Methodologies and Equipment,True,lFaZNTQAAAAJ:0UEzl8ZgZOgC,156,https://www.cabdirect.org/cabdirect/abstract/19960603745,11090231147645294103,/scholar?cites=11090231147645294103,,,,0,0,0
1278648,Pharmacological and therapeutic potential of Cordyceps with special reference to Cordycepin,2014,Hardeep S Tuli and Sardul S Sandhu and AK Sharma,4,,1,1-12,Springer Berlin Heidelberg,An entomopathogenic fungus. Cordyceps sp. has been known to have numerous pharmacological and therapeutic implications. especially. in terms of human health making it a suitable candidate for ethno-pharmacological use. Main constituent of the extract derived from this fungus comprises a novel bio-metabolite called as Cordycepin (3′deoxyadenosine) which has a very potent anti-cancer. anti-oxidant and anti-inflammatory activities. The current review discusses about the broad spectrum potential of Cordycepin including biological and pharmacological actions in immunological. hepatic. renal. cardiovascular systems as well as an anti-cancer agent. The article also reviews the current efforts to delineate the mechanism of action of Cordycepin in various bio-molecular processes. The study will certainly draw the attention of scientific community to improve the bioactivity and production of Cordycepin …,True,lFaZNTQAAAAJ:SOzfYv5sdkIC,141,https://link.springer.com/article/10.1007/s13205-013-0121-9,8592024027814218233,/scholar?cites=8592024027814218233,,,https://link.springer.com/article/10.1007/s13205-013-0121-9,0,0,0
1278649,Health and ecological risk assessment of emerging contaminants (pharmaceuticals. personal care products. and artificial sweeteners) in surface and groundwater (drinking water …,2019,Brij Mohan Sharma and Jitka Bečanová and Martin Scheringer and Anežka Sharma and Girija K Bharat and Paul G Whitehead and Jana Klánová and Luca Nizzetto,646,Science of the Total Environment,,1459-1467,Elsevier,Pharmaceuticals. personal care products (PPCPs). and artificial sweeteners (ASWs) are contaminants of emerging concern commonly found in the aquatic environments. In India. studies reporting environmental occurrence of these contaminants are scarce. In this study. we investigated the occurrence and distribution of 15 PPCPs and five ASWs in the river and groundwater (used untreated as drinking water) at several sites along the Ganges River. Based on the measured groundwater concentrations. we estimated the life-long human health risk from exposure to PPCPs through drinking. In addition. we estimated the risk of exposure to PPCPs and ASWs in the river water for aquatic organisms. The sum of detected PPCPs in the river water ranged between 54.7-826 ng/L. with higher concentrations in the severely anthropogenically influenced middle and lower reaches of the Ganges. The highest concentration …,True,lFaZNTQAAAAJ:GFlsLV1XnBgC,134,https://www.sciencedirect.com/science/article/pii/S0048969718327323,12383372357404823679,/scholar?cites=12383372357404823679,,,https://niva.brage.unit.no/niva-xmlui/bitstream/handle/11250/2659803/1704657.pdf?sequence=2,0,0,0
1278650,Magico-religious beliefs in schizophrenia: A study from North India,2000,Parmanand Kulhara and Ajit Avasthi and Avneet Sharma,33,Psychopathology,2,62-68,Karger Publishers,Psychiatric disorders in India are often attributed to influence of supernatural phenomena. and many patients are subjected to various kinds of ‘magico-religious’ treatments. We studied 40 cases of schizophrenia and ascertained magico-religious beliefs held by their key relatives. The effects of such magico-religious beliefs on psychopathology and treatment-seeking behaviour were explored. The sample were schizophrenia patients diagnosed according to ICD-10 of the World Health Organisation. Psychopathology was assessed on the 9th version of the Present State Examination (PSE-9). Supernatural Attitude Questionnaire was administered to the key relatives of the patients to ascertain their beliefs about various supernatural phenomena and magico-religious treatments. It was observed that the majority of the patients had undergone magico-religious treatment (n = 23). Nearly 74% of the patients who had …,True,lFaZNTQAAAAJ:MARohxuQWaQC,111,https://www.karger.com/article/Abstract/29122,13750598091332591366,/scholar?cites=13750598091332591366,,,,0,0,0
1278651,Moxonidine in the treatment of overweight and obese patients with the metabolic syndrome: a postmarketing surveillance study,2004,AM Sharma and Thomas Wagner and Parvaneh Marsalek,18,Journal of human hypertension,9,669-675,Nature Publishing Group,Moxonidine is a centrally active imidazoline receptor agonist that effectively lowers blood pressure and has been shown to have beneficial effects on lipid and carbohydrate metabolism. We assessed the efficacy of moxonidine in a postmarketing surveillance study (CAMUS) conducted in 772 practices in Germany. documenting 4005 patients with hypertension. who were overweight and/or suffered from metabolic syndrome. Patients were treated with moxonidine (Cynt®) for the first time following the baseline visit for 8 weeks. Mean blood pressure decreased from 168/97 to 141/83 mmHg for all patients and from 168/96 to 141/83 mmHg for patients with metabolic syndrome. Blood pressure reduction was particularly pronounced in patients with severe hypertension at baseline. The response rate (DBP⩽ 90 mmHg or reduction⩾ 10 mmHg) of antihypertensive treatment with moxonidine was 94.0% for all patients and …,True,lFaZNTQAAAAJ:ESN8wY4Sm6AC,102,https://www.nature.com/articles/1001676,8391601451700150922,/scholar?cites=8391601451700150922,,,https://www.nature.com/articles/1001676,0,0,0
1278652,Effectiveness of rapid transport of victims and community health education on snake bite fatalities in rural Nepal,2013,Sanjib K Sharma and Patrick Bovier and Nilambar Jha and Emilie Alirol and Louis Loutan and François Chappuis,89,The American journal of tropical medicine and hygiene,1,145-150,The American Society of Tropical Medicine and Hygiene,Snake bite is a major public problem in the rural tropics. In southern Nepal. most deaths caused by neurotoxic envenomation occur in the village or during transport to health centers. The effectiveness of victims' transport by motorcycle volunteers to a specialized treatment center. combined with community health education. was assessed in a non-randomized. single-arm. before-after study conducted in four villages (population = 62.127). The case-fatality rate of snake bite decreased from 10.5% in the pre-intervention period to 0.5% during the intervention (relative risk reduction = 0.949. 95% confidence interval = 0.695–0.999). The snake bite incidence decreased from 502 bites/100.000 population to 315 bites/100.000 population in the four villages (relative risk reduction = 0.373. 95% confidence interval = 0.245–0.48). but it remained constant in other villages. Simple educational messages and promotion of …,True,lFaZNTQAAAAJ:OJBCU0UFcNkC,98,https://www.ajtmh.org/content/journals/10.4269/ajtmh.12-0750,17211396958530390123,/scholar?cites=17211396958530390123,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3748471/,0,0,0
1278653,Suppression of ϒ (1S). ϒ (2S). and ϒ (3S) quarkonium states in PbPb collisions at sNN= 2.76 TeV,2017,Vardan Khachatryan and Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and E Asilar and Thomas Bergauer and Johannes Brandstetter and Erica Brondolin and Marko Dragicevic and Janos Erö and Martin Flechl and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Christian Hartl and Natascha Hörmann and Josef Hrubec and Manfred Jeitler and Axel König and Ilse Krätschmer and Dietrich Liko and Takashi Matsushita and Ivan Mikulec and Dinyar Rabady and Navid Rad and Babak Rahbaran and Herbert Rohringer and Jochen Schieck and Josef Strauss and Wolfgang Waltenberger and C-E Wulz and Oleg Dvornikov and Vladimir Makarenko and Vladimir Zykunov and Vladimir Mossolov and Nikolai Shumeiko and J Suarez Gonzalez and Sara Alderweireldt and Eddi A De Wolf and Xavier Janssen and Jasper Lauwers and Merijn Van De Klundert and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and S Abu Zeid and Freya Blekman and Jorgen D'Hondt and Nadir Daci and Isabelle De Bruyn and Kevin Deroover and Steven Lowette and Seth Moortgat and Lieselotte Moreels and Annik Olbrechts and Quentin Python and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Isis Van Parijs and Hugues Brun and Barbara Clerbaux and Gilles De Lentdecker and Hugo Delannoy and Giuseppe Fasanella and Laurent Favart and Reza Goldouzian and Anastasia Grebenyuk and Georgia Karapostoli and Thomas Lenzi and Alexandre Léonard and Jelena Luetic and Thierry Maerschalk and Andrey Marinov and Aidan Randle-conde and Tomislav Seva and C Vander Velde and P Vanlaer and D Vannerom and R Yonamine and F Zenoni and F Zhang and A Cimmino and T Cornelis and D Dobur and A Fagot and G Garcia and M Gul and I Khvastunov and D Poyraz and S Salva and R Schöfbeck and A Sharma and M Tytgat and W Van Driessche and E Yazgan and N Zaganidis and H Bakhshiansohi and C Beluffi and O Bondu and S Brochet and G Bruno and A Caudron and S De Visscher and C Delaere and M Delcourt and B Francois and A Giammanco and A Jafari and P Jez and M Komm and G Krintiras and V Lemaitre and A Magitteri and A Mertens and M Musich and C Nuttens and K Piotrzkowski and L Quertenmont and M Selvaggi and M Vidal Marono and S Wertz and N Beliy and WL Aldá Júnior and FL Alves and GA Alves and L Brito and C Hensel and A Moraes and ME Pol and P Rebello Teles and E Belchior Batista Das Chagas and W Carvalho and J Chinellato and A Custódio and EM Da Costa and GG Da Silveira and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and LM Huertas Guativa and H Malbouisson and D Matos Figueiredo and C Mora Herrera and L Mundim and H Nogima and WL Prado Da Silva and A Santoro and A Sznajder,770,Physics Letters B,,357-379,North-Holland,The production yields of ϒ (1S). ϒ (2S). and ϒ (3S) quarkonium states are measured through their decays into muon pairs in the CMS detector. in PbPb and pp collisions at the centre-of-mass energy per nucleon pair of 2.76 TeV. The data correspond to integrated luminosities of 166 μb− 1 and 5.4 pb− 1 for PbPb and pp collisions. respectively. Differential production cross sections are reported as functions of ϒ rapidity y up to 2.4. and transverse momentum p T up to 20 GeV/c. A strong centrality-dependent suppression is observed in PbPb relative to pp collisions. by factors of up to≈ 2 and 8. for the ϒ (1S) and ϒ (2S) states. respectively. No significant dependence of this suppression is observed as a function of y or p T. The ϒ (3S) state is not observed in PbPb collisions. which corresponds to a suppression for the centrality-integrated data by at least a factor of≈ 7 at a 95% confidence level. The observed …,True,lFaZNTQAAAAJ:46ZxqUMUUiUC,96,https://www.sciencedirect.com/science/article/pii/S0370269317303052,18180452896414275360,/scholar?cites=18180452896414275360,,,https://www.sciencedirect.com/science/article/pii/S0370269317303052,0,0,0
1278654,Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals,2018,U Rajendra Acharya and Shu Lih Oh and Yuki Hagiwara and Jen Hong Tan and Hojjat Adeli,100,Computers in biology and medicine,,270-278,Pergamon,An encephalogram (EEG) is a commonly used ancillary test to aide in the diagnosis of epilepsy. The EEG signal contains information about the electrical activity of the brain. Traditionally. neurologists employ direct visual inspection to identify epileptiform abnormalities. This technique can be time-consuming. limited by technical artifact. provides variable results secondary to reader expertise level. and is limited in identifying abnormalities. Therefore. it is essential to develop a computer-aided diagnosis (CAD) system to automatically distinguish the class of these EEG signals using machine learning techniques. This is the first study to employ the convolutional neural network (CNN) for analysis of EEG signals. In this work. a 13-layer deep convolutional neural network (CNN) algorithm is implemented to detect normal. preictal. and seizure classes. The proposed technique achieved an accuracy. specificity. and …,True,uJlD-A0AAAAJ:xtRiw3GOFMkC,754,https://www.sciencedirect.com/science/article/pii/S0010482517303153,6776943037550973528,/scholar?cites=6776943037550973528,,,https://www.researchgate.net/profile/Yuki-Hagiwara/publication/320072603_Deep_convolutional_neural_network_for_the_automated_detection_and_diagnosis_of_seizure_using_EEG_signals/links/59cc56e5aca272bb050c6c33/Deep-convolutional-neural-network-for-the-automated-detection-and-diagnosis-of-seizure-using-EEG-signals.pdf,0,0,0
1278655,A deep convolutional neural network model to classify heartbeats,2017,U Rajendra Acharya and Shu Lih Oh and Yuki Hagiwara and Jen Hong Tan and Muhammad Adam and Arkadiusz Gertych and Ru San Tan,89,Computers in biology and medicine,,389-396,Pergamon,The electrocardiogram (ECG) is a standard test used to monitor the activity of the heart. Many cardiac abnormalities will be manifested in the ECG including arrhythmia which is a general term that refers to an abnormal heart rhythm. The basis of arrhythmia diagnosis is the identification of normal versus abnormal individual heart beats. and their correct classification into different diagnoses. based on ECG morphology. Heartbeats can be sub-divided into five categories namely non-ectopic. supraventricular ectopic. ventricular ectopic. fusion. and unknown beats. It is challenging and time-consuming to distinguish these heartbeats on ECG as these signals are typically corrupted by noise. We developed a 9-layer deep convolutional neural network (CNN) to automatically identify 5 different categories of heartbeats in ECG signals. Our experiment was conducted in original and noise attenuated sets of ECG signals …,True,uJlD-A0AAAAJ:abG-DnoFyZgC,465,https://www.sciencedirect.com/science/article/pii/S0010482517302810,8526775522176257003,/scholar?cites=8526775522176257003,,,https://www.researchgate.net/profile/Yuki_Hagiwara2/publication/319271551_A_Deep_Convolutional_Neural_Network_Model_to_Classify_Heartbeats/links/59cc2f55aca272bb050c6836/A-Deep-Convolutional-Neural-Network-Model-to-Classify-Heartbeats.pdf,0,0,0
1278656,Deep learning for healthcare applications based on physiological signals: A review,2018,Oliver Faust and Yuki Hagiwara and Tan Jen Hong and Oh Shu Lih and U Rajendra Acharya,161,,,1-13,Elsevier,Background and objective: We have cast the net into the ocean of knowledge to retrieve the latest scientific research on deep learning methods for physiological signals. We found 53 research papers on this topic. published from 01.01.2008 to 31.12.2017.An initial bibliometric analysis shows that the reviewed papers focused on Electromyogram(EMG). Electroencephalogram(EEG). Electrocardiogram(ECG). and Electrooculogram(EOG). These four categories were used to structure the subsequent content review.During the content review. we understood that deep learning performs better for big and varied datasets than classic analysis and machine classification methods. Deep learning algorithms try to develop the model by using all the available input.This review paper depicts the application of various deep learning algorithms used till recently. but in future it will be used for more …,True,uJlD-A0AAAAJ:738O_yMBCRsC,424,https://www.sciencedirect.com/science/article/pii/S0169260718301226,7491434081672953055,/scholar?cites=7491434081672953055,,,http://shura.shu.ac.uk/21073/1/Deep%20learning%20for%20healthcare%20applications%20based%20on%20physiological%20signals%20a%20review.pdf,0,0,0
1278657,Application of deep convolutional neural network for automated detection of myocardial infarction using ECG signals,2017,U Rajendra Acharya and Hamido Fujita and Shu Lih Oh and Yuki Hagiwara and Jen Hong Tan and Muhammad Adam,415,Information Sciences,,190-198,Elsevier,The electrocardiogram (ECG) is a useful diagnostic tool to diagnose various cardiovascular diseases (CVDs) such as myocardial infarction (MI). The ECG records the heart's electrical activity and these signals are able to reflect the abnormal activity of the heart. However. it is challenging to visually interpret the ECG signals due to its small amplitude and duration. Therefore. we propose a novel approach to automatically detect the MI using ECG signals. In this study. we implemented a convolutional neural network (CNN) algorithm for the automated detection of a normal and MI ECG beats (with noise and without noise). We achieved an average accuracy of 93.53% and 95.22% using ECG beats with noise and without noise removal respectively. Further. no feature extraction or selection is performed in this work. Hence. our proposed algorithm can accurately detect the unknown ECG signals even with noise. So. this …,True,uJlD-A0AAAAJ:_xSYboBqXhAC,424,https://www.sciencedirect.com/science/article/pii/S0020025517308009,14642244986977853935,/scholar?cites=14642244986977853935,,,https://www.researchgate.net/profile/Yuki-Hagiwara/publication/317821702_Application_of_Deep_Convolutional_Neural_Network_for_Automated_Detection_of_Myocardial_Infarction_Using_ECG_Signals/links/59cc2f7f0f7e9bbfdc3b7b45/Application-of-Deep-Convolutional-Neural-Network-for-Automated-Detection-of-Myocardial-Infarction-Using-ECG-Signals.pdf,0,0,0
1278658,Automated detection of arrhythmias using different intervals of tachycardia ECG segments with convolutional neural network,2017,U Rajendra Acharya and Hamido Fujita and Oh Shu Lih and Yuki Hagiwara and Jen Hong Tan and Muhammad Adam,405,Information sciences,,81-90,Elsevier,Our cardiovascular system weakens and is more prone to arrhythmia as we age. An arrhythmia is an abnormal heartbeat rhythm which can be life-threatening. Atrial fibrillation (Afib). atrial flutter (Afl). and ventricular fibrillation (Vfib) are the recurring life-threatening arrhythmias that affect the elderly population. An electrocardiogram (ECG) is the principal diagnostic tool employed to record and interpret ECG signals. These signals contain information about the different types of arrhythmias. However. due to the complexity and non-linearity of ECG signals. it is difficult to manually analyze these signals. Moreover. the interpretation of ECG signals is subjective and might vary between the experts. Hence. a computer-aided diagnosis (CAD) system is proposed. The CAD system will ensure that the assessment of ECG signals is objective and accurate. In this work. we present a convolutional neural network (CNN …,True,uJlD-A0AAAAJ:u_35RYKgDlwC,358,https://www.sciencedirect.com/science/article/pii/S0020025517306539,3920665146379032154,/scholar?cites=3920665146379032154,,,https://www.researchgate.net/profile/Yuki-Hagiwara/publication/315821873_Automated_Detection_of_Arrhythmias_Using_Different_Intervals_of_Tachycardia_ECG_Segments_with_Convolutional_Neural_Network/links/59cb0983aca272bb05079f23/Automated-Detection-of-Arrhythmias-Using-Different-Intervals-of-Tachycardia-ECG-Segments-with-Convolutional-Neural-Network.pdf,0,0,0
1278659,Thermography based breast cancer detection using texture features and support vector machine,2012,U Rajendra Acharya and Eddie Yin-Kwee Ng and Jen-Hong Tan and S Vinitha Sree,36,Journal of medical systems,3,1503-1510,Springer US,Breast cancer is a leading cause of death nowadays in women throughout the world. In developed countries. it is the most common type of cancer in women. and it is the second or third most common malignancy in developing countries. The cancer incidence is gradually increasing and remains a significant public health concern. The limitations of mammography as a screening and diagnostic modality. especially in young women with dense breasts. necessitated the development of novel and more effective strategies with high sensitivity and specificity. Thermal imaging (thermography) is a noninvasive imaging procedure used to record the thermal patterns using Infrared (IR) camera. The aim of this study is to evaluate the feasibility of using thermal imaging as a potential tool for detecting breast cancer. In this work. we have used 50 IR breast images (25 normal and 25 cancerous) collected from Singapore …,True,uJlD-A0AAAAJ:9yKSN-GCB0IC,293,https://link.springer.com/article/10.1007/s10916-010-9611-z,12718121358960190465,/scholar?cites=12718121358960190465,,,https://tahomaclinic.com/Private/Articles3/Thermography/Acharya%202010%20-%20Thermography%20Based%20Breast%20Cancer%20Detection%20Using%20Texture%20Features%20and%20Support%20Vector%20Machine.pdf,0,0,0
1278660,Infrared thermography on ocular surface temperature: a review,2009,Jen-Hong Tan and EYK Ng and U Rajendra Acharya and Caroline Chee,52,,4,97-108,Pergamon,Body temperature is a good indicator of human health. Thermal imaging system (thermography) is a non-invasive imaging procedure used to record the thermal patterns using Infrared (IR) camera. It provides visual and qualitative documentation of temperature changes in the vascular tissues. and is beginning to play an important role in the field of ophthalmology. This paper deals with the working principle. use and advantages of IR thermography in the field of ophthalmology. Different algorithms to acquire the ocular surface temperature (OST). that can be used for the diagnosis of ocular diseases are discussed.,True,uJlD-A0AAAAJ:u5HHmVD_uO8C,237,https://www.sciencedirect.com/science/article/pii/S1350449509000310,4331727190837636028,/scholar?cites=4331727190837636028,,,,0,0,0
1278661,Automated detection of coronary artery disease using different durations of ECG segments with convolutional neural network,2017,U Rajendra Acharya and Hamido Fujita and Oh Shu Lih and Muhammad Adam and Jen Hong Tan and Chua Kuang Chua,132,Knowledge-Based Systems,,62-71,Elsevier,Coronary artery disease (CAD) is caused due by the blockage of inner walls of coronary arteries by plaque. This constriction reduces the blood flow to the heart muscles resulting in myocardial infarction (MI). The electrocardiogram (ECG) is commonly used to screen the cardiac health. The ECG signals are nonstationary and nonlinear in nature whereby the transient disease indicators may appear randomly on the time scale. Therefore. the procedure to diagnose the abnormal beat is arduous. time consuming and prone to human errors. The automated diagnosis system overcomes these problems. In this study. convolutional neural network (CNN) structures comprising of four convolutional layers. four max pooling layers and three fully connected layers are proposed for the diagnosis of CAD using two and five seconds durations of ECG signal segments. Deep CNN is able to differentiate between normal and …,True,uJlD-A0AAAAJ:pyW8ca7W8N0C,203,https://www.sciencedirect.com/science/article/pii/S0950705117302769,11449502924551628802,/scholar?cites=11449502924551628802,,,https://www.researchgate.net/profile/Shu_Lih_Oh/publication/317336647_Automated_Detection_of_Coronary_Artery_Disease_Using_Different_Durations_of_ECG_Segments_with_Convolutional_Neural_Network/links/59cda13caca272b0ec150325/Automated-Detection-of-Coronary-Artery-Disease-Using-Different-Durations-of-ECG-Segments-with-Convolutional-Neural-Network.pdf,0,0,0
1278662,Deep convolution neural network for accurate diagnosis of glaucoma using digital fundus images,2018,U Raghavendra and Hamido Fujita and Sulatha V Bhandary and Anjan Gudigar and Jen Hong Tan and U Rajendra Acharya,441,Information Sciences,,41-49,Elsevier,Glaucoma progressively affects the optic nerve and may cause partial or complete vision loss. Raised intravascular pressure is the only factor which can be modified to prevent blindness from this condition. Accurate early detection and continuous screening may prevent the vision loss. Computer aided diagnosis (CAD) is a non-invasive technique which can detect the glaucoma in its early stage using digital fundus images. Developing such a system require diverse huge database in order to reach optimum performance. This paper proposes a novel CAD tool for the accurate detection of glaucoma using deep learning technique. An eighteen layer convolutional neural networks (CNN) is effectively trained in order to extract robust features from the digital fundus images. Finally these features are classified into normal and glaucoma classes during testing. We have achieved the highest accuracy of 98.13% using 1426 …,True,uJlD-A0AAAAJ:XiSMed-E-HIC,195,https://www.sciencedirect.com/science/article/pii/S0020025518300744,8297831005191391809,/scholar?cites=8297831005191391809,,,https://www.academia.edu/download/62109668/Deep_Convolution_Neural_Network_for_Accurate_Diagnosis_of-201820200215-83776-wextx2.pdf,0,0,0
1278663,Application of empirical mode decomposition (EMD) for automated detection of epilepsy using EEG signals,2012,Roshan Joy Martis and U Rajendra Acharya and Jen Hong Tan and Andrea Petznick and Ratna Yanti and Chua Kuang Chua and EY Kwee Ng and Louis Tong,22,International journal of neural systems,06,1250027,World Scientific Publishing Company,Epilepsy is a global disease with considerable incidence due to recurrent unprovoked seizures. These seizures can be noninvasively diagnosed using electroencephalogram (EEG). a measure of neuronal electrical activity in brain recorded along scalp. EEG is highly nonlinear. nonstationary and non-Gaussian in nature. Nonlinear adaptive models such as empirical mode decomposition (EMD) provide intuitive understanding of information present in these signals. In this study a novel methodology is proposed to automatically classify EEG of normal. inter-ictal and ictal subjects using EMD decomposition. EEG decomposition using EMD yields few intrinsic mode functions (IMF). which are amplitude and frequency modulated (AM and FM) waves. Hilbert transform of these IMF provides AM and FM frequencies. Features such as spectral peaks. spectral entropy and spectral energy in each IMF are extracted and fed to …,True,uJlD-A0AAAAJ:W7OEmFMy1HYC,195,https://www.worldscientific.com/doi/abs/10.1142/S012906571250027X,14394167560419871639,/scholar?cites=14394167560419871639,,,https://www.academia.edu/download/46492254/0c960531c0d43314b1000000.pdf,0,0,0
1278664,Automated EEG-based screening of depression using deep convolutional neural network,2018,U Rajendra Acharya and Shu Lih Oh and Yuki Hagiwara and Jen Hong Tan and Hojjat Adeli and D Puthankattil Subha,161,Computer methods and programs in biomedicine,,103-113,Elsevier,In recent years. advanced neurocomputing and machine learning techniques have been used for Electroencephalogram (EEG)-based diagnosis of various neurological disorders. In this paper. a novel computer model is presented for EEG-based screening of depression using a deep neural network machine learning approach. known as Convolutional Neural Network (CNN). The proposed technique does not require a semi-manually-selected set of features to be fed into a classifier for classification. It learns automatically and adaptively from the input EEG signals to differentiate EEGs obtained from depressive and normal subjects. The model was tested using EEGs obtained from 15 normal and 15 depressed patients. The algorithm attained accuracies of 93.5% and 96.0% using EEG signals from the left and right hemisphere. respectively. It was discovered in this research that the EEG signals from the right …,True,uJlD-A0AAAAJ:K3LRdlH-MEoC,186,https://www.sciencedirect.com/science/article/pii/S0169260718301494,2494396273575643656,/scholar?cites=2494396273575643656,,,https://www.researchgate.net/profile/Yuki_Hagiwara2/publication/324599164_Automated_EEG-based_Screening_of_Depression_Using_Deep_Convolutional_Neural_Network/links/5ad7e3ef458515c60f588de5/Automated-EEG-based-Screening-of-Depression-Using-Deep-Convolutional-Neural-Network.pdf,0,0,0
1278665,Block compressed sensing of images using directional transforms,2009,Sungkwang Mun and James E Fowler,,,,3021-3024,IEEE,Block-based random image sampling is coupled with a projection-driven compressed-sensing recovery that encourages sparsity in the domain of directional transforms simultaneously with a smooth reconstructed image. Both contourlets as well as complex-valued dual-tree wavelets are considered for their highly directional representation. while bivariate shrinkage is adapted to their multiscale decomposition structure to provide the requisite sparsity constraint. Smoothing is achieved via a Wiener filter incorporated into iterative projected Landweber compressed-sensing recovery. yielding fast reconstruction. The proposed approach yields images with quality that matches or exceeds that produced by a popular. yet computationally expensive. technique which minimizes total variation. Additionally. reconstruction quality is substantially superior to that from several prominent pursuits-based algorithms that do not …,True,A5A5NWIAAAAJ:qUcmZB5y_30C,613,https://ieeexplore.ieee.org/abstract/document/5414429/,1447288473528600747,/scholar?cites=1447288473528600747,,,http://my.ece.msstate.edu/faculty/fowler/Publications/Papers/MF2009.pdf,0,0,0
1278666,Hyperspectral image compression using JPEG2000 and principal component analysis,2007,Qian Du and James E Fowler,4,IEEE Geoscience and Remote sensing letters,2,201-205,IEEE,Principal component analysis (PCA) is deployed in JPEG2000 to provide spectral decorrelation as well as spectral dimensionality reduction. The proposed scheme is evaluated in terms of rate-distortion performance as well as in terms of information preservation in an anomaly-detection task. Additionally. the proposed scheme is compared to the common approach of JPEG2000 coupled with a wavelet transform for spectral decorrelation. Experimental results reveal that. not only does the proposed PCA-based coder yield rate-distortion and information-preservation performance superior to that of the wavelet-based coder. the best PCA performance occurs when a reduced number of PCs are retained and coded. A linear model to estimate the optimal number of PCs to use in such dimensionality reduction is proposed,True,A5A5NWIAAAAJ:aqlVkmm33-oC,447,https://ieeexplore.ieee.org/abstract/document/4156154/,14885298439632732894,/scholar?cites=14885298439632732894,,,https://www.researchgate.net/profile/Qian_Du/publication/3449831_Hyperspectral_Image_Compression_Using_JPEG2000_and_Principal_Component_Analysis/links/540e00c00cf2df04e756c70e.pdf,0,0,0
1278667,Locality-preserving dimensionality reduction and classification for hyperspectral image analysis,2011,Wei Li and Saurabh Prasad and James E Fowler and Lori Mann Bruce,50,IEEE Transactions on Geoscience and Remote Sensing,4,1185-1198,IEEE,Hyperspectral imagery typically provides a wealth of information captured in a wide range of the electromagnetic spectrum for each pixel in the image; however. when used in statistical pattern-classification tasks. the resulting high-dimensional feature spaces often tend to result in ill-conditioned formulations. Popular dimensionality-reduction techniques such as principal component analysis. linear discriminant analysis. and their variants typically assume a Gaussian distribution. The quadratic maximum-likelihood classifier commonly employed for hyperspectral analysis also assumes single-Gaussian class-conditional distributions. Departing from this single-Gaussian assumption. a classification paradigm designed to exploit the rich statistical structure of the data is proposed. The proposed framework employs local Fisher's discriminant analysis to reduce the dimensionality of the data while preserving its multimodal …,True,A5A5NWIAAAAJ:cFHS6HbyZ2cC,410,https://ieeexplore.ieee.org/abstract/document/6032745/,6705167806399022754,/scholar?cites=6705167806399022754,,,https://my.ece.msstate.edu/faculty/fowler/Publications/Papers/LPF2012.pdf,0,0,0
1278668,The redundant discrete wavelet transform and additive noise,2005,James E Fowler,12,IEEE Signal Processing Letters,9,629-632,IEEE,The behavior under additive noise of the redundant discrete wavelet transform (RDWT). which is a frame expansion that is essentially an undecimated discrete wavelet transform. is studied. Known prior results in the form of inequalities bound distortion energy in the original signal domain from additive noise in frame-expansion coefficients. In this letter. a precise relationship between RDWT-domain and original-signal-domain distortion for additive white noise in the RDWT domain is derived.,True,A5A5NWIAAAAJ:Wp0gIr-vW9MC,369,https://ieeexplore.ieee.org/abstract/document/1495429/,2149736629649374241,/scholar?cites=2149736629649374241,,,https://my.ece.msstate.edu/faculty/fowler/Publications/Papers/Fow2004a.pdf,0,0,0
1278669,Compressed-sensing recovery of images and video using multihypothesis predictions,2011,Chen Chen and Eric W Tramel and James E Fowler,,,,1193-1198,IEEE,Compressed-sensing reconstruction of still images and video sequences driven by multihypothesis predictions is considered. Specifically. for still images. multiple predictions drawn for an image block are made from spatially surrounding blocks within an initial non-predicted reconstruction. For video. multihypothesis predictions of the current frame are generated from one or more previously reconstructed reference frames. In each case. the predictions are used to generate a residual in the domain of the compressed-sensing random projections. This residual being typically more compressible than the original signal leads to improved reconstruction quality. To appropriately weight the hypothesis predictions. a Tikhonov regularization to an ill-posed least-squares optimization is proposed. Experimental results demonstrate that the proposed reconstructions outperform alternative strategies not employing …,True,A5A5NWIAAAAJ:uWQEDVKXjbEC,239,https://ieeexplore.ieee.org/abstract/document/6190204/,306412477692973758,/scholar?cites=306412477692973758,,,https://pdfs.semanticscholar.org/8d37/ee24df29ddbdbd1d4822eb9a7fade0db44f1.pdf,0,0,0
1278670,Block-based compressed sensing of images and video,2012,James E Fowler and Sungkwang Mun and Eric W Tramel,4,Foundations and Trends in Signal Processing,4,297-416,Now Publishers Inc.,A number of techniques for the compressed sensing of imagery are surveyed. Various imaging media are considered. including still images. motion video. as well as multiview image sets and multiview video. A particular emphasis is placed on block-based compressed sensing due to its advantages in terms of both lightweight reconstruction complexity as well as a reduced memory burden for the random-projection measurement operator. For multiple-image scenarios. including video and multiview imagery. motion and disparity compensation is employed to exploit frame-to-frame redundancies due to object motion and parallax. resulting in residual frames which are more compressible and thus more easily reconstructed from compressed-sensing measurements. Extensive experimental comparisons evaluate various prominent reconstruction algorithms for still-image. motion-video. and multiview scenarios in terms …,True,A5A5NWIAAAAJ:dshw04ExmUIC,216,https://dl.acm.org/doi/abs/10.1561/2000000033,7585257093160511621,/scholar?cites=7585257093160511621,,,https://dl.acm.org/doi/abs/10.1561/2000000033,0,0,0
1278671,Residual reconstruction for block-based compressed sensing of video,2011,Sungkwang Mun and James E Fowler,,,,183-192,IEEE,A simple block-based compressed-sensing reconstruction for still images is adapted to video. Incorporating reconstruction from a residual arising from motion estimation and compensation. the proposed technique alternatively reconstructs frames of the video sequence and their corresponding motion fields in an iterative fashion. Experimental results reveal that the proposed technique achieves significantly higher quality than a straightforward reconstruction that applies a still-image reconstruction independently frame by frame. a 3D reconstruction that exploits temporal correlation between frames merely in the form of a motion-agnostic 3D transform. and a similar. yet non-iterative. motion-compensated residual reconstruction.,True,A5A5NWIAAAAJ:JV2RwH3_ST0C,197,https://ieeexplore.ieee.org/abstract/document/5749476/,14056617767707900038,/scholar?cites=14056617767707900038,,,https://sungkwang.info/pub/MF2011_pres.pdf,0,0,0
1278672,Nearest regularized subspace for hyperspectral classification,2013,Wei Li and Eric W Tramel and Saurabh Prasad and James E Fowler,52,IEEE Transactions on Geoscience and Remote Sensing,1,477-489,IEEE,A classifier that couples nearest-subspace classification with a distance-weighted Tikhonov regularization is proposed for hyperspectral imagery. The resulting nearest-regularized-subspace classifier seeks an approximation of each testing sample via a linear combination of training samples within each class. The class label is then derived according to the class which best approximates the test sample. The distance-weighted Tikhonov regularization is then modified by measuring distance within a locality-preserving lower-dimensional subspace. Furthermore. a competitive process among the classes is proposed to simplify parameter tuning. Classification results for several hyperspectral image data sets demonstrate superior performance of the proposed approach when compared to other. more traditional classification techniques.,True,A5A5NWIAAAAJ:JoZmwDi-zQgC,195,https://ieeexplore.ieee.org/abstract/document/6472065/,2543645326515174330,/scholar?cites=2543645326515174330,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.703.6880&rep=rep1&type=pdf,0,0,0
1278673,Multiscale block compressed sensing with smoothed projected landweber reconstruction,2011,James E Fowler and Sungkwang Mun and Eric W Tramel,,,,564-568,IEEE,A multiscale variant of the block compressed sensing with smoothed projected Landweber reconstruction algorithm is proposed for the compressed sensing of images. In essence. block-based compressed-sensing sampling is deployed independently within each subband of each decomposition level of a wavelet transform of an image. The corresponding multiscale reconstruction interleaves Landweber steps on the individual blocks with a smoothing filter in the spatial domain of the image as well as thresholding within a sparsity transform. Experimental results reveal that the proposed multiscale reconstruction preserves the fast computation associated with block-based compressed sensing while rivaling the reconstruction quality of a popular total-variation algorithm known for both its high-quality reconstruction as well as its exceedingly large computational cost.,True,A5A5NWIAAAAJ:D03iK_w7-QYC,176,https://ieeexplore.ieee.org/abstract/document/7073994/,1605093091181365234,/scholar?cites=1605093091181365234,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.370.582&rep=rep1&type=pdf,0,0,0
1278674,Compressive-projection principal component analysis,2009,James E Fowler,18,IEEE transactions on image processing,10,2230-2242,IEEE,Principal component analysis (PCA) is often central to dimensionality reduction and compression in many applications. yet its data-dependent nature as a transform computed via expensive eigendecomposition often hinders its use in severely resource-constrained settings such as satellite-borne sensors. A process is presented that effectively shifts the computational burden of PCA from the resource-constrained encoder to a presumably more capable base-station decoder. The proposed approach. compressive-projection PCA (CPPCA). is driven by projections at the sensor onto lower-dimensional subspaces chosen at random. while the CPPCA decoder. given only these random projections. recovers not only the coefficients associated with the PCA transform. but also an approximation to the PCA transform basis itself. An analysis is presented that extends existing Rayleigh-Ritz theory to the special case of highly …,True,A5A5NWIAAAAJ:HDshCWvjkbEC,172,https://ieeexplore.ieee.org/abstract/document/5071221/,12034249334001569419,/scholar?cites=12034249334001569419,,,https://my.ece.msstate.edu/faculty/fowler/Publications/Papers/Fow2009.pdf,0,0,0
1278675,QccPack: An open-source software library for quantization. compression. and coding,2000,James E Fowler,4115,,,294-301,International Society for Optics and Photonics,We describe the QccPack software package. an open-source collection of library routines and utility programs for quantization. compression. and coding of data. QccPack is being written to expedite data-compression research and development by providing general and reliable implementations of common compression techniques. Functionality of the current release includes entropy coding. scalar quantization. vector quantization. adaptive vector quantization. wavelet transforms and subband coding. error-correcting codes. image-processing support. and general vector-math. matrix-math. file-I/O. and error-message routines. All QccPack functionality is accessible via library calls; additionally. many utility programs provide command-line access. The QccPack software package. downloadable free of charge from the QccPack Web page. is published under the terms of the GNU General Public License and the GNU …,True,A5A5NWIAAAAJ:4DMP91E08xMC,156,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4115/0000/QccPack--an-open-source-software-library-for-quantization-compression/10.1117/12.411554.short,8329374594826539435,/scholar?cites=8329374594826539435,,,https://cavs.msstate.edu/publications/docs/2000/08/5054fowler04.pdf,0,0,0
1278676,System and method for indexing. searching. identifying. and editing portions of electronic multimedia files,2009,Sanghoon Sull and Hyeokman Kim and Min Gyo Chung and Ja-cheon Yoon and Hyungseok Choi,,,,,,A method and system are provided for tagging. indexing. searching. retrieving. manipulating. and editing video images on a wide area network such as the Internet. A first set of methods is provided for enabling users to add bookmarks to multimedia files. such as movies. and audio files. such as music. The multimedia bookmark facilitates the searching of portions or segments of multimedia files. particularly when used in conjunction with a search engine. Additional methods are provided that reformat a video image for use on a variety of devices that have a wide range of resolutions by selecting some material (in the case of smaller resolutions) or more material (in the case of larger resolutions) from the same multimedia file. Still more methods are provided for interrogating images that contain textual information (in graphical form) so that the text may be copied to a tag or bookmark that can itself be indexed and …,True,WECOOxQAAAAJ:zYLM7Y9cAGgC,1327,https://patents.google.com/patent/US7624337B2/en,1104599060687558362,/scholar?cites=1104599060687558362,,,,0,0,0
1278677,Techniques for navigating multiple video streams,2006,Sanghoon Sull and Hyeokman Kim and Yeon-Seok Seong and Michael Rostoker and Jung Kim,,,,,,Techniques for poster-thumbnail and/or animated thumbnail development and/or usage to effectively navigate for potential selection between a plurality of images or programs/video files or video segments. The poster and animated thumbnail images are presented in a GUI on adapted apparatus to provide an efficient system for navigating. browsing and/or selecting images or programs or video segments to be viewed by a user. The poster and animated thumbnails may be automatically produced without human-necessary editing and may also have one or more various associated data (such as text overlay. image overlay. cropping. text or image deletion or replacement. and/or associated audio).,True,WECOOxQAAAAJ:R3hNpaxXUhUC,680,https://patents.google.com/patent/US20060064716A1/en,9246565860398592852,/scholar?cites=9246565860398592852,,,https://patentimages.storage.googleapis.com/pdfs/US20060064716.pdf,0,0,0
1278678,Method and apparatus for fast metadata generation. delivery and access for live broadcast program,2009,Sanghoon Sull and Hyeokman Kim and Ja-cheon Yoon and Min Gyo Chung,,,,,,Techniques for fast indexing of live video broadcasts are provided which incorporate both efficient manual processing and automatic indexing steps to generate semantically meaningful and practically usable highlight hierarchy of broadcast television programs in real-time. In one technique. a list of predefined keywords is provided. describing the highlights. and the manual marking process can be implemented by just a few mouse clicks. A technique is provided for grouping highlights into a semantic hierarchy in real-time. A technique is provided for efficiently generating highlight metadata on live broadcast programs. using a coarse-to-fine indexing methodology in order for a operator to quickly generate highlight summaries of live broadcast programs.,True,WECOOxQAAAAJ:u_35RYKgDlwC,487,https://patents.google.com/patent/US7548565B2/en,16202869516714082228,/scholar?cites=16202869516714082228,,,https://patentimages.storage.googleapis.com/a8/b9/ff/26eb5764c4f893/US7548565.pdf,0,0,0
1278679,Efficient video indexing scheme for content-based retrieval,1999,Hyun Sung Chang and Sanghoon Sull and Sang Uk Lee,9,IEEE Transactions on Circuits and Systems for Video Technology,8,1269-1279,IEEE,Extracting a small number of key frames that can abstract the content of video is very important for efficient browsing and retrieval in video databases. In this paper. the key frame extraction problem is considered from a set-theoretic point of view. and systematic algorithms are derived to find a compact set of key frames that can represent a video segment for a given degree of fidelity. The proposed extraction algorithms can be hierarchically applied to obtain a tree-structured key frame hierarchy that is a multilevel abstract of the video. The key frame hierarchy enables an efficient content-based retrieval by using the depth-first search scheme with pruning.. Intensive experiments on a variety of video sequences are presented to demonstrate the improved performance of the proposed algorithms over the existing approaches.,True,WECOOxQAAAAJ:IjCSPb-OGe4C,347,https://ieeexplore.ieee.org/abstract/document/809161/,1085370948703299067,/scholar?cites=1085370948703299067,,,https://dml.korea.ac.kr/wp-content/uploads/2019/05/Efficient-Video-Indexing-Scheme-for-Content-Based-Retrieval.pdf,0,0,0
1278680,System and method for indexing. searching. identifying. and editing multimedia files,2010,Sanghoon Sull and Hyeokman Kim,,,,,,A method and system are provided for tagging. indexing. searching. retrieving. manipulating. and editing video images on a wide area network such as the Internet. A first set of methods is provided for enabling users to add bookmarks to multimedia files. such as movies. and audio files. such as music. The multimedia bookmark facilitates the searching of portions or segments of multimedia files. particularly when used in conjunction with a search engine. Additional methods are provided that reformat a video image for use on a variety of devices that have a wide range of resolutions by selecting some material (in the case of smaller resolutions) or more material (in the case of larger resolutions) from the same multimedia file. Still more methods are provided for interrogating images that contain textual information (in graphical form) so that the text may be copied to a tag or bookmark that can itself be indexed and …,True,WECOOxQAAAAJ:1sJd4Hv_s6UC,326,https://patents.google.com/patent/US7823055B2/en,18113669605064331310,/scholar?cites=18113669605064331310,,,https://patentimages.storage.googleapis.com/02/bb/fe/d0460166be05a9/US7823055.pdf,0,0,0
1278681,Methods and apparatuses for viewing. browsing. navigating and bookmarking videos and displaying images,2004,Sanghoon Sull and Seong Chun and Ja-cheon Yoon and Jung-Rim Kim and Hyeokman Kim,,,,,,Locally generating content characteristics for a plurality of video programs which have been recorded and displaying the content characteristics of the plurality of video programs. thereby enabling users to easily select the video of interest as well as a segment of interest within the selected video. The content characteristic can be generated according to user preference. and will typically comprise at least one key frame image or a plurality of images displayed in the form of an animated image or a video stream shown in a small size.,True,WECOOxQAAAAJ:SeFeTyx0c_EC,321,https://patents.google.com/patent/US20040128317A1/en,15279507640227891460,/scholar?cites=15279507640227891460,,,https://patentimages.storage.googleapis.com/39/2a/15/dc5968f385225f/US20040128317A1.pdf,0,0,0
1278682,Delivering and processing multimedia bookmark,2005,Hyeokman Kim and Ja-cheon Yoon and Sanghoon Sull and Jung Kim and Seong Chun,,,,,,A multimedia bookmark (VMark) bulletin board service (BBS) system comprises: a web host comprising storage for messages. a web server. and a VMark BBS server; a media host comprising storage for audiovisual (AV) files. and a streaming server; a client comprising storage for VMark. a web browser. a media player and a VMark client; and a VMark server located at the media host or at the client; a communication network connecting the web host. the media host and the client. A method of performing a multimedia bookmark bulletin board service (BBS) comprises: creating a message including a multimedia bookmark for an AV file; and posting the message into the multimedia bookmark BBS. A method of sending multimedia bookmark (VMark) between clients comprises: at a first client. making a VMark indicative of a bookmarked position in an AV program; sending the VMark from the first client to a second client …,True,WECOOxQAAAAJ:NaGl4SEjCO4C,318,https://patents.google.com/patent/US20050210145A1/en,12834045085189656740,/scholar?cites=12834045085189656740,,,https://patentimages.storage.googleapis.com/cf/d2/59/803a0cf447c3d8/US20050210145A1.pdf,0,0,0
1278683,Delivery and presentation of content-relevant information associated with frames of audio-visual programs,2005,Sanghoon Sull and Jung Kim and Seong Chun and Ja-cheon Yoon,,,,,,A method for delivery and presentation of content-relevant information associated with frames in an AV program enables TV viewers to retrieve information on the contents (for example. objects. items. concepts and the like) associated with a frame or a set of frames (video segments) when they watch TV or video programs. The information relevant to frame (s) is delivered to a STB or DVR by third-party service providers through back channels such as the Internet if the information of how to accurately access the frames pointed by STB users are delivered to the service providers. and the content-relevant information may be presented in the form of a GUI for the TV viewer.,True,WECOOxQAAAAJ:IWHjjKOFINEC,268,https://patents.google.com/patent/US20050193425A1/en,7357507150080589070,/scholar?cites=7357507150080589070,,,https://patentimages.storage.googleapis.com/pdfs/US20050193425.pdf,0,0,0
1278684,Techniques for constructing and browsing a hierarchical video structure,2004,Hyeokman Kim and Min Chung and Sanghoon Sull and Sangwook Oh,,,,,,Techniques for providing an intuitive methodology for a user to control the process of constructing and/or browsing a semantic hierarchy of a video content with a computer controlled graphical user interface by utilizing a tree view of a video. a list view of a current segment. a view of visual rhythm and a view of hierarchical status bar. A graphical user interface (GUI) is used for constructing and browsing a hierarchical video structure. The GUI allows the easier video browsing of the final hierarchical video structure as well as the efficient construction or modeling of the intermediate hierarchies into the final one. The modeling can be done manually. automatically or semi-automatically. Especially during the process of manual or semi-automatic modeling. the convenient GUI increases the speed of the construction process. allowing the quick mechanism for checking the current status of intermediate hierarchies being …,True,WECOOxQAAAAJ:hC7cP41nSMkC,247,https://patents.google.com/patent/US20040125124A1/en,7421697354554037684,/scholar?cites=7421697354554037684,,,https://patentimages.storage.googleapis.com/09/44/42/f6f85c1f12db57/US20040125124A1.pdf,0,0,0
1278685,Processing and presentation of infomercials for audio-visual programs,2005,Sanghoon Sull and Seong Chun and Michael Rostoker and Hyeokman Kim,,,,,,Techniques are provided enabling users to search for. select and/or watch an infomercial of interest including commercials. advertisements. and the like from a recorded stream. The user's history can be analyzed in the DVR. and replacing an original advertisement in a live/recorded program by one or more other advertisement (s) belonging to a genre type from the user history stored in the DVR. A GUI is provided for an infomercial guide; and when a user selects the infomercial guide. displaying the infomercial guide so that the user can select infomercials of interest. The user may select the infomercial guide by pressing a dedicated key on a remote control. In a first window of the GUI. upper categories of infomercials that are recorded or downloaded in the DVR may be displayed. The user may select one of the upper categories of interest by moving a highlight cursor. In a second window of the GUI. a more detailed …,True,WECOOxQAAAAJ:NMxIlDl6LWMC,204,https://patents.google.com/patent/US20050204385A1/en,11511589770634966759,/scholar?cites=11511589770634966759,,,https://patentimages.storage.googleapis.com/d3/1c/a1/1c25b295776606/US20050204385A1.pdf,0,0,0
1278686,Rapid production of reduced-size images from compressed video streams,2008,Sanghoon Sull and Sungjoo Suh and Jung Rim Kim and Seong Soo Chun,,,,,,Methods for fast generating spatially reduced-size images directly from compressed video streams supporting the coding of interlaced frames through transform coding and motion compensation. A sequence of reduced-size images are rapidly generated from compressed video streams by efficiently combining the steps of inverse transform. down-sampling and construction of each field image. The construction of reduced-size field images also allows the efficient motion compensation. The fast generation of reduced-size images is applicable to a variety of low-cost applications such as video browsing. video summary. fast thumbnail playback and video indexing.,True,WECOOxQAAAAJ:2P1L_qKh6hAC,185,https://patents.google.com/patent/US7471834B2/en,14573486806189907844,/scholar?cites=14573486806189907844,,,https://patentimages.storage.googleapis.com/db/c9/a5/adcda94d7ca788/US7471834.pdf,0,0,0
1278687,Intratumor heterogeneity characterized by textural features on baseline 18F-FDG PET images predicts response to concomitant radiochemotherapy in esophageal cancer,2011,Florent Tixier and Catherine Cheze Le Rest and Mathieu Hatt and Nidal Albarghach and Olivier Pradier and Jean-Philippe Metges and Laurent Corcos and Dimitris Visvikis,52,Journal of Nuclear Medicine,3,369-378,Society of Nuclear Medicine,,True,xAYVzEAAAAAJ:u-x6o8ySG0sC,614,https://jnm.snmjournals.org/content/52/3/369.short,3123767499724229129,/scholar?cites=3123767499724229129,,,https://jnm.snmjournals.org/content/jnumed/52/3/369.full.pdf,0,0,0
1278688,The image biomarker standardization initiative: standardized quantitative radiomics for high-throughput image-based phenotyping,2020,Alex Zwanenburg and Martin Vallières and Mahmoud A Abdalah and Hugo JWL Aerts and Vincent Andrearczyk and Aditya Apte and Saeed Ashrafinia and Spyridon Bakas and Roelof J Beukinga and Ronald Boellaard and Marta Bogowicz and Luca Boldrini and Irène Buvat and Gary JR Cook and Christos Davatzikos and Adrien Depeursinge and Marie-Charlotte Desseroit and Nicola Dinapoli and Cuong Viet Dinh and Sebastian Echegaray and Issam El Naqa and Andriy Y Fedorov and Roberto Gatta and Robert J Gillies and Vicky Goh and Michael Götz and Matthias Guckenberger and Sung Min Ha and Mathieu Hatt and Fabian Isensee and Philippe Lambin and Stefan Leger and Ralph TH Leijenaar and Jacopo Lenkowicz and Fiona Lippert and Are Losnegård and Klaus H Maier-Hein and Olivier Morin and Henning Müller and Sandy Napel and Christophe Nioche and Fanny Orlhac and Sarthak Pati and Elisabeth AG Pfaehler and Arman Rahmim and Arvind UK Rao and Jonas Scherer and Muhammad Musib Siddique and Nanna M Sijtsema and Jairo Socarras Fernandez and Emiliano Spezi and Roel JHM Steenbakkers and Stephanie Tanadini-Lang and Daniela Thorwarth and Esther GC Troost and Taman Upadhaya and Vincenzo Valentini and Lisanne V van Dijk and Joost van Griethuysen and Floris HP van Velden and Philip Whybra and Christian Richter and Steffen Löck,295,Radiology,2,328-338,Radiological Society of North America,Radiomic features may quantify characteristics present in medical                             imaging. However. the lack of standardized definitions and validated                             reference values have hampered clinical use.To standardize a set of 174 radiomic features.Radiomic features were assessed in three phases. In phase I. 487 features                             were derived from the basic set of 174 features. Twenty-five research                             teams with unique radiomics software implementations computed feature                             values directly from a digital phantom. without any additional image                             processing. In phase II. 15 teams computed values for 1347 derived                             features using a CT image of a patient with …,True,xAYVzEAAAAAJ:Bg7qf7VwUHIC,476,https://pubs.rsna.org/doi/abs/10.1148/radiol.2020191145,2804098788651751737,/scholar?cites=2804098788651751737,,,https://arxiv.org/pdf/1612.07003,0,0,0
1278689,A fuzzy locally adaptive Bayesian segmentation approach for volume determination in PET,2009,Mathieu Hatt and Catherine Cheze Le Rest and Alexandre Turzo and Christian Roux and Dimitris Visvikis,28,IEEE transactions on medical imaging,6,881-893,IEEE,Accurate volume estimation in positron emission tomography (PET) is crucial for different oncology applications. The objective of our study was to develop a new fuzzy locally adaptive Bayesian (FLAB) segmentation for automatic lesion volume delineation. FLAB was compared with a threshold approach as well as the previously proposed fuzzy hidden Markov chains (FHMC) and the fuzzy C-Means (FCM) algorithms. The performance of the algorithms was assessed on acquired datasets of the IEC phantom. covering a range of spherical lesion sizes (10-37 mm). contrast ratios (4:1 and 8:1). noise levels (1. 2. and 5 min acquisitions). and voxel sizes (8 and 64 mm 3 ). In addition. the performance of the FLAB model was assessed on realistic nonuniform and nonspherical volumes simulated from patient lesions. Results show that FLAB performs better than the other methodologies. particularly for smaller objects. The …,True,xAYVzEAAAAAJ:u5HHmVD_uO8C,358,https://ieeexplore.ieee.org/abstract/document/4749328/,11276644929671964505,/scholar?cites=11276644929671964505,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2912931/,0,0,0
1278690,Characterization of PET/CT images using texture analysis: the past. the present… any future?,2017,Mathieu Hatt and Florent Tixier and Larry Pierce and Paul E Kinahan and Catherine Cheze Le Rest and Dimitris Visvikis,44,,1,151-165,Springer Berlin Heidelberg,After seminal papers over the period 2009 – 2011. the use of texture analysis of PET/CT images for quantification of intratumour uptake heterogeneity has received increasing attention in the last 4 years. Results are difficult to compare due to the heterogeneity of studies and lack of standardization. There are also numerous challenges to address. In this review we provide critical insights into the recent development of texture analysis for quantifying the heterogeneity in PET/CT images. identify issues and challenges. and offer recommendations for the use of texture analysis in clinical research. Numerous potentially confounding issues have been identified. related to the complex workflow for the calculation of textural features. and the dependency of features on various factors such as acquisition. image reconstruction. preprocessing. functional volume segmentation. and methods of establishing and …,True,xAYVzEAAAAAJ:ipzZ9siozwsC,345,https://link.springer.com/content/pdf/10.1007/s00259-016-3427-0.pdf,6238729697209906019,/scholar?cites=6238729697209906019,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5283691/,0,0,0
1278691,18F-FDG PET uptake characterization through texture analysis: investigating the complementary nature of heterogeneity and functional tumor volume in a multi–cancer site patient …,2015,Mathieu Hatt and Mohamed Majdoub and Martin Vallières and Florent Tixier and Catherine Cheze Le Rest and David Groheux and Elif Hindié and Antoine Martineau and Olivier Pradier and Roland Hustinx and Remy Perdrisot and Remy Guillevin and Issam El Naqa and Dimitris Visvikis,56,Journal of nuclear medicine,1,38-44,Society of Nuclear Medicine,,True,xAYVzEAAAAAJ:q3oQSFYPqjQC,338,https://jnm.snmjournals.org/content/56/1/38.short,16666928419323260767,/scholar?cites=16666928419323260767,,,https://jnm.snmjournals.org/content/jnumed/56/1/38.full.pdf,0,0,0
1278692,Reproducibility of tumor uptake heterogeneity characterization through textural feature analysis in 18F-FDG PET,2012,Florent Tixier and Mathieu Hatt and Catherine Cheze Le Rest and Adrien Le Pogam and Laurent Corcos and Dimitris Visvikis,53,Journal of Nuclear Medicine,5,693-700,Society of Nuclear Medicine,,True,xAYVzEAAAAAJ:YsMSGLbcyi4C,298,https://jnm.snmjournals.org/content/53/5/693.short,16551452867057122827,/scholar?cites=16551452867057122827,,,https://jnm.snmjournals.org/content/53/5/693.full.pdf,0,0,0
1278693,Accurate automatic delineation of heterogeneous functional volumes in positron emission tomography for oncology applications,2010,Mathieu Hatt and Catherine Cheze Le Rest and Patrice Descourt and André Dekker and Dirk De Ruysscher and Michel Oellers and Philippe Lambin and Olivier Pradier and Dimitris Visvikis,77,International Journal of Radiation Oncology* Biology* Physics,1,301-308,Elsevier,Accurate contouring of positron emission tomography (PET) functional volumes is now considered crucial in image-guided radiotherapy and other oncology applications because the use of functional imaging allows for biological target definition. In addition. the definition of variable uptake regions within the tumor itself may facilitate dose painting for dosimetry optimization.Current state-of-the-art algorithms for functional volume segmentation use adaptive thresholding. We developed an approach called fuzzy locally adaptive Bayesian (FLAB). validated on homogeneous objects. and then improved it by allowing the use of up to three tumor classes for the delineation of inhomogeneous tumors (3-FLAB). Simulated and real tumors with histology data containing homogeneous and heterogeneous activity distributions were used to assess the algorithm's accuracy.The new 3-FLAB …,True,xAYVzEAAAAAJ:9yKSN-GCB0IC,186,https://www.sciencedirect.com/science/article/pii/S036030160902954X,7875606873431678982,/scholar?cites=7875606873431678982,,,https://www.hal.inserm.fr/inserm-00537776/document,0,0,0
1278694,Robustness of intratumour 18 F-FDG PET uptake heterogeneity quantification for therapy response prediction in oesophageal carcinoma,2013,Mathieu Hatt and Florent Tixier and Catherine Cheze Le Rest and Olivier Pradier and Dimitris Visvikis,40,European journal of nuclear medicine and molecular imaging,11,1662-1671,Springer Berlin Heidelberg,Intratumour uptake heterogeneity in PET quantified in terms of textural features for response to therapy has been investigated in several studies. including assessment of their robustness for reconstruction and physiological reproducibility. However. there has been no thorough assessment of the potential impact of preprocessing steps on the resulting quantification and its predictive value. The goal of this work was to assess the robustness of PET heterogeneity in textural features for delineation of functional volumes and partial volume correction (PVC).This retrospective analysis included 50 patients with oesophageal cancer. PVC of each PET image was performed. Tumour volumes were determined using fixed and adaptive thresholding. and the fuzzy locally adaptive Bayesian algorithm. and heterogeneity was quantified using local …,True,xAYVzEAAAAAJ:hqOjcs7Dif8C,178,https://link.springer.com/article/10.1007/s00259-013-2486-8,653052058422944197,/scholar?cites=653052058422944197,,,https://www.hal.inserm.fr/docs/00/84/59/76/PDF/manuscript.pdf,0,0,0
1278695,Prognostic value of 18 F-FDG PET image-based parameters in oesophageal cancer and impact of tumour delineation methodology,2011,Mathieu Hatt and Dimitris Visvikis and Nidal M Albarghach and Florent Tixier and Olivier Pradier and Catherine Cheze-le Rest,38,European journal of nuclear medicine and molecular imaging,7,1191-1202,Springer-Verlag,18F-fluorodeoxyglucose (FDG) positron emission tomography (PET) image-derived parameters. such as standardized uptake value (SUV). functional tumour length (TL) and tumour volume (TV) or total lesion glycolysis (TLG). may be useful for determining prognosis in patients with oesophageal carcinoma. The objectives of this work were to investigate the prognostic value of these indices in oesophageal cancer patients undergoing combined chemoradiotherapy treatment and the impact of TV delineation strategies.A total of 45 patients were retrospectively analysed. Tumours were delineated on pretreatment 18F-FDG scans using adaptive threshold and automatic (fuzzy locally adaptive Bayesian. FLAB) methodologies. The maximum standardized uptake value (SUVmax). SUVpeak. SUVmean. TL. TV and TLG were computed. The …,True,xAYVzEAAAAAJ:qjMakFHDy7sC,151,https://link.springer.com/article/10.1007/s00259-011-1755-7,928753903130668693,/scholar?cites=928753903130668693,,,https://www.hal.inserm.fr/inserm-00574267/file/manuscript.pdf,0,0,0
1278696,Impact of tumor size and tracer uptake heterogeneity in 18F-FDG PET and CT non–small cell lung cancer tumor delineation,2011,Mathieu Hatt and Catherine Cheze-le Rest and Angela Van Baardwijk and Philippe Lambin and Olivier Pradier and Dimitris Visvikis,52,Journal of Nuclear Medicine,11,1690-1697,Society of Nuclear Medicine,,True,xAYVzEAAAAAJ:Tyk-4Ss8FVUC,150,https://jnm.snmjournals.org/content/52/11/1690.short,4420264885121954814,/scholar?cites=4420264885121954814,,,https://jnm.snmjournals.org/content/52/11/1690.full.pdf,0,0,0
1278697,A multiresolution image based approach for correction of partial volume effects in emission tomography,2006,Nicolas Boussion and Mathieu Hatt and Frédéric Lamare and Yves Bizais and Alexandre Turzo and Catherine Cheze-Le Rest and Dimitri Visvikis,51,Physics in Medicine & Biology,7,1857,IOP Publishing,Partial volume effects (PVEs) are consequences of the limited spatial resolution in emission tomography. They lead to a loss of signal in tissues of size similar to the point spread function and induce activity spillover between regions. Although PVE can be corrected for by using algorithms that provide the correct radioactivity concentration in a series of regions of interest (ROIs). so far little attention has been given to the possibility of creating improved images as a result of PVE correction. Potential advantages of PVE-corrected images include the ability to accurately delineate functional volumes as well as improving tumour-to-background ratio. resulting in an associated improvement in the analysis of response to therapy studies and diagnostic examinations. respectively. The objective of our study was therefore to develop a methodology for PVE correction not only to enable the accurate recuperation of activity …,True,xAYVzEAAAAAJ:d1gkVwhDpl0C,137,https://iopscience.iop.org/article/10.1088/0031-9155/51/7/016/meta,10109129946436094546,/scholar?cites=10109129946436094546,,,http://nboussion.chez-alice.fr/doc/proof_pmb_boussion.pdf,0,0,0
1278698,Composite kernels for hyperspectral image classification,2006,Gustavo Camps-Valls and Luis Gomez-Chova and Jordi Muñoz-Marí and Joan Vila-Francés and Javier Calpe-Maravilla,3,IEEE geoscience and remote sensing letters,1,93-97,IEEE,This letter presents a framework of composite kernel machines for enhanced classification of hyperspectral images. This novel method exploits the properties of Mercer's kernels to construct a family of composite kernels that easily combine spatial and spectral information. This framework of composite kernels demonstrates: 1) enhanced classification accuracy as compared to traditional approaches that take into account the spectral information only: 2) flexibility to balance between the spatial and spectral information in the classifier; and 3) computational efficiency. In addition. the proposed family of kernel classifiers opens a wide field for future developments in which spatial and spectral information can be easily integrated.,True,7LQsYOcAAAAJ:qxL8FJ1GzNcC,1054,https://ieeexplore.ieee.org/abstract/document/1576697/,3627514708236222101,/scholar?cites=3627514708236222101,,,https://www.researchgate.net/profile/Javier_Calpe/publication/3449668_Composite_Kernels_for_Hyperspectral_Image_Classification/links/0c9605177d3376bd19000000/Composite-Kernels-for-Hyperspectral-Image-Classification.pdf,0,0,0
1278699,Kernel methods for remote sensing data analysis,2009,Gustau Camps-Valls and Lorenzo Bruzzone,,,,,John Wiley & Sons,Kernel methods have long been established as effective techniques in the framework of machine learning and pattern recognition. and have now become the standard approach to many remote sensing applications. With algorithms that combine statistics and geometry. kernel methods have proven successful across many different domains related to the analysis of images of the Earth acquired from airborne and satellite sensors. including natural resource control. detection and monitoring of anthropic infrastructures (eg urban areas). agriculture inventorying. disaster prevention and damage assessment. and anomaly and target detection. Presenting the theoretical foundations of kernel methods (KMs) relevant to the remote sensing domain. this book serves as a practical guide to the design and implementation of these methods. Five distinct parts present state-of-the-art research related to remote sensing based on the recent advances in kernel methods. analysing the related methodological and practical challenges: Part I introduces the key concepts of machine learning for remote sensing. and the theoretical and practical foundations of kernel methods. Part II explores supervised image classification including Super Vector Machines (SVMs). kernel discriminant analysis. multi-temporal image classification. target detection with kernels. and Support Vector Data Description (SVDD) algorithms for anomaly detection. Part III looks at semi-supervised classification with transductive SVM approaches for hyperspectral image classification and kernel mean data classification. Part IV examines regression and model inversion. including the concept of a …,True,7LQsYOcAAAAJ:eq2jaN3J8jMC,402,http://books.google.com/books?hl=en&lr=&id=_KhUMXQQkmQC&oi=fnd&pg=PR5&dq=info:7jG4_wmNjzgJ:scholar.google.com&ots=IZBO95yEUu&sig=6_uG2lgSD6Wv0-7IwvG3cfi7zL8,4075631261878071790,/scholar?cites=4075631261878071790,,,,0,0,0
1278700,Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection,2008,Gustavo Camps-Valls and Luis Gómez-Chova and Jordi Muñoz-Marí and José Luis Rojo-Álvarez and Manel Martínez-Ramón,46,IEEE Transactions on Geoscience and Remote Sensing,6,1822-1835,IEEE,The multitemporal classification of remote sensing images is a challenging problem. in which the efficient combination of different sources of information (e.g.. temporal. contextual. or multisensor) can improve the results. In this paper. we present a general framework based on kernel methods for the integration of heterogeneous sources of information. Using the theoretical principles in this framework. three main contributions are presented. First. a novel family of kernel-based methods for multitemporal classification of remote sensing images is presented. The second contribution is the development of nonlinear kernel classifiers for the well-known difference and ratioing change detection methods by formulating them in an adequate high-dimensional feature space. Finally. the presented methodology allows the integration of contextual information and multisensor images with different levels of nonlinear …,True,7LQsYOcAAAAJ:QIV2ME_5wuYC,383,https://ieeexplore.ieee.org/abstract/document/4509590/,3853767982982637893,/scholar?cites=3853767982982637893,,,https://burjcdigital.urjc.es/bitstream/handle/10115/2202/Kernel-Based%20Framework%20for%20Multitemporal-2008.pdf?sequence=1&isAllowed=y,0,0,0
1278701,Robust support vector method for hyperspectral data classification and knowledge discovery,2004,Gustavo Camps-Valls and Luis Gómez-Chova and Javier Calpe-Maravilla and José David Martín-Guerrero and Emilio Soria-Olivas and Luis Alonso-Chordá and José Moreno,42,IEEE Transactions on Geoscience and Remote sensing,7,1530-1542,IEEE,We propose the use of support vector machines (SVMs) for automatic hyperspectral data classification and knowledge discovery. In the first stage of the study. we use SVMs for crop classification and analyze their performance in terms of efficiency and robustness. as compared to extensively used neural and fuzzy methods. Efficiency is assessed by evaluating accuracy and statistical differences in several scenes. Robustness is analyzed in terms of: (1) suitability to working conditions when a feature selection stage is not possible and (2) performance when different levels of Gaussian noise are introduced at their inputs. In the second stage of this work. we analyze the distribution of the support vectors (SVs) and perform sensitivity analysis on the best classifier in order to analyze the significance of the input spectral bands. For classification purposes. six hyperspectral images acquired with the 128-band HyMAP …,True,7LQsYOcAAAAJ:rO6llkc54NcC,327,https://ieeexplore.ieee.org/abstract/document/1315837/,9631800554285336333,/scholar?cites=9631800554285336333,,,https://www.researchgate.net/profile/Emilio_Olivas/publication/3203526_Robust_support_vector_method_for_hyperspectral_data_classification_and_knowledge_discovery/links/09e4150c257f5ca1c4000000.pdf,0,0,0
1278702,Semisupervised image classification with Laplacian support vector machines,2008,Luis Gómez-Chova and Gustavo Camps-Valls and Jordi Munoz-Mari and Javier Calpe,5,IEEE Geoscience and Remote Sensing Letters,3,336-340,IEEE,This letter presents a semisupervised method based on kernel machines and graph theory for remote sensing image classification. The support vector machine (SVM) is regularized with the unnormalized graph Laplacian. thus leading to the Laplacian SVM (LapSVM). The method is tested in the challenging problems of urban monitoring and cloud screening. in which an adequate exploitation of the wealth of unlabeled samples is critical. Results obtained using different sensors. and with low number of training samples. demonstrate the potential of the proposed LapSVM for remote sensing image classification.,True,7LQsYOcAAAAJ:u5HHmVD_uO8C,254,https://ieeexplore.ieee.org/abstract/document/4476091/,181590484388271523,/scholar?cites=181590484388271523,,,https://isp.uv.es/papers/Gomez-Chova08_IEEEGRSL.pdf,0,0,0
1278703,Semisupervised one-class support vector machines for classification of remote sensing data,2010,Jordi Mũnoz-Marí and Francesca Bovolo and Luis Gómez-Chova and Lorenzo Bruzzone and Gustavo Camp-Valls,48,IEEE transactions on geoscience and remote sensing,8,3188-3197,IEEE,This paper presents two semisupervised one-class support vector machine (OC-SVM) classifiers for remote sensing applications. In  one-class  image classification. one tries to detect pixels belonging to one of the classes in the image and reject the others. When few labeled pixels of only one class are available. obtaining a reliable classifier is a difficult task. In the particular case of SVM-based classifiers. this task is even harder because the free parameters of the model need to be finely adjusted. but no clear criterion can be adopted. In order to improve the OC-SVM classifier accuracy and alleviate the problem of free-parameter selection. the information provided by unlabeled samples present in the scene can be used. In this paper. we present two state-of-the-art algorithms for semisupervised one-class classification for remote sensing classification problems. The first proposed algorithm is based on modifying the …,True,7LQsYOcAAAAJ:eMMeJKvmdy0C,237,https://ieeexplore.ieee.org/abstract/document/5460897/,2941424115454501687,/scholar?cites=2941424115454501687,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.462.3363&rep=rep1&type=pdf,0,0,0
1278704,Multimodal classification of remote sensing images: A review and future directions,2015,Luis Gómez-Chova and Devis Tuia and Gabriele Moser and Gustau Camps-Valls,103,,9,1560-1584,IEEE,Earth observation through remote sensing images allows the accurate characterization and identification of materials on the surface from space and airborne platforms. Multiple and heterogeneous image sources can be available for the same geographical region: multispectral. hyperspectral. radar. multitemporal. and multiangular images can today be acquired over a given scene. These sources can be combined/fused to improve classification of the materials on the surface. Even if this type of systems is generally accurate. the field is about to face new challenges: the upcoming constellations of satellite sensors will acquire large amounts of images of different spatial. spectral. angular. and temporal resolutions. In this scenario. multimodal image fusion stands out as the appropriate framework to address these problems. In this paper. we provide a taxonomical view of the field and review the current methodologies …,True,7LQsYOcAAAAJ:abG-DnoFyZgC,210,https://ieeexplore.ieee.org/abstract/document/7182258/,10505770644988682080,/scholar?cites=10505770644988682080,,,,0,0,0
1278705,Remote sensing image processing,2011,Gustavo Camps-Valls and Devis Tuia and Luis Gómez-Chova and Sandra Jiménez and Jesús Malo,5,"Synthesis Lectures on Image, Video, and Multimedia Processing",1,1-192,Morgan & Claypool Publishers,Earth observation is the field of science concerned with the problem of monitoring and modeling the processes on the Earth surface and their interaction with the atmosphere. The Earth is continuously monitored with advanced optical and radar sensors. The images are analyzed and processed to deliver useful products to individual users. agencies and public administrations. To deal with these problems. remote sensing image processing is nowadays a mature research area. and the techniques developed in the field allow many real-life applications with great societal value. For instance. urban monitoring. fire detection or flood prediction can have a great impact on economical and environmental issues. To attain such objectives. the remote sensing community has turned into a multidisciplinary field of science that embraces physics. signal theory. computer science. electronics and communications. From a …,True,7LQsYOcAAAAJ:5ugPr518TE4C,175,https://www.morganclaypool.com/doi/abs/10.2200/S00392ED1V01Y201107IVM012,16448685730264877908,/scholar?cites=16448685730264877908,,,,0,0,0
1278706,Hyperspectral system for early detection of rottenness caused by Penicillium digitatum in mandarins,2008,J Gómez-Sanchis and L Gómez-Chova and Nuria Aleixos and G Camps-Valls and Clara Montesinos-Herrero and Enrique Moltó and José Blasco,89,Journal of Food Engineering,1,80-86,Elsevier,Nowadays. the detection of fruit infected with Penicillium sp. fungi on packing lines is carried out manually under ultraviolet illumination. Ultraviolet sources induce visible fluorescence of essential oils. present in the skin of citrus and which are released by the action of fungi. thus increasing the contrast between sound and rotten skin. This work analyses a set of techniques aimed at detecting rotten citrus without the use of UV lighting. The techniques used include hyperspectral image acquisition. pre-processing and calibration. feature selection and segmentation using linear and non-linear methods for classification of fruits. Different methods such as correlation analysis. mutual information. stepwise. and genetic algorithms based on linear discriminant analysis (LDA) are studied to select the most relevant bands. Image segmentation relies on the combination of efficient band selection techniques and also on pixel …,True,7LQsYOcAAAAJ:HDshCWvjkbEC,159,https://www.sciencedirect.com/science/article/pii/S0260877408001684,4912936927246129065,/scholar?cites=4912936927246129065,,,,0,0,0
1278707,Cloud-screening algorithm for ENVISAT/MERIS multispectral images,2007,Luis Gómez-Chova and Gustavo Camps-Valls and Javier Calpe-Maravilla and Luis Guanter and José Moreno,45,IEEE Transactions on Geoscience and Remote Sensing,12,4105-4118,IEEE,This paper presents a methodology for cloud screening of multispectral images acquired with the Medium Resolution Imaging Spectrometer (MERIS) instrument on-board the Environmental Satellite (ENVISAT). The method yields both a discrete cloud mask and a cloud-abundance product from MERIS level-1b data on a per-pixel basis. The cloud-screening method relies on the extraction of meaningful physical features (e.g.. brightness and whiteness). which are combined with atmospheric-absorption features at specific MERIS-band locations (oxygen and water-vapor absorptions) to increase the cloud-detection accuracy. All these features are inputs to an unsupervised classification algorithm; the cloud-probability output is then combined with a spectral unmixing procedure to provide a cloud-abundance product instead of binary flags. The method is conceived to be robust and applicable to a broad range of actual …,True,7LQsYOcAAAAJ:tkaPQYYpVKoC,148,https://ieeexplore.ieee.org/abstract/document/4378555/,17583352033385541451,/scholar?cites=17583352033385541451,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.516.7408&rep=rep1&type=pdf,0,0,0
1278708,Improved Fraunhofer Line Discrimination method for vegetation fluorescence quantification,2008,Luis Alonso and Luis Gomez-Chova and Joan Vila-Frances and Julia Amoros-Lopez and Luis Guanter and Javier Calpe and José Moreno,5,IEEE Geoscience and Remote Sensing Letters,4,620-624,IEEE,This letter presents a modification to the established Fraunhofer line discrimination (FLD) method for improving the accuracy of the solar-induced chlorophyll fluorescence (ChF) retrieval over terrestrial vegetation. The FLD method relies on the decoupling of reflected and ChF emitted radiation by the evaluation of measurements inside and outside the absorption bands. The improved FLD method introduces two correction coefficients that relate the values of the fluorescence and the reflectance inside and outside the absorption band. The new method uses the full spectral information around the absorption band to derive these coefficients. A sensitivity analysis has been performed to evaluate the impact of the correction coefficients on the accuracy of the ChF estimation. The new formulation has been tested for the O 2  A-band on synthetic data obtaining lower errors in comparison to the standard FLD and has been …,True,7LQsYOcAAAAJ:mvPsJ3kp5DgC,144,https://ieeexplore.ieee.org/abstract/document/4656472/,15605968358299954734,/scholar?cites=15605968358299954734,,,https://www.researchgate.net/profile/Luis_Alonso3/publication/224342461_Improved_Fraunhofer_Line_Discrimination_Method_for_Vegetation_Fluorescence_Quantification/links/569cc39608aed091d774de15/Improved-Fraunhofer-Line-Discrimination-Method-for-Vegetation-Fluorescence-Quantification.pdf,0,0,0
1278709,Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising,2017,Kai Zhang and Wangmeng Zuo and Yunjin Chen and Deyu Meng and Lei Zhang,,"IEEE TIP 2017, code: https://github.com/cszn/KAIR",,,,The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper. we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture. learning algorithm. and regularization method into image denoising. Specifically. residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level. our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e.. blind Gaussian denoising). With the residual learning strategy. DnCNN implicitly removes the latent clean image in the hidden …,True,0RycFIIAAAAJ:E7VqQtBCVmcC,3054,https://ieeexplore.ieee.org/abstract/document/7839189/,8389787286584772945,/scholar?cites=8389787286584772945,,,https://arxiv.org/pdf/1608.03981.pdf).,0,0,0
1278710,Learning Deep CNN Denoiser Prior for Image Restoration,2017,Kai Zhang and Wangmeng Zuo and Shuhang Gu and Lei Zhang,,,,,,Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically. those two kinds of methods have their respective merits and drawbacks. eg. model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile. discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that. with the aid of variable splitting techniques. denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (eg. deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However. the study of integration with fast discriminative denoiser prior is still lacking. To this end. this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers can not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.,True,0RycFIIAAAAJ:7H_jS4BsgvYC,889,http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Learning_Deep_CNN_CVPR_2017_paper.html,11733015574117803846,/scholar?cites=11733015574117803846,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Learning_Deep_CNN_CVPR_2017_paper.pdf,0,0,0
1278711,FFDNet: Toward a fast and flexible solution for CNN based image denoising,2018,Kai Zhang and Wangmeng Zuo and Lei Zhang,,"IEEE TIP 2018, code: https://github.com/cszn/KAIR",,,,Due to the fast inference and good performance. discriminative learning methods have been widely studied in image denoising. However. these methods mostly learn a specific model for each noise level. and require multiple models for denoising images with different noise levels. They also lack flexibility to deal with spatially variant noise. limiting their applications in practical denoising. To address these issues. we present a fast and flexible denoising convolutional neural network. namely FFDNet. with a tunable noise level map as the input. The proposed FFDNet works on downsampled sub-images. achieving a good trade-off between inference speed and denoising performance. In contrast to the existing discriminative denoisers. FFDNet enjoys several desirable properties. including: 1) the ability to handle a wide range of noise levels (i.e.. [0. 75]) effectively with a single network; 2) the ability to remove spatially …,True,0RycFIIAAAAJ:V_vSwabWVtYC,663,https://ieeexplore.ieee.org/abstract/document/8365806/,15583678590061571270,/scholar?cites=15583678590061571270,,,https://arxiv.org/pdf/1710.04026,0,0,0
1278712,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang and Bee Lim and Sanghyun Son and Heewon Kim and Seungjun Nah and Kyoung Mu Lee and Xintao Wang and Yapeng Tian and Ke Yu and Yulun Zhang and Shixiang Wu and Chao Dong and Liang Lin and Yu Qiao and Chen Change Loy and Woong Bae and Jaejun Yoo and Yoseob Han and Jong Chul Ye and Jae-Seok Choi and Munchurl Kim and Yuchen Fan and Jiahui Yu and Wei Han and Ding Liu and Haichao Yu and Zhangyang Wang and Honghui Shi and Xinchao Wang and Thomas S Huang and Yunjin Chen and Kai Zhang and Wangmeng Zuo and Zhimin Tang and Linkai Luo and Shaohui Li and Min Fu and Lei Cao and Wen Heng and Giang Bui and Truc Le and Ye Duan and Dacheng Tao and Ruxin Wang and Xu Lin and Jianxin Pang and Jinchang Xu and Yu Zhao and Xiangyu Xu and Jinshan Pan and Deqing Sun and Yujin Zhang and Xibin Song and Yuchao Dai and Xueying Qin and Xuan-Phung Huynh and Tiantong Guo and Hojjat Seyed Mousavi and Tiep Huu Vu and Vishal Monga and Cristovao Cruz and Karen Egiazarian and Vladimir Katkovnik and Rakesh Mehta and Arnav Kumar Jain and Abhinav Agarwalla and Ch V Sai Praveen,,,,,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,0RycFIIAAAAJ:WWeOtg8bX_EC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1278713,Learning a single convolutional super-resolution network for multiple degradations,2018,Kai Zhang and Wangmeng Zuo and Lei Zhang,,"CVPR 2018, code: https://github.com/cszn/KAIR",,,,Recent years have witnessed the unprecedented success of deep convolutional neural networks (CNNs) in single image super-resolution (SISR). However. existing CNN-based SISR methods mostly assume that a low-resolution (LR) image is bicubicly downsampled from a high-resolution (HR) image. thus inevitably giving rise to poor performance when the true degradation does not follow this assumption. Moreover. they lack scalability in learning a single model to non-blindly deal with multiple degradations. To address these issues. we propose a general framework with dimensionality stretching strategy that enables a single convolutional super-resolution network to take two key factors of the SISR degradation process. ie. blur kernel and noise level. as input. Consequently. the super-resolver can handle multiple and even spatially variant degradations. which significantly improves the practicability. Extensive experimental results on synthetic and real LR images show that the proposed convolutional super-resolution network not only can produce favorable results on multiple degradations but also is computationally efficient. providing a highly effective and scalable solution to practical SISR applications.,True,0RycFIIAAAAJ:e84hm74t-eoC,360,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Learning_a_Single_CVPR_2018_paper.html,12748399699451058322,/scholar?cites=12748399699451058322,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Learning_a_Single_CVPR_2018_paper.pdf,0,0,0
1278714,Toward convolutional blind denoising of real photographs,2019,Shi Guo and Zifei Yan and Kai Zhang and Wangmeng Zuo and Lei Zhang,,,,,,While deep convolutional neural networks (CNNs) have achieved impressive success in image denoising with additive white Gaussian noise (AWGN). their performance remains limited on real-world noisy photographs. The main reason is that their learned models are easy to overfit on the simplified AWGN model which deviates severely from the complicated real-world noise model. In order to improve the generalization ability of deep CNN denoisers. we suggest training a convolutional blind denoising network (CBDNet) with more realistic noise model and real-world noisy-clean image pairs. On the one hand. both signal-dependent noise and in-camera signal processing pipeline is considered to synthesize realistic noisy images. On the other hand. real-world noisy photographs and their nearly noise-free counterparts are also included to train our CBDNet. To further provide an interactive strategy to rectify denoising result conveniently. a noise estimation subnetwork with asymmetric learning to suppress under-estimation of noise level is embedded into CBDNet. Extensive experimental results on three datasets of real-world noisy pho-tographs clearly demonstrate the superior performance of CBDNet over state-of-the-arts in terms of quantitative met-rics and visual quality. The code has been made available at https://github. com/GuoShi28/CBDNet.,True,0RycFIIAAAAJ:Vztgr1qGG8IC,236,http://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.html,10808191985805196679,/scholar?cites=10808191985805196679,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.pdf,0,0,0
1278715,Multi-level wavelet-CNN for image restoration,2018,Pengju Liu and Hongzhi Zhang and Kai Zhang and Liang Lin and Wangmeng Zuo,,,,,,The tradeoff between receptive field size and efficiency is a crucial issue in low level vision. Plain convolutional networks (CNNs) generally enlarge the receptive field at the expense of computational cost. Recently. dilated filtering has been adopted to address this issue. But it suffers from gridding effect. and the resulting receptive field is only a sparse sampling of input image with checkerboard patterns. In this paper. we present a novel multi-level wavelet CNN (MWCNN) model for better tradeoff between receptive field size and computational efficiency. With the modified U-Net architecture. wavelet transform is introduced to reduce the size of feature maps in the contracting subnetwork. Furthermore. another convolutional layer is further used to decrease the channels of feature maps. In the expanding subnetwork. inverse wavelet transform is then deployed to reconstruct the high resolution feature maps. Our MWCNN can also be explained as the generalization of dilated filtering and subsampling. and can be applied to many image restoration tasks. The experimental results clearly show the effectiveness of MWCNN for image denoising. single image super-resolution. and JPEG image artifacts removal.,True,0RycFIIAAAAJ:Nw_I7GeUguwC,202,https://openaccess.thecvf.com/content_cvpr_2018_workshops/w13/html/Liu_Multi-Level_Wavelet-CNN_for_CVPR_2018_paper.html,9078715442130893321,/scholar?cites=9078715442130893321,,,http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Liu_Multi-Level_Wavelet-CNN_for_CVPR_2018_paper.pdf,0,0,0
1278716,End-to-End Blind Image Quality Assessment Using Deep Neural Networks,2018,Kede Ma and Wentao Liu and Kai Zhang and Zhengfang Duanmu and Zhou Wang and Wangmeng Zuo,,IEEE TIP 2018,,,,We propose a multi-task end-to-end optimized deep neural network (MEON) for blind image quality assessment (BIQA). MEON consists of two sub-networks-a distortion identification network and a quality prediction network-sharing the early layers. Unlike traditional methods used for training multi-task networks. our training process is performed in two steps. In the first step. we train a distortion type identification sub-network. for which large-scale training samples are readily available. In the second step. starting from the pre-trained early layers and the outputs of the first sub-network. we train a quality prediction sub-network using a variant of the stochastic gradient descent method. Different from most deep neural networks. we choose biologically inspired generalized divisive normalization (GDN) instead of rectified linear unit as the activation function. We empirically demonstrate that GDN is effective at reducing …,True,0RycFIIAAAAJ:KI9T_ytC6pkC,176,https://ieeexplore.ieee.org/abstract/document/8110690/,15728934202050608122,/scholar?cites=15728934202050608122,,,https://ece.uwaterloo.ca/~k29ma/papers/18_TIP_MEON.pdf,0,0,0
1278717,Extreme learning machine and adaptive sparse representation for image classification,2016,Jiuwen Cao and Kai Zhang and Minxia Luo and Chun Yin and Xiaoping Lai,81,Neural networks,,91-102,Pergamon,Recent research has shown the speed advantage of extreme learning machine (ELM) and the accuracy advantage of sparse representation classification (SRC) in the area of image classification. Those two methods. however. have their respective drawbacks. e.g.. in general. ELM is known to be less robust to noise while SRC is known to be time-consuming. Consequently. ELM and SRC complement each other in computational complexity and classification accuracy. In order to unify such mutual complementarity and thus further enhance the classification performance. we propose an efficient hybrid classifier to exploit the advantages of ELM and SRC in this paper. More precisely. the proposed classifier consists of two stages: first. an ELM network is trained by supervised learning. Second. a discriminative criterion about the reliability of the obtained ELM output is adopted to decide whether the query image can be …,True,0RycFIIAAAAJ:_5tno0g5mFcC,161,https://www.sciencedirect.com/science/article/pii/S0893608016300673,2273066800080215617,/scholar?cites=2273066800080215617,,,https://www.researchgate.net/profile/Jiuwen_Cao/publication/304453759_Extreme_learning_machine_and_adaptive_sparse_representation_for_image_classification/links/57806d1408ae5f367d371752.pdf,0,0,0
1278718,Ntire 2018 challenge on single image super-resolution: Methods and results,2018,Radu Timofte and Shuhang Gu and Jiqing Wu and Luc Van Gool,,,,,,This paper reviews the 2nd NTIRE challenge on single image super-resolution (restoration of rich details in a low resolution image) with focus on proposed solutions and results. The challenge had 4 tracks. Track 1 employed the standard bicubic downscaling setup. while Tracks 2. 3 and 4 had realistic unknown downgrading operators simulating camera image acquisition pipeline. The operators were learnable through provided pairs of low and high resolution train images. The tracks had 145. 114. 101. and 113 registered participants. resp.. and 31 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,0RycFIIAAAAJ:inmFHauC9wsC,158,http://openaccess.thecvf.com/content_cvpr_2018_workshops/w13/html/Timofte_NTIRE_2018_Challenge_CVPR_2018_paper.html,308702806833114296,/scholar?cites=308702806833114296,,,http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Timofte_NTIRE_2018_Challenge_CVPR_2018_paper.pdf,0,0,0
1278719,Outlier-robust extreme learning machine for regression problems,2015,Kai Zhang and Minxia Luo,151,Neurocomputing,,1519-1527,Elsevier,Extreme learning machine (ELM). as one of the most useful techniques in machine learning. has attracted extensive attentions due to its unique ability for extremely fast learning. In particular. it is widely recognized that ELM has speed advantage while performing satisfying results. However. the presence of outliers may give rise to unreliable ELM model. In this paper. our study addresses the outlier robustness of ELM in regression problems. Based on the sparsity characteristic of outliers. this work proposes an outlier-robust ELM where the ℓ1-norm loss function is used to enhance the robustness. Specially. the fast and accurate augmented Lagrangian multiplier method is applied to guarantee the effectiveness and efficiency. According to the experiments on function approximation and some real-world applications. the proposed approach not only maintains the advantages from original ELM. but also shows notable …,True,0RycFIIAAAAJ:u-x6o8ySG0sC,128,https://www.sciencedirect.com/science/article/pii/S0925231214012053,15337076545496951515,/scholar?cites=15337076545496951515,,,,0,0,0
1278720,Hyperactivity and hyperconnectivity of the default network in schizophrenia and in first-degree relatives of persons with schizophrenia,2009,Susan Whitfield-Gabrieli and Heidi W Thermenos and Snezana Milanovic and Ming T Tsuang and Stephen V Faraone and Robert W McCarley and Martha E Shenton and Alan I Green and Alfonso Nieto-Castanon and Peter LaViolette and Joanne Wojcik and John DE Gabrieli and Larry J Seidman,106,Proceedings of the National Academy of Sciences,4,1279-1284,National Academy of Sciences,We examined the status of the neural network mediating the default mode of brain function. which typically exhibits greater activation during rest than during task. in patients in the early phase of schizophrenia and in young first-degree relatives of persons with schizophrenia. During functional MRI. patients. relatives. and controls alternated between rest and performance of working memory (WM) tasks. As expected. controls exhibited task-related suppression of activation in the default network. including medial prefrontal cortex (MPFC) and posterior cingulate cortex/precuneus. Patients and relatives exhibited significantly reduced task-related suppression in MPFC. and these reductions remained after controlling for performance. Increased task-related MPFC suppression correlated with better WM performance in patients and relatives and with less psychopathology in all 3 groups. For WM task performance. patients …,True,FcYNVOUAAAAJ:u5HHmVD_uO8C,1282,https://www.pnas.org/content/106/4/1279.short,15888468379801543231,/scholar?cites=15888468379801543231,,,https://www.pnas.org/content/pnas/106/4/1279.full.pdf,0,0,0
1278721,Amyloid deposition is associated with impaired default network function in older persons without dementia,2009,Reisa A Sperling and Peter S LaViolette and Kelly O'Keefe and Jacqueline O'Brien and Dorene M Rentz and Maija Pihlajamaki and Gad Marshall and Bradley T Hyman and Dennis J Selkoe and Trey Hedden and Randy L Buckner and J Alex Becker and Keith A Johnson,63,Neuron,2,178-188,Cell Press,Alzheimer's disease (AD) has been associated with functional alterations in a distributed network of brain regions linked to memory function. with a recent focus on the cortical regions collectively known as the default network. Posterior components of the default network. including the precuneus and posterior cingulate. are particularly vulnerable to early deposition of amyloid β-protein. one of the hallmark pathologies of AD. In this study. we use in vivo amyloid imaging to demonstrate that high levels of amyloid deposition are associated with aberrant default network functional magnetic resonance imaging (fMRI) activity in asymptomatic and minimally impaired older individuals. similar to the pattern of dysfunction reported in AD patients. These findings suggest that amyloid pathology is linked to neural dysfunction in brain regions supporting memory function and provide support for the hypothesis that cognitively intact …,True,FcYNVOUAAAAJ:u-x6o8ySG0sC,899,https://www.sciencedirect.com/science/article/pii/S0896627309005054,769562837414681609,/scholar?cites=769562837414681609,,,https://www.sciencedirect.com/science/article/pii/S0896627309005054,0,0,0
1278722,Functional alterations in memory networks in early Alzheimer’s disease,2010,Reisa A Sperling and Bradford C Dickerson and Maija Pihlajamaki and Patrizia Vannini and Peter S LaViolette and Ottavio V Vitolo and Trey Hedden and J Alex Becker and Dorene M Rentz and Dennis J Selkoe and Keith A Johnson,12,,1,27-43,Humana Press Inc,The hallmark clinical symptom of early Alzheimer’s disease (AD) is episodic memory impairment. Recent functional imaging studies suggest that memory function is subserved by a set of distributed networks. which include both the medial temporal lobe (MTL) system and the set of cortical regions collectively referred to as the default network. Specific regions of the default network. in particular. the posteromedial cortices. including the precuneus and posterior cingulate. are selectively vulnerable to early amyloid deposition in AD. These regions are also thought to play a key role in both memory encoding and retrieval. and are strongly functionally connected to the MTL. Multiple functional magnetic resonance imaging (fMRI) studies during memory tasks have revealed alterations in these networks in patients with clinical AD. Similar functional abnormalities have been detected in subjects at-risk for AD …,True,FcYNVOUAAAAJ:d1gkVwhDpl0C,540,https://link.springer.com/content/pdf/10.1007/s12017-009-8109-7.pdf,1568240869457538052,/scholar?cites=1568240869457538052,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3036844/,0,0,0
1278723,Precision measurement of the weak mixing angle in Moeller scattering,2005,PL Anthony and RG Arnold and C Arroyo and K Bega and J Biesiada and PE Bosted and G Bower and J Cahoon and R Carr and GD Cates and J-P Chen and E Chudakov and M Cooke and P Decowski and A Deur and W Emam and R Erickson and T Fieguth and C Field and J Gao and M Gary and K Gustafsson and RS Hicks and R Holmes and EW Hughes and TB Humensky and GM Jones and LJ Kaufman and L Keller and Yu G Kolomensky and KS Kumar and P LaViolette and D Lhuillier and RM Lombard-Nelsen and Z Marshall and P Mastromarino and RD McKeown and R Michaels and J Niedziela and M Olson and KD Paschke and GA Peterson and R Pitthan and D Relyea and SE Rock and O Saxton and J Singh and PA Souder and ZM Szalata and J Turner and B Tweedie and A Vacheret and D Walz and T Weber and J Weisend and M Woods and I Younus and SLAC E158 Collaboration,95,Physical review letters,8,081601,American Physical Society,We report on a precision measurement of the parity-violating asymmetry in fixed target electron-electron (Møller) scattering: A PV=[− 131±14 (stat)±10 (syst)]× 10− 9. leading to the determination of the weak mixing angle sin﻿ 2 θ W eff= 0.2397±0.0010 (stat)±0.0008 (syst). evaluated at Q 2= 0.026 GeV 2. Combining this result with the measurements of sin﻿ 2 θ W eff at the Z 0 pole. the running of the weak mixing angle is observed with over 6 σ significance. The measurement sets constraints on new physics effects at the TeV scale.,True,FcYNVOUAAAAJ:M3NEmzRMIkIC,394,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.95.081601,760820354951246677,/scholar?cites=760820354951246677,,,https://arxiv.org/pdf/hep-ex/0504049,0,0,0
1278724,Precision measurement of the weak mixing angle in Moeller scattering,2005,PL Anthony and RG Arnold and C Arroyo and K Bega and J Biesiada and PE Bosted and G Bower and J Cahoon and R Carr and GD Cates and J-P Chen and E Chudakov and M Cooke and P Decowski and A Deur and W Emam and R Erickson and T Fieguth and C Field and J Gao and M Gary and K Gustafsson and RS Hicks and R Holmes and EW Hughes and TB Humensky and GM Jones and LJ Kaufman and L Keller and Yu G Kolomensky and KS Kumar and P LaViolette and D Lhuillier and RM Lombard-Nelsen and Z Marshall and P Mastromarino and RD McKeown and R Michaels and J Niedziela and M Olson and KD Paschke and GA Peterson and R Pitthan and D Relyea and SE Rock and O Saxton and J Singh and PA Souder and ZM Szalata and J Turner and B Tweedie and A Vacheret and D Walz and T Weber and J Weisend and M Woods and I Younus and SLAC E158 Collaboration,95,Physical review letters,8,081601,American Physical Society,We report on a precision measurement of the parity-violating asymmetry in fixed target electron-electron (Møller) scattering: A PV=[− 131±14 (stat)±10 (syst)]× 10− 9. leading to the determination of the weak mixing angle sin﻿ 2 θ W eff= 0.2397±0.0010 (stat)±0.0008 (syst). evaluated at Q 2= 0.026 GeV 2. Combining this result with the measurements of sin﻿ 2 θ W eff at the Z 0 pole. the running of the weak mixing angle is observed with over 6 σ significance. The measurement sets constraints on new physics effects at the TeV scale.,True,FcYNVOUAAAAJ:iH-uZ7U-co4C,394,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.95.081601,760820354951246677,/scholar?cites=760820354951246677,,,https://arxiv.org/pdf/hep-ex/0504049,0,0,0
1278725,Precision Measurements of the Nucleon Strange Form Factors at ,2007,A Acha and KA Aniol and DS Armstrong and John Arrington and Todd Averett and SL Bailey and James Barber and Arie Beck and Hachemi Benaoum and Jay Benesch and PY Bertin and P Bosted and F Butaru and E Burtin and GD Cates and Y-C Chao and J-P Chen and E Chudakov and E Cisbani and B Craver and F Cusanno and R De Leo and P Decowski and A Deur and RJ Feuerbach and JM Finn and S Frullani and SA Fuchs and K Fuoti and Ronald Gilman and LE Glesener and K Grimm and JM Grames and JO Hansen and J Hansknecht and DW Higinbotham and R Holmes and T Holmstrom and H Ibrahim and CW De Jager and X Jiang and J Katich and LJ Kaufman and A Kelleher and PM King and A Kolarkar and S Kowalski and E Kuchina and KS Kumar and L Lagamba and P LaViolette and J LeRose and RA Lindgren and D Lhuillier and N Liyanage and DJ Margaziotis and P Markowitz and DG Meekins and Z-E Meziani and R Michaels and B Moffit and S Nanda and V Nelyubin and K Otis and KD Paschke and SK Phillips and M Poelker and R Pomatsalyuk and M Potokar and Y Prok and A Puckett and X Qian and Y Qiang and B Reitz and J Roche and A Saha and B Sawatzky and J Singh and K Slifer and S Sirca and R Snyder and P Solvignon and PA Souder and ML Stutzman and R Subedi and R Suleiman and V Sulkosky and WA Tobias and PE Ulmer and GM Urciuoli and K Wang and A Whitbeck and R Wilson and B Wojtsekhowski and H Yao and Y Ye and X Zhan and X Zheng and S Zhou and V Ziskin and HAPPEX Collaboration,98,Physical review letters,3,032301,American Physical Society,We report new measurements of the parity-violating asymmetry A PV in elastic scattering of 3 GeV electrons off hydrogen and He 4 targets with⟨ θ lab⟩≈ 6.0. The He 4 result is A PV=(+ 6.40±0.23 (stat)±0.12 (syst))× 10− 6. The hydrogen result is A PV=(− 1.58±0.12 (stat)±0.04 (syst))× 10− 6. These results significantly improve constraints on the electric and magnetic strange form factors G E s and G M s. We extract G E s= 0.002±0.014±0.007 at⟨ Q 2⟩= 0.077 GeV 2. and G E s+ 0.09 G M s= 0.007±0.011±0.006 at⟨ Q 2⟩= 0.109 GeV 2. providing new limits on the role of strange quarks in the nucleon charge and magnetization distributions.,True,FcYNVOUAAAAJ:bEWYMUwI8FkC,338,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.98.032301,17148794178484324429,/scholar?cites=17148794178484324429,,,https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1029&context=nrc_faculty_pubs,0,0,0
1278726,A functional magnetic resonance imaging study on the neural mechanisms of hyperalgesic nocebo effect,2008,Jian Kong and Randy L Gollub and Ginger Polich and Irving Kirsch and Peter LaViolette and Mark Vangel and Bruce Rosen and Ted J Kaptchuk,28,Journal of Neuroscience,49,13354-13362,Society for Neuroscience,Previous studies suggest that nocebo effects. sometimes termed “negative placebo effects.” can contribute appreciably to a variety of medical symptoms and adverse events in clinical trials and medical care. In this study. using a within-subject design. we combined functional magnetic resonance imaging (fMRI) and an expectation/conditioning manipulation model to investigate the neural substrates of nocebo hyperalgesia using heat pain on the right forearm. Thirteen subjects completed the study. Results showed that. after administering inert treatment. subjective pain intensity ratings increased significantly more on nocebo regions compared with the control regions in which no expectancy/conditioning manipulation was performed. fMRI analysis of hyperalgesic nocebo responses to identical calibrated noxious stimuli showed signal increases in brain regions including bilateral dorsal anterior cingulate cortex (ACC …,True,FcYNVOUAAAAJ:9yKSN-GCB0IC,260,https://www.jneurosci.org/content/28/49/13354.short,4124892849161007707,/scholar?cites=4124892849161007707,,,https://www.jneurosci.org/content/jneuro/28/49/13354.full.pdf,0,0,0
1278727,Longitudinal fMRI in elderly reveals loss of hippocampal activation with clinical decline,2010,JL O'brien and KM O'keefe and PS LaViolette and AN DeLuca and D Blacker and BC Dickerson and RA Sperling,74,Neurology,24,1969-1976,Wolters Kluwer Health. Inc. on behalf of the American Academy of Neurology,Background: Previous cross-sectional fMRI studies in subjects with prodromal Alzheimer disease (AD) have reported variable results. ranging from hypoactivation. similar to patients with AD. to paradoxically increased activation or hyperactivation compared to cognitively normal older individuals. We have hypothesized that subjects in early phases of prodromal AD may experience a period of hippocampal hyperactivation. followed by loss of hippocampal activation as the disease progresses.Methods: We studied 51 older individuals without dementia (Clinical Dementia Rating [CDR] at baseline of 0. n = 21. and 0.5. n = 30) with longitudinal clinical and neuropsychological assessments. as well as fMRI during a face-name associative memory paradigm. Whole brain and region-of-interest analyses were applied to the longitudinal fMRI data.Results: Subjects classified as CDR 0 at baseline showed no difference in …,True,FcYNVOUAAAAJ:2osOgNQ5qMEC,254,https://n.neurology.org/content/74/24/1969.short,5805904998301939159,/scholar?cites=5805904998301939159,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2905893/,0,0,0
1278728,Intrinsic connectivity between the hippocampus and posteromedial cortex predicts memory performance in cognitively intact older individuals,2010,Liang Wang and Peter LaViolette and Kelly O'Keefe and Deepti Putcha and Akram Bakkour and Koene RA Van Dijk and Maija Pihlajamäki and Bradford C Dickerson and Reisa A Sperling,51,Neuroimage,2,910-917,Academic Press,Coherent fluctuations of spontaneous brain activity are present in distinct functional-anatomic brain systems during undirected wakefulness. However. the behavioral significance of this spontaneous activity has only begun to be investigated. Our previous studies have demonstrated that successful memory formation requires coordinated neural activity in a distributed memory network including the hippocampus and posteromedial cortices. specifically the precuneus and posterior cingulate (PPC). thought to be integral nodes of the default network. In this study. we examined whether intrinsic connectivity during the resting state between the hippocampus and PPC can predict individual differences in the performance of an associative memory task among cognitively intact older individuals. The intrinsic connectivity. between regions within the hippocampus and PPC that were maximally engaged during a subsequent …,True,FcYNVOUAAAAJ:IjCSPb-OGe4C,239,https://www.sciencedirect.com/science/article/pii/S1053811910002144,13936509216776967285,/scholar?cites=13936509216776967285,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2856812/,0,0,0
1278729,Validation of functional diffusion maps (fDMs) as a biomarker for human glioma cellularity,2010,Benjamin M Ellingson and Mark G Malkin and Scott D Rand and Jennifer M Connelly and Carolyn Quinsey and Pete S LaViolette and Devyani P Bedekar and Kathleen M Schmainda,31,Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine,3,538-548,Wiley Subscription Services. Inc.. A Wiley Company,To present comprehensive examinations of the assumptions made in functional diffusion map (fDM) analyses and provide a biological basis for fDM classification.Sixty‐nine patients with gliomas were enrolled in this study. To determine the sensitivity of apparent diffusion coefficients (ADCs) to cellularity. cell density from stereotactic biopsy specimens was correlated with preoperative ADC maps. For definition of ADC thresholds used for fDMs. the 95% confidence intervals (CI) for changes in voxel‐wise ADC measurements in normal appearing tissue was analyzed. The sensitivity and specificity to progressing disease was examined using both radiographic and neurological criteria.Results support the hypothesis that ADC is inversely proportional to cell density with a sensitivity of 1.01 × 10−7 [mm2/s]/[nuclei/mm2]. The 95% CI for white matter = 0.25 × 10−3 mm2/s. gray …,True,FcYNVOUAAAAJ:Se3iqnhoufwC,235,https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.22068,8633067205613883238,/scholar?cites=8633067205613883238,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.22068,0,0,0
1278730,Parity-Violating Electron Scattering from  and the Strange Electric Form Factor of the Nucleon,2006,KA Aniol and DS Armstrong and Todd Averett and Hachemi Benaoum and PY Bertin and Etienne Burtin and Jason Cahoon and GD Cates and CC Chang and Y-C Chao and J-P Chen and Seonho Choi and Eugene Chudakov and Brandon Craver and Francesco Cusanno and Piotr Decowski and Deepa Deepa and Catherine Ferdi and RJ Feuerbach and JM Finn and Salvatore Frullani and Kirsten Fuoti and Franco Garibaldi and Ronald Gilman and A Glamazdin and V Gorbenko and JM Grames and John Hansknecht and DW Higinbotham and Richard Holmes and Timothy Holmstrom and TB Humensky and Hassan Ibrahim and CW De Jager and Xiaodong Jiang and LJ Kaufman and Aidan Kelleher and Ameya Kolarkar and Stanley Kowalski and KS Kumar and Daniel Lambert and Peter Laviolette and John LeRose and David Lhuillier and Nilanga Liyanage and DJ Margaziotis and Malek Mazouz and Kathy McCormick and DG Meekins and Z-E Meziani and Robert Michaels and Bryan Moffit and Peter Monaghan and C Munoz-Camacho and Sirish Nanda and Vladimir Nelyubin and Damien Neyret and KD Paschke and M Poelker and Roman Pomatsalyuk and Yi Qiang and Bodo Reitz and Julie Roche and Arunava Saha and Jaideep Singh and Ryan Snyder and PA Souder and Ramesh Subedi and Riad Suleiman and Vincent Sulkosky and WA Tobias and GM Urciuoli and Antonin Vacheret and Eric Voutier and Kebin Wang and R Wilson and Bogdan Wojtsekhowski and Xiaochao Zheng and HAPPEX Collaboration,96,Physical review letters,2,022003,American Physical Society,We have measured the parity-violating electroweak asymmetry in the elastic scattering of polarized electrons from He 4 at an average scattering angle⟨ θ lab⟩= 5.7 and a four-momentum transfer Q 2= 0.091 GeV 2. From these data. for the first time. the strange electric form factor of the nucleon G E s can be isolated. The measured asymmetry of A PV=(6.72±0.84 (stat)±0.21 (syst))× 10− 6 yields a value of G E s=− 0.038±0.042 (stat)±0.010 (syst). consistent with zero.,True,FcYNVOUAAAAJ:TFP_iSt0sucC,234,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.96.022003,16183328226054100259,/scholar?cites=16183328226054100259,,,https://arxiv.org/pdf/nucl-ex/0506010,0,0,0
1278731,Collective robotics: From social insects to robots,1993,C Ronald Kube and Hong Zhang,2,Adaptive behavior,2,189-218,Sage Publications,Achieving tasks with multiple robots will require a control system that is both simple and scalable as the number of robots increases. Collective behavior as demonstrated by social insects is a form of decentralized control that may prove useful in controlling multiple robots. Nature's several examples of collective behavior have motivated our approach to controlling a multiple robot system using a group behavior. Our mechanisms. used to invoke the group behavior. allow the system of robots to perform tasks without centralized control or explicit communication. We have constructed a system of five mobile robots capable of achieving simple collective tasks to verify the results obtained in simulation. The results suggest that decentralized control without explicit communication can be used to perform cooperative tasks requiring a collective behavior.,True,J7UkpAIAAAAJ:u5HHmVD_uO8C,453,https://journals.sagepub.com/doi/abs/10.1177/105971239300200204,12983939486711077635,/scholar?cites=12983939486711077635,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5571&rep=rep1&type=pdf,0,0,0
1278732,Collective robotic intelligence,1992,C Ronald Kube and Hong Zhang,,Second International Conference on Simulation of Adaptive Behavior,,460-468,,In this paper. we examine the problem of controlling multiple behaviour-based autonomous robots. Based on observations made from the study of social insects. we propose five simple mechanisms used to invoke group behaviour in simple sensor-based mobile robots. The proposed mechanisms allow populations of behaviour-based robots to perform tasks without centralized con-trol or use of explicit communication. We have verified our collective control strategies by designing a robot population simulator called SimbotCity. We have also constructed a system of five homogeneous sensor-based mobile robots. capable of achieving simple collective tasks. to demonstrate the feasibility of some of the control mechanisms.,True,J7UkpAIAAAAJ:u-x6o8ySG0sC,206,http://books.google.com/books?hl=en&lr=&id=teHhVHk3a54C&oi=fnd&pg=PA460&dq=info:Y5ThiiPZdicJ:scholar.google.com&ots=h1q90tSr6p&sig=pkOykdmuZJkz_qqe7QpGaGi-oY8,2843698961408169059,/scholar?cites=2843698961408169059,,,https://www.researchgate.net/profile/Hong_Zhang150/publication/2453803_Collective_Robotic_Intelligence/links/5630d48008ae0530378cde0c/Collective-Robotic-Intelligence.pdf,0,0,0
1278733,An evaluation metric for image segmentation of multiple objects,2009,Mark Polak and Hong Zhang and Minghong Pi,27,Image and Vision Computing,8,1223-1227,Elsevier,It is important to be able to evaluate the performance of image segmentation algorithms objectively. In this paper. we define a new error measure which quantifies the performance of an image segmentation algorithm for identifying multiple objects in an image. This error measure is based on object-by-object comparisons of a segmented image and a ground-truth (reference) image. It takes into account the size. shape. and position of each object. Compared to existing error measures. our proposed error measure works at the object level. and is sensitive to both over-segmentation and under-segmentation. Hence. it can serve as a useful tool for comparing image segmentation algorithms and for tuning the parameters of a segmentation algorithm.,True,J7UkpAIAAAAJ:MXK_kJrjxJIC,201,https://www.sciencedirect.com/science/article/pii/S0262885608001984,16328221439756085721,/scholar?cites=16328221439756085721,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.966&rep=rep1&type=pdf,0,0,0
1278734,Fast Approximate Nearest-Neighbor Search with k-Nearest Neighbor Graph,2011,Kiana Hajebi and Yasin Abbasi-Yadkori and Hossein Shahbazi and Hong Zhang,,,,1312-1317,,We introduce a new nearest neighbor search algorithm. The algorithm builds a nearest neighbor graph in an offline phase and when queried with a new point. performs hill-climbing starting from a randomly sampled node of the graph. We provide theoretical guarantees for the accuracy and the computational complexity and empirically show the effectiveness of this algorithm.,True,J7UkpAIAAAAJ:WA5NYHcadZ8C,189,https://www.ijcai.org/Proceedings/11/Papers/222.pdf,570256015358098293,/scholar?cites=570256015358098293,,,https://www.ijcai.org/Proceedings/11/Papers/222.pdf,0,0,0
1278735,Task modelling in collective robotics,1997,C Ronald Kube and Hong Zhang,4,Autonomous Robots,1,53-72,Springer Netherlands,Does coherent collective behaviour require an explicit mechanism of cooperation? In this paper. we demonstrate that a certain class of cooperative tasks. namely coordinated box manipulation. are possible without explicit communication or cooperation mechanisms. The approach relies on subtask decomposition and sensor preprocessing. A framework is proposed for modelling multi-robot tasks which are described as a series of steps with each step possibly consisting of substeps. Finite state automata theory is used to model steps with state transitions specified as binary sensing predicates called perceptual cues. A perceptual cue (Q). whose computation is disjoint from the operation of the automata. is processed by a 3-level finite state machine called a Q-machine. The model is based on entomological evidence that suggests local stimulus cues are used to regulate a linear series of building acts in nest …,True,J7UkpAIAAAAJ:9yKSN-GCB0IC,164,https://link.springer.com/article/10.1023/A:1008859119831,2619315431441464962,/scholar?cites=2619315431441464962,,,http://webdocs.cs.ualberta.ca/~kube/papers/KubeZhangAR97.pdf,0,0,0
1278736,The use of perceptual cues in multi-robot box-pushing,1996,C Ronald Kube and Hong Zhang,3,,,2085-2090 vol. 3,IEEE,In this paper we present an approach to controlling transitions in multirobot tasks which have been modelled as a linear series of steps. A box-pushing task is described as a sequence of sub-tasks with a separate controller designed for each step using finite state automata theory. Perceptual cues are formed by concatenating binary variables which represent locally sensed stimuli into boolean vectors used to specify transitions between sub-task steps. The approach is designed for a redundant set of homogeneous mobile robots equipped with simple sensors and stimulus-response behaviours. A set of perceptual cues used in box-pushing are designed and tested on 10 physical mobile robots. It is argued that perceptual cues and finite state automata offers a new approach to environment-specific task modelling in collective robotics.,True,J7UkpAIAAAAJ:2osOgNQ5qMEC,148,https://ieeexplore.ieee.org/abstract/document/506178/,13813265946774583075,/scholar?cites=13813265946774583075,,,https://www.researchgate.net/profile/Hong_Zhang150/publication/3631685_The_use_of_perceptual_cues_in_multi-robot_box-pushing/links/5630d47c08ae3de9381cb8c6.pdf,0,0,0
1278737,Computationally efficient kinematics for manipulators with spherical wrists based on the homogeneous transformation representation,1986,Richard Paul and Hong Zhang,5,International Journal of Robotics Reserch,2,32-44,,Most manipulators in use today are kinematically simple. and closed-form symbolic equations are the most efficient means of expressing their kinematics. The analysis presented in this paper is based on the use of homogeneous transforma tions to describe position and orientation. Using these methods. kinematic equations are obtained directly in a form suitable for computer implementation. The equations are numerically stable and are obtained almost automatically. The resulting equations involve the minimum number of mathematical operations.,True,J7UkpAIAAAAJ:yL7DKRohVA8C,143,https://journals.sagepub.com/doi/abs/10.1177/027836498600500204,8842614088834809946,/scholar?cites=8842614088834809946,,,,0,0,0
1278738,A multistage adaptive thresholding method,2005,Feixiang Yan and Hong Zhang and C Ronald Kube,26,Pattern recognition letters,8,1183-1191,North-Holland,Thresholding is a simple but effective technique for image segmentation. In this paper. a general locally adaptive thresholding method using neighborhood processing is presented. The method makes use of local image statistics of mean and variance within a variable neighborhood and two thresholds obtained from the global intensity distribution. It can thus take advantage of local thresholding and. at the same time. prevent over segmentation with the global image information. We also present a systematic method to calculate a combination coefficient of the mean and the variance based on global image information. Experiments on both optical character recognition (OCR) images and oil sand images demonstrate that this method provides superior image segmentation to existing thresholding methods for images that are severely degraded due to noise. poor illumination and shadow.,True,J7UkpAIAAAAJ:W7OEmFMy1HYC,138,https://www.sciencedirect.com/science/article/pii/S0167865504003290,3369277685153783001,/scholar?cites=3369277685153783001,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.8990&rep=rep1&type=pdf,0,0,0
1278739,Classification-driven watershed segmentation,2007,Ilya Levner and Hong Zhang,16,IEEE Transactions on Image Processing,5,1437-1445,IEEE,This paper presents a novel approach for creation of topographical function and object markers used within watershed segmentation. Typically. marker-driven watershed segmentation extracts seeds indicating the presence of objects or background at specific image locations. The marker locations are then set to be regional minima within the topological surface (typically. the gradient of the original input image). and the watershed algorithm is applied. In contrast. our approach uses two classifiers. one trained to produce markers. the other trained to produce object boundaries. As a result of using machine-learned pixel classification. the proposed algorithm is directly applicable to both single channel and multichannel image data. Additionally. rather than flooding the gradient image. we use the inverted probability map produced by the second aforementioned classifier as input to the watershed algorithm …,True,J7UkpAIAAAAJ:Tyk-4Ss8FVUC,129,https://ieeexplore.ieee.org/abstract/document/4154796/,16913284646332191852,/scholar?cites=16913284646332191852,,,https://www.researchgate.net/profile/Hong_Zhang150/publication/6341385_Classification-driven_watershed_segmentation_IEEE_Trans_Image_Process/links/5630d47608ae0530378cde01.pdf,0,0,0
1278740,Modified GMM background modeling and optical flow for detection of moving objects,2005,Dongxiang Zhou and Hong Zhang,3,,,2224-2229 Vol. 3,IEEE,Segmentation of moving objects in image sequences is a fundamental step in many computer vision applications such as mineral processing industry and automated visual surveillance. In this paper. we introduce a novel approach to detect moving objects in a noisy background. Our approach combines a modified adaptive Gaussian mixture model (GMM) for background subtraction and optical flow methods supported by temporal differencing in order to achieve robust and accurate extraction of the shapes of moving objects. The algorithm works well for image sequences having many moving objects with different sizes as demonstrated by experimental results on real image sequences.,True,J7UkpAIAAAAJ:KlAtU1dfN6UC,123,https://ieeexplore.ieee.org/abstract/document/1571479/,3334881852904557538,/scholar?cites=3334881852904557538,,,https://www.researchgate.net/profile/Hong_Zhang150/publication/4210558_Modified_GMM_background_modeling_and_optical_flow_for_detection_of_moving_objects/links/5630d47808ae506cea674311/Modified-GMM-background-modeling-and-optical-flow-for-detection-of-moving-objects.pdf,0,0,0
1278741,Person Tracking and Following with 2D Laser Scanners,2015,Angus Leigh and Joelle Pineau and Nicolas Olmedo and Hong Zhang,,,,,,Having accurate knowledge of the positions of people around a robot provides rich. objective and quantitative data that can be highly useful for a wide range of tasks. including autonomous person following. The primary objective of this research is to promote the development of robust. repeatable and transferable software for robots that can automatically detect. track and follow people in their environment. The work is strongly motivated by the need for such functionality onboard an intelligent power wheelchair robot designed to assist people with mobility impairments. In this paper we propose a new algorithm for robust detection. tracking and following from laser data. We show that the approach is effective in various environments. both indoor and outdoor. and on different robot platforms (the intelligent power wheelchair and a Clearpath Husky). The method has been implemented in the Robot Operating System …,True,J7UkpAIAAAAJ:2mikiJ1VBVsC,121,https://ieeexplore.ieee.org/abstract/document/7139259/,6988517488387367696,/scholar?cites=6988517488387367696,,,https://www.cs.mcgill.ca/~jpineau/files/leigh-icra15.pdf,0,0,0
1278742,Image compression using block truncation coding,1979,Edward Delp and O Mitchell,27,IEEE transactions on Communications,9,1335-1342,IEEE,A new technique for image compression called Block Truncation Coding (BTC) is presented and compared with transform and other techniques. The BTC algorithm uses a two-level (one-bit) nonparametric quantizer that adapts to local properties of the image. The quantizer that shows great promise is one which preserves the local sample moments. This quantizer produces good quality images that appear to be enhanced at data rates of 1.5 bits/picture element. No large data storage is required. and the computation is small. The quantizer is compared with standard (minimum mean-square error and mean absolute error) one-bit quantizers. Modifications of the basic BTC algorithm are discussed along with the performance of BTC in the presence of channel errors.,True,R6txprUJzQMJ:e5wmG9Sq2KIC,1123,https://ieeexplore.ieee.org/abstract/document/1094560/,8220926504912356006,/scholar?cites=8220926504912356006,,,https://www.researchgate.net/profile/Owen_Mitchell/publication/224732413_Image_Compression_Using_Block_Truncation_Coding/links/5460d5120cf295b561637c75.pdf,0,0,0
1278743,Subpixel measurements using a moment-based edge operator,1989,Edward P.  Lyvers and Owen Robert  Mitchell and Mark L.  Akey and Anthony P.  Reeves,11,IEEE Transactions on pattern analysis and machine intelligence,12,1293-1309,IEEE,Recent results in precision measurements using computer vision are presented. An edge operator based on two-dimensional spatial moments is given. The operator can be implemented for virtually any size of window and has been shown to locate edges in digitized images to a twentieth of a pixel. This accuracy is unaffected by additive or multiplicative changes to the data values. The precision is achieved by correcting for many of the deterministic errors caused by nonideal edge profiles using a lookup table to correct the original estimates of edge orientation and location. This table is generated using a synthesized edge which is located at various subpixel locations and various orientations. The operator is extended to accommodate nonideal edge profiles and rectangularly sampled pixels. The technique is applied to the measurement of imaged machined metal parts. Theoretical and experimental noise analyses …,True,R6txprUJzQMJ:hqOjcs7Dif8C,577,https://ieeexplore.ieee.org/abstract/document/41367/,3049068447032673730,/scholar?cites=3049068447032673730,,,https://www.researchgate.net/profile/Owen_Mitchell/publication/3191707_Subpixel_Measurement_Using_a_Moment-Based_Edge_Operator/links/5460d5170cf2c1a63bff72f4/Subpixel-Measurement-Using-a-Moment-Based-Edge-Operator.pdf,0,0,0
1278744,Edge location to subpixel values in digital imagery,1984,Ali J Tabatabai and O Robert Mitchell,,IEEE transactions on pattern analysis and machine intelligence,2,188-201,IEEE,A new method for locating edges in digital data to subpixel values and which is invariant to additive and multiplicative changes in the data is presented. For one-dimensional edge patterns an ideal edge is fit to the data by matching moments. It is shown that the edge location is related to the so-called ``Christoffel numbers.'' Also presented is the study of the effect of additive noise on edge location. The method is extended to include two-dimensional edge patterns where a line equation is derived to locate an edge. This in turn is compared with the standard Hueckel edge operator. An application of the new edge operator as an edge detector is also provided and is compared with Sobel and Hueckel edge detectors in presence and absence of noise.,True,R6txprUJzQMJ:r0BpntZqJG4C,529,https://ieeexplore.ieee.org/abstract/document/4767502/,9280337308545097870,/scholar?cites=9280337308545097870,,,,0,0,0
1278745,Vision-guided servoing with feature-based trajectory generation (for robots),1989,John T Feddema and Owen Robert Mitchell,5,IEEE Transactions on Robotics and Automation,5,691-700,IEEE,The authors present a vision module which is able to guide an eye-in-hand robot through general servoing and tracking problems using off-the-shelf image-processing equipment. The vision module uses the location of binary image features from a camera on the robot's end-effector to control the position and one degree of orientation of the robot manipulator. A unique feature-based trajectory generator provides smooth motion between the actual image features and the desired image features even with asynchronous and discontinuous vision updates. By performing the trajectory generation in image feature space. image-processing constraints such as the feature extraction time can be accounted for when determining the appropriate segmentation and acceleration times of the trajectory. Experimental results of a PUMA robot tracking objects with vision feedback are discussed.< >,True,R6txprUJzQMJ:8k81kl-MbHgC,482,https://ieeexplore.ieee.org/abstract/document/88086/,3311137650109603125,/scholar?cites=3311137650109603125,,,,0,0,0
1278746,Absolute moment block truncation coding and its application to color images,1984,M Lema and O Mitchell,32,IEEE Transactions on communications,10,1148-1157,IEEE,A new quantization method that uses the criterion of preserving sample absolute moments is presented. This is based on the same basic idea for block truncation coding of Delp and Mitchell but it is simpler in any practical implementation. Moreover. output equations are those for a two-level nonparametric minimum mean square error quantizer when the threshold is fixed to the sample mean. The application of this method to single frame color images is developed. A color image coding system that uses absolute moment block truncation coding of luminance and chroma information is presented. Resulting color images show reasonable performance with bit rates as low as 2.13 bits/pixel.,True,R6txprUJzQMJ:UeHWp8X0CEIC,461,https://ieeexplore.ieee.org/abstract/document/1095973/,819502640992903424,/scholar?cites=819502640992903424,,,https://www.researchgate.net/profile/Owen_Mitchell/publication/224733361_Absolute_Moment_Block_Truncation_Coding_and_Its_Application_to_Color_Images/links/5460d50f0cf295b561637c6f/Absolute-Moment-Block-Truncation-Coding-and-Its-Application-to-Color-Images.pdf,0,0,0
1278747,Weighted selection of image features for resolved rate visual feedback control,1991,John T Feddema and CS George Lee and Owen Robert Mitchell,7,IEEE Transactions on Robotics and Automation,1,31-47,IEEE,The authors develop methodologies for the automatic selection of image features to be used to visually control the relative position and orientation (pose) between the end-effector of an eye-in-hand robot and a workpiece. A resolved motion rate control scheme is used to update the robot's pose based on the position of three features in the camera's image. The selection of these three features depends on a blend of image recognition and control criteria. The image recognition criteria include feature robustness. completeness. cost of feature extraction. and feature uniqueness. The control criteria include system observability. controllability. and sensitivity. A weighted criteria function is used to select the combination of image features that provides the best control of the end-effector of a general six-degrees-of-freedom manipulator. Both computer simulations and laboratory experiments on a PUMA robot arm were …,True,R6txprUJzQMJ:ns9cj8rnVeAC,305,https://ieeexplore.ieee.org/abstract/document/68068/,11495201527184880514,/scholar?cites=11495201527184880514,,,,0,0,0
1278748,Machine vision and image processing for plant identification,1986,D Eetal Guyer and GE Miles and MM Schreiber and OR Mitchell and VC Vanderbilt,29,Transactions of the ASAE,6,1500-1507,American Society of Agricultural and Biological Engineers,Amachine vision system coupled with image processing algorithms has successfully recorded and identified images of the juvenile stages of corn. soybeans. tomatoes. Johnsongrass. Jimsonweed. velvetleaf. giant foxtail. and lambsquarters. Plants were grown in containers and images were obtained in a laboratory setting with the camera and light source positioned directly above the plants. Spatial parameters of the plants within the digital images were computed and used in a classification scheme for identification..,True,R6txprUJzQMJ:HoB7MX3m0LUC,272,https://elibrary.asabe.org/abstract.asp?aid=30344,12884441192534409387,/scholar?cites=12884441192534409387,,,,0,0,0
1278749,Threshold decomposition of gray-scale morphology into binary morphology,1989,Frank Y Shih and Owen Robert  Mitchell,11,IEEE Transactions on Pattern Analysis and Machine Intelligence,1,31-42,IEEE,Recently. a superposition property called threshold decomposition and another property called stacking were introduced and shown to apply successfully to gray-scale morphological operations. This property allows gray-scale signals to be decomposed into multiple binary signals. The signals are processed in parallel. and the results are combined to produce the desired gray-scale result. The authors present the threshold decomposition architecture and the stacking property that allows the implementation of this architecture. Gray-scale operations are decomposed into binary operations. This decomposition allows gray-scale morphological operations to be implemented using only logic gates in VLSI architectures that can significantly improve speed as well as give theoretical insight into the operations.< >,True,R6txprUJzQMJ:Y0pCki6q_DkC,215,https://ieeexplore.ieee.org/abstract/document/23111/,1364459298828719583,/scholar?cites=1364459298828719583,,,,0,0,0
1278750,Precision edge contrast and orientation estimation,1988,Edward P.  Lyvers and Owen Robert  Mitchell,10,IEEE Transactions on Pattern Analysis and Machine Intelligence,6,927-937,IEEE,The contrast and orientation estimation accuracy of several edge operators that have been proposed in the literature is examined both for the noiseless case and in the presence of additive Gaussian noise. The test image is an ideal step edge that has been sampled with a square-aperture grid. The effects of subpixel translations and rotations of the edge on the performance of the operators are studied. It is shown that the effect of subpixel translations of an edge can generate more error than moderate noise levels. Methods with improved results are presented for Sobel angle estimates and the Nevatia-Babu operator. and theoretical noise performance evaluations are also provided. An edge operator based on two-dimensional spatial moments is presented. All methods are compared according to worst-case and RMS error in an ideal noiseless situation and RMS error under various noise levels.< >,True,R6txprUJzQMJ:blknAaTinKkC,210,https://ieeexplore.ieee.org/abstract/document/9114/,10964748805447321532,/scholar?cites=10964748805447321532,,,,0,0,0
1278751,Partial shape recognition using dynamic programming,1988,John W.  Gorman and Owen Robert  Mitchell and Frank P.  Kuhl,10,IEEE Transactions on pattern analysis and machine intelligence,2,257-266,IEEE,A partial-shape-recognition technique utilizing local features described by Fourier descriptors is introduced. A dynamic programming formulation for shape matching is developed. and a method for comparison of match quality is discussed. This technique is shown to recognize unknown contours that may be occluded or that may overlap other objects. Precise scale information is not required. and the unknown objects may appear at any orientation with respect to the camera. The segment-matching dynamic programming method is contrasted with other sequence-comparison techniques that utilize dynamic programming. Experimental results are discussed that indicate that partial contours can be recognized with reasonable accuracy.< >,True,R6txprUJzQMJ:Zph67rFs4hoC,195,https://ieeexplore.ieee.org/abstract/document/3887/,4058927685715441451,/scholar?cites=4058927685715441451,,,https://www.researchgate.net/profile/Owen_Mitchell/publication/3191547_Partial_Shape_Recognition_Using_Dynamic_Programming/links/5460d5180cf295b561637c7d/Partial-Shape-Recognition-Using-Dynamic-Programming.pdf,0,0,0
1278752,A Euclidean distance transform using grayscale morphology decomposition,1994,C. Tony  Huang and O. Robert  Mitchell,16,IEEE Transactions on pattern analysis and machine intelligence,4,443-448,IEEE,A fast and exact Euclidean distance transformation using decomposed grayscale morphological operators is presented. Applied on a binary image. a distance transformation assigns each object pixel a value that corresponds to the shortest distance between the object pixel and the background pixels. It is shown that the large structuring element required for the Euclidean distance transformation can be easily decomposed into 3/spl times/3 windows. This is possible because the square of the Euclidean distance matrix changes uniformly both in the vertical and horizontal directions. A simple extension for a 3D Euclidean distance transformation is discussed. A fast distance transform for serial computers is also presented. Acting like thinning algorithms. the version for serial computers focuses operations only on the potential changing pixels and propagates from the boundary of objects. significantly reducing …,True,R6txprUJzQMJ:iH-uZ7U-co4C,146,https://ieeexplore.ieee.org/abstract/document/277600/,9352658750683020540,/scholar?cites=9352658750683020540,,,,0,0,0
1278753,Kernel-based framework for multitemporal and multisource remote sensing data classification and change detection,2008,Gustavo Camps-Valls and Luis Gómez-Chova and Jordi Muñoz-Marí and José Luis Rojo-Álvarez and Manel Martínez-Ramón,46,IEEE Transactions on Geoscience and Remote Sensing,6,1822-1835,IEEE,The multitemporal classification of remote sensing images is a challenging problem. in which the efficient combination of different sources of information (e.g.. temporal. contextual. or multisensor) can improve the results. In this paper. we present a general framework based on kernel methods for the integration of heterogeneous sources of information. Using the theoretical principles in this framework. three main contributions are presented. First. a novel family of kernel-based methods for multitemporal classification of remote sensing images is presented. The second contribution is the development of nonlinear kernel classifiers for the well-known difference and ratioing change detection methods by formulating them in an adequate high-dimensional feature space. Finally. the presented methodology allows the integration of contextual information and multisensor images with different levels of nonlinear …,True,KaBeaJwAAAAJ:u-x6o8ySG0sC,383,https://ieeexplore.ieee.org/abstract/document/4509590/,3853767982982637893,/scholar?cites=3853767982982637893,,,https://burjcdigital.urjc.es/bitstream/handle/10115/2202/Kernel-Based%20Framework%20for%20Multitemporal-2008.pdf?sequence=1&isAllowed=y,0,0,0
1278754,Support vector method for robust ARMA system identification,2004,José Luis Rojo-Álvarez and Manel Martínez-Ramón and Mario de Prado-Cumplido and Antonio Artés-Rodríguez and Aníbal R Figueiras-Vidal,52,IEEE transactions on signal processing,1,155-164,IEEE,This paper presents a new approach to auto-regressive and moving average (ARMA) modeling based on the support vector method (SVM) for identification applications. A statistical analysis of the characteristics of the proposed method is carried out. An analytical relationship between residuals and SVM-ARMA coefficients allows the linking of the fundamentals of SVM with several classical system identification methods. Additionally. the effect of outliers can be cancelled. Application examples show the performance of SVM-ARMA algorithm when it is compared with other system identification methods.,True,KaBeaJwAAAAJ:u5HHmVD_uO8C,181,https://ieeexplore.ieee.org/abstract/document/1254033/,16088966804760599988,/scholar?cites=16088966804760599988,,,https://e-archivo.uc3m.es/bitstream/handle/10016/7257/SVM_?sequence=1,0,0,0
1278755,Robust support vector regression for biophysical variable estimation from remotely sensed images,2006,Gustavo Camps-Valls and Lorenzo Bruzzone and José Luis Rojo-Álvarez and Farid Melgani,3,IEEE Geoscience and Remote Sensing Letters,3,339-343,IEEE,This letter introduces the epsiv-Huber loss function in the support vector regression (SVR) formulation for the estimation of biophysical parameters extracted from remotely sensed data. This cost function can handle the different types of noise contained in the dataset. The method is successfully compared to other cost functions in the SVR framework. neural networks and classical bio-optical models for the particular case of the estimation of ocean chlorophyll concentration from satellite remote sensing data. The proposed model provides more accurate. less biased. and improved robust estimation results on the considered case study. especially significant when few in situ measurements are available,True,KaBeaJwAAAAJ:qjMakFHDy7sC,180,https://ieeexplore.ieee.org/abstract/document/1658001/,12438341710405275635,/scholar?cites=12438341710405275635,,,https://burjcdigital.urjc.es/bitstream/handle/10115/1907/GEOSCIENCE.pdf?sequence=1&isAllowed=y,0,0,0
1278756,Detection of life-threatening arrhythmias using feature selection and support vector machines,2013,Felipe Alonso-Atienza and Eduardo Morgado and Lorena Fernandez-Martinez and Arcadi García-Alberola and José Luis Rojo-Alvarez,61,IEEE Transactions on Biomedical Engineering,3,832-840,IEEE,Early detection of ventricular fibrillation (VF) and rapid ventricular tachycardia (VT) is crucial for the success of the defibrillation therapy. A wide variety of detection algorithms have been proposed based on temporal. spectral. or complexity parameters extracted from the ECG. However. these algorithms are mostly constructed by considering each parameter individually. In this study. we present a novel life-threatening arrhythmias detection algorithm that combines a number of previously proposed ECG parameters by using support vector machines classifiers. A total of 13 parameters were computed accounting for temporal (morphological). spectral. and complexity features of the ECG signal. A filter-type feature selection (FS) procedure was proposed to analyze the relevance of the computed parameters and how they affect the detection performance. The proposed methodology was evaluated in two different binary …,True,KaBeaJwAAAAJ:1yQoGdGgb4wC,177,https://ieeexplore.ieee.org/abstract/document/6663664/,12797091581199191237,/scholar?cites=12797091581199191237,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.711.4077&rep=rep1&type=pdf,0,0,0
1278757,A systematic review of the literature on home monitoring for patients with heart failure,2006,Andrés Martínez and Estrella Everss and José Luis Rojo-Álvarez and Domingo Pascual Figal and Arcadio García-Alberola,12,,5,234-241,SAGE Publications,We conducted a systematic review of the literature for assessing the value of home monitoring for heart failure (HF) patients. The abstracts of 383 articles were read. We excluded those in which either no home monitoring was done or only the technical aspects of the telemedicine application were described. Forty-two studies met the selection criteria. We classified the results into feasibility (technical and institutional) and impact (on the clinical process. on patient health. on accessibility and acceptability of the health system. and on the economy). Evaluating the articles showed that home monitoring in HF patients is viable. given that: (1) it appears to be technically effective for following the patient remotely; (2) it appears to be easy to use. and it is widely accepted by patients and health professionals; and (3) it appears to be economically viable. Furthermore. home monitoring of HF patients has been shown to have a …,True,KaBeaJwAAAAJ:2osOgNQ5qMEC,147,https://journals.sagepub.com/doi/abs/10.1258/135763306777889109,11822741199903902699,/scholar?cites=11822741199903902699,,,https://burjcdigital.urjc.es/bitstream/handle/10115/2297/A%20systematic%20review%20of%20the%20literature%20on%20home%20monitoring%20for%20patients%20with%20heart%20failure.pdf?sequence=1&isAllowed=y,0,0,0
1278758,A noninvasive method for assessing impaired diastolic suction in patients with dilated cardiomyopathy,2005,Raquel Yotti and Javier Bermejo and J Carlos Antoranz and M Mar Desco and Cristina Cortina and José Luis Rojo-Álvarez and Carmen Allué and Laura Martín and Mar Moreno and José A Serrano and Roberto Muñoz and Miguel A García-Fernández,112,Circulation,19,2921-2929,Lippincott Williams & Wilkins,Background— Diastolic suction is a major determinant of early left ventricular filling in animal experiments. However. suction remains incompletely characterized in the clinical setting.Methods and Results— First. we validated a method for measuring the spatio-temporal distributions of diastolic intraventricular pressure gradients and differences (DIVPDs) by digital processing color Doppler M-mode recordings. In 4 pigs. the error of peak DIVPD was 0.0±0.2 mm Hg (intraclass correlation coefficient. 0.95) compared with micromanometry. Forty patients with dilated cardiomyopathy (DCM) and 20 healthy volunteers were studied at baseline and during dobutamine infusion. A positive DIVPD (toward the apex) originated during isovolumic relaxation. reaching its peak shortly after mitral valve opening. Peak DIVPD was less than half in patients with DCM than in control subjects (1.2±0.6 versus 2.5±0.8 mm Hg. P<0.001 …,True,KaBeaJwAAAAJ:d1gkVwhDpl0C,137,https://www.ahajournals.org/doi/abs/10.1161/CIRCULATIONAHA.105.561340,9714809462244472051,/scholar?cites=9714809462244472051,,,https://www.ahajournals.org/doi/pdf/10.1161/CIRCULATIONAHA.105.561340,0,0,0
1278759,Support vector machines for nonlinear kernel ARMA system identification,2006,Manel Martínez-Ramón and Jos Luis Rojo-Alvarez and Gustavo Camps-Valls and Jordi Muñoz-Marí and Emilio Soria-Olivas and Anbal R Figueiras-Vidal,17,IEEE Transactions on Neural Networks,6,1617-1622,IEEE,Nonlinear system identification based on support vector machines (SVM) has been usually addressed by means of the standard SVM regression (SVR). which can be seen as an implicit nonlinear autoregressive and moving average (ARMA) model in some reproducing kernel Hilbert space (RKHS). The proposal of this letter is twofold. First. the explicit consideration of an ARMA model in an RKHS (SVM-ARMA 2K ) is proposed. We show that stating the ARMA equations in an RKHS leads to solving the regularized normal equations in that RKHS. in terms of the autocorrelation and cross correlation of the (nonlinearly) transformed input and output discrete time processes. Second. a general class of SVM-based system identification nonlinear models is presented. based on the use of composite Mercer's kernels. This general class can improve model flexibility by emphasizing the input-output cross information (SVM …,True,KaBeaJwAAAAJ:s9ia6_kGH2AC,108,https://ieeexplore.ieee.org/abstract/document/4012036/,15009080877077388712,/scholar?cites=15009080877077388712,,,https://burjcdigital.urjc.es/bitstream/handle/10115/1913/SVM%20for%20nonlinear%20kernel%20ARMA2006.pdf?sequence=1&isAllowed=y,0,0,0
1278760,Kernel methods in bioengineering. signal and image processing,2006,Gustavo Camps-Valls,,,,,Igi Global,In the last decade. a number of powerful kernel-based learning methods have been proposed in the machine learning community: support vector machines (SVMs). kernel fisher discriminant (KFD) analysis. kernel PCA/ICA. kernel mutual information. kernel k-means. and kernel ARMA. Successful applications of these algorithms have been reported in many fields. such as medicine. bioengineering. communications. audio and image processing. and computational biology and bioinformatics. Kernel Methods in Bioengineering. Signal and Image Processing covers real-world applications. such as computational biology. text categorization. time series prediction. interpolation. system identification. speech recognition. image de-noising. image coding. classification. and segmentation. Kernel Methods in Bioengineering. Signal and Image Processing encompasses the vast field of kernel methods from a multidisciplinary approach by presenting chapters dedicated to adaptation and use of kernel methods in the selected areas of bioengineering. signal processing and communications. and image processing.,True,KaBeaJwAAAAJ:HDshCWvjkbEC,106,http://books.google.com/books?hl=en&lr=&id=ScPB1v5eqH0C&oi=fnd&pg=PR1&dq=info:F3UXeKTbxqoJ:scholar.google.com&ots=KtGG5C-ZO7&sig=kdaRgepOYkr8R4TLZmGrtK650bM,12305764531272381719,/scholar?cites=12305764531272381719,,,,0,0,0
1278761,Support vector machines in engineering: an overview,2014,Sancho Salcedo‐Sanz and José Luis Rojo‐Álvarez and Manel Martínez‐Ramón and Gustavo Camps‐Valls,4,,3,234-267,Wiley Periodicals. Inc,This paper provides an overview of the support vector machine (SVM) methodology and its applicability to real‐world engineering problems. Specifically. the aim of this study  is to review the current state of the SVM technique. and to show some of its latest successful results in real‐world problems present in different engineering fields. The paper starts by reviewing the main basic concepts of SVMs and kernel methods. Kernel theory. SVMs. support vector regression (SVR). and SVM in signal processing and hybridization of SVMs with meta‐heuristics are fully described in the first part of this paper. The adoption of SVMs in engineering is nowadays a fact. As we illustrate in this paper. SVMs can handle high‐dimensional. heterogeneous and scarcely labeled datasets very efficiently. and it can be also successfully tailored to particular applications. The second part of this review is devoted to different case studies in …,True,KaBeaJwAAAAJ:NJ774b8OgUMC,95,https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1125,2050726823242414531,/scholar?cites=2050726823242414531,,,https://www.academia.edu/download/45176192/Support_vector_machines_in_engineering_a20160428-18392-1qenwwi.pdf,0,0,0
1278762,Traffic sign segmentation and classification using statistical learning methods,2015,JM Lillo-Castellano and I Mora-Jiménez and Carlos Figuera-Pozuelo and José Luis Rojo-Álvarez,153,Neurocomputing,,286-299,Elsevier,Traffic signs are an essential part of any circulation system. and failure detection by the driver may significantly increase the accident risk. Currently. automatic traffic sign detection systems still have some performance limitations. specially for achromatic signs and variable lighting conditions. In this work. we propose an automatic traffic-sign detection method capable of detecting both chromatic and achromatic signs. while taking into account rotations. scale changes. shifts. partial deformations. and shadows. The proposed system is divided into three stages:(1) segmentation of chromatic and achromatic scene elements using L⁎ a⁎ b⁎ and HSI spaces. where two machine learning techniques (k-Nearest Neighbors and Support Vector Machines) are benchmarked;(2) post-processing in order to discard non-interest regions. to connect fragmented signs. and to separate signs located at the same post; and (3) sign …,True,KaBeaJwAAAAJ:Z5m8FVwuT1cC,87,https://www.sciencedirect.com/science/article/pii/S0925231214015598,6602913632783318707,/scholar?cites=6602913632783318707,,,,0,0,0
1278763,Feature selection using support vector machines and bootstrap methods for ventricular fibrillation detection,2012,Felipe Alonso-Atienza and José Luis Rojo-Álvarez and Alfredo Rosado-Muñoz and Juan J Vinagre and Arcadi García-Alberola and Gustavo Camps-Valls,39,Expert Systems with Applications,2,1956-1967,Pergamon,Early detection of ventricular fibrillation (VF) is crucial for the success of the defibrillation therapy in automatic devices. A high number of detectors have been proposed based on temporal. spectral. and time–frequency parameters extracted from the surface electrocardiogram (ECG). showing always a limited performance. The combination ECG parameters on different domain (time. frequency. and time–frequency) using machine learning algorithms has been used to improve detection efficiency. However. the potential utilization of a wide number of parameters benefiting machine learning schemes has raised the need of efficient feature selection (FS) procedures. In this study. we propose a novel FS algorithm based on support vector machines (SVM) classifiers and bootstrap resampling (BR) techniques. We define a backward FS procedure that relies on evaluating changes in SVM performance when removing …,True,KaBeaJwAAAAJ:NhqRSupF_l8C,86,https://www.sciencedirect.com/science/article/pii/S0957417411011626,4587839335488120936,/scholar?cites=4587839335488120936,,,http://www.vpredict.org/tabs/pdf/vpredict_feature_selection_using_support_vector_machines_and_bootstrap_methods_for_ventricular_fibrillation_detection.pdf,0,0,0
1278764,Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response,2000,Adam Hoover and Valentina Kouznetsova and Michael Goldbaum,19,"Medical Imaging, IEEE Transactions on",3,203-210,IEEE,Describes an automated method to locate and outline blood vessels in images of the ocular fundus. Such a tool should prove useful to eye care specialists for purposes of patient screening. treatment evaluation. and clinical study. The authors' method differs from previously known methods in that it uses local and global vessel features cooperatively to segment the vessel network. The authors evaluate their method using hand-labeled ground truth segmentations of 20 images. A plot of the operating characteristic shows that the authors' method reduces false positives by as much as 15 times over basic thresholding of a matched filter response (MFR). at up to a 75% true positive rate. For a baseline. they also compared the ground truth against a second hand-labeling. yielding a 90% true positive and a 4% false positive detection rate. on average. These numbers suggest there is still room for a 15% true positive rate …,True,Sa6bwmIAAAAJ:ns9cj8rnVeAC,2145,https://ieeexplore.ieee.org/abstract/document/845178/,3227082893625589822,/scholar?cites=3227082893625589822,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2232087/pdf/procamiasymp00005-0963.pdf,0,0,0
1278765,An experimental comparison of range image segmentation algorithms,1996,Adam Hoover and Gillian Jean-Baptiste and Xiaoyi Jiang and Patrick J Flynn and Horst Bunke and Dmitry B Goldgof and Kevin Bowyer and David W Eggert and Andrew Fitzgibbon and Robert B Fisher,18,IEEE transactions on pattern analysis and machine intelligence,7,673-689,IEEE,A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented. missed. and noise regions. over- and under-segmentation. and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches.,True,Sa6bwmIAAAAJ:u5HHmVD_uO8C,1124,https://ieeexplore.ieee.org/abstract/document/506791/,10259986182752622785,/scholar?cites=10259986182752622785,,,https://homepages.inf.ed.ac.uk/rbf/PAPERS/hoover.pdf,0,0,0
1278766,Locating the optic nerve in a retinal image using the fuzzy convergence of the blood vessels,2003,Adam Hoover and Michael Goldbaum,22,IEEE transactions on medical imaging,8,951-958,IEEE,We describe an automated method to locate the optic nerve in images of the ocular fundus. Our method uses a novel algorithm we call fuzzy convergence to determine the origination of the blood vessel network. We evaluate our method using 31 images of healthy retinas and 50 images of diseased retinas. containing such diverse symptoms as tortuous vessels. choroidal neovascularization. and hemorrhages that completely obscure the actual nerve. On this difficult data set. our method achieved 89% correct detection. We also compare our method against three simpler methods. demonstrating the performance improvement. All our images and data are freely available for other researchers to use in evaluating related methods.,True,Sa6bwmIAAAAJ:u-x6o8ySG0sC,897,https://ieeexplore.ieee.org/abstract/document/1216219/,13002635733257032050,/scholar?cites=13002635733257032050,,,https://www.researchgate.net/profile/Michael_Goldbaum/publication/10624130_Locating_the_optic_nerve_in_a_retinal_image_using_the_fuzzy_convergence_of_the_blood_vessels/links/00b7d52146f1c1b268000000.pdf,0,0,0
1278767,A new method for measuring meal intake in humans via automated wrist motion tracking,2012,Yujie Dong and Adam Hoover and Jenna Scisco and Eric Muth,37,Applied psychophysiology and biofeedback,3,205-215,Springer US,Measuring the energy intake (kcal) of a person in day-to-day life is difficult. The best laboratory tool achieves 95 % accuracy on average. while tools used in daily living typically achieve 60–80 % accuracy. This paper describes a new method for measuring intake via automated tracking of wrist motion. Our method uses a watch-like device with a micro-electro-mechanical gyroscope to detect and record when an individual has taken a bite of food. Two tests of the accuracy of our device in counting bites found that our method has 94 % sensitivity in a controlled meal setting and 86 % sensitivity in an uncontrolled meal setting. with one false positive per every 5 bites in both settings. Preliminary data from daily living indicates that bites measured by the device are positively related to caloric intake illustrating the potential of the device to monitor energy intake. Future research should seek to further explore the …,True,Sa6bwmIAAAAJ:lSLTfruPkqcC,221,https://link.springer.com/article/10.1007/s10484-012-9194-1,6107782205579329528,/scholar?cites=6107782205579329528,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4487660/,0,0,0
1278768,Detecting periods of eating during free-living by tracking wrist motion,2013,Yujie Dong and Jenna Scisco and Mike Wilson and Eric Muth and Adam Hoover,18,IEEE journal of biomedical and health informatics,4,1253-1260,IEEE,This paper is motivated by the growing prevalence of obesity. a health problem affecting over 500 million people. Measurements of energy intake are commonly used for the study and treatment of obesity. However. the most widely used tools rely upon self-report and require a considerable manual effort. leading to under reporting of consumption. noncompliance. and discontinued use over the long term. The purpose of this paper is to describe a new method that uses a watch-like configuration of sensors to continuously track wrist motion throughout the day and automatically detect periods of eating. Our method uses the novel idea that meals tend to be preceded and succeeded by the periods of vigorous wrist motion. We describe an algorithm that segments and classifies such periods as eating or noneating activities. We also evaluate our method on a large dataset (43 subjects. 449 total h of data. containing 116 …,True,Sa6bwmIAAAAJ:nb7KW1ujOQ8C,190,https://ieeexplore.ieee.org/abstract/document/6601618/,14931775781691198182,/scholar?cites=14931775781691198182,,,https://cecas.clemson.edu/~ahoover/bite-counter/IEEE-JBHI-2013.pdf,0,0,0
1278769,Real-time detection of workload changes using heart rate variability,2012,Adam Hoover and Anirud Singh and Stephanie Fishel-Brown and Eric Muth,7,Biomedical Signal Processing and Control,4,333-341,Elsevier,This work presents a novel approach to detecting real-time changes in workload using heart rate variability (HRV). We propose that for a given workload state. the values of HRV vary in a sub-range of a Gaussian distribution. We describe methods to monitor a HRV signal in real-time for change points based upon sub-Gaussian fitting. We tested our method on subjects sitting at a computer performing a low workload surveillance task and a high workload video game task. The proposed algorithm showed superior performance compared to the classic CUSUM method for detecting task changes.,True,Sa6bwmIAAAAJ:HDshCWvjkbEC,103,https://www.sciencedirect.com/science/article/pii/S1746809411000802,842574118424556083,/scholar?cites=842574118424556083,,,,0,0,0
1278770,Slowing bite-rate reduces energy intake: an application of the bite counter device,2011,Jenna L Scisco and Eric R Muth and Yujie Dong and Adam W Hoover,111,Journal of the American Dietetic Association,8,1231-1235,Elsevier,Slow eating may be associated with reduced energy intake. A device that counts bites can provide bite-rate feedback to the user. The purpose of this study was to explore the bite counter's utility for slowing bite-rate and reducing energy intake. The study was a within-participants design with three conditions. From February to April 2009. university students (N=30) ate three meals in the laboratory: a baseline meal without feedback (Baseline). a meal during which participants received bite-rate feedback (Feedback). and a meal during which participants followed a 50% slower bite-rate target (Slow Bite-Rate). Kilocalories of food consumed. ratings of satiation and food-liking. and milliliters of water consumed were statistically compared across conditions using repeated-measures analyses of variance. Overall. participants ate 70 kcal fewer during the Slow Bite-Rate condition compared with the Feedback condition. In …,True,Sa6bwmIAAAAJ:M3NEmzRMIkIC,87,https://www.sciencedirect.com/science/article/pii/S0002822311005773,14432449751212649769,/scholar?cites=14432449751212649769,,,,0,0,0
1278771,Physiological compliance and team performance,2009,Amanda N Elkins and Eric R Muth and Adam W Hoover and Alexander D Walker and Thomas L Carpenter and Fred S Switzer,40,Applied ergonomics,6,997-1003,Elsevier,Physiological compliance (PC) refers to the correlation between physiological measures of team members over time. The goals of this study were to examine ways of measuring PC in heart rate variability (HRV) data and the relationship between PC and team performance. Teams were tasked with entering both real and simulated rooms and “shooting” individuals with a weapon and identifying individuals without a weapon. The linear correlation and directional agreement PC methods were shown to be the most sensitive to differences in performance. with greater PC being associated with better performance. The correlation method when applied to a measure of respiratory sinus arrhythmia (RSA) revealed a significant difference between high and low performers (t[8] = −2.31. p = 0.03) and the directional agreement applied to inter-beat-intervals and RSA revealed trend-level differences (t[4.62] = −1.86. p = 0.06 and …,True,Sa6bwmIAAAAJ:KlAtU1dfN6UC,87,https://www.sciencedirect.com/science/article/pii/S0003687009000271,844338195629110648,/scholar?cites=844338195629110648,,,,0,0,0
1278772,Drusen detection in a retinal image using multi-level analysis,2003,Lee Brandon and Adam Hoover,,,,618-625,Springer. Berlin. Heidelberg,This paper concerns a method to automatically detect drusen in a retinal image without human supervision or interaction. We use a multi-level approach. beginning with classification at the pixel level and proceeding to the region level. area level. and then image level. This allows the lowest levels of classification to be tuned to detect even the faintest and most difficult to discern drusen. relying upon the higher levels of classification to use an ever broadening context to refine the segmentation. We test our methods on a set of 119 images containing all types of drusen as well as images containing no drusen or other potentially confusing lesions. Our overall correct detection rate is 87%.,True,Sa6bwmIAAAAJ:eQOLeE2rZwMC,73,https://link.springer.com/chapter/10.1007/978-3-540-39899-8_76,4672165390698794249,/scholar?cites=4672165390698794249,,,https://link.springer.com/content/pdf/10.1007/978-3-540-39899-8_76.pdf,0,0,0
1278773,Examining the utility of a bite-count–based measure of eating activity in free-living human beings,2014,Jenna L Scisco and Eric R Muth and Adam W Hoover,114,Journal of the Academy of Nutrition and Dietetics,3,464-469,Elsevier,The obesity epidemic has triggered a need for novel methods for measuring eating activity in free-living settings. Here. we introduce a bite-count method that has the potential to be used in long-term investigations of eating activity. The purpose of our observational study was to describe the relationship between bite count and energy intake and determine whether there are sex and body mass index group differences in kilocalories per bite in free-living human beings. From October 2011 to February 2012. 77 participants used a wrist-worn device for 2 weeks to measure bite count during 2.975 eating activities. An automated self-administered 24-hour recall was completed daily to provide kilocalorie estimates for each eating activity. Pearson's correlation indicated a moderate. positive correlation between bite count and kilocalories (r=0.44; P<0.001) across all 2.975 eating activities. The average per-individual …,True,Sa6bwmIAAAAJ:dshw04ExmUIC,68,https://www.sciencedirect.com/science/article/pii/S2212267213014251,2262588978274016745,/scholar?cites=2262588978274016745,,,https://cecas.clemson.edu/~ahoover/bite-counter/Scisco-2013.pdf,0,0,0
1278774,A device for detecting and counting bites of food taken by a person during eating,2009,Yujie Dong and Adam Hoover and Eric Muth,,,,265-268,IEEE,We introduce methods for detecting in real-time information concerning bites taken during a meal. Our methods use an orientation sensor placed on the wrist of a user. and analyze the rolling motion of the wrist in order to detect a pattern related to biting behavior. We have built a prototype bite detector device based upon our methods. The device can count the total number of bites the user has taken. and provide the bites-taken rate (bites per minute) of the user. Experiments have been conducted to determine its accuracy. Ten subjects ate a meal of their choice. using utensils (or fingers) of their choice. Video was recorded of subjects eating. and synchronized with our device. in order to evaluate its performance. The sensitivity of the device was found to be 91%. Our methods could find use in a number of applications. including helping a user with obesity. eating disorders or eating rate problems.,True,Sa6bwmIAAAAJ:IWHjjKOFINEC,59,https://ieeexplore.ieee.org/abstract/document/5341790/,10147744935302823314,/scholar?cites=10147744935302823314,,,https://www.researchgate.net/profile/Eric_Muth/publication/221204276_A_Device_for_Detecting_and_Counting_Bites_of_Food_Taken_by_a_Person_During_Eating/links/54d4aa810cf2970e4e636a07.pdf,0,0,0
1278775,A snake-based approach to accurate determination of both contact points and contact angles,2006,Aurelien F Stalder and Gerit Kulik and Daniel Sage and L Barbieri and Patrick Hoffmann,286,Colloids and surfaces A: physicochemical and engineering aspects,1-3,92-103,Elsevier,We present a new method based on B-spline snakes (active contours) for measuring high-accuracy contact angles. In this approach. we avoid making physical assumptions by defining the contour of the drop as a versatile B-spline curve. When useful. we extend this curve by mirror symmetry so that we can take advantage of the reflection of the drop onto the substrate to detect the position of the contact points. To keep a wide range of applicability. we refrain from discretizing the contour of the drop. and we choose to optimize an advanced image-energy term to drive the evolution of the curve. This term has directional gradient and region-based components; additionally. another term—an internal energy—is responsible for the snake elasticity and constrains the parameterization of the spline. While preserving precision at the contact points. we limit the computational complexity by constraining a non-uniform …,True,bGVd_8oAAAAJ:u5HHmVD_uO8C,805,https://www.sciencedirect.com/science/article/pii/S0927775706002214,7147735809188952554,/scholar?cites=7147735809188952554,,,https://infoscience.epfl.ch/record/130322/files/stalder0601.pdf,0,0,0
1278776,Experimental investigation of collagen waviness and orientation in the arterial adventitia using confocal laser scanning microscopy,2012,Rana Rezakhaniha and Aristotelis Agianniotis and Jelle Tymen Christiaan Schrauwen and Alessandra Griffa and Daniel Sage and CVC vd Bouten and FN Van De Vosse and Michaël Unser and Nikolaos Stergiopulos,11,Biomechanics and modeling in mechanobiology,3,461-473,Springer-Verlag,Mechanical properties of the adventitia are largely determined by the organization of collagen fibers. Measurements on the waviness and orientation of collagen. particularly at the zero-stress state. are necessary to relate the structural organization of collagen to the mechanical response of the adventitia. Using the fluorescence collagen marker CNA38-OG488 and confocal laser scanning microscopy. we imaged collagen fibers in the adventitia of rabbit common carotid arteries ex vivo. The arteries were cut open along their longitudinal axes to get the zero-stress state. We used semi-manual and automatic techniques to measure parameters related to the waviness and orientation of fibers. Our results showed that the straightness parameter (defined as the ratio between the distances of endpoints of a fiber to its length) was distributed with a beta distribution (mean value 0.72. variance 0.028) and did not …,True,bGVd_8oAAAAJ:9yKSN-GCB0IC,719,https://link.springer.com/article/10.1007/s10237-011-0325-z,7567861839320424754,/scholar?cites=7567861839320424754,,,https://link.springer.com/content/pdf/10.1007/s10237-011-0325-z.pdf,0,0,0
1278777,Low-bond axisymmetric drop shape analysis for surface tension and contact angle measurements of sessile drops,2010,Aurélien F Stalder and Tobias Melchior and Michael Müller and Daniel Sage and Thierry Blu and Michael Unser,364,Colloids and Surfaces A: Physicochemical and Engineering Aspects,1-3,72-81,Elsevier,A new method based on the Young–Laplace equation for measuring contact angles and surface tensions is presented. In this approach. a first-order perturbation technique helps to analytically solve the Young–Laplace equation according to photographic images of axisymmetric sessile drops. When appropriate. the calculated drop contour is extended by mirror symmetry so that reflection of the drop into substrate allows the detection of position of the contact points. To keep a wide range of applicability. a discretisation of the drop’s profile is not realised; instead. an optimisation of an advanced image-energy term fits an approximation of the Young–Laplace equation to drop boundaries. In addition. cubic B-spline interpolation is applied to the image of the drop to reach subpixel resolution. To demonstrate the method’s accuracy. simulated drops as well as images of liquid coal ash slags were analysed. Thanks to the …,True,bGVd_8oAAAAJ:2osOgNQ5qMEC,564,https://www.sciencedirect.com/science/article/pii/S0927775710002761,16272884424456273217,/scholar?cites=16272884424456273217,,,https://infoscience.epfl.ch/record/163621/files/stalder1001.pdf,0,0,0
1278778,Automatic tracking of individual fluorescence particles: application to the study of chromosome dynamics,2005,Daniel Sage and Franck R Neumann and Florence Hediger and Susan M Gasser and Michael Unser,14,IEEE transactions on image processing,9,1372-1383,IEEE,We present a new. robust. computational procedure for tracking fluorescent markers in time-lapse microscopy. The algorithm is optimized for finding the time-trajectory of single particles in very noisy dynamic (two- or three-dimensional) image sequences. It proceeds in three steps. First. the images are aligned to compensate for the movement of the biological structure under investigation. Second. the particle's signature is enhanced by applying a Mexican hat filter. which we show to be the optimal detector of a Gaussian-like spot in 1//spl omega//sup 2/ noise. Finally. the optimal trajectory of the particle is extracted by applying a dynamic programming optimization procedure. We have used this software. which is implemented as a Java plug-in for the public-domain ImageJ software. to track the movement of chromosomal loci within nuclei of budding yeast cells. Besides reducing trajectory analysis time by several 100 …,True,bGVd_8oAAAAJ:u-x6o8ySG0sC,480,https://ieeexplore.ieee.org/abstract/document/1495509/,9682766955534318780,/scholar?cites=9682766955534318780,,,https://infoscience.epfl.ch/record/63139/files/sage0501.pdf,0,0,0
1278779,Complex wavelets for extended depth‐of‐field: A new method for the fusion of multichannel microscopy images,2004,Brigitte Forster and Dimitri Van De Ville and Jesse Berent and Daniel Sage and Michael Unser,65,Microscopy research and technique,1‐2,33-42,Wiley Subscription Services. Inc.. A Wiley Company,Microscopy imaging often suffers from limited depth‐of‐field. However. the specimen can be “optically sectioned” by moving the object along the optical axis. Then different areas appear in focus in different images. Extended depth‐of‐field is a fusion algorithm that combines those images into one single sharp composite. One promising method is based on the wavelet transform. Here. we show how the wavelet‐based image fusion technique can be improved and easily extended to multichannel data. First. we propose the use of complex‐valued wavelet bases. which seem to outperform traditional real‐valued wavelet transforms. Second. we introduce a way to apply this technique for multichannel images that suppresses artifacts and does not introduce false colors. an important requirement for multichannel optical microscopy imaging. We evaluate our method on simulated image stacks and give results relevant to …,True,bGVd_8oAAAAJ:d1gkVwhDpl0C,379,https://onlinelibrary.wiley.com/doi/abs/10.1002/jemt.20092,6212747914090618750,/scholar?cites=6212747914090618750,,,https://infoscience.epfl.ch/record/63122/files/forster0404.pdf,0,0,0
1278780,Quantitative evaluation of software packages for single-molecule localization microscopy,2015,Daniel Sage and Hagai Kirshner and Thomas Pengo and Nico Stuurman and Junhong Min and Suliana Manley and Michael Unser,12,Nature methods,8,717-724,Nature Publishing Group,The quality of super-resolution images obtained by single-molecule localization microscopy (SMLM) depends largely on the software used to detect and accurately localize point sources. In this work. we focus on the computational aspects of super-resolution microscopy and present a comprehensive evaluation of localization software packages. Our philosophy is to evaluate each package as a whole. thus maintaining the integrity of the software. We prepared synthetic data that represent three-dimensional structures modeled after biological components. taking excitation parameters. noise sources. point-spread functions and pixelation into account. We then asked developers to run their software on our data; most responded favorably. allowing us to present a broad picture of the methods available. We evaluated their results using quantitative and user-interpretable criteria: detection rate. accuracy. quality of image …,True,bGVd_8oAAAAJ:Se3iqnhoufwC,326,https://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3442.html,13615726031814029729,/scholar?cites=13615726031814029729,,,https://www.researchgate.net/profile/Daniel_Sage/publication/278330458_Quantitative_Evaluation_of_Software_Packages_for_Single-Molecule_Localization_Microscopy/links/5f2c7df2299bf13404ab3d0f/Quantitative-Evaluation-of-Software-Packages-for-Single-Molecule-Localization-Microscopy.pdf,0,0,0
1278781,Fast  Bilateral Filtering Using Trigonometric Range Kernels,2011,Kunal Narayan Chaudhury and Daniel Sage and Michael Unser,20,IEEE transactions on image processing,12,3376-3382,IEEE,It is well known that spatial averaging can be realized (in space or frequency domain) using algorithms whose complexity does not scale with the size or shape of the filter. These fast algorithms are generally referred to as constant-time or O(1) algorithms in the image-processing literature. Along with the spatial filter. the edge-preserving bilateral filter involves an additional range kernel. This is used to restrict the averaging to those neighborhood pixels whose intensity are similar or close to that of the pixel of interest. The range kernel operates by acting on the pixel intensities. This makes the averaging process nonlinear and computationally intensive. particularly when the spatial filter is large. In this paper. we show how the O(1) averaging algorithms can be leveraged for realizing the bilateral filter in constant time. by using trigonometric range kernels. This is done by generalizing the idea presented by Porikli. i.e …,True,bGVd_8oAAAAJ:Tyk-4Ss8FVUC,252,https://ieeexplore.ieee.org/abstract/document/5872028/,369746088990916314,/scholar?cites=369746088990916314,,,https://arxiv.org/pdf/1105.4204,0,0,0
1278782,DeconvolutionLab2: An open-source software for deconvolution microscopy,2017,Daniel Sage and Lauréne Donati and Ferréol Soulez and Denis Fortun and Guillaume Schmit and Arne Seitz and Romain Guiet and Cédric Vonesch and Michael Unser,115,,,28-41,Academic Press,Images in fluorescence microscopy are inherently blurred due to the limit of diffraction of light. The purpose of deconvolution microscopy is to compensate numerically for this degradation. Deconvolution is widely used to restore fine details of 3D biological samples. Unfortunately. dealing with deconvolution tools is not straightforward. Among others. end users have to select the appropriate algorithm. calibration and parametrization. while potentially facing demanding computational tasks. To make deconvolution more accessible. we have developed a practical platform for deconvolution microscopy called DeconvolutionLab. Freely distributed. DeconvolutionLab hosts standard algorithms for 3D microscopy deconvolution and drives them through a user-oriented interface. In this paper. we take advantage of the release of DeconvolutionLab2 to provide a complete description of the software package and its built-in …,True,bGVd_8oAAAAJ:RYcK_YlVTxYC,233,https://www.sciencedirect.com/science/article/pii/S1046202316305096,4293145777760909235,/scholar?cites=4293145777760909235,,,https://www.sciencedirect.com/science/article/pii/S1046202316305096,0,0,0
1278783,Effect of aging on elastin functionality in human cerebral arteries,2009,Edouard Fonck and Georg G Feigl and Jean Fasel and Daniel Sage and Michael Unser and Daniel A Rüfenacht and Nikolaos Stergiopulos,40,Stroke,7,2552-2556,Lippincott Williams & Wilkins,Background and Purpose— Aging affects elastin. a key component of the arterial wall integrity and functionality. Elastin degradation in cerebral vessels is associated with cerebrovascular disease. The goal of this study is to assess the biomechanical properties of human cerebral arteries. their composition. and their geometry. with particular focus on the functional alteration of elastin attributable to aging.Methods— Twelve posterior cranial arteries obtained from human cadavers of 2 different age groups were compared morphologically and tested biomechanically before and after enzymatic degradation of elastin. Light. confocal. and scanning electron microscopy were used to analyze and determine structural differences. potentially attributed to aging.Results— Aging affects structural morphology and the mechanical properties of intracranial arteries. In contrast to main systemic arteries. intima and media …,True,bGVd_8oAAAAJ:Y0pCki6q_DkC,214,https://www.ahajournals.org/doi/abs/10.1161/STROKEAHA.108.528091,305083444856991172,/scholar?cites=305083444856991172,,,https://www.ahajournals.org/doi/full/10.1161/STROKEAHA.108.528091,0,0,0
1278784,Multiresolution monogenic signal analysis using the Riesz–Laplace wavelet transform,2009,Michael Unser and Daniel Sage and Dimitri Van De Ville,18,IEEE Transactions on Image Processing,11,2402-2418,IEEE,The monogenic signal is the natural 2D counterpart of the 1D analytic signal. We propose to transpose the concept to the wavelet domain by considering a complexified version of the Riesz transform which has the remarkable property of mapping a real-valued (primary) wavelet basis of L 2 (R 2 ) into a complex one. The Riesz operator is also steerable in the sense that it give access to the Hilbert transform of the signal along any orientation. Having set those foundations. we specify a primary polyharmonic spline wavelet basis of L 2 (R 2 ) that involves a single Mexican-hat-like mother wavelet (Laplacian of a B-spline). The important point is that our primary wavelets are quasi-isotropic: they behave like multiscale versions of the fractional Laplace operator from which they are derived. which ensures steerability. We propose to pair these real-valued basis functions with their complex Riesz counterparts to specify a …,True,bGVd_8oAAAAJ:IjCSPb-OGe4C,208,https://ieeexplore.ieee.org/abstract/document/5164973/,8855501901007110656,/scholar?cites=8855501901007110656,,,https://infoscience.epfl.ch/record/159337/files/unser0907.pdf,0,0,0
1278785,PixFRET. an ImageJ plug‐in for FRET calculation that can accommodate variations in spectral bleed‐throughs,2005,Jérôme N Feige and Daniel Sage and Walter Wahli and Béatrice Desvergne and Laurent Gelman,68,Microscopy research and technique,1,51-58,Wiley Subscription Services. Inc.. A Wiley Company,Fluorescence resonance energy transfer (FRET) allows the user to investigate interactions between fluorescent partners. One crucial issue when calculating sensitized emission FRET is the correction for spectral bleed‐throughs (SBTs). which requires to calculate the ratios between the intensities in the FRET and in the donor or acceptor settings. when only the donor or acceptor are present. Theoretically. SBT ratios should be constant. However. experimentally. these ratios can vary as a function of fluorophore intensity. and assuming constant values may hinder precise FRET calculation. One possible cause for such a variation is the use of a microscope set‐up with different photomultipliers for the donor and FRET channels. a set‐up allowing higher speed acquisitions on very dynamic fluorescent molecules in living cells. Herein. we show that the bias introduced by the differential response of the two PMTs can be …,True,bGVd_8oAAAAJ:UeHWp8X0CEIC,207,https://onlinelibrary.wiley.com/doi/abs/10.1002/jemt.20215,8552908524218706978,/scholar?cites=8552908524218706978,,,https://infoscience.epfl.ch/record/63141/files/feige0501.pdf,0,0,0
1278786,Deep neural networks segment neuronal membranes in electron microscopy images,2012,Dan Ciresan and Alessandro Giusti and Luca Gambardella and Jürgen Schmidhuber,25,Advances in neural information processing systems,,2843-2851,,We address a central problem of neuroanatomy. namely. the automatic segmentation of neuronal structures depicted in stacks of electron microscopy (EM) images. This is necessary to efficiently map 3D brain structure and connectivity. To segment biological neuron membranes. we use a special type of deep artificial neural network as a pixel classifier. The label of each pixel (membrane or nonmembrane) is predicted from raw pixel values in a square window centered on it. The input layer maps each window pixel to a neuron. It is followed by a succession of convolutional and max-pooling layers which preserve 2D information and extract features with increasing levels of abstraction. The output layer produces a calibrated probability for each class. The classifier is trained by plain gradient descent on a 512× 512× 30 stack with known ground truth. and tested on a stack of the same size (ground truth unknown to the authors) by the organizers of the ISBI 2012 EM Segmentation Challenge. Even without problem-specific postprocessing. our approach outperforms competing techniques by a large margin in all three considered metrics. ie rand error. warping error and pixel error. For pixel error. our approach is the only one outperforming a second human observer.,True,7wj5gXgAAAAJ:R3hNpaxXUhUC,1409,http://people.idsia.ch/~ciresan/data/nips2012.pdf,750234041877790810,/scholar?cites=750234041877790810,,,http://people.idsia.ch/~ciresan/data/nips2012.pdf,0,0,0
1278787,Mitosis detection in breast cancer histology images with deep neural networks,2013,Dan C Cireşan and Alessandro Giusti and Luca M Gambardella and Jürgen Schmidhuber,,,,411-418,Springer. Berlin. Heidelberg,We use deep max-pooling convolutional neural networks to detect mitosis in breast histology images. The networks are trained to classify each pixel in the images. using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition. outperforming other contestants by a significant margin.,True,7wj5gXgAAAAJ:isC4tDSrTZIC,1313,https://link.springer.com/chapter/10.1007/978-3-642-40763-5_51,4486026543476056412,/scholar?cites=4486026543476056412,,,https://link.springer.com/content/pdf/10.1007/978-3-642-40763-5_51.pdf,0,0,0
1278788,A machine learning approach to visual perception of forest trails for mobile robots,2015,Alessandro Giusti and Jérôme Guzzi and Dan C Cireşan and Fang-Lin He and Juan P Rodríguez and Flavio Fontana and Matthias Faessler and Christian Forster and Jürgen Schmidhuber and Gianni Di Caro and Davide Scaramuzza and Luca M Gambardella,1,IEEE Robotics and Automation Letters,2,661-667,IEEE,We study the problem of perceiving forest or mountain trails from a single monocular image acquired from the viewpoint of a robot traveling on the trail itself. Previous literature focused on trail segmentation. and used low-level features such as image saliency or appearance contrast; we propose a different approach based on a deep neural network used as a supervised image classifier. By operating on the whole image at once. our system outputs the main direction of the trail compared to the viewing direction. Qualitative and quantitative results computed on a large real-world dataset (which we provide for download) show that our approach outperforms alternatives. and yields an accuracy comparable to the accuracy of humans that are tested on the same image classification task. Preliminary results on using this information for quadrotor control in unseen trails are reported. To the best of our knowledge. this is the …,True,7wj5gXgAAAAJ:UxriW0iASnsC,541,https://ieeexplore.ieee.org/abstract/document/7358076/,11089448494001932539,/scholar?cites=11089448494001932539,,,https://www.zora.uzh.ch/id/eprint/125475/1/RAL16_Giusti.pdf,0,0,0
1278789,Max-pooling convolutional neural networks for vision-based hand gesture recognition,2011,Jawad Nagi and Frederick Ducatelle and Gianni A Di Caro and Dan Cireşan and Ueli Meier and Alessandro Giusti and Farrukh Nagi and Jürgen Schmidhuber and Luca Maria Gambardella,,,,342-347,IEEE,Automatic recognition of gestures using computer vision is important for many real-world applications such as sign language recognition and human-robot interaction (HRI). Our goal is a real-time hand gesture-based HRI interface for mobile robots. We use a state-of-the-art big and deep neural network (NN) combining convolution and max-pooling (MPCNN) for supervised feature learning and classification of hand gestures given by humans to mobile robots using colored gloves. The hand contour is retrieved by color segmentation. then smoothened by morphological image processing which eliminates noisy edges. Our big and deep MPCNN classifies 6 gesture classes with 96% accuracy. nearly three times better than the nearest competitor. Experiments with mobile robots using an ARM 11 533MHz processor achieve real-time gesture recognition performance.,True,7wj5gXgAAAAJ:QIV2ME_5wuYC,459,https://ieeexplore.ieee.org/abstract/document/6144164/,344799027105415661,/scholar?cites=344799027105415661,,,https://www.researchgate.net/profile/Frederick_Ducatelle/publication/221296082_Max-pooling_convolutional_neural_networks_for_vision-based_hand_gesture_recognition/links/09e4150911c0d2d12e000000.pdf,0,0,0
1278790,Assessment of algorithms for mitosis detection in breast cancer histopathology images,2015,Mitko Veta and Paul J Van Diest and Stefan M Willems and Haibo Wang and Anant Madabhushi and Angel Cruz-Roa and Fabio Gonzalez and Anders BL Larsen and Jacob S Vestergaard and Anders B Dahl and Dan C Cireşan and Jürgen Schmidhuber and Alessandro Giusti and Luca M Gambardella and F Boray Tek and Thomas Walter and Ching-Wei Wang and Satoshi Kondo and Bogdan J Matuszewski and Frederic Precioso and Violet Snell and Josef Kittler and Teofilo E De Campos and Adnan M Khan and Nasir M Rajpoot and Evdokia Arkoumani and Miangela M Lacle and Max A Viergever and Josien PW Pluim,20,Medical image analysis,1,237-248,Elsevier,The proliferative activity of breast tumors. which is routinely estimated by counting of mitotic figures in hematoxylin and eosin stained histology sections. is considered to be one of the most important prognostic markers. However. mitosis counting is laborious. subjective and may suffer from low inter-observer agreement. With the wider acceptance of whole slide images in pathology labs. automatic image analysis has been proposed as a potential solution for these issues.In this paper. the results from the Assessment of Mitosis Detection Algorithms 2013 (AMIDA13) challenge are described. The challenge was based on a data set consisting of 12 training and 11 testing subjects. with more than one thousand annotated mitotic figures by multiple observers. Short descriptions and results from the evaluation of eleven methods are presented. The top performing method has an error rate that is comparable to the inter …,True,7wj5gXgAAAAJ:f2IySw72cVMC,341,https://www.sciencedirect.com/science/article/pii/S1361841514001807,3287706387125995408,/scholar?cites=3287706387125995408,,,https://arxiv.org/pdf/1411.5825,0,0,0
1278791,Fast image scanning with deep max-pooling convolutional neural networks,2013,Alessandro Giusti and Dan C Cireşan and Jonathan Masci and Luca M Gambardella and Jürgen Schmidhuber,,,,4034-4038,IEEE,Deep Neural Networks now excel at image classification. detection and segmentation. When used to scan images by means of a sliding window. however. their high computational complexity can bring even the most powerful hardware to its knees. We show how dynamic programming can speedup the process by orders of magnitude. even when max-pooling layers are present.,True,7wj5gXgAAAAJ:RHpTSmoSYBkC,300,https://ieeexplore.ieee.org/abstract/document/6738831/,11106965245059143583,/scholar?cites=11106965245059143583,,,https://arxiv.org/pdf/1302.1700,0,0,0
1278792,Crowdsourcing the creation of image segmentation algorithms for connectomics,2015,Ignacio Arganda-Carreras and Srinivas C Turaga and Daniel R Berger and Dan Cireşan and Alessandro Giusti and Luca M Gambardella and Jürgen Schmidhuber and Dmitry Laptev and Sarvesh Dwivedi and Joachim M Buhmann and Ting Liu and Mojtaba Seyedhosseini and Tolga Tasdizen and Lee Kamentsky and Radim Burget and Vaclav Uher and Xiao Tan and Changming Sun and Tuan D Pham and Erhan Bas and Mustafa G Uzunbas and Albert Cardona and Johannes Schindelin and H Sebastian Seung,9,Frontiers in neuroanatomy,,142,Frontiers,To stimulate progress in automating the reconstruction of neural circuits. we organized the first international challenge on 2D segmentation of electron microscopic (EM) images of the brain. Participants submitted boundary maps predicted for a test set of images. and were scored based on their agreement with ground truth from human experts. The winning team had no prior experience with EM images. and employed a convolutional network. This ``deep learning'' approach has since become accepted as a standard for segmentation of EM images. The challenge has continued to accept submissions. and the best so far has resulted from cooperation between two teams. The challenge has probably saturated. as algorithms cannot progress beyond limits set by ambiguities inherent in 2D scoring. Retrospective evaluation of the challenge scoring system reveals that it was not sufficiently robust to variations in the widths of neurite borders. We propose a solution to this problem. which should be useful for a future 3D segmentation challenge.,True,7wj5gXgAAAAJ:KxtntwgDAa4C,233,https://www.frontiersin.org/articles/10.3389/fnana.2015.00142/full?utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Neuroanatomy&id=152591,4792660200369442560,/scholar?cites=4792660200369442560,,,https://www.frontiersin.org/articles/10.3389/fnana.2015.00142/full?utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Neuroanatomy&id=152591,0,0,0
1278793,Tinylime: Bridging mobile and sensor networks through middleware,2005,Carlo Curino and Matteo Giani and Marco Giorgetta and Alessandro Giusti and Amy L Murphy and Gian Pietro Picco,,,,61-72,IEEE,In the rapidly developing field of sensor networks. bridging the gap between the applications and the hardware presents a major challenge. Although middleware is one solution. it must be specialized to the qualities of sensor networks. especially energy consumption. The work presented here provides two contributions: a new operational setting for sensor networks and a middleware for easing software development in this setting. The operational setting we target removes the usual assumption of a central collection point for sensor data. Instead the sensors are sparsely distributed in an environment. not necessarily able to communicate among themselves. and a set of clients move through space accessing the data of sensors nearby. yielding a system which naturally provides context relevant information to client applications. We further assume the clients are wirelessly networked and share locally accessed data …,True,7wj5gXgAAAAJ:u5HHmVD_uO8C,207,https://ieeexplore.ieee.org/abstract/document/1392743/,14292360469193435191,/scholar?cites=14292360469193435191,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.5310&rep=rep1&type=pdf,0,0,0
1278794,Rawseeds ground truth collection systems for indoor self-localization and mapping,2009,Simone Ceriani and Giulio Fontana and Alessandro Giusti and Daniele Marzorati and Matteo Matteucci and Davide Migliore and Davide Rizzi and Domenico G Sorrenti and Pierluigi Taddei,27,Autonomous Robots,4,353-371,Springer US,A trustable and accurate ground truth is a key requirement for benchmarking self-localization and mapping algorithms; on the other hand. collection of ground truth is a complex and daunting task. and its validation is a challenging issue. In this paper we propose two techniques for indoor ground truth collection. developed in the framework of the European project Rawseeds. which are mutually independent and also independent on the sensors onboard the robot. These techniques are based. respectively. on a network of fixed cameras. and on a network of fixed laser scanners. We show how these systems are implemented and deployed. and. most importantly. we evaluate their performance; moreover. we investigate the possible fusion of their outputs.,True,7wj5gXgAAAAJ:9yKSN-GCB0IC,154,https://link.springer.com/article/10.1007/s10514-009-9156-5,11807855499623101541,/scholar?cites=11807855499623101541,,,https://www.researchgate.net/profile/Daniele_Marzorati/publication/216250068_Rawseeds_ground_truth_collection_systems_for_indoor_self-localization_and_mapping/links/09e415082609581443000000/Rawseeds-ground-truth-collection-systems-for-indoor-self-localization-and-mapping.pdf,0,0,0
1278795,Mobile data collection in sensor networks: The TinyLime middleware,2005,Carlo Curino and Matteo Giani and Marco Giorgetta and Alessandro Giusti and Amy L Murphy and Gian Pietro Picco,1,Pervasive and Mobile Computing,4,446-469,Elsevier,In this paper we describe TinyLime. a novel middleware for wireless sensor networks that departs from the traditional setting where sensor data is collected by a central monitoring station. and enables instead multiple mobile monitoring stations to access the sensors in their proximity and share the collected data through wireless links. This intrinsically context-aware setting is demanded by applications where the sensors are sparse and possibly isolated. and where on-site. location-dependent data collection is required. An extension of the Lime middleware for mobile ad hoc networks. TinyLime makes sensor data available through a tuple space interface. providing the illusion of shared memory between applications and sensors. Data aggregation capabilities and a power-savvy architecture complete the middleware features. The paper presents the model and application programming interface of TinyLime …,True,7wj5gXgAAAAJ:u-x6o8ySG0sC,107,https://www.sciencedirect.com/science/article/pii/S1574119205000453,15527686963078496443,/scholar?cites=15527686963078496443,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.3700&rep=rep1&type=pdf,0,0,0
1278796,Machine-learning method for quality of transmission prediction of unestablished lightpaths,2018,Cristina Rottondi and Luca Barletta and Alessandro Giusti and Massimo Tornatore,10,Journal of Optical Communications and Networking,2,A286-A297,Optical Society of America,Predicting the quality of transmission (QoT) of a lightpath prior to its deployment is a step of capital importance for an optimized design of optical networks. Due to the continuous advances in optical transmission. the number of design parameters available to system engineers (e.g.. modulation formats. baud rate. code rate. etc.) is growing dramatically. thus significantly increasing the alternative scenarios for lightpath deployment. As of today. existing (pre-deployment) estimation techniques for lightpath QoT belong to two categories: “exact” analytical models estimating physical-layer impairments. which provide accurate results but incur heavy computational requirements. and margined formulas. which are computationally faster but typically introduce high link margins that lead to underutilization of network resources. In this paper. we explore a third option. i.e.. machine learning (ML). as ML techniques have already …,True,7wj5gXgAAAAJ:dJ_BR67V0s4C,94,https://www.osapublishing.org/abstract.cfm?uri=jocn-10-2-a286,13484162802291522391,/scholar?cites=13484162802291522391,,,https://www.osapublishing.org/viewmedia.cfm?seq=0&uri=jocn-10-2-A286,0,0,0
1278797,A new 1D chaotic system for image encryption,2014,Yicong Zhou and Long Bao and CL Philip Chen,97,Signal processing,,172-182,Elsevier,This paper introduces a simple and effective chaotic system using a combination of two existing one-dimension (1D) chaotic maps (seed maps). Simulations and performance evaluations show that the proposed system is able to produce many 1D chaotic maps with larger chaotic ranges and better chaotic behaviors compared with their seed maps. To investigate its applications in multimedia security. a novel image encryption algorithm is proposed. Using a same set of security keys. this algorithm is able to generate a completely different encrypted image each time when it is applied to the same original image. Experiments and security analysis demonstrate the algorithm's excellent performance in image encryption and various attacks.,True,Fe5Ru58AAAAJ:svGagg1hbZMC,528,https://www.sciencedirect.com/science/article/pii/S0165168413004258,3367498797269577401,/scholar?cites=3367498797269577401,,,https://www.researchgate.net/profile/Yicong_Zhou/publication/259098824_A_new_1D_chaotic_system_for_image_encryption/links/5ce7ee47a6fdccc9ddcb16ca/A-new-1D-chaotic-system-for-image-encryption.pdf,0,0,0
1278798,2D Sine Logistic modulation map for image encryption,2015,Zhongyun Hua and Yicong Zhou and Chi-Man Pun and CL Philip Chen,297,Information Sciences,,80-94,Elsevier,Because of the excellent properties of unpredictability. ergodicity and sensitivity to their parameters and initial values. chaotic maps are widely used in security applications. In this paper. we introduce a new two-dimensional Sine Logistic modulation map (2D-SLMM) which is derived from the Logistic and Sine maps. Compared with existing chaotic maps. it has the wider chaotic range. better ergodicity. hyperchaotic property and relatively low implementation cost. To investigate its applications. we propose a chaotic magic transform (CMT) to efficiently change the image pixel positions. Combining 2D-SLMM with CMT. we further introduce a new image encryption algorithm. Simulation results and security analysis demonstrate that the proposed algorithm is able to protect images with low time complexity and a high security level as well as to resist various attacks.,True,Fe5Ru58AAAAJ:zfsRRabFVBUC,403,https://www.sciencedirect.com/science/article/pii/S0020025514010883,15475601598018142173,/scholar?cites=15475601598018142173,,,http://huazhongyun.cn/wp-content/themes/homepage/Paper_PDF/2D%20Sine%20Logistic%20modulation%20map%20for%20image%20encryption.pdf,0,0,0
1278799,Image encryption using 2D Logistic-adjusted-Sine map,2016,Zhongyun Hua and Yicong Zhou,339,Information Sciences,,237–253,Elsevier,With complex properties of ergodicity. unpredictability and sensitivity to initial states. chaotic systems are widely used in cryptography. This paper proposes a two-dimensional Logistic-adjusted-Sine map (2D-LASM). Performance evaluations show that it has better ergodicity and unpredictability. and a wider chaotic range than many existing chaotic maps. Using the proposed map. this paper further designs a 2D-LASM-based image encryption scheme (LAS-IES). The principle of diffusion and confusion are strictly fulfilled. and a mechanism of adding random values to plain-image is designed to enhance the security level of cipher-image. Simulation results and security analysis show that LAS-IES can efficiently encrypt different kinds of images into random-like ones that have strong ability of resisting various security attacks.,True,Fe5Ru58AAAAJ:xm1hsP5ya-EC,347,https://www.sciencedirect.com/science/article/pii/S0020025516000281,6179689533069429125,/scholar?cites=6179689533069429125,,,https://viplab.cis.um.edu.mo/publications/journal/Image%20encryption%20using%202D%20Logistic-adjusted-Sinemap.pdf,0,0,0
1278800,Local Shannon entropy measure with statistical tests for image randomness,2013,Yue Wu and Yicong Zhou and George Saveriades and Sos Agaian and Joseph P Noonan and Premkumar Natarajan,2,Information Sciences,39,62-65,,In this paper we propose a new image randomness measure using Shannon entropy over local image blocks. The proposed local Shannon entropy measure overcomes several weaknesses of the conventional global Shannon entropy measure. including unfair randomness comparisons between images of different sizes. failure to discern image randomness before and after image shuffling. and possible inaccurate scores for synthesized images. Statistical tests pertinent to this new measure are also derived. This new measure is therefore both quantitative and qualitative. The parameters in the local Shannon entropy measure are further optimized for a better capture of local image randomness. The estimated statistics and observed distribution from 50.000 experiments match the theoretical ones. Finally. two examples are given. applying the proposed measure to image randomness among shuffled images and …,True,Fe5Ru58AAAAJ:Dmoar05iI2YC,319,https://www.sciencedirect.com/science/article/pii/S002002551200521X,16445092966626713768,/scholar?cites=16445092966626713768,,,https://viplab.cis.um.edu.mo/publications/journal/Local%20Shannon%20entropy%20measure%20with%20statistical%20tests%20for%20image%20randomness.pdf,0,0,0
1278801,Genetic learning particle swarm optimization,2016,Yue-Jiao Gong and Jing-Jing Li and Yicong Zhou and Yun Li and Henry Shu-Hung Chung and Yu-Hui Shi and Jun Zhang,46,IEEE Transactions on Cybernetics,10,2277 - 2290,IEEE,Social learning in particle swarm optimization (PSO) helps collective efficiency. whereas individual reproduction in genetic algorithm (GA) facilitates global effectiveness. This observation recently leads to hybridizing PSO with GA for performance enhancement. However. existing work uses a mechanistic parallel superposition and research has shown that construction of superior exemplars in PSO is more effective. Hence. this paper first develops a new framework so as to organically hybridize PSO with another optimization technique for “learning.” This leads to a generalized “learning PSO” paradigm. the *L-PSO. The paradigm is composed of two cascading layers. the first for exemplar generation and the second for particle updates as per a normal PSO algorithm. Using genetic evolution to breed promising exemplars for PSO. a specific novel *L-PSO algorithm is proposed in the paper. termed genetic learning …,True,Fe5Ru58AAAAJ:TNEldfgDb5MC,264,https://ieeexplore.ieee.org/abstract/document/7271066/,17813735694499887906,/scholar?cites=17813735694499887906,,,https://ieeexplore.ieee.org/iel7/6221036/6352949/07271066.pdf,0,0,0
1278802,Image encryption using a new parametric switching chaotic system,2013,Yicong Zhou and Long Bao and CL Philip Chen,93,Signal processing,11,3039-3052,Elsevier,This paper introduces a new parametric switching chaotic system (PSCS) and its corresponding transforms for image encryption. The proposed PSCS has a simple structure and integrates the Logistic. Sine and Tent maps into one single system. The PSCS shows more general properties. including the Sine and Tent maps as special instances. It has complex chaotic behaviors. A novel image encryption algorithm is introduced using the proposed PSCS and its transforms. Simulation results and security analysis are given to demonstrate that the proposed algorithm can encrypt different types of images with a high level of security.,True,Fe5Ru58AAAAJ:lPDSu1ZU3VAC,203,https://www.sciencedirect.com/science/article/pii/S0165168413001643,827940045243101001,/scholar?cites=827940045243101001,,,,0,0,0
1278803,Nonlinear unsharp masking for mammogram enhancement,2011,Karen Panetta and Yicong Zhou and Sos Agaian and Hongwei Jia,15,IEEE Transactions on Information Technology in Biomedicine,6,918-928,IEEE,This paper introduces a new unsharp masking (UM) scheme. called nonlinear UM (NLUM). for mammogram enhancement. The NLUM offers users the flexibility 1) to embed different types of filters into the nonlinear filtering operator; 2) to choose different linear or nonlinear operations for the fusion processes that combines the enhanced filtered portion of the mammogram with the original mammogram; and 3) to allow the NLUM parameter selection to be performed manually or by using a quantitative enhancement measure to obtain the optimal enhancement parameters. We also introduce a new enhancement measure approach. called the second-derivative-like measure of enhancement. which is shown to have better performance than other measures in evaluating the visual quality of image enhancement. The comparison and evaluation of enhancement performance demonstrate that the NLUM can improve the …,True,Fe5Ru58AAAAJ:R6EwkKsDylYC,191,https://ieeexplore.ieee.org/abstract/document/5981393/,16236662634344996912,/scholar?cites=16236662634344996912,,,https://viplab.cis.um.edu.mo/publications/journal/Nonlinear%20Unsharp%20Masking%20for%20Mammogram%20Enhancement.pdf,0,0,0
1278804,Cosine-transform-based chaotic system for image encryption,2019,Zhongyun Hua and Yicong Zhou and Hejiao Huang,480,Information Sciences,,403–419,Elsevier,Chaos is known as a natural candidate for cryptography applications owing to its properties such as unpredictability and initial state sensitivity. However. certain chaos-based cryptosystems have been proven to exhibit various security defects because their used chaotic maps do not have complex dynamical behaviors. To address this problem. this paper introduces a cosine-transform-based chaotic system (CTBCS). Using two chaotic maps as seed maps. the CTBCS can produce chaotic maps with complex dynamical behaviors. For illustration. we produce three chaotic maps using the CTBCS and analyze their chaos complexity. Using one of the generated chaotic maps. we further propose an image encryption scheme. The encryption scheme uses high-efficiency scrambling to separate adjacent pixels and employs random order substitution to spread a small change in the plain-image to all pixels of the cipher …,True,Fe5Ru58AAAAJ:Vxkav03X4woC,190,https://www.sciencedirect.com/science/article/pii/S0020025518309927,15326155348409637819,/scholar?cites=15326155348409637819,,,https://www.sciencedirect.com/science/article/pii/S0020025518309927,0,0,0
1278805,Cascade chaotic system with applications,2014,Yangzhong Zhou and Zhe Hua and Chi-Man Pun and CL Philip Chen,45,IEEE Transactions on Cybernetics,9,2001 - 2012,IEEE,Chaotic maps are widely used in different applications. Motivated by the cascade structure in electronic circuits. this paper introduces a general chaotic framework called the cascade chaotic system (CCS). Using two 1-D chaotic maps as seed maps. CCS is able to generate a huge number of new chaotic maps. Examples and evaluations show the CCS's robustness. Compared with corresponding seed maps. newly generated chaotic maps are more unpredictable and have better chaotic performance. more parameters. and complex chaotic properties. To investigate applications of CCS. we introduce a pseudo-random number generator (PRNG) and a data encryption system using a chaotic map generated by CCS. Simulation and analysis demonstrate that the proposed PRNG has high quality of randomness and that the data encryption system is able to protect different types of data with a high-security level.,True,Fe5Ru58AAAAJ:1xBWf43XMUgC,165,https://ieeexplore.ieee.org/abstract/document/6940279/,2748287032081264787,/scholar?cites=2748287032081264787,,,http://www.huazhongyun.cn/wp-content/themes/homepage/Paper_PDF/Cascade%20chaotic%20system%20with%20applications.pdf,0,0,0
1278806,Dimension reduction using spatial and spectral regularized local discriminant embedding for hyperspectral image classification,2014,Yicong Zhou and Jiangtao Peng and CL Philip Chen,53,IEEE Transactions on Geoscience and Remote Sensing,2,1082-1095,IEEE,Dimension reduction (DR) is a necessary and helpful preprocessing for hyperspectral image (HSI) classification. In this paper. we propose a spatial and spectral regularized local discriminant embedding (SSRLDE) method for DR of hyperspectral data. In SSRLDE. hyperspectral pixels are first smoothed by the multiscale spatial weighted mean filtering. Then. the local similarity information is described by integrating a spectral-domain regularized local preserving scatter matrix and a spatial-domain local pixel neighborhood preserving scatter matrix. Finally. the optimal discriminative projection is learned by minimizing a local spatial-spectral scatter and maximizing a modified total data scatter. Experimental results on benchmark hyperspectral data sets show that the proposed SSRLDE significantly outperforms the state-of-the-art DR methods for HSI classification.,True,Fe5Ru58AAAAJ:-BKJ5vZJwzMC,165,https://ieeexplore.ieee.org/abstract/document/6856200/,11136255273112774509,/scholar?cites=11136255273112774509,,,https://viplab.cis.um.edu.mo/publications/journal/Dimension%20Reduction%20Using%20Spatial%20and%20Spectral%20Regularized%20Local%20Discriminant%20Embedding%20for%20Hyperspectral%20Image%20Classification.pdf,0,0,0
1278807,Medical image encryption using high-speed scrambling and pixel adaptive diffusion,2018,Zhongyun Hua and Shuang Yi and Yicong Zhou,144,Signal Processing,,134 -144,Elsevier,This paper presents a new encryption scheme of protecting medical images. It has high efficiency and shows robustness of defending some impulse noise and data loss. First. some random data are inserted into surroundings of the image. Then. two rounds of high-speed scrambling and pixel adaptive diffusion are performed to randomly shuffle neighboring pixels and spread these inserted random data over the entire image. The proposed encryption scheme can be directly applied to medical images with any representation format. We provide two kinds of operations to implement the pixel adaptive diffusion: bitwise XOR and modulo arithmetic. The former has high efficiency in hardware platforms while the latter can achieve fast speed in software platforms. Simulations and evaluations show that both encryption schemes using bitwise XOR and modulo arithmetic have high security levels. can achieve much faster …,True,Fe5Ru58AAAAJ:Z7R3Ocg27JUC,151,https://www.sciencedirect.com/science/article/pii/S0165168417303559,12239252859603938872,/scholar?cites=12239252859603938872,,,http://huazhongyun.cn/wp-content/themes/homepage/Paper_PDF/Medical%20image%20encryption%20using%20high-speed%20scrambling%20and%20pixel%20adaptive%20diffusion.pdf,0,0,0
1278808,Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration,2009,Arno Klein and Jesper Andersson and Babak A Ardekani and John Ashburner and Brian Avants and Ming-Chang Chiang and Gary E Christensen and D Louis Collins and James Gee and Pierre Hellier and Joo Hyun Song and Mark Jenkinson and Claude Lepage and Daniel Rueckert and Paul Thompson and Tom Vercauteren and Roger P Woods and J John Mann and Ramin V Parsey,46,Neuroimage,3,786-802,Academic Press,All fields of neuroscience that employ brain imaging need to communicate their results with reference to anatomical regions. In particular. comparative morphometry and group analysis of functional and physiological data require coregistration of brains to establish correspondences across brain structures. It is well established that linear registration of one brain to another is inadequate for aligning brain structures. so numerous algorithms have emerged to nonlinearly register brains to one another. This study is the largest evaluation of nonlinear deformation algorithms applied to brain image registration ever conducted. Fourteen algorithms from laboratories around the world are evaluated using 8 different error measures. More than 45.000 registrations between 80 manually labeled brains were performed by algorithms including: AIR. ANIMAL. ART. Diffeomorphic Demons. FNIRT. IRTK. JRD-fluid. ROMEO. SICLE …,True,U2BX6Q8AAAAJ:u5HHmVD_uO8C,2143,https://www.sciencedirect.com/science/article/pii/S1053811908012974,3800993754532760613,/scholar?cites=3800993754532760613,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2747506/,0,0,0
1278809,An optimized blockwise nonlocal means denoising filter for 3-D magnetic resonance images,2008,Pierrick Coupé and Pierre Yger and Sylvain Prima and Pierre Hellier and Charles Kervrann and Christian Barillot,27,IEEE transactions on medical imaging,4,425-441,IEEE,A critical issue in image restoration is the problem of noise removal while keeping the integrity of relevant image information. Denoising is a crucial step to increase image quality and to improve the performance of all the tasks needed for quantitative imaging analysis. The method proposed in this paper is based on a 3-D optimized blockwise version of the nonlocal (NL)-means filter (Buades. . 2005). The NL-means filter uses the redundancy of information in the image under study to remove the noise. The performance of the NL-means filter has been already demonstrated for 2-D images. but reducing the computational burden is a critical aspect to extend the method to 3-D images. To overcome this problem. we propose improvements to reduce the computational complexity. These different improvements allow to drastically divide the computational time while preserving the performances of the NL-means filter. A …,True,U2BX6Q8AAAAJ:d1gkVwhDpl0C,1086,https://ieeexplore.ieee.org/abstract/document/4359947/,6744502436116207963,/scholar?cites=6744502436116207963,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881565/,0,0,0
1278810,Nonlocal means-based speckle filtering for ultrasound images,2009,Pierrick Coupé and Pierre Hellier and Charles Kervrann and Christian Barillot,18,IEEE transactions on image processing,10,2221-2229,IEEE,In image processing. restoration is expected to improve the qualitative inspection of the image and the performance of quantitative image analysis techniques. In this paper. an adaptation of the nonlocal (NL)-means filter is proposed for speckle reduction in ultrasound (US) images. Originally developed for additive white Gaussian noise. we propose to use a Bayesian framework to derive a  NL-means  filter adapted to a relevant ultrasound noise model. Quantitative results on synthetic data show the performances of the proposed method compared to well-established and state-of-the-art methods. Results on real images demonstrate that the proposed method is able to preserve accurately edges and structural details of the image.,True,U2BX6Q8AAAAJ:Y0pCki6q_DkC,542,https://ieeexplore.ieee.org/abstract/document/4982678/,13044649729773097970,/scholar?cites=13044649729773097970,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2784081/,0,0,0
1278811,Retrospective evaluation of intersubject brain registration,2003,Pierre Hellier and Christian Barillot and Isabelle Corouge and Bernard Gibaud and Georges Le Goualher and D Louis Collins and Allan Evans and Grégoire Malandain and Nicholas Ayache and Gary E Christensen and Hans J.  Johnson,22,IEEE transactions on medical imaging,9,1120-1130,IEEE,Although numerous methods to register brains of different individuals have been proposed. no work has been done. as far as we know. to evaluate and objectively compare the performances of different nonrigid (or elastic) registration methods on the same database of subjects. In this paper. we propose an evaluation framework. based on global and local measures of the relevance of the registration. We have chosen to focus more particularly on the matching of cortical areas. since intersubject registration methods are dedicated to anatomical and functional normalization. and also because other groups have shown the relevance of such registration methods for deep brain structures. Experiments were conducted using 6 methods on a database of 18 subjects. The global measures used show that the quality of the registration is directly related to the transformation's degrees of freedom. More surprisingly. local …,True,U2BX6Q8AAAAJ:u-x6o8ySG0sC,280,https://ieeexplore.ieee.org/abstract/document/1225846/,6741379922443303930,/scholar?cites=6741379922443303930,,,https://www.nitrc.org/docman/view.php/6/457/01225846.pdf,0,0,0
1278812,Segmentation of brain 3D MR images using level sets and dense registration,2001,Caroline Baillard and Pierre Hellier and Christian Barillot,5,Medical image analysis,3,185-194,Elsevier,This paper presents a strategy for the segmentation of brain from volumetric MR images which integrates 3D segmentation and 3D registration processes. The segmentation process is based on the level set formalism. A closed 3D surface propagates towards the desired boundaries through the iterative evolution of a 4D implicit function. In this work. the propagation relies on a robust evolution model including adaptive parameters. These depend on the input data and on statistical distribution models. The main contribution of this paper is the use of an automatic registration method to initialize the surface. as an alternative solution to manual initialization. The registration is achieved through a robust multiresolution and multigrid minimization scheme. This coupling significantly improves the quality of the method. since the segmentation is faster. more reliable and fully automatic. Quantitative and qualitative results on …,True,U2BX6Q8AAAAJ:qjMakFHDy7sC,207,https://www.sciencedirect.com/science/article/pii/S1361841501000391,12112146663746142850,/scholar?cites=12112146663746142850,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.6017&rep=rep1&type=pdf,0,0,0
1278813,Coupling dense and landmark-based approaches for nonrigid registration,2003,Pierre Hellier and Christian Barillot,22,IEEE Transactions on medical imaging,2,217-227,IEEE,We investigate the introduction of cortical constraints for non rigid intersubject brain registration. We extract sulcal patterns with the active ribbon method. presented by Le Goualher et al. (1997). An energy based registration method (Hellier et al.. 2001). which will be called photometric registration method in this paper. makes it possible to incorporate the matching of cortical sulci. The local sparse similarity and the photometric similarity are. thus. expressed in a unified framework. We show the benefits of cortical constraints on a database of 18 subjects. with global and local assessment of the registration. This new registration scheme has also been evaluated on functional magnetoencephalography data. We show that the anatomically constrained registration leads to a substantial reduction of the intersubject functional variability.,True,U2BX6Q8AAAAJ:2osOgNQ5qMEC,183,https://ieeexplore.ieee.org/abstract/document/1194632/,6446161149288261551,/scholar?cites=6446161149288261551,,,https://hal.inria.fr/inria-00072557/document,0,0,0
1278814,Hierarchical estimation of a dense deformation field for 3-D robust registration,2001,Pierre Hellier and Christian Barillot and Etienne Mémin and Patrick Pérez,20,IEEE transactions on medical imaging,5,388-402,IEEE,A new method for medical image registration is formulated as a minimization problem involving robust estimators. The authors propose an efficient hierarchical optimization framework which is both multiresolution and multigrid. An anatomical segmentation of the cortex is introduced in the adaptive partitioning of the volume on which the multigrid minimization is based. This allows to limit the estimation to the areas of interest. to accelerate the algorithm. and to refine the estimation in specified areas. At each stage of the hierarchical estimation. the authors refine current estimate by seeking a piecewise affine model for the incremental deformation field. The performance of this method is numerically evaluated on simulated data and its benefits and robustness are shown on a database of 18 magnetic resonance imaging scans of the head.,True,U2BX6Q8AAAAJ:9yKSN-GCB0IC,170,https://ieeexplore.ieee.org/abstract/document/925292/,755795553744575011,/scholar?cites=755795553744575011,,,https://www.researchgate.net/profile/Christian_Barillot/publication/47800363_Hierarchical_estimation_of_a_dense_deformation_field_for_3-D_robust_registration/links/0fcfd513ee90ed75e6000000/Hierarchical-estimation-of-a-dense-deformation-field-for-3-D-robust-registration.pdf,0,0,0
1278815,Bayesian non local means-based speckle filtering,2008,Pierrick Coupé and Pierre Hellier and Charles Kervrann and Christian Barillot,,,,1291-1294,IEEE,In ultrasound (US) imaging. denoising is intended to improve quantitative image analysis techniques. In this paper. a new version of the non local (nl) means filter adapted for US images is proposed. Originally developed for Gaussian noise removal. a Bayesian framework is used to adapt the NL means filter for speckle noise. Experiments were carried out on synthetic data sets with different speckle simulations. Results show that our NL means-based speckle filter outperforms the classical implementation of the NL means filter. as well as two other speckle adapted denoising methods (SRAD and SBF filters).,True,U2BX6Q8AAAAJ:kNdYIx-mwKoC,110,https://ieeexplore.ieee.org/abstract/document/4541240/,13457119921372955915,/scholar?cites=13457119921372955915,,,https://hal.inria.fr/docs/00/28/34/77/PDF/Coupe08c.pdf,0,0,0
1278816,3D wavelet subbands mixing for image denoising,2008,Pierrick Coupé and Pierre Hellier and Sylvain Prima and Charles Kervrann and Christian Barillot,2008,Journal of Biomedical Imaging,,1,Hindawi Publishing Corp.,A critical issue in image restoration is the problem of noise removal while keeping the integrity of relevant image information. The method proposed in this paper is a fully automatic 3D blockwise version of the nonlocal (NL) means filter with wavelet subbands mixing. The proposed wavelet subbands mixing is based on a multiresolution approach for improving the quality of image denoising filter. Quantitative validation was carried out on synthetic datasets generated with the BrainWeb simulator. The results show that our NL-means filter with wavelet subbands mixing outperforms the classical implementation of the NL-means filter in terms of denoising quality and computation time. Comparison with wellestablished methods. such as nonlinear diffusion filter and total variation minimization. shows that the proposed NL-means filter produces better denoising results. Finally. qualitative results on real data are presented.,True,U2BX6Q8AAAAJ:Se3iqnhoufwC,90,https://www.hindawi.com/journals/ijbi/2008/590183/abs/,3648432665904268420,/scholar?cites=3648432665904268420,,,https://www.hindawi.com/journals/ijbi/2008/590183/abs/,0,0,0
1278817,STREM: a robust multidimensional parametric method to segment MS lesions in MRI,2005,Laure S Aït-Ali and Sylvain Prima and Pierre Hellier and Béatrice Carsin and Gilles Edan and Christian Barillot,,,,409-416,Springer. Berlin. Heidelberg,We propose to segment Multiple Sclerosis (MS) lesions overtime in multidimensional Magnetic Resonance (MR) sequences. We use a robust algorithm that allows the segmentation of the abnormalities using the whole time series simultaneously and we propose an original rejection scheme for outliers. We validate our method using the BrainWeb simulator. To conclude. promising preliminary results on longitudinal multi-sequences of clinical data are shown.,True,U2BX6Q8AAAAJ:IjCSPb-OGe4C,90,https://link.springer.com/chapter/10.1007/11566465_51,4280503952555976837,/scholar?cites=4280503952555976837,,,https://link.springer.com/content/pdf/10.1007/11566465_51.pdf,0,0,0
1278818,Split and match: Example-based adaptive patch sampling for unsupervised style transfer,2016,Oriel Frigo and Neus Sabater and Julie Delon and Pierre Hellier,,,,553-561,,This paper presents a novel unsupervised method to transfer the style of an example image to a source image. The complex notion of image style is here considered as a local texture transfer. eventually coupled with a global color transfer. For the local texture transfer. we propose a new method based on an adaptive patch partition that captures the style of the example image and preserves the structure of the source image. More precisely. this example-based partition predicts how well a source patch matches an example patch. Results on various images show that our method outperforms the most recent techniques.,True,U2BX6Q8AAAAJ:tL5YfqkXb3gC,87,http://openaccess.thecvf.com/content_cvpr_2016/html/Frigo_Split_and_Match_CVPR_2016_paper.html,7619759086647323498,/scholar?cites=7619759086647323498,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Frigo_Split_and_Match_CVPR_2016_paper.pdf,0,0,0
1278819,Local Binary Patterns and Extreme Learning Machine for Hyperspectral Imagery Classification,2015,Wei Li and Chen Chen and Hongjun Su and Qian Du,53,IEEE Transactions on Geoscience and Remote Sensing,7,3681-3693,IEEE,It is of great interest in exploiting texture information for classification of hyperspectral imagery (HSI) at high spatial resolution. In this paper. a classification paradigm to exploit rich texture information of HSI is proposed. The proposed framework employs local binary patterns (LBPs) to extract local image features. such as edges. corners. and spots. Two levels of fusion (i.e.. feature-level fusion and decision-level fusion) are applied to the extracted LBP features along with global Gabor features and original spectral features. where feature-level fusion involves concatenation of multiple features before the pattern classification process while decision-level fusion performs on probability outputs of each individual classification pipeline and soft-decision fusion rule is adopted to merge results from the classifier ensemble. Moreover. the efficient extreme learning machine with a very simple structure is employed as the …,True,TuEwcZ0AAAAJ:RtRctb2lSbAC,439,https://ieeexplore.ieee.org/abstract/document/7010879/,11324488493007738850,/scholar?cites=11324488493007738850,,,https://www.ematlab.com/paper/ap2/9/2015-Local-Binary-Patterns-and-Extreme-Learning-Machine-for-Hyperspectral-Imagery-Classification.pdf,0,0,0
1278820,UTD-MHAD: A multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor,2015,Chen Chen and Roozbeh Jafari and Nasser Kehtarnavaz,,,,168-172,IEEE,Human action recognition has a wide range of applications including biometrics. surveillance. and human computer interaction. The use of multimodal sensors for human action recognition is steadily increasing. However. there are limited publicly available datasets where depth camera and inertial sensor data are captured at the same time. This paper describes a freely available dataset. named UTD-MHAD. which consists of four temporally synchronized data modalities. These modalities include RGB videos. depth videos. skeleton positions. and inertial signals from a Kinect camera and a wearable inertial sensor for a comprehensive set of 27 human actions. Experimental results are provided to show how this database can be used to study fusion approaches that involve using both depth camera data and inertial sensor data. This public domain dataset is of benefit to multimodality research activities being …,True,TuEwcZ0AAAAJ:yY3RG6sOEgwC,404,https://ieeexplore.ieee.org/abstract/document/7350781/,12147481579159158699,/scholar?cites=12147481579159158699,,,https://webpages.uncc.edu/cchen62/ICIP2015-Chen-Final.pdf,0,0,0
1278821,Real-world anomaly detection in surveillance videos,2018,Waqas Sultani and Chen Chen and Mubarak Shah,,,,6479-6488,,Surveillance videos are able to capture a variety of realistic anomalies. In this paper. we propose to learn anomalies by exploiting both normal and anomalous videos. To avoid annotating the anomalous segments or clips in training videos. which is very time consuming. we propose to learn anomaly through the deep multiple instance ranking framework by leveraging weakly labeled training videos. ie the training labels (anomalous or normal) are at video-level instead of clip-level. In our approach. we consider normal and anomalous videos as bags and video segments as instances in multiple instance learning (MIL). and automatically learn a deep anomaly ranking model that predicts high anomaly scores for anomalous video segments. Furthermore. we introduce sparsity and temporal smoothness constraints in the ranking loss function to better localize anomaly during training. We also introduce a new large-scale first of its kind dataset of 128 hours of videos. It consists of 1900 long and untrimmed real-world surveillance videos. with 13 realistic anomalies such as fighting. road accident. burglary. robbery. etc. as well as normal activities. This dataset can be used for two tasks. First. general anomaly detection considering all anomalies in one group and all normal activities in another group. Second. for recognizing each of 13 anomalous activities. Our experimental results show that our MIL method for anomaly detection achieves significant improvement on anomaly detection performance as compared to the state-of-the-art approaches. We provide the results of several recent deep learning baselines on anomalous activity recognition. The low …,True,TuEwcZ0AAAAJ:nWoA1JPTheMC,395,http://openaccess.thecvf.com/content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html,4939083465294260487,/scholar?cites=4939083465294260487,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.pdf,0,0,0
1278822,Enhanced skeleton visualization for view invariant human action recognition,2017,Mengyuan Liu and Hong Liu and Chen Chen,68,Pattern Recognition,,346-362,Pergamon,Human action recognition based on skeletons has wide applications in human–computer interaction and intelligent surveillance. However. view variations and noisy data bring challenges to this task. What’s more. it remains a problem to effectively represent spatio-temporal skeleton sequences. To solve these problems in one goal. this work presents an enhanced skeleton visualization method for view invariant human action recognition. Our method consists of three stages. First. a sequence-based view invariant transform is developed to eliminate the effect of view variations on spatio-temporal locations of skeleton joints. Second. the transformed skeletons are visualized as a series of color images. which implicitly encode the spatio-temporal information of skeleton joints. Furthermore. visual and motion enhancement methods are applied on color images to enhance their local patterns. Third. a convolutional neural …,True,TuEwcZ0AAAAJ:natZJ_-F0IUC,351,https://www.sciencedirect.com/science/article/pii/S0031320317300936,17304648297596978132,/scholar?cites=17304648297596978132,,,https://webpages.uncc.edu/cchen62/PR_2017.pdf,0,0,0
1278823,Real-time human action recognition based on depth motion maps,2016,Chen Chen and Kui Liu and Nasser Kehtarnavaz,12,Journal of real-time image processing,1,155-163,Springer Berlin Heidelberg,This paper presents a human action recognition method by using depth motion maps (DMMs). Each depth frame in a depth video sequence is projected onto three orthogonal Cartesian planes. Under each projection view. the absolute difference between two consecutive projected maps is accumulated through an entire depth video sequence forming a DMM. An l 2-regularized collaborative representation classifier with a distance-weighted Tikhonov matrix is then employed for action recognition. The developed method is shown to be computationally efficient allowing it to run in real-time. The recognition results applied to the Microsoft Research Action3D dataset indicate superior performance of our method over the existing methods.,True,TuEwcZ0AAAAJ:NU-BerS4NX4C,288,https://link.springer.com/article/10.1007/s11554-013-0370-1,12271336011519409778,/scholar?cites=12271336011519409778,,,https://www.academia.edu/download/37337006/Real-time_human_action_recognition_based_on_depth_motion_maps.pdf,0,0,0
1278824,A survey of depth and inertial sensor fusion for human action recognition,2017,Chen Chen and Roozbeh Jafari and Nasser Kehtarnavaz,76,Multimedia Tools and Applications,3,4405-4425,Springer US,A number of review or survey articles have previously appeared on human action recognition where either vision sensors or inertial sensors are used individually. Considering that each sensor modality has its own limitations. in a number of previously published papers. it has been shown that the fusion of vision and inertial sensor data improves the accuracy of recognition. This survey article provides an overview of the recent investigations where both vision and inertial sensors are used together and simultaneously to perform human action recognition more effectively. The thrust of this survey is on the utilization of depth cameras and inertial sensors as these two types of sensors are cost-effective. commercially available. and more significantly they both provide 3D human action data. An overview of the components necessary to achieve fusion of data from depth and inertial sensors is provided. In addition …,True,TuEwcZ0AAAAJ:m4fbC6XIj1kC,246,https://link.springer.com/content/pdf/10.1007/s11042-015-3177-1.pdf,5368078684922749914,/scholar?cites=5368078684922749914,,,https://www.researchgate.net/profile/Chen_Chen82/publication/287974349_A_survey_of_depth_and_inertial_sensor_fusion_for_human_action_recognition/links/567c1b5c08ae1e63f1e3066f.pdf,0,0,0
1278825,Compressed-sensing recovery of images and video using multihypothesis predictions,2011,Chen Chen and Eric W Tramel and James E Fowler,,,,1193-1198,IEEE,Compressed-sensing reconstruction of still images and video sequences driven by multihypothesis predictions is considered. Specifically. for still images. multiple predictions drawn for an image block are made from spatially surrounding blocks within an initial non-predicted reconstruction. For video. multihypothesis predictions of the current frame are generated from one or more previously reconstructed reference frames. In each case. the predictions are used to generate a residual in the domain of the compressed-sensing random projections. This residual being typically more compressible than the original signal leads to improved reconstruction quality. To appropriately weight the hypothesis predictions. a Tikhonov regularization to an ill-posed least-squares optimization is proposed. Experimental results demonstrate that the proposed reconstructions outperform alternative strategies not employing …,True,TuEwcZ0AAAAJ:8xutWZnSdmoC,239,https://ieeexplore.ieee.org/abstract/document/6190204/,306412477692973758,/scholar?cites=306412477692973758,,,https://pdfs.semanticscholar.org/8d37/ee24df29ddbdbd1d4822eb9a7fade0db44f1.pdf,0,0,0
1278826,Tube convolutional neural network (t-cnn) for action detection in videos,2017,Rui Hou and Chen Chen and Mubarak Shah,,,,5822-5831,,Deep learning has been demonstrated to achieve excellent results for image classification and object detection. However. the impact of deep learning on video analysis (eg action detection and recognition) has been limited due to complexity of video data and lack of annotations. Previous convolutional neural networks (CNN) based video action detection approaches usually consist of two major steps: frame-level action proposal detection and association of proposals across frames. Also. these methods employ two-stream CNN framework to handle spatial and temporal feature separately. In this paper. we propose an end-to-end deep network called Tube Convolutional Neural Network (T-CNN) for action detection in videos. The proposed architecture is a unified network that is able to recognize and localize action based on 3D convolution features. A video is first divided into equal length clips and for each clip a set of tube proposals are generated next based on 3D Convolutional Network (ConvNet) features. Finally. the tube proposals of different clips are linked together employing network flow and spatio-temporal action detection is performed using these linked video proposals. Extensive experiments on several video datasets demonstrate the superior performance of T-CNN for classifying and localizing actions in both trimmed and untrimmed videos compared to state-of-the-arts.,True,TuEwcZ0AAAAJ:9shLKfS_uJEC,230,http://openaccess.thecvf.com/content_iccv_2017/html/Hou_Tube_Convolutional_Neural_ICCV_2017_paper.html,10434730271112640937,/scholar?cites=10434730271112640937,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Hou_Tube_Convolutional_Neural_ICCV_2017_paper.pdf,0,0,0
1278827,Improving Human Action Recognition Using Fusion of Depth Camera and Inertial Sensors,2015,Chen Chen and Roozbeh Jafari and Nasser Kehtarnavaz,45,IEEE Transactions on Human-Machine Systems,1,51-61,IEEE,This paper presents a fusion approach for improving human action recognition based on two differing modality sensors consisting of a depth camera and an inertial body sensor. Computationally efficient action features are extracted from depth images provided by the depth camera and from accelerometer signals provided by the inertial body sensor. These features consist of depth motion maps and statistical signal attributes. For action recognition. both feature-level fusion and decision-level fusion are examined by using a collaborative representation classifier. In the feature-level fusion. features generated from the two differing modality sensors are merged before classification. while in the decision-level fusion. the Dempster-Shafer theory is used to combine the classification outcomes from two classifiers. each corresponding to one sensor. The introduced fusion framework is evaluated using the Berkeley …,True,TuEwcZ0AAAAJ:unp9ATQDT5gC,215,https://ieeexplore.ieee.org/abstract/document/6934998/,14520107791039753291,/scholar?cites=14520107791039753291,,,http://jafari.tamu.edu/wp-content/uploads/2015/12/ChenChen_THMS15.pdf,0,0,0
1278828,Spectral-spatial classification of hyperspectral image based on kernel extreme learning machine,2014,Chen Chen and Wei Li and Hongjun Su and Kui Liu,6,Remote sensing,6,5795-5814,Multidisciplinary Digital Publishing Institute,Extreme learning machine (ELM) is a single-layer feedforward neural network based classifier that has attracted significant attention in computer vision and pattern recognition due to its fast learning speed and strong generalization. In this paper. we propose to integrate spectral-spatial information for hyperspectral image classification and exploit the benefits of using spatial features for the kernel based ELM (KELM) classifier. Specifically. Gabor filtering and multihypothesis (MH) prediction preprocessing are two approaches employed for spatial feature extraction. Gabor features have currently been successfully applied for hyperspectral image analysis due to the ability to represent useful spatial information. MH prediction preprocessing makes use of the spatial piecewise-continuous nature of hyperspectral imagery to integrate spectral and spatial information. The proposed Gabor-filtering-based KELM classifier and MH-prediction-based KELM classifier have been validated on two real hyperspectral datasets. Classification results demonstrate that the proposed methods outperform the conventional pixel-wise classifiers as well as Gabor-filtering-based support vector machine (SVM) and MH-prediction-based SVM in challenging small training sample size conditions. View Full-Text,True,TuEwcZ0AAAAJ:X9ykpCP0fEIC,197,https://www.mdpi.com/2072-4292/6/6/5795,6980608500527007643,/scholar?cites=6980608500527007643,,,https://www.mdpi.com/2072-4292/6/6/5795/pdf,0,0,0
1278829,Action Recognition from Depth Sequences Using Depth Motion Maps-based Local Binary Patterns,2015,Chen Chen and Roozbeh Jafari and Nasser Kehtarnavaz,,,,1092-1099,IEEE,This paper presents a computationally efficient method for action recognition from depth video sequences. It employs the so called depth motion maps (DMMs) from three projection views (front. side and top) to capture motion cues and uses local binary patterns (LBPs) to gain a compact feature representation. Two types of fusion consisting of feature-level fusion and decision-level fusion are considered. In the feature-level fusion. LBP features from three DMMs are merged before classification while in the decision-level fusion. a soft decision-fusion rule is used to combine the classification outcomes. The introduced method is evaluated on two standard datasets and is also compared with the existing methods. The results indicate that it outperforms the existing methods and is able to process depth video sequences in real-time.,True,TuEwcZ0AAAAJ:s9ia6_kGH2AC,193,https://ieeexplore.ieee.org/abstract/document/7046004/,7511050042497972147,/scholar?cites=7511050042497972147,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1084.9427&rep=rep1&type=pdf,0,0,0
1278830,Cloud-assisted industrial internet of things (iiot)–enabled framework for health monitoring,2016,M Shamim Hossain and Ghulam Muhammad,101,Computer Networks,,192-202,Elsevier,The promising potential of the emerging Internet of Things (IoT) technologies for interconnected medical devices and sensors has played an important role in the next-generation healthcare industry for quality patient care. Because of the increasing number of elderly and disabled people. there is an urgent need for a real-time health monitoring infrastructure for analyzing patients’ healthcare data to avoid preventable deaths. Healthcare Industrial IoT (HealthIIoT) has significant potential for the realization of such monitoring. HealthIIoT is a combination of communication technologies. interconnected apps. Things (devices and sensors). and people that would function together as one smart system to monitor. track. and store patients’ healthcare information for ongoing care. This paper presents a HealthIIoT-enabled monitoring framework. where ECG and other healthcare data are collected by mobile devices and …,True,mmKu4-EAAAAJ:35r97b3x0nAC,537,https://www.sciencedirect.com/science/article/pii/S1389128616300019,14903433792927136146,/scholar?cites=14903433792927136146,,,http://tarjomefa.com/wp-content/uploads/2016/09/4917-english.pdf,0,0,0
1278831,Passive copy move image forgery detection using undecimated dyadic wavelet transform,2012,Ghulam Muhammad and Muhammad Hussain and George Bebis,,Digital Investigation,,,Elsevier,In this paper. a blind copy move image forgery detection method using undecimated dyadic wavelet transform (DyWT) is proposed. DyWT is shift invariant and therefore more suitable than discrete wavelet transform (DWT) for data analysis. First. the input image is decomposed into approximation (LL1) and detail (HH1) subbands. Then the LL1 and HH1 subbands are divided into overlapping blocks and the similarity between blocks is calculated. The key idea is that the similarity between the copied and moved blocks from the LL1 subband should be high. while that from the HH1 subband should be low due to noise inconsistency in the moved block. Therefore. pairs of blocks are sorted based on high similarity using the LL1 subband and high dissimilarity using the HH1 subband. Using thresholding. matched pairs are obtained from the sorted list as copied and moved blocks. Experimental results show the …,True,mmKu4-EAAAAJ:IWHjjKOFINEC,218,https://www.sciencedirect.com/science/article/pii/S1742287612000242,1971027689522512170,/scholar?cites=1971027689522512170,,,http://dxsx.net/admin/editor/upload/201409/20140926171725907.pdf,0,0,0
1278832,Image forgery detection using steerable pyramid transform and local binary pattern,2014,Ghulam Muhammad and Munner H Al-Hammadi and Muhammad Hussain and George Bebis,25,Machine Vision and Applications,4,985-995,Springer Berlin Heidelberg,In this paper. a novel image forgery detection method is proposed based on the steerable pyramid transform (SPT) and local binary pattern (LBP). First. given a color image. we transform it in the YCbCr color space and apply the SPT transform on chrominance channels Cb and Cr. yielding a number of multi-scale and multi-oriented subbands. Then. we describe the texture in each SPT subband using LBP histograms. The histograms from each subband are concatenated to produce a feature vector. Finally. a support vector machine uses the feature vector to classify images into forged or authentic. The proposed method has been evaluated on three publicly available image databases. Our experimental results demonstrate the effectiveness of the proposed method and its superiority over some recent other methods.,True,mmKu4-EAAAAJ:abG-DnoFyZgC,161,https://link.springer.com/article/10.1007/s00138-013-0547-4,1133036445069416309,/scholar?cites=1133036445069416309,,,http://www.dxsx.net/admin/editor/upload/201412/20141229154133924.pdf,0,0,0
1278833,The impact of m-learning technology on students and educators,2014,Hamid R Abachi and Ghulam Muhammad,30,Computers in human behavior,,491-496,Pergamon,This paper addresses the notion of the impact of mobile learning technology from the learner’s as well as educator’s point of view. The authors have outlined the application of the e-learning in smart classes. which is followed by a similar argument with regard to the m-learning technology. This is followed by a statistical evaluation of the m-learning which through multiple surveys is conducted among the undergraduate and postgraduate students as well as the academics. In conclusion. the outcomes of these surveys are presented in graphical forms that highlight the merits and demerits of the m-learning technology.,True,mmKu4-EAAAAJ:CHSYGLWDkRkC,146,https://www.sciencedirect.com/science/article/pii/S0747563213002100,15408777197025652227,/scholar?cites=15408777197025652227,,,,0,0,0
1278834,Smart health solution integrating IoT and cloud: a case study of voice pathology monitoring,2017,Ghulam Muhammad and S. K. Md. Mizanur Rahman and Abdulhameed Alelaiwi and Atif Alamri,55,IEEE Communications Magazine,1,69-73,IEEE,The integration of the IoT and cloud technology is very important to have a better solution for an uninterrupted. secured. seamless. and ubiquitous framework. The complementary nature of the IoT and the could in terms of storage. processing. accessibility. security. service sharing. and components makes the convergence suitable for many applications. The advancement of mobile technologies adds a degree of flexibility to this solution. The health industry is one of the venues that can benefit from IoT-Cloud technology. because of the scarcity of specialized doctors and the physical movement restrictions of patients. among other factors. In this article. as a case study. we discuss the feasibility of and propose a solution for voice pathology monitoring of people using IoT-cloud. More specifically. a voice pathology detection system is proposed inside the monitoring framework using a local binary pattern on a Mel …,True,mmKu4-EAAAAJ:vbGhcppDl1QC,137,https://ieeexplore.ieee.org/abstract/document/7823340/,15104970317774535655,/scholar?cites=15104970317774535655,,,,0,0,0
1278835,IoT big data analytics for smart homes with fog and cloud computing,2019,Abdulsalam Yassine and Shailendra Singh and M Shamim Hossain and Ghulam Muhammad,91,Future Generation Computer Systems,,563-573,North-Holland,Internet of Things (IoT) analytics is an essential mean to derive knowledge and support applications for smart homes. Connected appliances and devices inside the smart home produce a significant amount of data about consumers and how they go about their daily activities. IoT analytics can aid in personalizing applications that benefit both homeowners and the ever growing industries that need to tap into consumers profiles. This article presents a new platform that enables innovative analytics on IoT captured data from smart homes. We propose the use of fog nodes and cloud system to allow data-driven services and address the challenges of complexities and resource demands for online and offline data processing. storage. and classification analysis. We discuss in this paper the requirements and the design components of the system. To validate the platform and present meaningful results. we present a case …,True,mmKu4-EAAAAJ:9pM33mqn1YgC,136,https://www.sciencedirect.com/science/article/pii/S0167739X18311099,7240557081854296715,/scholar?cites=7240557081854296715,,,http://eiu.thaieei.com/box/Technology/73/IoT%20Big%20Data%20Analytics%20for%20Smart%20Homes%20with%20Fog%20and%20Cloud%20Computing.pdf,0,0,0
1278836,Emotion recognition using deep learning approach from audio–visual emotional big data,2019,M Shamim Hossain and Ghulam Muhammad,49,Information Fusion,,69-78,Elsevier,This paper proposes an emotion recognition system using a deep learning approach from emotional Big Data. The Big Data comprises of speech and video. In the proposed system. a speech signal is first processed in the frequency domain to obtain a Mel-spectrogram. which can be treated as an image. Then this Mel-spectrogram is fed to a convolutional neural network (CNN). For video signals. some representative frames from a video segment are extracted and fed to the CNN. The outputs of the two CNNs are fused using two consecutive extreme learning machines (ELMs). The output of the fusion is given to a support vector machine (SVM) for final classification of the emotions. The proposed system is evaluated using two audio–visual emotional databases. one of which is Big Data. Experimental results confirm the effectiveness of the proposed system involving the CNNs and the ELMs.,True,mmKu4-EAAAAJ:4fGpz3EwCPoC,133,https://www.sciencedirect.com/science/article/pii/S1566253517307066,17540751811931411329,/scholar?cites=17540751811931411329,,,https://www.researchgate.net/profile/Ghulam_Muhammad2/publication/327639375_Emotion_Recognition_Using_Deep_Learning_Approach_from_Audio-Visual_Emotional_Big_Data/links/5bc595c1a6fdcc03c788f5e0/Emotion-Recognition-Using-Deep-Learning-Approach-from-Audio-Visual-Emotional-Big-Data.pdf,0,0,0
1278837,Smart healthcare monitoring: a voice pathology detection paradigm for smart cities,2019,M Shamim Hossain and Ghulam Muhammad and Atif Alamri,25,Multimedia Systems,5,565-575,Springer Berlin Heidelberg,With the increasing demand for automated. remote. intelligent. and real-time healthcare services in smart cities. smart healthcare monitoring is necessary to provide improved and complete care to residents. In this monitoring. health-related media or signals collected from smart-devices/objects are transmitted and processed to cater to the need for quality care. However. it is challenging to create a framework or method to handle media-related healthcare data analytics or signals (e.g.. voice/audio. video. or electroglottographic (EGG) signals) to meet the complex on-demand healthcare needs for successful smart city management. To this end. this paper proposes a cloud-oriented smart healthcare monitoring framework that interacts with surrounding smart devices. environments. and smart city stakeholders for affordable and accessible healthcare. As a smart city healthcare monitoring case study. a voice …,True,mmKu4-EAAAAJ:LI9QrySNdTsC,105,https://link.springer.com/article/10.1007/s00530-017-0561-x,2372571920288776786,/scholar?cites=2372571920288776786,,,,0,0,0
1278838,Cloud-assisted speech and face recognition framework for health monitoring,2015,M Shamim Hossain and Ghulam Muhammad,20,Mobile Networks and Applications,3,391-399,Springer US,The increasing demand for the remote monitoring of patients combined with the promising potential of cloud computing has enabled the design and development of a number of cloud-based systems and services for healthcare. The cloud computing. in combination with the popularity of smart handheld devices. has inspired healthcare professionals to remotely monitor patients’ health while the patient is at home. To this end. this paper proposes a cloud-assisted speech and face recognition framework for elderly health monitoring. where handheld devices or video cameras collect speech along with face images and deliver to the cloud server for possible analysis and classification. In the framework. a patient’s state such as pain. tensed. and so forth is recognized from his or her speech and face images. The patient state recognition system extracts local features from speech. and texture descriptors from face …,True,mmKu4-EAAAAJ:9vf0nzSNQJEC,105,https://link.springer.com/article/10.1007/s11036-015-0586-3,4722859315056882006,/scholar?cites=4722859315056882006,,,https://www.researchgate.net/profile/Ghulam_Muhammad2/publication/276348174_Cloud-Assisted_Speech_and_Face_Recognition_Framework_for_Health_Monitoring/links/5616412208ae0f2140065c54.pdf,0,0,0
1278839,Enforcing position-based confidentiality with machine learning paradigm through mobile edge computing in real-time industrial informatics,2019,Arun Kumar Sangaiah and Darshan Vishwasrao Medhane and Tao Han and M Shamim Hossain and Ghulam Muhammad,15,IEEE Transactions on Industrial Informatics,7,4189-4196,IEEE,Position-based services (PBSs) that deliver networked amenities based on roaming user's positions have become progressively popular with the propagation of smart mobile devices. Position is one of the important circumstances in PBSs. For effective PBSs. extraction and recognition of meaningful positions and estimating the subsequent position are fundamental procedures. Several researchers and practitioners have tried to recognize and predict positions using various techniques; however. only few deliberate the progress of position-based real-time applications considering significant tasks of PBSs. In this paper. a method for conserving position confidentiality of roaming PBSs users using machine learning techniques is proposed. We recommend a three-phase procedure for roaming PBS users. It identifies user position by merging decision trees and k-nearest neighbor and estimates user destination along …,True,mmKu4-EAAAAJ:cWzG1nlazyYC,104,https://ieeexplore.ieee.org/abstract/document/8637769/,9214586297421398817,/scholar?cites=9214586297421398817,,,,0,0,0
1278840,Cloud-assisted secure video transmission and sharing framework for smart cities,2018,M Shamim Hossain and Ghulam Muhammad and Wadood Abdul and Biao Song and BB Gupta,83,Future Generation Computer Systems,,596-606,North-Holland,With the innovations and increasing popularity of smart cities. video analytics (e.g.. from social media. entertainment. surveillance. smart health monitoring. and crowd management) are used in a range of application domains to provide safety. security. and well-being for residents. As these video analytics are shared through highly interconnected devices. sensors. and other smart city stakeholders. security and integrity is a concern for secure video content. Without proper techniques to address the security threats of such transmission and sharing. it would be very difficult for a smart city government to provide safety and quality-of-life to its residents. To this end. this paper proposes a cloud-assisted framework for secure video transmission and sharing. where mobile clients have limited capabilities; however. users need to share videos seamlessly without sacrificing integrity and quality. In the proposed framework …,True,mmKu4-EAAAAJ:oNZyr7d5Mn4C,102,https://www.sciencedirect.com/science/article/pii/S0167739X17305198,991313905982326729,/scholar?cites=991313905982326729,,,,0,0,0
1278841,Reliability of MRI-derived measurements of human cerebral cortical thickness: the effects of field strength. scanner upgrade and manufacturer,2006,Xiao Han and Jorge Jovicich and David Salat and Andre van der Kouwe and Brian Quinn and Silvester Czanner and Evelina Busa and Jenni Pacheco and Marilyn Albert and Ronald Killiany and Paul Maguire and Diana Rosas and Nikos Makris and Anders Dale and Bradford Dickerson and Bruce Fischl,32,Neuroimage,1,180-194,Academic Press,In vivo MRI-derived measurements of human cerebral cortex thickness are providing novel insights into normal and abnormal neuroanatomy. but little is known about their reliability. We investigated how the reliability of cortical thickness measurements is affected by MRI instrument-related factors. including scanner field strength. manufacturer. upgrade and pulse sequence. Several data processing factors were also studied. Two test–retest data sets were analyzed: 1) 15 healthy older subjects scanned four times at 2-week intervals on three scanners; 2) 5 subjects scanned before and after a major scanner upgrade. Within-scanner variability of global cortical thickness measurements was <0.03 mm. and the point-wise standard deviation of measurement error was approximately 0.12 mm. Variability was 0.15 mm and 0.17 mm in average. respectively. for cross-scanner (Siemens/GE) and cross-field strength (1.5 T/3 T …,True,XGVV3gEAAAAJ:u-x6o8ySG0sC,1282,https://www.sciencedirect.com/science/article/pii/S1053811906001601,15509811056373594171,/scholar?cites=15509811056373594171,,,http://www.nmr.mgh.harvard.edu/~fischl/reprints/Han_NeuroImage_2006_thickness_reliability.pdf,0,0,0
1278842,A topology preserving level set method for geometric deformable models,2003,Xiao Han and Chenyang Xu and Jerry L.  Prince,25,IEEE Transactions on Pattern Analysis and Machine Intelligence,6,755-768,IEEE,Active contour and surface models. also known as deformable models. are powerful image segmentation techniques. Geometric deformable models implemented using level set methods have advantages over parametric models due to their intrinsic behavior. parameterization independence. and ease of implementation. However. a long claimed advantage of geometric deformable models-the ability to automatically handle topology changes-turns out to be a liability in applications where the object to be segmented has a known topology that must be preserved. We present a new class of geometric deformable models designed using a novel topology-preserving level set method. which achieves topology preservation by applying the simple point concept from digital topology. These new models maintain the other advantages of standard geometric deformable models including subpixel accuracy and production of …,True,XGVV3gEAAAAJ:u5HHmVD_uO8C,597,https://ieeexplore.ieee.org/abstract/document/1201824/,2694231137578301902,/scholar?cites=2694231137578301902,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.7391&rep=rep1&type=pdf,0,0,0
1278843,MRI-derived measurements of human subcortical. ventricular and intracranial brain volumes: reliability effects of scan sessions. acquisition sequences. data analyses. scanner …,2009,Jorge Jovicich and Silvester Czanner and Xiao Han and David Salat and Andre van der Kouwe and Brian Quinn and Jenni Pacheco and Marilyn Albert and Ronald Killiany and Deborah Blacker and Paul Maguire and Diana Rosas and Nikos Makris and Randy Gollub and Anders Dale and Bradford C Dickerson and Bruce Fischl,46,Neuroimage,1,177-192,Academic Press,Automated MRI-derived measurements of in-vivo human brain volumes provide novel insights into normal and abnormal neuroanatomy. but little is known about measurement reliability. Here we assess the impact of image acquisition variables (scan session. MRI sequence. scanner upgrade. vendor and field strengths). FreeSurfer segmentation pre-processing variables (image averaging. B1 field inhomogeneity correction) and segmentation analysis variables (probabilistic atlas) on resultant image segmentation volumes from older (n = 15. mean age 69.5) and younger (both n = 5. mean ages 34 and 36.5) healthy subjects. The variability between hippocampal. thalamic. caudate. putamen. lateral ventricular and total intracranial volume measures across sessions on the same scanner on different days is less than 4.3% for the older group and less than 2.3% for the younger group. Within-scanner measurements are …,True,XGVV3gEAAAAJ:qjMakFHDy7sC,467,https://www.sciencedirect.com/science/article/pii/S1053811909001505,13292084609924481407,/scholar?cites=13292084609924481407,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2866077/,0,0,0
1278844,Evaluation of registration methods on thoracic CT: the EMPIRE10 challenge,2011,Keelin Murphy and Bram Van Ginneken and Joseph M Reinhardt and Sven Kabus and Kai Ding and Xiang Deng and Kunlin Cao and Kaifang Du and Gary E Christensen and Vincent Garcia and Tom Vercauteren and Nicholas Ayache and Olivier Commowick and Grégoire Malandain and Ben Glocker and Nikos Paragios and Nassir Navab and Vladlena Gorbunova and Jon Sporring and Marleen De Bruijne and Xiao Han and Mattias P Heinrich and Julia A Schnabel and Mark Jenkinson and Cristian Lorenz and Marc Modat and Jamie R McClelland and Sébastien Ourselin and Sascha EA Muenzing and Max A Viergever and Dante De Nigris and D Louis Collins and Tal Arbel and Marta Peroni and Rui Li and Gregory C Sharp and Alexander Schmidt-Richberg and Jan Ehrhardt and René Werner and Dirk Smeets and Dirk Loeckx and Gang Song and Nicholas Tustison and Brian Avants and James C Gee and Marius Staring and Stefan Klein and Berend C Stoel and Martin Urschler and Manuel Werlberger and Jef Vandemeulebroucke and Simon Rit and David Sarrut and Josien PW Pluim,30,IEEE transactions on medical imaging,11,1901-1920,IEEE,EMPIRE10 (Evaluation of Methods for Pulmonary Image REgistration 2010) is a public platform for fair and meaningful comparison of registration algorithms which are applied to a database of intra patient thoracic CT image pairs. Evaluation of nonrigid registration techniques is a nontrivial task. This is compounded by the fact that researchers typically test only on their own data. which varies widely. For this reason. reliable assessment and comparison of different registration algorithms has been virtually impossible in the past. In this work we present the results of the launch phase of EMPIRE10. which comprised the comprehensive evaluation and comparison of 20 individual algorithms from leading academic and industrial research groups. All algorithms are applied to the same set of 30 thoracic CT pairs. Algorithm settings and parameters are chosen by researchers expert in the con figuration of their own method …,True,XGVV3gEAAAAJ:sJK75vZXtG0C,422,https://ieeexplore.ieee.org/abstract/document/5782992/,11653185328679959383,/scholar?cites=11653185328679959383,,,https://research.tue.nl/en/publications/evaluation-of-registration-methods-on-thoracic-ct-the-empire10-ch,0,0,0
1278845,MR‐based synthetic CT generation using a deep convolutional neural network method,2017,Xiao Han,44,Medical physics,4,1408-1419,,Interests have been rapidly growing in the field of radiotherapy to replace CT with magnetic resonance imaging (MRI). due to superior soft tissue contrast offered by MRI and the desire to reduce unnecessary radiation dose. MR‐only radiotherapy also simplifies clinical workflow and avoids uncertainties in aligning MR with CT. Methods. however. are needed to derive CT‐equivalent representations. often known as synthetic CT (sCT). from patient MR images for dose calculation and DRR‐based patient positioning. Synthetic CT estimation is also important for PET attenuation correction in hybrid PET‐MR systems. We propose in this work a novel deep convolutional neural network (DCNN) method for sCT generation and evaluate its performance on a set of brain tumor patient images.The proposed method builds upon recent developments of deep learning and convolutional neural networks in …,True,XGVV3gEAAAAJ:DquSII9TDu4C,346,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12155,18335086673331122641,/scholar?cites=18335086673331122641,,,,0,0,0
1278846,Atlas renormalization for improved brain MR image segmentation across scanner platforms,2007,Xiao Han and Bruce Fischl,26,IEEE transactions on medical imaging,4,479-486,IEEE,Atlas-based approaches have demonstrated the ability to automatically identify detailed brain structures from 3-D magnetic resonance (MR) brain images. Unfortunately. the accuracy of this type of method often degrades when processing data acquired on a different scanner platform or pulse sequence than the data used for the atlas training. In this paper. we improve the performance of an atlas-based whole brain segmentation method by introducing an intensity renormalization procedure that automatically adjusts the prior atlas intensity model to new input data. Validation using manually labeled test datasets has shown that the new procedure improves the segmentation accuracy (as measured by the Dice coefficient) by 10% or more for several structures including hippocampus. amygdala. caudate. and pallidum. The results verify that this new procedure reduces the sensitivity of the whole brain segmentation …,True,XGVV3gEAAAAJ:UeHWp8X0CEIC,243,https://ieeexplore.ieee.org/abstract/document/4141193/,15635229412186940486,/scholar?cites=15635229412186940486,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.9260&rep=rep1&type=pdf,0,0,0
1278847,CRUISE: cortical reconstruction using implicit surface evolution,2004,Xiao Han and Dzung L Pham and Duygu Tosun and Maryam E Rettmann and Chenyang Xu and Jerry L Prince,23,NeuroImage,3,997-1012,Academic Press,Segmentation and representation of the human cerebral cortex from magnetic resonance (MR) images play an important role in neuroscience and medicine. A successful segmentation method must be robust to various imaging artifacts and produce anatomically meaningful and consistent cortical representations. A method for the automatic reconstruction of the inner. central. and outer surfaces of the cerebral cortex from T1-weighted MR brain images is presented. The method combines a fuzzy tissue classification method. an efficient topology correction algorithm. and a topology-preserving geometric deformable surface model (TGDM). The algorithm is fast and numerically stable. and yields accurate brain surface reconstructions that are guaranteed to be topologically correct and free from self-intersections. Validation results on real MR data are presented to demonstrate the performance of the method.,True,XGVV3gEAAAAJ:2osOgNQ5qMEC,233,https://www.sciencedirect.com/science/article/pii/S1053811904003611,5097500826499509217,/scholar?cites=5097500826499509217,,,https://www.academia.edu/download/47274892/CRUISE_Cortical_reconstruction_using_imp20160715-11704-1n0f1w6.pdf,0,0,0
1278848,Atlas-based auto-segmentation of head and neck CT images,2008,Xiao Han and Mischa S Hoogeman and Peter C Levendag and Lyndon S Hibbard and David N Teguh and Peter Voet and Andrew C Cowen and Theresa K Wolf,,,,434-441,Springer. Berlin. Heidelberg,Treatment planning for high precision radiotherapy of head and neck (H&N) cancer patients requires accurate delineation of many structures and lymph node regions. Manual contouring is tedious and suffers from large inter- and intra-rater variability. To reduce manual labor. we have developed a fully automated. atlas-based method for H&N CT image segmentation that employs a novel hierarchical atlas registration approach. This registration strategy makes use of object shape information in the atlas to help improve the registration efficiency and robustness while still being able to account for large inter-subject shape differences. Validation results showed that our method provides accurate segmentation for many structures despite difficulties presented by real clinical data. Comparison of two different atlas selection strategies is also reported.,True,XGVV3gEAAAAJ:YsMSGLbcyi4C,178,https://link.springer.com/chapter/10.1007/978-3-540-85990-1_52,2956903042524025997,/scholar?cites=2956903042524025997,,,https://link.springer.com/content/pdf/10.1007/978-3-540-85990-1_52.pdf,0,0,0
1278849,The liver tumor segmentation benchmark (lits),2019,Patrick Bilic and Patrick Ferdinand Christ and Eugene Vorontsov and Grzegorz Chlebus and Hao Chen and Qi Dou and Chi-Wing Fu and Xiao Han and Pheng-Ann Heng and Jürgen Hesser and Samuel Kadoury and Tomasz Konopczynski and Miao Le and Chunming Li and Xiaomeng Li and Jana Lipkovà and John Lowengrub and Hans Meine and Jan Hendrik Moltz and Chris Pal and Marie Piraud and Xiaojuan Qi and Jin Qi and Markus Rempfler and Karsten Roth and Andrea Schenk and Anjany Sekuboyina and Ping Zhou and Christian Hülsemeyer and Marcel Beetz and Florian Ettlinger and Felix Grün and Georgios Kaissis and Fabian Lohöfer and Rickmer Braren and Julian Holch and Felix Hofmann and Wieland Sommer and Volker Heinemann and Colin Jacobs and Gabriel Efrain Humpire Mamani and Bram van Ginneken and Gabriel Chartrand and An Tang and Michal Drozdzal and Avi Ben-Cohen and Eyal Klang and Marianne M Amitai and Eli Konen and Hayit Greenspan and Johan Moreau and Alexandre Hostettler and Luc Soler and Refael Vivanti and Adi Szeskin and Naama Lev-Cohain and Jacob Sosna and Leo Joskowicz and Bjoern H Menze,,arXiv preprint arXiv:1901.04056,,,,In this work. we report the set-up and results of the Liver Tumor Segmentation Benchmark (LITS) organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2016 and International Conference On Medical Image Computing Computer Assisted Intervention (MICCAI) 2017. Twenty four valid state-of-the-art liver and liver tumor segmentation algorithms were applied to a set of 131 computed tomography (CT) volumes with different types of tumor contrast levels (hyper-/hypo-intense). abnormalities in tissues (metastasectomie) size and varying amount of lesions. The submitted algorithms have been tested on 70 undisclosed volumes. The dataset is created in collaboration with seven hospitals and research institutions and manually reviewed by independent three radiologists. We found that not a single algorithm performed best for liver and tumors. The best liver segmentation algorithm achieved a Dice score of 0.96 (MICCAI) whereas for tumor segmentation the best algorithm evaluated at 0.67 (ISBI) and 0.70 (MICCAI). The LITS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.,True,XGVV3gEAAAAJ:tgTmbKTkO1IC,174,https://arxiv.org/abs/1901.04056,10996095861110041445,/scholar?cites=10996095861110041445,,,https://arxiv.org/pdf/1901.04056,0,0,0
1278850,Automated sulcal segmentation using watersheds on the cortical surface,2002,Maryam E Rettmann and Xiao Han and Chenyang Xu and Jerry L Prince,15,NeuroImage,2,329-344,Academic Press,The human cortical surface is a highly complex. folded structure. Sulci. the spaces between the folds. define location on the cortex and provide a parcellation into anatomically distinct areas. A topic that has recently received increased attention is the segmentation of these sulci from magnetic resonance images. with most work focusing on extracting either the sulcal spaces between the folds or curve representations of sulci. Unlike these methods. we propose a technique that extracts actual regions of the cortical surface that surround sulci. which we call “sulcal regions.” The method is based on a watershed algorithm applied to a geodesic depth measure on the cortical surface. A well-known problem with the watershed algorithm is a tendency toward oversegmentation. meaning that a single region is segmented as several pieces. To address this problem. we propose a postprocessing algorithm that merges …,True,XGVV3gEAAAAJ:9yKSN-GCB0IC,170,https://www.sciencedirect.com/science/article/pii/S1053811901909759,1870539711147688870,/scholar?cites=1870539711147688870,,,https://www.academia.edu/download/48280681/Automated_Sulcal_Segmentation_Using_Wate20160824-7334-1hzjdyh.pdf,0,0,0
1278851,Algorithm-enabled low-dose micro-CT imaging,2010,Xiao Han and Junguo Bian and Diane R Eaker and Timothy L Kline and Emil Y Sidky and Erik L Ritman and Xiaochuan Pan,30,IEEE transactions on medical imaging,3,606-620,IEEE,Micro-computed tomography (micro-CT) is an important tool in biomedical research and preclinical applications that can provide visual inspection of and quantitative information about imaged small animals and biological samples such as vasculature specimens. Currently. micro-CT imaging uses projection data acquired at a large number (300-1000) of views. which can limit system throughput and potentially degrade image quality due to radiation-induced deformation or damage to the small animal or specimen. In this work. we have investigated low-dose micro-CT and its application to specimen imaging from substantially reduced projection data by using a recently developed algorithm. referred to as the adaptive-steepest-descent-projection-onto-convex-sets (ASD-POCS) algorithm. which reconstructs an image through minimizing the image total-variation and enforcing data constraints. To validate and evaluate …,True,XGVV3gEAAAAJ:eAUscmXIlQ8C,159,https://ieeexplore.ieee.org/abstract/document/5609203/,1098248028757521042,/scholar?cites=1098248028757521042,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3645946/,0,0,0
1278852,Blood vessel segmentation methodologies in retinal images–a survey,2012,Muhammad Moazam Fraz and Paolo Remagnino and Andreas Hoppe and Bunyarit Uyyanonvara and Alicja R Rudnicka and Christopher G Owen and Sarah A Barman,108,,1,407-433,Elsevier,Retinal vessel segmentation algorithms are a fundamental component of automatic retinal disease screening systems. This work examines the blood vessel segmentation methodologies in two dimensional retinal images acquired from a fundus camera and a survey of techniques is presented. The aim of this paper is to review. analyze and categorize the retinal vessel extraction algorithms. techniques and methodologies. giving a brief description. highlighting the key points and the performance measures. We intend to give the reader a framework for the existing research; to introduce the range of retinal vessel segmentation algorithms; to discuss the current trends and future directions and summarize the open problems. The performance of algorithms is compared and analyzed on two publicly available databases (DRIVE and STARE) of retinal images using a number of measures which include accuracy. true …,True,8ub2nBgAAAAJ:MXK_kJrjxJIC,902,https://www.sciencedirect.com/science/article/pii/S0169260712000843,15709230708925200737,/scholar?cites=15709230708925200737,,,https://onlinemedicalimages.com/images/medical/publications/8.%20Blood%20vessel%20segmentation%20methodologies.pdf,0,0,0
1278853,An ensemble classification-based approach applied to retinal blood vessel segmentation,2012,Muhammad Moazam Fraz and Paolo Remagnino and Andreas Hoppe and Bunyarit Uyyanonvara and Alicja R Rudnicka and Christopher G Owen and Sarah A Barman,59,IEEE Transactions on Biomedical Engineering,9,2538-2548,IEEE,This paper presents a new supervised method for segmentation of blood vessels in retinal photographs. This method uses an ensemble system of bagged and boosted decision trees and utilizes a feature vector based on the orientation analysis of gradient vector field. morphological transformation. line strength measures. and Gabor filter responses. The feature vector encodes information to handle the healthy as well as the pathological retinal image. The method is evaluated on the publicly available DRIVE and STARE databases. frequently used for this purpose and also on a new public retinal vessel reference dataset CHASE_DB1 which is a subset of retinal images of multiethnic children from the Child Heart and Health Study in England (CHASE) dataset. The performance of the ensemble system is evaluated in detail and the incurred accuracy. speed. robustness. and simplicity make the algorithm a suitable …,True,8ub2nBgAAAAJ:hFOr9nPyWt4C,548,https://ieeexplore.ieee.org/abstract/document/6224174/,15194577552318495739,/scholar?cites=15194577552318495739,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.705.1497&rep=rep1&type=pdf,0,0,0
1278854,Automatic detection of diabetic retinopathy exudates from non-dilated retinal images using mathematical morphology methods,2008,Akara Sopharak and Bunyarit Uyyanonvara and Sarah Barman and Thomas H Williamson,32,Computerized medical imaging and graphics,8,720-727,Pergamon,Diabetic retinopathy is a complication of diabetes that is caused by changes in the blood vessels of the retina. The symptoms can blur or distort the patient’s vision and are a main cause of blindness. Exudates are one of the primary signs of diabetic retinopathy. Detection of exudates by ophthalmologists normally requires pupil dilation using a chemical solution which takes time and affects patients. This paper investigates and proposes a set of optimally adjusted morphological operators to be used for exudate detection on diabetic retinopathy patients’ non-dilated pupil and low-contrast images. These automatically detected exudates are validated by comparing with expert ophthalmologists’ hand-drawn ground-truths. The results are successful and the sensitivity and specificity for our exudate detection is 80% and 99.5%. respectively.,True,8ub2nBgAAAAJ:2osOgNQ5qMEC,482,https://www.sciencedirect.com/science/article/pii/S0895611108000931,494085987081925404,/scholar?cites=494085987081925404,,,http://www2.siit.tu.ac.th/bunyarit/publications/2008_ExudateMorphCMIG.pdf,0,0,0
1278855,Relationship between intraocular lens biomaterials and posterior capsule opacification,1998,Paul G Ursell and David J Spalton and Milind V Pande and Emma J Hollick and Sarah Barman and James Boyce and Kate Tilling,24,Journal of Cataract & Refractive Surgery,3,352-360,No longer published by Elsevier,Purpose: To determine whether posterior capsule opacification (PCO) is influenced by intraocular lens (IOL) material.Setting: A British teaching hospital eye department.Methods: Ninety eyes were prospectively randomized to receive a poly(methyl methacrylate) (PMMA). silicone. or AcrySof® IOL. All lenses had 6.0 mm optics and PMMA haptics. A standardized surgical protocol was performed by a single surgeon using an extracapsular technique with capsulorhexis. Patients having surgical complications were excluded. and all patients had standardized medication and follow-up. Posterior capsule opacification was assessed by a digital retroillumination camera using a dedicated software program based on the analysis of texture in the image and calculated as the percentage area of opacified capsule. Data were analyzed 2 years postoperatively.Results: There was a significant difference in percentage of PCO at 2 …,True,8ub2nBgAAAAJ:u5HHmVD_uO8C,445,https://www.sciencedirect.com/science/article/pii/S0886335098803234,6068465112723870722,/scholar?cites=6068465112723870722,,,,0,0,0
1278856,The effect of polymethylmethacrylate. silicone. and polyacrylic intraocular lenses on posterior capsular opacification 3 years after cataract surgery,1999,Emma J Hollick and David J Spalton and Paul G Ursell and Milind V Pande and Sarah A Barman and James F Boyce and Kate Tilling,106,Ophthalmology,1,49-55,Elsevier,To compare the visual outcome. neodymium:YAG (Nd:YAG) capsulotomy rates. and percentage of posterior capsular opacification (PCO) seen with polymethylmethacrylate (PMMA). silicone. and polyacrylic intraocular lens implants 3 years after surgery.Randomized. prospective trial.Ninety eyes of 81 patients were examined at a British teaching hospital.Ninety eyes were prospectively randomized to receive a PMMA. silicone. or polyacrylic (AcrySof. Alcon. Fort Worth. TX) implant. All lenses had 6-mm disc optics with PMMA haptics. A standardized surgical protocol was performed by a single surgeon using an extracapsular technique with capsulorhexis; any surgical complications were excluded and all patients had standardized postoperative medication and follow-up.Patients were seen at 6 months and 1. 2. and 3 years after surgery. At 3 years …,True,8ub2nBgAAAAJ:u-x6o8ySG0sC,440,https://www.sciencedirect.com/science/article/pii/S0161642099900477,1636023098406114142,/scholar?cites=1636023098406114142,,,,0,0,0
1278857,An approach to localize the retinal blood vessels using bit planes and centerline detection,2012,Muhammad Moazam Fraz and Sarah A Barman and Paolo Remagnino and Andreas Hoppe and Abdul Basit and Bunyarit Uyyanonvara and Alicja R Rudnicka and Christopher G Owen,108,Computer methods and programs in biomedicine,2,600-616,Elsevier,The change in morphology. diameter. branching pattern or tortuosity of retinal blood vessels is an important indicator of various clinical disorders of the eye and the body. This paper reports an automated method for segmentation of blood vessels in retinal images. A unique combination of techniques for vessel centerlines detection and morphological bit plane slicing is presented to extract the blood vessel tree from the retinal images. The centerlines are extracted by using the first order derivative of a Gaussian filter in four orientations and then evaluation of derivative signs and average derivative values is performed. Mathematical morphology has emerged as a proficient technique for quantifying the blood vessels in the retina. The shape and orientation map of blood vessels is obtained by applying a multidirectional morphological top-hat operator with a linear structuring element followed by bit plane slicing of the …,True,8ub2nBgAAAAJ:roLk4NBRz8UC,324,https://www.sciencedirect.com/science/article/pii/S0169260711002276,5801320269002291623,/scholar?cites=5801320269002291623,,,http://www2.siit.tu.ac.th/bunyarit/publications/2012_Moazam_Elsevier_bitplanes.pdf,0,0,0
1278858,Automatic exudate detection from non-dilated diabetic retinopathy retinal images using fuzzy c-means clustering,2009,Akara Sopharak and Bunyarit Uyyanonvara and Sarah Barman,9,sensors,3,2148-2161,Molecular Diversity Preservation International,Exudates are the primary sign of Diabetic Retinopathy. Early detection can potentially reduce the risk of blindness. An automatic method to detect exudates from low-contrast digital images of retinopathy patients with non-dilated pupils using a Fuzzy C-Means (FCM) clustering is proposed. Contrast enhancement preprocessing is applied before four features. namely intensity. standard deviation on intensity. hue and a number of edge pixels. are extracted to supply as input parameters to coarse segmentation using FCM clustering method. The first result is then fine-tuned with morphological techniques. The detection results are validated by comparing with expert ophthalmologists’ hand-drawn ground-truths. Sensitivity. specificity. positive predictive value (PPV). positive likelihood ratio (PLR) and accuracy are used to evaluate overall performance. It is found that the proposed method detects exudates successfully with sensitivity. specificity. PPV. PLR and accuracy of 87.28%. 99.24%. 42.77%. 224.26 and 99.11%. respectively. View Full-Text,True,8ub2nBgAAAAJ:IjCSPb-OGe4C,268,https://www.mdpi.com/1424-8220/9/3/2148,15749232704175038195,/scholar?cites=15749232704175038195,,,https://www.mdpi.com/1424-8220/9/3/2148/pdf,0,0,0
1278859,A review of ant algorithms,2009,Robert J Mullen and Dorothy Monekosso and Sarah Barman and Paolo Remagnino,36,,6,9608-9617,Pergamon,Ant algorithms are optimisation algorithms inspired by the foraging behaviour of real ants in the wild. Introduced in the early 1990s. ant algorithms aim at finding approximate solutions to optimisation problems through the use of artificial ants and their indirect communication via synthetic pheromones. The first ant algorithms and their development into the Ant Colony Optimisation (ACO) metaheuristic is described herein. An overview of past and present typical applications as well as more specialised and novel applications is given. The use of ant algorithms alongside more traditional machine learning techniques to produce robust. hybrid. optimisation algorithms is addressed. with a look towards future developments in this area of study.,True,8ub2nBgAAAAJ:d1gkVwhDpl0C,259,https://www.sciencedirect.com/science/article/pii/S0957417409000384,6290810243286487191,/scholar?cites=6290810243286487191,,,,0,0,0
1278860,Measuring retinal vessel tortuosity in 10-year-old children: validation of the computer-assisted image analysis of the retina (CAIAR) program,2009,Christopher G Owen and Alicja R Rudnicka and Robert Mullen and Sarah A Barman and Dorothy Monekosso and Peter H Whincup and Jeffrey Ng and Carl Paterson,50,Investigative ophthalmology & visual science,5,2004-2010,The Association for Research in Vision and Ophthalmology,purpose. To examine the agreement of a novel computer program measuring retinal vessel tortuosity with subjective assessment of tortuosity in school-aged children.methods. Cross-sectional study of 387 retinal vessels (193 arterioles. 194 veins) from 28 eyes of 14 children (aged 10 years). Retinal digital images were analyzed using the Computer Assisted Image Analysis of the Retina (CAIAR) program. including 14 measures of tortuosity. Vessels were graded (from 0= none; to 5= tortuous) independently by two observers. Interobserver agreement was assessed by using κ statistics. Agreement with all 14 objective measures was assessed with correlation/regression analyses. Intersession repeatability (comparing morning and afternoon sessions) of tortuosity indices was calculated.results. Interobserver agreement of vessel tortuosity within one grade was high (κ= 0.97). with total agreement in 56% of grades and 42% differing by±1 grade. Tortuosity indices based on subdivided chord length methods showed strong log-linear associations with agreed subjective grades (typically r> 0.6; P< 0.001). An approach that averages the distance from the vessel to chord length along the length of the vessel showed best agreement (r= 0.8; P< 0.0001). Tortuosity measures based on curvature performed less well. Intersession repeatability of the vessel to chord technique was good. differing by values equivalent to< 1 in subjective grade.conclusions. Tortuosity indices based on changes in subdivided chord lengths showed optimal agreement with subjective assessment. The relation of these indices to ethnicity and cardiovascular risk factors in childhood …,True,8ub2nBgAAAAJ:Y0pCki6q_DkC,167,https://jov.arvojournals.org/article.aspx?articleid=2126623,18248310613101191474,/scholar?cites=18248310613101191474,,,https://jov.arvojournals.org/article.aspx?articleid=2126623,0,0,0
1278861,Simple hybrid method for fine microaneurysm detection from non-dilated diabetic retinopathy retinal images,2013,Akara Sopharak and Bunyarit Uyyanonvara and Sarah Barman,37,Computerized Medical Imaging and Graphics,5-6,394-402,Pergamon,Microaneurysms detection is an important task in computer aided diagnosis of diabetic retinopathy. Microaneurysms are the first clinical sign of diabetic retinopathy. a major cause of vision loss in diabetic patients. Early microaneurysm detection can help reduce the incidence of blindness. Automatic detection of microaneurysms is still an open problem due to their tiny sizes. low contrast and also similarity with blood vessels. It is particularly very difficult to detect fine microaneurysms. especially from non-dilated pupils and that is the goal of this paper. Simple yet effective methods are used. They are coarse segmentation using mathematic morphology and fine segmentation using naive Bayes classifier. A total of 18 microaneurysms features are proposed in this paper and they are extracted for naive Bayes classifier. The detected microaneurysms are validated by comparing at pixel level with ophthalmologists’ hand …,True,8ub2nBgAAAAJ:O3NaXMp0MMsC,149,https://www.sciencedirect.com/science/article/pii/S0895611113001006,11531038602323984102,/scholar?cites=11531038602323984102,,,http://onlinemedicalimages.com/images/medical/publications/12.%20Simple%20hybrid%20method%20for%20fine%20microaneurysm%20detection%20fromnon-dilated%20diabetic%20retinopathy%20retinal%20images.pdf,0,0,0
1278862,Shape and texture based plant leaf classification,2010,Thibaut Beghin and James S Cope and Paolo Remagnino and Sarah Barman,,,,345-353,Springer. Berlin. Heidelberg,This article presents a novel method for classification of plants using their leaves. Most plant species have unique leaves which differ from each other by characteristics such as the shape. colour. texture and the margin. The method introduced in this study proposes to use two of these features: the shape and the texture. The shape-based method will extract the contour signature from every leaf and then calculate the dissimilarities between them using the Jeffrey-divergence measure. The orientations of edge gradients will be used to analyse the macro-texture of the leaf. The results of these methods will then be combined using an incremental classification algorithm.,True,8ub2nBgAAAAJ:8k81kl-MbHgC,146,https://link.springer.com/chapter/10.1007/978-3-642-17691-3_32,13096270052935766995,/scholar?cites=13096270052935766995,,,http://www.computing.surrey.ac.uk/morphidas/papers/acivs2010_Beghin.pdf,0,0,0
1278863,Cardiovascular function in multi-ethnic study of atherosclerosis: normal values by age. sex. and ethnicity,2006,Shunsuke Natori and Shenghan Lai and J Paul Finn and Antoinette S Gomes and W Gregory Hundley and Michael Jerosch-Herold and Gregory Pearson and Shantanu Sinha and Andrew Arai and Joao AC Lima and David A Bluemke,186,American Journal of Roentgenology,6_supplement_2,S357-S365,American Roentgen Ray Society,OBJECTIVE. MRI provides accurate and high-resolution measurements of cardiac anatomy and function. The purpose of this study was to describe the imaging protocol and normal values of left ventricular (LV) function and mass in the Multi-Ethnic Study of Atherosclerosis (MESA).SUBJECTS AND METHODS. Eight hundred participants (400 men. 400 women) in four age strata (45–54. 55–64. 65–74. 75–84 years) were chosen at random. Participants with the following known cardiovascular risk factors were excluded: current smoker. systolic blood pressure > 140 mm Hg. diastolic blood pressure > 90 mm Hg. fasting glucose > 110 mg/dL. total cholesterol > 240 mg/dL. and high-density lipoprotein (HDL) cholesterol < 40 mg/dL. Cardiac MR images were analyzed using MASS software (version 4.2). Mean values. SDs. and correlation coefficients in relationship to patient age were calculated.RESULTS. There were …,True,_Vp-c_AAAAAJ:u-x6o8ySG0sC,429,https://www.ajronline.org/doi/abs/10.2214/AJR.04.1868,8192397561922619275,/scholar?cites=8192397561922619275,,,https://www.ajronline.org/doi/pdfplus/10.2214/AJR.04.1868,0,0,0
1278864,In vivo diffusion‐weighted MRI of the breast: potential for lesion characterization,2002,Shantanu Sinha and Flora Anne Lucas‐Quesada and Usha Sinha and Nanette DeBruhl and Lawrence W Bassett,15,Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine,6,693-704,Wiley Subscription Services. Inc.. A Wiley Company,To investigate the potential of apparent diffusion coefficients (ADCs) in characterizing breast lesions in vivo.Two diffusion‐weighted (DW) sequences were implemented on a 1.5 Tesla scanner. with low b‐value orthogonal and high b‐value tetrahedral sensitized sequences. The orthogonal sequence was evaluated on 16 normal volunteers and 23 patients with known lesion types (six benign and 17 malignant). The tetrahedral sequence was evaluated on a smaller number of subjects: two normal. two malignant. and two benign.The mean value of the ADC of the malignant tumors was reduced compared to that of the benign lesions and normal tissue. This finding was related to the increased cellularity of the malignant lesions. The ADC values were elevated for all tissue types with the low b‐value sequence as compared to the high b‐value sequence. indicating …,True,_Vp-c_AAAAAJ:u5HHmVD_uO8C,396,https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.10116,17861187811777333122,/scholar?cites=17861187811777333122,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.10116,0,0,0
1278865,Long-range incommensurate magnetic order in a Dy-Y multilayer,1986,MB Salamon and Shantanu Sinha and JJ Rhyne and JE Cunningham and Ross W Erwin and Julie Borchers and CP Flynn,56,Physical review letters,3,259,American Physical Society,A multilayer sample of Dy (47 Å)/Y (40 Å). produced by molecular-beam-epitaxy techniques. is shown to order magnetically in an incommensurate helix that is coherent over several multilayer periods. The magnetic satellite peak has harmonics resulting from the multilayer modulation. The dc magnetic properties are suggestive of a metamagnet.,True,_Vp-c_AAAAAJ:JoZmwDi-zQgC,348,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.56.259,11180247985871470474,/scholar?cites=11180247985871470474,,,,0,0,0
1278866,Nonuniform strain of human soleus aponeurosis-tendon complex during submaximal voluntary contractions in vivo,2003,Taija Finni and John A Hodgson and Alex M Lai and V Reggie Edgerton and Shantanu Sinha,95,Journal of applied physiology,2,829-837,American Physiological Society,The distribution of strain along the soleus aponeurosis tendon was examined  during voluntary contractions in vivo. Eight subjects performed cyclic  isometric contractions (20 and 40% of maximal voluntary contraction).  Displacement and strain in the apparent Achilles tendon and in the aponeurosis  were calculated from cine phase-contrast magnetic resonance images acquired  with a field of view of 32 cm. The apparent Achilles tendon lengthened 2.8 and  4.7% in 20 and 40% maximal voluntary contraction. respectively. The midregion  of the aponeurosis. below the gastrocnemius insertion. lengthened 1.2 and  2.2%. but the distal aponeurosis shortened 2.1 and 2.5%. respectively. There  was considerable variation in the three-dimensional anatomy of the aponeurosis  and muscle-tendon junction. We suggest that the nonuniformity in aponeurosis  strain within an individual was due to the presence of active and …,True,_Vp-c_AAAAAJ:9yKSN-GCB0IC,202,https://journals.physiology.org/doi/abs/10.1152/japplphysiol.00775.2002,282165402450065603,/scholar?cites=282165402450065603,,,https://journals.physiology.org/doi/full/10.1152/japplphysiol.00775.2002,0,0,0
1278867,Generalized zero-and few-shot learning via aligned variational autoencoders,2019,Edgar Schonfeld and Sayna Ebrahimi and Samarth Sinha and Trevor Darrell and Zeynep Akata,,,,8247-8255,,Many approaches in generalized zero-shot learning rely on cross-modal mapping between the image feature space and the class embedding space. As labeled images are expensive. one direction is to augment the dataset by generating either images or image features. However. the former misses fine-grained details and the latter requires learning a mapping associated with class embeddings. In this work. we take feature generation one step further and propose a model where a shared latent space of image features and class embeddings is learned by modality-specific aligned variational autoencoders. This leaves us with the required discriminative information about the image and classes in the latent features. on which we train a softmax classifier. The key to our approach is that we align the distributions learned from images and from side-information to construct latent features that contain the essential multi-modal information associated with unseen classes. We evaluate our learned latent features on several benchmark datasets. ie CUB. SUN. AWA1 and AWA2. and establish a new state of the art on generalized zero-shot as well as on few-shot learning. Moreover. our results on ImageNet with various zero-shot splits show that our latent features generalize well in large-scale settings.,True,_Vp-c_AAAAAJ:sJsF-0ZLhtgC,194,http://openaccess.thecvf.com/content_CVPR_2019/html/Schonfeld_Generalized_Zero-_and_Few-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPR_2019_paper.html,16257929561947367613,/scholar?cites=16257929561947367613,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Schonfeld_Generalized_Zero-_and_Few-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPR_2019_paper.pdf,0,0,0
1278868,Magnetic structure of Dy-Y superlattices,1987,Ross W Erwin and JJ Rhyne and MB Salamon and J Borchers and Shantanu Sinha and R Du and JE Cunningham and CP Flynn,35,Physical Review B,13,6808,American Physical Society,Two samples of Dy-Y superlattices produced by molecular-beam-epitaxy techniques are shown by neutron diffraction to order magnetically in a helix which is incommensurate with the bilayer thickness. One sample consists of 64 bilayers. each bilayer made up of about 15 growth planes (42 Å) of Dy atoms followed by 14 planes (38 Å) of Y atoms. The second sample has 90 layers. each layer consisting of 9 Dy atomic planes and 8 Dy 0.5 Y 0.5 alloy planes. The phase coherence of this ordering extends over several bilayers. and is especially striking in the sample where the layers of localized Dy spins are separated by 14 atomic planes of nonmagnetic Y. The fact that the helix chirality propagates across several bilayers rules out a simple scalar Ruderman-Kittel-Kasuya-Yosida coupling between the Dy planes on either side of an Y layer. but suggests instead that a helical spin density wave is induced in the Y …,True,_Vp-c_AAAAAJ:dTyEYWd-f8wC,189,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.35.6808,9941780490342502245,/scholar?cites=9941780490342502245,,,,0,0,0
1278869,Left ventricular concentric remodeling is associated with decreased global and regional systolic function: the Multi-Ethnic Study of Atherosclerosis,2005,Boaz D Rosen and Thor Edvardsen and Shenghan Lai and Ernesto Castillo and Li Pan and Michael Jerosch-Herold and Shantanu Sinha and Richard Kronmal and Donna Arnett and John R Crouse III and Susan R Heckbert and David A Bluemke and Joao AC Lima,112,Circulation,7,984-991,Lippincott Williams & Wilkins,Background— The transition from compensatory concentric remodeling to myocardial failure is not completely understood in humans. To investigate determinants of incipient myocardial dysfunction. we examined the association between concentric remodeling and regional LV function in asymptomatic participants of the Multi-Ethnic Study of Atherosclerosis (MESA).Methods and Results— Myocardial tagged MRI was performed. Regional myocardial function expressed as peak systolic midwall circumferential strain (Ecc) was analyzed in 441 consecutive studies by HARP (Harmonic Phase) tool. Peak Ecc was correlated with the extent of concentric remodeling determined by the ratio of left ventricular mass to end-diastolic volume (M/V ratio). In men. a gradual decline in peak global Ecc was seen with increasing M/V ratio (test for trend. P<0.001). Among women. however. Ecc tended to be lower only in the fifth …,True,_Vp-c_AAAAAJ:2osOgNQ5qMEC,185,https://www.ahajournals.org/doi/abs/10.1161/circulationaha.104.500488,8797007179707842746,/scholar?cites=8797007179707842746,,,https://www.ahajournals.org/doi/full/10.1161/circulationaha.104.500488,0,0,0
1278870,In vivo diffusion tensor imaging of the human calf muscle,2006,Shantanu Sinha and Usha Sinha and V Reggie Edgerton,24,Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine,1,182-190,Wiley Subscription Services. Inc.. A Wiley Company,To demonstrate the feasibility of in vivo calf muscle fiber tracking in human subjects.An EPI‐based diffusion tensor imaging (DTI) sequence with six‐direction diffusion gradient sensitization was implemented. and DT images were acquired at 3 Tesla on five subjects using an extremity coil. The mean diffusivity. fractional anisotropy (FA). and fiber angle (with respect to the magnet z‐axis) were measured in different muscles. and fibers were tracked from several regions of interest (ROIs).The fiber orientations in the current DTI studies agree well with those determined in previous spectroscopic studies. The orientation angles ranged from 13.4° in the lateral gastrocnemius to 48.5° in the medial soleus. The diffusion ellipsoid in muscle tissue is anisotropic and approximates a prolate model. as shown by color maps of the anisotropy. Fibers were tracked from the different …,True,_Vp-c_AAAAAJ:UeHWp8X0CEIC,178,https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.20593,3130017677276961122,/scholar?cites=3130017677276961122,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.20593,0,0,0
1278871,Silicone breast implants in vivo: MR imaging.,1992,DP Gorczyca and S Sinha and CY Ahn and ND DeBruhl and MK Hayes and VR Gausche and WW Shaw and LW Bassett,185,Radiology,2,407-410,,This study was designed to evaluate pulse sequences and patient positioning for MR imaging of silicone breast implants in patients. One hundred forty-three patients (281 silicone implants) underwent imaging over a 21-month period. The combination of a T2-weighted fast spin echo technique (SE). T2-weighted fast SE with water suppression. and T1-weighted SE with fat suppression is recommended to reliably differentiate silicone from other breast tissues and to identify intracapsular and extracapsular ruptures or leaks. Seventy of the 143 patients underwent removal of their silicone implants. The sensitivity for detection of silicone implant rupture was 76%. with a specificity of 97%. Positioning the patient prone improved image quality.,True,_Vp-c_AAAAAJ:d1gkVwhDpl0C,178,https://pubs.rsna.org/doi/abs/10.1148/radiology.185.2.1410346,17712728349881810170,/scholar?cites=17712728349881810170,,,https://www.researchgate.net/profile/Mary_Hayes6/publication/21746061_Silicone_breast_implants_in_vivo_MR_imaging/links/590f40deaca2722d186049ad/Silicone-breast-implants-in-vivo-MR-imaging.pdf,0,0,0
1278872,Risk factor associations with the presence of a lipid core in carotid plaque of asymptomatic individuals using high-resolution MRI: the multi-ethnic study of atherosclerosis (MESA),2008,Bruce A Wasserman and A Richey Sharrett and Shenghan Lai and Antoinette S Gomes and Mary Cushman and Aaron R Folsom and Diane E Bild and Richard A Kronmal and Shantanu Sinha and David A Bluemke,39,Stroke,2,329-335,Lippincott Williams & Wilkins,Background and Purpose— Atheroma vulnerability to rupture is increased in the presence of a large lipid core. Factors associated with a lipid core in the general population have not been studied.Methods— The Multi-Ethnic Study of Atherosclerosis (MESA) is a multicenter cohort study of individuals free of clinical cardiovascular disease designed to include a high proportion of ethnic minorities. We selected MESA participants from the top 15th percentile of maximum carotid intima media thickness by ultrasound and acquired high-resolution black blood MRI images through their carotid plaque before and after the intravenous administration of gadodiamide (0.1 mmol/kg). Lumen and outer wall contours were defined using semiautomated analysis software. We analyzed only plaques with a maximum thickness ≥1.5 mm by MRI (n=214) and assessed cross-sectional risk factor associations with lipid core presence …,True,_Vp-c_AAAAAJ:Tyk-4Ss8FVUC,163,https://www.ahajournals.org/doi/abs/10.1161/strokeaha.107.498634,10093194680488430788,/scholar?cites=10093194680488430788,,,https://www.ahajournals.org/doi/full/10.1161/strokeaha.107.498634,0,0,0
1278873,Effect of field strength on susceptibility artifacts in magnetic resonance imaging,1990,Keyvan Farahani and Usha Sinha and Shantanu Sinha and Lee CL Chiu and Robert B Lufkin,14,Computerized Medical Imaging and Graphics,6,409-413,Pergamon,In magnetic resonance imaging susceptibility artifacts occur at the interface of substances with large magnetic susceptibility differences. resulting in geometric distortions of the image at those boundaries. The susceptibility artifacts are often subtle on clinical images and if not carefully examined they may lead to misdiagnosis. Magnetic susceptibility artifacts are prevalent on the boundary of air-containing paranasal sinuses. as well as bone-soft tissue interfaces in the spinal canal. The appearance of these artifacts on images from three different magnetic field strength instruments. 0.3. 0.5. and 1.5 Tesla were studied. T1- and T2-weighted spin echo and gradient recalled echo pulse sequences were selected to image a water phantom containing substances of varying susceptibilities. The effects were also studied in MR images of the head in a normal human volunteer. At any given field strength the artifacts were more …,True,_Vp-c_AAAAAJ:Y0pCki6q_DkC,140,https://www.sciencedirect.com/science/article/pii/089561119090040I,3590933454026806415,/scholar?cites=3590933454026806415,,,,0,0,0
1278874,Robust stochastic approximation approach to stochastic programming,2009,Arkadi Nemirovski and Anatoli Juditsky and Guanghui Lan and Alexander Shapiro,19,SIAM Journal on optimization,4,1574-1609,Society for Industrial and Applied Mathematics,In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques. namely. the stochastic approximation (SA) and the sample average approximation (SAA) methods. Both approaches. the SA and SAA methods. have a long history. Current opinion is that the SAA method can efficiently use a specific (say. linear) structure of the considered problem. while the SA approach is a crude subgradient method. which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class …,True,l3SflUcAAAAJ:u5HHmVD_uO8C,1831,https://epubs.siam.org/doi/abs/10.1137/070704277,4641429982562256044,/scholar?cites=4641429982562256044,,,http://people.eecs.berkeley.edu/~brecht/cs294docs/week1/09.Nemirovski.pdf,0,0,0
1278875,Stochastic first-and zeroth-order methods for nonconvex stochastic programming,2013,Saeed Ghadimi and Guanghui Lan,23,SIAM Journal on Optimization,4,2341-2368,Society for Industrial and Applied Mathematics,In this paper. we introduce a new stochastic approximation type algorithm. namely. the randomized stochastic gradient (RSG) method. for solving an important class of nonlinear (possibly nonconvex) stochastic programming problems. We establish the complexity of this method for computing an approximate stationary point of a nonlinear programming problem. We also show that this method possesses a nearly optimal rate of convergence if the problem is convex. We discuss a variant of the algorithm which consists of applying a postoptimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method. and we show that such modification allows us to improve significantly the large-deviation properties of the algorithm. These methods are then specialized for solving a class of simulation-based optimization problems in which only stochastic zeroth-order information is …,True,l3SflUcAAAAJ:5nxA0vEk-isC,757,https://epubs.siam.org/doi/abs/10.1137/120880811,7610916341219746414,/scholar?cites=7610916341219746414,,,https://arxiv.org/pdf/1309.5549,0,0,0
1278876,An optimal method for stochastic composite optimization,2012,Guanghui Lan,133,Mathematical Programming,1,365-397,Springer-Verlag,This paper considers an important class of convex programming (CP) problems. namely. the stochastic composite optimization (SCO). whose objective function is given by the summation of general nonsmooth and smooth stochastic components. Since SCO covers non-smooth. smooth and stochastic CP as certain special cases. a valid lower bound on the rate of convergence for solving these problems is known from the classic complexity theory of convex programming. Note however that the optimization algorithms that can achieve this lower bound had never been developed. In this paper. we show that the simple mirror-descent stochastic approximation method exhibits the best-known rate of convergence for solving these problems. Our major contribution is to introduce the accelerated stochastic approximation (AC-SA) algorithm based on Nesterov’s optimal method for smooth CP (Nesterov in Doklady …,True,l3SflUcAAAAJ:d1gkVwhDpl0C,418,https://link.springer.com/article/10.1007/s10107-010-0434-y,8729110658260039250,/scholar?cites=8729110658260039250,,,http://sites.gatech.edu/guanghui-lan/wp-content/uploads/sites/330/2016/02/OPT_SA_MPNov02.pdf,0,0,0
1278877,Accelerated gradient methods for nonconvex nonlinear and stochastic programming,2016,Saeed Ghadimi and Guanghui Lan,156,Mathematical Programming,1-2,59-99,Springer Berlin Heidelberg,In this paper. we generalize the well-known Nesterov’s accelerated gradient (AG) method. originally designed for convex smooth optimization. to solve nonconvex and possibly stochastic optimization problems. We demonstrate that by properly specifying the stepsize policy. the AG method exhibits the best known rate of convergence for solving general nonconvex smooth optimization problems by using first-order information. similarly to the gradient descent method. We then consider an important class of composite optimization problems and show that the AG method can solve them uniformly. i.e.. by using the same aggressive stepsize policy as in the convex case. even if the problem turns out to be nonconvex. We demonstrate that the AG method exhibits an optimal rate of convergence if the composite problem is convex. and improves the best known rate of convergence if the problem is nonconvex …,True,l3SflUcAAAAJ:qxL8FJ1GzNcC,416,https://link.springer.com/content/pdf/10.1007/s10107-015-0871-8.pdf,9956780273077643017,/scholar?cites=9956780273077643017,,,https://arxiv.org/pdf/1310.3787,0,0,0
1278878,Optimal Stochastic Approximation Algorithms for Strongly Convex Stochastic Composite Optimization. I: a Generic Algorithmic Framework,,Saeed Ghadimi and Guanghui Lan,,,,,,,True,l3SflUcAAAAJ:Se3iqnhoufwC,263,,7161098967713856135,/scholar?cites=7161098967713856135,,,,0,0,0
1278879,Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization,2016,Saeed Ghadimi and Guanghui Lan and Hongchao Zhang,155,Mathematical Programming,1-2,267-305,Springer Berlin Heidelberg,This paper considers a class of constrained stochastic composite optimization problems whose objective function is given by the summation of a differentiable (possibly nonconvex) component. together with a certain non-differentiable (but convex) component. In order to solve these problems. we propose a randomized stochastic projected gradient (RSPG) algorithm. in which proper mini-batch of samples are taken at each iteration depending on the total budget of stochastic samples allowed. The RSPG algorithm also employs a general distance function to allow taking advantage of the geometry of the feasible region. Complexity of this algorithm is established in a unified setting. which shows nearly optimal complexity of the algorithm for convex stochastic programming. A post-optimization phase is also proposed to significantly reduce the variance of the solutions returned by the algorithm. In addition …,True,l3SflUcAAAAJ:YOwf2qJgpHMC,258,https://link.springer.com/content/pdf/10.1007/s10107-014-0846-1.pdf,7893254839267998233,/scholar?cites=7893254839267998233,,,https://arxiv.org/pdf/1308.6594,0,0,0
1278880,Primal-dual first-order methods with  iteration-complexity for cone programming,2011,Guanghui Lan and Zhaosong Lu and Renato DC Monteiro,126,Mathematical Programming,1,1-29,Springer-Verlag,In this paper we consider the general cone programming problem. and propose primal-dual convex (smooth and/or nonsmooth) minimization reformulations for it. We then discuss first-order methods suitable for solving these reformulations. namely. Nesterov’s optimal method (Nesterov in Doklady AN SSSR 269:543–547. 1983; Math Program 103:127–152. 2005). Nesterov’s smooth approximation scheme (Nesterov in Math Program 103:127–152. 2005). and Nemirovski’s prox-method (Nemirovski in SIAM J Opt 15:229–251. 2005). and propose a variant of Nesterov’s optimal method which has outperformed the latter one in our computational experiments. We also derive iteration-complexity bounds for these first-order methods applied to the proposed primal-dual reformulations of the cone programming problem. The performance of these methods is then compared using a set of randomly generated linear …,True,l3SflUcAAAAJ:u-x6o8ySG0sC,192,https://link.springer.com/article/10.1007/s10107-008-0261-6,14822686162862723506,/scholar?cites=14822686162862723506,,,https://www2.isye.gatech.edu/people/faculty/Renato_Monteiro/publications/tech_reports/pdfirst3.pdf,0,0,0
1278881,An optimal randomized incremental gradient method,2018,Guanghui Lan and Yi Zhou,171,Mathematical programming,1,167-215,Springer Berlin Heidelberg,In this paper. we consider a class of finite-sum convex optimization problems whose objective function is given by the average of  smooth components together with some other relatively simple terms. We first introduce a deterministic primal–dual gradient (PDG) method that can achieve the optimal black-box iteration complexity for solving these composite optimization problems using a primal–dual termination criterion. Our major contribution is to develop a randomized primal–dual gradient (RPDG) method. which needs to compute the gradient of only one randomly selected smooth component at each iteration. but can possibly achieve better complexity than PDG in terms of the total number of gradient evaluations. More specifically. we show that the total number of gradient evaluations performed by RPDG can be  times smaller. both in expectation and with high probability. than those …,True,l3SflUcAAAAJ:hC7cP41nSMkC,190,https://link.springer.com/article/10.1007/s10107-017-1173-0,18224996424125225263,/scholar?cites=18224996424125225263,,,https://arxiv.org/pdf/1507.02000,0,0,0
1278882,An effective and simple heuristic for the set covering problem,2007,Guanghui Lan and Gail W DePuy and Gary E Whitehouse,176,European journal of operational research,3,1387-1403,North-Holland,This paper investigates the development of an effective heuristic to solve the set covering problem (SCP) by applying the meta-heuristic Meta-RaPS (Meta-heuristic for Randomized Priority Search). In Meta-RaPS. a feasible solution is generated by introducing random factors into a construction method. Then the feasible solutions can be improved by an improvement heuristic. In addition to applying the basic Meta-RaPS. the heuristic developed herein integrates the elements of randomizing the selection of priority rules. penalizing the worst columns when the searching space is highly condensed. and defining the core problem to speedup the algorithm. This heuristic has been tested on 80 SCP instances from the OR-Library. The sizes of the problems are up to 1000 rows × 10.000 columns for non-unicost SCP. and 28.160 rows × 11.264 columns for the unicost SCP. This heuristic is only one of two known SCP …,True,l3SflUcAAAAJ:9yKSN-GCB0IC,188,https://www.sciencedirect.com/science/article/pii/S0377221705008313,10200696897558937653,/scholar?cites=10200696897558937653,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.8539&rep=rep1&type=pdf,0,0,0
1278883,Optimal primal-dual methods for a class of saddle point problems,2014,Yunmei Chen and Guanghui Lan and Yuyuan Ouyang,24,SIAM Journal on Optimization,4,1779-1814,Society for Industrial and Applied Mathematics,We present a novel accelerated primal-dual (APD) method for solving a class of deterministic and stochastic saddle point problems (SPPs). The basic idea of this algorithm is to incorporate a multistep acceleration scheme into the primal-dual method without smoothing the objective function. For deterministic SPP. the APD method achieves the same optimal rate of convergence as Nesterov's  smoothing technique.  Our stochastic APD method exhibits an optimal rate of convergence for stochastic SPP not only in terms of its dependence on the number of  the iteration. but also on a variety of problem parameters. To the best of our knowledge. this is the first time that such an optimal algorithm has been developed for stochastic SPP in the literature. Furthermore.  for both deterministic and stochastic SPP.  the developed APD algorithms can deal with the situation when the feasible region is unbounded. as long as a …,True,l3SflUcAAAAJ:3fE2CSJIrl8C,182,https://epubs.siam.org/doi/abs/10.1137/130919362,15276618125692804956,/scholar?cites=15276618125692804956,,,https://arxiv.org/pdf/1309.5548,0,0,0
1278884,An accelerated linearized alternating direction method of multipliers,2015,Yuyuan Ouyang and Yunmei Chen and Guanghui Lan and Eduardo Pasiliao Jr,8,SIAM Journal on Imaging Sciences,1,644-681,Society for Industrial and Applied Mathematics,We present a novel framework. namely. accelerated alternating direction method of multipliers (AADMM). for acceleration of linearized ADMM. The basic idea of AADMM is to incorporate a multistep acceleration scheme into linearized ADMM. We demonstrate that for solving a class of convex composite optimization with linear constraints. the rate of convergence of AADMM is better than that of linearized ADMM. in terms of their dependence on the Lipschitz constant of the smooth component. Moreover. AADMM is capable of dealing with the situation when the feasible region is unbounded. as long as the corresponding saddle point problem has a solution. A backtracking algorithm is also proposed for practical performance.,True,l3SflUcAAAAJ:aqlVkmm33-oC,167,https://epubs.siam.org/doi/abs/10.1137/14095697X,9196599742565777416,/scholar?cites=9196599742565777416,,,https://arxiv.org/pdf/1401.6607,0,0,0
1278885,Biometrical Methods in Quantitative Genetic Analysis.,2005,MJ Asins and D Beck and S Vasal and J Crossa and FJ Betran and D Beck and M Banziger and GO Edmeades and D Das and P Arora and P Singh and BS Dhillon and NS Dodiya and VN Joshi and TK Doerksen and LW Kannenberg and EA Lee and AR Hallauer and JB Miranda and VN Joshi and N Pandiya and RB Dubey and R Kumar and M Singh and M Narwal and S Sharma and J Popi and L Kannenberg and Y Suneetha and J Patel and T Srinivas and H Zelleka and G Zaffar and RK Singh and BD Chaudhary,5,Asian Journal of Plant Sciences,6,281-286,orgz,,True,H_52KDcAAAAJ:vq7B84E5p90C,4765,,3666024834132826640,/scholar?cites=3666024834132826640,,,,0,0,0
1278886,Phytate: Its chemistry. occurrence. food interactions. nutritional significance and methods of analysis.,1995,SS Diarra and BA Usman and JU Igwebuike and AG Yisa and O Adeola and BV Lawrence and AL Sutton and TR Clime and R Alonso and E Orue and MJ Zabalza and G Grant and F Marzo and JC Anderson-Hafermann and Y Zhan and CM Parsons and PA Anderson and R Angel and SD Dhanhu and TJ Applegate and M Christman and JC Armour and RLC Perera and WC Buchan and G Grant and GC Ballam and TS Nelson and LK Kirby and B Barrier-Guillot and P Casado and P Maupetit and C Jonderville and F Gatel and ES Batherham and LM Anderson and DR Baigent and SA Beech and ES Batterham and R Elliott and RL Bernard and T Hymowitz and J Broz and P Oldale and AH Perrin-Voltz and G Rychen and J Schulze and CS Nunes and M Choct and DJ Cosgrove and GL Cromwell and NT Davies and R Nightingale and AR De Boland and GB Garner and BL O'Dekk and DM Denbow and V Ravindram and ET Kornegay and Z Yi and RM Hulet and SS Deshpande and M Cheryan and SS Diarra and BA Usman and ID Kwari and A Yisa and A Duhan and BM Chauhan and O Punia and AC Kapoor and MA Eastwood and W Eeckhout and M De Paepe and W Eeckhout and M De Paepe and W Eeckhout and M De Paepe and HM Edwards Jr and HM Edwards Jr and P Palo and S Soonchaerenying and MA Elliot and SP Golovan and RG Meidinger and A Ajakaiye and M Cotrill and MZ Wiederkehr and SN Hedge and BA Rolls and A Turvey and ME Coates and RF Hurrell and T Hymowitz and PA Kemme and AW Jongbloed and Z Mroz and AC Beynen and BE Knuckles and AA Betschart and S Khokhar and BM Chauhan and PA Kondra and JL Sell and W Guenter and ET Kornegay and S Leeson and GM Lolas and P Markakis and VT Maddaiah and AA Kumick and BJ Hullet and BL Reid and DD Maenz and CM Engele-Schaan and RW Newkirk and HL Classen and MO Kingsley and C Mohanna and Y Nys and Z Mroz and AW Jongbloed and PA Kemme and KH Nahm and JM Nasi and EH Helander and KH Partanen and TS Nelson and TR Shieh and RJ Wodzinski and JH Ware and BL O'Dell and JE Savage and BL O'Dell and AR De Boland and SR Koirtyohann and DI Officer and ES Batterman and AD Ologhobo and BL Fetuga and J Pallauf and G Rimbach and S Pippig and B Schinder and E Most and CM Parsons and K Hashimoto and KJ Wedekind and Y Han and DH Baker and A Pointillart,9,International Journal of Poultry Science,10,3384-3391,orgz,,True,H_52KDcAAAAJ:MaiMEk8tZqMC,832,,2951805394983020095,/scholar?cites=2951805394983020095,,,,0,0,0
1278887,Antimicrobial. wound healing and antioxidant activity of Plagiochasma appendiculatum Lehm. et Lind.,1993,A Soni and A Kumar and V Nath and A Niveden and RP Adams and T Demeke and RD Banerjee and H Bischler and H Bischler and MC Boisselier-Dubayle and H Bischler and MC Boisselier-Dubayle and MF Jubier and B Lejeune and H Bischler and RM Dewey and JJ Doyle and JL Doyle and JP Frahm and W Frey and H Freitas and A Brehm and W Frey and H Kurschner and F Fukarke and J Schultze-Motel and M Siegel and S Ghate and SB Chaphekar and P Kachroo and K Kumar and KK Singh and AK Asthana and V Nath and JGC Lehmann and JBW Lindenberg and MD Loveless and JL Hamrick and TS Mahabale and PD Bhate and BD Mishler and IJ Odrzykoski and J Szweykowski and NS Parihar and B Lal and N Katiyar and SM Perold and F Rohlf and RM Schuster and PHA Sneath and RR Sokal and ID Soane and AR Watkinson and K Walther and MJ Wigginton and JGK Williams and AR Kubelik and KJ Livak and JA Rafalski and SV Tingey and R Wyatt and IJ Odrzykoski and A Stoneburner and IV Yap and RJ Nelson and K Walther and M Singh and R Govindarajan and V Nath and AKS Rawat and S Mehrotra,4,Research Journal of Botany,3,553-571,orgz,,True,H_52KDcAAAAJ:VOx2b1Wkg3QC,212,,6824326574718631024,/scholar?cites=6824326574718631024,,,,0,0,0
1278888,Indigenous phytotherapy for genito-urinary diseases used by the Kandha tribe of Orissa. India.,2009,Farha Arakkaveettil Kabeer and Remani Prathapan and A Ahmad and AF Alkarkhi and S Hena and LH Khim and AP Singh and VT Anitha and JM Antonisamy and S Jeeva and LRN Athira and SV Anisha and K Avani and S Neeta and PPH But and PM Hon and H Cao and TWD Chan and BM Wu and N Chaidichoey and A Srikhao and CP Chen and CC Lin and N Tsuneo and P Daisy and R Jasmine and S Ignacimuthu and E Murugan and P Daisy and CE Priya and P Daisy and CE Priya and L Vargese and P Daisy and S Suveena and VS Lilly and P Daisy and SSS Mathew and NA Rayan and LB De Silva and WHMW Herath and RC Jennings and M Mahendran and GE Wannigamma and D Dubey and MC Sahu and S Rath and BP Paty and NK Debata and RN Padhy and AK Farha and BS Geetha and SN Mangalam and SR Dhanya and PG Latha and P Remani and AK Farha and BS Geetha and M Sivasankaran and SRD Nair and P Gopalakrishnan and KS Latha and P Remani and G Zou and Z Gao and J Wang and Y Zhang and H Ding and RB Ganga and RY Venkateswara and S Pavani and VSP Dasari and RB Ganga and YV Rao and VSP Dasari and BS Geetha and MS Nair and PG Latha and P Remani and BS Geetha and PG Latha and P Remani and BS Geetha and PG Latha and P Remani and S Rajashekharan and HW Geng and XL Zhang and GG Wang and XX Yang and X Wu and T Govindachari and AR Sidhaye and N Viswanathan and T Govindachari and N Viswanathan and H Fuhrer and GR Yan and Z Tan and Y Wang and ML Xu and G Yu and Y Li and QY He and MLA Hammer and EA Johns and H Ichikawa and MS Nair and Y Takada and DA Sheeja and MS Kumar and OV Oommen and BB Aggarwal and A Hisham and L Pieters and M Claeys and R Dommisse and DV Berghe and A Vlietinck and WY Ho and SK Yeap and CL Ho and R Abdul Rahim and NB Alitheen and CC Huang and CP Lo and CY Chiu and LF Shyur and T Huang and X Wu and Y Wang and WC Ye and YL Li and HF Hung and CW Hou and YL Chen and CC Lin and HW Fu and JS Wang and KC Jeng and R Jasmine and BN Selvakumar and A Jenny and D Saha and S Paul and M Dutta and MZ Uddin and AK Nath and P Kamalakannan and R Kavitha,5,Pharmacologia,8,36-49,orgz,,True,H_52KDcAAAAJ:bQkGhl1z2hUC,117,,1710495881417931130,/scholar?cites=1710495881417931130,,,,0,0,0
1278889,Chemical composition and biological activities of a new essential oil chemotype of Tunisian Artemisia herba alba Asso.,2012,Abderrahmane Moufid and Mohamed Eddouks and MJ Abad and LM Bedoya and L Apaza and P Bermejo and ZB Abid and M Feki and A Hedhili and MH Hamdaoui and S Abdel-Shafy and RM El-Khateeb and MMM Soliman and MM Abdel-Aziz and AHH Mohamed and MA El-Sayed and ME Hegazy and SE Helaly and AM Esmail and NS Mohamed and BE Abu-Irmaileh and FU Afifi and A Akrout and H El-Jani and S Amouri and M Neffati and S Aloui and H Skhiri and A Ltaief and M Elmay and MM Almasad and WS Qazan and H Daradka and M Alzweiri and A Al Sarhan and K Mansi and M Hudaib and T Aburjai and SM Al-Khazraji and LA Al-Shamaony and HAA Twaij and W Al-Momani and E Abu-Basha and S Janakat and RA Nicholas and RD Ayling and AH Al-Mustafa and OY Al-Thunibat and L Al-Shamaony and SM Al-Khazraji and HAA Twaiji and NS Al-Waili and NS Al-Waili and H Azaizeh and S Fulder and K Khalil and O Said and L Bezza and A Mannarino and K Fattarsi and C Mikail and L Abou and F Hadji-Minaglou and J Kaloustian and D Boriky and M Berrada and M Talbi and G Keravis and F Rouessac and M Chaouch and Z Charrouf and SC Dutta and M Eddouks and M Maghrani and A Lemhadri and ML Ouahidi and H Jouad and I Goze and A Alim and SA Cetinus and N Durmus and N Vural and HM Goze and N Hamza and B Berke and C Cheze and AN Agli and P Robinson and H Gin and N Moore and H Mohsen and F Ali and S Hatimi and M Boudouma and M Bichichi and N Chaib and NG Idrissi and L He and L He and Y Wu and LL Wang and Y Wu and M Hudaib and M Mohammad and Y Bustanji and R Tayyem and M Yousef and M Abuirjeie and T Aburjaie and H Jouad and M Haloui and H Rhiouani and J El Hilaly and M Eddouks and A Kadri and IB Chobba and Z Zarai and A Bekir and N Gharsallah and M Damak and R Gdoura and KR Kirtikar and BU Basu and M Laid and MEF Hegazy and AA Ahmed and K Ali and D Belkacemi and S Ohta and HI Marrif and BH Ali and KM Hassan and I Mehrdad and ES Ahmad and M Mahmoud-Soltani and D Messaoudene and H Belguendouz and ML Ahmedi and T Benabdekader and F Otmani and H Mighri and H Hajlaoui and A Akrout and H Najjaa and M Neffati and H Mighri and A Akrout and H El-Jeni and S Zaidi and F Tomi,15,Pakistan Journal of Biological Sciences,24,2542-2566,orgz,The aim of the present study was to investigate the chemical composition chemical composition Subject Category: Properties,True,H_52KDcAAAAJ:Tiz5es2fbqcC,79,https://www.cabdirect.org/cabdirect/abstract/20103200320,2362053422219441638,/scholar?cites=2362053422219441638,,,,0,0,0
1278890,Critical phenomena at the 140 and 200 K magnetic phase transitions in BiFeO {sub 3},2008,JF Scott and MK Singh and RS Katiyar,,,,,,,True,H_52KDcAAAAJ:oTdOBqtIf_kC,67,,5857798738835422620,/scholar?cites=5857798738835422620,,,,0,0,0
1278891,Direct somatic embryogenesis. Plant regeneration and in vitro flowering in rapid cycling Brassica napus.,2002,S Guha and SC Maheshwari and JW Snape and C Savaskan and I Szarejko and MC Toker and DS Hassawi and GH Liang and K Orhan and ME Gareth and JR Rout and NP Sharma and D Ozkum-Ciner and R Tipirdamaz and BM Tatiana and EV Richard and SK Raina and RD Iyer and K Prabhavathi and K Kumar and M Singh and A Mathews and SL Anagnostakis and F Khatun and Y Chen and MS Wang and FJ Zapata and K Nichterlein and H Umbach and W Friedt and K Nichterlein and H Umbach and W Friedt and E Heberle-Bors and J Reinert and WA Keller and GR Stringham and N Thurling and PM Chay and H Du and DH Zhuang and WH Huang and WL Koh and CS Loh,9,Pakistan Journal of Biological Sciences,1,pp: 150-pp: 150,orgz, A simple method to induce somatic embryogenesis from seeds of rapid-cycling Brassica napus is described. Seedlings cultured on Murashige and Skoog (MS) basal medium produced somatic embryos directly on hypocotyls and cotyledons after 2 to 3 subcultures onto the same medium. A low pH of the medium (3.5–5) was more conducive to somatic embryogenesis than a higher pH (6 and 7). Embryogenic potential of the seeds was inversely correlated to seed age: about 41–68% of immature seeds between the ages of 14 and 28 days after pollination (DAP) formed somatic embryos compared to 0–11% of the seeds obtained 29–37 DAP. About 54% of the somatic embryos produced secondary embryos after subculturing onto the same medium. The embryogenic potential of the cultures has been maintained on MS basal medium for 2 years (12 generations) without diminution. Up to 75% of the …,True,H_52KDcAAAAJ:0d9pApVQ-n0C,67,https://link.springer.com/article/10.1007/s002990000268,12934831110518391207,/scholar?cites=12934831110518391207,,,,0,0,0
1278892,Adaptation and diversity along an altitudinal gradient in Ethiopian barley (Hordeum vulgare L.) landraces revealed by molecular analysis.,1999,Z Jalata and A Ayana and H Zeleke and AA Abdelmula and W Link and E Von Kittlitz and D Stelling and Z Asfaw and RW Allard and A Alemayehu and GN Atlin and KJ Frey and MR Amin and NCD Barma and MA Razzaque and L Birhane and G Hailu and A Fekadu and R Von Bothmer and N Jacobsen and C Baden and RB Jargensen and I Linde-Laursen and GW Burton and WG Burton and EH Devane and S Ceccarelli and S Ceccarelli and S Grando and S Ceccarelli and S Ceccarelli and WG Cochran and GM Cox and AR Dabholkar and DS Falconer and TFC Mackay and E Firdissa and W Sinebo and G Heinrich and E Geremew and G Tilahun and H Aliye and G Hailu and L Birhane and F Fekadu and B Birhanu and A Fekadu and G Tesfaye and PA Jackson and DE Byth and RP Johnston and KS Fischer and AA Jaradat and M Shahid and A Al-Maskri and GR Johnson and KJ Frey and HW Johnson and HF Robinson and RE Comstock and JG Kling and PM Hayes and RH Moll and CW Stuber and JM Poehlman and DA Sleper and R Riaz and MA Chowdhry and JN Rytger and CW Schaller and AD Dickson and M Singh and S Ceccarelli and BD Singh and S Singh and S Mahabalram and DP Singh and SC Vimal and SR Vishwakarma and EJ Van Oosterom and D Klejin and S Ceccarelli and MM Nachit and RD Freed and SP Eisensmith and EH Everson and M Weber and E Paul and D Islcib and T Tanto and D Rau and E Bitocchi and R Papa,5,International Journal of Plant Breeding and Genetics,1,485-490,orgz,,True,H_52KDcAAAAJ:ohFW0PAxsewC,46,,8601628878354662788,/scholar?cites=8601628878354662788,,,,0,0,0
1278893,Cytotoxic activity of methanolic extract of Mentha longifolia and Ocimum basilicum against human breast cancer.,1981,Farooq Anwar and Khalid M Alkharfy and Elsadig Hassan Khamis Adam and Anwar-ul-Hassan Gilani and AA Abo-Hassan and H Sher and A Aldosari and S Collenette and MA Rahman and JS Mossa and MS Al-Said and MA Al-Yahya and AE Edris and SA Bazaid and MS El-Amoudi and EF Ali and AES Abdel-Hameed and AI Hussain and F Anwar and STH Sherazi and R Przybylski and AI Hussain and F Anwar and PS Nigam and M Ashraf and AH Gilani and M Nikolic and T Markovic and D Markovic and J Glamoclija and A Ciric and M Smiljkovic and M Sokovic and OY Celiktas and EEH Kocabas and E Bedir and FV Sukan and T Ozek and KHC Baser and I Ahmad and MSA Ahmad and M Ashraf and M Hussain and MY Ashraf and M Singh and N Guleria and M Salman and ESS Abdel-Hameed and SA Bazaid and MM Dabi and V Stamenkovic and AM Dzamic and MD Sokovic and MS Ristic and M Novakovic and S Grujic-Jovanovic and V Tesevic and PD Marin and Z Saeidi and KA Saeidi and A Salehi and RS Jouneghani and H Amirshekari and A Taghipour and AJ Shah and IA Bukhari and AH Gilani and P Mikaili and S Mojaverrostami and M Moloudizargari and S Aghajanshakeri and FA Al-Bayati and SY Al-Okbi and HHM Fadel and D Mohamed and AS Al-Sarar and HI Hussein and Y Abobakr and AE Bayoumi and MT Al-Otaibi and YMH Younis and SM Basher and FS Sharopov and VA Sulaimonova and WN Setzer and R Abedi and AR Golparvar and A Hadipanah and AM Viljoen and S Petkar and SF Van Vuuren and AC Figueiredo and LG Pedro and JG Barroso and KH Al-Ali and AA El-Badry and KH Al-Ali and HA El-Beshbishy and AA Alghaithy and H Abdallah and AA El-Badry and E Abdel-Sattar and K Al-Ali and M Abdelrazik and A Alghaithy and A Diab and H El-Beshbishy and H Baghdadi and RP Adams and S Prasad and RS Kashyap and JY Deopujari and HJ Purothit and GM Taori and HF Daginawala and D Malagoli and M Jamzad and Z Jamzad and F Mokhber and S Ziareh and M Yari and H Hajlaoui and M Snoussi and HB Jannet and Z Mighri and A Bakhrouf and T Iqbal and AI Hussain and SAS Chatha and SAR Naqvi and TH Bokhari and RS Verma and V Pandey and A Chauhan and R Tiwari and M Elmastas and I Dermirtas and O Isildak and HY Aboul-Enein and A Monfared and MR Nabid and A Rustaiyan and OT Asekun and DS Grierson and AJ Afolayan and D Fraisse and KN Suon and C Scharff and G Vernin and G Vernin,13,International Journal of Pharmacology,5,51-53,orgz,,True,H_52KDcAAAAJ:hC7cP41nSMkC,43,,11809123458323048727,/scholar?cites=11809123458323048727,,,,0,0,0
1278894,Effects of irrigation water salinity and leaching fraction on the growth of six Halophyte species.,1966,Maher N. Noaman and BL Mcneal and NT Coleman and AM El-Sheikh and A Ulrich and TG Broyer and JJ Lehr and RA Fisher and V Maas and RH Nieman and LM Kent and M Lauchli and RA Leigh and RGW Jones and AA Watad and L Reinhold and HR Lerner and NT Singh and DR Bhumbla and JS Kanwar and HC Nitana and KS Dargan and IP Abrol and PN Takkar and T Singh and R Chhabra and IP Abrol and M Singh and GA Pearson and L Bernstein and AH Mustafa and AI Shabassy and AT Gohar and EM Abdel Naim and AA Rahman and ME Elshad and CL Mehrotra and SK Das and YC Joshi and A Qadar and RS Rana and J Dvorak and MM Noaman and S Goyal and J Gorham and LO Hylton and A Ulrich and DR Cornlivs and M Helal and K Koch and K Mengel and MN Noaman and M Khodir and AA El-Sayed and W Kadry and RGD Steel and JH Torrie and MN Noaman and E El-Haddad,3,Journal of Agronomy,1,308-312,orgz,,True,H_52KDcAAAAJ:-TLX1-BxFiYC,35,,404873947141918625,/scholar?cites=404873947141918625,,,,0,0,0
1278895,Using charge passed and total chloride content to assess the effect of penetrating silane sealer on the transport properties of concrete.,1999,DM Paiva and M Singh and KS Macklin and SB Price and JB Hess and DE Conner and CK Bower and MA Daeschel and JF Brisou and ME Doyle and JF Frank and RAN Gillelt and GO Ware and DA Gabis and RS Flowers and D Evanson and RE Faust and M Gandhi and ML Chikindas and GE Gerats and JMA Snijders and JG Loglestun and JL Johnson and MP Doyle and RG Cassens and AM Katsuyama and JP Slrachan and EP Krysinski and LJ Brown and TJ Marchisello and D Lindsay and AV Holy and JA Lopes and B McClane and EG Nawy and WL Nicholson and N Munakata and G Horneck and HJ Melosh and P Setlow and P Setlow and EA Johnson and N Shetty and S Srinivasan and J Holton and GW Ridgway and RA Slepecky and HE Hemphill and PJ Taormina and WJ Dorsa and CJ Thomas and TA McMcekin and JT Patterson and CC Yang and LC Wang and TL Weng,9,International Journal of Poultry Science,3,33-44,orgz,,True,H_52KDcAAAAJ:54MofcL-yxcC,31,,560944317015081970,/scholar?cites=560944317015081970,,,,0,0,0
1278896,Effect of altitude on oxygen binding by hemoglobin and on organic phosphate levels,1968,Claude Lenfant and John Torrance and Eugenia English and Clement A Finch and Cesar Reynafarje and Jose Ramos and Jose Faura,47,The Journal of clinical investigation,12,2652-2656,American Society for Clinical Investigation,The relationship between oxygen dissociation and 2.3-diphosphoglycerate (2.3-DPG) in the red cell has been studied in subjects moving from low to high altitude and vice versa. Within 24 hr following the change in altitude there was a change in hemoglobin affinity for oxygen; this modification therefore represents an important rapid adaptive mechanism to anoxia. A parallel change occurred in the organic phosphate content of the red cell. While this study does not provide direct evidence of a cause-effect relationship. the data strongly suggest that with anoxia. the observed rise in organic phosphate content of the red cell is responsible for increased availability of oxygen to tissues.,True,d8qfFXAAAAAJ:u5HHmVD_uO8C,471,https://www.jci.org/articles/view/105948,12005739853633477097,/scholar?cites=12005739853633477097,,,https://www.jci.org/articles/view/105948/files/pdf,0,0,0
1278897,The Imaging Magnetograph eXperiment (IMaX) for the Sunrise balloon-borne solar observatory,2011,V Martínez Pillet and JC Del Toro Iniesta and A Álvarez-Herrero and V Domingo and JA Bonet and L González Fernández and A López Jiménez and C Pastor and JL Gasent Blesa and P Mellado and J Piqueras and B Aparicio and M Balaguer and E Ballesteros and T Belenguer and LR Bellot Rubio and T Berkefeld and M Collados and W Deutsch and A Feller and F Girela and B Grauf and RL Heredero and M Herranz and JM Jerónimo and H Laguna and R Meller and M Menéndez and R Morales and D Orozco Suárez and G Ramos and M Reina and JL Ramos and P Rodríguez and A Sánchez and N Uribe-Patarroyo and P Barthol and A Gandorfer and M Knoelker and W Schmidt and SK Solanki and S Vargas Domínguez,268,Solar Physics,1,57-102,Springer Netherlands,The Imaging Magnetograph eXperiment (IMaX) is a spectropolarimeter built by four institutions in Spain that flew on board the Sunrise balloon-borne solar observatory in June 2009 for almost six days over the Arctic Circle. As a polarimeter. IMaX uses fast polarization modulation (based on the use of two liquid crystal retarders). real-time image accumulation. and dual-beam polarimetry to reach polarization sensitivities of 0.1%. As a spectrograph. the instrument uses a LiNbO3 etalon in double pass and a narrow band pre-filter to achieve a spectral resolution of 85 mÅ. IMaX uses the high-Zeeman-sensitive line of Fe i at 5250.2 Å and observes all four Stokes parameters at various points inside the spectral line. This allows vector magnetograms. Dopplergrams. and intensity frames to be produced that. after reconstruction. reach spatial resolutions in the 0.15 – 0.18 arcsec range over a 50×50 arcsec field of …,True,d8qfFXAAAAAJ:Ade32sEp0pkC,240,https://link.springer.com/article/10.1007/s11207-010-9644-y,6185741510603491517,/scholar?cites=6185741510603491517,,,https://link.springer.com/content/pdf/10.1007/s11207-010-9644-y.pdf,0,0,0
1278898,Introducción al turismo,2014,Perla Guerrero and José Ramos,,México: Grupo Editorial Patria,,,,,True,d8qfFXAAAAAJ:OTTXONDVkokC,239,http://scholar.google.com/scholar?cluster=5049971592225756712&hl=en&oi=scholarr,5049971592225756712,/scholar?cites=5049971592225756712,,,,0,0,0
1278899,Perivascular fibroblasts form the fibrotic scar after contusive spinal cord injury,2013,Cynthia Soderblom and Xueting Luo and Ezra Blumenthal and Eric Bray and Kirill Lyapichev and Jose Ramos and Vidhya Krishnan and Catherine Lai-Hsu and Kevin K Park and Pantelis Tsoulfas and Jae K Lee,33,Journal of Neuroscience,34,13882-13887,Society for Neuroscience,Injury to the CNS leads to formation of scar tissue. which is important in sealing the lesion and inhibiting axon regeneration. The fibrotic scar that comprises a dense extracellular matrix is thought to originate from meningeal cells surrounding the CNS. However. using transgenic mice. we demonstrate that perivascular collagen1α1 cells are the main source of the cellular composition of the fibrotic scar after contusive spinal cord injury in which the dura remains intact. Using genetic lineage tracing. light sheet fluorescent microscopy. and antigenic profiling. we identify collagen1α1 cells as perivascular fibroblasts that are distinct from pericytes. Our results identify collagen1α1 cells as a novel source of the fibrotic scar after spinal cord injury and shift the focus from the meninges to the vasculature during scar formation.,True,d8qfFXAAAAAJ:JP7YXuLIOvAC,233,https://www.jneurosci.org/content/33/34/13882.short,16742174314740209508,/scholar?cites=16742174314740209508,,,https://www.jneurosci.org/content/jneuro/33/34/13882.full.pdf,0,0,0
1278900,The terminal portion of leptospiral immunoglobulin-like protein LigA confers protective immunity against lethal infection in the hamster model of leptospirosis,2007,Éverton F Silva and Marco A Medeiros and Alan JA McBride and Jim Matsunaga and Gabriela S Esteves and João GR Ramos and Cleiton S Santos and Júlio Croda and Akira Homma and Odir A Dellagostin and David A Haake and Mitermayer G Reis and Albert I Ko,25,Vaccine,33,6277-6286,Elsevier,Subunit vaccines are a potential intervention strategy against leptospirosis. which is a major public health problem in developing countries and a veterinary disease in livestock and companion animals worldwide. Leptospiral immunoglobulin-like (Lig) proteins are a family of surface-exposed determinants that have Ig-like repeat domains found in virulence factors such as intimin and invasin. We expressed fragments of the repeat domain regions of LigA and LigB from Leptospira interrogans serovar Copenhageni. Immunization of Golden Syrian hamsters with Lig fragments in Freund's adjuvant induced robust antibody responses against recombinant protein and native protein. as detected by ELISA and immunoblot. respectively. A single fragment. LigANI. which corresponds to the six carboxy-terminal Ig-like repeat domains of the LigA molecule. conferred immunoprotection against mortality (67–100%. P < 0.05) in …,True,d8qfFXAAAAAJ:g5m5HwL7SMYC,190,https://www.sciencedirect.com/science/article/pii/S0264410X07006330,13010134256573944222,/scholar?cites=13010134256573944222,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc1994161/,0,0,0
1278901,Biodegradable municipal solid waste: Characterization and potential use as animal feedstuffs,2005,AJ Garcıa and MB Esteban and MC Marquez and P Ramos,25,Waste Management,8,780-787,Pergamon,Five different fractions of the biodegradable municipal solid waste (BMSW) were evaluated as potential animal feedstuffs. For each source of waste (meat waste (MW). fish waste (FW). fruit and vegetables waste (FVW). restaurant waste (RW). household waste (HW)). samples were obtained from small shops (butchers. fishmongers. fruit and vegetable shops). restaurants and a MSW treatment plant (household waste). The chemical composition. microbiological characterization. dioxins. furans. PCB’s and mineral content were determined for every type of waste fraction.The analysed biodegradable waste presented high moisture content (from 60% to 90%). Some fractions were dense in one nutrient: meat waste in ether extract. fish waste in crude protein. fruit and vegetable waste in nitrogen free extract. The other studied fractions (restaurant fraction and household fraction) presented a more balanced composition …,True,d8qfFXAAAAAJ:tKAzc9rXhukC,181,https://www.sciencedirect.com/science/article/pii/S0956053X05000371,6061880564875491504,/scholar?cites=6061880564875491504,,,https://www.academia.edu/download/48205598/j.wasman.2005.01.00620160820-15207-iuzidb.pdf,0,0,0
1278902,Dengue virus in the brain of a fatal case of hemorrhagic dengue fever: case report,1998,Celso Ramos and Gilma SÁNchez and Rogelio Hernández Pando and Javier Baquera and Dalia HernÁNdez and Javier Mota and José Ramos and Adrian Flores and Eduardo LlausÁS,4,Journal of neurovirology,4,465-468,Taylor & Francis,Neurologic complications associated with dengue fever are in general unusual. However. recent reports evidence more frequent neurologic alterations. In Mexico. neurologic involvement has not been reported in dengue cases. This report demonstrates the detection of dengue virus in the brain of a fatal case of dengue hemorrhagic fever. Serotype 4 was detected by immunohistochemistry and by RT-PCR in the inferior olivary nucleus of medulla and in the granular layer of cerebellum. Immunoreactivity was observed in neurons. astrocytes. microglia and endothelial cells. Our results emphasize the importance of neurologic manifestations in patients with dengue fever.,True,d8qfFXAAAAAJ:DkZNVXde3BIC,181,https://www.tandfonline.com/doi/abs/10.3109/13550289809114548,9108947793787699011,/scholar?cites=9108947793787699011,,,https://www.researchgate.net/profile/Gilma_Sanchez/publication/13567645_Dengue_virus_in_the_brain_of_fatal_case_of_hemorrhagic_dengue_fever/links/54b69af90cf24eb34f6d37d4/Dengue-virus-in-the-brain-of-fatal-case-of-hemorrhagic-dengue-fever.pdf,0,0,0
1278903,Progression of chronic renal disease,2003,Saulo Klahr and Jeremiah Morrissey,41,,3,S3-S7,WB Saunders,Risk factors for progression of kidney disease include hypertension. proteinuria. male sex. obesity. diabetes mellitus. hyperlipidemia. smoking. high-protein diets. phosphate retention. and metabolic acidosis. Angiotensin II production upregulates the expression of transforming growth factor-β1. tumor necrosis factor-α. nuclear factor-κB. and several adhesion molecules and chemoattractants. In addition to angiotensin. other vasoactive compounds. such as thromboxane A2. endothelin. and prostaglandins. are upregulated. Treatment with one of several growth factors may ameliorate the progression of kidney disease: insulin-like growth factor-1. hepatocyte growth factor. and bone morphogenetic protein-7. Am J Kidney Dis 41(S1):S3-S7. © 2003 by the National Kidney Foundation. Inc.,True,d8qfFXAAAAAJ:SP6oXDckpogC,144,https://www.sciencedirect.com/science/article/pii/S0272638603000155,1145524759911284263,/scholar?cites=1145524759911284263,,,,0,0,0
1278904,Peritonitis in continuous ambulatory peritoneal dialysis: laboratory and clinical studies,1982,R Gokal and DMA Francis and THJ Goodship and AJ Bint and JM Ramos and RE Ferner and G Proud and MK Ward and DNS Kerr,320,The Lancet,8312,1388-1391,Elsevier,During a three year period. 1979-81. 82 patients were treated by continuous ambulatory peritoneal dialysis (CAPD). The incidence of peritonitis was reduced significantly during the three years from one episode per 20 patient-weeks to one episode every 37 patient-weeks. 83% of the 136 episodes of peritonitis were treated successfully by antibiotic therapy alone. 62% of the total episodes were managed successfully with intraperitoneal cefuroxime. In 13 (16%) patients. CAPD failed because of peritonitis. Hospital admission for peritonitis has been reduced to a mean of 4-3 days per patient per year of CAPD. From January to September. 1982. Clostridium-difficile colitis developed in 13 patients. This complication was associated with considerable mortality and morbidity and has prompted a change in antibiotic policy. Patients with peritonitis are now given intraperitoneal netilmicin and intravenous vancomycin …,True,d8qfFXAAAAAJ:e5wmG9Sq2KIC,141,https://www.sciencedirect.com/science/article/pii/S014067368291282X,18240643655812102727,/scholar?cites=18240643655812102727,,,,0,0,0
1278905,Effect of altitude on erythropoiesis,1969,Jose Faura and Jose Ramos and Cesar Reynafarje and Eugenia English and PER Finne and Clement A Finch,33,Blood,5,668-676,American Society of Hematology,Measurements were made to characterize the relationship between erythropoietin output and erythropoiesis in two groups of subjects. one moved from a sea level habitat to high altitude. and the second moved from a high altitude habitat to sea level. In the first group. there was a latent period of 6 hours followed by a rapid increase in erythropoietin. and a secondary fall to a level of approximately twice normal. The increased erythropoietin stimulus was also reflected in a shortened marrow radioiron transit time. In the second group. there was an initial unexplained rise. after which erythropoietin fell within 8 hours to undetectable amounts.Elevated erythropoietin was associated in Group I with an increased iron uptake within 24 hours of the stimulus. suggesting a direct action of erythropoietin on hemoglobin synthesis by the existing marrow population. Limitation in erythropoiesis to a rate of less than twice …,True,d8qfFXAAAAAJ:d1gkVwhDpl0C,131,https://ashpublications.org/blood/article/33/5/668/38908,9083388961694184559,/scholar?cites=9083388961694184559,,,https://pdfs.semanticscholar.org/b9a0/7ea8a6e11d4d5c555d964b1e3e23c88b57e2.pdf,0,0,0
1278906,H2 production with CO2 capture by sorption enhanced chemical-looping reforming using NiO as oxygen carrier and CaO as CO2 sorbent,2012,Magnus Rydén and Pedro Ramos,96,Fuel Processing Technology,,27-36,Elsevier,A novel process for conversion of hydrocarbons to H2 has been examined. The process. sorption enhanced chemical-looping reforming. involves three interconnected reactor vessels. In the reforming reactor. hydrocarbon fuel is partially oxidized with oxygen provided via a solid oxygen carrier such as NiO. Resulting CO is shifted instantly to CO2 via sorption enhanced water–gas shift. facilitated by the capturing of CO2 with a solid CO2 sorbent such as CaO. Ni and CaCO3. are regenerated downstream in separate reactors. The process produces H2. CO2 and N2 of reasonable purity in separate streams. without need for additional gas separation equipment. The characteristics of the process have been examined by thermodynamic calculations and by process modeling. At 1 bar it could produce > 2.8 mol H2 with a purity of > 98 vol.% for each mol CH4 added as fuel. while capturing > 95% of added carbon as CO2 …,True,d8qfFXAAAAAJ:7T2F9Uy0os0C,125,https://www.sciencedirect.com/science/article/pii/S0378382011004267,3147436804627074045,/scholar?cites=3147436804627074045,,,,0,0,0
1278907,Activity and location recognition using wearable sensors,2002,Seon-Woo Lee and Kenji Mase,1,IEEE pervasive computing,3,24-32,IEEE,Using measured acceleration and angular velocity data gathered through inexpensive. wearable sensors. this dead-reckoning method can determine a user's location. detect transitions between preselected locations. and recognize and classify sitting. standing. and walking behaviors. Experiments demonstrate the proposed method's effectiveness.,True,4swDjMAAAAAJ:u5HHmVD_uO8C,709,https://ieeexplore.ieee.org/abstract/document/1037719/,9652277274434947271,/scholar?cites=9652277274434947271,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.8965&rep=rep1&type=pdf,0,0,0
1278908,Recognition of facial expression from optical flow,1991,Kenji Mase,74,IEICE TRANSACTIONS on Information and Systems,10,3474-3483,The Institute of Electronics. Information and Communication Engineers,We present a method that uses optical flow to estimate facial muscle actions which can then be recognized as facial expressions. Facial expressions are the result of facial muscle actions which are triggered by the nerve impulses generated by emotions. The muscle actions cause the movement and deformation of facial skin and facial features such as eyes. mouth and nose. Since facial skin has the texture of a fine-grained organ. which helps in extracting the optical flow. we can extract muscle actions from external appearance. We are thus able to construct a facial expression recognition system based on optical flow data. We investigate the recogniton method in two ways. First. the optical-flow fields of skin movement is evaluated in muscle winsows. each of which defines one primary direction of muscle contraction to correctly extract muscle movement. Second. a fifteen dimensional feature vector is used to …,True,4swDjMAAAAAJ:7Hz3ACDFbsoC,697,https://search.ieice.org/bin/summary.php?id=e74-d_10_3474,16131206408698978699,/scholar?cites=16131206408698978699,,,,0,0,0
1278909,Automatic lipreading by optical‐flow analysis,1991,Kenji Mase and Alex Pentland,22,Systems and Computers in Japan,6,67-76,Wiley Subscription Services. Inc.. A Wiley Company,While the acoustic signal is the primary cue in human speech recognition. the visual cue is also very useful. especially when the acoustic signal is distorted. A computer system is developed for automatic recognition of continuously spoken words by using only visual data. The velocity of lip motions may be measured from optical flow data which allows muscle action to be estimated. Pauses in muscle action result in zero velocity of the flow and are used to locate word boundaries. The pattern of muscle action is used to recognize the spoken words.In limited experiments involving the recognition of digits. it appears that the visually derived patterns of muscle action are stable for multiple utterances of the same word. Even across speakers the patterns are so similar that speaker‐independent recognition is possible. An overall accuracy including word spotting and recognition of approximately 70 percent is obtained …,True,4swDjMAAAAAJ:u-x6o8ySG0sC,256,https://onlinelibrary.wiley.com/doi/abs/10.1002/scj.4690220607,9741714442411959997,/scholar?cites=9741714442411959997,,,,0,0,0
1278910,Recognizing user context via wearable sensors,2000,Brian Clarkson and Kenji Mase and Alex Pentland,,,,69-75,IEEE,We describe experiments in recognizing a person's situation from only a wearable camera and microphone. The types of situations considered in these experiments are coarse locations (such as at work. in a subway or in a grocery store) and coarse events (such as in a conversation or walking down a busy street) that would require only global. non-attentional features to distinguish them.,True,4swDjMAAAAAJ:d1gkVwhDpl0C,217,https://ieeexplore.ieee.org/abstract/document/888467/,7515338020579030299,/scholar?cites=7515338020579030299,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.6335&rep=rep1&type=pdf,0,0,0
1278911,C-map: Building a context-aware mobile assistant for exhibition tours,1998,Yasuyuki Sumi and Tameyuki Etani and Sidney Fels and Nicolas Simonet and Kaoru Kobayashi and Kenji Mase,,,,137-154,Springer. Berlin. Heidelberg,This paper presents the objectives and progress of the Contextaware Mobile Assistant Project (C-MAP). The C-MAP is an attempt to build a personal mobile assistant that provides visitors touring exhibitions with information based on their locations and individual interests. We have prototyped the first version of the mobile assistant and used an open house exhibition held by our research laboratory for a testbed. A personal guide agent with a life-like animated character on a mobile computer guides users using exhibition maps which are personalized depending on their physical and mental contexts. This paper also describes services for facilitating new encounters and information sharing among visitors and exhibitors who have shared interests during/after the exhibition tours.,True,4swDjMAAAAAJ:9yKSN-GCB0IC,170,https://link.springer.com/chapter/10.1007/3-540-49247-X_10,11882332086852007180,/scholar?cites=11882332086852007180,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/C/Community%20Computing%20and%20Support%20Systems,%20Social%20Interaction%20in%20Networked%20Communities(LNCS1519,%20Springer,%201998)(ISBN%203540654755)(400s)_CsLn_.pdf#page=145",0,0,0
1278912,Path drawing for 3D walkthrough,1998,Takeo Igarashi and Rieko Kadobayashi and Kenji Mase and Hidehiko Tanaka,,,,173-174,,This paper presents an interaction technique for walkthrough in virtual 3D spaces. where the user draws the intended path directly on the scene. and the avatar automatically moves along the path. The system calculates the path by projecting the stroke drawn on the screen to the walking surface in the 3D world. Using this technique. the user can specify not only the goal position. but also the route to take and the camera direction at the goal with a single stroke. A prototype system is tested using a displayintegrated tablet. and experimental results suggest that the technique can enhance existing walkthrough techniques.,True,4swDjMAAAAAJ:qjMakFHDy7sC,155,https://dl.acm.org/doi/pdf/10.1145/288392.288599,14778891779412670136,/scholar?cites=14778891779412670136,,,https://www.researchgate.net/profile/Rieko_Kadobayashi/publication/220877390_Path_Drawing_for_3D_Walkthrough/links/00b4952b0cf6e4dced000000.pdf,0,0,0
1278913,Simultaneous multiple optical flow estimation,1990,Masahiko Shizawa and Kenji Mase,1,,,274-278,IEEE,The authors propose a simultaneous closed-form estimation method for multiple optical flow from image sequences in which each image point has multiple motions. This method only requires convolution for space-time filtering and low-dimensional eigensystem analysis as an optimization process. The authors propose a mixture flow model of a multiple flow and energy integral minimization as a model fitting method. It is shown that symmetry between component flows of the mixture flow can reduce the dimension of the eigensystem and make the optimization unimodal and stable. Successful experiments on double-flow estimation of random texture patterns and natural scene images are reported.< >,True,4swDjMAAAAAJ:2osOgNQ5qMEC,135,https://ieeexplore.ieee.org/abstract/document/118111/,17839468149620538587,/scholar?cites=17839468149620538587,,,https://www.researchgate.net/profile/Masahiko_Shizawa2/publication/3504813_Simultaneous_multiple_optical_flow_estimation/links/5be9b311a6fdcc3a8dd1b6a4/Simultaneous-multiple-optical-flow-estimation.pdf,0,0,0
1278914,“Finger-Pointer”: Pointing interface by image processing,1994,Masaaki Fukumoto and Yasuhito Suenaga and Kenji Mase,18,Computers & graphics,5,633-642,Pergamon,We have developed an experimental system for the 3D direct pointing interface “Finger-Pointer.” which can recognize finger pointing actions and simple hand forms in real-time by processing the image sequences captured by stereoscopic TV cameras. The operator is not required to attach any peculiar device such as the Data-Glove or a magnetic sensor. Simple and fast image processing algorithms employed in the system enable real-time processing without any special image processing hardware. By introducing the notion of “VPO (Virtual Projection Origin).” the system can recognize pointing actions stably and accurately regardless of the operator's pointing style. The system also synchronizes and integrates the audio and the visual channels by introducing the “Timing Tag” technique.,True,4swDjMAAAAAJ:IjCSPb-OGe4C,134,https://www.sciencedirect.com/science/article/pii/0097849394901570,17724936520691550864,/scholar?cites=17724936520691550864,,,https://www.cmc.ss.is.nagoya-u.ac.jp/~mase/papers/finger.pdf,0,0,0
1278915,Recognition of walking behaviors for pedestrian navigation,2001,Seon-Woo Lee and Kenji Mase,,,,1152-1155,IEEE,"This paper presents a method for detecting and classifying walking behaviors based on acceleration measurements of a pedestrian. and is employed in an indoor navigation system currently being developed. The prototype navigation system uses a set of inexpensive and wearable sensors: a bi-axial accelerometer. a digital compass. and an infrared light detector. Using the measured acceleration data. the proposed method can detect forward steps and classify the steps as: ""level ground"". ""up"". and ""down"". The objective of the detection is to count steps for estimating the current position by dead-reckoning using heading measurements. The capability in detecting ""up/down"" steps can be used to correct estimated position errors. The effectiveness of the proposed method is demonstrated by experiments on six persons.",True,4swDjMAAAAAJ:Tyk-4Ss8FVUC,132,https://ieeexplore.ieee.org/abstract/document/974027/,2059808585323588126,/scholar?cites=2059808585323588126,,,https://www.researchgate.net/profile/Kenji-Mase/publication/224075520_Recognition_of_walking_behaviors_for_pedestrian_navigation/links/02e7e52ca9aa72b887000000/Recognition-of-walking-behaviors-for-pedestrian-navigation.pdf,0,0,0
1278916,Ontology-based semantic recommendation for context-aware e-learning,2007,Zhiwen Yu and Yuichi Nakamura and Seiie Jang and Shoji Kajita and Kenji Mase,,,,898-907,Springer. Berlin. Heidelberg,Nowadays. e-learning systems are widely used for education and training in universities and companies because of their electronic course content access and virtual classroom participation. However. with the rapid increase of learning content on the Web. it will be time-consuming for learners to find contents they really want to and need to study. Aiming at enhancing the efficiency and effectiveness of learning. we propose an ontology-based approach for semantic content recommendation towards context-aware e-learning. The recommender takes knowledge about the learner (user context). knowledge about content. and knowledge about the domain being learned into consideration. Ontology is utilized to model and represent such kinds of knowledge. The recommendation consists of four steps: semantic relevance calculation. recommendation refining. learning path generation. and recommendation …,True,4swDjMAAAAAJ:kNdYIx-mwKoC,121,https://link.springer.com/chapter/10.1007/978-3-540-73549-6_88,15813084399833721447,/scholar?cites=15813084399833721447,,,https://www.researchgate.net/profile/Kenji_Mase/publication/221601228_Ontology-Based_Semantic_Recommendation_for_Context-Aware_E-Learning/links/00b495187aa8466f17000000.pdf,0,0,0
1278917,Multipoint measuring system for video and sound-100-camera and microphone system,2006,Toshiaki Fujii and Kensaku Mori and Kazuya Takeda and Kenji Mase and Masayuki Tanimoto and Yasuhito Suenaga,,,,437-440,IEEE,"We developed a novel multipoint measurement system capable of acquiring video and sound at more than 100 points in a ""synchronized"" manner. In this paper. we first describe the specification of the system and how the system works in detail. Then we report some experimental results that confirm the performance of the system. We also describe test data set we provided for MPEG (moving picture experts group) multi-viewpoint video coding activities. Using this system. we are planning to conduct projects to measure humans and their activities. collect a large volume of real-world data of video and sound. and release them to the public",True,4swDjMAAAAAJ:W7OEmFMy1HYC,100,https://ieeexplore.ieee.org/abstract/document/4036630/,42340561104446254,/scholar?cites=42340561104446254,,,https://www.researchgate.net/profile/Kenji_Mase/publication/37503199_MULTIPOINT_MEASURING_SYSTEM_FOR_VIDEO_AND_SOUND_-_100_-_camera_and_microphone_system_-/links/00b495187aa8fdaaa0000000/MULTIPOINT-MEASURING-SYSTEM-FOR-VIDEO-AND-SOUND-100-camera-and-microphone-system.pdf,0,0,0
1278918,Survey over image thresholding techniques and quantitative performance evaluation,2004,Mehmet Sezgin and Bülent Sankur,13,,1,146-165,International Society for Optics and Photonics,We conduct an exhaustive survey of image thresholding methods. categorize them. express their formulas under a uniform notation. and finally carry their performance comparison. The thresholding methods are categorized according to the information they are exploiting. such as histogram shape. measurement space clustering. entropy. object attributes. spatial correlation. and local gray-level surface. 40 selected thresholding methods from various categories are compared in the context of nondestructive testing applications as well as for document images. The comparison is based on the combined performance measures. We identify the thresholding algorithms that perform uniformly better over nondestructive testing and document image applications.© 2004 SPIE and IS&T.[DOI: 10.1117/1.1631316],True,MEIZpk0AAAAJ:u5HHmVD_uO8C,5615,https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-13/issue-1/0000/Survey-over-image-thresholding-techniques-and-quantitative-performance-evaluation/10.1117/1.1631315.short,15528858675306988745,/scholar?cites=15528858675306988745,,,https://www.researchgate.net/profile/M_Sezgin/publication/309967669_Image_thresholding_techniques_A_survey_over_categories/links/5aab63e4aca272d39cd7b5dc/Image-thresholding-techniques-A-survey-over-categories.pdf,0,0,0
1278919,Observer-dependent variability of the thresholding step in the quantitative analysis of soil images and X-ray microtomography data,2010,Philippe C Baveye and Magdeline Laba and Wilfred Otten and Liesbeth Bouckaert and Patricia Dello Sterpaio and Rohit R Goswami and Dmitri Grinev and Alasdair Houston and Yaoping Hu and Jianli Liu and Sacha Mooney and Radoslaw Pajor and Steven Sleutel and Ana Tarquis and Wei Wang and Qiao Wei and Mehmet Sezgin,157,Geoderma,1-2,51-63,Elsevier,For the investigation of many geometrical features of soils. computer-assisted image analysis has become a method of choice over the last few decades. This analysis involves numerous steps. regarding which subjective decisions have to be made by the individuals conducting the research. This is particularly the case with the thresholding step. required to transform the original (color or greyscale) images into the type of binary representation (e.g.. pores in white. solids in black) needed for fractal analysis or simulation with Lattice–Boltzmann models. Limited information exists at present on whether different observers. analyzing the same soil. would be likely to obtain similar results. In this general context. the first objective of the research reported in this article was to determine. through a so-called “round-robin” test. how much variation exists among the outcomes of various image thresholding strategies (including …,True,MEIZpk0AAAAJ:2osOgNQ5qMEC,165,https://www.sciencedirect.com/science/article/pii/S0016706110000923,8995728187329248535,/scholar?cites=8995728187329248535,,,https://www.academia.edu/download/45650361/Observer-dependent_variability_of_the_th20160515-602-lqxtye.pdf,0,0,0
1278920,Selection of thresholding methods for nondestructive testing applications,2001,Mehmet Sezgin and Bülent Sankur,3,,,764-767,IEEE,In nondestructive testing (NDT) applications based on image analysis. image segmentation is the most important step in the extraction of defective regions of materials. An effective and very simple method of image segmentation. especially in NDT applications. is image thresholding. In an effort to present a quantitative evaluation of image thresholding methods NDT applications. 41 thresholding algorithms are compared. They are grouped in six categories based on the information they are exploiting. such as histogram shape. object attribute or clustering behavior. etc. Performance assessment is based on the weighted combination of four complementary objective metrics. Based on the results of such NDT images as defective thermal. ultrasonic. eddy current. etc.. the thresholding algorithms that perform well over the majority of cases are established and a mixture thresholding scheme is proposed.,True,MEIZpk0AAAAJ:u-x6o8ySG0sC,121,https://ieeexplore.ieee.org/abstract/document/958231/,261861639666173191,/scholar?cites=261861639666173191,,,https://www.researchgate.net/profile/Bulent_Sankur/publication/224074103_Selection_of_thresholding_methods_for_nondestructive_testing_applications/links/55c87c4e08aea2d9bdc8c9b9/Selection-of-thresholding-methods-for-nondestructive-testing-applications.pdf,0,0,0
1278921,An improved design of planar elliptical dipole antenna for UWB applications,2010,Hakk Nazli and Emrullah Bicak and Bahattin Turetken and Mehmet Sezgin,9,IEEE antennas and wireless propagation letters,,264-267,IEEE,In this letter. an enhanced planar elliptical dipole antenna design for ultrawideband (UWB) communication and impulse radar systems is presented. The printed-circuit-elliptical (PCE) antenna has been investigated to be an effective radiator for UWB applications. To enhance gain and return loss bandwidth of the antenna. elliptical slots are used on the dipole arms. The gain performance of the antenna has been increased by means of elliptical slots in the frequency range from 2.7 to 11 GHz. The standing wave ratio is less than 2 (SWR < 2) along 94.4% of operation bandwidth from 1.1 to 11 GHz. The radiation pattern in E- and H-plane for certain frequencies. the return loss. and the gain performance are presented with the experimental and simulation results. Moreover. the time domain analysis of the antenna is presented. The antenna introduces low-level ringing and pulse distortion. Consequently. the antenna is …,True,MEIZpk0AAAAJ:qjMakFHDy7sC,120,https://ieeexplore.ieee.org/abstract/document/5439860/,2461713800452999170,/scholar?cites=2461713800452999170,,,https://www.academia.edu/download/46860228/An_Improved_Design_of_Planar_Elliptical_20160628-27578-rj7wfu.pdf,0,0,0
1278922,A new dichotomization technique to multilevel thresholding devoted to inspection applications,2000,Mehmet Sezgin and Ramazan Taşaltın,21,Pattern Recognition Letters,2,151-161,North-Holland,In this paper. a new dichotomization technique is proposed for multilevel thresholding. The proposed method is based on selection of the consistent peak location of the correlation function as threshold value over the interested histogram region. Different dichotomization processes are also adapted to the multilevel thresholding proposed by Yen et al. (Yen. J.C.. Chang. F.J.. Chang. S.. 1995. IEEE Trans. Image Process. 4 (3). 370–378). Finally an evaluation is performed for different dichotomization processes and a comparative study is performed over the set of some real images for different methods. It is observed that the proposed method gives consistent results in the sense of human perception and gives satisfactory results to find uniform regions in the image plane.,True,MEIZpk0AAAAJ:9yKSN-GCB0IC,104,https://www.sciencedirect.com/science/article/pii/S0167865599001427,4560828995284189239,/scholar?cites=4560828995284189239,,,,0,0,0
1278923,A least squares approach to buried object detection using ground penetrating radar,2010,Ahmet Burak Yoldemir and Mehmet Sezgin,11,IEEE Sensors Journal,6,1337-1341,IEEE,In this study. we utilize the least squares formulation to solve the real-time buried object detection problem. Least squares estimation is used to estimate the next ground penetrating radar (GPR) signal from previous samples. where there is no underground object. If the measured GPR signal is considerably different than the estimated signal. presence of an underground object is concluded. In order to attain real-time performance. Cholesky factorization is used when solving the linear systems. The proposed approach is tested on an extensive data set of different surrogate mines and other objects that are commonly encountered under the ground. The data are collected from three different terrains with different soil types to reveal the true performance of the method. It is demonstrated that our approach achieves almost 100% performance with a false alarm rate of approximately 10% on real GPR data collected with a …,True,MEIZpk0AAAAJ:0EnyYjriUFMC,32,https://ieeexplore.ieee.org/abstract/document/5629346/,15935423575090538319,/scholar?cites=15935423575090538319,,,https://www.researchgate.net/profile/M_Sezgin/publication/224193407_A_Least_Squares_Approach_to_Buried_Object_Detection_Using_Ground_Penetrating_Radar/links/5d107aaf299bf1547c795859/A-Least-Squares-Approach-to-Buried-Object-Detection-Using-Ground-Penetrating-Radar.pdf,0,0,0
1278924,Getting the bugs out: A portable harmonic radar system for electronic countersurveillance applications,2015,Huseyin Aniktar and Dursun Baran and Enes Karav and Eren Akkaya and Y Serdar Birecik and Mehmet Sezgin,16,IEEE Microwave Magazine,10,40-52,IEEE,The concept of a radar that detects semiconductor and metallic objects by monitoring second and third harmonic reradiations was conceived over 35 years ago. Called harmonic or nonlinear [1]. [2]. these radars can transmit at one or multiple frequencies and then receive the reflected signals at. or close to. the harmonic frequencies. Recently. harmonic radars have been used in different applications such as insect and bee tracking. vital-sign monitoring. antitheft systems [3]. vehicular detection and identification. and countersurveillance [4]-[7]. Important design metrics for harmonic radars include operating frequencies. waveforms. polarizations. power levels. false-alarm rates. and detection sensitivity and range [5].,True,MEIZpk0AAAAJ:lSLTfruPkqcC,25,https://ieeexplore.ieee.org/abstract/document/7298555/,11978311367939930422,/scholar?cites=11978311367939930422,,,,0,0,0
1278925,Simultaneous buried object detection and imaging technique utilizing fuzzy weighted background calculation and target energy moments on ground penetrating radar data,2011,Mehmet Sezgin,2011,EURASIP Journal on Advances in Signal Processing,1,1-12,SpringerOpen,In this article. a simultaneous buried object detection and imaging method is proposed for time domain ground penetrating radar (GPR) data. Fuzzy weighted background removal is applied to the data through a sliding window and then target energy functions are obtained by means of convolution summations of consecutive A-scan signals in an appropriate manner. An auxiliary detection function is proposed as an emphasized detection test statistic and then an automatic detection warning signal creation method is devised. The proposed method has been tested over a set of small-sized surrogate anti-personnel (AP) mines which are not easily detectable and medium-sized surrogate AP and Anti-tank mines. The results are promising as nearly full detection performance. Zero false alarm rate is achieved in this dataset without remarkable corruption in estimated target GPR images. Moreover. it is observed that the noise immunity of the proposed method is highly satisfactory in terms of detection probability.,True,MEIZpk0AAAAJ:4DMP91E08xMC,23,https://asp-eurasipjournals.springeropen.com/articles/10.1186/1687-6180-2011-55,13593771287376993056,/scholar?cites=13593771287376993056,,,https://asp-eurasipjournals.springeropen.com/articles/10.1186/1687-6180-2011-55,0,0,0
1278926,Investigation of convenient antenna designs for ultra-wide band GPR systems,2007,Ahmet Serdar Turk and Demet Armagan Sahinkaya and M Sezgin and H Nazli,,,,192-196,IEEE,This paper proposes the planar and 3-dimensional ultra-wide band (UWB) antenna types suitable for hand-held and vehicle mounted impulse GPR systems. On this scope. bow-tie. spiral. TEM horn. dielectric-loaded Vivaldi. multi-sensor adaptive and array model antenna configurations are designed. simulated and measured. The numerical and experimental results are presented with performance comparisons.,True,MEIZpk0AAAAJ:YsMSGLbcyi4C,22,https://ieeexplore.ieee.org/abstract/document/4278873/,5844250400871816686,/scholar?cites=5844250400871816686,,,https://www.researchgate.net/profile/Ahmet_Turk/publication/4264307_Investigation_of_Convenient_Antenna_Designs_for_Ultra-Wide_Band_GPR_Systems/links/55d48bcb08aec1b042a15675/Investigation-of-Convenient-Antenna-Designs-for-Ultra-Wide-Band-GPR-Systems.pdf,0,0,0
1278927,Real-time detection of buried objects by using GPR,2004,Mehmet Sezgin and Fatih Kurugollu and Isa Tasdelen and Savas Ozturk,5415,,,447-455,International Society for Optics and Photonics,In this work the detection process of buried objects is presented utilizing Ground Penetrating Radar (GPR). Background removal algorithm is used to obtain the target signature and correlation process is performed to reveal the reflected target energy  Then. a detection warning signal is created depending on a special process. In this work. pulsed GPR system with 1 GHz bandwith is used. Scanning speed is 0.33cm/sec in the sweeping direction and this process is repeated in the walking direction with 4 cm spatial resolution.,True,MEIZpk0AAAAJ:IjCSPb-OGe4C,21,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5415/0000/Real-time-detection-of-buried-objects-by-using-GPR/10.1117/12.541128.short,12768646384573979184,/scholar?cites=12768646384573979184,,,https://www.researchgate.net/profile/M_Sezgin/publication/251809402_Buried_object_detection_by_using_GPR/links/5d10807fa6fdcc2462a036d8/Buried-object-detection-by-using-GPR.pdf,0,0,0
1278928,Quality inspection in PCBs and SMDs using computer vision techniques,1994,D Demir and S Birecik and F Kurugollu and M Sezgin and IO Bucak and B Sankur and E Anarim,2,,,857-861,IEEE,This paper addresses the task of automating the visual inspection of printed circuit board with through hole technique. and surface mount devices (SMD). We have focused on the following quality control of the mounted component using either technology: component twist. or pin defects. A comparison of binarization techniques as well as twist angle estimation methods have been carried out. For inspection of pin defects various morphological image processing techniques have been applied.< >,True,MEIZpk0AAAAJ:UeHWp8X0CEIC,13,https://ieeexplore.ieee.org/abstract/document/397899/,9942949382961032677,/scholar?cites=9942949382961032677,,,https://www.researchgate.net/profile/Emin_Anarim/publication/272827796_Baskili_devre_Plaketlerindeki_lehim_adaciklarinin_matematiksel_morfoloji_yardimiyla_incelenmesi/links/55c0ce1b08ae092e96670109/Baskili-devre-Plaketlerindeki-lehim-adaciklarinin-matematiksel-morfoloji-yardimiyla-incelenmesi.pdf,0,0,0
1278929,Switching convolutional neural network for crowd counting,2017,Deepak Babu Sam and Shiv Surya and R Venkatesh Babu,,,,5744-5752,,We propose a novel crowd counting model that maps a given crowd scene to its density. Crowd analysis is compounded by myriad of factors like inter-occlusion between people due to extreme crowding. high similarity of appearance between people and background elements. and large variability of camera view-points. Current state-of-the art approaches tackle these factors by using multi-scale CNN architectures. recurrent networks and late fusion of features from multi-column CNN with different receptive fields. We propose switching convolutional neural network that leverages variation of crowd density within an image to improve the accuracy and localization of the predicted crowd count. Patches from a grid within a crowd scene are relayed to independent CNN regressors based on crowd count prediction quality of the CNN established during training. The independent CNN regressors are designed to have different receptive fields and a switch classifier is trained to relay the crowd scene patch to the best CNN regressor. We perform extensive experiments on all major crowd counting datasets and evidence better performance compared to current state-of-the-art methods. We provide interpretable representations of the multichotomy of space of crowd scene patches inferred from the switch. It is observed that the switch relays an image patch to a particular CNN column based on density of crowd.,True,cVg7HrEAAAAJ:-FonjvnnhkoC,524,http://openaccess.thecvf.com/content_cvpr_2017/html/Sam_Switching_Convolutional_Neural_CVPR_2017_paper.html,18278994156144407180,/scholar?cites=18278994156144407180,,,https://openaccess.thecvf.com/content_cvpr_2017/papers/Sam_Switching_Convolutional_Neural_CVPR_2017_paper.pdf,0,0,0
1278930,Crowdnet: A deep convolutional network for dense crowd counting,2016,Lokesh Boominathan and Srinivas SS Kruthiventi and R Venkatesh Babu,,,,640-644,,Our work proposes a novel deep learning framework for estimating crowd density from static images of highly dense crowds. We use a combination of deep and shallow. fully convolutional networks to predict the density map for a given crowd image. Such a combination is used for effectively capturing both the high-level semantic information (face/body detectors) and the low-level features (blob detectors). that are necessary for crowd counting under large scale variations. As most crowd datasets have limited training samples (< 100 images) and deep learning based approaches require large amounts of training data. we perform multi-scale data augmentation. Augmenting the training samples in such a manner helps in guiding the CNN to learn scale invariant representations. Our method is tested on the challenging UCF_CC_50 dataset. and shown to outperform the state of the art methods.,True,cVg7HrEAAAAJ:2KloaMYe4IUC,359,https://dl.acm.org/doi/abs/10.1145/2964284.2967300,13728399135890034755,/scholar?cites=13728399135890034755,,,https://arxiv.org/pdf/1608.06197,0,0,0
1278931,Deepfix: A fully convolutional neural network for predicting human eye fixations,2017,Srinivas SS Kruthiventi and Kumar Ayush and R Venkatesh Babu,26,IEEE Transactions on Image Processing,9,4446-4456,IEEE,Understanding and predicting the human visual attention mechanism is an active area of research in the fields of neuroscience and computer vision. In this paper. we propose DeepFix. a fully convolutional neural network. which models the bottom-up mechanism of visual attention via saliency prediction. Unlike classical works. which characterize the saliency map using various hand-crafted features. our model automatically learns features in a hierarchical fashion and predicts the saliency map in an end-to-end manner. DeepFix is designed to capture semantics at multiple scales while taking global context into account. by using network layers with very large receptive fields. Generally. fully convolutional nets are spatially invariant-this prevents them from modeling location-dependent patterns (e.g.. centre-bias). Our network handles this by incorporating a novel location-biased convolutional layer. We evaluate our …,True,cVg7HrEAAAAJ:5awf1xo2G04C,351,https://ieeexplore.ieee.org/abstract/document/7937829/,5006210172099689340,/scholar?cites=5006210172099689340,,,https://arxiv.org/pdf/1510.02927,0,0,0
1278932,Data-free parameter pruning for deep neural networks,2015,Suraj Srinivas and R Venkatesh Babu,,arXiv preprint arXiv:1507.06149,,,,Deep Neural nets (NNs) with millions of parameters are at the heart of many state-of-the-art computer vision systems today. However. recent works have shown that much smaller models can achieve similar levels of performance. In this work. we address the problem of pruning parameters in a trained NN model. Instead of removing individual weights one at a time as done in previous works. we remove one neuron at a time. We show how similar neurons are redundant. and propose a systematic way to remove them. Our experiments in pruning the densely connected layers show that we can remove upto 85\% of the total parameters in an MNIST-trained network. and about 35\% for AlexNet without significantly affecting performance. Our method can be applied on top of most networks with a fully connected layer to give a smaller network.,True,cVg7HrEAAAAJ:prdVHNxh-e8C,335,https://arxiv.org/abs/1507.06149,11051139802386516763,/scholar?cites=11051139802386516763,,,https://arxiv.org/pdf/1507.06149,0,0,0
1278933,No-reference image quality assessment using modified extreme learning machine classifier,2009,Sundaram Suresh and R Venkatesh Babu and Hyoung J Kim,9,Applied soft computing,2,541-552,Elsevier,In this paper. we present a machine learning approach to measure the visual quality of JPEG-coded images. The features for predicting the perceived image quality are extracted by considering key human visual sensitivity (HVS) factors such as edge amplitude. edge length. background activity and background luminance. Image quality assessment involves estimating the functional relationship between HVS features and subjective test scores. The quality of the compressed images are obtained without referring to their original images (‘No Reference’ metric). Here. the problem of quality estimation is transformed to a classification problem and solved using extreme learning machine (ELM) algorithm. In ELM. the input weights and the bias values are randomly chosen and the output weights are analytically calculated. The generalization performance of the ELM algorithm for classification problems with imbalance in …,True,cVg7HrEAAAAJ:MXK_kJrjxJIC,260,https://www.sciencedirect.com/science/article/pii/S1568494608001075,7430655065538722690,/scholar?cites=7430655065538722690,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.5050&rep=rep1&type=pdf,0,0,0
1278934,Video object segmentation: a compressed domain approach,2004,R Venkatesh Babu and KR Ramakrishnan and SH Srinivasan,14,IEEE Transactions on Circuits and Systems for Video Technology,4,462-474,IEEE,This paper addresses the problem of extracting video objects from MPEG compressed video. The only cues used for object segmentation are the motion vectors which are sparse in MPEG. A method for automatically estimating the number of objects and extracting independently moving video objects using motion vectors is presented here. First. the motion vectors are accumulated over a few frames to enhance the motion information. which are further spatially interpolated to get dense motion vectors. The final segmentation. using the dense motion vectors. is obtained by applying the expectation maximization (EM) algorithm. A block-based affine clustering method is proposed for determining the number of appropriate motion models to be used for the EM step and the segmented objects are temporally tracked to obtain the video objects. Finally. a strategy for edge refinement is proposed to extract the precise object …,True,cVg7HrEAAAAJ:u5HHmVD_uO8C,200,https://ieeexplore.ieee.org/abstract/document/1281820/,7346120968276042694,/scholar?cites=7346120968276042694,,,https://www.researchgate.net/profile/Kalpathi_Ramakrishnan/publication/3308637_Video_Object_Segmentation_A_Compressed_Domain_Approach/links/02e7e53b4c96a49a4d000000/Video-Object-Segmentation-A-Compressed-Domain-Approach.pdf,0,0,0
1278935,DeepFuse: A Deep Unsupervised Approach for Exposure Fusion With Extreme Exposure Image Pairs,2017,K. Ram Prabhakar and V Sai Srikar and R. Venkatesh Babu,,,,4714-4722,http://openaccess.thecvf.com/content_ICCV_2017/papers/Prabhakar_DeepFuse_A_Deep_ICCV_2017_paper.pdf,As explained in section 4.1 of the main paper. in this experiment the CNN is trained in the presence of a ground truth. We have considered one of the results by Mertens [8] and GFF [2] for ground truth. The results of two methods are evaluated using MEF SSIM [6]. the one with maximum MEF SSIM score is selected as ground truth. The choice of loss function to calculate error between ground truth and estimated output is very crucial for training a CNN in supervised fashion. The Mean Square Error or l2 loss function is generally chosen as default cost function for training CNN. l2 cost function is desired for its smooth optimization properties. While l2 loss function is better suited for classification tasks. they may not be a correct choice for image processing tasks. It is well known phenomena that MSE does not correlate well with human perception of image quality [12]. In order to obtain visually pleasing result. the loss function should be well correlated with HVS. like Structural Similarity Index (SSIM)[12]. We have trained proposed CNN model using various loss functions. We have compared the results among l1. l2 and SSIM. In this section we shall denote the ground truth image and the network output as Gfused and Ofused respectively. l1 loss: l1 loss is defined as the absolute difference between the two quantities that are compared. In our experiment the two quantities compared are the network output and the ground truth. l1 loss for a patch P is expressed as.,True,cVg7HrEAAAAJ:TIZ-Mc8IlK0C,172,https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Prabhakar_DeepFuse_A_Deep_ICCV_2017_supplemental.pdf,5304347345838285786,/scholar?cites=5304347345838285786,,,https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Prabhakar_DeepFuse_A_Deep_ICCV_2017_supplemental.pdf,0,0,0
1278936,A taxonomy of deep convolutional neural nets for computer vision,2016,Suraj Srinivas and Ravi Kiran Sarvadevabhatla and Konda Reddy Mopuri and Nikita Prabhu and Srinivas SS Kruthiventi and R Venkatesh Babu,2,Frontiers in Robotics and AI,,36,Frontiers,"Traditional architectures for solving computer vision problems and the degree of success they enjoyed have been heavily reliant on hand-crafted features. However. of late. deep learning techniques have offered a compelling alternative -- that of automatically learning problem-specific features. With this new paradigm. every problem in computer vision is now being re-examined from a deep learning perspective. Therefore. it has become important to understand what kind of deep networks are suitable for a given problem. Although general surveys of this fast-moving paradigm (i.e. deep-networks) exist. a survey specific to computer vision is missing. We specifically consider one form of deep networks widely used in computer vision - convolutional neural networks (CNNs). We start with ""AlexNet'' as our base CNN and then examine the broad variations proposed over time to suit different applications. We hope that our recipe-style survey will serve as a guide. particularly for novice practitioners intending to use deep-learning techniques for computer vision.",True,cVg7HrEAAAAJ:VL0QpB8kHFEC,162,https://www.frontiersin.org/articles/10.3389/frobt.2015.00036/full,5224762766552498426,/scholar?cites=5224762766552498426,,,https://www.frontiersin.org/articles/10.3389/frobt.2015.00036/full,0,0,0
1278937,Robust tracking with motion estimation and local kernel-based color modeling,2007,R Venkatesh Babu and Patrick Perez and Patrick Bouthemy,25,Image and Vision Computing,8,1205-1216,Elsevier,Visual tracking has been a challenging problem in computer vision over the decades. The applications of visual tracking are far-reaching. ranging from surveillance and monitoring to smart rooms. Mean-shift tracker. which gained attention recently. is known for tracking objects in a cluttered environment. In this work. we propose a new method to track objects by combining two well-known trackers. sum-of-squared differences (SSD) and color-based mean-shift (MS) tracker. In the proposed combination. the two trackers complement each other by overcoming their respective disadvantages. The rapid model change in SSD tracker is overcome by the MS tracker module. while the inability of MS tracker to handle large displacements is circumvented by the SSD module. The performance of the combined tracker is illustrated to be better than those of the individual trackers. for tracking fast-moving objects. Since the MS …,True,cVg7HrEAAAAJ:u-x6o8ySG0sC,161,https://www.sciencedirect.com/science/article/pii/S0262885606002265,665894441765258916,/scholar?cites=665894441765258916,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.2736&rep=rep1&type=pdf,0,0,0
1278938,Deligan: Generative adversarial networks for diverse and limited data,2017,Swaminathan Gurumurthy and Ravi Kiran Sarvadevabhatla and R Venkatesh Babu,,,,166-174,,"A class of recent approaches for generating images. called Generative Adversarial Networks (GAN). have been used to generate impressively realistic images of objects. bedrooms. handwritten digits and a variety of other image modalities. However. typical GAN-based approaches require large amounts of training data to capture the diversity across the image modality. In this paper. we propose DeLiGAN--a novel GAN-based architecture for diverse and limited training data scenarios. In our approach. we reparameterize the latent generative space as a mixture model and learn the mixture model's parameters along with those of GAN. This seemingly simple modification to the GAN framework is surprisingly effective and results in models which enable diversity in generated samples although trained with limited data. In our work. we show that DeLiGAN can generate images of handwritten digits. objects and hand-drawn sketches. all using limited amounts of data. To quantitatively characterize intra-class diversity of generated samples. we also introduce a modified version of"" inception-score"". a measure which has been found to correlate well with human assessment of generated samples.",True,cVg7HrEAAAAJ:ML0RJ9NH7IQC,159,http://openaccess.thecvf.com/content_cvpr_2017/html/Gurumurthy_DeLiGAN__Generative_CVPR_2017_paper.html,16366073296318004852,/scholar?cites=16366073296318004852,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Gurumurthy_DeLiGAN__Generative_CVPR_2017_paper.pdf,0,0,0
1278939,Divide and grow: Capturing huge diversity in crowd images with incrementally growing cnn,2018,Deepak Babu Sam and Neeraj N Sajjan and R Venkatesh Babu and Mukundhan Srinivasan,,,,3618-3626,,Automated counting of people in crowd images is a challenging task. The major difficulty stems from the large diversity in the way people appear in crowds. In fact. features available for crowd discrimination largely depend on the crowd density to the extent that people are only seen as blobs in a highly dense scene. We tackle this problem with a growing CNN which can progressively increase its capacity to account for the wide variability seen in crowd scenes. Our model starts from a base CNN density regressor. which is trained in equivalence on all types of crowd images. In order to adapt with the huge diversity. we create two child regressors which are exact copies of the base CNN. A differential training procedure divides the dataset into two clusters and fine-tunes the child networks on their respective specialties. Consequently. without any hand-crafted criteria for forming specialties. the child regressors become experts on certain types of crowds. The child networks are again split recursively. creating two experts at every division. This hierarchical training leads to a CNN tree. where the child regressors are more fine experts than any of their parents. The leaf nodes are taken as the final experts and a classifier network is then trained to predict the correct specialty for a given test image patch. The proposed model achieves higher count accuracy on major crowd datasets. Further. we analyse the characteristics of specialties mined automatically by our method.,True,cVg7HrEAAAAJ:k8Z6L05lTy4C,140,http://openaccess.thecvf.com/content_cvpr_2018/html/Sam_Divide_and_Grow_CVPR_2018_paper.html,6792938529056565258,/scholar?cites=6792938529056565258,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Sam_Divide_and_Grow_CVPR_2018_paper.pdf,0,0,0
1278940,Unsupervised feature selection using feature similarity,2002,Pabitra Mitra and CA Murthy and Sankar K.  Pal,24,IEEE transactions on pattern analysis and machine intelligence,3,301-312,IEEE,In this article. we describe an unsupervised feature selection algorithm suitable for data sets. large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and. therefore. is fast. A new feature similarity measure. called maximum information compression index. is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm. in terms of speed and performance. is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.,True,--9udFEAAAAJ:HDshCWvjkbEC,1615,https://ieeexplore.ieee.org/abstract/document/990133/,12075535613665948590,/scholar?cites=12075535613665948590,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/5222/ITOPAAMI-24-3-P301-312.pdf?sequence=1&isAllowed=y,0,0,0
1278941,Unsupervised feature selection using feature similarity,2002,Pabitra Mitra and CA Murthy and Sankar K.  Pal,24,IEEE transactions on pattern analysis and machine intelligence,3,301-312,IEEE,In this article. we describe an unsupervised feature selection algorithm suitable for data sets. large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and. therefore. is fast. A new feature similarity measure. called maximum information compression index. is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm. in terms of speed and performance. is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.,True,--9udFEAAAAJ:Se3iqnhoufwC,1615,https://ieeexplore.ieee.org/abstract/document/990133/,12075535613665948590,/scholar?cites=12075535613665948590,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/5222/ITOPAAMI-24-3-P301-312.pdf?sequence=1&isAllowed=y,0,0,0
1278942,In search of optimal clusters using genetic algorithms,1996,Chivukula A Murthy and Nirmalya Chowdhury,17,Pattern Recognition Letters,8,825-832,North-Holland,Genetic Algorithms (GAs) are generally portrayed as search procedures which can optimize functions based on a limited sample of function values. In this paper. GAs have been used in an attempt to optimize a specified objective function related to a clustering problem. Several experiments on synthetic and real life data sets show the utility of the proposed method. K-Means is one of the most popular methods adopted to solve the clustering problem. Analysis of the experimental results shows that the proposed method may improve the final output of K-Means where an improvement is possible.,True,--9udFEAAAAJ:iH-uZ7U-co4C,396,https://www.sciencedirect.com/science/article/pii/0167865596000438,789929726777380450,/scholar?cites=789929726777380450,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/4285/Binder1.pdf?sequence=1&isAllowed=y,0,0,0
1278943,Hue-preserving color image enhancement without gamut problem,2003,Sarif Kumar Naik and CA Murthy,12,IEEE Transactions on image processing,12,1591-1598,IEEE,The first step in many techniques for processing intensity and saturation in color images keeping hue unaltered is the transformation of the image data from RGB space to other color spaces such as LHS. HSI. YIQ. HSV. etc. Transforming from one space to another and processing in these spaces usually generate a gamut problem. i.e.. the values of the variables may not be in their respective intervals. We study enhancement techniques for color images theoretically in a generalized setup. A principle is suggested to make the transformations gamut-problem free. Using the same principle. a class of hue-preserving. contrast-enhancing transformations is proposed; they generalize existing grey scale contrast intensification techniques to color images. These transformations are also seen to bypass the above mentioned color coordinate transformations for image enhancement. The developed principle is used to …,True,--9udFEAAAAJ:bEWYMUwI8FkC,394,https://ieeexplore.ieee.org/abstract/document/1257395/,14324397429963594051,/scholar?cites=14324397429963594051,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/4703/1/hue%20preserving%20color%20image%20enhancement%20without%20gamut%20problem.pdf,0,0,0
1278944,Genetic algorithm with elitist model and its convergence,1996,Dinabandhu Bhandari and CA Murthy and Sankar K Pal,10,International journal of pattern recognition and artificial intelligence,06,731-747,World Scientific Publishing Company,In this article. the genetic algorithm with elitist model (EGA) is modeled as a finite state Markov chain. A state in the Markov chain denotes a population together with a potential string. Proof for the convergence of an EGA to the best chromosome (string). among all possible chromosomes. is provided here. Mutation operation has been found to be essential for convergence. It has been shown that an EGA converges to the global optimal solution with any choice of initial population.,True,--9udFEAAAAJ:TFP_iSt0sucC,244,https://www.worldscientific.com/doi/abs/10.1142/S0218001496000438,12891207094329096506,/scholar?cites=12891207094329096506,,,,0,0,0
1278945,Thresholding in edge detection: a statistical approach,2004,Rishi R Rakesh and Probal Chaudhuri and CA Murthy,13,IEEE Transactions on image processing,7,927-936,IEEE,Many edge detectors are available in image processing literature where the choices of input parameters are to be made by the user. Most of the time. such choices are made on an ad-hoc basis. In this article. an edge detector is proposed where thresholding is performed using statistical principles. Local standardization of thresholds for each individual pixel (local thresholding). which depends upon the statistical variability of the gradient vector at that pixel. is done. Such a standardized statistic based on the gradient vector at each pixel is used to determine the eligibility of the pixel to be an edge pixel. The results obtained from the proposed method are found to be comparable to those from many well-known edge detectors. However. the values of the input parameters providing the appreciable results in the proposed detector are found to be more stable than other edge detectors and possess statistical interpretation.,True,--9udFEAAAAJ:k_IJM867U9cC,200,https://ieeexplore.ieee.org/abstract/document/1303645/,14681041796386011622,/scholar?cites=14681041796386011622,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/2707/1/THRESHOLDING%20IN%20EDGE%20DETECTION.pdf,0,0,0
1278946,Density-based multiscale data condensation,2002,Pabitra Mitra and CA Murthy and Sankar K.  Pal,24,IEEE Transactions on pattern analysis and machine intelligence,6,734-747,IEEE,A problem gaining interest in pattern recognition applied to data mining is that of selecting a small representative subset from a very large data set. In this article. a nonparametric data reduction scheme is suggested. It attempts to represent the density underlying the data. The algorithm selects representative points in a multiscale fashion which is novel from existing density-based approaches. The accuracy of representation by the condensed set is measured in terms of the error in density estimates of the original and reduced sets. Experimental studies on several real life data sets show that the multiscale approach is superior to several related condensation methods both in terms of condensation ratio and estimation error. The condensed set obtained was also experimentally shown to be effective for some important data mining tasks like classification. clustering. and rule generation on large data sets. Moreover. it is …,True,--9udFEAAAAJ:M3NEmzRMIkIC,186,https://ieeexplore.ieee.org/abstract/document/1008381/,15698933371529334287,/scholar?cites=15698933371529334287,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/5325/Density%20based%20multiscale%20data%20condensation-IEEEOPAAMI-24-6-2002-p%20734-747.pdf?sequence=1&isAllowed=y,0,0,0
1278947,Pattern classification with genetic algorithms,1995,Sanghamitra Bandyopadhyay and Chivukula A Murthy and Sankar K Pal,16,Pattern recognition letters,8,801-808,North-Holland,A method is proposed for finding decision boundaries. approximated by piecewise linear segments. for the classification of patterns in R 2 using an elitist model of a genetic algorithm. It involves the generation and placement of a set of lines (represented by strings) in the feature space that yields minimum misclassification. The effectiveness of the algorithm is demonstrated. for different parameter values. on both artificial data and speech data having non-linear class boundaries. Its comparison with the k-NN classifier is also made.,True,--9udFEAAAAJ:isC4tDSrTZIC,176,https://www.sciencedirect.com/science/article/pii/016786559500052I,454282385815003170,/scholar?cites=454282385815003170,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/4363/1/pattern%20classification.pdf,0,0,0
1278948,Technique for fractal image compression using genetic algorithm,1998,Suman K Mitra and CA Murthy and Malay Kumar Kundu,7,IEEE transactions on image processing,4,586-593,IEEE,A new method for fractal image compression is proposed using genetic algorithm (GA) with an elitist model. The self transformation property of images is assumed and exploited in the fractal image compression technique. The technique described utilizes the GA. which greatly decreases the search space for finding the self similarities in the given image. This article presents theory. implementation. and an analytical study of the proposed method along with a simple classification scheme. A comparison with other fractal-based image compression methods is also reported.,True,--9udFEAAAAJ:maZDTaKrznsC,174,https://ieeexplore.ieee.org/abstract/document/663505/,17026218180518078114,/scholar?cites=17026218180518078114,,,http://library.isical.ac.in:8080/jspui/bitstream/10263/4059/1/Binder2.pdf,0,0,0
1278949,A probabilistic active support vector learning algorithm,2004,Pabitra Mitra and CA Murthy and Sankar K Pal,26,IEEE Transactions on Pattern Analysis and Machine Intelligence,3,413-418,IEEE,The paper describes a probabilistic active learning strategy for support vector machine (SVM) design in large data applications. The learning strategy is motivated by the statistical query model. While most existing methods of active SVM learning query for points based on their proximity to the current separating hyperplane. the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. This enables the algorithm to have more robust and efficient learning capabilities. The confidence factor is estimated from local information using the k nearest neighbor principle. The effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance. query complexity. and training time.,True,--9udFEAAAAJ:JV2RwH3_ST0C,139,https://ieeexplore.ieee.org/abstract/document/1262340/,2656675381522684213,/scholar?cites=2656675381522684213,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/2848/Binder1.pdf?sequence=1&isAllowed=y,0,0,0
1278950,Fuzzy thresholding: mathematical framework. bound functions and weighted moving average technique,1990,Chivukula A Murthy and Sankar K Pal,11,Pattern Recognition Letters,3,197-206,North-Holland,The problem of histogram sharpening and thresholding by minimising greylevel fuzziness is considered. The earlier work on the said problem consists only of algorithms without mathematical justification of the findings. For example. the choices of appropriate membership function and the optimum value of its window size (band width) for detecting thresholds were made experimentally with iterative manner.The present work provides a complete theoretical formulation of the same and establishes the criteria regarding the choices of membership function and its window size (band width). The variation in membership function is seen to be restricted by bound functions. thus enabling the method of segmentation more flexible but effective. Finally. the method can be viewed as a weighted moving average technique. greyness ambiguity being the weights.,True,--9udFEAAAAJ:blknAaTinKkC,127,https://www.sciencedirect.com/science/article/pii/016786559090006N,7346649696459089773,/scholar?cites=7346649696459089773,,,http://library.isical.ac.in:8080/xmlui/bitstream/handle/10263/5683/Fuzzy%20thresolding-mathematical%20framework%20bounds%20functions....PRL-11-1990-%20p%20197-206.pdf?sequence=1&isAllowed=y,0,0,0
1278951,Advances in computational stereo,2003,Myron Z Brown and Darius Burschka and Gregory D Hager,25,,8,993-1008,IEEE,Extraction of three-dimensional structure of a scene from stereo images is a problem that has been studied by the computer vision community for decades. Early work focused on the fundamentals of image correspondence and stereo geometry. Stereo research has matured significantly throughout the years and many advances in computational stereo continue to be made. allowing stereo to be applied to new and more demanding problems. We review recent advances in computational stereo. focusing primarily on three important topics: correspondence methods. methods for occlusion. and real-time implementations. Throughout. we present tables that summarize and draw distinctions among key ideas and approaches. Where available. we provide comparative analyses and we make suggestions for analyses yet to be done.,True,y-MzVoUAAAAJ:u5HHmVD_uO8C,1722,https://ieeexplore.ieee.org/abstract/document/1217603/,17724155666798060845,/scholar?cites=17724155666798060845,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.7946&rep=rep1&type=pdf,0,0,0
1278952,Toward a fully autonomous UAV: Research platform for indoor and outdoor urban search and rescue,2012,Teodor Tomic and Korbinian Schmid and Philipp Lutz and Andreas Domel and Michael Kassecker and Elmar Mair and Iris Lynne Grixa and Felix Ruess and Michael Suppa and Darius Burschka,19,IEEE robotics & automation magazine,3,46-56,IEEE,Urban search and rescue missions raise special requirements on robotic systems. Small aerial systems provide essential support to human task forces in situation assessment and surveillance. As external infrastructure for navigation and communication is usually not available. robotic systems must be able to operate autonomously. A limited payload of small aerial systems poses a great challenge to the system design. The optimal tradeoff between flight performance. sensors. and computing resources has to be found. Communication to external computers cannot be guaranteed; therefore. all processing and decision making has to be done on board. In this article. we present an unmanned aircraft system design fulfilling these requirements. The components of our system are structured into groups to encapsulate their functionality and interfaces. We use both laser and stereo vision odometry to enable seamless …,True,y-MzVoUAAAAJ:R3hNpaxXUhUC,616,https://ieeexplore.ieee.org/abstract/document/6290694/,4931456332468538802,/scholar?cites=4931456332468538802,,,https://mediatum.ub.tum.de/doc/1285852/file.pdf,0,0,0
1278953,Adaptive and generic corner detection based on the accelerated segment test,2010,Elmar Mair and Gregory D Hager and Darius Burschka and Michael Suppa and Gerhard Hirzinger,,,,183-196,Springer. Berlin. Heidelberg,The efficient detection of interesting features is a crucial step for various tasks in Computer Vision. Corners are favored cues due to their two dimensional constraint and fast algorithms to detect them. Recently. a novel corner detection approach. FAST. has been presented which outperforms previous algorithms in both computational performance and repeatability. We will show how the accelerated segment test. which underlies FAST. can be significantly improved by making it more generic while increasing its performance.We do so by finding the optimal decision tree in an extended configuration space. and demonstrating how specialized trees can be combined to yield an adaptive and generic accelerated segment test. The resulting method provides high performance for arbitrary environments and so unlike FAST does not have to be adapted to a specific scene structure. We will also discuss how different …,True,y-MzVoUAAAAJ:Se3iqnhoufwC,592,https://link.springer.com/chapter/10.1007/978-3-642-15552-9_14,391822541355979121,/scholar?cites=391822541355979121,,,https://link.springer.com/content/pdf/10.1007/978-3-642-15552-9_14.pdf,0,0,0
1278954,An efficient ransac for 3d object recognition in noisy and occluded scenes,2010,Chavdar Papazov and Darius Burschka,,,,135-148,Springer. Berlin. Heidelberg,In this paper. we present an efficient algorithm for 3D object recognition in presence of clutter and occlusions in noisy. sparse and unsegmented range data. The method uses a robust geometric descriptor. a hashing technique and an efficient RANSAC-like sampling strategy. We assume that each object is represented by a model consisting of a set of points with corresponding surface normals. Our method recognizes multiple model instances and estimates their position and orientation in the scene. The algorithm scales well with the number of models and its main procedure runs in linear time in the number of scene points. Moreover. the approach is conceptually simple and easy to implement. Tests on a variety of real data sets show that the proposed method performs well on noisy and cluttered scenes in which only small parts of the objects are visible.,True,y-MzVoUAAAAJ:MXK_kJrjxJIC,245,https://link.springer.com/chapter/10.1007/978-3-642-19315-6_11,11817754947847914838,/scholar?cites=11817754947847914838,,,https://mediatum.ub.tum.de/doc/1287471/file.pdf,0,0,0
1278955,Effects of visual force feedback on robot-assisted surgical task performance,2008,Carol E Reiley and Takintope Akinbiyi and Darius Burschka and David C Chang and Allison M Okamura and David D Yuh,135,The Journal of thoracic and cardiovascular surgery,1,196-202,Mosby,Direct haptic (force or tactile) feedback is negligible in current surgical robotic systems. The relevance of haptic feedback in robot-assisted performances of surgical tasks is controversial. We studied the effects of visual force feedback. a haptic feedback surrogate. on tying surgical knots with fine sutures similar to those used in cardiovascular surgery.By using a modified da Vinci robotic system (Intuitive Surgical. Inc. Sunnyvale. Calif) equipped with force-sensing instrument tips and real-time visual force feedback overlays in the console image. 10 surgeons each tied 10 knots with and 10 knots without visual force feedback. Four surgeons had significant prior da Vinci experience. and the remaining 6 surgeons did not. Performance parameters. including suture breakage and secure knots. peak and standard deviation of applied forces. and completion times using 5-0 silk sutures. were recorded. Chi …,True,y-MzVoUAAAAJ:9yKSN-GCB0IC,231,https://www.sciencedirect.com/science/article/pii/S002252230701536X,15113159236800220854,/scholar?cites=15113159236800220854,,,https://www.sciencedirect.com/science/article/pii/S002252230701536X,0,0,0
1278956,Scale-invariant registration of monocular endoscopic images to CT-scans for sinus surgery,2005,Darius Burschka and Ming Li and Masaru Ishii and Russell H Taylor and Gregory D Hager,9,Medical Image Analysis,5,413-426,Elsevier,In this paper. we present a novel method for intra-operative registration directly from monocular endoscopic images. This technique has the potential to provide a more accurate surface registration at the surgical site than existing methods. It can operate autonomously from as few as two images and can be particularly useful in revision cases where surgical landmarks may be absent. A by-product of video registration is an estimate of the local surface structure of the anatomy. thus providing the opportunity to dynamically update anatomical models as the surgery progresses.Our approach is based on a previously presented method [Burschka. D.. Hager. G.D.. 2004. V-GPS (SLAM): – Vision-based inertial system for mobile robots. In: Proceedings of ICRA. 409–415] for reconstruction of a scaled 3D model of the environment from unknown camera motion. We use this scaled reconstruction as input to a PCA-based …,True,y-MzVoUAAAAJ:qjMakFHDy7sC,192,https://www.sciencedirect.com/science/article/pii/S1361841505000605,4202662081698521656,/scholar?cites=4202662081698521656,,,https://link.springer.com/content/pdf/10.1007/978-3-540-30136-3_51.pdf,0,0,0
1278957,DaVinci canvas: a telerobotic surgical system with integrated. robot-assisted. laparoscopic ultrasound capability,2005,Joshua Leven and Darius Burschka and Rajesh Kumar and Gary Zhang and Steve Blumenkranz and Xiangtian Donald Dai and Mike Awad and Gregory D Hager and Mike Marohn and Mike Choti and Chris Hasser and Russell H Taylor,,,,811-818,Springer. Berlin. Heidelberg,We present daVinci Canvas: a telerobotic surgical system with integrated robot-assisted laparoscopic ultrasound capability. DaVinci Canvas consists of the integration of a rigid laparoscopic ultrasound probe with the daVinci robot. video tracking of ultrasound probe motions. endoscope and ultrasound calibration and registration. autonomous robot motions. and the display of registered 2D and 3D ultrasound images. Although we used laparoscopic liver cancer surgery as a focusing application. our broader aim was the development of a versatile system that would be useful for many procedures.,True,y-MzVoUAAAAJ:d1gkVwhDpl0C,191,https://link.springer.com/chapter/10.1007/11566465_100,17489292817944650413,/scholar?cites=17489292817944650413,,,https://link.springer.com/content/pdf/10.1007/11566465_100.pdf,0,0,0
1278958,Rigid 3D geometry matching for grasping of known objects in cluttered scenes,2012,Chavdar Papazov and Sami Haddadin and Sven Parusel and Kai Krieger and Darius Burschka,31,The International Journal of Robotics Research,4,538-553,SAGE Publications,In this paper. we present an efficient 3D object recognition and pose estimation approach for grasping procedures in cluttered and occluded environments. In contrast to common appearance-based approaches. we rely solely on 3D geometry information. Our method is based on a robust geometric descriptor. a hashing technique and an efficient. localized RANSAC-like sampling strategy. We assume that each object is represented by a model consisting of a set of points with corresponding surface normals. Our method simultaneously recognizes multiple model instances and estimates their pose in the scene. A variety of tests shows that the proposed method performs well on noisy. cluttered and unsegmented range scans in which only small parts of the objects are visible. The main procedure of the algorithm has a linear time complexity resulting in a high recognition speed which allows a direct integration of the …,True,y-MzVoUAAAAJ:ldfaerwXgEUC,161,https://journals.sagepub.com/doi/abs/10.1177/0278364911436019,6458863989910789369,/scholar?cites=6458863989910789369,,,https://mediatum.ub.tum.de/doc/1308158/file.pdf,0,0,0
1278959,Efficient occupancy grid computation on the GPU with lidar and radar for road boundary detection,2010,Florian Homm and Nico Kaempchen and Jeff Ota and Darius Burschka,,,,1006-1013,IEEE,Accurate maps of the static environment are essential for many advanced driver-assistance systems. In this paper a new method for the fast computation of occupancy grid maps with laser range-finders and radar sensors is proposed. The approach utilizes the Graphics Processing Unit to overcome the limitations of classical occupancy grid computation in automotive environments. It is possible to generate highly accurate grid maps in just a few milliseconds without the loss of sensor precision. Moreover. in the case of a lower resolution radar sensor it is shown that it is suitable to apply super-resolution algorithms to achieve the accuracy of a higher resolution laser-scanner. Finally. a novel histogram based approach for road boundary detection with lidar and radar sensors is presented.,True,y-MzVoUAAAAJ:UebtZRa9Y70C,140,https://ieeexplore.ieee.org/abstract/document/5548091/,17324594370049833677,/scholar?cites=17324594370049833677,,,https://mediatum.ub.tum.de/doc/1287438/file.pdf,0,0,0
1278960,Navigating inner space: 3-d assistance for minimally invasive surgery,2005,Darius Burschka and Jason J Corso and Maneesh Dewan and William Lau and Ming Li and Henry Lin and Panadda Marayong and Nicholas Ramey and Gregory D Hager and Brian Hoffman and David Larkin and Christopher Hasser,52,Robotics and Autonomous Systems,1,5-26,North-Holland,Since its inception about three decades ago. modern minimally invasive surgery has made huge advances in both technique and technology. However. the minimally invasive surgeon is still faced with daunting challenges in terms of visualization and hand-eye coordination.At the Center for Computer Integrated Surgical Systems and Technology (CISST) we have been developing a set of techniques for assisting surgeons in navigating and manipulating the three-dimensional space within the human body. In order to develop such systems. a variety of challenging visual tracking. reconstruction and registration problems must be solved. In addition. this information must be tied to methods for assistance that improve surgical accuracy and reliability but allow the surgeon to retain ultimate control of the procedure and do not prolong time in the operating room.In this article. we present two problem areas. eye …,True,y-MzVoUAAAAJ:IjCSPb-OGe4C,131,https://www.sciencedirect.com/science/article/pii/S0921889005000618,7192681460799628952,/scholar?cites=7192681460799628952,,,http://web2.cs.jhu.edu/CIRL/publications/pdf/BuHaetal05.pdf,0,0,0
1278961,Vision-based control of mobile robots,2001,Darius Burschka and Gregory Hager,2,,,1707-1713,IEEE,This paper presents an approach for direct control of a mobile robot to keep it on a pre-taught path based solely on the perception from a monocular CCD camera. In particular. we present a novel vision-based control algorithm for mobile systems equipped with a conventional camera and a pan-tilt head or with an omnidirection camera. This algorithm avoids numerical instabilities of previously reported approaches. The experimental performance of the method as well as its practical limitations are discussed.,True,y-MzVoUAAAAJ:u-x6o8ySG0sC,109,https://ieeexplore.ieee.org/abstract/document/932857/,8065360968618841209,/scholar?cites=8065360968618841209,,,https://www.academia.edu/download/30714662/Q0735.pdf,0,0,0
1278962,The unreasonable effectiveness of deep features as a perceptual metric,2018,Richard Zhang and Phillip Isola and Alexei A Efros and Eli Shechtman and Oliver Wang,,CVPR,,,,"While it is nearly effortless for humans to quickly assess the perceptual similarity between two images. the underlying processes are thought to be quite complex. Despite this. the most widely used perceptual metrics today. such as PSNR and SSIM. are simple. shallow functions. and fail to account for many nuances of human perception. Recently. the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called``perceptual losses""? What elements are critical for their success? To answer these questions. we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly. this result is not restricted to ImageNet-trained VGG features. but holds across different deep architectures and levels of supervision (supervised. self-supervised. or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",True,0B8uuBkAAAAJ:oMtqKo3K3HAC,1352,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.html,14149575231067904672,/scholar?cites=14149575231067904672,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.pdf,0,0,0
1278963,Toward multimodal image-to-image translation,2017,Jun-Yan Zhu and Richard Zhang and Deepak Pathak and Trevor Darrell and Alexei A Efros and Oliver Wang and Eli Shechtman,,arXiv preprint arXiv:1711.11586,,,,Many image-to-image translation problems are ambiguous. as a single input image may correspond to multiple possible outputs. In this work. we aim to model a\emph {distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector. which can be randomly sampled at test time. A generator learns to map the given input. combined with this latent code. to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training. also known as the problem of mode collapse. and produces more diverse results. We explore several variants of this approach by employing different training objectives. network architectures. and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.,True,0B8uuBkAAAAJ:tFyepMjQr3wC,785,https://arxiv.org/abs/1711.11586,4719212061533508568,/scholar?cites=4719212061533508568,,,https://arxiv.org/pdf/1711.11586,0,0,0
1278964,Nonlinear disparity mapping for stereoscopic 3D,2010,Manuel Lang and Alexander Hornung and Oliver Wang and Steven Poulakos and Aljoscha Smolic and Markus Gross,29,ACM Transactions on Graphics (TOG),4,1-10,ACM,This paper addresses the problem of remapping the disparity range of stereoscopic images and video. Such operations are highly important for a variety of issues arising from the production. live broadcast. and consumption of 3D content. Our work is motivated by the observation that the displayed depth and the resulting 3D viewing experience are dictated by a complex combination of perceptual. technological. and artistic constraints. We first discuss the most important perceptual aspects of stereo vision and their implications for stereoscopic content creation. We then formalize these insights into a set of basic disparity mapping operators. These operators enable us to control and retarget the depth of a stereoscopic scene in a nonlinear and locally adaptive fashion. To implement our operators. we propose a new strategy based on stereoscopic warping of the input video streams. From a sparse set of stereo …,True,0B8uuBkAAAAJ:u5HHmVD_uO8C,552,https://dl.acm.org/doi/abs/10.1145/1778765.1778812,9609294130311425234,/scholar?cites=9609294130311425234,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.592.2137&rep=rep1&type=pdf,0,0,0
1278965,High-resolution image inpainting using multi-scale neural patch synthesis,2017,Chao Yang and Xin Lu and Zhe Lin and Eli Shechtman and Oliver Wang and Hao Li,,,,6721-6729,,Recent advances in deep learning have shown exciting promise in filling large holes in natural images with semantically plausible and context aware details. impacting fundamental image manipulation tasks such as object removal. While these learning-based methods are significantly more effective in capturing high-level features than prior techniques. they can only handle very low-resolution inputs due to memory limitations and difficulty in training. Even for slightly larger images. the inpainted regions would appear blurry and unpleasant boundaries become visible. We propose a multi-scale neural patch synthesis approach based on joint optimization of image content and texture constraints. which not only preserves contextual structures but also produces high-frequency details by matching and adapting patches with the most similar mid-layer feature correlations of a deep classification network. We evaluate our method on the ImageNet and Paris Streetview datasets and achieved state-of-the-art inpainting accuracy. We show our approach produces sharper and more coherent results than prior methods. especially for high-resolution images.,True,0B8uuBkAAAAJ:P5F9QuxV20EC,523,http://openaccess.thecvf.com/content_cvpr_2017/html/Yang_High-Resolution_Image_Inpainting_CVPR_2017_paper.html,154146008869681014,/scholar?cites=154146008869681014,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_High-Resolution_Image_Inpainting_CVPR_2017_paper.pdf,0,0,0
1278966,Deep video deblurring for hand-held cameras,2017,Shuochen Su and Mauricio Delbracio and Jue Wang and Guillermo Sapiro and Wolfgang Heidrich and Oliver Wang,,,,1279-1288,,Motion blur from camera shake is a major problem in videos captured by hand-held devices. Unlike single-image deblurring. video-based approaches can take advantage of the abundant information that exists across neighboring frames. As a result the best performing methods rely on the alignment of nearby frames. However. aligning images is a computationally expensive and fragile procedure. and methods that aggregate information must therefore be able to identify which regions have been accurately aligned and which have not. a task that requires high level scene understanding. In this work. we introduce a deep learning solution to video deblurring. where a CNN is trained end-to-end to learn how to accumulate information across frames. To train this network. we collected a dataset of real videos recorded with a high frame rate camera. which we use to generate synthetic motion blur for supervision. We show that the features learned from this dataset extend to deblurring motion blur that arises due to camera shake in a wide range of videos. and compare the quality of results to a number of other baselines.,True,0B8uuBkAAAAJ:1sJd4Hv_s6UC,266,http://openaccess.thecvf.com/content_cvpr_2017/html/Su_Deep_Video_Deblurring_CVPR_2017_paper.html,4032392505584693684,/scholar?cites=4032392505584693684,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Su_Deep_Video_Deblurring_CVPR_2017_paper.pdf,0,0,0
1278967,Localizing moments in video with natural language,2017,Lisa Anne Hendricks and Oliver Wang and Eli Shechtman and Josef Sivic and Trevor Darrell and Bryan Russell,,,,5803-5812,,We consider retrieving a specific temporal segment. or moment. from a video given a natural language text description. Methods designed to retrieve whole video clips with natural language determine what occurs in a video but not when. To address this issue. we propose the Moment Context Network (MCN) which effectively localizes natural language queries in videos by integrating local and global video features over time. A key obstacle to training our MCN model is that current video datasets do not include pairs of localized video segments and referring expressions. or text descriptions which uniquely identify a corresponding moment. Therefore. we collect the Distinct Describable Moments (DiDeMo) dataset which consists of over 10.000 unedited. personal videos in diverse visual settings with pairs of localized video segments and referring expressions. We demonstrate that MCN outperforms several baseline methods and believe that our initial results together with release of DiDeMo will inspire further research on localizing video moments with natural language.,True,0B8uuBkAAAAJ:738O_yMBCRsC,224,http://openaccess.thecvf.com/content_iccv_2017/html/Hendricks_Localizing_Moments_in_ICCV_2017_paper.html,12634028903798866045,/scholar?cites=12634028903798866045,,,https://openaccess.thecvf.com/content_ICCV_2017/papers/Hendricks_Localizing_Moments_in_ICCV_2017_paper.pdf,0,0,0
1278968,Bilateral space video segmentation,2016,Nicolas Märki and Federico Perazzi and Oliver Wang and Alexander Sorkine-Hornung,,,,743-751,,In this work. we propose a novel approach to video segmentation that operates in bilateral space. We design a new energy on the vertices of a regularly sampled spatio-temporal bilateral grid. which can be solved efficiently using a standard graph cut label assignment. Using a bilateral formulation. the energy that we minimize implicitly approximates long-range. spatio-temporal connections between pixels while still containing only a small number of variables and only local graph edges. We compare to a number of recent methods. and show that our approach achieves state-of-the-art results on multiple benchmarks in a fraction of the runtime. Furthermore. our method scales linearly with image size. allowing for interactive feedback on real-world high resolution video.,True,0B8uuBkAAAAJ:f2IySw72cVMC,203,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Maerki_Bilateral_Space_Video_CVPR_2016_paper.html,13387448665720685558,/scholar?cites=13387448665720685558,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Maerki_Bilateral_Space_Video_CVPR_2016_paper.pdf,0,0,0
1278969,Phase-based frame interpolation for video,2015,Simone Meyer and Oliver Wang and Henning Zimmer and Max Grosse and Alexander Sorkine-Hornung,,,,1410-1418,,Standard approaches to computing interpolated (in-between) frames in a video sequence require accurate pixel correspondences between images eg using optical flow. We present an efficient alternative by leveraging recent developments in phase-based methods that represent motion in the phase shift of individual pixels. This concept allows in-between images to be generated by simple per-pixel phase modification. without the need for any form of explicit correspondence estimation. Up until now. such methods have been limited in the range of motion that can be interpolated. which fundamentally restricts their usefulness. In order to reduce these limitations. we introduce a novel. bounded phase shift correction method that combines phase information across the levels of a multi-scale pyramid. Additionally. we propose extensions for phase-based image synthesis that yield smoother transitions between the interpolated images. Our approach avoids expensive global optimization typical of optical flow methods. and is both simple to implement and easy to parallelize. This allows us to interpolate frames at a fraction of the computational cost of traditional optical flow-based solutions. while achieving similar quality and in some cases even superior results. Our method fails gracefully in difficult interpolation settings. eg. significant appearance changes. where flow-based methods often introduce serious visual artifacts. Due to its efficiency. our method is especially well suited for frame interpolation and retiming of high resolution. high frame rate video.,True,0B8uuBkAAAAJ:blknAaTinKkC,167,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Meyer_Phase-Based_Frame_Interpolation_2015_CVPR_paper.html,8626813123453622114,/scholar?cites=8626813123453622114,,,https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Meyer_Phase-Based_Frame_Interpolation_2015_CVPR_paper.pdf,0,0,0
1278970,Fully connected object proposals for video segmentation,2015,Federico Perazzi and Oliver Wang and Markus Gross and Alexander Sorkine-Hornung,,,,3227-3234,,We present a novel approach to video segmentation using multiple object proposals. The problem is formulated as a minimization of a novel energy function defined over a fully connected graph of object proposals. Our model combines appearance with long-range point tracks. which is key to ensure robustness with respect to fast motion and occlusions over longer video sequences. As opposed to previous approaches based on object proposals. we do not seek the best per-frame object hypotheses to perform the segmentation. Instead. we combine multiple. potentially imperfect proposals to improve overall segmentation accuracy and ensure robustness to outliers. Overall. the basic algorithm consists of three steps. First. we generate a very large number of object proposals for each video frame using existing techniques. Next. we perform an SVM-based pruning step to retain only high quality proposals with sufficiently discriminative power. Finally. we determine the fore-and background classification by solving for the maximum a posteriori of a fully connected conditional random field. defined using our novel energy function. Experimental results on a well established dataset demonstrate that our method compares favorably to several recent state-of-the-art approaches.,True,0B8uuBkAAAAJ:ldfaerwXgEUC,165,https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Perazzi_Fully_Connected_Object_ICCV_2015_paper.html,2357192075196348324,/scholar?cites=2357192075196348324,,,https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Perazzi_Fully_Connected_Object_ICCV_2015_paper.pdf,0,0,0
1278971,Practical temporal consistency for image-based graphics applications,2012,Manuel Lang and Oliver Wang and Tunc Aydin and Aljoscha Smolic and Markus Gross,31,ACM Transactions on Graphics (ToG),4,1-8,ACM,We present an efficient and simple method for introducing temporal consistency to a large class of optimization driven image-based computer graphics problems. Our method extends recent work in edge-aware filtering. approximating costly global regularization with a fast iterative joint filtering operation. Using this representation. we can achieve tremendous efficiency gains both in terms of memory requirements and running time. This enables us to process entire shots at once. taking advantage of supporting information that exists across far away frames. something that is difficult with existing approaches due to the computational burden of video data. Our method is able to filter along motion paths using an iterative approach that simultaneously uses and estimates per-pixel optical flow vectors. We demonstrate its utility by creating temporally consistent results for a number of applications including optical flow …,True,0B8uuBkAAAAJ:Zph67rFs4hoC,145,https://dl.acm.org/doi/abs/10.1145/2185520.2185530,16464996558531742725,/scholar?cites=16464996558531742725,,,,0,0,0
1278972,Panoramic video from unstructured camera arrays,2015,Federico Perazzi and Alexander Sorkine‐Hornung and Henning Zimmer and Peter Kaufmann and Oliver Wang and Sharon Watson and Markus Gross,34,Computer Graphics Forum,2,57-68,,We describe an algorithm for generating panoramic video from unstructured camera arrays. Artifact‐free panorama stitching is impeded by parallax between input views. Common strategies such as multi‐level blending or minimum energy seams produce seamless results on quasi‐static input. However. on video input these approaches introduce noticeable visual artifacts due to lack of global temporal and spatial coherence. In this paper we extend the basic concept of local warping for parallax removal. Firstly. we introduce an error measure with increased sensitivity to stitching artifacts in regions with pronounced structure. Using this measure. our method efficiently finds an optimal ordering of pair‐wise warps for robust stitching with minimal parallax artifacts. Weighted extrapolation of warps in non‐overlap regions ensures temporal stability. while at the same time avoiding visual discontinuities around transitions …,True,0B8uuBkAAAAJ:BqipwSGYUEgC,105,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12541,9788526371393985464,/scholar?cites=9788526371393985464,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.726.7570&rep=rep1&type=pdf,0,0,0
1278973,Hybrid neural network models for hydrologic time series forecasting,2007,Ashu Jain and Avadhnam Madhav Kumar,7,Applied Soft Computing,2,585-592,Elsevier,The need for increased accuracies in time series forecasting has motivated the researchers to develop innovative models. In this paper. a new hybrid time series neural network model is proposed that is capable of exploiting the strengths of traditional time series approaches and artificial neural networks (ANNs). The proposed approach consists of an overall modelling framework. which is a combination of the conventional and ANN techniques. The steps involved in the time series analysis. e.g. de-trending and de-seasonalisation. can be carried out before gradually presenting the modified time series data to the ANN. The proposed hybrid approach for time series forecasting is tested using the monthly streamflow data at Colorado River at Lees Ferry. USA. Specifically. results from four time series models of auto-regressive (AR) type and four ANN models are presented. The results obtained in this study suggest that …,True,sUFJvtMAAAAJ:5-tCjTwfAdEC,467,https://www.sciencedirect.com/science/article/pii/S1568494606000317,4103332800860278903,/scholar?cites=4103332800860278903,,,https://www.academia.edu/download/47457913/j.asoc.2006.03.00220160723-28774-1fhm37p.pdf,0,0,0
1278974,Rotavirus diarrhea in bovines and other domestic animals,2009,K Dhama and RS Chauhan and M Mahendran and SVS Malik,33,,1,1-23,Springer Netherlands,Rotavirus diarrhea is the major cause of death of millions of children in developing countries besides causing economically significant malady in neonates of many domestic animals. In neonates. the infection is non-viremic. have very short incubation period. and manifests profuse diarrhea and severe dehydration. Concurrent infection with secondary pathogens may augment the disease severity. Diarrhea occurs due to virus-mediated destruction of absorption efficient enterocytes. activation of enteric nervous system. or due to a rotavirus enterotoxin. Diagnosis of the infection relies on conventional techniques like isolation in MA 104 cell lines. electron microscopy. electro-pherotyping. and various serological tests. Presently. diagnosis and molecular typing is performed using serotype specific RT-PCR. sequencing or genomic hybridization techniques. As the rotaviruses are known to exhibit extreme genetic …,True,sUFJvtMAAAAJ:ifIdVpG6JtcC,212,https://link.springer.com/article/10.1007/s11259-008-9070-x,7395416129644935565,/scholar?cites=7395416129644935565,,,https://link.springer.com/article/10.1007/s11259-008-9070-x,0,0,0
1278975,Reversal of GSTP1 CpG island hypermethylation and reactivation of π-class glutathione S-transferase (GSTP1) expression in human prostate cancer cells by treatment with procainamide,2001,Xiaohui Lin and Kekule Asgari and Mathew J Putzi and Wesley R Gage and Xiang Yu and Brian S Cornblatt and Arunima Kumar and Steven Piantadosi and Theodore L DeWeese and Angelo M De Marzo and William G Nelson,61,Cancer research,24,8611-8616,American Association for Cancer Research,Among the many somatic genome alterations present in cancer cells. changes in DNA methylation may represent reversible “epigenetic” lesions. rather than irreversible “genetic” alterations. Cancer cell DNA is typically characterized by increases in the methylation of CpG dinucleotides clustered into CpG islands. near the transcriptional regulatory regions of critical genes. and by an overall reduction in CpG dinucleotide methylation. The transcriptional “silencing” of gene expression associated with such CpG island DNA hypermethylation presents an attractive therapeutic target: restoration of “silenced” gene expression may be possible via therapeutic reversal of CpG island hypermethylation. 5-Aza-cytidine (5-aza-C) and 5-aza-deoxycytidine (5-aza-dC). nucleoside analogue inhibitors of DNA methyltransferases. have been widely used in attempts to reverse abnormal DNA hypermethylation in cancer cells and …,True,sUFJvtMAAAAJ:dzJfEEo5V9YC,209,https://cancerres.aacrjournals.org/content/61/24/8611.short,16020638108121856192,/scholar?cites=16020638108121856192,,,https://cancerres.aacrjournals.org/content/canres/61/24/8611.full.pdf,0,0,0
1278976,Determination of the full dose–response relation of intrathecal bupivacaine. levobupivacaine. and ropivacaine. combined with sufentanil. for labor analgesia,2007,Marc Van de Velde and Rebekka Dreelinck and Jasperina Dubois and Ariane Kumar and Jan Deprest and Liesbeth Lewi and Eugene Vandermeersch,106,The Journal of the American Society of Anesthesiologists,1,149-156,The American Society of Anesthesiologists,Ropivacaine and levobupivacaine are local anesthetics that produce less motor block and greater sensory-motor separation when compared with equal milligram doses of bupivacaine. Although minimum local analgesic concentration studies suggested that they are less potent than bupivacaine. full dose-response studies have not been performed. The current trial describes the dose-response relation of levobupivacaine. ropivacaine. and bupivacaine. combined with sufentanil. when used for intrathecal labor analgesia.Four hundred fifty term parturients in active labor were included in this double-blind. randomized trial. Combined spinal-epidural anesthesia was performed. and ropivacaine. levobupivacaine. or bupivacaine was intrathecally administered in a dose of 1.0. 1.5. 2.0. 2.5. 3.0. or 3.5 mg. always combined with 1.5 microg sufentanil. Patients were considered responders to spinal analgesia if the visual analog scale score for pain was less than 25 mm within 15 min and the visual analog scale score remained less than 25 mm for 45 min. Patient demographics. obstetric data. maternal side effects. and fetal and neonatal well-being were noted. Group-specific dose-response curves were constructed using a probit regression model.The ED95 of bupivacaine was 3.3 mg (95% confidence interval. 2.9-4.1). The ED95s of ropivacaine and levobupivacaine were 4.8 mg (95% confidence interval. 4.0-6.7) and 5.0 mg (95% confidence interval. 4.1-7.0). respectively. Racemic bupivacaine was significantly more potent than ropivacaine (P=0.0027) and …,True,sUFJvtMAAAAJ:gfRb5cj6lVgC,129,https://pubs.asahq.org/anesthesiology/article-abstract/106/1/149/8841,10690516473176390112,/scholar?cites=10690516473176390112,,,https://pubs.asahq.org/anesthesiology/article-pdf/106/1/149/362539/0000542-200701000-00024.pdf,0,0,0
1278977,Comparative evaluation of midazolam and ketamine with midazolam alone as oral premedication,2005,Babita Ghai and Radhika Prasad Grandhe and Arun Kumar and Pramila Chari,15,Pediatric anesthesia,7,554-559,Blackwell Science Ltd,Background : Oral premedication with midazolam and ketamine is widely used in pediatric anesthesia to reduce emotional trauma and ensure smooth induction. However. various dosing regimens when used alone or in combination have variable efficacy and side effect profile. The aim of our study was to investigate and compare the efficacy of oral midazolam alone with a low‐dose combination of oral midazolam and ketamine.Methods : We performed a prospective randomized double‐blind study in 100 children who were randomly allocated into two groups. Group M received 0.5 mg·kg−1 oral midazolam and group MK received 0.25 mg·kg−1 oral midazolam with 2.5 mg·kg−1 oral ketamine. The preoperative sedation score. ease of parental separation and ease of mask acceptance were evaluated on a 4‐point scale. The time to recovery from anesthesia and to achieve satisfactory Aldrete score was also …,True,sUFJvtMAAAAJ:APw3zysQxTcC,102,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1460-9592.2004.01523.x,4318662108033355498,/scholar?cites=4318662108033355498,,,,0,0,0
1278978,Antioxidant and antibacterial activity of six edible wild plants (Sonchus spp.) in China,2011,Dao-Zong Xia and Xin-Fen Yu and Zhuo-Ying Zhu and Zhuang-Dan Zou,25,Natural product research,20,1893-1901,Taylor & Francis Group,The total phenolic and flavonoid. antioxidant and antibacterial activities of six Sonchus wild vegetables (Sonchus oleraceus L.. Sonchus arvensis L.. Sonchus asper (L.) Hill.. Sonchus uliginosus M.B.. Sonchus brachyotus DC. and Sonchus lingianus Shih) in China were investigated. The results revealed that S. arvensis extract and S. oleraceus extract contained the highest amount of phenolic and flavonoid. respectively. Among the methanol extracts of six Sonchus species. S. arvensis extract exhibited the highest radical (DPPH and ABTS+) scavenging power and lipid peroxidation inhibitory power. It also exhibited the highest reducing power at 500 µg mL−1 by A 700 = 0.80. The results of antibacterial test indicated that the S. oleraceus extract showed higher activity than the other five Sonchus wild vegetables extracts. both in Gram-negative bacteria (Escherichia coli. Salmonella enterica and Vibrio …,True,sUFJvtMAAAAJ:AYaE08C4-t8C,101,https://www.tandfonline.com/doi/abs/10.1080/14786419.2010.534093,3445030750831045030,/scholar?cites=3445030750831045030,,,https://www.researchgate.net/profile/Daozong-Xia/publication/51525433_Antioxidant_and_antibacterial_activity_of_six_edible_wild_plants_Sonchus_spp_in_China/links/5ed3b572299bf1c67d2cd036/Antioxidant-and-antibacterial-activity-of-six-edible-wild-plants-Sonchus-spp-in-China.pdf,0,0,0
1278979,MDR1 promoter hypermethylation in MCF-7 human breast cancer cells: changes in chromatin structure induced by treatment with 5-Aza-cytidine,2004,Gloria L David and Srinivasan Yegnasubramanian and Arunima Kumar and Valerie L Marchi and Angelo M De Marzo and Xiaohiu Lin and William G Nelson,3,Cancer biology & therapy,6,540-548,Taylor & Francis,Resistance to the cytotoxic actions of antineoplastic drugs. whether intrinsic or acquired. remains a barrier to the establishment of curative chemotherapy regimens for advanced breast cancer.  Over-expression of P-glycoprotein (P-gp). encoded by the MDR1 gene and known to mediate resistance to many antineoplastic drugs. may contribute to poor breast cancer treatment outcome.  Nonetheless. the precise molecular mechanisms responsible for high or low level P-gp expression in breast cancer cells have not been established.  We assessed the role of DNA hypermethylation near the MDR1 transcriptional regulatory region in MDR1 expression in MCF-7 breast cancer cells. which fail to express MDR1 mRNA. and MCF-7/ADR cells. known to express high MDR1 mRNA levels.  When compared to MCF-7/ADR cells. MCF-7 cells manifested markedly diminished MDR1 transcription rates by nuclear run-off assay. but …,True,sUFJvtMAAAAJ:q7xreA_uRSAC,99,https://www.tandfonline.com/doi/abs/10.4161/cbt.3.6.845,2257081610357658063,/scholar?cites=2257081610357658063,,,https://www.tandfonline.com/doi/pdf/10.4161/cbt.3.6.845,0,0,0
1278980,Prospective derivation and validation of early dynamic model for predicting outcome in patients with acute liver failure,2012,Ramesh Kumar and Hanish Sharma and Rohit Goyal and Ajay Kumar and Shankar Khanal and Shyam Prakash and S Datta Gupta and Subrat Kumar Panda and Subrat Kumar Acharya,61,Gut,7,1068-1075,BMJ Publishing Group,It is difficult to predict the outcome in patients with acute liver failure (ALF) using existing prognostic models. This study investigated whether early changes in the levels of dynamic variables can predict outcome better than models based on static baseline variables.380 patients with ALF (derivation cohort n=244. validation cohort n=136) participated in a prospective observational study. The derivation cohort was used to identify predictors of mortality. The ALF early dynamic (ALFED) model was constructed based on whether the levels of predictive variables remained persistently high or increased over 3 days above the discriminatory cut-off values identified in this study. The model had four variables: arterial ammonia. serum bilirubin. international normalised ratio and hepatic encephalopathy >grade II. The model was validated in a cohort of 136 patients with ALF.The ALFED model …,True,sUFJvtMAAAAJ:hnLuywnv79wC,89,https://gut.bmj.com/content/61/7/1068.short,232064576415346344,/scholar?cites=232064576415346344,,,https://www.researchgate.net/profile/Dr_Shalimar/publication/221835685_Prospective_derivation_and_validation_of_early_dynamic_model_for_predicting_outcome_in_patients_with_acute_liver_failure/links/5759080a08ae414b8e3f648f.pdf,0,0,0
1278981,Nurses’ attitudes toward pain treatment with opioids: a survey in a Belgian university hospital,2004,Susan Broekmans and Steven Vanderschueren and Bart Morlion and A Kumar and G Evers,41,International Journal of Nursing Studies,2,183-189,Pergamon,Aim: To investigate nurses’ attitudes toward pain treatment with opioids in a Belgian university hospital.Method: A cross-sectional. descriptive study design was used. The randomised sample included 350 nurses working in the University Hospital Leuven. Belgium. Non-response was 10.9%. Nurses’ attitudes were explored by a structured questionnaire. The score on the opioid attitude scale (OAS) varied between 9 and 45.Results: Despite a neutral to positive score on the OAS (mean=69.4%). nurses had clearly negative attitudes towards the use of opioids during a diagnostic phase and the risk of possible addiction. These negative attitudes can hinder adequate pain treatment.,True,sUFJvtMAAAAJ:uYXrTPzN_RMC,80,https://www.sciencedirect.com/science/article/pii/S0020748903001299,17924413482197175554,/scholar?cites=17924413482197175554,,,,0,0,0
1278982,Evaluation of biosurfactant/bioemulsifier production by a marine bacterium,2007,Anita Suresh Kumar and Kalpana Mody and Bhavanath Jha,79,Bulletin of environmental contamination and toxicology,6,617-621,Springer-Verlag, Planococcus maitriensis Anita I (NCBI GenBank Accession number EF467308) was tested for its biosurfactant/bioemulsifying efficacy. The crude extracellular polymeric substance (EPS) produced by this bacterium contained carbohydrate (12.06%). protein (24.44%). uronic acid (11%) and sulfate (3.03%). The oil spreading potential of this EPS was comparable to Triton X100 and Tween 80. This exopolymer emulsified xylene more efficiently as compared to few standard gums. It also formed stable emulsions (E 1.080=100) with jatropha. paraffin and silicone oils. The cell free supernatant of this bacterium successfully reduced the surface tension (from 72 to 46.07 mN m−1). It also decreased interfacial tension of hexane and xylene. Based on the emulsifying and tensiometric properties. this bacterium or its exopolymer could be used for bioremediation. enhanced oil recovery and in …,True,sUFJvtMAAAAJ:v4854jF90TkC,79,https://link.springer.com/article/10.1007/s00128-007-9283-7,577455705149625044,/scholar?cites=577455705149625044,,,,0,0,0
1278983,Cell surface interactions in the study of biocompatibility,2002,TV Kumari and Usha Vasudev and Anil Kumar and Bindhu Menon,15,,2,,,Implantation of materials in the body can lead to to adverse local and systematic reactions. knowledge of basic mechanisms of cell material interaction and better understanding of the ongoing processes at the cellular and intracellular level during interaction of anchorage dependent cells with biomaterials will help in the development of new biocompatible materials. As fibroblasts are the predominant tissue cell coming in contact with most of the material in the body. mamalian fibroblast cells were used for the study. Cell attachment and adhesion pattern of cells on different materials were studied using microscopic techniques. Fluorscent labelling of actin and vinculin of osteoblast cells demonstrated a typical sequence of events of cells as rounded. attachment with attachment structures. microfilaments etc.,True,sUFJvtMAAAAJ:5s5aUJDWGkQC,76,http://scholar.google.com/scholar?cluster=18010398141615482264&hl=en&oi=scholarr,18010398141615482264,/scholar?cites=18010398141615482264,,,,0,0,0
1278984,Deep learning for computer vision: A brief review,2018,Athanasios Voulodimos and Nikolaos Doulamis and Anastasios Doulamis and Eftychios Protopapadakis,2018,,,,Hindawi,Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields. with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems. that is. Convolutional Neural Networks. Deep Boltzmann Machines and Deep Belief Networks. and Stacked Denoising Autoencoders. A brief account of their history. structure. advantages. and limitations is given. followed by a description of their applications in various computer vision tasks. such as object detection. face recognition. action and activity recognition. and human pose estimation. Finally. a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.,True,gJDbVgIAAAAJ:0CzhzZyukY4C,831,https://www.hindawi.com/journals/cin/2018/7068349/abs/,8556666434397597688,/scholar?cites=8556666434397597688,,,https://www.hindawi.com/journals/cin/2018/7068349/abs/,0,0,0
1278985,Deep supervised learning for hyperspectral data classification through convolutional neural networks,2015,Konstantinos Makantasis and Konstantinos Karantzalos and Anastasios Doulamis and Nikolaos Doulamis,,,,4959-4962,IEEE,Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition. which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm. which is based on the construction of complex handcrafted features. However. it is rarely known which features are important for the problem at hand. In contrast to these approaches. we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the …,True,gJDbVgIAAAAJ:0KyAp5RtaNEC,486,https://ieeexplore.ieee.org/abstract/document/7326945/,10646184102623179652,/scholar?cites=10646184102623179652,,,http://users.ntua.gr/karank/img/Makantasis_etal_igrass15.pdf,0,0,0
1278986,Enabling applications on the grid: A gridlab overview,2003,Gabrielle Allen and Tom Goodale and Thomas Radke and Michael Russell and Ed Seidel and Kelly Davis and Konstantinos N Dolkas and Nikolaos D Doulamis and Thilo Kielmann and André Merzky and Jarek Nabrzyski and Juliusz Pukacki and John Shalf and Ian Taylor,17,The International Journal of High Performance Computing Applications,4,449-466,Sage Publications,Grid technology is widely emerging. Still. there is an eminent shortage of real Grid                users. mostly due to the lack of a “critical mass” of widely                deployed and reliable higher-level Grid services. tailored to application needs. The                GridLab project aims to provide fundamentally new capabilities for applications to                exploit the power of Grid computing. thus bridging the gap between application needs                and existing Grid middleware. We present an overview of GridLab. a large-scale.                EU-funded Grid project spanning over a dozen groups in Europe and the US. We first                outline our vision of Grid-empowered applications and then discuss                GridLab’s general architecture and its Grid Application Toolkit (GAT). We                illustrate how applications can be Grid-enabled with the GAT and discuss                GridLab’s scheduler as an example of GAT services.,True,gJDbVgIAAAAJ:u5HHmVD_uO8C,224,https://journals.sagepub.com/doi/abs/10.1177/10943420030174008,7325037437100132988,/scholar?cites=7325037437100132988,,,https://pure.mpg.de/rest/items/item_151830/component/file_151829/content,0,0,0
1278987,A fuzzy video content representation for video summarization and content-based retrieval,2000,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,80,Signal Processing,6,1049-1067,Elsevier,In this paper. a fuzzy representation of visual content is proposed. which is useful for the new emerging multimedia applications. such as content-based image indexing and retrieval. video browsing and summarization. In particular. a multidimensional fuzzy histogram is constructed for each video frame based on a collection of appropriate features. extracted using video sequence analysis techniques. This approach is then applied both for video summarization. in the context of a content-based sampling algorithm. and for content-based indexing and retrieval. In the first case. video summarization is accomplished by discarding shots or frames of similar visual content so that only a small but meaningful amount of information is retained (key-frames). In the second case. a content-based retrieval scheme is investigated. so that the most similar images to a query are extracted. Experimental results and comparison with …,True,gJDbVgIAAAAJ:JTqpx9DYBaYC,148,https://www.sciencedirect.com/science/article/pii/S0165168400000190,10952171234810203006,/scholar?cites=10952171234810203006,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1714&rep=rep1&type=pdf,0,0,0
1278988,On-line retrainable neural networks: improving the performance of neural networks in image analysis problems,2000,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,11,IEEE Transactions on neural networks,1,137-155,IEEE,A novel approach is presented in this paper for im-proving the performance of neural-network classifiers in image recognition. segmentation. or coding applications. based on a retraining procedure at the user level. The procedure includes: 1) a training algorithm for adapting the network weights to the current condition; 2) a maximum a posteriori (MAP) estimation procedure for optimally selecting the most representative data of the current environment as retraining data; and 3) a decision mechanism for determining when network retraining should be activated. The training algorithm takes into consideration both the former and the current network knowledge in order to achieve good generalization. The MAP estimation procedure models the network output as a Markov random field (MRF) and optimally selects the set of training inputs and corresponding desired outputs. Results are presented which illustrate the theoretical developments as well as the performance of the proposed approach in real-life experiments.,True,gJDbVgIAAAAJ:2osOgNQ5qMEC,126,https://pdfs.semanticscholar.org/156d/8d07823a2a66e0d13c3f2b34ffb7307f5bb3.pdf,11471558226732535199,/scholar?cites=11471558226732535199,,,https://pdfs.semanticscholar.org/156d/8d07823a2a66e0d13c3f2b34ffb7307f5bb3.pdf,0,0,0
1278989,Low bit-rate coding of image sequences using adaptive regions of interest,1998,Nikolaos Doulamis and Anastasios Doulamis and Dimitrios Kalogeras and Stefanos Kollias,8,IEEE transactions on circuits and systems for video technology,8,928-934,IEEE,An adaptive algorithm for extracting foreground objects from background in videophone or videoconference applications is presented. The algorithm uses a neural network architecture that classifies the video frames in regions of interest (ROI) and non-ROI areas. also being able to automatically adapt its performance to scene changes. The algorithm is incorporated in motion-compensated discrete cosine transform (MC-DCT)-based coding schemes. allocating more bits to ROI than to non-ROI areas. Simulation results are presented. using the Claire and Trevor sequences. which show reconstructed images of better quality. as well as signal-to-noise ratio improvements of about 1.4 dB. compared to those achieved by standard MC-DCT encoders.,True,gJDbVgIAAAAJ:u-x6o8ySG0sC,125,https://ieeexplore.ieee.org/abstract/document/736718/,4602300891471484248,/scholar?cites=4602300891471484248,,,https://www.researchgate.net/profile/Dimitris_Kalogeras/publication/3307978_Low_bit-rate_coding_of_image_sequences_using_adaptive_regions_of_interest/links/02e7e5188be6fc70bd000000.pdf,0,0,0
1278990,Efficient summarization of stereoscopic video sequences,2000,Nikolaos D Doulamis and Anastasios D Doulamis and Yannis S Avrithis and Klimis S Ntalianis and Stefanos D Kollias,10,IEEE Transactions on Circuits and Systems for Video Technology,4,501-517,IEEE,An efficient technique for summarization of stereoscopic video sequences is presented. which extracts a small but meaningful set of video frames using a content-based sampling algorithm. The proposed video-content representation provides the capability of browsing digital stereoscopic video sequences and performing more efficient content-based queries and indexing. Each stereoscopic video sequence is first partitioned into shots by applying a shot-cut detection algorithm so that frames (or stereo pairs) of similar visual characteristics are gathered together. Each shot is then analyzed using stereo-imaging techniques. and the disparity field. occluded areas. and depth map are estimated. A multiresolution implementation of the recursive shortest spanning tree (RSST) algorithm is applied for color and depth segmentation. while fusion of color and depth segments is employed for reliable video object extraction. In …,True,gJDbVgIAAAAJ:qjMakFHDy7sC,123,https://ieeexplore.ieee.org/abstract/document/844996/,5921830990220809695,/scholar?cites=5921830990220809695,,,https://avrithis.net/data/pub/pdf/journ/J02.csvt99.pdf,0,0,0
1278991,An adaptable neural-network model for recursive nonlinear traffic prediction and modeling of MPEG video sources,2003,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,14,IEEE Transactions on Neural Networks,1,150-166,IEEE,Multimedia services and especially digital video is expected to be the major traffic component transmitted over communication networks [such as internet protocol (IP)-based networks]. For this reason. traffic characterization and modeling of such services are required for an efficient network operation. The generated models can be used as traffic rate predictors. during the network operation phase (online traffic modeling). or as video generators for estimating the network resources. during the network design phase (offline traffic modeling). In this paper. an adaptable neural-network architecture is proposed covering both cases. The scheme is based on an efficient recursive weight estimation algorithm. which adapts the network response to current conditions. In particular. the algorithm updates the network weights so that 1) the network output. after the adaptation. is approximately equal to current bit rates (current …,True,gJDbVgIAAAAJ:UeHWp8X0CEIC,119,https://ieeexplore.ieee.org/abstract/document/1176135/,1224680158503398573,/scholar?cites=1224680158503398573,,,https://www.researchgate.net/profile/Stefanos_Kollias/publication/5613961_An_adaptable_neural-network_model_for_recursive_nonlinear_traffic_prediction_and_modeling_of_MPEG_video_sources/links/56a9fba708ae2df82166a235.pdf,0,0,0
1278992,A stochastic framework for optimal key frame extraction from MPEG video databases,1999,Yannis S Avrithis and Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,75,Computer Vision and Image Understanding,1-2,3-24,Academic Press,A video content representation framework is proposed in this paper for extracting limited. but meaningful. information of video data. directly from the MPEG compressed domain. A hierarchical color and motion segmentation scheme is applied to each video shot. transforming the frame-based representation to a feature-based one. The scheme is based on a multiresolution implementation of the recursive shortest spanning tree (RSST) algorithm. Then. all segment features are gathered together using a fuzzy multidimensional histogram to reduce the possibility of classifying similar segments to different classes. Extraction of several key frames is performed for each shot in a content-based rate-sampling framework. Two approaches are examined for key frame extraction. The first is based on examination of the temporal variation of the feature vector trajectory; the second is based on minimization of a cross-correlation …,True,gJDbVgIAAAAJ:9yKSN-GCB0IC,116,https://www.sciencedirect.com/science/article/pii/S1077314299907610,5077865837034791527,/scholar?cites=5077865837034791527,,,https://www.academia.edu/download/36193575/5.pdf,0,0,0
1278993,Fair scheduling algorithms in grids,2007,Nikolaos D Doulamis and Anastasios D Doulamis and Emmanouel A Varvarigos and Theodora A Varvarigou,18,IEEE Transactions on Parallel and Distributed Systems,11,1630-1648,IEEE,In this paper. we propose a new algorithm for fair scheduling. and we compare it to other scheduling schemes such as the earliest deadline first (EDF) and the first come first served (FCFS) schemes. Our algorithm uses a max-min fair sharing approach for providing fair access to users. When there is no shortage of resources. the algorithm assigns to each task enough computational power for it to finish within its deadline. When there is congestion. the main idea is to fairly reduce the CPU rates assigned to the tasks so that the share of resources that each user gets is proportional to the users weight. The weight of a user may be defined as the users contribution to the infrastructure or the price he is willing to pay for services or any other socioeconomic consideration. In our algorithms. all tasks whose requirements are lower than their fair share CPU rate are served at their demanded CPU rates. However. the CPU rates …,True,gJDbVgIAAAAJ:W7OEmFMy1HYC,113,https://ieeexplore.ieee.org/abstract/document/4339205/,6815200130678790326,/scholar?cites=6815200130678790326,,,,0,0,0
1278994,A service oriented architecture for decision support systems in environmental crisis management,2012,Vassilios Vescoukis and Nikolaos Doulamis and Sofia Karagiorgou,28,Future generation computer systems,3,593-604,North-Holland,Efficient management of natural disasters impose great research challenges to the current environmental crisis management systems in terms of both architecture and services. This is mainly due to the fact that a large amount of geospatial content is usually distributed. non-compliant to standards. and needs to be transmitted under a QoS guaranteed framework to support effective decision making either in case of an emergency or in advance planning. Incorporating real time capabilities in Web services. both in terms of dynamic configuration and service selection. is an open research agenda. The things get worst in geospatial context due to the huge amount of data transmitted from distributed sensors under heterogeneous platforms. making the need of synchronization an important issue. In this paper. we propose a flexible service oriented architecture for planning and decision support in environmental crisis …,True,gJDbVgIAAAAJ:maZDTaKrznsC,99,https://www.sciencedirect.com/science/article/pii/S0167739X11000380,3520597523936293265,/scholar?cites=3520597523936293265,,,,0,0,0
1278995,Geometry-driven diffusion in computer vision,2013,Bart M Haar Romeny,1,,,,Springer Science & Business Media,"Scale is a concept the antiquity of which can hardly be traced. Certainly the familiar phenomena that accompany sc ale changes in optical patterns are mentioned in the earliest written records. The most obvious topological changes such as the creation or annihilation of details have been a topic to philosophers. artists and later scientists. This appears to of fascination be the case for all cultures from which extensive written records exist. For th instance. chinese 17 c artist manuals remark that"" distant faces have no eyes"". The merging of details is also obvious to many authors. eg. Lucretius mentions the fact that distant islands look like a single one. The one topo logical event that is (to the best of my knowledge) mentioned only late (by th John Ruskin in his"" Elements of drawing"" of the mid 19 c) is the splitting of a blob on blurring. The change of images on a gradual increase of resolu tion has been a recurring theme in the arts (eg. the poetic description of the distant armada in Calderon's The Constant Prince) and this"" mystery""(as Ruskin calls it) is constantly exploited by painters.",True,qbzezVEAAAAJ:EkHepimYqZsC,664,http://books.google.com/books?hl=en&lr=&id=Fr2rCAAAQBAJ&oi=fnd&pg=PR2&dq=info:_8fb0nTuBKgJ:scholar.google.com&ots=kF9RQj0fAN&sig=Ux8s--n_K_L3-ds8TEDAwEwI8T0,12107063883799971839,/scholar?cites=12107063883799971839,,,,0,0,0
1278996,Scale and the differential structure of images,1992,Luc MJ Florack and Bart M ter Haar Romeny and Jan J Koenderink and Max A Viergever,10,Image and vision computing,6,376-388,Elsevier,Why and how one should study a scale-space is prescribed by the universal physical law of scale invariance. expressed by the so-called Pi-theorem. The fact that any image is a physical observable with an inner and outer scale bound. necessarily gives rise to a ‘scale-space representation’. in which a given image is represented by a one-dimensional family of images representing that image on various levels of inner spatial scale. An early vision system is completely ignorant of the geometry of its input. Its primary task is to establish this geometry at any available scale. The absence of geometrical knowledge poses additional constraints on the construction of a scale-space. notably linearity. spatial shift invariance and isotropy. thereby defining a complete hierarchical family of scaled partial differential operators: the Gaussian kernel (the lowest order. resettling operator) and its linear partial derivatives. They enable …,True,qbzezVEAAAAJ:u5HHmVD_uO8C,570,https://www.sciencedirect.com/science/article/pii/026288569290024W,7362934793074771412,/scholar?cites=7362934793074771412,,,,0,0,0
1278997,Image structure,2013,Luc Florack,10,,,,Springer Science & Business Media,Despite the fact that images constitute the main objects in computer vision and image analysis. there is remarkably little concern about their actual definition. In this book a complete account of image structure is proposed in terms of rigorously defined machine concepts. using basic tools from algebra. analysis. and differential geometry. Machine technicalities such as discretisation and quantisation details are de-emphasised. and robustness with respect to noise is manifest. From the foreword by Jan Koenderink:It is my hope that the book will find a wide audience. including physicists-who still are largely unaware of the general importance and power of scale space theory. mathematicians-who will find in it a principled and formally tight exposition of a topic awaiting further development. and computer scientists-who will find here a unified and conceptually well founded framework for many apparently unrelated and largely historically motivated methods they already know and love. The book is suited for self-study and graduate courses. the carefully formulated exercises are designed to get to grips with the subject matter and prepare the reader for original research.',True,qbzezVEAAAAJ:u-x6o8ySG0sC,361,http://books.google.com/books?hl=en&lr=&id=PeaoCAAAQBAJ&oi=fnd&pg=PP10&dq=info:4cAWve1BA9YJ:scholar.google.com&ots=wNVqLaJXUE&sig=AnMXYzD_W7mlTiBkAypbn3SPHNk,15421242038382149857,/scholar?cites=15421242038382149857,,,https://www.researchgate.net/profile/Luc_Florack/publication/230675330_Image_Structure/links/00b7d5278aecc8a056000000.pdf,0,0,0
1278998,Gaussian scale-space theory,2013,Jon Sporring and Mads Nielsen and Luc Florack and Peter Johansen,8,,,,Springer Science & Business Media,Gaussian scale-space is one of the best understood multi-resolution techniques available to the computer vision and image analysis community. It is the purpose of this book to guide the reader through some of its main aspects. During an intensive weekend in May 1996 a workshop on Gaussian scale-space theory was held in Copenhagen. which was attended by many of the leading experts in the field. The bulk of this book originates from this workshop. Presently there exist only two books on the subject. In contrast to Lindeberg's monograph (Lindeberg. 1994e) this book collects contributions from several scale space researchers. whereas it complements the book edited by ter Haar Romeny (Haar Romeny. 1994) on non-linear techniques by focusing on linear diffusion. This book is divided into four parts. The reader not so familiar with scale-space will find it instructive to first consider some potential applications described in Part 1. Parts II and III both address fundamental aspects of scale-space. Whereas scale is treated as an essentially arbitrary constant in the former. the latter em phasizes the deep structure. ie the structure that is revealed by varying scale. Finally. Part IV is devoted to non-linear extensions. notably non-linear diffusion techniques and morphological scale-spaces. and their relation to the linear case. The Danish National Science Research Council is gratefully acknowledged for providing financial support for the workshop under grant no. 9502164.,True,qbzezVEAAAAJ:9yKSN-GCB0IC,234,http://books.google.com/books?hl=en&lr=&id=heWoCAAAQBAJ&oi=fnd&pg=PR14&dq=info:r546vjncUaIJ:scholar.google.com&ots=ROIaR0UtwQ&sig=eVYpra4VtrZBCh5AP6AQh8yXc44,11696371847820648111,/scholar?cites=11696371847820648111,,,,0,0,0
1278999,General intensity transformations and differential invariants,1994,Luc MJ Florack and BM Ter Haar Romeny and Jan J Koenderink and Max A Viergever,4,Journal of Mathematical Imaging and Vision,2,171-187,Kluwer Academic Publishers,We consider the group of invertible image gray-value transformations and propose a generating equation for a complete set of differential gray-value invariants up to any order. Such invariants describe the image's geometrical structure independent of how its gray-values are mapped (contrast or brightness adjustments).,True,qbzezVEAAAAJ:d1gkVwhDpl0C,230,https://link.springer.com/article/10.1007/BF01249895,4656859751692384844,/scholar?cites=4656859751692384844,,,http://mate.tue.nl/mate/pdfs/5165.pdf,0,0,0
1279000,The syntactical structure of scalar images,1993,Ludovicus Maria Jozef Florack,,,,,,"The human visual system is one of the most astonishing creations of nature. After millions of years of evolution this system has reached a degree of perfection without an equal. Accordingly. man is visually minded to a large extent. The human visual system allows man to take effective action according to circumstances. By means of observation it yields information about the optical environment. The exact way in which the acquired data are processed is an outstanding mystery of nature. Anyway. human action as well as knowledge (potential action) are to a large extent inferred from these data. The study of biological visual systems is of an unexpected complexity considering the self-evidence of the human ability to deal with visual tasks. The phenomenological laws of the every-day environment have been hammered into man's head over and over again. It is quite a paradox that major achievements have been accomplished precisely in those fields in which the visual system fails completely. Physicists have not been playing billiards with elementary particles a long time. and the universe is nowadays considered to entail more than a collection of light spots against a nocturnal sky. However. many basic principles underlying the\internal representation"" of the visual system are yet to be disclosed. Yet it should be pointed out in this context that even the very abstract physical theories often have a visual peg. For example. think of Feynman's principle with its diagrammatic picture of field interactions (a game of billiards enriched with ghost and other virtual balls. but with unambiguous rules). and of the geometric picture of a black hole (a billiard-table …",True,qbzezVEAAAAJ:DJbcl8HfkQkC,194,https://www.researchgate.net/profile/Luc_Florack/publication/230675327_The_Syntactical_Structure_of_Scalar_Images/links/09e4150b865fcdc7e0000000/The-Syntactical-Structure-of-Scalar-Images.pdf,3728974732544685740,/scholar?cites=3728974732544685740,,,https://www.researchgate.net/profile/Luc_Florack/publication/230675327_The_Syntactical_Structure_of_Scalar_Images/links/09e4150b865fcdc7e0000000/The-Syntactical-Structure-of-Scalar-Images.pdf,0,0,0
1279001,The topological structure of scale-space images,2000,Luc Florack and Arjan Kuijper,12,Journal of Mathematical Imaging and Vision,1,65-79,Kluwer Academic Publishers,We investigate the “deep structure” of a scale-space image. The emphasis is on topology. i.e. we concentrate on critical points—points with vanishing gradient—and top-points—critical points with degenerate Hessian—and monitor their displacements. respectively generic morsifications in scale-space. Relevant parts of catastrophe theory in the context of the scale-space paradigm are briefly reviewed. and subsequently rewritten into coordinate independent form. This enables one to implement topological descriptors using a conveniently defined coordinate system.,True,qbzezVEAAAAJ:qjMakFHDy7sC,164,https://link.springer.com/article/10.1023/A:1008304909717,10969090357208466323,/scholar?cites=10969090357208466323,,,https://dspace.library.uu.nl/bitstream/handle/1874/18929/florack_98_the_topological.pdf?sequence=1,0,0,0
1279002,Higher order differential structure of images,1993,Bart M ter Haar Romeny and Luc MJ Florack and Alfons H Salden and Max A Viergever,,,,77-93,Springer. Berlin. Heidelberg,This paper is meant as a tutorial on the basic concepts for vision in the ’Koenderink’ school. The concept of scale-space is a necessity. if the extraction of structure from measured physical signals (i.e. images) is at stage. The Gaussian derivative kernels then are for physical signals the natural analogs of the mathematical differential operators. This paper discusses first some interesting properties of the Gaussian derivative kernels. like their orthogonality and behaviour with noisy input data. Geometrical structure to extract is expressed as differential invariants. in this paper limited to invariants under orthogonal transformations. Three representations are summarized: Cartesian. gauge and manifest invariant notation. Many explicit examples are given. A section is included about computer implementation of the calculation of higher order invariant structure.,True,qbzezVEAAAAJ:2osOgNQ5qMEC,161,https://link.springer.com/chapter/10.1007/BFb0013782,9416530109123664973,/scholar?cites=9416530109123664973,,,http://www.frontendvision.net/2018/wp-content/uploads/2018/11/Romeny1994-HigherOrder.pdf,0,0,0
1279003,On the axioms of scale space theory,2004,Remco Duits and Luc Florack and Jan De Graaf and Bart ter Haar Romeny,20,Journal of Mathematical Imaging and Vision,3,267-298,Kluwer Academic Publishers,We consider alternative scale space representations beyond the well-established Gaussian case that satisfy all “reasonable” axioms. One of these turns out to be subject to a first order pseudo partial differential equation equivalent to the Laplace equation on the upper half plane {(x. s) ∈ ℝ d  × ℝ | s > 0}. We investigate this so-called Poisson scale space and show that it is indeed a viable alternative to Gaussian scale space. Poisson and Gaussian scale space are related via a one-parameter class of operationally well-defined intermediate representations generated by a fractional power of (minus) the spatial Laplace operator.,True,qbzezVEAAAAJ:YsMSGLbcyi4C,152,https://link.springer.com/article/10.1023/B:JMIV.0000024043.96722.aa,10628918236190216638,/scholar?cites=10628918236190216638,,,https://research.tue.nl/files/1995486/595679.pdf,0,0,0
1279004,The Gaussian scale-space paradigm and the multiscale local jet,1996,Luc Florack and Bart Ter Haar Romeny and Max Viergever and Jan Koenderink,18,International Journal of Computer Vision,1,61-75,Kluwer Academic Publishers,A representation of local image structure is proposed which takes into account both the image's spatial structure at a given location. as well as its “deep structure”. that is. its local behaviour as a function of scale or resolution (scale-space). This is of interest for several low-level image tasks. The proposed basis of scale-space. for example. enables a precise local study of interactions of neighbouring image intensities in the course of the blurring process. It also provides an extrapolation scheme for local image data. obtained at a given spatial location and resolution. to a finite scale-space neighbourhood. This is especially useful for the determination of sampling rates and for interpolation algorithms in a multilocal context. Another. particularly straightforward application is image enhancement or deblurring. which is an instance of data extrapolation in the high-resolution direction.A potentially interesting …,True,qbzezVEAAAAJ:W7OEmFMy1HYC,150,https://link.springer.com/article/10.1007/BF00126140,13635067205969252478,/scholar?cites=13635067205969252478,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.551.3575&rep=rep1&type=pdf,0,0,0
1279005,Linear scale-space,1994,Luc MJ Florack and Bart M ter Haar Romeny and Jan J Koenderink and Max A Viergever,4,Journal of Mathematical Imaging and Vision,4,325-351,Kluwer Academic Publishers,The formulation of afront-end or“early vision” system is addressed. and its connection with scale-space is shown. A front-end vision system is designed to establish a convenient format of some sampled scalar field. which is suited for postprocessing by various dedicated routines. The emphasis is on the motivations and implications of symmetries of the environment; they pose natural. a priori constraints on the design of a front-end.The focus is on static images. defined on a multidimensional spatial domain. for which it is assumed that there are no a priori preferred points. directions. or scales. In addition. the front-end is required to be linear. These requirements are independent of any particular image geometry and express the front-end's pure syntactical. “bottom up” nature.It is shown that these symmetries suffice to establish the functionality properties of a front-end. For each location in the …,True,qbzezVEAAAAJ:IjCSPb-OGe4C,149,https://link.springer.com/article/10.1007/BF01262401,9637305252080996460,/scholar?cites=9637305252080996460,,,https://www.academia.edu/download/40575612/Linear_scale-space20151202-13866-eczf84.pdf,0,0,0
1279006,Learning hierarchical features for scene labeling,2012,Clement Farabet and Camille Couprie and Laurent Najman and Yann LeCun,35,IEEE transactions on pattern analysis and machine intelligence,8,1915-1929,IEEE,Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features. and produces a powerful representation that captures texture. shape. and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those. we propose a technique to automatically retrieve. from a pool of segmentation components. an optimal set of components that best explain the scene; these components are arbitrary. for example. they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona …,True,1T2Xh68AAAAJ:WF5omc3nYNoC,2700,https://ieeexplore.ieee.org/abstract/document/6338939/,4430348583332880731,/scholar?cites=4430348583332880731,,,http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/1028/Scene_Labeling.pdf,0,0,0
1279007,Deep multi-scale video prediction beyond mean square error,2015,Michael Mathieu and Camille Couprie and Yann LeCun,,,,,,Learning to predict future images from a video sequence involves the construction of an internal representation that models the image evolution accurately. and therefore. to some degree. its content and dynamics. This is why pixel-space video prediction may be viewed as a promising avenue for unsupervised feature learning. In addition. while optical flow has been a very studied problem in computer vision for a long time. future frame prediction is rarely approached. Still. many vision applications could benefit from the knowledge of the next frames of videos. that does not require the complexity of tracking every pixel trajectories. In this work. we train a convolutional network to generate future frames given an input sequence. To deal with the inherently blurry predictions obtained from the standard Mean Squared Error (MSE) loss function. we propose three different and complementary feature learning strategies: a multi-scale architecture. an adversarial training method. and an image gradient difference loss function. We compare our predictions to different published results based on recurrent neural networks on the UCF101 dataset,True,1T2Xh68AAAAJ:M3ejUd6NZC8C,1397,https://arxiv.org/abs/1511.05440,2726105701998692678,/scholar?cites=2726105701998692678,,,https://arxiv.org/pdf/1511.05440.pdf%5D,0,0,0
1279008,Semantic segmentation using adversarial networks,2016,Pauline Luc and Camille Couprie and Soumith Chintala and Jakob Verbeek,,arXiv preprint arXiv:1611.08408,,,,Adversarial training has been shown to produce state of the art results for generative image modeling. In this paper we propose an adversarial training approach to train semantic segmentation models. We train a convolutional semantic segmentation network along with an adversarial network that discriminates segmentation maps coming either from the ground truth or from the segmentation network. The motivation for our approach is that it can detect and correct higher-order inconsistencies between ground truth segmentation maps and the ones produced by the segmentation net. Our experiments show that our adversarial training approach leads to improved accuracy on the Stanford Background and PASCAL VOC 2012 datasets.,True,1T2Xh68AAAAJ:QIV2ME_5wuYC,529,https://arxiv.org/abs/1611.08408,14128093309117410333,/scholar?cites=14128093309117410333,,,https://arxiv.org/pdf/1611.08408.pdf%5D,0,0,0
1279009,Indoor semantic segmentation using depth information,2013,Camille Couprie and Clément Farabet and Laurent Najman and Yann LeCun,,,arXiv preprint arXiv:1301.3572,,,This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently. most works still rely on hand-crafted features. In contrast. we apply a multiscale convolutional network to learn features directly from the images and the depth information. We obtain state-of-the-art on the NYU-v2 depth dataset with an accuracy of 64.5%. We illustrate the labeling of indoor scenes in videos sequences that could be processed in real-time using appropriate hardware such as an FPGA.,True,1T2Xh68AAAAJ:LkGwnXOMwfcC,417,https://arxiv.org/abs/1301.3572,8998397382018253620,/scholar?cites=8998397382018253620,,,https://arxiv.org/pdf/1301.3572,0,0,0
1279010,Power watershed: A unifying graph-based optimization framework,2010,Camille Couprie and Leo Grady and Laurent Najman and Hugues Talbot,33,IEEE transactions on pattern analysis and machine intelligence,7,1384-1399,IEEE,In this work. we extend a common framework for graph-based image segmentation that includes the graph cuts. random walker. and shortest path optimization algorithms. Viewing an image as a weighted graph. these algorithms can be expressed by means of a common energy function with differing choices of a parameter q acting as an exponent on the differences between neighboring nodes. Introducing a new parameter p that fixes a power for the edge weights allows us to also include the optimal spanning forest algorithm for watershed in this same framework. We then propose a new family of segmentation algorithms that fixes p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm. which we term the power watershed. In particular. when q=2. the power watershed leads to a multilabel. scale and contrast invariant. unique global optimum obtained in practice in …,True,1T2Xh68AAAAJ:u-x6o8ySG0sC,350,https://ieeexplore.ieee.org/abstract/document/5639015/,5967201595225707241,/scholar?cites=5967201595225707241,,,https://www.researchgate.net/profile/Hugues_Talbot/publication/224196187_Power_Watershed_A_Unifying_Graph-Based_Optimization_Framework/links/0046352cec6c478c5d000000.pdf,0,0,0
1279011,Scene parsing with multiscale feature learning. purity trees. and optimal covers,2012,Clément Farabet and Camille Couprie and Laurent Najman and Yann LeCun,,,,,,"Scene parsing. or semantic segmentation. consists in labeling each pixel in an image with the category of the object it belongs to. It is a challenging task that involves the simultaneous detection. segmentation and recognition of all the objects in the image.The scene parsing method proposed here starts by computing a tree of segments from a graph of pixel dissimilarities. Simultaneously. a set of dense feature vectors is computed which encodes regions of multiple sizes centered on each pixel. The feature extractor is a multiscale convolutional network trained from raw pixels. The feature vectors associated with the segments covered by each node in the tree are aggregated and fed to a classifier which produces an estimate of the distribution of object categories contained in the segment. A subset of tree nodes that cover the image are then selected so as to maximize the average"" purity"" of the class distributions. hence maximizing the overall likelihood that each segment will contain a single object. The convolutional network feature extractor is trained end-to-end from raw pixels. alleviating the need for engineered features. After training. the system is parameter free.",True,1T2Xh68AAAAJ:W7OEmFMy1HYC,234,https://arxiv.org/abs/1202.2160,6844699399494671685,/scholar?cites=6844699399494671685,,,https://arxiv.org/pdf/1202.2160,0,0,0
1279012,Predicting deeper into the future of semantic segmentation,2017,Pauline Luc and Natalia Neverova and Camille Couprie and Jakob Verbeek and Yann LeCun,,,,648-657,,The ability to predict and therefore to anticipate the future is an important attribute of intelligence. It is also of utmost importance in real-time systems. eg. in robotics or autonomous driving. which depend on visual scene understanding for decision making. While prediction of the raw RGB pixel values in future video frames has been studied in previous work. here we introduce the novel task of predicting semantic segmentations of future frames. Given a sequence of video frames. our goal is to predict segmentation maps of not yet observed video frames that lie up to a second or further in the future. We develop an autoregressive convolutional neural network that learns to iteratively generate multiple frames. Our results on the Cityscapes dataset show that directly predicting future segmentations is substantially better than predicting and then segmenting future RGB frames. Prediction results up to half a second in the future are visually convincing and are much more accurate than those of a baseline based on warping semantic segmentations using optical flow.,True,1T2Xh68AAAAJ:iH-uZ7U-co4C,186,http://openaccess.thecvf.com/content_iccv_2017/html/Luc_Predicting_Deeper_Into_ICCV_2017_paper.html,12299910231065503543,/scholar?cites=12299910231065503543,,,https://openaccess.thecvf.com/content_ICCV_2017/papers/Luc_Predicting_Deeper_Into_ICCV_2017_paper.pdf,0,0,0
1279013,Power watersheds: A new image segmentation framework extending graph cuts. random walker and optimal spanning forest,2009,Camille Couprie and Leo Grady and Laurent Najman and Hugues Talbot,,,,731-738,IEEE,In this work. we extend a common framework for seeded image segmentation that includes the graph cuts. random walker. and shortest path optimization algorithms. Viewing an image as a weighted graph. these algorithms can be expressed by means of a common energy function with differing choices of a parameter q acting as an exponent on the differences between neighboring nodes. Introducing a new parameter p that fixes a power for the edge weights allows us to also include the optimal spanning forest algorithm for watersheds in this same framework. We then propose a new family of segmentation algorithms that fixes p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm. which we term power watersheds. Placing the watershed algorithm in this energy minimization framework also opens new possibilities for using unary terms in traditional watershed …,True,1T2Xh68AAAAJ:u5HHmVD_uO8C,172,https://ieeexplore.ieee.org/abstract/document/5459284/,9822415093216837734,/scholar?cites=9822415093216837734,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212.3407&rep=rep1&type=pdf,0,0,0
1279014,Dual constrained TV-based regularization on graphs,2013,Camille Couprie and Leo Grady and Laurent Najman and Jean-Christophe Pesquet and Hugues Talbot,6,SIAM Journal on Imaging Sciences,3,1246-1273,Society for Industrial and Applied Mathematics,Algorithms based on total variation (TV) minimization are prevalent in image processing. They play a key role in a variety of applications such as image denoising. compressive sensing. and inverse problems in general. In this work. we extend the TV dual framework that includes Chambolle's and Gilboa and Osher's projection algorithms for TV minimization. We use a flexible graph data representation that allows us to generalize the constraint on the projection variable. We show how this new formulation of the TV problem may be solved by means of fast parallel proximal algorithms. In denoising and deblurring examples. the proposed approach is shown not only to perform better than recent TV-based approaches. but also to perform well on arbitrary graphs instead of regular grids. The proposed method consequently applies to a variety of other inverse problems including image fusion and mesh filtering.,True,1T2Xh68AAAAJ:ufrVoPGSRksC,63,https://epubs.siam.org/doi/abs/10.1137/120895068,9908709635450582472,/scholar?cites=9908709635450582472,,,https://hal-upec-upem.archives-ouvertes.fr/docs/00/81/62/23/PDF/journal_DCTV.pdf,0,0,0
1279015,Toward real-time indoor semantic segmentation using depth information,2014,Camille Couprie and Clément Farabet and Laurent Najman and Yann LeCun,,Journal of Machine Learning Research,,,Microtome Publishing,This work addresses multi-class segmentation of indoor scenes with RGB-D inputs. While this area of research has gained much attention recently. most works still rely on handcrafted features. In contrast. we apply a multiscale convolutional network to learn features directly from the images and the depth information. Using a frame by frame labeling. we obtain nearly state-of-the-art performance on the NYU-v2 depth dataset with an accuracy of 64.5%. We then show that the labeling can be further improved by exploiting the temporal consistency in the video sequence of the scene. To that goal. we present a method producing temporally consistent superpixels from a streaming video. Among the different methods producing superpixel segmentations of an image. the graph-based approach of Felzenszwalb and Huttenlocher is broadly employed. One of its interesting properties is that the regions are computed in a greedy manner in quasi-linear time by using a minimum spanning tree. In a framework exploiting minimum spanning trees all along. we propose an efficient video segmentation approach that computes temporally consistent pixels in a causal manner. filling the need for causal and real-time applications. We illustrate the labeling of indoor scenes in video sequences that could be processed in real-time using appropriate hardware such as an FPGA.,True,1T2Xh68AAAAJ:4DMP91E08xMC,47,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.431.9275&rep=rep1&type=pdf,8723472047546675100,/scholar?cites=8723472047546675100,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.431.9275&rep=rep1&type=pdf,0,0,0
1279016,Predicting future instance segmentation by forecasting convolutional features,2018,Pauline Luc and Camille Couprie and Yann Lecun and Jakob Verbeek,,,,584-599,,"Anticipating future events is an important prerequisite towards intelligent behavior. Video forecasting has been studied as a proxy task towards this goal. Recent work has shown that to predict semantic segmentation of future frames. forecasting at the semantic level is more effective than forecasting RGB frames and then segmenting these. In this paper we consider the more challenging problem of future instance segmentation. which additionally segments out individual objects. To deal with a varying number of output labels per image. we develop a predictive model in the space of fixed-sized convolutional features of the Mask R-CNN instance segmentation model. We apply the"" detection head"" of Mask R-CNN on the predicted features to produce the instance segmentation of future frames. Experiments show that this approach significantly improves over strong baselines based on optical flow and repurposed instance segmentation architectures.",True,1T2Xh68AAAAJ:TFP_iSt0sucC,43,http://openaccess.thecvf.com/content_ECCV_2018/html/Pauline_Luc_Predicting_Future_Instance_ECCV_2018_paper.html,9361174918280550859,/scholar?cites=9361174918280550859,,,http://openaccess.thecvf.com/content_ECCV_2018/papers/Pauline_Luc_Predicting_Future_Instance_ECCV_2018_paper.pdf,0,0,0
1279017,Domain transform for edge-aware image and video processing,2011,Eduardo SL Gastal and Manuel M Oliveira,30,ACM Transactions on Graphics (TOG),4,69,ACM,We present a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves. adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters. show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations. and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings; its computational cost is not affected by the choice of the filter parameters; and it is the first edge-preserving …,True,f2UrnmAAAAAJ:LkGwnXOMwfcC,771,https://dl.acm.org/doi/abs/10.1145/1964921.1964964,10050534801272867223,/scholar?cites=10050534801272867223,,,http://www.inf.ufrgs.br/~eslgastal/DomainTransform/Gastal_Oliveira_SIGGRAPH2011_Domain_Transform.pdf,0,0,0
1279018,Fast digital image inpainting,2001,Manuel M. Oliveira and Brian Bowen and Richard McKenna and Yu-Sung Chang,,"Appeared in the Proceedings of the International Conference on Visualization, Imaging and Image Processing (VIIP 2001), Marbella, Spain",,,,,True,f2UrnmAAAAAJ:TFP_iSt0sucC,561,,11753513186241446369,/scholar?cites=11753513186241446369,,,,0,0,0
1279019,Real-time line detection through an improved Hough transform voting scheme,2008,Leandro AF Fernandes and Manuel M Oliveira,41,Pattern recognition,1,299-314,Pergamon,The Hough transform (HT) is a popular tool for line detection due to its robustness to noise and missing data. However. the computational cost associated to its voting scheme has prevented software implementations to achieve real-time performance. except for very small images. Many dedicated hardware designs have been proposed. but such architectures restrict the image sizes they can handle. We present an improved voting scheme for the HT that allows a software implementation to achieve real-time performance even on relatively large images. Our approach operates on clusters of approximately collinear pixels. For each cluster. votes are cast using an oriented elliptical-Gaussian kernel that models the uncertainty associated with the best-fitting line with respect to the corresponding cluster. The proposed approach not only significantly improves the performance of the voting scheme. but also produces a …,True,f2UrnmAAAAAJ:YOwf2qJgpHMC,474,https://www.sciencedirect.com/science/article/pii/S0031320307001823,4846234338148016188,/scholar?cites=4846234338148016188,,,https://www.academia.edu/download/49093857/Real-time_line_detection_through_an_impr20160924-14383-95su0u.pdf,0,0,0
1279020,Relief texture mapping,2000,Manuel M Oliveira and Gary Bishop and David McAllister,,,,359-368,,We present an extension to texture mapping that supports the representation of 3-D surface details and view motion parallax. The results are correct for viewpoints that are static or moving. far away or nearby. Our approach is very simple: a relief texture (texture extended with an orthogonal displacement per texel) is mapped onto a polygon using a two-step process: First. it is converted into an ordinary texture using a surprisingly simple 1-D forward transform. The resulting texture is then mapped onto the polygon using standard texture mapping. The 1-D warping functions work in texture coordinates to handle the parallax and visibility changes that result from the 3-D shape of the displacement surface. The subsequent texture-mapping operation handles the transformation from texture to screen coordinates.,True,f2UrnmAAAAAJ:Tyk-4Ss8FVUC,444,https://dl.acm.org/doi/abs/10.1145/344779.344947,5316476052690542605,/scholar?cites=5316476052690542605,,,http://artis.imag.fr/Membres/Gilles.Debunne/Enseignement/DEA/PDF/IBR/ReliefTextureMapping.pdf,0,0,0
1279021,Real-time relief mapping on arbitrary polygonal surfaces,2005,Fábio Policarpo and Manuel M Oliveira and Joao LD Comba,,,,155-162,,This paper presents a technique for mapping relief textures onto arbitrary polygonal models in real time. In this approach. the mapping of the relief data is done in tangent space. As a result. it can be applied to polygonal representations of curved surfaces producing correct self-occlusions. interpenetrations. shadows and per-pixel lighting effects. The approach can be used to consistently add surface details to geometric models undergoing deformations. such as in the case of animated characters commonly found in games. The technique uses an inverse formulation (ie. pixel driven) based on an efficient ray-height-field intersection algorithm implemented on the GPU. It supports extreme close-up views of the surfaces. mip mapping and anisotropic texture filtering. Also. contrary to high-dimensional representations of surface details. the low memory requirements of the proposed technique do not restrict its use to tiled …,True,f2UrnmAAAAAJ:Y0pCki6q_DkC,352,https://dl.acm.org/doi/abs/10.1145/1053427.1053453,11316975398087384666,/scholar?cites=11316975398087384666,,,http://www.inf.ufrgs.br/~oliveira/pubs_files/Policarpo_Oliveira_Comba_RTRM_I3D_2005.pdf,0,0,0
1279022,Shared sampling for real‐time alpha matting,2010,Eduardo SL Gastal and Manuel M Oliveira,29,Computer Graphics Forum,2,575-584,Blackwell Publishing Ltd,Image matting aims at extracting foreground elements from an image by means of color and opacity (alpha) estimation. While a lot of progress has been made in recent years on improving the accuracy of matting techniques. one common problem persisted: the low speed of matte computation. We present the first real‐time matting technique for natural images and videos. Our technique is based on the observation that. for small neighborhoods. pixels tend to share similar attributes. Therefore. independently treating each pixel in the unknown regions of a trimap results in a lot of redundant work. We show how this computation can be significantly and safely reduced by means of a careful selection of pairs of background and foreground samples. Our technique achieves speedups of up to two orders of magnitude compared to previous ones. while producing high‐quality alpha mattes. The quality of our results has …,True,f2UrnmAAAAAJ:UebtZRa9Y70C,337,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01627.x,2364865259612614487,/scholar?cites=2364865259612614487,,,http://www.inf.ufrgs.br/~eslgastal/SharedMatting/Gastal_Oliveira_EG2010_Shared_Matting.pdf,0,0,0
1279023,Adaptive manifolds for real-time high-dimensional filtering,2012,Eduardo SL Gastal and Manuel M Oliveira,31,ACM Transactions on Graphics (TOG),4,1-13,ACM,We present a technique for performing high-dimensional filtering of images and videos in real time. Our approach produces high-quality results and accelerates filtering by computing the filter's response at a reduced set of sampling points. and using these for interpolation at all N input pixels. We show that for a proper choice of these sampling points. the total cost of the filtering operation is linear both in N and in the dimension d of the space in which the filter operates. As such. ours is the first high-dimensional filter with such a complexity. We present formal derivations for the equations that define our filter. as well as for an algorithm to compute the sampling points. This provides a sound theoretical justification for our method and for its properties. The resulting filter is quite flexible. being capable of producing responses that approximate either standard Gaussian. bilateral. or non-local-means filters. Such flexibility …,True,f2UrnmAAAAAJ:YsMSGLbcyi4C,255,https://dl.acm.org/doi/abs/10.1145/2185520.2185529,7067329148390779836,/scholar?cites=7067329148390779836,,,https://www.researchgate.net/profile/Manuel_Oliveira8/publication/234188790_Adaptive_Manifolds_for_Real-Time_High-Dimensional_Filtering/links/0a85e53237d8e9ecdc000000.pdf,0,0,0
1279024,Photorealistic models for pupil light reflex and iridal pattern deformation,2009,Vitor F Pamplona and Manuel M Oliveira and Gladimir VG Baranoski,28,ACM Transactions on Graphics (TOG),4,1-12,ACM,We introduce a physiologically-based model for pupil light reflex (PLR) and an image-based model for iridal pattern deformation. Our PLR model expresses the pupil diameter as a function of the lighting of the environment. and is described by a delay-differential equation. naturally adapting the pupil diameter even to abrupt changes in light conditions. Since the parameters of our PLR model were derived from measured data. it correctly simulates the actual behavior of the human pupil. Another contribution of our work is a model for realistic deformation of the iris pattern as a function of pupil dilation and constriction. Our models produce high-fidelity appearance effects and can be used to produce real-time predictive animations of the pupil and iris under variable lighting conditions. We assess the predictability and quality of our simulations through comparisons of modeled results against measured data derived from …,True,f2UrnmAAAAAJ:8k81kl-MbHgC,169,https://dl.acm.org/doi/abs/10.1145/1559755.1559763,7259979905350932678,/scholar?cites=7259979905350932678,,,https://www.lume.ufrgs.br/bitstream/handle/10183/15309/000677246.pdf?sequence=1,0,0,0
1279025,A hole-filling strategy for reconstruction of smooth surfaces in range images,2003,Jianning Wang and Manuel M Oliveira,,,,11-18,IEEE,Creating models of real scenes is a complex task for which the use of traditional modelling techniques is inappropriate. For this task. laser rangefinders are frequently used to sample the scene from several viewpoints. with the resulting range images integrated into a final model. In practice. due to surface reflectance properties. occlusions and accessibility limitations. certain areas of the scenes are usually not sampled. leading to holes and introducing undesirable artifacts in the resulting models. We present an algorithm for filling holes on surfaces reconstructed from point clouds. The algorithm is based on moving least squares and can recover both geometry and shading information. providing a good alternative when the properties to be reconstructed are locally smooth. The reconstruction process is mostly automatic and the sampling rate in the reconstructed areas follows the given samples. We demonstrate the …,True,f2UrnmAAAAAJ:4TOpqqG69KYC,168,https://ieeexplore.ieee.org/abstract/document/1240986/,15476880944977604357,/scholar?cites=15476880944977604357,,,https://www.researchgate.net/profile/Manuel_Oliveira8/publication/4040989_A_hole-filling_strategy_for_reconstruction_of_smooth_surfaces_in_range_images/links/0f317532dc8e274f3c000000.pdf,0,0,0
1279026,Overview and state-of-the-art of uncertainty visualization,2014,Georges-Pierre Bonneau and Hans-Christian Hege and Chris R Johnson and Manuel M Oliveira and Kristin Potter and Penny Rheingans and Thomas Schultz,,,,3-27,Springer. London,The goal of visualization is to effectively and accurately communicate data. Visualization research has often overlooked the errors and uncertainty which accompany the scientific process and describe key characteristics used to fully understand the data. The lack of these representations can be attributed. in part. to the inherent difficulty in defining. characterizing. and controlling this uncertainty. and in part. to the difficulty in including additional visual metaphors in a well designed. potent display. However. the exclusion of this information cripples the use of visualization as a decision making tool due to the fact that the display is no longer a true representation of the data. This systematic omission of uncertainty commands fundamental research within the visualization community to address. integrate. and expect uncertainty information. In this chapter. we outline sources and models of uncertainty. give an …,True,f2UrnmAAAAAJ:XiSMed-E-HIC,155,https://link.springer.com/chapter/10.1007/978-1-4471-6497-5_1,10075940536454430861,/scholar?cites=10075940536454430861,,,https://sdm.lbl.gov/sdav/images/publications/Bon2014a/Overview-Uncertainty-Visualization-2015.pdf,0,0,0
1279027,A physiologically-based model for simulation of color vision deficiency,2009,Gustavo M Machado and Manuel M Oliveira and Leandro AF Fernandes,15,IEEE transactions on visualization and computer graphics,6,1291-1298,IEEE,Color vision deficiency (CVD) affects approximately 200 million people worldwide. compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision. anomalous trichromacy. and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of …,True,f2UrnmAAAAAJ:5nxA0vEk-isC,143,https://ieeexplore.ieee.org/abstract/document/5290741/,6193801814411777075,/scholar?cites=6193801814411777075,,,https://www.lume.ufrgs.br/bitstream/handle/10183/27630/000751721.pdf,0,0,0
1279028,Medical image analysis with artificial neural networks,2010,Jianmin Jiang and P Trundle and Jinchang Ren,34,Computerized Medical Imaging and Graphics,8,617-631,Pergamon,Given that neural networks have been widely reported in the research community of medical imaging. we provide a focused literature survey on recent neural network developments in computer-aided diagnosis. medical image segmentation and edge detection towards visual content analysis. and medical image registration for its pre-processing and post-processing. with the aims of increasing awareness of how neural networks can be applied to these areas and to provide a foundation for further research and practical development. Representative techniques and algorithms are explained in detail to provide inspiring examples illustrating: (i) how a known neural network with fixed structure and training procedure could be applied to resolve a medical imaging problem; (ii) how medical images could be analysed. processed. and characterised by neural networks; and (iii) how neural networks could be expanded …,True,IpMcSfcAAAAJ:hFOr9nPyWt4C,355,https://www.sciencedirect.com/science/article/pii/S0895611110000741,14093165290381582866,/scholar?cites=14093165290381582866,,,https://strathprints.strath.ac.uk/29267/1/Medical_Imaging_ANN_v1.pdf,0,0,0
1279029,Image compression with neural networks–a survey,1999,J Jiang,14,Signal processing: image Communication,9,737-760,Elsevier,Apart from the existing technology on image compression represented by series of JPEG. MPEG and H.26x standards. new technology such as neural networks and genetic algorithms are being developed to explore the future of image coding. Successful applications of neural networks to vector quantization have now become well established. and other aspects of neural network involvement in this area are stepping up to play significant roles in assisting with those traditional technologies. This paper presents an extensive survey on the development of neural networks for image compression which covers three categories: direct image compression by neural networks; neural network implementation of existing techniques. and neural network based technology which provide improvement over traditional algorithms.,True,IpMcSfcAAAAJ:8k81kl-MbHgC,252,https://www.sciencedirect.com/science/article/pii/S0923596598000411,5087202662655794701,/scholar?cites=5087202662655794701,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.6973&rep=rep1&type=pdf,0,0,0
1279030,A novel feature selection approach for biomedical data classification,2010,Yonghong Peng and Zhiqing Wu and Jianmin Jiang,43,Journal of Biomedical Informatics,1,15-23,Academic Press,This paper presents a novel feature selection approach to deal with issues of high dimensionality in biomedical data classification. Extensive research has been performed in the field of pattern recognition and machine learning. Dozens of feature selection methods have been developed in the literature. which can be classified into three main categories: filter. wrapper and hybrid approaches. Filter methods apply an independent test without involving any learning algorithm. while wrapper methods require a predetermined learning algorithm for feature subset evaluation. Filter and wrapper methods have their. respectively. drawbacks and are complementary to each other in that filter approaches have low computational cost with insufficient reliability in classification while wrapper methods tend to have superior classification accuracy but require great computational power. The approach proposed in this paper …,True,IpMcSfcAAAAJ:ZeXyd9-uunAC,240,https://www.sciencedirect.com/science/article/pii/S1532046409001014,6489914583916331526,/scholar?cites=6489914583916331526,,,https://www.sciencedirect.com/science/article/pii/S1532046409001014,0,0,0
1279031,A simple pooling-based design for real-time salient object detection,2019,Jiang-Jiang Liu and Qibin Hou and Ming-Ming Cheng and Jiashi Feng and Jianmin Jiang,,,,3917-3926,,We solve the problem of salient object detection by investigating how to expand the role of pooling in convolutional neural networks. Based on the U-shape architecture. we first build a global guidance module (GGM) upon the bottom-up pathway. aiming at providing layers at different feature levels the location information of potential salient objects. We further design a feature aggregation module (FAM) to make the coarse-level semantic information well fused with the fine-level features from the top-down path-way. By adding FAMs after the fusion operations in the top-down pathway. coarse-level features from the GGM can be seamlessly merged with features at various scales. These two pooling-based modules allow the high-level semantic features to be progressively refined. yielding detail enriched saliency maps. Experiment results show that our proposed approach can more accurately locate the salient objects with sharpened details and hence substantially improve the performance compared to the previous state-of-the-arts. Our approach is fast as well and can run at a speed of more than 30 FPS when processing a 300x400 image. Code can be found at http://mmcheng. net/poolnet/.,True,IpMcSfcAAAAJ:FGCrkofroJsC,194,http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.html,2400314036830544160,/scholar?cites=2400314036830544160,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.pdf,0,0,0
1279032,The spatial relationship of DCT coefficients between a block and its sub-blocks,2002,Jianmin Jiang and Guocan Feng,50,IEEE transactions on signal processing,5,1160-1169,IEEE,At present. almost all digital images are stored and transferred in their compressed format in which discrete cosine transform (DCT)-based compression remains one of the most important data compression techniques due to the efforts from JPEG. In order to save the computation and memory cost. it is desirable to have image processing operations such as feature extraction. image indexing. and pattern classifications implemented directly in the DCT domain. To this end. we present in this paper a generalized analysis of spatial relationships between the DCTs of any block and its sub-blocks. The results reveal that DCT coefficients of any block can be directly obtained from the DCT coefficients of its sub-blocks and that the interblock relationship remains linear. It is useful in extracting global features in the compressed domain for general image processing tasks such as those widely used in pyramid algorithms and …,True,IpMcSfcAAAAJ:MXK_kJrjxJIC,171,https://ieeexplore.ieee.org/abstract/document/995072/,12685314100930777427,/scholar?cites=12685314100930777427,,,https://pdfs.semanticscholar.org/90f5/dd564495a0451193ea087af6f542f95d9c53.pdf,0,0,0
1279033,Authentication protocols for internet of things: a comprehensive survey,2017,Mohamed Amine Ferrag and Leandros A Maglaras and Helge Janicke and Jianmin Jiang and Lei Shu,2017,,,,Hindawi,In this paper. a comprehensive survey of authentication protocols for Internet of Things (IoT) is presented. Specifically more than forty authentication protocols developed for or applied in the context of the IoT are selected and examined in detail. These protocols are categorized based on the target environment: (1) Machine to Machine Communications (M2M). (2) Internet of Vehicles (IoV). (3) Internet of Energy (IoE). and (4) Internet of Sensors (IoS). Threat models. countermeasures. and formal security verification techniques used in authentication protocols for the IoT are presented. In addition a taxonomy and comparison of authentication protocols that are developed for the IoT in terms of network model. specific security goals. main processes. computation complexity. and communication overhead are provided. Based on the current survey. open issues are identified and future research directions are proposed.,True,IpMcSfcAAAAJ:6LI0FKmQuhEC,148,https://www.hindawi.com/journals/scn/2017/6562953/abs/,7542764407164348389,/scholar?cites=7542764407164348389,,,https://www.hindawi.com/journals/scn/2017/6562953/abs/,0,0,0
1279034,JPEG compressed image retrieval via statistical features,2003,Guocan Feng and Jianmin Jiang,36,Pattern recognition,4,977-985,Pergamon,To improve efficiency of compressed image retrieval. we propose a novel statistical feature extraction algorithm in this paper to characterize the image content directly in its compressed domain. The statistical feature extracted is mainly through computing a set of moments directly from DCT coefficients without involving full decompression or inverse DCT. Following the algorithm design. a content-based image retrieval system is implemented especially targeting retrieving joint picture expert group compressed images. Theoretical analysis and experimental results support that the system is robust to translation. rotation and scale transform with minor disturbance. and the system achieves good performances in terms of retrieval efficiency and effectiveness.,True,IpMcSfcAAAAJ:3fE2CSJIrl8C,135,https://www.sciencedirect.com/science/article/pii/S0031320302001140,2621837320638104054,/scholar?cites=2621837320638104054,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.8410&rep=rep1&type=pdf,0,0,0
1279035,Offline handwritten Arabic cursive text recognition using Hidden Markov Models and re-ranking,2011,Jawad H AlKhateeb and Jinchang Ren and Jianmin Jiang and Husni Al-Muhtaseb,32,Pattern Recognition Letters,8,1081-1088,North-Holland,Recognition of handwritten Arabic cursive texts is a complex task due to the similarities between letters under different writing styles. In this paper. a word-based off-line recognition system is proposed. using Hidden Markov Models (HMMs). The method employed involves three stages. namely preprocessing. feature extraction and classification. First. words from input scripts are segmented and normalized. Then. a set of intensity features are extracted from each of the segmented words. which is based on a sliding window moving across each mirrored word image. Meanwhile. structure-like features are also extracted including number of subwords and diacritical marks. Finally. these features are applied in a combined scheme for classification. Intensity features are used to train a HMM classifier. whose results are re-ranked using structure-like features for improved recognition rate. In order to validate the proposed …,True,IpMcSfcAAAAJ:tKAzc9rXhukC,122,https://www.sciencedirect.com/science/article/pii/S0167865511000432,1072817639060575463,/scholar?cites=1072817639060575463,,,https://strathprints.strath.ac.uk/48363/1/Jawad_PRL.pdf,0,0,0
1279036,Late Quaternary climate change in Eastern North America: A comparison of pollen-derived estimates with climate model results,1998,Thompson Webb III and Katherine H Anderson and Patrick J Bartlein and Robert S Webb,17,,6-7,587-606,Pergamon,Late Quaternary pollen data from eastern North America and pollen-climate response surfaces provide tests of the climate simulations from Version 1 of the National Center for Atmospheric Research (NCAR) Community Climate Model (CCM1) for 21. 16. 14. 11. and 6 ka. The model results are also compared to those from Version 0 of the NCAR model (CCM0). In contrast to CCM0. CCM1 used a slab ocean model to compute sea surface temperatures. included a seasonal cycle. and computed soil moisture. It also used an improved set of boundary conditions from 21 to 6 ka. In eastern North America. CCM1 simulated lower temperatures at the last glacial maximum (LGM) 21.000 years ago than did CCM0 and therefore was in better agreement with the pollen data than the CCM0 simulations were. The simulations by CCM1 for mean July temperatures from 16 to 11 ka. however. were much higher than those by …,True,IpMcSfcAAAAJ:7bRg-L-9LFcC,117,https://www.sciencedirect.com/science/article/pii/S0277379198000134,13767743139329504819,/scholar?cites=13767743139329504819,,,http://www.geo.brown.edu/georesearch/esh/QE/Publications/QSR1998/TWebb/ClimateComparisons/ClimateComparison.pdf,0,0,0
1279037,Perceptual image hashing based on virtual watermark detection,2009,Fouad Khelifi and Jianmin Jiang,19,IEEE Transactions on Image Processing,4,981-994,IEEE,This paper proposes a new robust and secure perceptual image hashing technique based on virtual watermark detection. The idea is justified by the fact that the watermark detector responds similarly to perceptually close images using a non embedded watermark. The hash values are extracted in binary form with a perfect control over the probability distribution of the hash bits. Moreover. a key is used to generate pseudo-random noise whose real values contribute to the randomness of the feature vector with a significantly increased uncertainty of the adversary. measured by mutual information. in comparison with linear correlation. Experimentally. the proposed technique has been shown to outperform related state-of-the art techniques recently proposed in the literature in terms of robustness with respect to image processing manipulations and geometric attacks.,True,IpMcSfcAAAAJ:dfsIfKJdRG4C,115,https://ieeexplore.ieee.org/abstract/document/5353736/,9434172057781256173,/scholar?cites=9434172057781256173,,,,0,0,0
1279038,A deep-learning based feature hybrid framework for spatiotemporal saliency detection inside videos,2018,Zheng Wang and Jinchang Ren and Dong Zhang and Meijun Sun and Jianmin Jiang,287,Neurocomputing,,68-83,Elsevier,Although research on detection of saliency and visual attention has been active over recent years. most of the existing work focuses on still image rather than video based saliency. In this paper. a deep learning based hybrid spatiotemporal saliency feature extraction framework is proposed for saliency detection from video footages. The deep learning model is used for the extraction of high-level features from raw video data. and they are then integrated with other high-level features. The deep learning network has been found extremely effective for extracting hidden features than that of conventional handcrafted methodology. The effectiveness for using hybrid high-level features for saliency detection in video is demonstrated in this work. Rather than using only one static image. the proposed deep learning model take several consecutive frames as input and both the spatial and temporal characteristics are …,True,IpMcSfcAAAAJ:fJljFJTiP-AC,110,https://www.sciencedirect.com/science/article/pii/S0925231218301097,13050977373663338347,/scholar?cites=13050977373663338347,,,https://strathprints.strath.ac.uk/63200/1/Wang_etal_Neurocomputing_2018_A_deep_learning_based_feature_hybrid_framework_for_spatiotemporal.pdf,0,0,0
1279039,Numerical methods for image registration,2004,Jan Modersitzki,,,,,Oxford University Press on Demand,Based on the author's lecture notes and research. this well-illustrated and comprehensive text is one of the first to provide an introduction to image registration with particular emphasis on numerical methods in medical imaging. Ideal for researchers in industry and academia. it is also a suitable study guide for graduate mathematicians. computer scientists. engineers. medical physicists. and radiologists. Image registration is utilised whenever information obtained from different viewpoints needs to be combined or compared and unwanted distortion needs to be eliminated. For example. CCTV images. ultrasound images. brain scan images. fingerprint and retinal scanning. Modersitzki's book provides a systematic introduction to the theoretical. practical. and numerical aspects of image registration. with special emphasis on medical applications. Various techniques are described. discussed and compared using numerous illustrations. The text starts with an introduction to the mathematical principles and the motivating example of the Human Neuroscanning Project whose aim is to build an atlas of the human brain through reconstructing essential information out of deformed images of sections of a prepared brain. The introduction is followed by coverage of parametric image registrations such as landmark based. principal axes based. and optimal affine linear registration. Basic distance measures like sum of squared differences. correlation. and mutual information are also discussed. The next section is devoted to state-of-the-art non-parametric image registrations where general variational based framework for image registration is presented and …,True,kjJlVk8AAAAJ:u5HHmVD_uO8C,1345,http://books.google.com/books?hl=en&lr=&id=9CoTDAAAQBAJ&oi=fnd&pg=PR7&dq=info:o8MSjaVkOXkJ:scholar.google.com&ots=DxHe2fb6ls&sig=UDHk2GxgTWloy31vm5Oos3_Muko,8735123614460986275,/scholar?cites=8735123614460986275,,,,0,0,0
1279040,Visual field representations and locations of visual areas V1/2/3 in human visual cortex,2003,Robert F Dougherty and Volker M Koch and Alyssa A Brewer and Bernd Fischer and Jan Modersitzki and Brian A Wandell,3,Journal of vision,10,1-1,The Association for Research in Vision and Ophthalmology,The position. surface area and visual field representation of human visual areas V1. V2 and V3 were measured using fMRI in 7 subjects (14 hemispheres). Cortical visual field maps of the central 12 deg were measured using rotating wedge and expanding ring stimuli. The boundaries between areas were identified using an automated procedure to fit an atlas of the expected visual field map to the data. All position and surface area measurements were made along the boundary between white matter and gray matter.,True,kjJlVk8AAAAJ:u-x6o8ySG0sC,564,https://jov.arvojournals.org/article.aspx?articleid=2192509,3244886879528969575,/scholar?cites=3244886879528969575,,,https://jov.arvojournals.org/article.aspx?articleid=2192509,0,0,0
1279041,FAIR: flexible algorithms for image registration,2009,Jan Modersitzki,,,,,Society for Industrial and Applied Mathematics,This book really shows how registration works: the flip-book appearing at the top right corners shows a registration of a human knee from bent to straight position (keeping bones rigid). Of course. the book also provides insight into concepts and practical tools. The presented framework exploits techniques from various fields such as image processing. numerical linear algebra. and optimization. Therefore. a brief overview of some preliminary literature in those fields is presented in the introduction (references [1–51]). and registration-specific literature is assembled at the end of the book (references [52–212]). Examples and results are based on the FAIR software. a package written in MATLAB. The FAIR software. as well as a PDF version of this entire book. can be freely downloaded from www.siam.org/books/fa06.This book would not have been possible without the help of Bernd Fischer. Eldad Haber. Claudia …,True,kjJlVk8AAAAJ:qjMakFHDy7sC,447,https://epubs.siam.org/doi/pdf/10.1137/1.9780898718843.bm,7379070022170422851,/scholar?cites=7379070022170422851,,,https://epubs.siam.org/doi/pdf/10.1137/1.9780898718843.bm,0,0,0
1279042,Curvature based image registration,2003,Bernd Fischer and Jan Modersitzki,18,Journal of Mathematical Imaging and Vision,1,81-85,Kluwer Academic Publishers,A fully automated. non-rigid image registration algorithm is presented. The deformation field is found by minimizing a suitable measure subject to a curvature based constraint. It is a well-known fact that non-rigid image registration techniques may converge poorly if the initial position is not sufficiently near to the solution. A common approach to address this problem is to perform a time consuming rigid pre-registration step. In this paper we show that the new curvature registration not only produces accurate and smooth solutions but also allows for an automatic rigid alignment. Thus. in contrast to other popular registration schemes. the new method no longer requires a pre-registration step. Furthermore. we present an implementation of the new scheme based on the numerical solution of the underlying Euler-Lagrange equations. The real discrete cosine transform is the backbone of our implementation and …,True,kjJlVk8AAAAJ:d1gkVwhDpl0C,325,https://link.springer.com/article/10.1023/A:1021897212261,4490086038897877477,/scholar?cites=4490086038897877477,,,http://www.cas.mcmaster.ca/~modersit/Pubs/2003-IJCV-FM.pdf,0,0,0
1279043,Ill-posed medicine—an introduction to image registration,2008,Bernd Fischer and Jan Modersitzki,24,Inverse Problems,3,034008,IOP Publishing,Image registration is the process of aligning two or more images of the same scene taken at different times. from different viewpoints and/or by different sensors. Image registration is a crucial step in imaging problems where the valuable information is contained in more than one image. Here. spatial alignment is required to properly integrate useful information from the separate images. It is the goal of this paper to give an overview on modern techniques in this area. It turns out that the registration problem is an inverse problem which does require a sound regularization and the use of proper models. Also. the numerics have to be done with great care. We will comment on these issues and supplement it by real life examples.,True,kjJlVk8AAAAJ:IjCSPb-OGe4C,263,https://iopscience.iop.org/article/10.1088/0266-5611/24/3/034008/meta,13914342879184743295,/scholar?cites=13914342879184743295,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.706.3774&rep=rep1&type=pdf,0,0,0
1279044,A unified approach to fast image registration and a new curvature based registration technique,2004,Bernd Fischer and Jan Modersitzki,380,Linear Algebra and its applications,,107-124,North-Holland,Image registration is central to many challenges in medical imaging today. It has a vast range of applications.The purpose of this note is twofold. First. we review some of the most promising non-linear registration strategies currently used in medical imaging. We show that all these techniques may be phrased in terms of a variational problem and allow for a unified treatment.Second. we introduce. within the variational framework. a new non-linear registration model based on a curvature type smoother. We show that affine linear transformations belong to the kernel of this regularizer. As a result. the approach becomes more robust against poor initializations of a pre-registration step. Furthermore. we develop a stable and fast implementation of the new scheme based on a real discrete cosine transformation. We demonstrate the advantages of the new technique for synthetic data sets and present an application of the …,True,kjJlVk8AAAAJ:9yKSN-GCB0IC,232,https://www.sciencedirect.com/science/article/pii/S0024379503008115,528740699647001242,/scholar?cites=528740699647001242,,,https://www.sciencedirect.com/science/article/pii/S0024379503008115/pdf?md5=5c7612a21d87e0cccd60c715abe433a7&pid=1-s2.0-S0024379503008115-main.pdf,0,0,0
1279045,Intensity gradient based registration and fusion of multi-modal images,2006,Eldad Haber and Jan Modersitzki,,,,726-733,Springer. Berlin. Heidelberg,A particular problem in image registration arises for multi-modal images taken from different imaging devices and/or modalities. Starting in 1995. mutual information has shown to be a very successful distance measure for multi-modal image registration. However. mutual information has also a number of well-known drawbacks. Its main disadvantage is that it is known to be highly non-convex and has typically many local maxima.This observation motivate us to seek a different image similarity measure which is better suited for optimization but as well capable to handle multi-modal images. In this work we investigate an alternative distance measure which is based on normalized gradients and compare its performance to Mutual Information. We call the new distance measure Normalized Gradient Fields (NGF).,True,kjJlVk8AAAAJ:Y0pCki6q_DkC,226,https://link.springer.com/chapter/10.1007/11866763_89,7614618966048410348,/scholar?cites=7614618966048410348,,,https://link.springer.com/content/pdf/10.1007/11866763_89.pdf,0,0,0
1279046,Fast diffusion registration,2002,Bernd Fischer and Jan Modersitzki,313,Contemporary Mathematics,,117-128,Providence. RI; American Mathematical Society; 1999,Image registration is one of the most challenging tasks within digital imaging. in particular in medical imaging. Typically. the underlying problems are high dimensional and demand for fast and efficient numerical schemes. Here. we propose a novel scheme for automatic image registration by introducing a specific regularizing term. The new scheme is called diffusion registration since its implementation is based on the solution of a diffusion type partial differential equation (PDE). The main ingredient for a fast implemen-tation of the diffusion registration is the so-called additive operator splitting (AOS) scheme. The AOS-scheme is known to be as accurate as a conventional semi-implicit scheme and has a linear complexity with respect to the size of the images. We present a proof of these properties based purely on matrix analysis.,True,kjJlVk8AAAAJ:2osOgNQ5qMEC,201,http://books.google.com/books?hl=en&lr=&id=73EbCAAAQBAJ&oi=fnd&pg=PA117&dq=info:H0bKvuC54UEJ:scholar.google.com&ots=YbmhEmIqee&sig=FdndZi8sBBw_6FLyVMFtc62aAA0,4747279857149953567,/scholar?cites=4747279857149953567,,,,0,0,0
1279047,Numerical methods for volume preserving image registration,2004,Eldad Haber and Jan Modersitzki,20,Inverse problems,5,1621,IOP Publishing,Image registration is one of today's challenging image processing problems. particularly in medical imaging. Since the problem is ill posed. one may like to add additional information about distortions. This applies. for example. to the registration of time series of contrast-enhanced images. where variations of substructures are not related to patient motion but to contrast uptake. Here. one may only be interested in registrations which do not alter the volume of any substructure. In this paper. we discuss image registration techniques with a focus on volume preserving constraints. These constraints can reduce the non-uniqueness of the registration problem significantly. Our implementation is based on a constrained optimization formulation. Upon discretization. we obtain a large. discrete. highly nonlinear optimization problem and the necessary conditions for the solution form a discretized nonlinear partial differential …,True,kjJlVk8AAAAJ:zYLM7Y9cAGgC,178,https://iopscience.iop.org/article/10.1088/0266-5611/20/5/018/meta,15796946275470986361,/scholar?cites=15796946275470986361,,,http://www.math.emory.edu/technical-reports/techrep-00058.pdf,0,0,0
1279048,Intensity gradient based registration and fusion of multi-modal images,2007,Eldad Haber and Jan Modersitzki,46,Methods of information in medicine,03,292-299,Schattauer GmbH,  Objectives:  A particular problem in image registration arises for multi-modal images taken from different imaging devices and/or modalities. Starting in 1995. mutual information has shown to be a very successful distance measure for multi-modal image registration. Therefore. mutual information is considered to be the state-of-the-art approach to multi-modal image registration. However. mutual information has also a number of well-known drawbacks. Its main disadvantage is that it is known to be highly non-convexand hastypicallymanylocal maxima.  Methods:  This observation motivates us to seek a different image similarity measure which is better suited for optimization but as well capable to handle multimodal images.  Results:  In this work. we investigate an alternative distance measure which is based on normalized gradients.  Conclusions:  As we show. the alternative approach is …,True,kjJlVk8AAAAJ:mvPsJ3kp5DgC,150,https://www.thieme-connect.com/products/ejournals/abstract/10.1160/ME9046,7513379104341857321,/scholar?cites=7513379104341857321,,,,0,0,0
1279049,3D ultrasound-CT registration of the liver using combined landmark-intensity information,2009,Thomas Lange and Nils Papenberg and Stefan Heldmann and Jan Modersitzki and Bernd Fischer and Hans Lamecker and Peter M Schlag,4,International journal of computer assisted radiology and surgery,1,79-88,Springer-Verlag,An important issue in computer-assisted surgery of the liver is a fast and reliable transfer of preoperative resection plans to the intraoperative situation. One problem is to match the planning data. derived from preoperative CT or MR images. with 3D ultrasound images of the liver. acquired during surgery. As the liver deforms significantly in the intraoperative situation non-rigid registration is necessary. This is a particularly challenging task because pre- and intraoperative image data stem from different modalities and ultrasound images are generally very noisy.One way to overcome these problems is to incorporate prior knowledge into the registration process. We propose a method of combining anatomical landmark information with a fast non-parametric intensity registration approach. Mathematically. this leads to a constrained …,True,kjJlVk8AAAAJ:YsMSGLbcyi4C,143,https://link.springer.com/article/10.1007/s11548-008-0270-1,4156993464099630031,/scholar?cites=4156993464099630031,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.453.7643&rep=rep1&type=pdf,0,0,0
1279050,Deep learning for computer vision: A brief review,2018,Athanasios Voulodimos and Nikolaos Doulamis and Anastasios Doulamis and Eftychios Protopapadakis,2018,,,,Hindawi,Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields. with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems. that is. Convolutional Neural Networks. Deep Boltzmann Machines and Deep Belief Networks. and Stacked Denoising Autoencoders. A brief account of their history. structure. advantages. and limitations is given. followed by a description of their applications in various computer vision tasks. such as object detection. face recognition. action and activity recognition. and human pose estimation. Finally. a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.,True,5bsC2t0AAAAJ:prdVHNxh-e8C,831,https://www.hindawi.com/journals/cin/2018/7068349/abs/,8556666434397597688,/scholar?cites=8556666434397597688,,,https://www.hindawi.com/journals/cin/2018/7068349/abs/,0,0,0
1279051,Deep supervised learning for hyperspectral data classification through convolutional neural networks,2015,Konstantinos Makantasis and Konstantinos Karantzalos and Anastasios Doulamis and Nikolaos Doulamis,,,,4959-4962,IEEE,Spectral observations along the spectrum in many narrow spectral bands through hyperspectral imaging provides valuable information towards material and object recognition. which can be consider as a classification task. Most of the existing studies and research efforts are following the conventional pattern recognition paradigm. which is based on the construction of complex handcrafted features. However. it is rarely known which features are important for the problem at hand. In contrast to these approaches. we propose a deep learning based classification method that hierarchically constructs high-level features in an automated way. Our method exploits a Convolutional Neural Network to encode pixels' spectral and spatial information and a Multi-Layer Perceptron to conduct the classification task. Experimental results and quantitative validation on widely used datasets showcasing the potential of the …,True,5bsC2t0AAAAJ:HtS1dXgVpQUC,486,https://ieeexplore.ieee.org/abstract/document/7326945/,10646184102623179652,/scholar?cites=10646184102623179652,,,http://users.ntua.gr/karank/img/Makantasis_etal_igrass15.pdf,0,0,0
1279052,A fuzzy video content representation for video summarization and content-based retrieval,2000,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,80,Signal Processing,6,1049-1067,Elsevier,In this paper. a fuzzy representation of visual content is proposed. which is useful for the new emerging multimedia applications. such as content-based image indexing and retrieval. video browsing and summarization. In particular. a multidimensional fuzzy histogram is constructed for each video frame based on a collection of appropriate features. extracted using video sequence analysis techniques. This approach is then applied both for video summarization. in the context of a content-based sampling algorithm. and for content-based indexing and retrieval. In the first case. video summarization is accomplished by discarding shots or frames of similar visual content so that only a small but meaningful amount of information is retained (key-frames). In the second case. a content-based retrieval scheme is investigated. so that the most similar images to a query are extracted. Experimental results and comparison with …,True,5bsC2t0AAAAJ:u-x6o8ySG0sC,148,https://www.sciencedirect.com/science/article/pii/S0165168400000190,10952171234810203006,/scholar?cites=10952171234810203006,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.1714&rep=rep1&type=pdf,0,0,0
1279053,On-line retrainable neural networks: improving the performance of neural networks in image analysis problems,2000,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,11,IEEE Transactions on neural networks,1,137-155,IEEE,A novel approach is presented in this paper for im-proving the performance of neural-network classifiers in image recognition. segmentation. or coding applications. based on a retraining procedure at the user level. The procedure includes: 1) a training algorithm for adapting the network weights to the current condition; 2) a maximum a posteriori (MAP) estimation procedure for optimally selecting the most representative data of the current environment as retraining data; and 3) a decision mechanism for determining when network retraining should be activated. The training algorithm takes into consideration both the former and the current network knowledge in order to achieve good generalization. The MAP estimation procedure models the network output as a Markov random field (MRF) and optimally selects the set of training inputs and corresponding desired outputs. Results are presented which illustrate the theoretical developments as well as the performance of the proposed approach in real-life experiments.,True,5bsC2t0AAAAJ:9yKSN-GCB0IC,126,https://pdfs.semanticscholar.org/156d/8d07823a2a66e0d13c3f2b34ffb7307f5bb3.pdf,11471558226732535199,/scholar?cites=11471558226732535199,,,https://pdfs.semanticscholar.org/156d/8d07823a2a66e0d13c3f2b34ffb7307f5bb3.pdf,0,0,0
1279054,Low bit-rate coding of image sequences using adaptive regions of interest,1998,Nikolaos Doulamis and Anastasios Doulamis and Dimitrios Kalogeras and Stefanos Kollias,8,IEEE transactions on circuits and systems for video technology,8,928-934,IEEE,An adaptive algorithm for extracting foreground objects from background in videophone or videoconference applications is presented. The algorithm uses a neural network architecture that classifies the video frames in regions of interest (ROI) and non-ROI areas. also being able to automatically adapt its performance to scene changes. The algorithm is incorporated in motion-compensated discrete cosine transform (MC-DCT)-based coding schemes. allocating more bits to ROI than to non-ROI areas. Simulation results are presented. using the Claire and Trevor sequences. which show reconstructed images of better quality. as well as signal-to-noise ratio improvements of about 1.4 dB. compared to those achieved by standard MC-DCT encoders.,True,5bsC2t0AAAAJ:u5HHmVD_uO8C,125,https://ieeexplore.ieee.org/abstract/document/736718/,4602300891471484248,/scholar?cites=4602300891471484248,,,https://www.researchgate.net/profile/Dimitris_Kalogeras/publication/3307978_Low_bit-rate_coding_of_image_sequences_using_adaptive_regions_of_interest/links/02e7e5188be6fc70bd000000.pdf,0,0,0
1279055,Efficient summarization of stereoscopic video sequences,2000,Nikolaos D Doulamis and Anastasios D Doulamis and Yannis S Avrithis and Klimis S Ntalianis and Stefanos D Kollias,10,IEEE Transactions on Circuits and Systems for Video Technology,4,501-517,IEEE,An efficient technique for summarization of stereoscopic video sequences is presented. which extracts a small but meaningful set of video frames using a content-based sampling algorithm. The proposed video-content representation provides the capability of browsing digital stereoscopic video sequences and performing more efficient content-based queries and indexing. Each stereoscopic video sequence is first partitioned into shots by applying a shot-cut detection algorithm so that frames (or stereo pairs) of similar visual characteristics are gathered together. Each shot is then analyzed using stereo-imaging techniques. and the disparity field. occluded areas. and depth map are estimated. A multiresolution implementation of the recursive shortest spanning tree (RSST) algorithm is applied for color and depth segmentation. while fusion of color and depth segments is employed for reliable video object extraction. In …,True,5bsC2t0AAAAJ:2osOgNQ5qMEC,123,https://ieeexplore.ieee.org/abstract/document/844996/,5921830990220809695,/scholar?cites=5921830990220809695,,,https://avrithis.net/data/pub/pdf/journ/J02.csvt99.pdf,0,0,0
1279056,An adaptable neural-network model for recursive nonlinear traffic prediction and modeling of MPEG video sources,2003,Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,14,IEEE Transactions on Neural Networks,1,150-166,IEEE,Multimedia services and especially digital video is expected to be the major traffic component transmitted over communication networks [such as internet protocol (IP)-based networks]. For this reason. traffic characterization and modeling of such services are required for an efficient network operation. The generated models can be used as traffic rate predictors. during the network operation phase (online traffic modeling). or as video generators for estimating the network resources. during the network design phase (offline traffic modeling). In this paper. an adaptable neural-network architecture is proposed covering both cases. The scheme is based on an efficient recursive weight estimation algorithm. which adapts the network response to current conditions. In particular. the algorithm updates the network weights so that 1) the network output. after the adaptation. is approximately equal to current bit rates (current …,True,5bsC2t0AAAAJ:qjMakFHDy7sC,119,https://ieeexplore.ieee.org/abstract/document/1176135/,1224680158503398573,/scholar?cites=1224680158503398573,,,https://www.researchgate.net/profile/Stefanos_Kollias/publication/5613961_An_adaptable_neural-network_model_for_recursive_nonlinear_traffic_prediction_and_modeling_of_MPEG_video_sources/links/56a9fba708ae2df82166a235.pdf,0,0,0
1279057,A stochastic framework for optimal key frame extraction from MPEG video databases,1999,Yannis S Avrithis and Anastasios D Doulamis and Nikolaos D Doulamis and Stefanos D Kollias,75,Computer Vision and Image Understanding,1-2,3-24,Academic Press,A video content representation framework is proposed in this paper for extracting limited. but meaningful. information of video data. directly from the MPEG compressed domain. A hierarchical color and motion segmentation scheme is applied to each video shot. transforming the frame-based representation to a feature-based one. The scheme is based on a multiresolution implementation of the recursive shortest spanning tree (RSST) algorithm. Then. all segment features are gathered together using a fuzzy multidimensional histogram to reduce the possibility of classifying similar segments to different classes. Extraction of several key frames is performed for each shot in a content-based rate-sampling framework. Two approaches are examined for key frame extraction. The first is based on examination of the temporal variation of the feature vector trajectory; the second is based on minimization of a cross-correlation …,True,5bsC2t0AAAAJ:d1gkVwhDpl0C,116,https://www.sciencedirect.com/science/article/pii/S1077314299907610,5077865837034791527,/scholar?cites=5077865837034791527,,,https://www.academia.edu/download/36193575/5.pdf,0,0,0
1279058,Fair scheduling algorithms in grids,2007,Nikolaos D Doulamis and Anastasios D Doulamis and Emmanouel A Varvarigos and Theodora A Varvarigou,18,IEEE Transactions on Parallel and Distributed Systems,11,1630-1648,IEEE,In this paper. we propose a new algorithm for fair scheduling. and we compare it to other scheduling schemes such as the earliest deadline first (EDF) and the first come first served (FCFS) schemes. Our algorithm uses a max-min fair sharing approach for providing fair access to users. When there is no shortage of resources. the algorithm assigns to each task enough computational power for it to finish within its deadline. When there is congestion. the main idea is to fairly reduce the CPU rates assigned to the tasks so that the share of resources that each user gets is proportional to the users weight. The weight of a user may be defined as the users contribution to the infrastructure or the price he is willing to pay for services or any other socioeconomic consideration. In our algorithms. all tasks whose requirements are lower than their fair share CPU rate are served at their demanded CPU rates. However. the CPU rates …,True,5bsC2t0AAAAJ:W7OEmFMy1HYC,113,https://ieeexplore.ieee.org/abstract/document/4339205/,6815200130678790326,/scholar?cites=6815200130678790326,,,,0,0,0
1279059,Deep convolutional neural networks for efficient vision based tunnel inspection,2015,Konstantinos Makantasis and Eftychios Protopapadakis and Anastasios Doulamis and Nikolaos Doulamis and Constantinos Loupos,,,,335-342,IEEE,The inspection. assessment. maintenance and safe operation of the existing civil infrastructure consists one of the major challenges facing engineers today. Such work requires either manual approaches. which are slow and yield subjective results. or automated approaches. which depend upon complex handcrafted features. Yet. for the latter case. it is rarely known in advance which features are important for the problem at hand. In this paper. we propose a fully automated tunnel assessment approach; using the raw input from a single monocular camera we hierarchically construct complex features. exploiting the advantages of deep learning architectures. Obtained features are used to train an appropriate defect detector. In particular. we exploit a Convolutional Neural Network to construct high-level features and as a detector we choose to use a Multi-Layer Perceptron due to its global function approximation …,True,5bsC2t0AAAAJ:DJbcl8HfkQkC,97,https://ieeexplore.ieee.org/abstract/document/7312681/,2333549668272128254,/scholar?cites=2333549668272128254,,,https://www.researchgate.net/profile/Konstantinos_Makantasis/publication/284169995_Deep_Convolutional_Neural_Networks_for_efficient_vision_based_tunnel_inspection/links/5ba364a2299bf13e603ec328/Deep-Convolutional-Neural-Networks-for-efficient-vision-based-tunnel-inspection.pdf,0,0,0
1279060,Evaluation of relevance feedback schemes in content-based in retrieval systems,2006,Nikolaos Doulamis and Anastasios Doulamis,21,Signal Processing: Image Communication,4,334-357,Elsevier,Multimedia content modeling. i.e.. identification of semantically meaningful entities. is an arduous task mainly due to the fact that (a) humans perceive the content using high-level concepts and (b) the subjectivity of human perception. which often interprets the same content in a different way at different times. For this reason. an efficient content management system has to be adapted to current user's information needs and preferences through an on-line learning strategy based on users’ interaction. One adaptive learning strategy is relevance feedback. originally developed in traditional text-based information retrieval systems. In this way. the user interacts with the system to provide information about the relevance of the content. which is then fed back to the system to update its performance. In this paper. we evaluate and investigate three main types of relevance feedback algorithms; the Euclidean. the query point …,True,5bsC2t0AAAAJ:Tyk-4Ss8FVUC,95,https://www.sciencedirect.com/science/article/pii/S0923596505001360,1354482273012560028,/scholar?cites=1354482273012560028,,,,0,0,0
1279061,Most apparent distortion: full-reference image quality assessment and the role of strategy,2010,Eric C Larson and Damon M Chandler,19,Journal of Electronic Imaging,1,011006-011006-21,International Society for Optics and Photonics,The mainstream approach to image quality assessment has centered around accurately modeling the single most relevant strategy employed by the human visual system (HVS) when judging image quality (e.g.. detecting visible differences. and extracting image structure/information). In this work. we suggest that a single strategy may not be sufficient; rather. we advocate that the HVS uses multiple strategies to determine image quality. For images containing near-threshold distortions. the image is most apparent. and thus the HVS attempts to look past the image and look for the distortions (a detection-based strategy). For images containing clearly visible distortions. the distortions are most apparent. and thus the HVS attempts to look past the distortion and look for the image's subject matter (an appearance-based strategy). Here. we present a quality assessment method [most apparent distortion (MAD)]. which …,True,0fLCNNAAAAAJ:u-x6o8ySG0sC,1443,https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-19/issue-1/011006/Most-apparent-distortion--full-reference-image-quality-assessment-and/10.1117/1.3267105.short,1950661418459718746,/scholar?cites=1950661418459718746,,,https://s2.smu.edu/~eclarson/pubs/2010JEI_MAD.pdf,0,0,0
1279062,VSNR: A wavelet-based visual signal-to-noise ratio for natural images,2007,Damon M Chandler and Sheila S Hemami,16,IEEE transactions on image processing,9,2284-2298,IEEE,This paper presents an efficient metric for quantifying the visual fidelity of natural images based on near-threshold and suprathreshold properties of human vision. The proposed metric. the visual signal-to-noise ratio (VSNR). operates via a two-stage approach. In the first stage. contrast thresholds for detection of distortions in the presence of natural images are computed via wavelet-based models of visual masking and visual summation in order to determine whether the distortions in the distorted image are visible. If the distortions are below the threshold of detection. the distorted image is deemed to be of perfect visual fidelity (VSNR = infin)and no further analysis is required. If the distortions are suprathreshold. a second stage is applied which operates based on the low-level visual property of perceived contrast. and the mid-level visual property of global precedence. These two properties are modeled as Euclidean …,True,0fLCNNAAAAAJ:u5HHmVD_uO8C,1336,https://ieeexplore.ieee.org/abstract/document/4286985/,16601438696004330842,/scholar?cites=16601438696004330842,,,https://www.researchgate.net/profile/Damon_Chandler/publication/3328654_VSNR_A_wavelet-based_Visual_Signal-to-Noise_Ratio_for_natural_images/links/56ea36d408aec8bc078178f9.pdf,0,0,0
1279063,Seven challenges in image quality assessment: past. present. and future research,2013,Damon M Chandler,2013,International Scholarly Research Notices,,,Hindawi,Image quality assessment (IQA) has been a topic of intense research over the last several decades. With each year comes an increasing number of new IQA algorithms. extensions of existing IQA algorithms. and applications of IQA to other disciplines. In this article. I first provide an up-to-date review of research in IQA. and then I highlight several open challenges in this field. The first half of this article provides  discuss key properties of visual perception. image quality databases. existing full-reference. no-reference. and reduced-reference IQA algorithms. Yet. despite the remarkable progress that has been made in IQA. many fundamental challenges remain largely unsolved. The second half of this article highlights some of these challenges. I specifically discuss challenges related to lack of complete perceptual models for: natural images. compound and suprathreshold distortions. and multiple distortions. and the interactive effects of these distortions on the images. I also discuss challenges related to IQA of images containing nontraditional. and I discuss challenges related to the computational efficiency. The goal of this article is not only to help practitioners and researchers keep abreast of the recent advances in IQA. but to also raise awareness of the key limitations of current IQA knowledge.,True,0fLCNNAAAAAJ:NMxIlDl6LWMC,411,http://downloads.hindawi.com/archive/2013/905685.pdf,4463820280655574659,/scholar?cites=4463820280655574659,,,http://downloads.hindawi.com/archive/2013/905685.pdf,0,0,0
1279064,S3: A spectral and spatial measure of local perceived sharpness in natural images,2012,Cuong T Vu and Thien D Phan and Damon M Chandler,21,"Image Processing, IEEE Transactions on",3,934-945,IEEE,This paper presents an algorithm designed to measure the local perceived sharpness in an image. Our method utilizes both spectral and spatial properties of the image: For each block. we measure the slope of the magnitude spectrum and the total spatial variation. These measures are then adjusted to account for visual perception. and then. the adjusted measures are combined via a weighted geometric mean. The resulting measure. i.e..  S 3  (spectral and spatial sharpness). yields a perceived sharpness map in which greater values denote perceptually sharper regions. This map can be collapsed into a single index. which quantifies the overall perceived sharpness of the whole image. We demonstrate the utility of the  S 3  measure for within-image and across-image sharpness prediction. no-reference image quality assessment of blurred images. and monotonic estimation of the standard deviation of the impulse …,True,0fLCNNAAAAAJ:3fE2CSJIrl8C,342,https://ieeexplore.ieee.org/abstract/document/6030937/,7228979498846096584,/scholar?cites=7228979498846096584,,,https://www.researchgate.net/profile/Damon_Chandler/publication/224259718_S-3_A_Spectral_and_Spatial_Measure_of_Local_Perceived_Sharpness_in_Natural_Images/links/56ea36cf08ae95bddc2a649d.pdf,0,0,0
1279065,Categorical image quality (CSIQ) database,2010,Eric C Larson and DM Chandler,,"Online, http://vision.eng.shizuoka.ac.jp/csiq/",,,,,True,0fLCNNAAAAAJ:NhqRSupF_l8C,239,http://scholar.google.com/scholar?cluster=4111012499880833418&hl=en&oi=scholarr,4111012499880833418,/scholar?cites=4111012499880833418,,,,0,0,0
1279066,A fast wavelet-based algorithm for global and local image sharpness estimation,2012,Phong V Vu and Damon M Chandler,19,IEEE Signal Processing Letters,7,423-426,IEEE,In this letter. we present a simple. yet effective wavelet-based algorithm for estimating both global and local image sharpness (FISH. Fast Image Sharpness). FISH operates by first decomposing the input image via a three-level separable discrete wavelet transform (DWT). Next. the log-energies of the DWT subbands are computed. Finally. a scalar index corresponding to the image's overall sharpness is computed via a weighted average of these log-energies. Testing on several image databases demonstrates that. despite its simplicity. FISH is competitive with the currently best-performing techniques both for sharpness estimation and for no-reference image quality assessment.,True,0fLCNNAAAAAJ:M3ejUd6NZC8C,230,https://ieeexplore.ieee.org/abstract/document/6202326/,2795707635773638631,/scholar?cites=2795707635773638631,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.664.9410&rep=rep1&type=pdf,0,0,0
1279067,A spatiotemporal most-apparent-distortion model for video quality assessment,2011,Phong V Vu and Cuong T Vu and Damon M Chandler,,,,2505-2508,IEEE,This paper presents an algorithm for video quality assessment. spatiotemporal MAD (ST-MAD). which extends our previous image-based algorithm (MAD [1]) to take into account visual perception of motion artifacts. ST-MAD employs spatiotemporal “images” (STS images [2]) created by taking time-based slices of the original and distorted videos. Motion artifacts manifest in the STS images as spatial artifacts. which allows one to quantify motion-based distortion by using classical image-quality assessment techniques. ST-MAD estimates motion-based distortion by applying MAD's appearance-based model to compare the distorted video's STS images to the original video's STS images. This comparison is further adjusted by using optical-flow-derived weights designed to give greater precedence to fast-moving regions located toward the center of the video. Testing on the LIVE video database demonstrates that ST …,True,0fLCNNAAAAAJ:j3f4tGmQtD8C,144,https://ieeexplore.ieee.org/abstract/document/6116171/,15259930907099511605,/scholar?cites=15259930907099511605,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.667.791&rep=rep1&type=pdf,0,0,0
1279068,ViS3: an algorithm for video quality assessment via analysis of spatial and spatiotemporal slices,2014,Phong V Vu and Damon M Chandler,23,Journal of Electronic Imaging,1,013016,International Society for Optics and Photonics,Algorithms for video quality assessment (VQA) aim to estimate the qualities of videos in a manner that agrees with human judgments of quality. Modern VQA algorithms often estimate video quality by comparing localized space-time regions or groups of frames from the reference and distorted videos. using comparisons based on visual features. statistics. and/or perceptual models. We present a VQA algorithm that estimates quality via separate estimates of perceived degradation due to (1) spatial distortion and (2) joint spatial and temporal distortion. The first stage of the algorithm estimates perceived quality degradation due to spatial distortion; this stage operates by adaptively applying to groups of spatial video frames the two strategies from the most apparent distortion algorithm with an extension to account for temporal masking. The second stage of the algorithm estimates perceived quality degradation due to …,True,0fLCNNAAAAAJ:RYcK_YlVTxYC,121,https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-23/issue-1/013016/ViS3--an-algorithm-for-video-quality-assessment-via-analysis/10.1117/1.JEI.23.1.013016.short,6681322892713470615,/scholar?cites=6681322892713470615,,,https://www.spiedigitallibrary.org/journalArticle/Download?fullDOI=10.1117/1.JEI.23.1.013016,0,0,0
1279069,No-reference image quality assessment based on log-derivative statistics of natural scenes,2013,Yi Zhang and Damon M Chandler,22,Journal of Electronic Imaging,4,043025,International Society for Optics and Photonics,We propose an efficient blind/no-reference image quality assessment algorithm using a log-derivative statistical model of natural scenes. Our method. called DErivative Statistics-based QUality Evaluator (DESIQUE). extracts image quality-related statistical features at two image scales in both the spatial and frequency domains. In the spatial domain. normalized pixel values of an image are modeled in two ways: pointwise-based statistics for single pixel values and pairwise-based log-derivative statistics for the relationship of pixel pairs. In the frequency domain. log-Gabor filters are used to extract the fine scales of the image. which are also modeled by the log-derivative statistics. All of these statistics can be fitted by a generalized Gaussian distribution model. and the estimated parameters are fed into combined frameworks to estimate image quality. We train our models on the LIVE database by using optimized …,True,0fLCNNAAAAAJ:hMod-77fHWUC,108,https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-22/issue-4/043025/No-reference-image-quality-assessment-based-on-log-derivative-statistics/10.1117/1.JEI.22.4.043025.short,8903226143647106337,/scholar?cites=8903226143647106337,,,https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-22/issue-4/043025/No-reference-image-quality-assessment-based-on-log-derivative-statistics/10.1117/1.JEI.22.4.043025.pdf,0,0,0
1279070,Dynamic contrast-based quantization for lossy wavelet image compression,2005,Damon M Chandler and Sheila S Hemami,14,IEEE Transactions on Image Processing,4,397-410,IEEE,This paper presents a contrast-based quantization strategy for use in lossy wavelet image compression that attempts to preserve visual quality at any bit rate. Based on the results of recent psychophysical experiments using near-threshold and suprathreshold wavelet subband quantization distortions presented against natural-image backgrounds. subbands are quantized such that the distortions in the reconstructed image exhibit root-mean-squared contrasts selected based on image. subband. and display characteristics and on a measure of total visual distortion so as to preserve the visual system's ability to integrate edge structure across scale space. Within a single. unified framework. the proposed contrast-based strategy yields images which are competitive in visual quality with results from current visually lossless approaches at high bit rates and which demonstrate improved visual quality over current visually …,True,0fLCNNAAAAAJ:d1gkVwhDpl0C,108,https://ieeexplore.ieee.org/abstract/document/1407970/,8548122208489611435,/scholar?cites=8548122208489611435,,,https://www.researchgate.net/profile/Damon_Chandler/publication/3327935_Dynamic_contrast-based_quantization_for_lossy_wavelet_image_compression/links/56ea36d508ae95bddc2a64a8.pdf,0,0,0
1279071,Can the theory of “whitening” explain the center-surround properties of retinal ganglion cell receptive fields?,2006,Daniel J Graham and Damon M Chandler and David J Field,46,Vision research,18,2901-2913,Pergamon,To account for the spatial and temporal response properties of the retina. a number of studies have proposed that these properties serve to “whiten” the visual input. In particular. it has been argued that the sensitivity of retinal ganglion cells is matched to the spatial frequency spectrum of natural scenes. resulting in a flattened or “whitened” response spectrum across a range of frequencies. However. we argue that there are two distinct hypotheses regarding the flattening of the spectrum. The decorrelation hypothesis proposes that the magnitude of each ganglion cell tuning curve rises with spatial frequency. resulting in a flattened response spectrum for natural scene stimuli. With appropriate sampling. this scheme allows neighboring neurons to be uncorrelated with each other. The response equalization hypothesis proposes that the overall response magnitude of neurons increases with spatial frequency. The …,True,0fLCNNAAAAAJ:qjMakFHDy7sC,98,https://www.sciencedirect.com/science/article/pii/S0042698906001489,13903367778288299751,/scholar?cites=13903367778288299751,,,https://www.sciencedirect.com/science/article/pii/S0042698906001489,0,0,0
1279072,Integration of interferon-α/β signalling to p53 responses in tumour suppression and antiviral defence,2003,Akinori Takaoka and Sumio Hayakawa and Hideyuki Yanai and Dagmar Stoiber and Hideo Negishi and Hideaki Kikuchi and Shigeru Sasaki and Kohzoh Imai and Tsukasa Shibue and Kenya Honda and Tadatsugu Taniguchi,424,Nature,6948,516-523,Nature Publishing Group,Swift elimination of undesirable cells is an important feature in tumour suppression and immunity. The tumour suppressor p53 and interferon-α and-β (IFN-α/β) are essential for the induction of apoptosis in cancerous cells and in antiviral immune responses. respectively. but little is known about their interrelationship. Here we show that transcription of the p53 gene is induced by IFN-α/β. accompanied by an increase in p53 protein level. IFN-α/β signalling itself does not activate p53; rather. it contributes to boosting p53 responses to stress signals. We show examples in which p53 gene induction by IFN-α/β contributes to tumour suppression. Furthermore. we show that p53 is activated in virally infected cells to evoke an apoptotic response and that p53 is critical for antiviral defence of the host. Our study reveals a hitherto unrecognized link between p53 and IFN-α/β in tumour suppression and antiviral immunity. which …,True,IzuTQLoAAAAJ:GUYAmugLYisC,959,https://www.nature.com/articles/nature01850?free=2?message=remove&free=2,16024207995859325535,/scholar?cites=16024207995859325535,,,http://bio.gnu.ac.kr/research/SUMO/general/Ub_Nature_2003_Takaoka.pdf,0,0,0
1279073,Association between restriction fragment length polymorphism of the human cytochrome P450IIE1 gene and susceptibility to lung cancer,1991,Fumiyuki Uematsu and Hideaki Kikuchi and Masakichi Motomiya and Tatsuya Abe and Ikuko Sagami and Tetsuo Ohmachi and Akira Wakui and Ryunosuke Kanamaru and Minro Watanabe,82,Japanese journal of cancer research,3,254-256,Blackwell Publishing Ltd,Cytochrome P450IIE1 (P450IIE1) is involved in metabolic activation of carcinogenic nitrosamines. aniline and benzene. We detected a restriction fragment length polymorphism of the human P450IIE1 gene with the restriction endonuclease Oral. The population was thus divided into three genotypes. namely. heterozygotes (CD) and two forms of homozygotes (CC and DD). The distribution of these genotypes among lung cancer patients differed front that among controls with statistical significance of P< 0.05 (x2=7.01 with 2 degrees of freedom). This result strongly suggests that host susceptibility to lung cancer is associated with the Dral polymorphism of the P450IIE1 gene.,True,IzuTQLoAAAAJ:jRIwE-1ttnoC,267,https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1349-7006.1991.tb01838.x,16865555396451546401,/scholar?cites=16865555396451546401,,,https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1349-7006.1991.tb01838.x,0,0,0
1279074,Improved outcome of adult T cell leukemia/lymphoma with allogeneic hematopoietic stem cell transplantation,2001,A Utsunomiya and Y Miyazaki and Y Takatsuka and S Hanada and K Uozumi and S Yashiki and M Tara and F Kawano and Y Saburi and H Kikuchi and M Hara and H Sao and Y Morishima and Y Kodera and S Sonoda and M Tomonaga,27,Bone marrow transplantation,1,15-20,Nature Publishing Group,Adult T cell leukemia/lymphoma (ATL) is a poor prognosis T cell malignancy. In order to improve the outcome. we employed allogeneic stem cell transplantation (allo-SCT) for ATL in 10 patients. nine of whom were from HLA-identical siblings and one from an unrelated donor. Conditioning regimens varied among the patients except that all received total body irradiation. The patients tolerated the regimens well with mild. if any toxicity. and engraftment occurred in all cases. Median leukemia-free survival after allo-SCT was 17.5+ months (range 3.7–34.4+). Six of the 10 patients developed acute GVHD (one case each with grade I. III or IV. and three cases with grade II) and three patients developed extensive chronic GVHD. Four patients died after allo-SCT during the study period from either acute GVHD (grade IV). pneumonitis. gastrointestinal bleeding or renal insufficiency. Two of the 10 cases with no symptoms of …,True,IzuTQLoAAAAJ:71d7Y1FijdoC,246,https://www.nature.com/articles/1702731,9289579137044902605,/scholar?cites=9289579137044902605,,,https://www.nature.com/articles/1702731,0,0,0
1279075,Hayabusa2 arrives at the carbonaceous asteroid 162173 Ryugu—A spinning top–shaped rubble pile,2019,Seiichiro Watanabe and M Hirabayashi and N Hirata and Na Hirata and R Noguchi and Y Shimaki and H Ikeda and E Tatsumi and M Yoshikawa and S Kikuchi and H Yabuta and T Nakamura and S Tachibana and Y Ishihara and T Morota and K Kitazato and N Sakatani and K Matsumoto and K Wada and H Senshu and C Honda and T Michikami and H Takeuchi and T Kouyama and R Honda and S Kameda and T Fuse and H Miyamoto and G Komatsu and S Sugita and T Okada and N Namiki and M Arakawa and M Ishiguro and M Abe and R Gaskell and E Palmer and OS Barnouin and P Michel and AS French and JW McMahon and DJ Scheeres and PA Abell and Y Yamamoto and S Tanaka and K Shirai and M Matsuoka and M Yamada and Y Yokota and H Suzuki and K Yoshioka and Y Cho and N Nishikawa and T Sugiyama and H Kikuchi and R Hemmi and Tomohiro Yamaguchi and Naoko Ogawa and G Ono and Yuya Mimasu and K Yoshikawa and T Takahashi and Yoh Takei and Atsushi Fujii and C Hirose and Takahiro Iwata and Masahiko Hayakawa and Satoshi Hosoda and Osamu Mori and Hirotaka Sawada and Takanobu Shimada and Stefania Soldini and Hajime Yano and Ryudo Tsukizaki and Masanobu Ozaki and Yuichi Iijima and K Ogawa and Masaki Fujimoto and T-M Ho and A Moussi and R Jaumann and J-P Bibring and C Krause and Fuyuto Terui and Takanao Saiki and Satoru Nakazawa and Yuichi Tsuda,364,Science,6437,268-272,American Association for the Advancement of Science,The Hayabusa2 spacecraft arrived at the near-Earth carbonaceous asteroid 162173 Ryugu in 2018. We present Hayabusa2 observations of Ryugu’s shape. mass. and geomorphology. Ryugu has an oblate “spinning top” shape. with a prominent circular equatorial ridge. Its bulk density. 1.19 ± 0.02 grams per cubic centimeter. indicates a high-porosity (>50%) interior. Large surface boulders suggest a rubble-pile structure. Surface slope analysis shows Ryugu’s shape may have been produced from having once spun at twice the current rate. Coupled with the observed global material homogeneity. this suggests that Ryugu was reshaped by centrifugally induced deformation during a period of rapid rotation. From these remote-sensing investigations. we identified a suitable sample collection site on the equatorial ridge.,True,IzuTQLoAAAAJ:DwWRdx-KAo4C,205,https://science.sciencemag.org/content/364/6437/268.abstract,14411781918256089173,/scholar?cites=14411781918256089173,,,,0,0,0
1279076,The NADPH oxidase Nox3 constitutively produces superoxide in a p22phox-dependent manner: its regulation by oxidase organizers and activators,2005,Noriko Ueno and Ryu Takeya and Kei Miyano and Hideaki Kikuchi and Hideki Sumimoto,280,Journal of Biological Chemistry,24,23328-23339,Elsevier,Nox3. a member of the superoxide-producing NADPH oxidase (Nox) family. participates in otoconia formation in mouse inner ears. which is required for perception of balance and gravity. The activity of other Nox enzymes such as gp91phox/Nox2 and Nox1 is known to absolutely require both an organizer protein (p47phox or Noxo1) andanactivatorprotein (p67phox or Noxa1); for the p47phox-dependent activation of these oxidases. treatment of cells with stimulants such as phorbol 12-myristate 13-acetate is also indispensable. Here we show that ectopic expression of Nox3 in various types of cells leads to phorbol 12-myristate 13-acetate-independent constitutive production of a substantial amount of superoxide under the conditions where gp91phox and Nox1 fail to generate superoxide. i.e. in the absence of the oxidase organizers and activators. Nox3 likely forms a functional complex with p22phox; Nox3 …,True,IzuTQLoAAAAJ:cdwqcPQS8ssC,198,https://www.sciencedirect.com/science/article/pii/S0021925820615095,7562540236843795539,/scholar?cites=7562540236843795539,,,https://www.sciencedirect.com/science/article/pii/S0021925820615095,0,0,0
1279077,NADPH oxidase subunit. gp91phox homologue. preferentially expressed in human colon epithelial cells,2000,Hideaki Kikuchi and Mituru Hikage and Hitoshi Miyashita and Manabu Fukumoto,254,Gene,1-2,237-243,Elsevier,The NADPH oxidases are a group of plasma membrane-associated enzymes found in a variety of cells. They catalyze the production of superoxide (O−2) by a one-electron reduction of oxygen. using NADPH as the electron donor. To characterize the expression of this enzyme. two homologues of the NADPH oxidase catalytic subunit. gp91phox. were cloned from the cDNAs of a human colon cancer cell line. Caco2. and human fetal kidney. using information relating to an expressed sequence tag (EST) from a DNA database. Amino acid identity was 58% (gp91-2) and 56% (gp91-3). respectively. against the catalytic subunit (gp91-1/gp91phox) of the NADPH oxidase found in peripheral blood leukocytes. Using the reverse transcription–polymerase chain reaction (RT–PCR) method. the messenger RNA of gp91-2 was detected mainly in the colon (and also in kidney and prostate) among human adult tissues. in the …,True,IzuTQLoAAAAJ:-38epGy1wY0C,187,https://www.sciencedirect.com/science/article/pii/S0378111900002584,15779898081553201750,/scholar?cites=15779898081553201750,,,,0,0,0
1279078,A new robust watermark embedding into wavelet DC components,2002,Sanghyun Joo and Youngho Suh and Jaeho Shin and Hisakazu Kikuchi,24,ETRI journal,5,401-404,,In this paper. we propose a non‐blind watermarking method that embeds a pseudo‐random sequence (watermarks) into wavelet DC components. The DC area is not suitable for embedding because of severe visual degradation. We overcome the degradation problem by embedding watermarks into visually insensitive locations. We compare our experimental results with respect to JPEG compression with Cox's popular correlation‐based method. We also compare the robustness of our technique with other methods registered in CheckMark. This study reveals that the proposed method simultaneously provides good fidelity in quality as well as robustness against external attacks,True,IzuTQLoAAAAJ:rHJHxKgnXwkC,163,https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.02.0202.0502,2987646659409223881,/scholar?cites=2987646659409223881,,,https://onlinelibrary.wiley.com/doi/pdf/10.4218/etrij.02.0202.0502,0,0,0
1279079,Restriction fragment length polymorphism of the human CYP 2E1 (cytochrome P450IIE1) gene and susceptibility to lung cancer: possible relevance to low smoking exposure,1994,Fumiyuki Uematsu and Shuntaro Ikawa and Hideaki Kikuchi and Ikuko Sagami and Ryunosuke Kanamaru and Tatsuya Abe and Ken Satoh and Masakichi Motomiya and Minro Watanabe,4,Pharmacogenetics and Genomics,2,58-63,LWW,Polymorphic metabolism of certain chemical carcinogens may result in differences in susceptibility to cancers. Human CYP2E1 (cytochrome P450IIE1) is an enzyme involved in the metabolic activation of precarcinogens such as nitrosamincs. We detected a restriction fragment length polymorphism (RFLP) of the human CYP2E1 gene for the restriction endonuclease Dra I. The distribution of this polymorphism was examined among lung cancer patients (n= 91). patients with cancer of the digestive tract (n= 45) and controls (n= 76). A significant difference in the distribution was observed between lung cancer patients and controls (z2= 11.4 with 2 df; p< 0.005). On the other hand. there was no significant difference between patients between cancer of the digestive tract and controls (z2= 4.87 with 2 df; NS). This finding suggests that the Dra I polymorphism of the CYP2E1 gene is associated with susceptibility to lung …,True,IzuTQLoAAAAJ:htyGaKyDgHMC,149,http://publicationslist.org/data/fumiyuki-uematsu/ref-16/pharm_uem.pdf,3764367722164883998,/scholar?cites=3764367722164883998,,,http://publicationslist.org/data/fumiyuki-uematsu/ref-16/pharm_uem.pdf,0,0,0
1279080,Genetic mechanisms of tumor-specific loss of 11p DNA sequences in Wilms tumor.,1987,DD Dao and WANDA T Schroeder and LY Chao and HIDEAKI Kikuchi and LC Strong and VM Riccardi and S Pathak and WW Nichols and WH Lewis and GF Saunders,41,American journal of human genetics,2,202,Elsevier,Wilms tumor. a common childhood renal tumor. occurs in both a heritable and a nonheritable form. The heritable form may occasionally be attributed to a chromosome deletion at 11p13. and tumors from patients with normal constitutional chromosomes often show deletion or rearrangement of 11p13. It has been suggested that a germinal or somatic mutation may occur on one chromosome 11 and predispose to Wilms tumor and that a subsequent somatic genetic event on the normal homologue at 11p13 may permit tumor development. To study the frequency and mechanism of such tumor-specific genetic events. we have examined the karyotype and chromosome 11 genotype of normal and tumor tissues from 13 childhood renal tumor patients with different histologic tumor types and associated clinical conditions. Tumors of eight of the 12 Wilms tumor patients. including all viable tumors examined directly. show …,True,IzuTQLoAAAAJ:i91s68tWr-MC,106,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1684225/,376855637768731004,/scholar?cites=376855637768731004,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1684225/pdf/ajhg00131-0118.pdf,0,0,0
1279081,Method and apparatus for creating an EH antenna,2005,Robert T Hart,,,,,,An antenna system for transmitting and receiving. in association with a radio device that develops an H-field and an E-field corresponding to a radio frequency power signal having a voltage and a current. the voltage having a phase relationship to the current. The antenna system includes a Hertz-type radiating element. A phasing and matching circuit is electrically coupled between the Hertz-type radiating element and the radio device. The phasing and matching circuit adjusts the phase relationship between the voltage and the current of the radio frequency power signal so that the H-field and the E-field are in nominal time phase. This enhances the performance of all of the antenna parameters in addition to allowing reduction in size.,True,IzuTQLoAAAAJ:w7CBUyPWg-0C,104,https://patents.google.com/patent/US6864849B2/en,14793290239105791765,/scholar?cites=14793290239105791765,,,https://patentimages.storage.googleapis.com/ac/13/04/234eeb8253029d/US6864849.pdf,0,0,0
1279082,The Ah receptor is not involved in 2. 3. 7. 8-tetrachlorodibenzo-p-dioxin-mediated apoptosis in human leukemic T cell lines,1998,Anwar Hossain and Shigeru Tsuchiya and Masayoshi Minegishi and Motonobu Osada and Shuntaro Ikawa and Fumi-aki Tezuka and Mitsuji Kaji and Tasuke Konno and Minro Watanabe and Hideaki Kikuchi,273,Journal of Biological Chemistry,31,19853-19858,Elsevier,2.3.7.8-Tetrachlorodibenzo-p-dioxin (TCDD) is a common environmental pollutant causing public concern. Its toxic effects include disruption of the immune. endocrine. and reproductive systems. impairment of fetal development. carcinogenicity. and lethality in rodents. Here. we report that TCDD induces apoptosis in two cultured human leukemic lymphoblastic T cell lines. This cell death was found not to be dependent on an aryl hydrocarbon receptor and to be inhibited by the inhibitor of tyrosine kinases and caspases. Apoptosis-linked c-Jun N-terminal kinase is rapidly activated in these cells by the treatment with TCDD. A dominant-negative mutant of c-Jun N-terminal kinase prevented cell death in the treatment with TCDD. Furthermore. TCDD decreases the Bcl-2 protein level in these cell lines. These findings will help in the understanding of the molecular mechanism underlying TCDD-mediated immunotoxicity.,True,IzuTQLoAAAAJ:u_mOZUIutIEC,86,https://www.sciencedirect.com/science/article/pii/S002192581849182X,7818755810925625115,/scholar?cites=7818755810925625115,,,https://www.sciencedirect.com/science/article/pii/S002192581849182X,0,0,0
1279083,A robust competitive clustering algorithm with applications in computer vision,1999,Hichem Frigui and Raghu Krishnapuram,21,Ieee transactions on pattern analysis and machine intelligence,5,450-465,IEEE,This paper addresses three major issues associated with conventional partitional clustering. namely. sensitivity to initialization. difficulty in determining the number of clusters. and sensitivity to noise and outliers. The proposed robust competitive agglomeration (RCA) algorithm starts with a large number of clusters to reduce the sensitivity to initialization. and determines the actual number of clusters by a process of competitive agglomeration. Noise immunity is achieved by incorporating concepts from robust statistics into the algorithm. RCA assigns two different sets of weights for each data point: the first set of constrained weights represents degrees of sharing. and is used to create a competitive environment and to generate a fuzzy partition of the data set. The second set corresponds to robust weights. and is used to obtain robust estimates of the cluster prototypes. By choosing an appropriate distance measure in the …,True,kj8gkFAAAAAJ:u5HHmVD_uO8C,662,https://ieeexplore.ieee.org/abstract/document/765656/,8796603901063633692,/scholar?cites=8796603901063633692,,,https://www.researchgate.net/profile/Raghu_Krishnapuram/publication/3192979_A_robust_competitive_clustering_algorithm_with_application_in_computer_vision/links/5672420908aeb8b21c6f780a/A-robust-competitive-clustering-algorithm-with-application-in-computer-vision.pdf,0,0,0
1279084,Clustering by competitive agglomeration,1997,Hichem Frigui and Raghu Krishnapuram,30,Pattern recognition,7,1109-1119,Pergamon,We present a new clustering algorithm called Competitive Agglomeration (CA). which minimizes an objective function that incorporates the advantages of both hierarchical and partitional clustering. The CA algorithm produces a sequence of partitions with a decreasing number of clusters. The initial partition has an over specified number of clusters. and the final one has the “optimal” number of clusters. The update equation in the CA algorithm creates an environment in which clusters compete for feature points and only clusters with large cardinalities survive. The algorithm can incorporate different distance measures in the objective function to f find an unknown number of clusters of various shapes.,True,kj8gkFAAAAAJ:u-x6o8ySG0sC,502,https://www.sciencedirect.com/science/article/pii/S0031320396001409,4130440858081433886,/scholar?cites=4130440858081433886,,,https://ms.sapientia.ro/~lalo/concurs/references/t%F6bbi/1997%20Frigui%20Krishnapuram%20-%20Clustering%20by%20Competitive%20Agglomeration.pdf,0,0,0
1279085,Fuzzy and possibilistic shell clustering algorithms and their application to boundary detection and surface approximation. i,1995,Raghuram Krishnapuram and Hichem Frigui and Olfa Nasraoui,3,IEEE Transactions on Fuzzy Systems,1,29-43,IEEE,"Traditionally. prototype-based fuzzy clustering algorithms such as the Fuzzy C Means (FCM) algorithm have been used to find ""compact"" or ""filled"" clusters. Recently. there have been attempts to generalize such algorithms to the case of hollow or ""shell-like"" clusters. i.e.. clusters that lie in subspaces of feature space. The shell clustering approach provides a powerful means to solve the hitherto unsolved problem of simultaneously fitting multiple curves/surfaces to unsegmented. scattered and sparse data. In this paper. we present several fuzzy and possibilistic algorithms to detect linear and quadric shell clusters. We also introduce generalizations of these algorithms in which the prototypes represent sets of higher-order polynomial functions. The suggested algorithms provide a good trade-off between computational complexity and performance. since the objective function used in these algorithms is the sum of …",True,kj8gkFAAAAAJ:yeKNu01O_4gC,288,https://ieeexplore.ieee.org/abstract/document/366564/,12137747931965062295,/scholar?cites=12137747931965062295,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.539.7347&rep=rep1&type=pdf,0,0,0
1279086,Unsupervised learning of prototypes and attribute weights,2004,Hichem Frigui and Olfa Nasraoui,37,Pattern recognition,3,567-581,Pergamon,In this paper. we introduce new algorithms that perform clustering and feature weighting simultaneously and in an unsupervised manner. The proposed algorithms are computationally and implementationally simple. and learn a different set of feature weights for each identified cluster. The cluster dependent feature weights offer two advantages. First. they guide the clustering process to partition the data set into more meaningful clusters. Second. they can be used in the subsequent steps of a learning system to improve its learning behavior. An extension of the algorithm to deal with an unknown number of clusters is also proposed. The extension is based on competitive agglomeration. whereby the number of clusters is over-specified. and adjacent clusters are allowed to compete for data points in a manner that causes clusters which lose in the competition to gradually become depleted and vanish. We illustrate the …,True,kj8gkFAAAAAJ:qjMakFHDy7sC,263,https://www.sciencedirect.com/science/article/pii/S003132030300253X,16440270942210287353,/scholar?cites=16440270942210287353,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.8675&rep=rep1&type=pdf,0,0,0
1279087,The fuzzy c spherical shells algorithm: A new approach,1992,Raghu Krishnapuram and Olfa Nasraoui and Hichem Frigui,3,IEEE Transactions on neural networks,5,663-671,IEEE,The fuzzy c spherical shells (FCSS) algorithm is specially designed to search for clusters that can be described by circular arcs or. generally. by shells of hyperspheres. A new approach to the FCSS algorithm is presented. This algorithm is computationally and implementationally simpler than other clustering algorithms that have been suggested for this purpose. An unsupervised algorithm which automatically finds the optimum number of clusters is not known. It uses a cluster validity measure to identify good clusters. merges all compatible clusters. and eliminates spurious clusters to achieve the final results. Experimental results on several data sets are presented.< >,True,kj8gkFAAAAAJ:2osOgNQ5qMEC,243,https://ieeexplore.ieee.org/abstract/document/159056/,8586869254600878668,/scholar?cites=8586869254600878668,,,,0,0,0
1279088,Mining web access logs using relational competitive fuzzy clustering,1999,Olfa Nasraoui and Hichem Frigui and Anupam Joshi and Raghu Krishnapuram,1,Proceedings of the Eight International Fuzzy Systems Association World Congress,,195-204,,"The proliferation of information on the world wide web has made the personalization of this information space a necessity. An important component of web personalization is to mine typical user pro les from the vast amount of historical data stored in access logs. In the absence of any a priori knowledge. unsupervised classi cation or clustering methods seem to be ideally suited to analyze the semi-structured log data of user accesses. In this paper. we de ne the notion of a\user session"" as being a temporally compact sequence of web accesses by a user. We also de ne a new distance measure between two web sessions that captures the organization of a web site. The Competitive Agglomeration clustering algorithm which can automatically cluster data into the optimal number of components is extended so that it can work on relational data. The resulting Competitive Agglomeration for Relational Data (CARD) algorithm can deal with complex. non-Euclidean. distance/similarity measures. This algorithm was used to successfully analyze server access logs and obtain typical session pro les of users.",True,kj8gkFAAAAAJ:9yKSN-GCB0IC,217,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.2671&rep=rep1&type=pdf,3792136115175388213,/scholar?cites=3792136115175388213,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.2671&rep=rep1&type=pdf,0,0,0
1279089,Detection and Discrimination of Land Mines in Ground-Penetrating Radar Based on Edge Histogram Descriptors and a Possibilistic -Nearest Neighbor Classifier,2008,Hichem Frigui and Paul Gader,17,IEEE Transactions on Fuzzy Systems,1,185-199,IEEE,This paper describes an algorithm for land mine detection using sensor data generated by a ground-penetrating radar (GPR) system that uses edge histogram descriptors for feature extraction and a possibilistic  K  -nearest neighbors ( K -NNs) rule for confidence assignment. The algorithm demonstrated the best performance among several high-performance algorithms in extensive testing on a large real-world datasets associated with the difficult problem of land mine detection. The superior performance of the algorithm is attributed to the use of the possibilistic  K  -NN algorithm. thereby providing important evidence supporting the use of possibilistic methods in real-world applications. The GPR produces a 3-D array of intensity values. representing a volume below the surface of the ground. First. a computationally inexpensive prescreening algorithm for anomaly detection is used to focus attention and identify …,True,kj8gkFAAAAAJ:Se3iqnhoufwC,214,https://ieeexplore.ieee.org/abstract/document/4610973/,12963351581396616789,/scholar?cites=12963351581396616789,,,,0,0,0
1279090,A large-scale systematic evaluation of algorithms using ground-penetrating radar for landmine detection and discrimination,2007,Joseph N Wilson and Paul Gader and Wen-Hsiung Lee and Hichem Frigui and KC Ho,45,IEEE Transactions on Geoscience and Remote Sensing,8,2560-2572,IEEE,A variety of algorithms for the detection of landmines and discrimination between landmines and clutter objects have been presented. We discuss four quite different approaches in using data collected by a vehicle-mounted ground-penetrating radar sensor to detect landmines and distinguish them from clutter objects. One uses edge features in a hidden Markov model; the second uses geometric features in a feed-forward order-weighted average network; the third employs spectral features as its basis; and the fourth clusters edge histograms. We present the results of a large-scale cross-validation evaluation that uses a diverse set of data collected over 41 807.57 m 2  of ground. including 1593 mine encounters. Finally. we discuss the results of that ranking and what one can conclude concerning the performance of these four algorithms in various settings.,True,kj8gkFAAAAAJ:ufrVoPGSRksC,172,https://ieeexplore.ieee.org/abstract/document/4276906/,4032830620328249097,/scholar?cites=4032830620328249097,,,https://www.researchgate.net/profile/Paul_Gader/publication/252274296_Comparison_of_Different_Classification_Algorithms_for_Landmine_Detection_using_GPR/links/5a64a236aca272a1581f1471/Comparison-of-Different-Classification-Algorithms-for-Landmine-Detection-using-GPR.pdf,0,0,0
1279091,A robust algorithm for automatic extraction of an unknown number of clusters from noisy data,1996,Hichem Frigui and Raghu Krishnapuram,17,Pattern Recognition Letters,12,1223-1232,North-Holland,A clustering algorithm that combines the advantages of fuzzy clustering and robust statistical estimators is presented. The algorithm generates two sets of weights (memberships) for each feature vector as a by-product. These two sets of weights are used to partition the data set and to obtain robust estimates of the prototype parameters. respectively. An extension of the algorithm to deal with an unknown number of clusters is also proposed. The extension is based on overspecifying the number of clusters. and merging compatible clusters.,True,kj8gkFAAAAAJ:IjCSPb-OGe4C,167,https://www.sciencedirect.com/science/article/pii/0167865596000803,11053524826803149207,/scholar?cites=11053524826803149207,,,,0,0,0
1279092,Extracting web user profiles using relational competitive fuzzy clustering,2000,Olfa Nasraoui and Hichem Frigui and Raghu Krishnapuram and Anupam Joshi,9,International journal on artificial intelligence tools,04,509-526,World Scientific Publishing Company,"The proliferation of information on the World Wide Web has made the personalization of this information space a necessity. An important component of Web personalization is to mine typical user profiles from the vast amount of historical data stored in access logs. In the absence of any a priori knowledge. unsupervised classification or clustering methods seem to be ideally suited to analyze the semi-structured log data of user accesses. In this paper. we define the notion of a ""user session"" as being a temporally compact sequence of Web accesses by a user. We also define a new distance measure between two Web sessions that captures the organization of a Web site. The Competitive Agglomeration clustering algorithm which can automatically cluster data into the optimal number of components is extended so that it can work on relational data. The resulting Competitive Agglomeration for Relational Data (CARD …",True,kj8gkFAAAAAJ:UeHWp8X0CEIC,153,https://www.worldscientific.com/doi/abs/10.1142/s021821300000032x,6233007166419334107,/scholar?cites=6233007166419334107,,,,0,0,0
1279093,Self-organization of pulse-coupled oscillators with application to clustering,2001,Mohamed Ben Hadj Rhouma and Hichem Frigui,23,IEEE Transactions on Pattern Analysis and Machine Intelligence,2,180-195,IEEE,We introduce an efficient synchronization model that organizes a population of integrate-and-fire oscillators into stable and structured groups. Each oscillator fires synchronously with all the others within its group. but the groups themselves fire with a constant phase difference. The structure of the synchronized groups depends on the choice of the coupling function. We show that by defining the interaction between oscillators according to the relative distance between them. our model can be used as a general clustering algorithm. Unlike existing models. our model incorporates techniques from relational and prototype-based clustering methods and results in a clustering algorithm that is simple. efficient. robust. unbiased by the size of the clusters. and that can find an arbitrary number of clusters. In addition to helping the model self-organize into stable groups. the synergy between clustering and synchronization …,True,kj8gkFAAAAAJ:zYLM7Y9cAGgC,136,https://ieeexplore.ieee.org/abstract/document/908968/,18138844074386432435,/scholar?cites=18138844074386432435,,,,0,0,0
1279094,Automatic single-image-based rain streaks removal via image decomposition,2012,Li-Wei Kang and Chia-Wen Lin and Yu-Hsiang Fu,21,IEEE Transactions on Image Processing,4,1742-1755,IEEE,Rain removal from a video is a challenging problem and has been recently investigated extensively. Nevertheless. the problem of rain removal from a single image was rarely studied in the literature. where no temporal information among successive images can be exploited. making the problem very challenging. In this paper. we propose a single-image-based rain removal framework via properly formulating rain removal as an image decomposition problem based on morphological component analysis. Instead of directly applying a conventional image decomposition technique. the proposed method first decomposes an image into the low- and high-frequency (HF) parts using a bilateral filter. The HF part is then decomposed into a “rain component” and a “nonrain component” by performing dictionary learning and sparse coding. As a result. the rain component can be successfully removed from the image while …,True,fXN3dl0AAAAJ:8AbLer7MMksC,525,https://ieeexplore.ieee.org/abstract/document/6099619/,11176651253501716273,/scholar?cites=11176651253501716273,,,https://www.researchgate.net/profile/Chia-Wen_Lin2/publication/51876705_Automatic_Single-Image-Based_Rain_Streaks_Removal_via_Image_Decomposition/links/0f31752f97ea61f2b4000000.pdf,0,0,0
1279095,Digital video transcoding,2005,Jun Xin and Chia-Wen Lin and Ming-Ting Sun,93,Proceedings of the IEEE,1,84-97,IEEE,Video transcoding. due to its high practical values for a wide range of networked video applications. has become an active research topic. We outline the technical issues and research results related to video transcoding. We also discuss techniques for reducing the complexity. and techniques for improving the video quality. by exploiting the information extracted from the input video bit stream.,True,fXN3dl0AAAAJ:u5HHmVD_uO8C,499,https://ieeexplore.ieee.org/abstract/document/1369700/,9933185679706241173,/scholar?cites=9933185679706241173,,,https://www.cs.ccu.edu.tw/~cwlin/pub/xcodingprocieee04.pdf,0,0,0
1279096,Motion vector refinement for high-performance transcoding,1999,Jeongnam Youn and Ming-Ting Sun and Chia-Wen Lin,1,IEEE transactions on multimedia,1,30-40,IEEE,In transcoding. simply reusing the motion vectors extracted from an incoming video bit stream may not result in the best quality. In this paper. we show that the incoming motion vectors become nonoptimal due to the reconstruction errors. To achieve the best video quality possible. a new motion estimation should be performed in the transcoder. We propose a fast-search adaptive motion vector refinement scheme that is capable of providing video quality comparable to that can be achieved by performing a new full-scale motion estimation but with much less computation. We discuss the case when some incoming frames are dropped for frame-rate conversions. and propose motion vector composition method to compose a motion vector from the incoming motion vectors. The composed motion vector can also be refined using the proposed motion vector refinement scheme to achieve better results.,True,fXN3dl0AAAAJ:u-x6o8ySG0sC,368,https://ieeexplore.ieee.org/abstract/document/748169/,6154138910437771937,/scholar?cites=6154138910437771937,,,https://www.researchgate.net/profile/Chia-Wen_Lin2/publication/3423987_Motion_Vector_Refinement_for_High-Performance_Transcoding/links/55730eda08aeacff1ffbebbe.pdf,0,0,0
1279097,Saliency detection in the compressed domain for adaptive image retargeting,2012,Yuming Fang and Zhenzhong Chen and Weisi Lin and Chia-Wen Lin,21,IEEE Transactions on Image Processing,9,3888-3901,IEEE,Saliency detection plays important roles in many image processing applications. such as regions of interest extraction and image resizing. Existing saliency detection models are built in the uncompressed domain. Since most images over Internet are typically stored in the compressed domain such as joint photographic experts group (JPEG). we propose a novel saliency detection model in the compressed domain in this paper. The intensity. color. and texture features of the image are extracted from discrete cosine transform (DCT) coefficients in the JPEG bit-stream. Saliency value of each DCT block is obtained based on the Hausdorff distance calculation and feature map fusion. Based on the proposed saliency detection model. we further design an adaptive image retargeting algorithm in the compressed domain. The proposed image retargeting algorithm utilizes multioperator operation comprised of the block …,True,fXN3dl0AAAAJ:i2xiXl-TujoC,302,https://ieeexplore.ieee.org/abstract/document/6199980/,8915793310899039145,/scholar?cites=8915793310899039145,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.721.6739&rep=rep1&type=pdf,0,0,0
1279098,A Video Saliency Detection Model in Compressed Domain,2014,Yuming Fang and Weisi Lin and Zhenzhong Chen and C Tsai and C Lin,24,IEEE Transactions on Circuits and Systems for Video Technology,1,27−38,IEEE,Saliency detection is widely used to extract regions of interest in images for various image processing applications. Recently. many saliency detection models have been proposed for video in uncompressed (pixel) domain. However. video over Internet is always stored in compressed domains. such as MPEG2. H.264. and MPEG4 Visual. In this paper. we propose a novel video saliency detection model based on feature contrast in compressed domain. Four types of features including luminance. color. texture. and motion are extracted from the discrete cosine transform coefficients and motion vectors in video bitstream. The static saliency map of unpredicted frames (I frames) is calculated on the basis of luminance. color. and texture features. while the motion saliency map of predicted frames (P and B frames) is computed by motion feature. A new fusion method is designed to combine the static saliency and motion …,True,fXN3dl0AAAAJ:LO7wyVUgiFcC,205,https://ieeexplore.ieee.org/abstract/document/6560380/,4373762888276741163,/scholar?cites=4373762888276741163,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.721.4923&rep=rep1&type=pdf,0,0,0
1279099,Video forgery detection using correlation of noise residue,2008,Chih-Chung Hsu and Tzu-Yi Hung and Chia-Wen Lin and Chiou-Ting Hsu,,,,170-174,IEEE,We propose a new approach for locating forged regions in a video using correlation of noise residue. In our method. block-level correlation values of noise residual are extracted as a feature for classification. We model the distribution of correlation of temporal noise residue in a forged video as a Gaussian mixture model (GMM). We propose a two-step scheme to estimate the model parameters. Consequently. a Bayesian classifier is used to find the optimal threshold value based on the estimated parameters. Two video inpainting schemes are used to simulate two different types of forgery processes for performance evaluation. Simulation results show that our method achieves promising accuracy in video forgery detection.,True,fXN3dl0AAAAJ:5nxA0vEk-isC,201,https://ieeexplore.ieee.org/abstract/document/4665069/,15448653989428742373,/scholar?cites=15448653989428742373,,,https://www.researchgate.net/profile/Chih-Chung_Hsu/publication/221273886_Video_forgery_detection_using_correlation_of_noise_residue/links/0912f513eb24527225000000/Video-forgery-detection-using-correlation-of-noise-residue.pdf,0,0,0
1279100,Self-Learning Based Image Decomposition with Applications to Single Image Denoising,2014,D Huang and L Kang and Y Wang and C Lin,16,IEEE Transactions on Multimedia,1,83−93,IEEE,Decomposition of an image into multiple semantic components has been an effective research topic for various image processing applications such as image denoising. enhancement. and inpainting. In this paper. we present a novel self-learning based image decomposition framework. Based on the recent success of sparse representation. the proposed framework first learns an over-complete dictionary from the high spatial frequency parts of the input image for reconstruction purposes. We perform unsupervised clustering on the observed dictionary atoms (and their corresponding reconstructed image versions) via affinity propagation. which allows us to identify image-dependent components with similar context information. While applying the proposed method for the applications of image denoising. we are able to automatically determine the undesirable patterns (e.g.. rain streaks or Gaussian noise) from the …,True,fXN3dl0AAAAJ:6ZxmRoH8BuwC,192,https://ieeexplore.ieee.org/abstract/document/6623207/,13680918862041675527,/scholar?cites=13680918862041675527,,,https://www.researchgate.net/profile/Li-Wei_Kang/publication/264573776_Self-Learning_Based_Image_Decomposition_With_Applications_to_Single_Image_Denoising/links/54978c770cf2ec13375d3d7f/Self-Learning-Based-Image-Decomposition-With-Applications-to-Single-Image-Denoising.pdf,0,0,0
1279101,Bottom-up saliency detection model based on human visual sensitivity and amplitude spectrum,2012,Yuming Fang and Weisi Lin and Bu-Sung Lee and Chiew-Tong Lau and Zhenzhong Chen and Chia-Wen Lin,14,IEEE Transactions on Multimedia,1,187-198,IEEE,With the wide applications of saliency information in visual signal processing. many saliency detection methods have been proposed. However. some key characteristics of the human visual system (HVS) are still neglected in building these saliency detection models. In this paper. we propose a new saliency detection model based on the human visual sensitivity and the amplitude spectrum of quaternion Fourier transform (QFT). We use the amplitude spectrum of QFT to represent the color. intensity. and orientation distributions for image patches. The saliency value for each image patch is calculated by not only the differences between the QFT amplitude spectrum of this patch and other patches in the whole image. but also the visual impacts for these differences determined by the human visual sensitivity. The experiment results show that the proposed saliency detection model outperforms the state-of-the-art …,True,fXN3dl0AAAAJ:tYavs44e6CUC,158,https://ieeexplore.ieee.org/abstract/document/6029456/,15543581818106727093,/scholar?cites=15543581818106727093,,,https://www.ee.nthu.edu.tw/cwlin/pub/tmm_saliency_2012.pdf,0,0,0
1279102,Wireless video transport using conditional retransmission and low-delay interleaving,2002,Supavadee Aramvith and Chia-Wen Lin and Sumit Roy and Ming-Ting Sun,12,IEEE Transactions on Circuits and Systems for Video Technology,6,558-565,IEEE,We consider the scenario of using Automatic Repeat reQuest (ARQ) retransmission for two-way low-bit-rate video communications over wireless Rayleigh fading channels. Low-delay constraint may require that a corrupted retransmitted packet not be retransmitted again. and thus there will be packet errors at the decoder which results in video quality degradation. We propose a scheme to improve the video quality. First. we propose a low-delay interleaving scheme that uses the video encoder buffer as a part of interleaving memory. Second. we propose a conditional retransmission strategy that reduces the number of retransmissions. Simulation results show that our proposed scheme can effectively reduce the number of packet errors and improve the channel utilization. As a result. we reduce the number of skipped frames and obtain a peak signal-to-noise ratio improvement up to about 4 dB compared to H.263 …,True,fXN3dl0AAAAJ:2osOgNQ5qMEC,128,https://ieeexplore.ieee.org/abstract/document/1013860/,15397253480769771473,/scholar?cites=15397253480769771473,,,https://www.researchgate.net/profile/Chia-Wen_Lin2/publication/3308410_Wireless_video_transport_using_conditional_retransmission_and_low-delay_interleaving/links/0912f50f059689a736000000.pdf,0,0,0
1279103,Dynamic frame-skipping in video transcoding,1998,Jenq-Neng Hwang and Tzong-Der Wu and Chia-Wen Lin,,,,616-621,IEEE,This paper investigates the dynamic frame skipping strategy in video transcoding. To speed up the operation. a video transcoder usually reuses the decoded motion vectors to reencode the video sequences at a lower bit-rate. When frame skipping is allowed in a transcoder. those motion vectors can not be reused because the motion vectors of the current frame is no longer estimated from the immediate past frame. To reduce the computational complexity of motion vectors reestimation. a bilinear interpolation approach is developed to overcome this problem. Based on these interpolated motion vectors. the search range can be much reduced. Furthermore. we propose a frame rate control scheme which can dynamically adjust the number of skipped frames according to the accumulated magnitude of the motion vectors. As a result. the decoded sequence can present much smoother motion.,True,fXN3dl0AAAAJ:9yKSN-GCB0IC,126,https://ieeexplore.ieee.org/abstract/document/739049/,8558463118011095428,/scholar?cites=8558463118011095428,,,,0,0,0
1279104,mDASH: A Markov Decision based Rate Adaptation Approach for Dynamic HTTP Streaming,2016,Chao Zhou and Chia-Wen Lin and Zongming Guo,18,IEEE Transactions on Multimedia,4,pp. 738-751,IEEE,Dynamic adaptive streaming over HTTP (DASH) has recently been widely deployed in the Internet. It. however. does not impose any adaptation logic for selecting the quality of video fragments requested by clients. In this paper. we propose a novel Markov decision-based rate adaptation scheme for DASH aiming to maximize the quality of user experience under time-varying channel conditions. To this end. our proposed method takes into account those key factors that make a critical impact on visual quality. including video playback quality. video rate switching frequency and amplitude. buffer overflow/underflow. and buffer occupancy. Besides. to reduce computational complexity. we propose a low-complexity sub-optimal greedy algorithm which is suitable for real-time video streaming. Our experiments in network test-bed and real-world Internet all demonstrate the good performance of the proposed method in both …,True,fXN3dl0AAAAJ:KaMxkj08jr0C,122,https://ieeexplore.ieee.org/abstract/document/7393865/,4128155301414311586,/scholar?cites=4128155301414311586,,,https://www.ee.nthu.edu.tw/cwlin/pub/tmm_dash_2016.pdf,0,0,0
1279105,TID2008-a database for evaluation of full-reference visual quality assessment metrics,2009,Nikolay Ponomarenko and Vladimir Lukin and Alexander Zelensky and Karen Egiazarian and Marco Carli and Federica Battisti,10,Advances of Modern Radioelectronics,4,30-45,,TID2008. for evaluation of full-reference visual quality assessment metrics is described. It contains 1700 test images (25 reference images. 17 types of distortions for each reference image. 4 different levels of each type of distortion). Mean Opinion Scores (MOS) for this database have been obtained as a result of more than 800 experiments. During these tests. observers from three countries (Finland. Italy. and Ukraine) have carried out about 256000 individual human quality judgments. The obtained MOS can be used for effective testing of different visual quality metrics as well as for the design of new metrics. Using the designed image database. we have tested several known quality metrics. The designed test image database is freely available for downloading and utilization in scientific investigations.,True,IhPhafcAAAAJ:8k81kl-MbHgC,1204,http://k504.khai.edu/attachments/article/89/mre2009tid.pdf,10197442694825674852,/scholar?cites=10197442694825674852,,,http://k504.khai.edu/attachments/article/89/mre2009tid.pdf,0,0,0
1279106,Image database TID2013: Peculiarities. results and perspectives,2015,Nikolay Ponomarenko and Lina Jin and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Jaakko Astola and Benoit Vozel and Kacem Chehdi and Marco Carli and Federica Battisti and C-C Jay Kuo,30,Signal processing: Image communication,,57-77,Elsevier,This paper describes a recently created image database. TID2013. intended for evaluation of full-reference visual quality assessment metrics. With respect to TID2008. the new database contains a larger number (3000) of test images obtained from 25 reference images. 24 types of distortions for each reference image. and 5 levels for each type of distortion. Motivations for introducing 7 new types of distortions and one additional level of distortions are given; examples of distorted images are presented. Mean opinion scores (MOS) for the new database have been collected by performing 985 subjective experiments with volunteers (observers) from five countries (Finland. France. Italy. Ukraine. and USA). The availability of MOS allows the use of the designed database as a fundamental tool for assessing the effectiveness of visual quality. Furthermore. existing visual quality metrics have been tested with the proposed …,True,IhPhafcAAAAJ:L7CI7m0gUJcC,689,https://www.sciencedirect.com/science/article/pii/S0923596514001490,5014264754084340197,/scholar?cites=5014264754084340197,,,https://www.sciencedirect.com/science/article/pii/S0923596514001490,0,0,0
1279107,On between-coefficient contrast masking of DCT basis functions,2007,Nikolay Ponomarenko and Flavia Silvestri and Karen Egiazarian and Marco Carli and Jaakko Astola and Vladimir Lukin,,CD-ROM Proc. of the Third International Workshop on Video Processing and Quality Metrics,,4,,In this paper we propose a simple and effective model of visual between-coefficient contrast masking of DCT basis functions based on a human visual system (HVS). The model operates with the values of DCT coefficients of 8x8 pixel block of an image. For each DCT coefficient of the block the model allows to calculate its maximal distortion that is not visible due to the between-coefficient masking. A modification of the PSNR is also described in this paper. The proposed metric. PSNR-HVS-M. takes into account the proposed model and the contrast sensitivity function (CSF). For efficiency analysis of the proposed model. a set of 18 test images with different effects of noise masking has been used. During experiments. 155 observers have sorted this set of test images in the order of their visual appearance comparing them to undistorted original. The new metric. PSNRHVS-M has outperformed other well-known reference based quality metrics and demonstrated high correlation with the results of subjective experiments (Spearman correlation is 0.984. Kendall correlation is 0.948).,True,IhPhafcAAAAJ:MXK_kJrjxJIC,454,http://ponomarenko.info/vpqm07_p.pdf,12374871955639270101,/scholar?cites=12374871955639270101,,,http://ponomarenko.info/vpqm07_p.pdf,0,0,0
1279108,Color image database TID2013: Peculiarities and preliminary results,2013,Nikolay Ponomarenko and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Lina Jin and Jaakko Astola and Benoit Vozel and Kacem Chehdi and Marco Carli and Federica Battisti and C-C Jay Kuo,,,,106-111,IEEE,Visual quality of color images is an important aspect in various applications of digital image processing and multimedia. A large number of visual quality metrics (indices) has been proposed recently. In order to assess their reliability. several databases of color images with various sets of distortions have been exploited. Here we present a new database called TID2013 that contains a larger number of images. Compared to its predecessor TID2008. seven new types and one more level of distortions are included. The need for considering these new types of distortions is briefly described. Besides. preliminary results of experiments with a large number of volunteers for determining the mean opinion score (MOS) are presented. Spearman and Kendall rank order correlation factors between MOS and a set of popular metrics are calculated and presented. Their analysis shows that adequateness of the existing metrics is …,True,IhPhafcAAAAJ:iH-uZ7U-co4C,403,https://ieeexplore.ieee.org/abstract/document/6623960/,17384081905530121099,/scholar?cites=17384081905530121099,,,https://www.researchgate.net/profile/Marco_Carli/publication/261094981_Color_image_database_TID2013_Peculiarities_and_preliminary_results/links/0deec536c86764dad6000000/Color-image-database-TID2013-Peculiarities-and-preliminary-results.pdf,0,0,0
1279109,New full-reference quality metrics based on HVS,2006,Karen Egiazarian and Jaakko Astola and Nikolay Ponomarenko and Vladimir Lukin and Federica Battisti and Marco Carli,4,Proceedings of the Second International Workshop on Video Processing and Quality Metrics,,,,In this paper. two new full-reference metrics for image quality assessment are presented. They are based on the Peak-Signal-to-Noise Ratio (PSNR) and Universal Quality Index (UQI) modified to take into account the Human Visual System (HVS) properties. Many studies confirm that the HVS is more sensitive to low frequency distortions rather than to high frequency ones. It is also very sensitive to contrast changes and noise. To test the effectiveness of the proposed metrics. we have performed a subjective experiment. In our experiment we have used seven types of distortions with three distortion levels in each. Three independent groups of observers from Finland. Ukraine and Italy. have been participating in image quality evaluation test. The analysis of the results shows that the proposed PSNR-HVS provides better correlation to Mean Observer Score (MOS) than PSNR. and that the proposed UQI-HVS metric …,True,IhPhafcAAAAJ:3fE2CSJIrl8C,347,https://www.researchgate.net/profile/Vladimir_Lukin2/publication/251229783_A_NEW_FULL-REFERENCE_QUALITY_METRICS_BASED_ON_HVS/links/0046351f669a9c1869000000.pdf,254551988233235440,/scholar?cites=254551988233235440,,,https://www.researchgate.net/profile/Vladimir_Lukin2/publication/251229783_A_NEW_FULL-REFERENCE_QUALITY_METRICS_BASED_ON_HVS/links/0046351f669a9c1869000000.pdf,0,0,0
1279110,Color image database for evaluation of image quality metrics,2008,N Ponomarenko and V Lukin and K Egiazarian and Jaakko Astola and Marco Carli and Federica Battisti,,,,403-408,IEEE,In this contribution. a new image database for testing full-reference image quality assessment metrics is presented. It is based on 1700 test images (25 reference images. 17 types of distortions for each reference image. 4 levels for each type of distortion). Using this image database. 654 observers from three different countries (Finland. Italy. and Ukraine) have carried out about 400000 individual human quality judgments (more than 200 judgments for each distorted image). The obtained mean opinion scores for the considered images can be used for evaluating the performances of visual quality metrics as well as for comparison and for the design of new metrics. The database. with testing results. is freely available.,True,IhPhafcAAAAJ:5awf1xo2G04C,210,https://ieeexplore.ieee.org/abstract/document/4665112/,5134212323661291120,/scholar?cites=5134212323661291120,,,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/Color%20Image%20Database%20for%20Evaluation%20of%20Image%20Quality%20Metrics.pdf,0,0,0
1279111,Metrics performance comparison for color image database,2009,Nikolay Ponomarenko and Federica Battisti and Karen Egiazarian and Jaakko Astola and Vladimir Lukin,27,Fourth international workshop on video processing and quality metrics for consumer electronics,,1-6,,In this paper. we exploit a new database of distorted test images TID2008 for verification of full-reference metrics of image visual quality. A comparative analysis of TID20008 and its nearest analog LIVE Database is presented. For a wide variety of known metrics. their correspondence to human visual system is evaluated. The values of rank correlations of Spearman and Kendall with the considered metrics and Mean Opinion Score (MOS) obtained by exploiting TID2008 in experiments are presented. The metrics are verified for both full set of distorted test images in TID2008 (1700 distorted images. 17 types of distortions) and for particular subsets of TID2008 that include distortions most important for digital image processing applications.,True,IhPhafcAAAAJ:kNdYIx-mwKoC,147,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/METRICS%20PERFORMANCE%20COMPARISON%20FOR%20COLOR%20IMAGE%20DATABASE.pdf,6139492325250458546,/scholar?cites=6139492325250458546,,,http://www.comlab.uniroma3.it/Marco/Articoli%20Battisti/METRICS%20PERFORMANCE%20COMPARISON%20FOR%20COLOR%20IMAGE%20DATABASE.pdf,0,0,0
1279112,DCT based high quality image compression,2005,Nikolay Ponomarenko and Vladimir Lukin and Karen Egiazarian and Jaakko Astola,,,,1177-1185,Springer Berlin Heidelberg,DCT based image compression using blocks of size 32x32 is considered. An effective method of bit-plane coding of quantized DCT coefficients is proposed. Parameters of post-filtering for removing of blocking artifacts in decoded images are given. The efficiency of the proposed method for test images compression is analyzed. It is shown that the proposed method is able to provide the quality of decoding images higher than for JPEG2000 by up to 1.9 dB.,True,IhPhafcAAAAJ:KlAtU1dfN6UC,127,https://link.springer.com/chapter/10.1007/11499145_119,16868295085921118402,/scholar?cites=16868295085921118402,,,https://link.springer.com/content/pdf/10.1007/11499145_119.pdf,0,0,0
1279113,Modified image visual quality metrics for contrast change and mean shift accounting,2011,Nikolay Ponomarenko and Oleg Ieremeiev and Vladimir Lukin and Karen Egiazarian and Marco Carli,,,,305-311,IEEE,Graphical information as color images is widely used in CAD and telecommunication systems. Several factors can contribute to impair the quality of an image. This paper deals with image visual quality assessment using objective metrics. Experimental results show that the two modified quality metrics outperform existing ones for a wide set of possible distortions.,True,IhPhafcAAAAJ:4JMBOYKVnBMC,107,https://ieeexplore.ieee.org/abstract/document/5744476/,17984532548489114357,/scholar?cites=17984532548489114357,,,https://ponomarenko.info/papers/psnrhma.pdf,0,0,0
1279114,Locally adaptive DCT filtering for signal-dependent noise removal,2007,Ruşen Öktem and Karen Egiazarian and Vladimir V Lukin and Nikolay N Ponomarenko and Oleg V Tsymbal,2007,EURASIP Journal on Advances in Signal Processing,,1-10,Springer International Publishing,This work addresses the problem of signal-dependent noise removal in images. An adaptive nonlinear filtering approach in the orthogonal transform domain is proposed and analyzed for several typical noise environments in the DCT domain. Being applied locally. that is. within a window of small support. DCT is expected to approximate the Karhunen-Loeve decorrelating transform. which enables effective suppression of noise components. The detail preservation ability of the filter allowing not to destroy any useful content in images is especially emphasized and considered. A local adaptive DCT filtering for the two cases. when signal-dependent noise can be and cannot be mapped into additive uncorrelated noise with homomorphic transform. is formulated. Although the main issue is signal-dependent and pure multiplicative noise. the proposed filtering approach is also found to be competing with the …,True,IhPhafcAAAAJ:Zph67rFs4hoC,82,https://link.springer.com/content/pdf/10.1155/2007/42472.pdf,5897666347723209547,/scholar?cites=5897666347723209547,,,https://link.springer.com/content/pdf/10.1155/2007/42472.pdf,0,0,0
1279115,Image filtering based on discrete cosine transform,2007,VV Lukin and R Oktem and NN Ponomarenko and K Egiazarian,66,Telecommunications and Radio Engineering,18,1685-1701,Begel House Inc.,,True,IhPhafcAAAAJ:ULOm3_A8WrAC,80,,10211919210745053067,/scholar?cites=10211919210745053067,,,,0,0,0
