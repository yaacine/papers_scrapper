,title,pub_year,author,volume,journal,number,pages,publisher,abstract,filled,author_pub_id,num_citations,pub_url,cites_id,citedby_url,gsrank,author_id,eprint_url,got_citations,got_author_ids,author_ids
1281436,Method and apparatus for communications using turbo like codes,2011,Keith Michael Chugg and Paul Kingsley Gray and Georgios Dimitrios Dimou and Phunsak Thiennviboon,,,,,,,True,0jawlUUAAAAJ:P5F9QuxV20EC,196,,4159668465585979657,/scholar?cites=4159668465585979657,,,,0,0,0
1281437,Iterative Detection: Adaptivity. Complexity Reduction. and Applications,2012,Keith Chugg and Achilleas Anastasopoulos and Xiaopeng Chen,602,,,,Springer Science & Business Media,,True,0jawlUUAAAAJ:u5HHmVD_uO8C,180,,1969225421154765587,/scholar?cites=1969225421154765587,,,,0,0,0
1281438,Method and apparatus for communications using improved turbo like codes,2010,Keith Michael Chugg and Paul Kingsley Gray,,,,,,,True,0jawlUUAAAAJ:XiSMed-E-HIC,146,,3755708769122479417,/scholar?cites=3755708769122479417,,,,0,0,0
1281439,MLSE for an unknown channel. I. Optimality considerations,1996,Keith M Chugg and Andreas Polydoros,44,IEEE Transactions on Communications,7,836-846,IEEE,,True,0jawlUUAAAAJ:d1gkVwhDpl0C,141,,17331939591678331076,/scholar?cites=17331939591678331076,,,,0,0,0
1281440,Adaptive soft-input soft-output algorithms for iterative detection with parametric uncertainty,2000,Achilleas Anastasopoulos and Keith M Chugg,48,IEEE Transactions on Communications,10,1638-1649,IEEE,,True,0jawlUUAAAAJ:u-x6o8ySG0sC,135,,15254758510050975520,/scholar?cites=15254758510050975520,,,,0,0,0
1281441,Further results in likelihood classification of QAM signals,1994,CS Long and KM Chugg and A Polydoros,,,,57-61,IEEE,,True,0jawlUUAAAAJ:UeHWp8X0CEIC,111,,15331709690201248031,/scholar?cites=15331709690201248031,,,,0,0,0
1281442,A new approach to rapid PN code acquisition using iterative message passing techniques,2005,Keith M Chugg and Mingrui Zhu,23,IEEE journal on selected areas in communications,5,884-897,IEEE,,True,0jawlUUAAAAJ:IjCSPb-OGe4C,108,,8575139376195503393,/scholar?cites=8575139376195503393,,,,0,0,0
1281443,Towards mobile ad-hoc WANs: Terminodes,2000,J-P Hubaux and J-Y Le Boudec and Silvia Giordano and Maher Hamdi and Ljubica Blazevic and Levente Buttyan and Milan Vojnovic,3,,,1052-1059,IEEE,,True,0jawlUUAAAAJ:AvfA0Oy_GE0C,107,,9576850884223182823,/scholar?cites=9576850884223182823,,,,0,0,0
1281444,An algorithm for counting short cycles in bipartite graphs,2005,Thomas R Halford and Keith M Chugg,52,IEEE Transactions on Information Theory,1,287-292,IEEE,,True,0jawlUUAAAAJ:5nxA0vEk-isC,105,,17299447868105511762,/scholar?cites=17299447868105511762,,,,0,0,0
1281445,Adaptive iterative detection for phase tracking in turbo-coded systems,2001,Achilleas Anastasopoulos and Keith M Chugg,49,IEEE Transactions on Communications,12,2135-2144,IEEE,,True,0jawlUUAAAAJ:9yKSN-GCB0IC,99,,5730470279542861293,/scholar?cites=5730470279542861293,,,,0,0,0
1281446,A theoretical study on the effects of interference UWB multiple access impulse radio,2002,Ali Taha and Keith M Chugg,1,,,728-732,IEEE,,True,0jawlUUAAAAJ:2osOgNQ5qMEC,89,,16061848867231696757,/scholar?cites=16061848867231696757,,,,0,0,0
1281447,Hand Gesture Recognition with 3D Convolutional Neural Networks,2015,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Jan Jautz,,,,,IEEE Computer Society,,True,MVanlR8AAAAJ:SeFeTyx0c_EC,407,,13528217692621440063,/scholar?cites=13528217692621440063,,,,0,0,0
1281448,Online detection and classification of dynamic hand gestures with recurrent 3d convolutional neural network,2016,Pavlo Molchanov and Xiaodong Yang and Shalini Gupta and Kihwan Kim and Stephen Tyree and Jan Kautz,,,,4207-4215,,,True,MVanlR8AAAAJ:9c2xU6iGI7YC,375,,3040705073843151431,/scholar?cites=3040705073843151431,,,,0,0,0
1281449,Multi-sensor System for Driver’s Hand-Gesture Recognition,2015,Pavlo Molchanov and Shalini Gupta and Kim and Kari Kihwan and Pulli,,,,,IEEE,,True,MVanlR8AAAAJ:RYcK_YlVTxYC,193,,5817183552051842322,/scholar?cites=5817183552051842322,,,,0,0,0
1281450,Gaussian process regression flow for analysis of motion trajectories,2011,Kihwan Kim and Dongryeol Lee and Irfan Essa,,,,,,,True,MVanlR8AAAAJ:D03iK_w7-QYC,191,,11387664996386206079,/scholar?cites=11387664996386206079,,,,0,0,0
1281451,Geometry-aware learning of maps for camera localization,2018,Samarth Brahmbhatt and Jinwei Gu and Kihwan Kim and James Hays and Jan Kautz,,,,2616-2625,,,True,MVanlR8AAAAJ:w0F2JDEymm0C,184,,15361942550307476955,/scholar?cites=15361942550307476955,,,,0,0,0
1281452,Competitive collaboration: Joint unsupervised learning of depth. camera motion. optical flow and motion segmentation,2019,Anurag Ranjan and Varun Jampani and Lukas Balles and Kihwan Kim and Deqing Sun and Jonas Wulff and Michael J Black,,,,12240-12249,,,True,MVanlR8AAAAJ:qE4H1tSSYIIC,172,,8899288224036536376,/scholar?cites=8899288224036536376,,,,0,0,0
1281453,Short-range FMCW monopulse radar for hand-gesture sensing,2015,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Kari Pulli,,,,1491-1496,IEEE,,True,MVanlR8AAAAJ:vV6vV6tmYwMC,150,,16613778594857123430,/scholar?cites=16613778594857123430,,,,0,0,0
1281454,How transformational leadership facilitates innovative behavior of Korean workers,2016,Suk Bong Choi and Kihwan Kim and SM Ebrahim Ullah and Seung-Wan Kang,,Personnel Review,,,Emerald Group Publishing Limited,,True,MVanlR8AAAAJ:q0uBw5dMOAkC,132,,14601266838676609284,/scholar?cites=14601266838676609284,,,,0,0,0
1281455,Effects of transformational and shared leadership styles on employees' perception of team effectiveness,2017,Suk Bong Choi and Kihwan Kim and Seung-Wan Kang,45,Social Behavior and Personality: an international journal,3,377-386,Scientific Journal Publishers,,True,MVanlR8AAAAJ:LXmCCkuhhTsC,128,,14281164858399521778,/scholar?cites=14281164858399521778,,,,0,0,0
1281456,Motion fields to predict play evolution in dynamic sport scenes,2010,Kihwan Kim and Matthias Grundmann and Ariel Shamir and Iain Matthews and Jessica Hodgins and Irfan Essa,,,,840-847,IEEE,,True,MVanlR8AAAAJ:d1gkVwhDpl0C,107,,14101707447794239098,/scholar?cites=14101707447794239098,,,,0,0,0
1281457,Radar based user interface,2019,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Kari Pulli,,,,,,,True,MVanlR8AAAAJ:KNjnJ3z-R6IC,73,,2645889365309959006,/scholar?cites=2645889365309959006,,,,0,0,0
1281458,SGDR: stochastic gradient descent with warm restarts,2016,Ilya Loshchilov and Frank Hutter,,,,,,,True,GladWQwAAAAJ:FPJr55Dyh1AC,1570,,9496349859848656559,/scholar?cites=9496349859848656559,,,,0,0,0
1281459,Decoupled Weight Decay Regularization,2018,Ilya Loshchilov and Frank Hutter,,,,,,,True,GladWQwAAAAJ:anf4URPfarAC,1225,,5602734827563786057,/scholar?cites=5602734827563786057,,,,0,0,0
1281460,CMA-ES for Hyperparameter Optimization of Deep Neural Networks,2016,Ilya Loshchilov and Frank Hutter,,International Conference on Learning Representations (ICLR 2016). Workshop Track.,,,,,True,GladWQwAAAAJ:Ug5p-4gJ2f0C,193,,1379162563687232263,/scholar?cites=1379162563687232263,,,,0,0,0
1281461,A downsampled variant of imagenet as an alternative to the cifar datasets,2017,Patryk Chrabaszcz and Ilya Loshchilov and Frank Hutter,,arXiv preprint arXiv:1707.08819,,,,,True,GladWQwAAAAJ:rmuvC79q63oC,178,,11571282705029144764,/scholar?cites=11571282705029144764,,,,0,0,0
1281462,Online batch selection for faster training of neural networks,2015,Ilya Loshchilov and Frank Hutter,,,,,,,True,GladWQwAAAAJ:k8Z6L05lTy4C,158,,5870835542096085843,/scholar?cites=5870835542096085843,,,,0,0,0
1281463,CMA-ES with restarts for solving CEC 2013 benchmark problems,2013,Ilya Loshchilov,,,,369-376,Ieee,,True,GladWQwAAAAJ:WF5omc3nYNoC,125,,16526302899445684359,/scholar?cites=16526302899445684359,,,,0,0,0
1281464,Self-adaptive surrogate-assisted covariance matrix adaptation evolution strategy,2012,Ilya Loshchilov and Marc Schoenauer and Michèle Sebag,,,,321-328,,,True,GladWQwAAAAJ:UeHWp8X0CEIC,79,,10295250954286550931,/scholar?cites=10295250954286550931,,,,0,0,0
1281465,A mono surrogate for multiobjective optimization,2010,Ilya Loshchilov and Marc Schoenauer and Michèle Sebag,,,,471-478,ACM,,True,GladWQwAAAAJ:u-x6o8ySG0sC,70,,17447730458332556510,/scholar?cites=17447730458332556510,,,,0,0,0
1281466,Comparison-based optimizers need comparison-based surrogates,2011,Ilya Loshchilov and Marc Schoenauer and Michèle Sebag,,Parallel Problem Solving from Nature–PPSN XI,,364-373,Springer Berlin/Heidelberg,,True,GladWQwAAAAJ:u5HHmVD_uO8C,69,,5008297690421607844,/scholar?cites=5008297690421607844,,,,0,0,0
1281467,RoboGen: Robot Generation through Artificial Evolution,2014,Joshua E Auerbach and Deniz Aydin and Andrea Maesani and Przemyslaw M Kornatowski and Titus Cieslewski and Grégoire Heitz and Pradeep R Fernando and Ilya Loshchilov and Ludovic Daler and Dario Floreano,14,,,136-137,,,True,GladWQwAAAAJ:gsN89kCJA0AC,64,,12853120095746318193,/scholar?cites=12853120095746318193,,,,0,0,0
1281468,A Computationally Efficient Limited Memory CMA-ES for Large Scale Optimization,2014,Ilya Loshchilov,,,,,,,True,GladWQwAAAAJ:tYavs44e6CUC,62,,17689722758172339653,/scholar?cites=17689722758172339653,,,,0,0,0
1281469,Efficientnet: Rethinking model scaling for convolutional neural networks,2019,Mingxing Tan and Quoc Le,,,,6105-6114,PMLR,,True,6POeyBoAAAAJ:kRWSkSYxWN8C,2176,,5472015514843683656,/scholar?cites=5472015514843683656,,,,0,0,0
1281470,Mnasnet: Platform-aware neural architecture search for mobile,2019,Mingxing Tan and Bo Chen and Ruoming Pang and Vijay Vasudevan and Mark Sandler and Andrew Howard and Quoc V Le,,,,2820-2828,,,True,6POeyBoAAAAJ:eflP2zaiRacC,998,,1725364759924402840,/scholar?cites=1725364759924402840,,,,0,0,0
1281471,Searching for mobilenetv3,2019,Andrew Howard and Mark Sandler and Grace Chu and Liang-Chieh Chen and Bo Chen and Mingxing Tan and Weijun Wang and Yukun Zhu and Ruoming Pang and Vijay Vasudevan and Quoc V Le and Hartwig Adam,,,,1314-1324,,,True,6POeyBoAAAAJ:mvPsJ3kp5DgC,749,,10660854575390248964,/scholar?cites=10660854575390248964,,,,0,0,0
1281472,Efficientdet: Scalable and efficient object detection,2020,Mingxing Tan and Ruoming Pang and Quoc V Le,,,,10781-10790,,,True,6POeyBoAAAAJ:5ugPr518TE4C,445,,16138254679061222132,/scholar?cites=16138254679061222132,,,,0,0,0
1281473,Adversarial examples improve image recognition,2020,Cihang Xie and Mingxing Tan and Boqing Gong and Jiang Wang and Alan L Yuille and Quoc V Le,,,,819-828,,,True,6POeyBoAAAAJ:J-pR_7NvFogC,107,,12540097159832752079,/scholar?cites=12540097159832752079,,,,0,0,0
1281474,MixConv: Mixed Depthwise Convolutional Kernels,2019,Mingxing Tan and Quoc V Le,,,,,,,True,6POeyBoAAAAJ:1qzjygNMrQYC,104,,7962729053282363521,/scholar?cites=7962729053282363521,,,,0,0,0
1281475,Elasticflow: A complexity-effective approach for pipelining irregular loop nests,2015,Mingxing Tan and Gai Liu and Ritchie Zhao and Steve Dai and Zhiru Zhang,,,,78-85,IEEE,,True,6POeyBoAAAAJ:LPZeul_q3PIC,43,,12480425444635647667,/scholar?cites=12480425444635647667,,,,0,0,0
1281476,Spinenet: Learning scale-permuted backbone for recognition and localization,2020,Xianzhi Du and Tsung-Yi Lin and Pengchong Jin and Golnaz Ghiasi and Mingxing Tan and Yin Cui and Quoc V Le and Xiaodan Song,,,,11592-11601,,,True,6POeyBoAAAAJ:bnK-pcrLprsC,39,,1529254353402789268,/scholar?cites=1529254353402789268,,,,0,0,0
1281477,Bignas: Scaling up neural architecture search with big single-stage models,2020,Jiahui Yu and Pengchong Jin and Hanxiao Liu and Gabriel Bender and Pieter-Jan Kindermans and Mingxing Tan and Thomas Huang and Xiaodan Song and Ruoming Pang and Quoc Le,,,,702-717,Springer. Cham,,True,6POeyBoAAAAJ:HE397vMXCloC,38,,14713025129873223206,/scholar?cites=14713025129873223206,,,,0,0,0
1281478,Architectural specialization for inter-iteration loop dependence patterns,2014,Shreesha Srinath and Berkin Ilbeyi and Mingxing Tan and Gai Liu and Zhiru Zhang and Christopher Batten,,,,583-595,IEEE,,True,6POeyBoAAAAJ:738O_yMBCRsC,33,,13551311265864948994,/scholar?cites=13551311265864948994,,,,0,0,0
1281479,Assemblenet: Searching for multi-stream neural connectivity in video architectures,2019,Michael S Ryoo and AJ Piergiovanni and Mingxing Tan and Anelia Angelova,,arXiv preprint arXiv:1905.13209,,,,,True,6POeyBoAAAAJ:V3AGJWp-ZtQC,32,,4088147155924192014,/scholar?cites=4088147155924192014,,,,0,0,0
1281480,Self-Normalizing Neural Networks,2017,Günter Klambauer and Thomas Unterthiner and Andreas Mayr and Sepp Hochreiter,,,,972--981,,,True,rb2AvxIAAAAJ:yB1At4FlUx8C,1432,,3659160383490046744,/scholar?cites=3659160383490046744,,,,0,0,0
1281481,DeepTox: toxicity prediction using deep learning,2016,Andreas Mayr and Günter Klambauer and Thomas Unterthiner and Sepp Hochreiter,3,Frontiers in Environmental Science,,80,Frontiers,,True,rb2AvxIAAAAJ:_Ybze24A_UAC,431,,6232357894134252275,/scholar?cites=6232357894134252275,,,,0,0,0
1281482,cn. MOPS: mixture of Poissons for discovering copy number variations in next-generation sequencing data with a low false discovery rate,2012,Günter Klambauer and Karin Schwarzbauer and Andreas Mayr and Djork-Arné Clevert and Andreas Mitterecker and Ulrich Bodenhofer and Sepp Hochreiter,40,Nucleic acids research,9,e69,Oxford University Press,,True,rb2AvxIAAAAJ:u5HHmVD_uO8C,339,,16810642960646768971,/scholar?cites=16810642960646768971,,,,0,0,0
1281483,GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium,2017,M Heusel and H Ramsauer and T Unterthiner and B Nessler and G Klambauer and S Hochreiter,,,,,,,True,rb2AvxIAAAAJ:lmc2jWPfTJgC,265,,54268214411324516,/scholar?cites=54268214411324516,,,,0,0,0
1281484,Large-scale comparison of machine learning methods for drug target prediction on ChEMBL,2018,Andreas Mayr and Günter Klambauer and Thomas Unterthiner and Marvin Steijaert and Jörg K Wegner and Hugo Ceulemans and Djork-Arné Clevert and Sepp Hochreiter,9,Chemical science,24,5441-5451,Royal Society of Chemistry,,True,rb2AvxIAAAAJ:epqYDVWIO7EC,188,,18007879668317683284,/scholar?cites=18007879668317683284,,,,0,0,0
1281485,Deep learning as an opportunity in virtual screening,2014,T. Unterthiner and A. Mayr and G. Klambauer and M. Steijaert and J. K. Wegner and H. Ceulemans and S. Hochreiter,,,,,,,True,rb2AvxIAAAAJ:dQ2og3OwTAUC,157,,15436735814886956305,/scholar?cites=15436735814886956305,,,,0,0,0
1281486,DeepSynergy: predicting anti-cancer drug synergy with Deep Learning,2018,Kristina Preuer and Richard PI Lewis and Sepp Hochreiter and Andreas Bender and Krishna C Bulusu and Günter Klambauer,34,Bioinformatics,9,1538-1546,Oxford University Press,,True,rb2AvxIAAAAJ:nrtMV_XWKgEC,136,,14785802506873719336,/scholar?cites=14785802506873719336,,,,0,0,0
1281487,Repurposed high-throughput image assays enables biological activity prediction for drug discovery,2018,Jaak Simm and Guenter Klambauer and Adam Arany and Marvin Steijaert and Joerg Kurt Wegner and Emmanuel Gustin and Vladimir Chupakhin and Yolanda T Chong and Jorge Vialard and Peter Buijnsters and Ingrid Velter and Alexander Vapirev and Shantanu Singh and Anne Carpenter and Roel Wuyts and Sepp Hochreiter and Yves Moreau and Hugo Ceulemans,,Cell Chemical Biology,,108399,Cold Spring Harbor Laboratory,,True,rb2AvxIAAAAJ:_Re3VWB3Y0AC,111,,7250633998206681179,/scholar?cites=7250633998206681179,,,,0,0,0
1281488,How adverse outcome pathways can aid the development and use of computational prediction models for regulatory toxicology,2017,Clemens Wittwehr and Hristo Aladjov and Gerald Ankley and Hugh J Byrne and Joop de Knecht and Elmar Heinzle and Günter Klambauer and Brigitte Landesmann and Mirjam Luijten and Cameron MacKay and Gavin Maxwell and ME Meek and Alicia Paini and Edward Perkins and Tomasz Sobanski and Dan Villeneuve and Katrina M Waters and Maurice Whelan,155,Toxicological Sciences,2,326-336,Oxford University Press,,True,rb2AvxIAAAAJ:7T2F9Uy0os0C,95,,13964954130240863460,/scholar?cites=13964954130240863460,,,,0,0,0
1281489,Prediction of human population responses to toxic compounds by a collaborative competition,2015,Federica Eduati and Lara M Mangravite and Tao Wang and Hao Tang and Sepp Hochreiter and Günter Klambauer and Andreas Mayr and Ivan Rusyn and Fred A Wright and Gustavo Stolovitzky and Yang Xie and Julio Saez-Rodriguez,,Nature biotechnology,,,,,True,rb2AvxIAAAAJ:JQOojiI6XY0C,91,,395712320854227471,/scholar?cites=395712320854227471,,,,0,0,0
1281490,Toxicity prediction using deep learning,2015,Thomas Unterthiner and Andreas Mayr and Günter Klambauer and Sepp Hochreiter,,arXiv preprint arXiv:1503.01445,,,,,True,rb2AvxIAAAAJ:kzcrU_BdoSEC,75,,11429858184424095168,/scholar?cites=11429858184424095168,,,,0,0,0
1281491,Stacked Generative Adversarial Networks,2017,Xun Huang and Yixuan Li and Omid Poursaeed and John Hopcroft and Serge Belongie,,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,,,True,QSTd1oUAAAAJ:Mojj43d5GZwC,1889,,17276767268002585863,/scholar?cites=17276767268002585863,,,,0,0,0
1281492,Exploring the limits of weakly supervised pretraining,2018,Dhruv Mahajan and Ross Girshick and Vignesh Ramanathan and Kaiming He and Manohar Paluri and Yixuan Li and Ashwin Bharambe and Laurens Van Der Maaten,,,,181-196,,,True,QSTd1oUAAAAJ:ye4kPcJQO24C,544,,8358288919170046195,/scholar?cites=8358288919170046195,,,,0,0,0
1281493,Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks,2018,Shiyu Liang and Yixuan Li and R Srikant,,,,,,,True,QSTd1oUAAAAJ:_B80troHkn4C,498,,7536099354022278878,/scholar?cites=7536099354022278878,,,,0,0,0
1281494,Snapshot Ensembles: Train 1. Get M for Free,2017,Gao Huang* and Yixuan Li* and Geoff Pleiss and Zhuang Liu and John E. Hopcroft and Kilian Q. Weinberger,,,,,,,True,QSTd1oUAAAAJ:Y5dfb0dijaUC,409,,13258787322136448860,/scholar?cites=13258787322136448860,,,,0,0,0
1281495,Convergent Learning: Do different neural networks learn the same representations?,2015,Yixuan Li and Jason Yosinski and Jeff Clune and Hod Lipson and John Hopcroft,,,,,,,True,QSTd1oUAAAAJ:u5HHmVD_uO8C,173,,11744724581370429392,/scholar?cites=11744724581370429392,,,,0,0,0
1281496,Uncovering the small community structure in large networks: A local spectral approach,2015,Yixuan Li and Kun He and David Bindel and John E Hopcroft,,,,658-668,,,True,QSTd1oUAAAAJ:2osOgNQ5qMEC,93,,8600317253490145954,/scholar?cites=8600317253490145954,,,,0,0,0
1281497,The lifecycle and cascade of wechat social messaging groups,2016,Jiezhong Qiu and Yixuan Li and Jie Tang and Zheng Lu and Hao Ye and Bo Chen and Qiang Yang and John E Hopcroft,,,,311-320,,,True,QSTd1oUAAAAJ:olpn-zPbct0C,71,,2605898496780949639,/scholar?cites=2605898496780949639,,,,0,0,0
1281498,Deep manifold traversal: Changing labels with convolutional features,2015,Jacob R Gardner and Paul Upchurch and Matt J Kusner and Yixuan Li and Kilian Q Weinberger and Kavita Bala and John E Hopcroft,,arXiv preprint arXiv:1511.06421,,,,,True,QSTd1oUAAAAJ:9yKSN-GCB0IC,62,,14475583420390812731,/scholar?cites=14475583420390812731,,,,0,0,0
1281499,Detecting overlapping communities from local spectral subspaces,2015,Kun He and Yiwei Sun and David Bindel and John Hopcroft and Yixuan Li,,,,769-774,IEEE,,True,QSTd1oUAAAAJ:UeHWp8X0CEIC,57,,14577152744489065904,/scholar?cites=14577152744489065904,,,,0,0,0
1281500,Understanding the loss surface of neural networks for binary classification,2018,Shiyu Liang and Ruoyu Sun and Yixuan Li and Rayadurgam Srikant,,,,2835-2843,PMLR,,True,QSTd1oUAAAAJ:SdhP9T11ey4C,48,,111227920399475959,/scholar?cites=111227920399475959,,,,0,0,0
1281501,Local spectral clustering for overlapping community detection,2018,Yixuan Li and Kun He and Kyle Kloster and David Bindel and John Hopcroft,12,ACM Transactions on Knowledge Discovery from Data (TKDD),2,1-27,ACM,,True,QSTd1oUAAAAJ:JoZmwDi-zQgC,48,,13043119186656251868,/scholar?cites=13043119186656251868,,,,0,0,0
1281502,The visual object tracking VOT2016 challenge results,2016,Matej Kristan and et al.,9914,,,777-823,,,True,3TggrEkAAAAJ:dMpQl7XwOw4C,1625,,5030672482439802527,/scholar?cites=5030672482439802527,,,,0,0,0
1281503,Latent regression forest: Structured estimation of 3d articulated hand posture,2014,Danhang Tang and Hyung Jin Chang and Alykhan Tejani and Tae-Kyun Kim,,,,3786-3793,,,True,3TggrEkAAAAJ:J_g5lzvAfSwC,348,,1769363859732722827,/scholar?cites=1769363859732722827,,,,0,0,0
1281504,The sixth visual object tracking vot2018 challenge results,2018,Matej Kristan and Ales Leonardis and Jiri Matas and Michael Felsberg and Roman Pflugfelder and Luka ˇCehovin Zajc and Tomas Vojir and Goutam Bhat and Alan Lukezic and Abdelrahman Eldesokey and Gustavo Fernandez and Álvaro García-Martín and Álvaro Iglesias-Arias and A Aydin Alatan and Abel González-García and Alfredo Petrosino and Alireza Memarmoghadam and Andrea Vedaldi and Andrej Muhic and Anfeng He and Arnold Smeulders and Asanka G Perera and Bo Li and Boyu Chen and Changick Kim and Changsheng Xu and Changzhen Xiong and Cheng Tian and Chong Luo and Chong Sun and Cong Hao and Daijin Kim and Deepak Mishra and Deming Chen and Dong Wang and Dongyoon Wee and Efstratios Gavves and Erhan Gundogdu and Erik Velasco-Salido and Fahad Shahbaz Khan and Fan Yang and Fei Zhao and Feng Li and Francesco Battistone and George De Ath and Gorthi RKS Subrahmanyam and Guilherme Bastos and Haibin Ling and Hamed Kiani Galoogahi and Hankyeol Lee and Haojie Li and Haojie Zhao and Heng Fan and Honggang Zhang and Horst Possegger and Houqiang Li and Huchuan Lu and Hui Zhi and Huiyun Li and Hyemin Lee and Hyung Jin Chang and Isabela Drummond and Jack Valmadre and Jaime Spencer Martin and Javaan Chahl and Jin Young Choi and Jing Li and Jinqiao Wang and Jinqing Qi and Jinyoung Sung and Joakim Johnander and Joao Henriques and Jongwon Choi and Joost van de Weijer and Jorge Rodriguez Herranz and José M Martínez and Josef Kittler and Junfei Zhuang and Junyu Gao and Klemen Grm and Lichao Zhang and Lijun Wang and Lingxiao Yang and Litu Rout and Liu Si and Luca Bertinetto and Lutao Chu and Manqiang Che and Mario Edoardo Maresca and Martin Danelljan and Ming-Hsuan Yang and Mohamed Abdelpakey and Mohamed Shehata and Myunggu Kang and Namhoon Lee and Ning Wang and Ondrej Miksik and Payman Moallem and Pablo Vicente-Moñivar and Pedro Senna and Peixia Li and Philip Torr and Priya Mariam Raju and Qian Ruihe and Qiang Wang and Qin Zhou and Qing Guo and Rafael Martin-Nieto and Rama Krishna Gorthi and Ran Tao and Richard Bowden and Richard Everson and Runling Wang and Sangdoo Yun and Seokeon Choi and Sergio Vivas and Shuai Bai and Shuangping Huang and Sihang Wu and Simon Hadfield and Siwen Wang and Stuart Golodetz and Tang Ming and Tianyang Xu and Tianzhu Zhang and Tobias Fischer and Vincenzo Santopietro and Vitomir Struc and Wang Wei and Wangmeng Zuo and Wei Feng and Wei Wu and Wei Zou and Weiming Hu and Wengang Zhou and Wenjun Zeng and Xiaofan Zhang and Xiaohe Wu and Xiao-Jun Wu and Xinmei Tian and Yan Li and Yan Lu and Yee Wei Law and Yi Wu and Yiannis Demiris and Yicai Yang and Yifan Jiao and Yuhong Li and Yunhua Zhang and Yuxuan Sun,,,,0-0,,,True,3TggrEkAAAAJ:aU4yMueWZ3QC,329,,15781444868292583646,/scholar?cites=15781444868292583646,,,,0,0,0
1281505,Attentional correlation filter network for adaptive visual tracking,2017,Jongwon Choi and Hyung Jin Chang and Sangdoo Yun and Tobias Fischer and Yiannis Demiris and Jin Young Choi,,,,4807-4816,,,True,3TggrEkAAAAJ:SP6oXDckpogC,250,,7048582756083604217,/scholar?cites=7048582756083604217,,,,0,0,0
1281506,Visual tracking using attention-modulated disintegration and integration,2016,Jongwon Choi and Hyung Jin Chang and Jiyeoup Jeong and Yiannis Demiris and Jin Young Choi,,,,4321-4330,,,True,3TggrEkAAAAJ:f2IySw72cVMC,170,,4923123732085070946,/scholar?cites=4923123732085070946,,,,0,0,0
1281507,Context-aware deep feature compression for high-speed visual tracking,2018,Jongwon Choi and Hyung Jin Chang and Tobias Fischer and Sangdoo Yun and Kyuewang Lee and Jiyeoup Jeong and Yiannis Demiris and Jin Young Choi,,,,479-488,,,True,3TggrEkAAAAJ:cx97FdCJQX8C,140,,571172096804857192,/scholar?cites=571172096804857192,,,,0,0,0
1281508,Detection of moving objects with non-stationary cameras in 5.8 ms: Bringing motion detection to your mobile device,2013,Kwang Moo Yi and Kimin Yun and Soo Wan Kim and Hyung Jin Chang and Jin Young Choi,,,,27-34,,,True,3TggrEkAAAAJ:blknAaTinKkC,111,,15425458958659768679,/scholar?cites=15425458958659768679,,,,0,0,0
1281509,Rt-gene: Real-time eye gaze estimation in natural environments,2018,Tobias Fischer and Hyung Jin Chang and Yiannis Demiris,,,,334-352,,,True,3TggrEkAAAAJ:MqTxh1vmwXEC,85,,17481902067810525081,/scholar?cites=17481902067810525081,,,,0,0,0
1281510,3d finger cape: Clicking action and position estimation under self-occlusions in egocentric viewpoint,2015,Youngkyoon Jang and Seung-Tak Noh and Hyung Jin Chang and Tae-Kyun Kim and Woontack Woo,21,IEEE Transactions on Visualization and Computer Graphics,4,501-510,IEEE,,True,3TggrEkAAAAJ:SeFeTyx0c_EC,85,,9544570429290580354,/scholar?cites=9544570429290580354,,,,0,0,0
1281511,Robust action recognition using local motion and group sparsity,2014,Jungchan Cho and Minsik Lee and Hyung Jin Chang and Songhwai Oh,47,Pattern Recognition,5,1813-1825,Pergamon,,True,3TggrEkAAAAJ:BqipwSGYUEgC,63,,11819093402209393410,/scholar?cites=11819093402209393410,,,,0,0,0
1281512,Robust moving object detection against fast illumination change,2012,JinMin Choi and Hyung Jin Chang and Yung Jun Yoo and Jin Young Choi,116,Computer Vision and Image Understanding,2,179-193,Academic Press,,True,3TggrEkAAAAJ:UeHWp8X0CEIC,53,,5483006206724495181,/scholar?cites=5483006206724495181,,,,0,0,0
1281513,Bayesian compressive sensing,2008,Shihao Ji and Ya Xue and Lawrence Carin,56,IEEE Transactions on signal processing,6,2346-2356,IEEE,,True,qMfWf9EAAAAJ:u5HHmVD_uO8C,2193,,9030205691967861345,/scholar?cites=9030205691967861345,,,,0,0,0
1281514,Multitask compressive sensing,2008,Shihao Ji and David Dunson and Lawrence Carin,57,IEEE Transactions on Signal Processing,1,92-106,IEEE,,True,qMfWf9EAAAAJ:u-x6o8ySG0sC,513,,7261477203662623862,/scholar?cites=7261477203662623862,,,,0,0,0
1281515,Cost-sensitive feature acquisition and classification,2007,Shihao Ji and Lawrence Carin,40,Pattern Recognition,5,1474-1485,Pergamon,,True,qMfWf9EAAAAJ:9yKSN-GCB0IC,134,,6359738783363820630,/scholar?cites=6359738783363820630,,,,0,0,0
1281516,Intent-based diversification of web search results: metrics and algorithms,2011,Olivier Chapelle and Shihao Ji and Ciya Liao and Emre Velipasaoglu and Larry Lai and Su-Lin Wu,14,Information Retrieval,6,572-592,Springer Netherlands,,True,qMfWf9EAAAAJ:Y0pCki6q_DkC,118,,10274727848292564815,/scholar?cites=10274727848292564815,,,,0,0,0
1281517,Incorporating recency in network search using machine learning,2014,Anlei Dong and Yi Chang and Ruiqiang Zhang and Zhaohui Zheng and Gilad Avraham Mishne and Jing Bai and Karolina Barbara Buchner and Ciya Liao and Shihao Ji and Gilbert Leung and Georges-eric Albert Marie Robert Dupret and Ling Liu,,,,,,,True,qMfWf9EAAAAJ:0EnyYjriUFMC,73,,13656504270787467874,/scholar?cites=13656504270787467874,,,,0,0,0
1281518,Variational Bayes for continuous hidden Markov models and its application to active learning,2006,Shihao Ji and Balaji Krishnapuram and Lawrence Carin,28,IEEE Transactions on Pattern Analysis and Machine Intelligence,4,522-532,IEEE,,True,qMfWf9EAAAAJ:d1gkVwhDpl0C,71,,16200624801815623154,/scholar?cites=16200624801815623154,,,,0,0,0
1281519,Blackout: Speeding up recurrent neural network language models with very large vocabularies,2015,Shihao Ji and SVN Vishwanathan and Nadathur Satish and Michael J Anderson and Pradeep Dubey,,arXiv preprint arXiv:1511.06909,,,,,True,qMfWf9EAAAAJ:9ZlFYXVOiuMC,68,,9087616384060218141,/scholar?cites=9087616384060218141,,,,0,0,0
1281520,Nonmyopic multiaspect sensing with partially observable Markov decision processes,2007,Shihao Ji and Ronald Parr and Lawrence Carin,55,IEEE Transactions on Signal Processing,6,2720-2730,IEEE,,True,qMfWf9EAAAAJ:qjMakFHDy7sC,67,,1639860877703027885,/scholar?cites=1639860877703027885,,,,0,0,0
1281521,Global ranking by exploiting user clicks,2009,Shihao Ji and Ke Zhou and Ciya Liao and Zhaohui Zheng and Gui-Rong Xue and Olivier Chapelle and Gordon Sun and Hongyuan Zha,,,,35-42,,,True,qMfWf9EAAAAJ:2osOgNQ5qMEC,59,,700603547853797178,/scholar?cites=700603547853797178,,,,0,0,0
1281522,Bayesian compressive sensing and projection optimization,2007,Shihao Ji and Lawrence Carin,,,,377-384,,,True,qMfWf9EAAAAJ:UeHWp8X0CEIC,57,,12165330900452819174,/scholar?cites=12165330900452819174,,,,0,0,0
1281523,Point-based policy iteration,2007,Shihao Ji and Ronald Parr and Hui Li and Xuejun Liao and Lawrence Carin,,,,1243-1249,,,True,qMfWf9EAAAAJ:IjCSPb-OGe4C,56,,1083245306967005538,/scholar?cites=1083245306967005538,,,,0,0,0
1281524,Convolutional neural networks for speech recognition,2014,Ossama Abdel-Hamid and Abdel-rahman Mohamed and Hui Jiang and Li Deng and Gerald Penn and Dong Yu,22,"IEEE/ACM Transactions on audio, speech, and language processing",10,1533-1545,IEEE,,True,nfZNs5AAAAAJ:ufrVoPGSRksC,1636,,1312499869604546054,/scholar?cites=1312499869604546054,,,,0,0,0
1281525,Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition,2012,Ossama Abdel-Hamid and Abdel-rahman Mohamed and Hui Jiang and Gerald Penn,,,,4277-4280,IEEE,,True,nfZNs5AAAAAJ:d1gkVwhDpl0C,935,,507237803824555927,/scholar?cites=507237803824555927,,,,0,0,0
1281526,Exploring convolutional neural network structures and optimization techniques for speech recognition.,2013,Ossama Abdel-Hamid and Li Deng and Dong Yu,11,Interspeech,,73-5,,,True,nfZNs5AAAAAJ:Y0pCki6q_DkC,363,,2969487650303083097,/scholar?cites=2969487650303083097,,,,0,0,0
1281527,Fast speaker adaptation of hybrid NN/HMM model for speech recognition based on discriminative learning of speaker code,2013,Ossama Abdel-Hamid and Hui Jiang,,,,7942-7946,IEEE,,True,nfZNs5AAAAAJ:zYLM7Y9cAGgC,231,,592434749424056765,/scholar?cites=592434749424056765,,,,0,0,0
1281528,A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion,2013,Li Deng and Ossama Abdel-Hamid and Dong Yu,,,,6669-6673,IEEE,,True,nfZNs5AAAAAJ:IjCSPb-OGe4C,181,,6202733932875270331,/scholar?cites=6202733932875270331,,,,0,0,0
1281529,Fast adaptation of deep neural network based on discriminant codes for speech recognition,2014,Shaofei Xue and Ossama Abdel-Hamid and Hui Jiang and Lirong Dai and Qingfeng Liu,22,"IEEE/ACM Transactions on Audio, Speech, and Language Processing",12,1713-1725,IEEE,,True,nfZNs5AAAAAJ:_FxGoFyzp5QC,144,,13305070730380882907,/scholar?cites=13305070730380882907,,,,0,0,0
1281530,Direct adaptation of hybrid DNN/HMM model for fast speaker adaptation in LVCSR based on speaker code,2014,Shaofei Xue and Ossama Abdel-Hamid and Hui Jiang and Lirong Dai,,,,6339-6343,IEEE,,True,nfZNs5AAAAAJ:WF5omc3nYNoC,70,,14535432726500471037,/scholar?cites=14535432726500471037,,,,0,0,0
1281531,Computer aided pronunciation learning system using speech recognition techniques,2006,Sherif Mahdy Abdou and Salah Eldeen Hamid and Mohsen Rashwan and Abdurrahman Samir and Ossama Abdel-Hamid and Mostafa Shahin and Waleed Nazih,,,,,,,True,nfZNs5AAAAAJ:u5HHmVD_uO8C,62,,8168380909079536996,/scholar?cites=8168380909079536996,,,,0,0,0
1281532,Rapid and effective speaker adaptation of convolutional neural network based models for speech recognition.,2013,Ossama Abdel-Hamid and Hui Jiang,,,,1248-1252,,,True,nfZNs5AAAAAJ:YsMSGLbcyi4C,58,,1226468660478601213,/scholar?cites=1226468660478601213,,,,0,0,0
1281533,Detecting the origin of text segments efficiently,2009,Ossama Abdel Hamid and Behshad Behzadi and Stefan Christoph and Monika Henzinger,,,,61-70,,,True,nfZNs5AAAAAJ:qjMakFHDy7sC,51,,3172742802573322220,/scholar?cites=3172742802573322220,,,,0,0,0
1281534,Deep segmental neural networks for speech recognition.,2013,Ossama Abdel-Hamid and Li Deng and Dong Yu and Hui Jiang,36,Interspeech,,70,,,True,nfZNs5AAAAAJ:Tyk-4Ss8FVUC,42,,13937263443448198895,/scholar?cites=13937263443448198895,,,,0,0,0
1281535,The Sorcerer II Global Ocean Sampling expedition: expanding the universe of protein families,2007,Shibu Yooseph and Granger Sutton and Douglas B Rusch and Aaron L Halpern and Shannon J Williamson and Karin Remington and Jonathan A Eisen and Karla B Heidelberg and Gerard Manning and Weizhong Li and Lukasz Jaroszewski and Piotr Cieplak and Christopher S Miller and Huiying Li and Susan T Mashiyama and Marcin P Joachimiak and Christopher Van Belle and John-Marc Chandonia and David A Soergel and Yufeng Zhai and Kannan Natarajan and Shaun Lee and Benjamin J Raphael and Vineet Bafna and Robert Friedman and Steven E Brenner and Adam Godzik and David Eisenberg and Jack E Dixon and Susan S Taylor and Robert L Strausberg and Marvin Frazier and J Craig Venter,5,,3,e16,Public Library of Science,,True,zSlIlYQAAAAJ:u5HHmVD_uO8C,926,,9046128461973334308,/scholar?cites=9046128461973334308,,,,0,0,0
1281536,Co-evolution of proteins with their interaction partners,2000,Chern-Sing Goh and Andrew A Bogan and Marcin Joachimiak and Dirk Walther and Fred E Cohen,299,Journal of molecular biology,2,283-293,Academic Press,,True,zSlIlYQAAAAJ:u-x6o8ySG0sC,522,,10113024506467477112,/scholar?cites=10113024506467477112,,,,0,0,0
1281537,Expression profiling of the schizont and trophozoite stages of Plasmodium falciparum with a long-oligonucleotide microarray,2003,Zbynek Bozdech and Jingchun Zhu and Marcin P Joachimiak and Fred E Cohen and Brian Pulliam and Joseph L DeRisi,4,Genome biology,2,1-15,BioMed Central,,True,zSlIlYQAAAAJ:d1gkVwhDpl0C,453,,1719001060953292451,/scholar?cites=1719001060953292451,,,,0,0,0
1281538,MicrobesOnline: an integrated portal for comparative and functional genomics,2010,Paramvir S Dehal and Marcin P Joachimiak and Morgan N Price and John T Bates and Jason K Baumohl and Dylan Chivian and Greg D Friedland and Katherine H Huang and Keith Keller and Pavel S Novichkov and Inna L Dubchak and Eric J Alm and Adam P Arkin,38,Nucleic acids research,suppl_1,D396-D400,Oxford University Press,,True,zSlIlYQAAAAJ:2osOgNQ5qMEC,445,,12915908747352673227,/scholar?cites=12915908747352673227,,,,0,0,0
1281539,KBase: the United States department of energy systems biology knowledgebase,2018,Adam P Arkin and Robert W Cottingham and Christopher S Henry and Nomi L Harris and Rick L Stevens and Sergei Maslov and Paramvir Dehal and Doreen Ware and Fernando Perez and Shane Canon and Michael W Sneddon and Matthew L Henderson and William J Riehl and Dan Murphy-Olson and Stephen Y Chan and Roy T Kamimura and Sunita Kumari and Meghan M Drake and Thomas S Brettin and Elizabeth M Glass and Dylan Chivian and Dan Gunter and David J Weston and Benjamin H Allen and Jason Baumohl and Aaron A Best and Ben Bowen and Steven E Brenner and Christopher C Bun and John-Marc Chandonia and Jer-Ming Chia and Ric Colasanti and Neal Conrad and James J Davis and Brian H Davison and Matthew DeJongh and Scott Devoid and Emily Dietrich and Inna Dubchak and Janaka N Edirisinghe and Gang Fang and José P Faria and Paul M Frybarger and Wolfgang Gerlach and Mark Gerstein and Annette Greiner and James Gurtowski and Holly L Haun and Fei He and Rashmi Jain and Marcin P Joachimiak and Kevin P Keegan and Shinnosuke Kondo and Vivek Kumar and Miriam L Land and Folker Meyer and Marissa Mills and Pavel S Novichkov and Taeyun Oh and Gary J Olsen and Robert Olson and Bruce Parrello and Shiran Pasternak and Erik Pearson and Sarah S Poon and Gavin A Price and Srividya Ramakrishnan and Priya Ranjan and Pamela C Ronald and Michael C Schatz and Samuel MD Seaver and Maulik Shukla and Roman A Sutormin and Mustafa H Syed and James Thomason and Nathan L Tintle and Daifeng Wang and Fangfang Xia and Hyunseung Yoo and Shinjae Yoo and Dantong Yu,36,Nature biotechnology,7,566-569,Nature Publishing Group,,True,zSlIlYQAAAAJ:vV6vV6tmYwMC,308,,194686999540813172,/scholar?cites=194686999540813172,,,,0,0,0
1281540,Cell-wide responses to low-oxygen exposure in Desulfovibrio vulgaris Hildenborough,2007,Aindrila Mukhopadhyay and Alyssa M Redding and Marcin P Joachimiak and Adam P Arkin and Sharon E Borglin and Paramvir S Dehal and Romy Chakraborty and Jil T Geller and Terry C Hazen and Qiang He and Dominique C Joyner and Vincent JJ Martin and Judy D Wall and Zamin Koo Yang and Jizhong Zhou and Jay D Keasling,189,Journal of bacteriology,16,5996-6010,American Society for Microbiology Journals,,True,zSlIlYQAAAAJ:9yKSN-GCB0IC,119,,12190576912155506679,/scholar?cites=12190576912155506679,,,,0,0,0
1281541,JColorGrid: software for the visualization of biological measurements,2006,Marcin P Joachimiak and Jennifer L Weisman and Barnaby CH May,7,BMC bioinformatics,1,1-5,BioMed Central,,True,zSlIlYQAAAAJ:qjMakFHDy7sC,106,,3694281160457572874,/scholar?cites=3694281160457572874,,,,0,0,0
1281542,Effects of genetic variation on the E. coli host-circuit interface,2013,Stefano Cardinale and Marcin Pawel Joachimiak and Adam Paul Arkin,4,,2,231-237,Cell Press,,True,zSlIlYQAAAAJ:qUcmZB5y_30C,80,,17335789907195308527,/scholar?cites=17335789907195308527,,,,0,0,0
1281543,Global transcriptional. physiological. and metabolite analyses of the responses of Desulfovibrio vulgaris Hildenborough to salt adaptation,2010,Zhili He and Aifen Zhou and Edward Baidoo and Qiang He and Marcin P Joachimiak and Peter Benke and Richard Phan and Aindrila Mukhopadhyay and Christopher L Hemme and Katherine Huang and Eric J Alm and Matthew W Fields and Judy Wall and David Stahl and Terry C Hazen and Jay D Keasling and Adam P Arkin and Jizhong Zhou,76,Applied and Environmental Microbiology,5,1574-1586,American Society for Microbiology,,True,zSlIlYQAAAAJ:WF5omc3nYNoC,63,,11894604415106329676,/scholar?cites=11894604415106329676,,,,0,0,0
1281544,Functional responses of methanogenic archaea to syntrophic growth,2012,Christopher B Walker and Alyssa M Redding-Johanson and Edward E Baidoo and Lara Rajeev and Zhili He and Erik L Hendrickson and Marcin P Joachimiak and Sergey Stolyar and Adam P Arkin and John A Leigh and Jizhong Zhou and Jay D Keasling and Aindrila Mukhopadhyay and David A Stahl,6,The ISME journal,11,2045-2055,Nature Publishing Group,,True,zSlIlYQAAAAJ:Wp0gIr-vW9MC,60,,16669243033719741237,/scholar?cites=16669243033719741237,,,,0,0,0
1281545,Response of Desulfovibrio vulgaris to alkaline stress,2007,Sergey Stolyar and Qiang He and Marcin P Joachimiak and Zhili He and Zamin Koo Yang and Sharon E Borglin and Dominique C Joyner and Katherine Huang and Eric Alm and Terry C Hazen and Jizhong Zhou and Judy D Wall and Adam P Arkin and David A Stahl,189,Journal of bacteriology,24,8944-8952,American Society for Microbiology Journals,,True,zSlIlYQAAAAJ:UeHWp8X0CEIC,57,,6503858067258153972,/scholar?cites=6503858067258153972,,,,0,0,0
1281546,Understanding convolution for semantic segmentation,2018,Panqu Wang and Pengfei Chen and Ye Yuan and Ding Liu and Zehua Huang and Xiaodi Hou and Garrison Cottrell,,,,1451-1460,IEEE,,True,PGtHUI0AAAAJ:Wp0gIr-vW9MC,772,,14464615562378306377,/scholar?cites=14464615562378306377,,,,0,0,0
1281547,Deep networks for image super-resolution with sparse prior,2015,Zhaowen Wang and Ding Liu and Jianchao Yang and Wei Han and Thomas Huang,,,,370-378,,,True,PGtHUI0AAAAJ:_FxGoFyzp5QC,665,,16776231602849831052,/scholar?cites=16776231602849831052,,,,0,0,0
1281548,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang and Bee Lim and Sanghyun Son and Heewon Kim and Seungjun Nah and Kyoung Mu Lee and Xintao Wang and Yapeng Tian and Ke Yu and Yulun Zhang and Shixiang Wu and Chao Dong and Liang Lin and Yu Qiao and Chen Change Loy and Woong Bae and Jaejun Yoo and Yoseob Han and Jong Chul Ye and Jae-Seok Choi and Munchurl Kim and Yuchen Fan and Jiahui Yu and Wei Han and Ding Liu and Haichao Yu and Zhangyang Wang and Honghui Shi and Xinchao Wang and Thomas S Huang and Yunjin Chen and Kai Zhang and Wangmeng Zuo and Zhimin Tang and Linkai Luo and Shaohui Li and Min Fu and Lei Cao and Wen Heng and Giang Bui and Truc Le and Ye Duan and Dacheng Tao and Ruxin Wang and Xu Lin and Jianxin Pang and Jinchang Xu and Yu Zhao and Xiangyu Xu and Jinshan Pan and Deqing Sun and Yujin Zhang and Xibin Song and Yuchao Dai and Xueying Qin and Xuan-Phung Huynh and Tiantong Guo and Hojjat Seyed Mousavi and Tiep Huu Vu and Vishal Monga and Cristovao Cruz and Karen Egiazarian and Vladimir Katkovnik and Rakesh Mehta and Arnav Kumar Jain and Abhinav Agarwalla and Ch V Sai Praveen and Ruofan Zhou and Hongdiao Wen and Che Zhu and Zhiqiang Xia and Zhengtao Wang and Qi Guo,,,,1110-1121,IEEE,,True,PGtHUI0AAAAJ:5nxA0vEk-isC,660,,7685867950273076567,/scholar?cites=7685867950273076567,,,,0,0,0
1281549,Non-local recurrent network for image restoration,2018,Ding Liu and Bihan Wen and Yuchen Fan and Chen Change Loy and Thomas S Huang,31,Advances in Neural Information Processing Systems,,1673-1682,,,True,PGtHUI0AAAAJ:M3ejUd6NZC8C,243,,17713021931965385894,/scholar?cites=17713021931965385894,,,,0,0,0
1281550,Robust Single Image Super-Resolution via Deep Networks With Sparse Prior,2016,Ding Liu and Zhaowen Wang and Bihan Wen and Jianchao Yang and Wei Han and Thomas S Huang,25,IEEE Transactions on Image Processing,7,3194-3207,IEEE,,True,PGtHUI0AAAAJ:Tyk-4Ss8FVUC,210,,10747816744170109801,/scholar?cites=10747816744170109801,,,,0,0,0
1281551,Studying very low resolution recognition using deep networks,2016,Zhangyang Wang and Shiyu Chang and Yingzhen Yang and Ding Liu and Thomas S Huang,,,,4792-4800,,,True,PGtHUI0AAAAJ:IjCSPb-OGe4C,175,,11512989278363956953,/scholar?cites=11512989278363956953,,,,0,0,0
1281552,D3: Deep dual-domain based fast restoration of JPEG-compressed images,2016,Zhangyang Wang and Ding Liu and Shiyu Chang and Qing Ling and Yingzhen Yang and Thomas S Huang,,,,2764-2772,,,True,PGtHUI0AAAAJ:Y0pCki6q_DkC,150,,5460802687666357032,/scholar?cites=5460802687666357032,,,,0,0,0
1281553,Robust video super-resolution with learned temporal dynamics,2017,Ding Liu and Zhaowen Wang and Yuchen Fan and Xianming Liu and Zhangyang Wang and Shiyu Chang and Thomas Huang,,,,2526-2534,IEEE,,True,PGtHUI0AAAAJ:MXK_kJrjxJIC,145,,548111155614556858,/scholar?cites=548111155614556858,,,,0,0,0
1281554,When image denoising meets high-level vision tasks: A deep learning approach,2017,Ding Liu and Bihan Wen and Xianming Liu and Zhangyang Wang and Thomas S Huang,,arXiv preprint arXiv:1706.04284,,,,,True,PGtHUI0AAAAJ:4DMP91E08xMC,120,,2324992229169057065,/scholar?cites=2324992229169057065,,,,0,0,0
1281555,Image super-resolution via dual-state recurrent networks,2018,Wei Han and Shiyu Chang and Ding Liu and Mo Yu and Michael Witbrock and Thomas S Huang,,,,1654-1663,,,True,PGtHUI0AAAAJ:4TOpqqG69KYC,116,,3474602784285914846,/scholar?cites=3474602784285914846,,,,0,0,0
1281556,Enlightengan: Deep light enhancement without paired supervision,2021,Yifan Jiang and Xinyu Gong and Ding Liu and Yu Cheng and Chen Fang and Xiaohui Shen and Jianchao Yang and Pan Zhou and Zhangyang Wang,30,IEEE Transactions on Image Processing,,2340-2349,IEEE,,True,PGtHUI0AAAAJ:hC7cP41nSMkC,107,,17465380415045488778,/scholar?cites=17465380415045488778,,,,0,0,0
1281557,High-quality binary protein interaction map of the yeast interactome network,2008,Haiyuan Yu and Pascal Braun and Muhammed A Yıldırım and Irma Lemmens and Kavitha Venkatesan and Julie Sahalie and Tomoko Hirozane-Kishikawa and Fana Gebreab and Na Li and Nicolas Simonis and Tong Hao and Jean-François Rual and Amélie Dricot and Alexei Vazquez and Ryan R Murray and Christophe Simon and Leah Tardivo and Stanley Tam and Nenad Svrzikapa and Changyu Fan and Anne-Sophie De Smet and Adriana Motyl and Michael E Hudson and Juyong Park and Xiaofeng Xin and Michael E Cusick and Troy Moore and Charlie Boone and Michael Snyder and Frederick P Roth and Albert-László Barabási and Jan Tavernier and David E Hill and Marc Vidal,322,Science,5898,104-110,American Association for the Advancement of Science,,True,rfOGWOkAAAAJ:u5HHmVD_uO8C,1486,,6718869669884464287,/scholar?cites=6718869669884464287,,,,0,0,0
1281558,First-in-humans trial of an RNA interference therapeutic targeting VEGF and KSP in cancer patients with liver involvement,2013,Josep Tabernero and Geoffrey I Shapiro and Patricia M LoRusso and Andres Cervantes and Gary K Schwartz and Glen J Weiss and Luis Paz-Ares and Daniel C Cho and Jeffrey R Infante and Maria Alsina and Mrinal M Gounder and Rick Falzone and Jamie Harrop and Amy C Seila White and Iva Toudjarska and David Bumcrot and Rachel E Meyers and Gregory Hinkle and Nenad Svrzikapa and Renta M Hutabarat and Valerie A Clausen and Jeffrey Cehelsky and Saraswathy V Nochur and Christina Gamba-Vitalo and Akshay K Vaishnaw and Dinah WY Sah and Jared A Gollob and Howard A Burris,3,Cancer discovery,4,406-417,American Association for Cancer Research,,True,rfOGWOkAAAAJ:Y0pCki6q_DkC,587,,18434304992885547417,/scholar?cites=18434304992885547417,,,,0,0,0
1281559,JNK regulates lifespan in Caenorhabditis elegans by modulating nuclear translocation of forkhead transcription factor/DAF-16,2005,Seung Wook Oh and Arnab Mukhopadhyay and Nenad Svrzikapa and Feng Jiang and Roger J Davis and Heidi A Tissenbaum,102,Proceedings of the National Academy of Sciences,12,4494-4499,National Academy of Sciences,,True,rfOGWOkAAAAJ:u-x6o8ySG0sC,526,,17172901934589343640,/scholar?cites=17172901934589343640,,,,0,0,0
1281560,Genome-scale analysis of in vivo spatiotemporal promoter activity in Caenorhabditis elegans,2007,Denis Dupuy and Nicolas Bertin and César A Hidalgo and Kavitha Venkatesan and Domena Tu and David Lee and Jennifer Rosenberg and Nenad Svrzikapa and Aurélie Blanc and Alain Carnec and Anne-Ruxandra Carvunis and Rock Pulak and Jane Shingles and John Reece-Hoyes and Rebecca Hunt-Newbury and Ryan Viveiros and William A Mohler and Murat Tasan and Frederick P Roth and Christian Le Peuch and Ian A Hope and Robert Johnsen and Donald G Moerman and Albert-László Barabási and David Baillie and Marc Vidal,25,Nature biotechnology,6,663-668,Nature Publishing Group,,True,rfOGWOkAAAAJ:d1gkVwhDpl0C,319,,8890520033829178579,/scholar?cites=8890520033829178579,,,,0,0,0
1281561,Next-generation sequencing to generate interactome datasets,2011,Haiyuan Yu and Leah Tardivo and Stanley Tam and Evan Weiner and Fana Gebreab and Changyu Fan and Nenad Svrzikapa and Tomoko Hirozane-Kishikawa and Edward Rietman and Xinping Yang and Julie Sahalie and Kourosh Salehi-Ashtiani and Tong Hao and Michael E Cusick and David E Hill and Frederick P Roth and Pascal Braun and Marc Vidal,8,Nature methods,6,478-480,Nature Publishing Group,,True,rfOGWOkAAAAJ:9yKSN-GCB0IC,248,,10184341713297419542,/scholar?cites=10184341713297419542,,,,0,0,0
1281562,Control of phosphorothioate stereochemistry substantially increases the efficacy of antisense oligonucleotides,2017,Naoki Iwamoto and David CD Butler and Nenad Svrzikapa and Susovan Mohapatra and Ivan Zlatev and Dinah WY Sah and Stephany M Standley and Genliang Lu and Luciano H Apponi and Maria Frank-Kamenetsky and Jason Jingxin Zhang and Chandra Vargeese and Gregory L Verdine,35,Nature biotechnology,9,845-851,Nature Publishing Group,,True,rfOGWOkAAAAJ:aqlVkmm33-oC,135,,190003122912459599,/scholar?cites=190003122912459599,,,,0,0,0
1281563,'Edgetic'perturbation of a C. elegans BCL2 ortholog,2009,Matija Dreze and Benoit Charloteaux and Stuart Milstein and Pierre-Olivier Vidalain and Muhammed A Yildirim and Quan Zhong and Nenad Svrzikapa and Viviana Romero and Géraldine Laloux and Robert Brasseur and Jean Vandenhaute and Mike Boxem and Michael E Cusick and David E Hill and Marc Vidal,6,Nature methods,11,843-849,Nature Publishing Group,,True,rfOGWOkAAAAJ:hqOjcs7Dif8C,76,,13703888120562096152,/scholar?cites=13703888120562096152,,,,0,0,0
1281564,'Edgetic'perturbation of a C. elegans BCL2 ortholog,2009,Matija Dreze and Benoit Charloteaux and Stuart Milstein and Pierre-Olivier Vidalain and Muhammed A Yildirim and Quan Zhong and Nenad Svrzikapa and Viviana Romero and Géraldine Laloux and Robert Brasseur and Jean Vandenhaute and Mike Boxem and Michael E Cusick and David E Hill and Marc Vidal,6,Nature methods,11,843-849,Nature Publishing Group,,True,rfOGWOkAAAAJ:2osOgNQ5qMEC,76,,13703888120562096152,/scholar?cites=13703888120562096152,,,,0,0,0
1281565,An antibiotic selection marker for nematode transgenesis,2010,Rosina Giordano-Santini and Stuart Milstein and Nenad Svrzikapa and Domena Tu and Robert Johnsen and David Baillie and Marc Vidal and Denis Dupuy,7,nature methods,9,721-723,Nature Publishing Group,,True,rfOGWOkAAAAJ:UeHWp8X0CEIC,61,,4779897591117459268,/scholar?cites=4779897591117459268,,,,0,0,0
1281566,In vivo quantification of formulated and chemically modified small interfering RNA by heating-in-Triton quantitative reverse transcription polymerase chain reaction (HIT qRT-PCR),2010,Yosef Landesman and Nenad Svrzikapa and Armand Cognetta and Xuemei Zhang and Brian R Bettencourt and Satya Kuchimanchi and Keri Dufault and Sarfraz Shaikh and Maple Gioia and Akin Akinc and Renta Hutabarat and Rachel Meyers,1,Silence,1,1-14,BioMed Central,,True,rfOGWOkAAAAJ:IjCSPb-OGe4C,47,,13723513325585828506,/scholar?cites=13723513325585828506,,,,0,0,0
1281567,First-in-humans trial of an RNA interference therapeutic targeting VEGF and KSP in cancer patients with liver involvement. Cancer Discov. 2013; 3: 406–417. doi: 10.1158/2159-8290,2008,J Tabernero and GI Shapiro and PM LoRusso and A Cervantes and GK Schwartz and GJ Weiss and L Paz-Ares and DC Cho and JR Infante and M Alsina and MM Gounder and R Falzone and J Harrop and A White and I Toudjarska and D Bumcrot and R Meyers and G Hinkle and N Svrzikapa and R Hutabarat and V Clausen and J Cehelsky and S Nochur and C Gamba-Vitalo and A Vaishnaw and D Sah and J Gollob and H Burris,26,Nat Biotechnol,4,431-42,,,True,rfOGWOkAAAAJ:iH-uZ7U-co4C,47,,17467213385265073955,/scholar?cites=17467213385265073955,,,,0,0,0
1281568,Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models,2017,Pin-Yu Chen* and Huan Zhang* and Yash Sharma and Jinfeng Yi and Cho-Jui Hsieh,,,,15-26,,,True,LTa3GzEAAAAJ:UeHWp8X0CEIC,658,,9543108161118261540,/scholar?cites=9543108161118261540,,,,0,0,0
1281569,Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent,2017,Xiangru Lian and Ce Zhang and Huan Zhang and Cho-Jui Hsieh and Wei Zhang and Ji Liu,,,,5330-5340,,,True,LTa3GzEAAAAJ:W7OEmFMy1HYC,377,,18334580252706636011,/scholar?cites=18334580252706636011,,,,0,0,0
1281570,Ead: elastic-net attacks to deep neural networks via adversarial examples,2018,Pin-Yu Chen and Yash Sharma and Huan Zhang and Jinfeng Yi and Cho-Jui Hsieh,32,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,,True,LTa3GzEAAAAJ:IjCSPb-OGe4C,325,,12822881129295839300,/scholar?cites=12822881129295839300,,,,0,0,0
1281571,Towards fast computation of certified robustness for relu networks,2018,Lily Weng* and Huan Zhang* and Hongge Chen and Zhao Song and Cho-Jui Hsieh and Luca Daniel and Duane Boning and Inderjit Dhillon,,,,5276-5285,PMLR,,True,LTa3GzEAAAAJ:LkGwnXOMwfcC,290,,13154362274812885800,/scholar?cites=13154362274812885800,,,,0,0,0
1281572,Efficient neural network robustness certification with general activation functions,2018,Huan Zhang* and Tsui-Wei Weng* and Pin-Yu Chen and Cho-Jui Hsieh and Luca Daniel,,,,4939-4948,,,True,LTa3GzEAAAAJ:5nxA0vEk-isC,225,,6606953928208344058,/scholar?cites=6606953928208344058,,,,0,0,0
1281573,Spectral and spatial 2D fragmentation-aware routing and spectrum assignment algorithms in elastic optical networks,2013,Yawei Yin and Huan Zhang and Mingyang Zhang and Ming Xia and Zuqing Zhu and Stefan Dahlfort and SJ Ben Yoo,5,IEEE/OSA Journal of Optical Communications and Networking,10,A100-A106,IEEE,,True,LTa3GzEAAAAJ:YsMSGLbcyi4C,206,,13760639897720587659,/scholar?cites=13760639897720587659,,,,0,0,0
1281574,Towards robust neural networks via random self-ensemble,2018,Xuanqing Liu and Minhao Cheng and Huan Zhang and Cho-Jui Hsieh,,,,369-385,,,True,LTa3GzEAAAAJ:eQOLeE2rZwMC,183,,18255130367494828002,/scholar?cites=18255130367494828002,,,,0,0,0
1281575,Evaluating the robustness of neural networks: An extreme value theory approach,2018,Tsui-Wei Weng* and Huan Zhang* and Pin-Yu Chen and Jinfeng Yi and Dong Su and Yupeng Gao and Cho-Jui Hsieh and Luca Daniel,,(*Equal Contribution) arXiv preprint arXiv:1801.10578,,,,,True,LTa3GzEAAAAJ:ufrVoPGSRksC,176,,2078120094241692942,/scholar?cites=2078120094241692942,,,,0,0,0
1281576,Is Robustness the Cost of Accuracy?--A Comprehensive Study on the Robustness of 18 Deep Image Classification Models,2018,Dong Su* and Huan Zhang* and Hongge Chen and Jinfeng Yi and Pin-Yu Chen and Yupeng Gao,,,,631-648,,,True,LTa3GzEAAAAJ:hqOjcs7Dif8C,165,,380810929013428531,/scholar?cites=380810929013428531,,,,0,0,0
1281577,Provably robust deep learning via adversarially trained smoothed classifiers,2019,Hadi Salman and Jerry Li and Ilya Razenshteyn and Pengchuan Zhang and Huan Zhang and Sebastien Bubeck and Greg Yang,,,,11292-11303,,,True,LTa3GzEAAAAJ:qxL8FJ1GzNcC,151,,9920393851690535434,/scholar?cites=9920393851690535434,,,,0,0,0
1281578,Query-efficient hard-label black-box attack: An optimization-based approach,2018,Minhao Cheng and Thong Le and Pin-Yu Chen and Jinfeng Yi and Huan Zhang and Cho-Jui Hsieh,,International Conference on Learning Representations (ICLR) 2019,,,,,True,LTa3GzEAAAAJ:Se3iqnhoufwC,146,,5116459169179417425,/scholar?cites=5116459169179417425,,,,0,0,0
1281579,Ensemble of Exemplar-SVMs for Object Detection and Beyond,2011,Tomasz Malisiewicz and Abhinav Gupta and Alexei A. Efros,,International Conference of Computer Vision (ICCV),,,,,True,RCTeTV0AAAAJ:IjCSPb-OGe4C,970,,12924479804389189802,/scholar?cites=12924479804389189802,,,,0,0,0
1281580,Superpoint: Self-supervised interest point detection and description,2018,Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich,,,,224-236,,,True,RCTeTV0AAAAJ:EkHepimYqZsC,396,,4947327642964317263,/scholar?cites=4947327642964317263,,,,0,0,0
1281581,Undoing the Damage of Dataset Bias,2012,Aditya Khosla and Tinghui Zhou and Tomasz Malisiewicz and Alexei A Efros and Antonio Torralba,,,,,,,True,RCTeTV0AAAAJ:W7OEmFMy1HYC,374,,2174836068449396440,/scholar?cites=2174836068449396440,,,,0,0,0
1281582,Improving spatial support for objects via multiple segmentations,2007,Tomasz Malisiewicz and Alexei A Efros,,,,,,,True,RCTeTV0AAAAJ:u5HHmVD_uO8C,345,,15713966619590596027,/scholar?cites=15713966619590596027,,,,0,0,0
1281583,Hoggles: Visualizing object detection features,2013,Carl Vondrick and Aditya Khosla and Tomasz Malisiewicz and Antonio Torralba,,,,1-8,,,True,RCTeTV0AAAAJ:_FxGoFyzp5QC,327,,10724519462746617784,/scholar?cites=10724519462746617784,,,,0,0,0
1281584,Data-driven Visual Similarity for Cross-domain Image Matching,2011,Abhinav Shrivastava and Tomasz Malisiewicz and Abhinav Gupta and Alexei A. Efros,,ACM Transaction of Graphics (TOG) (Proceedings of ACM SIGGRAPH ASIA),,,,,True,RCTeTV0AAAAJ:zYLM7Y9cAGgC,286,,12079073413768576951,/scholar?cites=12079073413768576951,,,,0,0,0
1281585,Deep image homography estimation,2016,Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich,,arXiv preprint arXiv:1606.03798,,,,,True,RCTeTV0AAAAJ:t7zJ5fGR-2UC,217,,1429198938882725117,/scholar?cites=1429198938882725117,,,,0,0,0
1281586,Recognition by association via learning per-exemplar distances,2008,Tomasz Malisiewicz and Alexei A Efros,,,,1-8,IEEE,,True,RCTeTV0AAAAJ:u-x6o8ySG0sC,203,,361232278861575617,/scholar?cites=361232278861575617,,,,0,0,0
1281587,Beyond categories: The visual memex model for reasoning about object relationships,2009,Tomasz Malisiewicz and Alexei A Efros,,Neural Inf. Proc. Systems (NIPS),,,,,True,RCTeTV0AAAAJ:d1gkVwhDpl0C,154,,4620933639941276086,/scholar?cites=4620933639941276086,,,,0,0,0
1281588,Superglue: Learning feature matching with graph neural networks,2020,Paul-Edouard Sarlin and Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich,,,,4938-4947,,,True,RCTeTV0AAAAJ:L7CI7m0gUJcC,107,,15521088276096645515,/scholar?cites=15521088276096645515,,,,0,0,0
1281589,Roomnet: End-to-end room layout estimation,2017,Chen-Yu Lee and Vijay Badrinarayanan and Tomasz Malisiewicz and Andrew Rabinovich,,,,4865-4874,,,True,RCTeTV0AAAAJ:9Nmd_mFXekcC,103,,13482194693502910624,/scholar?cites=13482194693502910624,,,,0,0,0
1281590,B1 mapping by Bloch‐Siegert shift,2010,Laura I Sacolick and Florian Wiesinger and Ileana Hancu and Mika W Vogel,63,Magnetic resonance in medicine,5,1315-1322,Wiley Subscription Services. Inc.. A Wiley Company,,True,D-5WGeQAAAAJ:2osOgNQ5qMEC,511,,8214567440480989274,/scholar?cites=8214567440480989274,,,,0,0,0
1281591,Transmit and receive transmission line arrays for 7 Tesla parallel imaging,2005,Gregor Adriany and Pierre‐Francois Van de Moortele and Florian Wiesinger and Steen Moeller and John P Strupp and Peter Andersen and Carl Snyder and Xiaoliang Zhang and Wei Chen and Klaas P Pruessmann and Peter Boesiger and Tommy Vaughan and Kāmil Uğurbil,53,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,2,434-445,Wiley Subscription Services. Inc.. A Wiley Company,,True,D-5WGeQAAAAJ:u5HHmVD_uO8C,441,,173230707065493198,/scholar?cites=173230707065493198,,,,0,0,0
1281592,Electrodynamics and ultimate SNR in parallel MR imaging,2004,Florian Wiesinger and Peter Boesiger and Klaas P Pruessmann,52,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,2,376-390,Wiley Subscription Services. Inc.. A Wiley Company,,True,D-5WGeQAAAAJ:u-x6o8ySG0sC,279,,15827146904534648370,/scholar?cites=15827146904534648370,,,,0,0,0
1281593,Parallel imaging performance as a function of field strength—an experimental investigation using electrodynamic scaling,2004,Florian Wiesinger and Pierre‐Francois Van de Moortele and Gregor Adriany and Nicola De Zanche and Kamil Ugurbil and Klaas P Pruessmann,52,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,5,953-964,Wiley Subscription Services. Inc.. A Wiley Company,,True,D-5WGeQAAAAJ:d1gkVwhDpl0C,198,,16201276415932265919,/scholar?cites=16201276415932265919,,,,0,0,0
1281594,Zero TE MR bone imaging in the head,2016,Florian Wiesinger and Laura I Sacolick and Anne Menini and Sandeep S Kaushik and Sangtae Ahn and Patrick Veit‐Haibach and Gaspar Delso and Dattesh D Shanbhag,75,Magnetic resonance in medicine,1,107-114,,,True,D-5WGeQAAAAJ:GtqhT-R7ZnwC,176,,2398169408998182877,/scholar?cites=2398169408998182877,,,,0,0,0
1281595,IDEAL spiral CSI for dynamic metabolic MR imaging of hyperpolarized [1‐13C]pyruvate,2012,Florian Wiesinger and Eliane Weidl and Marion I Menzel and Martin A Janich and Oleksandr Khegai and Steffen J Glaser and Axel Haase and Markus Schwaiger and Rolf F Schulte,68,Magnetic resonance in medicine,1,8-16,Wiley Subscription Services. Inc.. A Wiley Company,,True,D-5WGeQAAAAJ:5nxA0vEk-isC,163,,1446754062535925871,/scholar?cites=1446754062535925871,,,,0,0,0
1281596,Potential and feasibility of parallel MRI at high field,2006,Florian Wiesinger and Pierre‐Francois Van de Moortele and Gregor Adriany and Nicola De Zanche and Kamil Ugurbil and Klaas P Pruessmann,19,,3,368-378,John Wiley & Sons. Ltd.,,True,D-5WGeQAAAAJ:9yKSN-GCB0IC,132,,10149950318360258973,/scholar?cites=10149950318360258973,,,,0,0,0
1281597,PET–MR imaging using a tri-modality PET/CT–MR system with a dedicated shuttle in clinical routine,2013,Patrick Veit-Haibach and Felix Pierre Kuhn and Florian Wiesinger and Gaspar Delso and Gustav von Schulthess,26,,1,25-35,Springer-Verlag,,True,D-5WGeQAAAAJ:ZeXyd9-uunAC,115,,1243209370111163204,/scholar?cites=1243209370111163204,,,,0,0,0
1281598,Clinical evaluation of zero-echo-time MR imaging for the segmentation of the skull,2015,Gaspar Delso and Florian Wiesinger and Laura I Sacolick and Sandeep S Kaushik and Dattesh D Shanbhag and Martin Hüllner and Patrick Veit-Haibach,56,Journal of Nuclear Medicine,3,417-422,Society of Nuclear Medicine,,True,D-5WGeQAAAAJ:DGzKIA18-3YC,107,,10614018018244944414,/scholar?cites=10614018018244944414,,,,0,0,0
1281599,Zero-echo-time and Dixon deep pseudo-CT (ZeDD CT): direct generation of pseudo-CT images for pelvic PET/MRI attenuation correction using deep convolutional neural networks with …,2018,Andrew P Leynes and Jaewon Yang and Florian Wiesinger and Sandeep S Kaushik and Dattesh D Shanbhag and Youngho Seo and Thomas A Hope and Peder EZ Larson,59,Journal of Nuclear Medicine,5,852-858,Society of Nuclear Medicine,,True,D-5WGeQAAAAJ:qCaWouos7ogC,90,,18133753493746499295,/scholar?cites=18133753493746499295,,,,0,0,0
1281600,Comparison of 4-class and continuous fat/water methods for whole-body. MR-based PET attenuation correction,2013,SD Wollenweber and S Ambwani and AHR Lonn and DD Shanbhag and S Thiruvenkadam and S Kaushik and R Mullick and H Qian and G Delso and F Wiesinger,60,IEEE Transactions on Nuclear Science,5,3391-3398,IEEE,,True,D-5WGeQAAAAJ:blknAaTinKkC,89,,12556626327886194462,/scholar?cites=12556626327886194462,,,,0,0,0
1281601,GeOpps: Geographical opportunistic routing for vehicular networks,2007,Ilias Leontiadis and Cecilia Mascolo,,,,1-6,Ieee,,True,HAOtV_AAAAAJ:u-x6o8ySG0sC,452,,12269808153435138757,/scholar?cites=12269808153435138757,,,,0,0,0
1281602,"The cost of the"" s"" in https",2014,David Naylor and Alessandro Finamore and Ilias Leontiadis and Yan Grunenberger and Marco Mellia and Maurizio Munafò and Konstantina Papagiannaki and Peter Steenkiste,,,,133-140,,,True,HAOtV_AAAAAJ:-f6ydRqryjwC,218,,14731607435200017247,/scholar?cites=14731607435200017247,,,,0,0,0
1281603,On the effectiveness of an opportunistic traffic management system for vehicular networks,2011,Ilias Leontiadis and Gustavo Marfia and David Mack and Giovanni Pau and Cecilia Mascolo and Mario Gerla,12,IEEE Transactions on Intelligent Transportation Systems,4,1537-1548,IEEE,,True,HAOtV_AAAAAJ:zYLM7Y9cAGgC,203,,17454586298641438070,/scholar?cites=17454586298641438070,,,,0,0,0
1281604,Don't kill my ads! balancing privacy in an ad-supported mobile application market,2012,Ilias Leontiadis and Christos Efstratiou and Marco Picone and Cecilia Mascolo,,,,1-6,,,True,HAOtV_AAAAAJ:5nxA0vEk-isC,201,,10717990633236554499,/scholar?cites=10717990633236554499,,,,0,0,0
1281605,ClouDedup: secure deduplication with encrypted data for cloud storage,2013,Pasquale Puzio and Refik Molva and Melek Önen and Sergio Loureiro,1,,,363-370,IEEE,,True,HAOtV_AAAAAJ:L8Ckcad2t8MC,190,,6016861858889709947,/scholar?cites=6016861858889709947,,,,0,0,0
1281606,Large scale crowdsourcing and characterization of twitter abusive behavior,2018,Antigoni Founta and Constantinos Djouvas and Despoina Chatzakou and Ilias Leontiadis and Jeremy Blackburn and Gianluca Stringhini and Athena Vakali and Michael Sirivianos and Nicolas Kourtellis,12,Proceedings of the International AAAI Conference on Web and Social Media,1,,,,True,HAOtV_AAAAAJ:ZHo1McVdvXMC,177,,13572369194635253793,/scholar?cites=13572369194635253793,,,,0,0,0
1281607,Kek. cucks. and god emperor trump: A measurement study of 4chan’s politically incorrect forum and its effects on the web,2017,Gabriel Hine and Jeremiah Onaolapo and Emiliano De Cristofaro and Nicolas Kourtellis and Ilias Leontiadis and Riginos Samaras and Gianluca Stringhini and Jeremy Blackburn,11,Proceedings of the International AAAI Conference on Web and Social Media,1,,,,True,HAOtV_AAAAAJ:blknAaTinKkC,177,,9972774043750549355,/scholar?cites=9972774043750549355,,,,0,0,0
1281608,Multi-context tls (mctls) enabling secure in-network functionality in tls,2015,David Naylor and Kyle Schomp and Matteo Varvello and Ilias Leontiadis and Jeremy Blackburn and Diego R López and Konstantina Papagiannaki and Pablo Rodriguez Rodriguez and Peter Steenkiste,45,ACM SIGCOMM Computer Communication Review,4,199-212,ACM,,True,HAOtV_AAAAAJ:_Qo2XoVZTnwC,144,,11782923566431646727,/scholar?cites=11782923566431646727,,,,0,0,0
1281609,Opportunistic spatio-temporal dissemination system for vehicular networks,2007,Ilias Leontiadis and Cecilia Mascolo,,,,39-46,,,True,HAOtV_AAAAAJ:u5HHmVD_uO8C,140,,1011326455841048789,/scholar?cites=1011326455841048789,,,,0,0,0
1281610,SenShare: transforming sensor networks into multi-application sensing infrastructures,2012,Ilias Leontiadis and Christos Efstratiou and Cecilia Mascolo and Jon Crowcroft,,,,65-81,Springer. Berlin. Heidelberg,,True,HAOtV_AAAAAJ:0EnyYjriUFMC,137,,17139999223256884711,/scholar?cites=17139999223256884711,,,,0,0,0
1281611,The web centipede: understanding how web communities influence each other through the lens of mainstream and alternative news sources,2017,Savvas Zannettou and Tristan Caulfield and Emiliano De Cristofaro and Nicolas Kourtelris and Ilias Leontiadis and Michael Sirivianos and Gianluca Stringhini and Jeremy Blackburn,,,,405-417,,,True,HAOtV_AAAAAJ:lSLTfruPkqcC,115,,16329990683342566006,/scholar?cites=16329990683342566006,,,,0,0,0
1281612,The indexable web is more than 11.5 billion pages,2005,Antonio Gulli and Alessio Signorini,,,,902-903,,,True,wfiEFPQAAAAJ:9ZlFYXVOiuMC,800,,16531523336289286202,/scholar?cites=16531523336289286202,,,,0,0,0
1281613,Deep Learning with Keras,2017,Antonio Gulli and Sujit Pal,,,,,Packt Publishing Ltd,,True,wfiEFPQAAAAJ:Zph67rFs4hoC,768,,11448874898499818358,/scholar?cites=11448874898499818358,,,,0,0,0
1281614,A personalized search engine based on Web‐snippet hierarchical clustering,2008,Paolo Ferragina and Antonio Gulli,38,Software: Practice and Experience,2,189-225,John Wiley & Sons. Ltd.,,True,wfiEFPQAAAAJ:0EnyYjriUFMC,416,,8806933861391530365,/scholar?cites=8806933861391530365,,,,0,0,0
1281615,Automatic Web page categorization by link and context analysis,1999,Giuseppe Attardi and Antonio Gullì and Fabrizio Sebastiani,99,Proceedings of THAI,99,105-119,,,True,wfiEFPQAAAAJ:L8Ckcad2t8MC,228,,17178223116648721463,/scholar?cites=17178223116648721463,,,,0,0,0
1281616,Ranking a stream of news,2005,Gianna M Del Corso and Antonio Gulli and Francesco Romani,,,,97-106,,,True,wfiEFPQAAAAJ:d1gkVwhDpl0C,211,,1073329092229563069,/scholar?cites=1073329092229563069,,,,0,0,0
1281617,Similarity detection and clustering of images,2010,Antonio Savona and Tao Yang and Xin Liu and Beitao Li and Ankur Choksi and Filippo Tanganelli and Luigi Carnevale,,,,,,,True,wfiEFPQAAAAJ:mB3voiENLucC,207,,10592512569770965777,/scholar?cites=10592512569770965777,,,,0,0,0
1281618,Storyline visualization,2013,Antonino Gulli and Antonio Savona and Giovanni Deretta and Daniel Bernhardt,,,,,,,True,wfiEFPQAAAAJ:8k81kl-MbHgC,173,,9745621072980432315,/scholar?cites=9745621072980432315,,,,0,0,0
1281619,Method and system to present video content,2010,Antonino Gulli and Antonio Savona and Mario Veri,,,,,,,True,wfiEFPQAAAAJ:eQOLeE2rZwMC,117,,5018765452967211610,/scholar?cites=5018765452967211610,,,,0,0,0
1281620,Sampling internet user traffic to improve search results,2011,Antonino Gulli and Antonio Savona and Monica Mori,,,,,,,True,wfiEFPQAAAAJ:WF5omc3nYNoC,93,,6120048299426646090,/scholar?cites=6120048299426646090,,,,0,0,0
1281621,System and method for monitoring evolution over time of temporal content,2007,Antonino Gulli and Filippo Tanganelli and Antonio Savona,,,,,,,True,wfiEFPQAAAAJ:5nxA0vEk-isC,86,,9043996990847080021,/scholar?cites=9043996990847080021,,,,0,0,0
1281622,Fast PageRank computation via a sparse linear system,2005,Gianna M Del Corso and Antonio Gulli and Francesco Romani,2,Internet Mathematics,3,251-273,AK Peters,,True,wfiEFPQAAAAJ:aqlVkmm33-oC,85,,14620023059827928314,/scholar?cites=14620023059827928314,,,,0,0,0
1281623,Traffic flow prediction with big data: a deep learning approach,2015,Yisheng Lv and Yanjie Duan and Wenwen Kang and Zhengxi Li and Fei-Yue Wang,16,IEEE Transactions on Intelligent Transportation Systems,2,865-873,IEEE,,True,RRKqjKAAAAAJ:L8Ckcad2t8MC,2046,,2368017218408906128,/scholar?cites=2368017218408906128,,,,0,0,0
1281624,Traffic signal timing via deep reinforcement learning,2016,Li Li and Yisheng Lv and Fei-Yue Wang,3,IEEE/CAA Journal of Automatica Sinica,3,247-254,IEEE,,True,RRKqjKAAAAAJ:RHpTSmoSYBkC,303,,2988786463751444070,/scholar?cites=2988786463751444070,,,,0,0,0
1281625,Travel time prediction with LSTM neural network,2016,Yanjie Duan and LV Yisheng and Fei-Yue Wang,,,,1053-1058,IEEE,,True,RRKqjKAAAAAJ:TQgYirikUcIC,188,,14584885585914788053,/scholar?cites=14584885585914788053,,,,0,0,0
1281626,An efficient realization of deep learning for traffic data imputation,2016,Yanjie Duan and Yisheng Lv and Yu-Liang Liu and Fei-Yue Wang,72,Transportation research part C: emerging technologies,,168-181,Pergamon,,True,RRKqjKAAAAAJ:R3hNpaxXUhUC,157,,18241005936995701714,/scholar?cites=18241005936995701714,,,,0,0,0
1281627,Long short-term memory model for traffic congestion prediction with online open data,2016,Yuan-yuan Chen and Yisheng Lv and Zhenjiang Li and Fei-Yue Wang,,,,132-137,IEEE,,True,RRKqjKAAAAAJ:e5wmG9Sq2KIC,88,,2350815823576527761,/scholar?cites=2350815823576527761,,,,0,0,0
1281628,Social media based transportation research: The state of the work and the networking,2017,Yisheng Lv and Yuanyuan Chen and Xiqiao Zhang and Yanjie Duan and Naiqiang Li Li,4,,1,19-26,IEEE,,True,RRKqjKAAAAAJ:mB3voiENLucC,84,,3271761581954372738,/scholar?cites=3271761581954372738,,,,0,0,0
1281629,Autonomous vehicles testing methods review,2016,WuLing Huang and Kunfeng Wang and Yisheng Lv and FengHua Zhu,,,,163-168,IEEE,,True,RRKqjKAAAAAJ:isC4tDSrTZIC,79,,17468191879023415059,/scholar?cites=17468191879023415059,,,,0,0,0
1281630,Short-term traffic flow prediction with LSTM recurrent neural network,2017,Danqing Kang and Yisheng Lv and Yuan-yuan Chen,,,,1-6,IEEE,,True,RRKqjKAAAAAJ:iH-uZ7U-co4C,70,,10992579500825629567,/scholar?cites=10992579500825629567,,,,0,0,0
1281631,深度学习在控制领域的研究现状与展望,2016,段艳杰， 吕宜生， 张杰， 赵学亮， 王飞跃,42,自动化学报,5,643-654,,,True,RRKqjKAAAAAJ:NaGl4SEjCO4C,69,,1718091210133286468,/scholar?cites=1718091210133286468,,,,0,0,0
1281632,Cyber-physical-social systems: The state of the art and perspectives,2018,Jun Jason Zhang and Fei-Yue Wang and Xiao Wang and Gang Xiong and Fenghua Zhu and Yisheng Lv and Jiachen Hou and Shuangshuang Han and Yong Yuan and Qingchun Lu and Yishi Lee,5,,3,829-840,IEEE,,True,RRKqjKAAAAAJ:BqipwSGYUEgC,64,,7602045303333142747,/scholar?cites=7602045303333142747,,,,0,0,0
1281633,A game-engine-based platform for modeling and computing artificial transportation systems,2011,Qinghai Miao and Fenghua Zhu and Yisheng Lv and Changjian Cheng and Cheng Chen and Xiaogang Qiu,12,IEEE Transactions on Intelligent Transportation Systems,2,343-353,IEEE,,True,RRKqjKAAAAAJ:zYLM7Y9cAGgC,54,,17871235881107488469,/scholar?cites=17871235881107488469,,,,0,0,0
1281634,Recurrent marked temporal point processes: Embedding event history to vector,2016,Nan Du and Hanjun Dai and Rakshit Trivedi and Utkarsh Upadhyay and Manuel Gomez-Rodriguez and Le Song,,,,1555-1564,,,True,v474hP4AAAAJ:HoB7MX3m0LUC,341,,3103707433170867086,/scholar?cites=3103707433170867086,,,,0,0,0
1281635,Scalable influence estimation in continuous-time diffusion networks,2013,Nan Du and Le Song and Manuel Gomez-Rodriguez and Hongyuan Zha,26,Advances in neural information processing systems,,3147,NIH Public Access,,True,v474hP4AAAAJ:QIV2ME_5wuYC,288,,13367146681353749385,/scholar?cites=13367146681353749385,,,,0,0,0
1281636,Community detection in large-scale social networks,2007,Nan Du and Bin Wu and Xin Pei and Bai Wang and Liutong Xu,,,,16-25,,,True,v474hP4AAAAJ:Wp0gIr-vW9MC,279,,935110639063220996,/scholar?cites=935110639063220996,,,,0,0,0
1281637,Influence estimation and maximization in continuous-time diffusion networks,2016,Manuel Gomez-Rodriguez and Le Song and Nan Du and Hongyuan Zha and Bernhard Schölkopf,34,ACM Transactions on Information Systems (TOIS),2,1-33,ACM,,True,v474hP4AAAAJ:2P1L_qKh6hAC,249,,10015264296941634215,/scholar?cites=10015264296941634215,,,,0,0,0
1281638,Learning networks of heterogeneous influence,2012,Nan Du and Le Song and Ming Yuan and Alex Smola,25,Advances in neural information processing systems,,2780-2788,,,True,v474hP4AAAAJ:dhFuZR0502QC,157,,7974641597750725498,/scholar?cites=7974641597750725498,,,,0,0,0
1281639,Shaping social activity by incentivizing users,2014,Mehrdad Farajtabar and Nan Du and Manuel Gomez Rodriguez and Isabel Valera and Hongyuan Zha and Le Song,27,Advances in neural information processing systems,,,NIH Public Access,,True,v474hP4AAAAJ:R3hNpaxXUhUC,150,,12448910949720598106,/scholar?cites=12448910949720598106,,,,0,0,0
1281640,AnatomyNet: Deep learning for fast and fully automated whole‐volume segmentation of head and neck anatomy,2019,Wentao Zhu and Yufang Huang and Liang Zeng and Xuming Chen and Yong Liu and Zhen Qian and Nan Du and Wei Fan and Xiaohui Xie,46,Medical physics,2,576-589,,,True,v474hP4AAAAJ:AXPGKjj_ei8C,146,,4286591292215863929,/scholar?cites=4286591292215863929,,,,0,0,0
1281641,Dirichlet-hawkes processes with applications to clustering continuous-time document streams,2015,Nan Du and Mehrdad Farajtabar and Amr Ahmed and Alexander J Smola and Le Song,,,,219-228,,,True,v474hP4AAAAJ:iH-uZ7U-co4C,141,,9221799675692808736,/scholar?cites=9221799675692808736,,,,0,0,0
1281642,Improved recommendation based on collaborative tagging behaviors,2008,Shiwan Zhao and Nan Du and Andreas Nauerz and Xiatian Zhang and Quan Yuan and Rongyao Fu,,,,413-416,,,True,v474hP4AAAAJ:mVmsd5A6BfQC,141,,8315757889911962361,/scholar?cites=8315757889911962361,,,,0,0,0
1281643,A deep learning approach to link prediction in dynamic networks,2014,Xiaoyi Li and Nan Du and Hui Li and Kang Li and Jing Gao and Aidong Zhang,,,,289-297,Society for Industrial and Applied Mathematics,,True,v474hP4AAAAJ:RYcK_YlVTxYC,119,,12970386912591699750,/scholar?cites=12970386912591699750,,,,0,0,0
1281644,Time-Sensitive Recommendation From Recurrent User Activities.,2015,Nan Du and Yichen Wang and Niao He and Jimeng Sun and Le Song,15,NIPS,,3492-3500,,,True,v474hP4AAAAJ:YFjsv_pBGBYC,118,,13893927327441983990,/scholar?cites=13893927327441983990,,,,0,0,0
1281645,Gliomas: Histogram Analysis of Apparent Diffusion Coefficient Maps with Standard- or High-b-Value Diffusion-weighted MR Imaging—Correlation with Tumor Grade,2011,Yusuhn Kang and Seung Hong Choi and Young-Jae Kim and Kwang Gi Kim and Chul-Ho Sohn and Ji-Hoon Kim and Tae Jin Yun and Kee-Hyun Chang,261,Radiology,3,882-890,Radiological Society of North America. Inc.,,True,ZDM67bsAAAAJ:D_sINldO8mEC,296,,10050393001958322630,/scholar?cites=10050393001958322630,,,,0,0,0
1281646,Computerized texture analysis of persistent part-solid ground-glass nodules: differentiation of preinvasive lesions from invasive pulmonary adenocarcinomas,2014,Hee-Dong Chae and Chang Min Park and Sang Joon Park and Sang Min Lee and Kwang Gi Kim and Jin Mo Goo,273,Radiology,1,285-293,Radiological Society of North America,,True,ZDM67bsAAAAJ:pqnbT2bcN3wC,185,,3934324031506033400,/scholar?cites=3934324031506033400,,,,0,0,0
1281647,Pulmonary Nodules: Automated Detection on CT Images with Morphologic Matching Algorithm—Preliminary Results1,2005,Kyongtae T Bae and Jin-Sung Kim and Yong-Hum Na and Kwang Gi Kim and Jin-Hwan Kim,236,Radiology,1,286-293,Radiological Society of North America,,True,ZDM67bsAAAAJ:sSrBHYA8nusC,168,,9508087865992888774,/scholar?cites=9508087865992888774,,,,0,0,0
1281648,Predictive CT findings of malignancy in ground-glass nodules on thin-section chest CT: the effects on radiologist performance,2009,Hyun Ju Lee and Jin Mo Goo and Chang Hyun Lee and Chang Min Park and Kwang Gi Kim and Eun-Ah Park and Ho Yun Lee,19,European radiology,3,552-560,Springer-Verlag,,True,ZDM67bsAAAAJ:2KloaMYe4IUC,129,,15871408116432346603,/scholar?cites=15871408116432346603,,,,0,0,0
1281649,Transient Part-Solid Nodules Detected at Screening Thin-Section CT for Lung Cancer: Comparison with Persistent Part-Solid Nodules,2010,Sang Min Lee and Chang Min Park and Jin Mo Goo and Chang Hyun Lee and Hyun Ju Lee and Kwang Gi Kim and Mi-Jin Kang and In Sun Lee,255,Radiology,1,242-251,Radiological Society of North America. Inc.,,True,ZDM67bsAAAAJ:AvfA0Oy_GE0C,116,,17895635861163653190,/scholar?cites=17895635861163653190,,,,0,0,0
1281650,Computer-aided Diagnosis of Localized Ground-Glass Opacity in the Lung at CT: Initial Experience1,2005,Kwang Gi Kim and Jin Mo Goo and Jong Hyo Kim and Hyun Ju Lee and Byung Goo Min and Kyongtae T Bae and Jung-Gi Im,237,Radiology,2,657-661,Radiological Society of North America,,True,ZDM67bsAAAAJ:XD-gHx7UXLsC,108,,16981305291537718413,/scholar?cites=16981305291537718413,,,,0,0,0
1281651,3T 1H-MR spectroscopy in grading of cerebral gliomas: comparison of short and intermediate echo time sequences,2006,J-h Kim and K-H Chang and DG Na and IC Song and BJ Kwon and MH Han and K Kim,27,American journal of neuroradiology,7,1412-1418,American Journal of Neuroradiology,,True,ZDM67bsAAAAJ:9Nmd_mFXekcC,103,,17049486581782498403,/scholar?cites=17049486581782498403,,,,0,0,0
1281652,Differentiation between malignancy and inflammation in pulmonary ground-glass nodules: the feasibility of integrated 18F-FDG PET/CT,2009,Eun Ju Chun and Hyun Ju Lee and Won Jun Kang and Kwang Gi Kim and Jin Mo Goo and Chang Min Park and Chang Hyun Lee,65,Lung Cancer,2,180-186,Elsevier,,True,ZDM67bsAAAAJ:V3AGJWp-ZtQC,98,,10551654637439209152,/scholar?cites=10551654637439209152,,,,0,0,0
1281653,Pulmonary nodular ground-glass opacities in patients with extrapulmonary cancers: what is their clinical significance and how can we determine whether they are malignant or …,2008,Chang Min Park and Jin Mo Goo and Tae Jung Kim and Hyun Ju Lee and Kyung Won Lee and Chang Hyun Lee and Young Tae Kim and Kwang Gi Kim and Ho Yun Lee and Eun-Ah Park and Jung-Gi Im,133,Chest,6,1402-1409,Elsevier,,True,ZDM67bsAAAAJ:08ZZubdj9fEC,78,,9292428813917553553,/scholar?cites=9292428813917553553,,,,0,0,0
1281654,Iterative reconstruction of dual-source coronary CT angiography: assessment of image quality and radiation dose,2012,Eun-Ah Park and Whal Lee and Kwang Woo Kim and Kwang Gi Kim and Allmendinger Thomas and Jin Wook Chung and Jae Hyung Park,28,The international journal of cardiovascular imaging,7,1775-1786,Springer Netherlands,,True,ZDM67bsAAAAJ:ZHo1McVdvXMC,73,,4163434907245042586,/scholar?cites=4163434907245042586,,,,0,0,0
1281655,A study on hemorrhage detection using hybrid method in fundus images,2011,Jang Pyo Bae and Kwang Gi Kim and Ho Chul Kang and Chang Bu Jeong and Kyu Hyung Park and Jeong-Min Hwang,24,Journal of digital imaging,3,394-404,Springer-Verlag,,True,ZDM67bsAAAAJ:u9iWguZQMMsC,73,,8040806657767709961,/scholar?cites=8040806657767709961,,,,0,0,0
1281656,End to End Learning for Self-Driving Cars,2016,Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba,,arXiv preprint arXiv:1604.07316,,,,,True,5isUxCgAAAAJ:3fE2CSJIrl8C,2597,,9841425441326142274,/scholar?cites=9841425441326142274,,,,0,0,0
1281657,Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car,2017,Mariusz Bojarski and Philip Yeres and Anna Choromanska and Krzysztof Choromanski and Bernhard Firner and Lawrence Jackel and Urs Muller,,arXiv preprint arXiv:1704.07911,,,,,True,5isUxCgAAAAJ:4DMP91E08xMC,281,,16414439666471841147,/scholar?cites=16414439666471841147,,,,0,0,0
1281658,A novel phase-shift control of semibridgeless active rectifier for wireless power transfer,2015,Kerim Colak and Erdem Asa and Mariusz Bojarski and Dariusz Czarkowski and Omer C Onar,30,IEEE Transactions on Power Electronics,11,6288-6297,IEEE,,True,5isUxCgAAAAJ:LkGwnXOMwfcC,160,,13890598449932446957,/scholar?cites=13890598449932446957,,,,0,0,0
1281659,End to end learning for self-driving cars. arXiv 2016,2016,Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao,103,arXiv preprint arXiv:1604.07316,,,,,True,5isUxCgAAAAJ:HDshCWvjkbEC,94,,437137459044025045,/scholar?cites=437137459044025045,,,,0,0,0
1281660,End to end learning for self-driving cars. arXiv 2016,2016,Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao,103,arXiv preprint arXiv:1604.07316,,,,,True,5isUxCgAAAAJ:-f6ydRqryjwC,94,,437137459044025045,/scholar?cites=437137459044025045,,,,0,0,0
1281661,Frequency-Dependent Resistance of Litz-Wire Square Solenoid Coils and Quality Factor Optimization for Wireless Power Transfer,2016,Qijun Deng and Jiangtao Liu and Dariusz Czarkowski and Marian K Kazimierczuk and Mariusz Bojarski and Hong Zhou and Wenshan Hu,63,IEEE Transactions on Industrial Electronics,5,2825-2837,IEEE,,True,5isUxCgAAAAJ:MXK_kJrjxJIC,62,,6729009729561200937,/scholar?cites=6729009729561200937,,,,0,0,0
1281662,Visualbackprop: visualizing cnns for autonomous driving,2016,Mariusz Bojarski and Anna Choromanska and Krzysztof Choromanski and Bernhard Firner and Larry Jackel and Urs Muller and Karol Zieba,2,arXiv preprint arXiv:1611.05418,,,,,True,5isUxCgAAAAJ:M3ejUd6NZC8C,54,,4181629551650288818,/scholar?cites=4181629551650288818,,,,0,0,0
1281663,Asymmetrical Duty-Cycle and Phase-Shift Control of a Novel Multiport CLL Resonant Converter,2015,Erdem Asa and Kerim Colak and Mariusz Bojarski and Dariusz Czarkowski,3,IEEE Journal of Emerging and Selected Topics in Power Electronics,4,1122-1131,IEEE,,True,5isUxCgAAAAJ:eQOLeE2rZwMC,46,,1415001564770224265,/scholar?cites=1415001564770224265,,,,0,0,0
1281664,Analysis and control of multiphase inductively coupled resonant converter for wireless electric vehicle charger applications,2016,Mariusz Bojarski and Erdem Asa and Kerim Colak and Dariusz Czarkowski,3,IEEE transactions on transportation electrification,2,312-320,IEEE,,True,5isUxCgAAAAJ:KlAtU1dfN6UC,45,,12816353902641570210,/scholar?cites=12816353902641570210,,,,0,0,0
1281665,A 25 kW industrial prototype wireless electric vehicle charger,2016,Mariusz Bojarski and Erdem Asa and Kerim Colak and Dariusz Czarkowski,,,,1756-1761,IEEE,,True,5isUxCgAAAAJ:kNdYIx-mwKoC,37,,3466369163421535987,/scholar?cites=3466369163421535987,,,,0,0,0
1281666,Binary embeddings with structured hashed projections,2016,Anna Choromanska and Krzysztof Choromanski and Mariusz Bojarski and Tony Jebara and Sanjiv Kumar and Yann LeCun,,,,344-353,,,True,5isUxCgAAAAJ:hqOjcs7Dif8C,34,,8213909987576988267,/scholar?cites=8213909987576988267,,,,0,0,0
1281667,Searching for exotic particles in high-energy physics with deep learning,2014,Pierre Baldi and Peter Sadowski and Daniel Whiteson,5,Nature Communications,,,,,True,5-s3bS8AAAAJ:_FxGoFyzp5QC,895,,10628473223663935847,/scholar?cites=10628473223663935847,,,,0,0,0
1281668,Theano: A Python framework for fast computation of mathematical expressions,2016,Rami Al-Rfou and Guillaume Alain and Amjad Almahairi and Christof Angermueller and Dzmitry Bahdanau and Nicolas Ballas and Frédéric Bastien and Justin Bayer and Anatoly Belikov and Alexander Belopolsky and Yoshua Bengio and Arnaud Bergeron and James Bergstra and Valentin Bisson and Josh Bleecher Snyder and Nicolas Bouchard and Nicolas Boulanger-Lewandowski and Xavier Bouthillier and Alexandre de Brébisson and Olivier Breuleux and Pierre-Luc Carrier and Kyunghyun Cho and Jan Chorowski and Paul Christiano and Tim Cooijmans and Marc-Alexandre Côté and Myriam Côté and Aaron Courville and Yann N Dauphin and Olivier Delalleau and Julien Demouth and Guillaume Desjardins and Sander Dieleman and Laurent Dinh and Melanie Ducoffe and Vincent Dumoulin and Samira Ebrahimi Kahou and Dumitru Erhan and Ziye Fan and Orhan Firat and Mathieu Germain and Xavier Glorot and Ian Goodfellow and Matt Graham and Caglar Gulcehre and Philippe Hamel and Iban Harlouchet and Jean-Philippe Heng and Balázs Hidasi and Sina Honari and Arjun Jain and Sébastien Jean and Kai Jia and Mikhail Korobov and Vivek Kulkarni and Alex Lamb and Pascal Lamblin and Eric Larsen and César Laurent and Sean Lee and Simon Lefrançois and Simon Lemieux and Nicholas Léonard and Zhouhan Lin and Jesse A Livezey and Cory Lorenz and Jeremiah Lowin and Qianli Ma and Pierre-Antoine Manzagol and Olivier Mastropietro and Robert T McGibbon and Roland Memisevic and Bart van Merriënboer and Vincent Michalski and Mehdi Mirza and Alberto Orlandi and Christopher Pal and Razvan Pascanu and Mohammad Pezeshki and Colin Raffel and Daniel Renshaw and Matthew Rocklin and Adriana Romero and Markus Roth and Peter Sadowski and John Salvatier and François Savard and Jan Schlüter and John Schulman and Gabriel Schwartz and Iulian Vlad Serban and Dmitriy Serdyuk and Samira Shabanian and Étienne Simon and Sigurd Spieckermann and S Ramana Subramanyam and Jakub Sygnowski and Jérémie Tanguay and Gijs van Tulder and Joseph Turian and Sebastian Urban and Pascal Vincent and Francesco Visin and Harm de Vries and David Warde-Farley and Dustin J Webb and Matthew Willson and Kelvin Xu and Lijun Xue and Li Yao and Saizheng Zhang and Ying Zhang,,arXiv e-prints,,arXiv: 1605.02688,,,True,5-s3bS8AAAAJ:YOwf2qJgpHMC,772,,3168617625725328375,/scholar?cites=3168617625725328375,,,,0,0,0
1281669,Understanding dropout,2013,Pierre Baldi and Peter Sadowski,,,,2814-2822,,,True,5-s3bS8AAAAJ:zYLM7Y9cAGgC,357,,16355053762352405454,/scholar?cites=16355053762352405454,,,,0,0,0
1281670,Learning activation functions to improve deep neural networks,2014,Forest Agostinelli and Matthew Hoffman and Peter Sadowski and Pierre Baldi,,arXiv preprint arXiv:1412.6830,,,,,True,5-s3bS8AAAAJ:Se3iqnhoufwC,343,,5255373738796360629,/scholar?cites=5255373738796360629,,,,0,0,0
1281671,The dropout learning algorithm,2014,Pierre Baldi and Peter Sadowski,210,Artificial intelligence,,78-122,Elsevier,,True,5-s3bS8AAAAJ:IjCSPb-OGe4C,246,,17764957409006857880,/scholar?cites=17764957409006857880,,,,0,0,0
1281672,Jet substructure classification in high-energy physics with deep neural networks,2016,Pierre Baldi and Kevin Bauer and Clara Eng and Peter Sadowski and Daniel Whiteson,93,Physical Review D,9,094034,American Physical Society,,True,5-s3bS8AAAAJ:3fE2CSJIrl8C,180,,15756109311404856763,/scholar?cites=15756109311404856763,,,,0,0,0
1281673,Deep autoencoder neural networks for gene ontology annotation predictions,2014,Davide Chicco and Peter Sadowski and Pierre Baldi,,,,533-540,,,True,5-s3bS8AAAAJ:YsMSGLbcyi4C,172,,3634209041731475652,/scholar?cites=3634209041731475652,,,,0,0,0
1281674,Parameterized neural networks for high-energy physics,2016,Pierre Baldi and Kyle Cranmer and Taylor Faucett and Peter Sadowski and Daniel Whiteson,76,The European Physical Journal C,5,1-7,Springer Berlin Heidelberg,,True,5-s3bS8AAAAJ:ULOm3_A8WrAC,166,,11985488929991585417,/scholar?cites=11985488929991585417,,,,0,0,0
1281675,Decorrelated jet substructure tagging using adversarial neural networks,2017,Chase Shimmin and Peter Sadowski and Pierre Baldi and Edison Weik and Daniel Whiteson and Edward Goul and Andreas Søgaard,96,Physical Review D,7,074034,American Physical Society,,True,5-s3bS8AAAAJ:mVmsd5A6BfQC,113,,10581924328517717060,/scholar?cites=10581924328517717060,,,,0,0,0
1281676,Enhanced Higgs Boson to  Search with Deep Learning,2015,Pierre Baldi and Peter Sadowski and Daniel Whiteson,114,Physical review letters,11,111801,American Physical Society,,True,5-s3bS8AAAAJ:eQOLeE2rZwMC,107,,6329096395451468926,/scholar?cites=6329096395451468926,,,,0,0,0
1281677,A theory of local learning. the learning channel. and the optimality of backpropagation,2016,Pierre Baldi and Peter Sadowski,83,Neural Networks,,51-74,Pergamon,,True,5-s3bS8AAAAJ:4TOpqqG69KYC,66,,14323147986625117593,/scholar?cites=14323147986625117593,,,,0,0,0
1281678,The Visual Object Tracking VOT2014 Challenge Results,2014,Matej Kristan and Roman Pflugfelder and Aleš Leonardis and Jiri Matas and Luka Čehovin and Georg Nebehay and Tomáš Vojíř and Gustavo Fernández and Alan Lukežič and Aleksandar Dimitriev and Alfredo Petrosino and Amir Saffari and Bo Li and Bohyung Han and CherKeng Heng and Christophe Garcia and Dominik Pangeršič and Gustav Häger and Fahad Shahbaz Khan and Franci Oven and Horst Possegger and Horst Bischof and Hyeonseob Nam and Jianke Zhu and JiJia Li and Jin Young Choi and Jin-Woo Choi and João F. Henriques and Joost van de Weijer and Jorge Batista and Karel Lebeda and Kristoffer Öfjäll and Kwang Moo Yi and Lei Qin and Longyin Wen and Mario Edoardo Maresca and Martin Danelljan and Michael Felsberg and Ming-Ming Cheng and Philip Torr and Qingming Huang and Richard Bowden and Sam Hare and Samantha YueYing Lim and Seunghoon Hong and Shengcai Liao and Simon Hadfield and Stan Z. Li and Stefan Duffner and Stuart Golodetz and Thomas Mauthner and Vibhav Vineet and Weiyao Lin and Yang Li and Yuankai Qi and Zhen Lei and Zhi Heng Niu,,,,,,,True,pr6rIJEAAAAJ:J_g5lzvAfSwC,1594,,5030672482439802527,/scholar?cites=5030672482439802527,,,,0,0,0
1281679,LIFT: Learned Invariant Feature Transform,2016,Kwang Moo Yi and Eduard Trulls and Vincent Lepetit and Pascal Fua,,,,,,,True,pr6rIJEAAAAJ:GnPB-g6toBAC,634,,8648671042395507368,/scholar?cites=8648671042395507368,,,,0,0,0
1281680,Intelligent visual surveillance—a survey,2010,In Su Kim and Hong Seok Choi and Kwang Moo Yi and Jin Young Choi and Seong G Kong,8,"International Journal of Control, Automation and Systems",5,926-939,Institute of Control. Robotics and Systems and The Korean Institute of Electrical Engineers,,True,pr6rIJEAAAAJ:QIV2ME_5wuYC,201,,8490700555978916288,/scholar?cites=8490700555978916288,,,,0,0,0
1281681,TILDE: A Temporally Invariant Learned DEtector,2015,Yannick Verdie and Kwang Moo Yi and Pascal Fua and Vincent Lepetit,,,,5279 - 5288,IEEE,,True,pr6rIJEAAAAJ:RHpTSmoSYBkC,200,,17048769840534034013,/scholar?cites=17048769840534034013,,,,0,0,0
1281682,LF-Net: Learning local features from images,2018,Yuki Ono and Eduard Trulls and Pascal Fua and Kwang Moo Yi,,,,6234-6244,,,True,pr6rIJEAAAAJ:SeFeTyx0c_EC,158,,8243342192916977654,/scholar?cites=8243342192916977654,,,,0,0,0
1281683,Learning to Find Good Correspondences,2018,Kwang Moo Yi and Eduard Trulls and Yuki Ono and Vincent Lepetit and Mathieu Salzmann and Pascal Fua,,,,2666-2674,,,True,pr6rIJEAAAAJ:ZHo1McVdvXMC,148,,12387887282018559067,/scholar?cites=12387887282018559067,,,,0,0,0
1281684,Detection of moving objects with non-stationary cameras in 5.8 ms: Bringing motion detection to your mobile device,2013,Kwang Moo Yi and Kimin Yun and Soo Wan Kim and Hyung Jin Chang and Jin Young Choi,,,,27-34,,,True,pr6rIJEAAAAJ:qUcmZB5y_30C,111,,15425458958659768679,/scholar?cites=15425458958659768679,,,,0,0,0
1281685,Detection of moving objects with a moving camera using non-panoramic background model,2013,Soo Wan Kim and Kimin Yun and Kwang Moo Yi and Sun Jung Kim and Jin Young Choi,24,Machine vision and applications,5,1015-1028,Springer-Verlag,,True,pr6rIJEAAAAJ:7PzlFSSx8tAC,102,,7209999995126505061,/scholar?cites=7209999995126505061,,,,0,0,0
1281686,A Novel Representation of Parts for Accurate 3D Object Detection and Tracking in Monocular Images,2015,Alberto Crivellaro and Mahdi Rad and Yannick Verdie and Kwang Moo Yi and Pascal Fua and Vincent Lepetit,,,,4391-4399,,,True,pr6rIJEAAAAJ:NMxIlDl6LWMC,88,,4200659001069467727,/scholar?cites=4200659001069467727,,,,0,0,0
1281687,Learning to Assign Orientations to Feature Points,2016,Kwang Moo Yi and Yannick Verdie and Pascal Fua and Vincent Lepetit,,,,107-116,,,True,pr6rIJEAAAAJ:RGFaLdJalmkC,85,,6336226218463269740,/scholar?cites=6336226218463269740,,,,0,0,0
1281688,Robust 3d object tracking from monocular images using stable parts,2018,Alberto Crivellaro and Mahdi Rad and Yannick Verdie and Kwang Moo Yi and Pascal Fua and Vincent Lepetit,40,IEEE transactions on pattern analysis and machine intelligence,6,1465-1479,IEEE,,True,pr6rIJEAAAAJ:35N4QoGY0k4C,48,,4683202969111134697,/scholar?cites=4683202969111134697,,,,0,0,0
1281689,Multiresolution face recognition,2005,Hazim Kemal Ekenel and Bülent Sankur,23,Image and Vision Computing,5,469-477,Elsevier,,True,LfIDj68AAAAJ:g5m5HwL7SMYC,234,,2506165074074564510,/scholar?cites=2506165074074564510,,,,0,0,0
1281690,Local appearance based face recognition using discrete cosine transform,2005,Hazim Kemal Ekenel and Rainer Stiefelhagen,,,,1-5,IEEE,,True,LfIDj68AAAAJ:u5HHmVD_uO8C,166,,14226309595631332562,/scholar?cites=14226309595631332562,,,,0,0,0
1281691,Video-based face recognition on real-world data,2007,Johannes Stallkamp and Hazim K Ekenel and Rainer Stiefelhagen,,,,1-8,IEEE,,True,LfIDj68AAAAJ:qxL8FJ1GzNcC,152,,13194695654767824034,/scholar?cites=13194695654767824034,,,,0,0,0
1281692,Enabling multimodal human–robot interaction for the karlsruhe humanoid robot,2007,Rainer Stiefelhagen and Hazim Kemal Ekenel and Christian Fugen and Petra Gieselmann and Hartwig Holzapfel and Florian Kraft and Kai Nickel and Michael Voit and Alex Waibel,23,IEEE Transactions on Robotics,5,840-851,IEEE,,True,LfIDj68AAAAJ:M3ejUd6NZC8C,144,,17650004359568634873,/scholar?cites=17650004359568634873,,,,0,0,0
1281693,Feature selection in the independent component subspace for face recognition,2004,Hazim Kemal Ekenel and Bülent Sankur,25,Pattern Recognition Letters,12,1377-1388,North-Holland,,True,LfIDj68AAAAJ:4TOpqqG69KYC,133,,11768287532830663780,/scholar?cites=11768287532830663780,,,,0,0,0
1281694,Analysis of local appearance-based face recognition: Effects of feature selection and feature normalization,2006,Hazim Kemal Ekenel and Rainer Stiefelhagen,,,,34-34,IEEE,,True,LfIDj68AAAAJ:u-x6o8ySG0sC,126,,7644379445528766356,/scholar?cites=7644379445528766356,,,,0,0,0
1281695,Strengths and weaknesses of deep learning models for face recognition against image degradations,2017,Klemen Grm and Vitomir Štruc and Anais Artiges and Matthieu Caron and Hazım K Ekenel,7,Iet Biometrics,1,81-89,IET Digital Library,,True,LfIDj68AAAAJ:TIZ-Mc8IlK0C,124,,135074023317001118,/scholar?cites=135074023317001118,,,,0,0,0
1281696,Cycle-dehaze: Enhanced cyclegan for single image dehazing,2018,Deniz Engin and Anil Genç and Hazim Kemal Ekenel,,,,825-833,,,True,LfIDj68AAAAJ:S16KYo8Pm5AC,119,,113876731288826314,/scholar?cites=113876731288826314,,,,0,0,0
1281697,A comprehensive analysis of deep learning based representation for face recognition,2016,Mostafa Mehdipour Ghazi and Hazim Kemal Ekenel,,,,34-41,,,True,LfIDj68AAAAJ:ye4kPcJQO24C,102,,11702398776207942825,/scholar?cites=11702398776207942825,,,,0,0,0
1281698,Ntire 2018 challenge on image dehazing: Methods and results,2018,Cosmin Ancuti and Codruta O Ancuti and Radu Timofte,,,,891-901,,,True,LfIDj68AAAAJ:i2xiXl-TujoC,84,,17806686477992997196,/scholar?cites=17806686477992997196,,,,0,0,0
1281699,Why is facial occlusion a challenging problem?,2009,Hazım Kemal Ekenel and Rainer Stiefelhagen,,,,299-308,Springer. Berlin. Heidelberg,,True,LfIDj68AAAAJ:QIV2ME_5wuYC,84,,5205611348285339299,/scholar?cites=5205611348285339299,,,,0,0,0
1281700,DEAP: Evolutionary algorithms made easy,2012,Félix-Antoine Fortin and François-Michel De Rainville and Marc-André Gardner and Marc Parizeau and Christian Gagné,13,Journal of Machine Learning Research,,2171-2175,,,True,egixsbEAAAAJ:L8Ckcad2t8MC,1336,,16822776618118742006,/scholar?cites=16822776618118742006,,,,0,0,0
1281701,Genericity in evolutionary computation software tools: Principles and case-study,2006,Christian Gagné and Marc Parizeau,15,International Journal on Artificial Intelligence Tools,2,173-194,World Scientific Publishing,,True,egixsbEAAAAJ:u5HHmVD_uO8C,152,,10283846699334725655,/scholar?cites=10283846699334725655,,,,0,0,0
1281702,The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities,2020,Joel Lehman and Jeff Clune and Dusan Misevic and Christoph Adami and Lee Altenberg and Julie Beaulieu and Peter J Bentley and Samuel Bernard and Guillaume Beslon and David M Bryson and Nick Cheney and Patryk Chrabaszcz and Antoine Cully and Stephane Doncieux and Fred C Dyer and Kai Olav Ellefsen and Robert Feldt and Stephan Fischer and Stephanie Forrest and Antoine Fŕenoy and Christian Gagńe and Leni Le Goff and Laura M Grabowski and Babak Hodjat and Frank Hutter and Laurent Keller and Carole Knibbe and Peter Krcah and Richard E Lenski and Hod Lipson and Robert MacCurdy and Carlos Maestre and Risto Miikkulainen and Sara Mitri and David E Moriarty and Jean-Baptiste Mouret and Anh Nguyen and Charles Ofria and Marc Parizeau and David Parsons and Robert T Pennock and William F Punch and Thomas S Ray and Marc Schoenauer and Eric Schulte and Karl Sims and Kenneth O Stanley and François Taddei and Danesh Tarapore and Simon Thibault and Richard Watson and Westley Weimer and Jason Yosinski,26,Artificial life,2,274-306,MIT Press,,True,egixsbEAAAAJ:08ZZubdj9fEC,135,,3980437369159466016,/scholar?cites=3980437369159466016,,,,0,0,0
1281703,Learning to predict indoor illumination from a single image,2017,Marc-André Gardner and Kalyan Sunkavalli and Ersin Yumer and Xiaohui Shen and Emiliano Gambaretto and Christian Gagné and Jean-François Lalonde,9,ACM Transactions on Graphics,4,,,,True,egixsbEAAAAJ:u9iWguZQMMsC,130,,9172270451999558730,/scholar?cites=9172270451999558730,,,,0,0,0
1281704,DEAP: A Python Framework for Evolutionary Algorithms,2012,François-Michel De Rainville and Félix-Antoine Fortin and Marc-André Gardner and Marc Parizeau and Christian Gagné,,,,85-92,ACM,,True,egixsbEAAAAJ:7PzlFSSx8tAC,127,,13888909457145045350,/scholar?cites=13888909457145045350,,,,0,0,0
1281705,Probabilistic Sensing Model for Sensor Placement Optimization Based on Line-of-Sight Coverage,2013,Vahab Akbarzadeh and Christian Gagné and Marc Parizeau and Meysam Argany and Mir Abolfazl Mostafavi,62,IEEE Transactions on Instrumentation and Measurement,2,293-303,IEEE,,True,egixsbEAAAAJ:HDshCWvjkbEC,119,,3541207292836348955,/scholar?cites=3541207292836348955,,,,0,0,0
1281706,Genetic programming. validation sets. and parsimony pressure,2006,Christian Gagné and Marc Schoenauer and Marc Parizeau and Marco Tomassini,,,,109-120,Springer Berlin/Heidelberg,,True,egixsbEAAAAJ:d1gkVwhDpl0C,89,,17291699711308613915,/scholar?cites=17291699711308613915,,,,0,0,0
1281707,Analysis of a master-slave architecture for distributed evolutionary computations,2006,Marc Dubreuil and Christian Gagné and Marc Parizeau,36,"IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics",1,229-235,IEEE,,True,egixsbEAAAAJ:zYLM7Y9cAGgC,86,,1063527109081961082,/scholar?cites=1063527109081961082,,,,0,0,0
1281708,Robustness to adversarial examples through an ensemble of specialists,2017,Mahdieh Abbasi and Christian Gagné,,,,,,,True,egixsbEAAAAJ:1sJd4Hv_s6UC,73,,9809992322264504013,/scholar?cites=9809992322264504013,,,,0,0,0
1281709,Demand-side management using deep learning for smart charging of electric vehicles,2019,Karol Lina López and Christian Gagné and Marc-André Gardner,10,IEEE Transactions on Smart Grid,3,2683-2691,IEEE,,True,egixsbEAAAAJ:tOudhMTPpwUC,71,,9963109399459937445,/scholar?cites=9963109399459937445,,,,0,0,0
1281710,A GIS based wireless sensor network coverage estimation and optimization: A Voronoi approach,2011,Meysam Argany and Mir Abolfazl Mostafavi and Farid Karimipour and Christian Gagné,,,,151-172,Springer. Berlin. Heidelberg,,True,egixsbEAAAAJ:ULOm3_A8WrAC,69,,11341481784611389505,/scholar?cites=11341481784611389505,,,,0,0,0
1281711,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,2017,Han Xiao and Kashif Rasul and Roland Vollgraf,,arXiv preprint arXiv:1708.07747,,,,,True,w8qPxSUAAAAJ:_FxGoFyzp5QC,2222,,17093201473631702655,/scholar?cites=17093201473631702655,,,,0,0,0
1281712,Contextual string embeddings for sequence labeling,2018,Alan Akbik and Duncan Blythe and Roland Vollgraf,,,,1638-1649,,,True,w8qPxSUAAAAJ:0EnyYjriUFMC,732,,9081362511964500166,/scholar?cites=9081362511964500166,,,,0,0,0
1281713,FLAIR: An easy-to-use framework for state-of-the-art NLP,2019,Alan Akbik and Tanja Bergmann and Duncan Blythe and Kashif Rasul and Stefan Schweter and Roland Vollgraf,,,,54-59,,,True,w8qPxSUAAAAJ:ULOm3_A8WrAC,197,,16599346400790737496,/scholar?cites=16599346400790737496,,,,0,0,0
1281714,Pooled contextualized embeddings for named entity recognition,2019,Alan Akbik and Tanja Bergmann and Roland Vollgraf,,,,724-728,,,True,w8qPxSUAAAAJ:Zph67rFs4hoC,146,,3388912822872306978,/scholar?cites=3388912822872306978,,,,0,0,0
1281715,Quadratic optimization for simultaneous matrix diagonalization,2006,Roland Vollgraf and Klaus Obermayer,54,IEEE Transactions on Signal Processing,9,3270-3278,IEEE,,True,w8qPxSUAAAAJ:u5HHmVD_uO8C,128,,8891933747496082055,/scholar?cites=8891933747496082055,,,,0,0,0
1281716,Texture synthesis with spatial generative adversarial networks,2016,Nikolay Jetchev and Urs Bergmann and Roland Vollgraf,,arXiv preprint arXiv:1611.08207,,,,,True,w8qPxSUAAAAJ:YsMSGLbcyi4C,116,,3251387337183172925,/scholar?cites=3251387337183172925,,,,0,0,0
1281717,Learning texture manifolds with the periodic spatial GAN,2017,Urs Bergmann and Nikolay Jetchev and Roland Vollgraf,,arXiv preprint arXiv:1705.06566,,,,,True,w8qPxSUAAAAJ:WF5omc3nYNoC,87,,1389278938259265903,/scholar?cites=1389278938259265903,,,,0,0,0
1281718,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms (2017),2017,Han Xiao and Kashif Rasul and Roland Vollgraf,32,arXiv preprint cs.LG/1708.07747,,,,,True,w8qPxSUAAAAJ:dhFuZR0502QC,86,,15521008059565511145,/scholar?cites=15521008059565511145,,,,0,0,0
1281719,From grids to places,2007,Mathias Franzius and Roland Vollgraf and Laurenz Wiskott,22,Journal of computational neuroscience,3,297-299,Kluwer Academic Publishers-Plenum Publishers,,True,w8qPxSUAAAAJ:u-x6o8ySG0sC,73,,18392462187773777571,/scholar?cites=18392462187773777571,,,,0,0,0
1281720,Fashion-mnist: A novel image dataset for benchmarking machine learning algorithms. arXiv 2017,,Han Xiao and Kashif Rasul and Roland Vollgraf,,arXiv preprint arXiv:1708.07747,,,,,True,w8qPxSUAAAAJ:mVmsd5A6BfQC,58,,1322913284632034543,/scholar?cites=1322913284632034543,,,,0,0,0
1281721,Fashion DNA: merging content and sales data for recommendation and article mapping,2016,Christian Bracher and Sebastian Heinz and Roland Vollgraf,,arXiv preprint arXiv:1609.02489,,,,,True,w8qPxSUAAAAJ:W7OEmFMy1HYC,33,,1860589835328268724,/scholar?cites=1860589835328268724,,,,0,0,0
1281722,Cbam: Convolutional block attention module,2018,Sanghyun Woo and Jongchan Park and Joon-Young Lee and In So Kweon,,,,3-19,,,True,6ajse1YAAAAJ:tKAzc9rXhukC,1783,,57030359015830554,/scholar?cites=57030359015830554,,,,0,0,0
1281723,Physically-based rendering for indoor scene understanding using convolutional neural networks,2017,Yinda Zhang and Shuran Song and Ersin Yumer and Manolis Savva and Joon-Young Lee and Hailin Jin and Thomas Funkhouser,,,,5287-5295,,,True,6ajse1YAAAAJ:VL0QpB8kHFEC,190,,10519725307300171189,/scholar?cites=10519725307300171189,,,,0,0,0
1281724,Bam: Bottleneck attention module,2018,Jongchan Park and Sanghyun Woo and Joon-Young Lee and In So Kweon,,arXiv preprint arXiv:1807.06514,,,,,True,6ajse1YAAAAJ:7T2F9Uy0os0C,178,,11241536010871634575,/scholar?cites=11241536010871634575,,,,0,0,0
1281725,Learning a deep convolutional network for light-field image super-resolution,2015,Youngjin Yoon and Hae-Gon Jeon and Donggeun Yoo and Joon-Young Lee and In So Kweon,,,,24-32,,,True,6ajse1YAAAAJ:WA5NYHcadZ8C,169,,4074716618280968127,/scholar?cites=4074716618280968127,,,,0,0,0
1281726,Fast video object segmentation by reference-guided mask propagation,2018,Seoung Wug Oh and Joon-Young Lee and Kalyan Sunkavalli and Seon Joo Kim,,,,7376-7385,,,True,6ajse1YAAAAJ:kzcrU_BdoSEC,166,,9213245007933084222,/scholar?cites=9213245007933084222,,,,0,0,0
1281727,Robust high dynamic range imaging by rank minimization,2015,Tae-Hyun Oh and Joon-Young Lee and Yu Wing Tai and In-So Kweon,,,,,IEEE Transactions on Pattern Analysis and Machine Intelligence,,True,6ajse1YAAAAJ:8AbLer7MMksC,123,,12330153962617579844,/scholar?cites=12330153962617579844,,,,0,0,0
1281728,Attentionnet: Aggregating weak directions for accurate object detection,2015,Donggeun Yoo and Sunggyun Park and Joon-Young Lee and Anthony S Paek and In So Kweon,,,,2659-2667,,,True,6ajse1YAAAAJ:fQNAKQ3IYiAC,118,,7945502788875583930,/scholar?cites=7945502788875583930,,,,0,0,0
1281729,Video object segmentation using space-time memory networks,2019,Seoung Wug Oh and Joon-Young Lee and Ning Xu and Seon Joo Kim,,,,9226-9235,,,True,6ajse1YAAAAJ:VLnqNzywnoUC,113,,4811785222141175494,/scholar?cites=4811785222141175494,,,,0,0,0
1281730,High quality shape from a single rgb-d image under uncalibrated natural illumination,2013,Yudeog Han and Joon-Young Lee and In So Kweon,,,,1617-1624,,,True,6ajse1YAAAAJ:CHSYGLWDkRkC,96,,4342876342546217886,/scholar?cites=4342876342546217886,,,,0,0,0
1281731,Color transfer using probabilistic moving least squares,2014,Youngbae Hwang and Joon-Young Lee and In So Kweon and Seon Joo Kim,,,,3342-3349,,,True,6ajse1YAAAAJ:b0M2c_1WBrUC,95,,6135796440460266003,/scholar?cites=6135796440460266003,,,,0,0,0
1281732,Multi-Scale Pyramid Pooling for Deep Convolutional Representation,2015,Donggeun Yoo and Sunggyun Park and Joon-Young Lee and In Kweon,,,,71-80,,,True,6ajse1YAAAAJ:LPZeul_q3PIC,89,,5897358979480286206,/scholar?cites=5897358979480286206,,,,0,0,0
1281733,RF-system-on-package (SOP) for wireless communications,2002,Kyutae Lim and Stephane Pinel and Mekita Davis and Albert Sutono and Chang-Ho Lee and Deukhyoun Heo and Ade Obatoynbo and Joy Laskar and Emmanouil M Tantzeris and Rao Tummala,3,IEEE Microwave magazine,1,88-99,IEEE,,True,gh4I3GYAAAAJ:R3hNpaxXUhUC,254,,6425399359295749168,/scholar?cites=6425399359295749168,,,,0,0,0
1281734,A 90nm cmos 60ghz radio,2008,Stephane Pinel and Saikat Sarkar and Padmanava Sen and Bevin Perumana and David Yeh and Debasis Dawn and Joy Laskar,,,,130-601,IEEE,,True,gh4I3GYAAAAJ:7PzlFSSx8tAC,216,,5123354044221002635,/scholar?cites=5123354044221002635,,,,0,0,0
1281735,A V-band front-end with 3-D integrated cavity filters/duplexers and antenna in LTCC technologies,2006,Jong-Hoon Lee and Nobutaka Kidera and Gerald DeJean and Stéphane Pinel and Joy Laskar and Manos M Tentzeris,54,IEEE Transactions on Microwave Theory and Techniques,7,2925-2936,IEEE,,True,gh4I3GYAAAAJ:ULOm3_A8WrAC,136,,3427217464575914727,/scholar?cites=3427217464575914727,,,,0,0,0
1281736,Low-loss LTCC cavity filters using system-on-package technology at 60 GHz,2005,Jong-Hoon Lee and Stephane Pinel and John Papapolymerou and Joy Laskar and Manos M Tentzeris,53,IEEE Transactions on Microwave Theory and Techniques,12,3817-3824,IEEE,,True,gh4I3GYAAAAJ:vRqMK49ujn8C,136,,13766877994586857143,/scholar?cites=13766877994586857143,,,,0,0,0
1281737,3-D-integrated RF and millimeter-wave functions and modules using liquid crystal polymer (LCP) system-on-package technology,2004,Manos M Tentzeris and Joy Laskar and John Papapolymerou and Stéphane Pinel and V Palazzari and R Li and G DeJean and N Papageorgiou and D Thompson and R Bairavasubramanian and S Sarkar and J-H Lee,27,IEEE Transactions on Advanced Packaging,2,332-340,IEEE,,True,gh4I3GYAAAAJ:VOx2b1Wkg3QC,123,,14351581749308314694,/scholar?cites=14351581749308314694,,,,0,0,0
1281738,Highly integrated millimeter-wave passive components using 3-D LTCC system-on-package (SOP) technology,2005,Jong-Hoon Lee and Gerald DeJean and Saikat Sarkar and Stephane Pinel and Kyutae Lim and John Papapolymerou and Joy Laskar and Manos M Tentzeris,53,IEEE transactions on microwave theory and techniques,6,2220-2229,IEEE,,True,gh4I3GYAAAAJ:TQgYirikUcIC,121,,6419102918604141776,/scholar?cites=6419102918604141776,,,,0,0,0
1281739,The next wireless wave is a millimeter wave,2007,J Laskar and Stephane Pinel and Debasis Dawn and Subir Sarkar and B Perumana and P Sen,50,Microwave Journal,8,22,HORIZON HOUSE PUBLICATIONS. INC.,,True,gh4I3GYAAAAJ:a0OBvERweLwC,114,,10927784237848316154,/scholar?cites=10927784237848316154,,,,0,0,0
1281740,Design of compact stacked-patch antennas in LTCC multilayer packaging modules for wireless applications,2004,RongLin Li and Gerald DeJean and Moonkyun Maeng and Kyutae Lim and Stephane Pinel and Manos M Tentzeris and Joy Laskar,27,IEEE Transactions on Advanced Packaging,4,581-589,IEEE,,True,gh4I3GYAAAAJ:RGFaLdJalmkC,110,,9049882636954373772,/scholar?cites=9049882636954373772,,,,0,0,0
1281741,A compact LTCC-based Ku-band transmitter module,2002,Chang-Ho Lee and Albert Sutono and Sangwoo Han and Kyutae Lim and Stéphane Pinel and Emmanouil M Tentzeris and Joy Laskar,25,IEEE Transactions on Advanced Packaging,3,374-384,IEEE,,True,gh4I3GYAAAAJ:uWQEDVKXjbEC,110,,12803665849703732012,/scholar?cites=12803665849703732012,,,,0,0,0
1281742,Wireless repeater assembly,2006,Stephane Pinel and Joy Laskar,,,,,,,True,gh4I3GYAAAAJ:WbkHhVStYXYC,99,,13410682601527802674,/scholar?cites=13410682601527802674,,,,0,0,0
1281743,Receiver assembly and method for multi-gigabit wireless systems,2009,Stephane Pinel and Joy Laskar,,,,,,,True,gh4I3GYAAAAJ:TFP_iSt0sucC,87,,6979736917633920541,/scholar?cites=6979736917633920541,,,,0,0,0
1281744,Skin segmentation using color pixel classification: analysis and comparison,2005,Son Lam Phung and Abdesselam Bouzerdoum and Douglas Chai,27,IEEE transactions on pattern analysis and machine intelligence,1,148-154,IEEE,,True,Ho9uKiwAAAAJ:u5HHmVD_uO8C,1021,,14144262569065633509,/scholar?cites=14144262569065633509,,,,0,0,0
1281745,A novel skin color model in ycbcr color space and its application to human face detection,2002,Son Lam Phung and Abdesselam Bouzerdoum and Douglas Chai,1,,,I-I,IEEE,,True,Ho9uKiwAAAAJ:u-x6o8ySG0sC,380,,15728680067882953032,/scholar?cites=15728680067882953032,,,,0,0,0
1281746,Learning pattern classification tasks with imbalanced data sets,2009,Giang Hoang Nguyen and Abdesselam Bouzerdoum and Son Lam Phung,,Pattern recognition,,193-208,InTech,,True,Ho9uKiwAAAAJ:Tyk-4Ss8FVUC,171,,16325381281389212416,/scholar?cites=16325381281389212416,,,,0,0,0
1281747,A pyramidal neural network for visual pattern recognition,2007,Son Lam Phung and Abdesselam Bouzerdoum,18,"Neural Networks, IEEE Transactions on",2,329-343,IEEE,,True,Ho9uKiwAAAAJ:9yKSN-GCB0IC,152,,13350398789870841600,/scholar?cites=13350398789870841600,,,,0,0,0
1281748,Skin segmentation using color and edge information,2003,Son Lam Phung and Abdesselam Bouzerdoum and Douglas Chai,1,,,525-528,IEEE,,True,Ho9uKiwAAAAJ:qjMakFHDy7sC,115,,7150487828875157515,/scholar?cites=7150487828875157515,,,,0,0,0
1281749,A universal and robust human skin color model using neural networks,2001,Son Lam Phung and Douglas Chai and Abdesselam Bouzerdoum,4,,,2844-2849,IEEE,,True,Ho9uKiwAAAAJ:d1gkVwhDpl0C,111,,5524655607797176278,/scholar?cites=5524655607797176278,,,,0,0,0
1281750,Adaptive skin segmentation in color images,2003,Son Lam Phung and Douglas Chai and Abdesselam Bouzerdoum,3,,,III-353,IEEE,,True,Ho9uKiwAAAAJ:2osOgNQ5qMEC,109,,17424285174738779100,/scholar?cites=17424285174738779100,,,,0,0,0
1281751,Breast cancer diagnosis in DCE-MRI using mixture ensemble of convolutional neural networks,2017,Reza Rasti and Mohammad Teshnehlab and Son Lam Phung,72,Pattern Recognition,,381-390,Pergamon,,True,Ho9uKiwAAAAJ:WbkHhVStYXYC,94,,5163360946445333470,/scholar?cites=5163360946445333470,,,,0,0,0
1281752,A supervised learning approach for imbalanced data sets,2008,Giang H Nguyen and Abdesselam Bouzerdoum and Son L Phung,,,,1-4,IEEE,,True,Ho9uKiwAAAAJ:Y0pCki6q_DkC,65,,2788797719635366078,/scholar?cites=2788797719635366078,,,,0,0,0
1281753,Automatic classification of human motions using Doppler radar,2012,Jingli Li and Son Lam Phung and Fok Hing Chi Tivive and Abdesselam Bouzerdoum,,,,1-6,IEEE,,True,Ho9uKiwAAAAJ:JV2RwH3_ST0C,54,,12226047801619262593,/scholar?cites=12226047801619262593,,,,0,0,0
1281754,On the analysis of background subtraction techniques using Gaussian mixture models,2010,Philippe Loic Marie Bouttefroy and Abdesselam Bouzerdoum and Son Lam Phung and Azeddine Beghdadi,,,,4042-4045,IEEE,,True,Ho9uKiwAAAAJ:ufrVoPGSRksC,53,,9480604075928884803,/scholar?cites=9480604075928884803,,,,0,0,0
1281755,Instance Normalization: The Missing Ingredient for Fast Stylization,2016,Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky,,"arXiv preprint arXiv:1607.08022, 2016/7/27",,,,,True,g9pQXZ4AAAAJ:9yKSN-GCB0IC,1514,,7452685526525981959,/scholar?cites=7452685526525981959,,,,0,0,0
1281756,Deep image prior,2018,Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky,,Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition,,,,,True,g9pQXZ4AAAAJ:zYLM7Y9cAGgC,966,,9402209269334396424,/scholar?cites=9402209269334396424,,,,0,0,0
1281757,Texture Networks: Feed-forward Synthesis of Textures and Stylized Images.,2016,Dmitry Ulyanov and Vadim Lebedev and Andrea Vedaldi and Victor S Lempitsky,1,ICML,2,4,,,True,g9pQXZ4AAAAJ:d1gkVwhDpl0C,643,,5452588382099665760,/scholar?cites=5452588382099665760,,,,0,0,0
1281758,Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis,2017,Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky,,,,6924-6932,,,True,g9pQXZ4AAAAJ:2osOgNQ5qMEC,372,,15121556168732029899,/scholar?cites=15121556168732029899,,,,0,0,0
1281759,Novel feature extraction. selection and fusion for effective malware family classification,2016,Mansour Ahmadi and Dmitry Ulyanov and Stanislav Semenov and Mikhail Trofimov and Giorgio Giacinto,,,,183-194,ACM,,True,g9pQXZ4AAAAJ:u5HHmVD_uO8C,240,,3318406593654821890,/scholar?cites=3318406593654821890,,,,0,0,0
1281760,It Takes (Only) Two: Adversarial Generator-Encoder Networks,2018,Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky,,,,,,,True,g9pQXZ4AAAAJ:Tyk-4Ss8FVUC,66,,10811218013915069795,/scholar?cites=10811218013915069795,,,,0,0,0
1281761,Neural Point-Based Graphics,2019,Kara-Ali Aliev and Dmitry Ulyanov and Victor Lempitsky,,,,,,,True,g9pQXZ4AAAAJ:8k81kl-MbHgC,46,,10159211515078402286,/scholar?cites=10159211515078402286,,,,0,0,0
1281762,Multicore-tsne,2016,Dmitry Ulyanov,,GitHub Repos. GitHub,,,,,True,g9pQXZ4AAAAJ:UebtZRa9Y70C,44,,13176259935140837509,/scholar?cites=13176259935140837509,,,,0,0,0
1281763,Textured neural avatars,2019,Aliaksandra Shysheya and Egor Zakharov and Kara-Ali Aliev and Renat Bashirov and Egor Burkov and Karim Iskakov and Aleksei Ivakhnenko and Yury Malkov and Igor Pasechnik and Dmitry Ulyanov and Alexander Vakhitov and Victor Lempitsky,,,,2387-2397,,,True,g9pQXZ4AAAAJ:WF5omc3nYNoC,41,,7357803994407634226,/scholar?cites=7357803994407634226,,,,0,0,0
1281764,Adversarial generator-encoder networks,2017,Dmitry Ulyanov and Andrea Vedaldi and Victor Lempitsky,20,arXiv preprint arXiv:1704.02304,,,,,True,g9pQXZ4AAAAJ:4DMP91E08xMC,38,,6452235055159491748,/scholar?cites=6452235055159491748,,,,0,0,0
1281765,Audio Texture Synthesis and Style Transfer,2016,Dmitry Ulyanov and Vadim Lebedev,,,,,,,True,g9pQXZ4AAAAJ:IjCSPb-OGe4C,34,,5916356410588376408,/scholar?cites=5916356410588376408,,,,0,0,0
1281766,Permutation invariant training of deep models for speaker-independent multi-talker speech separation,2017,Dong Yu and Morten Kolbæk and Zheng-Hua Tan and Jesper Jensen,,,,241-245,IEEE,,True,fugL2E8AAAAJ:4hFrxpcac9AC,411,,16933409780258115290,/scholar?cites=16933409780258115290,,,,0,0,0
1281767,Multitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks,2017,Morten Kolbæk and Dong Yu and Zheng-Hua Tan and Jesper Jensen,25,"IEEE/ACM Transactions on Audio, Speech, and Language Processing",10,1901-1913,IEEE,,True,fugL2E8AAAAJ:r_AWSJRzSzQC,387,,14041382867888045416,/scholar?cites=14041382867888045416,,,,0,0,0
1281768,Conditional generative adversarial networks for speech enhancement and noise-robust speaker verification,2017,Daniel Michelsanti and Zheng-Hua Tan,,arXiv preprint arXiv:1709.01703,,,,,True,fugL2E8AAAAJ:artPoR2Yc-kC,166,,11550830663320501930,/scholar?cites=11550830663320501930,,,,0,0,0
1281769,Speech intelligibility potential of general and specialized deep neural network based speech enhancement systems,2016,Morten Kolbæk and Zheng-Hua Tan and Jesper Jensen,25,"IEEE/ACM Transactions on Audio, Speech, and Language Processing",1,153-167,IEEE,,True,fugL2E8AAAAJ:HIFyuExEbWQC,127,,2418336815599211503,/scholar?cites=2418336815599211503,,,,0,0,0
1281770,Decorrelation of neutral vector variables: Theory and applications,2016,Zhanyu Ma and Jing-Hao Xue and Arne Leijon and Zheng-Hua Tan and Zhen Yang and Jun Guo,29,IEEE transactions on neural networks and learning systems,1,129-143,IEEE,,True,fugL2E8AAAAJ:9c2xU6iGI7YC,112,,8968952400382235129,/scholar?cites=8968952400382235129,,,,0,0,0
1281771,Low-complexity variable frame rate analysis for speech recognition and voice activity detection,2010,Zheng-Hua Tan and Børge Lindberg,4,IEEE Journal of Selected Topics in Signal Processing,5,798-807,IEEE,,True,fugL2E8AAAAJ:UebtZRa9Y70C,106,,9304536937713081424,/scholar?cites=9304536937713081424,,,,0,0,0
1281772,Reddots replayed: A new replay spoofing attack corpus for text-dependent speaker verification research,2017,Tomi Kinnunen and Md Sahidullah and Mauro Falcone and Luca Costantini and Rosa González Hautamäki and Dennis Thomsen and Achintya Sarkar and Zheng-Hua Tan and Héctor Delgado and Massimiliano Todisco and Nicholas Evans and Ville Hautamäki and Kong Aik Lee,,,,5395-5399,IEEE,,True,fugL2E8AAAAJ:cWzG1nlazyYC,101,,939637057764005610,/scholar?cites=939637057764005610,,,,0,0,0
1281773,Automatic speech recognition on mobile devices and over communication networks,2008,Zheng-Hua Tan and Børge Lindberg,,,,,Springer Science & Business Media,,True,fugL2E8AAAAJ:2osOgNQ5qMEC,96,,2389595540113876937,/scholar?cites=2389595540113876937,,,,0,0,0
1281774,Automatic speech recognition over error-prone wireless networks,2005,Zheng-Hua Tan and Paul Dalsgaard and Børge Lindberg,47,,1-2,220-242,North-Holland,,True,fugL2E8AAAAJ:u5HHmVD_uO8C,60,,4285049525924524928,/scholar?cites=4285049525924524928,,,,0,0,0
1281775,Spoofing detection in automatic speaker verification systems using DNN classifiers and dynamic acoustic features,2017,Hong Yu and Zheng-Hua Tan and Zhanyu Ma and Rainer Martin and Jun Guo,29,IEEE transactions on neural networks and learning systems,10,4633-4644,IEEE,,True,fugL2E8AAAAJ:4xDN1ZYqzskC,50,,1585000328190482946,/scholar?cites=1585000328190482946,,,,0,0,0
1281776,Internet of Things: Opportunities and Challenges,2010,Zheng-Hua Tan and Neeli R. Prasad,,,,,,,True,fugL2E8AAAAJ:1yQoGdGgb4wC,47,,18005361234923168216,/scholar?cites=18005361234923168216,,,,0,0,0
1281777,Learning to rank short text pairs with convolutional deep neural networks,2015,Aliaksei Severyn and Alessandro Moschitti,,,,373-382,,,True,EoVDI3MAAAAJ:vDijr-p_gm4C,666,,3053391355219807883,/scholar?cites=3053391355219807883,,,,0,0,0
1281778,Globally normalized transition-based neural networks,2016,Daniel Andor and Chris Alberti and David Weiss and Aliaksei Severyn and Alessandro Presta and Kuzman Ganchev and Slav Petrov and Michael Collins,,,,,,,True,EoVDI3MAAAAJ:ML0RJ9NH7IQC,572,,10973467127305341223,/scholar?cites=10973467127305341223,,,,0,0,0
1281779,Twitter sentiment analysis with deep convolutional neural networks,2015,Aliaksei Severyn and Alessandro Moschitti,,,,959-962,,,True,EoVDI3MAAAAJ:epqYDVWIO7EC,547,,15045491018633968940,/scholar?cites=15045491018633968940,,,,0,0,0
1281780,Neural ranking models with weak supervision,2017,Mostafa Dehghani and Hamed Zamani and Aliaksei Severyn and Jaap Kamps and W Bruce Croft,,,,65-74,,,True,EoVDI3MAAAAJ:L7CI7m0gUJcC,253,,18361974242139517447,/scholar?cites=18361974242139517447,,,,0,0,0
1281781,UNITN: Training Deep Convolutional Neural Network for Twitter Sentiment Classification,2015,Aliaksei Severyn and Alessandro Moschitti,,,,,ACL,,True,EoVDI3MAAAAJ:0KyAp5RtaNEC,225,,3024113887161912057,/scholar?cites=3024113887161912057,,,,0,0,0
1281782,A Hybrid Convolutional Variational Autoencoder for Text Generation,2017,Stanislau Semeniuta and Aliaksei Severyn and Erhardt Barth,,,,,,,True,EoVDI3MAAAAJ:vbGhcppDl1QC,172,,22686147435504388,/scholar?cites=22686147435504388,,,,0,0,0
1281783,Recurrent dropout without memory loss,2016,Stanislau Semeniuta and Aliaksei Severyn and Erhardt Barth,,,,,,,True,EoVDI3MAAAAJ:Z5m8FVwuT1cC,171,,16998373299318301099,/scholar?cites=16998373299318301099,,,,0,0,0
1281784,Automatic Feature Engineering for Answer Selection and Extraction,2013,Aliaksei Severyn and Alessandro Moschitti,,,,,,,True,EoVDI3MAAAAJ:5nxA0vEk-isC,138,,15342663546438654610,/scholar?cites=15342663546438654610,,,,0,0,0
1281785,Leveraging large amounts of weakly supervised data for multi-language sentiment classification,2017,Jan Deriu and Aurelien Lucchi and Valeria De Luca and Aliaksei Severyn and Simon Müller and Mark Cieliebak and Thomas Hofmann and Martin Jaggi,,,,1045-1052,,,True,EoVDI3MAAAAJ:EYYDruWGBe4C,103,,15751215125803462604,/scholar?cites=15751215125803462604,,,,0,0,0
1281786,Structural relationships for large-scale learning of answer re-ranking,2012,Aliaksei Severyn and Alessandro Moschitti,,,,741-750,,,True,EoVDI3MAAAAJ:WF5omc3nYNoC,91,,17547197626869002111,/scholar?cites=17547197626869002111,,,,0,0,0
1281787,Multi-lingual opinion mining on YouTube,2016,Aliaksei Severyn and Alessandro Moschitti and Olga Uryupina and Barbara Plank and Katja Filippova,52,Information Processing & Management,1,46-60,Pergamon,,True,EoVDI3MAAAAJ:yB1At4FlUx8C,66,,13871956156798947541,/scholar?cites=13871956156798947541,,,,0,0,0
1281788,Method and system for assessing the photo quality of a captured image in a digital still camera,2008,Qian Lin,,,,,,A method for assessing the photo quality of a captured image in a digital camera comprises the steps of checking in-camera the photo quality of the captured image to determine if the photo quality is acceptable. and providing a corresponding photo quality feedback to a camera user.,True,LdvJBLYAAAAJ:tuHXwOkdijsC,278,https://patents.google.com/patent/US7362354B2/en,1888234585776804288,/scholar?cites=1888234585776804288,,,https://patentimages.storage.googleapis.com/aa/2d/77/e8562e9b2ca452/US7362354.pdf,0,0,0
1281789,New approaches in interferometric SAR data processing,1992,Qian Lin and John F Vesecky and Howard A Zebker,30,IEEE Transactions on Geoscience and Remote Sensing,3,560-567,IEEE,It is known that interferometric synthetic-aperture radar (SAR) images can be inverted to perform surface elevation mapping. Among the factors critical to the mapping accuracy are registration of the interfering SAR images and phase unwrapping. A registration algorithm is presented that determines the registration parameters through optimization. A figure of merit is proposed that evaluates the registration result during the optimization. The phase unwrapping problem is approached through a new method involving fringe line detection. The algorithms are tested with two SEASAT SAR images of terrain near Yellowstone National Park. These images were collected on SEASAT orbits 1334 and 1420. which were very close together in space. i.e. less than 100 m.< >,True,LdvJBLYAAAAJ:hMsQuOkrut0C,222,https://ieeexplore.ieee.org/abstract/document/142934/,536910318337206807,/scholar?cites=536910318337206807,,,,0,0,0
1281790,Apparatus and a method for reducing red-eye in a digital image,2000,Qian Lin and Daniel R Tretter and Konstantinos Konstantinides and Andrew Patti,,,,,,A red-eye reduction system is described that includes a masking module. The masking module converts an image into a mask having first state areas representing red color pixels of the image and second state areas representing other color pixels of the image. The image includes an eye with a red pupil. A pupil locating module is coupled to the masking module to locate a substantially first state area in the mask that resembles a pupil. A color replacing module is then coupled to the pupil locating module to change the red color pixels in the area into monochrome (grey) or other predefined colors. The color replacing module also adjusts the boundary of the area by changing the colors of pixels in close proximity to the area if the color of these pixels is determined to be sufficiently close to red such that natural appearance of the eye is maintained when reducing the red pupil. A method of reducing red-eye effect in a …,True,LdvJBLYAAAAJ:-FonjvnnhkoC,204,https://patents.google.com/patent/US6016354A/en,9442921121118058918,/scholar?cites=9442921121118058918,,,https://patentimages.storage.googleapis.com/59/68/78/3a90858a28f5d3/US6016354.pdf,0,0,0
1281791,Image enhancement using face detection,2002,Qian Lin and Clayton Atkins and Daniel Tretter,,,,,,An image enhancement apparatus and a corresponding method use face detection to provide for automatic enhancement of appearances of an image based on knowledge of human faces in the image. By modifying and transforming the image automatically using facial information. the image. including the human faces in the image. may have more pleasing lightness. contrast. and/or color levels. The image enhancement method may also automatically reduce or remove any red eye artifact without human intervention. leading to images with more pleasing appearances.,True,LdvJBLYAAAAJ:b1wdh0AR-JQC,190,https://patents.google.com/patent/US20020172419A1/en,1724864534930460321,/scholar?cites=1724864534930460321,,,https://patentimages.storage.googleapis.com/e1/7e/54/200610dd820692/US20020172419A1.pdf,0,0,0
1281792,Method and system for accessing a collection of images in a database,2006,Qian Lin and Ullas Gargi and Hojohn Lee,,,,,,A method and system are disclosed for accessing a collection of images in a database. In accordance with exemplary embodiments of the present invention. each of the images is sorted into one of a plurality of time-based clusters. A weighted quality metric is used to assign to each image a quality number as a function of an image analysis heuristic. A representative image is automatically selected from each time-based cluster based on the quality number.,True,LdvJBLYAAAAJ:k8Z6L05lTy4C,187,https://patents.google.com/patent/US7130864B2/en,4531873241688613393,/scholar?cites=4531873241688613393,,,https://patentimages.storage.googleapis.com/pdfs/US7130864.pdf,0,0,0
1281793,Systems and methods for location-based real estate service,2011,Ullas Gargi and Ramin Samadani and Qian Lin,,,,,,A system and method for searching real estate properties. a system and method for estimating the size of an area. and a system and method for associating an image with information relevant to the image is disclosed. A system for searching real estate properties comprises a data storage unit configured to store map information. additional relevant georeferenced information and information about real estate properties. including information identifying the locations of the real estate properties; and a display unit configured to receive a search request from a user. communicate with the data storage unit. and provide search results to the user. including a map showing locations of real estate properties. in response to the search request. the display unit being further configured to displaying a user interface with which the user may associate information. personal to the user. with a particular real estate property.,True,LdvJBLYAAAAJ:WZBGuue-350C,139,https://patents.google.com/patent/US8051089B2/en,7376791740728143993,/scholar?cites=7376791740728143993,,,https://patentimages.storage.googleapis.com/57/5b/57/30d76808be024b/US8051089.pdf,0,0,0
1281794,System and method for producing a photobook,2006,Clayton Brian Atkins and Daniel Tretter and Qian Lin,,,,,,A method for producing a set of images as a photobook is provided. The method includes selecting a set of images having meta data and determining an attribute value for an attribute associated with each of the images. After determining an attribute value of an attribute. the method adjusts the attribute value associated with at least one of the images to render the attribute value of the images uniform. The method then organizes the images automatically using the meta data and determines a layout of the photobook by automatically adjusting spatial characteristics of the images within the photobook. Once the method determines a layout of the photobook. the method outputs the photobook.,True,LdvJBLYAAAAJ:S16KYo8Pm5AC,135,https://patents.google.com/patent/US7148990B2/en,13790939834200669981,/scholar?cites=13790939834200669981,,,https://patentimages.storage.googleapis.com/c3/bf/df/29398083261e33/US7148990.pdf,0,0,0
1281795,Combining multiple exposure images to increase dynamic range,2009,Mei Chen and Qian Lin and Suk Hwan Lim,,,,,,Methods. machines. and machine-readable media for processing multiple exposure source images. including a reference image and one or more non-reference images. are described. In one aspect. respective sets of motion vectors that establish correspondences between respective pairs of the source images are calculated. Ones of the source images are warped to a reference coordinate system based on the sets of motion vectors. For each of the non-reference ones of the warped images. a respective set of one or more measures of alignment confidence between the non-reference warped image and the reference image in the reference coordinate system is computed. Saturated pixels and unsaturated pixels are identified in the warped images. An output image with pixel value contributions from unsaturated pixels in the warped images is generated based on the computed alignment confidence measures.,True,LdvJBLYAAAAJ:PoWvk5oyLR8C,119,https://patents.google.com/patent/US7623683B2/en,14399669521957482958,/scholar?cites=14399669521957482958,,,https://patentimages.storage.googleapis.com/63/1f/c9/5fad14a71f68a0/US7623683.pdf,0,0,0
1281796,FM screen design using DBS algorithm,1996,J Allebach and Qian Lin,1,,,549-552,IEEE,We describe an algorithm to design a frequency modulated screen using the direct binary search algorithm. Compared with the direct binary search algorithm itself. we show that we can maintain halftone image quality while significantly reducing the required computation.,True,LdvJBLYAAAAJ:oNZyr7d5Mn4C,99,https://ieeexplore.ieee.org/abstract/document/559555/,6255393928038438800,/scholar?cites=6255393928038438800,,,,0,0,0
1281797,Automatic color processing to correct hue shift and incorrect exposure,1998,Qian Lin,,,,,,A digital color processing method for images from scanners and digital cameras processes image data suitable for display on monitors or color hardcopies produced by digital color printers and correct hue shift and incorrect exposure based on the image content. The method automatically corrects the data based on the histogram of the acquired image normalizing the image data to correct for the hue shift and determining the gamma parameter to correct the exposure of the image.,True,LdvJBLYAAAAJ:i2xiXl-TujoC,90,https://patents.google.com/patent/US5812286A/en,14031231049750041261,/scholar?cites=14031231049750041261,,,https://patentimages.storage.googleapis.com/pdfs/US5812286.pdf,0,0,0
1281798,System and method for enhancing scanned document images for color printing,2003,Jian Fan and Daniel Tretter and Qian Lin and Neerja Raman,,,,,,A system and method for enhancing scanned document images utilizes an estimated background luminance of a given digital image to remove or reduce visual “see-through” noise. The estimated background luminance is dependent on the luminance values of the edges pixels of detected text edges of the image. In one embodiment. the estimated background luminance is generated using only the edge pixels that are on the lighter side of the detected edges. In addition to the see-through removal. the system and method may further enhance the scanned document images by removing color fringes and sharpening and/or darkening edges of text contained in the images.,True,LdvJBLYAAAAJ:LI9QrySNdTsC,85,https://patents.google.com/patent/US6621595B1/en,3250121164288069110,/scholar?cites=3250121164288069110,,,https://patentimages.storage.googleapis.com/5b/52/75/4a52ddd04c58a5/US6621595.pdf,0,0,0
1281799,An atlas of combinatorial transcriptional regulation in mouse and man,2010,Timothy Ravasi and Harukazu Suzuki and Carlo Vittorio Cannistraci,140,Cell,5,744-752,Cell Press,Combinatorial interactions among transcription factors are critical to directing tissue-specific gene expression. To build a global atlas of these combinations. we have screened for physical interactions among the majority of human and mouse DNA-binding transcription factors (TFs). The complete networks contain 762 human and 877 mouse interactions. Analysis of the networks reveals that highly connected TFs are broadly expressed across tissues. and that roughly half of the measured interactions are conserved between mouse and human. The data highlight the importance of TF combinations for determining cell fate. and they lead to the identification of a SMAD3/FLI1 complex expressed during development of immunity. The availability of large TF combinatorial networks in both human and mouse will provide many opportunities to study gene regulation. tissue differentiation. and mammalian evolution.,True,eVNtrtgAAAAJ:hqOjcs7Dif8C,701,https://www.sciencedirect.com/science/article/pii/S0092867410000796,12383024494707723331,/scholar?cites=12383024494707723331,,,https://www.sciencedirect.com/science/article/pii/S0092867410000796,0,0,0
1281800,A simple algorithm for identifying abbreviation definitions in biomedical text,2003,Ariel S Schwartz and Marti A Hearst,,,,451-62,,The volume of biomedical text is growing at a fast rate. creating challenges for humans and computer systems alike. One of these challenges arises from the frequent use of novel abbreviations in these texts. thus requiring that biomedical lexical ontologies be continually updated. In this paper we show that the problem of identifying abbreviations' definitions can be solved with a much simpler algorithm than that proposed by other research efforts. The algorithm achieves 96% precision and 82% recall on a standard test collection. which is at least as good as existing approaches. It also achieves 95% precision and 82% recall on another. larger test set. A notable advantage of the algorithm is that. unlike other approaches. it does not require any training data.,True,eVNtrtgAAAAJ:8k81kl-MbHgC,647,https://www.worldscientific.com/doi/abs/10.1142/9789812776303_0042,820621787756643242,/scholar?cites=820621787756643242,,,https://flamenco.berkeley.edu/papers/psb03.pdf,0,0,0
1281801,Domestication and divergence of Saccharomyces cerevisiae beer yeasts,2016,Brigida Gallone and Jan Steensels and Troels Prahl and Leah Soriaga and Veerle Saels and Beatriz Herrera-Malaver and Adriaan Merlevede and Miguel Roncoroni and Karin Voordeckers and Loren Miraglia and Clotilde Teiling and Brian Steffy and Maryann Taylor and Ariel Schwartz and Toby Richardson and Christopher White and Guy Baele and Steven Maere and Kevin J Verstrepen,166,Cell,6,1397-1410. e16,Cell Press,Whereas domestication of livestock. pets. and crops is well documented. it is still unclear to what extent microbes associated with the production of food have also undergone human selection and where the plethora of industrial strains originates from. Here. we present the genomes and phenomes of 157 industrial Saccharomyces cerevisiae yeasts. Our analyses reveal that today’s industrial yeasts can be divided into five sublineages that are genetically and phenotypically separated from wild strains and originate from only a few ancestors through complex patterns of domestication and local divergence. Large-scale phenotyping and genome analysis further show strong industry-specific selection for stress tolerance. sugar utilization. and flavor production. while the sexual cycle and other phenotypes related to survival in nature show decay. particularly in beer yeasts. Together. these results shed light on the origins …,True,eVNtrtgAAAAJ:nPT8s1NX_-sC,370,https://www.sciencedirect.com/science/article/pii/S0092867416310716,12300522216929102892,/scholar?cites=12300522216929102892,,,https://www.sciencedirect.com/science/article/pii/S0092867416310716,0,0,0
1281802,The transcriptional network that controls growth arrest and differentiation in a human myeloid leukemia cell line,2009,Harukazu Suzuki and Alistair RR Forrest and Erik Van Nimwegen and Carsten O Daub and Piotr J Balwierz and Katharine M Irvine and Timo Lassmann and Timothy Ravasi and Yuki Hasegawa and Michiel JL De Hoon and Shintaro Katayama and Kate Schroder and Piero Carninci and Yasuhiro Tomaru and Mutsumi Kanamori-Katayama and Atsutaka Kubosaki and Altuna Akalin and Yoshinari Ando and Erik Arner and Maki Asada and Hiroshi Asahara and Timothy Bailey and Vladimir B Bajic and Denis Bauer and Anthony G Beckhouse and Nicolas Bertin and Johan Björkegren and Frank Brombacher and Erika Bulger and Alistair M Chalk and Joe Chiba and Nicole Cloonan and Adam Dawe and Josee Dostie and Pär G Engström and Magbubah Essack and Geoffrey J Faulkner and J Lynn Fink and David Fredman and Ko Fujimori and Masaaki Furuno and Takashi Gojobori and Julian Gough and Sean M Grimmond and Mika Gustafsson and Megumi Hashimoto and Takehiro Hashimoto and Mariko Hatakeyama and Susanne Heinzel and Winston Hide and Oliver Hofmann and Michael Hörnquist and Lukasz Huminiecki and Kazuho Ikeo and Naoko Imamoto and Satoshi Inoue and Yusuke Inoue and Ryoko Ishihara and Takao Iwayanagi and Anders Jacobsen and Mandeep Kaur and Hideya Kawaji and Markus C Kerr and Ryuichiro Kimura and Syuhei Kimura and Yasumasa Kimura and Hiroaki Kitano and Hisashi Koga and Toshio Kojima and Shinji Kondo and Takeshi Konno and Anders Krogh and Adele Kruger and Ajit Kumar and Boris Lenhard and Andreas Lennartsson and Morten Lindow and Marina Lizio and Cameron MacPherson and Norihiro Maeda and Christopher A Maher and Monique Maqungo and Jessica Mar and Nicholas A Matigian and Hideo Matsuda and John S Mattick and Stuart Meier and Sei Miyamoto and Etsuko Miyamoto-Sato and Kazuhiko Nakabayashi and Yutaka Nakachi and Mika Nakano and Sanne Nygaard and Toshitsugu Okayama and Yasushi Okazaki and Haruka Okuda-Yabukami and Valerio Orlando and Jun Otomo and Mikhail Pachkov and Nikolai Petrovsky and Charles Plessy and John Quackenbush and Aleksandar Radovanovic and Michael Rehli and Rintaro Saito and Albin Sandelin and Sebastian Schmeier and Christian Schönbach and Ariel S Schwartz and Colin A Semple and Miho Sera and Jessica Severin and Katsuhiko Shirahige and Cas Simons and George St Laurent and Masanori Suzuki and Takahiro Suzuki and Matthew J Sweet and Ryan J Taft and Shizu Takeda and Yoichi Takenaka and Kai Tan and Martin S Taylor and Rohan D Teasdale and Jesper Tegnér and Sarah Teichmann and Eivind Valen and Claes Wahlestedt and Kazunori Waki and Andrew Waterhouse and Christine A Wells and Ole Winther and Linda Wu and Kazumi Yamaguchi and Hiroshi Yanagawa and Jun Yasuda and Mihaela Zavolan and David A Hume and Riken Omics Science Center and Takahiro Arakawa and Shiro Fukuda and Kengo Imamura and Chikatoshi Kai and Ai Kaiho and Tsugumi Kawashima and Chika Kawazu and Yayoi Kitazume and Miki Kojima and Hisashi Miura and Kayoko Murakami,41,Nature genetics,5,553,Nature Publishing Group,Using deep sequencing (deepCAGE). the FANTOM4 study measured the genome-wide dynamics of transcription-start-site usage in the human monocytic cell line THP-1 throughout a time course of growth arrest and differentiation. Modeling the expression dynamics in terms of predicted cis-regulatory sites. we identified the key transcription regulators. their time-dependent activities and target genes. Systematic siRNA knockdown of 52 transcription factors confirmed the roles of individual factors in the regulatory network. Our results indicate that cellular states are constrained by complex networks involving both positive and negative regulatory interactions among substantial numbers of transcription factors and that no single transcription factor is both necessary and sufficient to drive the differentiation process.,True,eVNtrtgAAAAJ:u-x6o8ySG0sC,353,https://www.nature.com/ng/journal/v41/n5/abs/ng.375.html,5472755647599628960,/scholar?cites=5472755647599628960,,,https://research.monash.edu/en/publications/the-transcriptional-network-that-controls-growth-arrest-and-diffe,0,0,0
1281803,Analyses of deep mammalian sequence alignments and constraint predictions for 1% of the human genome,2007,Elliott H Margulies and Gregory M Cooper and George Asimenos and Daryl J Thomas and Colin N Dewey and Adam Siepel and Ewan Birney and Damian Keefe and Ariel S Schwartz and Minmei Hou and James Taylor and Sergey Nikolaev and Juan I Montoya-Burgos and Ari Löytynoja and Simon Whelan and Fabio Pardi and Tim Massingham and James B Brown and Peter Bickel and Ian Holmes and James C Mullikin and Abel Ureta-Vidal and Benedict Paten and Eric A Stone and Kate R Rosenbloom and W James Kent and Gerard G Bouffard and Xiaobin Guan and Nancy F Hansen and Jacquelyn R Idol and Valerie VB Maduro and Baishali Maskeri and Jennifer C McDowell and Morgan Park and Pamela J Thomas and Alice C Young and Robert W Blakesley and Donna M Muzny and Erica Sodergren and David A Wheeler and Kim C Worley and Huaiyang Jiang and George M Weinstock and Richard A Gibbs and Tina Graves and Robert Fulton and Elaine R Mardis and Richard K Wilson and Michele Clamp and James Cuff and Sante Gnerre and David B Jaffe and Jean L Chang and Kerstin Lindblad-Toh and Eric S Lander and Angie Hinrichs and Heather Trumbower and Hiram Clawson and Ann Zweig and Robert M Kuhn and Galt Barber and Rachel Harte and Donna Karolchik and Matthew A Field and Richard A Moore and Carrie A Matthewson and Jacqueline E Schein and Marco A Marra and Stylianos E Antonarakis and Serafim Batzoglou and Nick Goldman and Ross Hardison and David Haussler and Webb Miller and Lior Pachter and Eric D Green and Arend Sidow,17,Genome research,6,760-774,Cold Spring Harbor Lab,A key component of the ongoing ENCODE project involves rigorous comparative sequence analyses for the initially targeted 1% of the human genome. Here. we present orthologous sequence generation. alignment. and evolutionary constraint analyses of 23 mammalian species for all ENCODE targets. Alignments were generated using four different methods; comparisons of these methods reveal large-scale consistency but substantial differences in terms of small genomic rearrangements. sensitivity (sequence coverage). and specificity (alignment accuracy). We describe the quantitative and qualitative trade-offs concomitant with alignment method choice and the levels of technical error that need to be accounted for in applications that require multisequence alignments. Using the generated alignments. we identified constrained regions using three different methods. While the different constraint-detecting …,True,eVNtrtgAAAAJ:u5HHmVD_uO8C,243,https://genome.cshlp.org/content/17/6/760.short,4812373238227635492,/scholar?cites=4812373238227635492,,,https://genome.cshlp.org/content/17/6/760.full.pdf,0,0,0
1281804,Lipid production in Nannochloropsis gaditana is doubled by decreasing expression of a single transcriptional regulator,2017,Imad Ajjawi and John Verruto and Moena Aqui and Leah B Soriaga and Jennifer Coppersmith and Kathleen Kwok and Luke Peach and Elizabeth Orchard and Ryan Kalb and Weidong Xu and Tom J Carlson and Kristie Francis and Katie Konigsfeld and Judit Bartalis and Andrew Schultz and William Lambert and Ariel S Schwartz and Robert Brown and Eric R Moellering,35,Nature biotechnology,7,647-652,Nature Publishing Group,Lipid production in the industrial microalga Nannochloropsis gaditana exceeds that of model algal species and can be maximized by nutrient starvation in batch culture. However. starvation halts growth. thereby decreasing productivity. Efforts to engineer N. gaditana strains that can accumulate biomass and overproduce lipids have previously met with little success. We identified 20 transcription factors as putative negative regulators of lipid production by using RNA-seq analysis of N. gaditana during nitrogen deprivation. Application of a CRISPR–Cas9 reverse-genetics pipeline enabled insertional mutagenesis of 18 of these 20 transcription factors. Knocking out a homolog of fungal Zn (II) 2 Cys 6-encoding genes improved partitioning of total carbon to lipids from 20%(wild type) to 40–55%(mutant) in nutrient-replete conditions. Knockout mutants grew poorly. but attenuation of Zn (II) 2 Cys 6 expression yielded …,True,eVNtrtgAAAAJ:LK8CI43ZvvMC,229,https://www.nature.com/articles/nbt.3865?report=reader,16589825699771102417,/scholar?cites=16589825699771102417,,,,0,0,0
1281805,Metagenomes from high-temperature chemotrophic systems reveal geochemical controls on microbial community structure and function,2010,William P Inskeep and Douglas B Rusch and Zackary J Jay and Markus J Herrgard and Mark A Kozubal and Toby H Richardson and Richard E Macur and Natsuko Hamamura and Ryan deM Jennings and Bruce W Fouke and Anna-Louise Reysenbach and Frank Roberto and Mark Young and Ariel Schwartz and Eric S Boyd and Jonathan H Badger and Eric J Mathur and Alice C Ortmann and Mary Bateson and Gill Geesey and Marvin Frazier,5,PloS one,3,e9773,Public Library of Science,The Yellowstone caldera contains the most numerous and diverse geothermal systems on Earth. yielding an extensive array of unique high-temperature environments that host a variety of deeply-rooted and understudied Archaea. Bacteria and Eukarya. The combination of extreme temperature and chemical conditions encountered in geothermal environments often results in considerably less microbial diversity than other terrestrial habitats and offers a tremendous opportunity for studying the structure and function of indigenous microbial communities and for establishing linkages between putative metabolisms and element cycling. Metagenome sequence (14–15.000 Sanger reads per site) was obtained for five high-temperature (>65°C) chemotrophic microbial communities sampled from geothermal springs (or pools) in Yellowstone National Park (YNP) that exhibit a wide range in geochemistry including pH. dissolved sulfide. dissolved oxygen and ferrous iron. Metagenome data revealed significant differences in the predominant phyla associated with each of these geochemical environments. Novel members of the Sulfolobales are dominant in low pH environments. while other Crenarchaeota including distantly-related Thermoproteales and Desulfurococcales populations dominate in suboxic sulfidic sediments. Several novel archaeal groups are well represented in an acidic (pH 3) Fe-oxyhydroxide mat. where a higher O2 influx is accompanied with an increase in archaeal diversity. The presence or absence of genes and pathways important in S oxidation-reduction. H2-oxidation. and aerobic respiration (terminal oxidation) provide insight …,True,eVNtrtgAAAAJ:0EnyYjriUFMC,192,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009773,4499319652489264269,/scholar?cites=4499319652489264269,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009773,0,0,0
1281806,Citances: Citation sentences for semantic analysis of bioscience text,2004,Preslav I Nakov and Ariel S Schwartz and Marti Hearst,4,Proceedings of the SIGIR,,81-88,,We propose the use of the text of the sentences surrounding citations as an important tool for semantic interpretation of bioscience text. We hypothesize several different uses of citation sentences (which we call citances). including the creation of training and testing data for semantic analysis (especially for entity and relation recognition). synonym set creation. database curation. document summarization. and information retrieval generally. We illustrate some of these ideas. showing that citations to one document in particular align well with what a hand-built curator extracted. We also show preliminary results on the problem of normalizing the different ways that the same concepts are expressed within a set of citances. using and improving on existing techniques in automatic paraphrase generation.,True,eVNtrtgAAAAJ:9yKSN-GCB0IC,172,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.2666&rep=rep1&type=pdf,16601677849047554433,/scholar?cites=16601677849047554433,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.2666&rep=rep1&type=pdf,0,0,0
1281807,Phylogenetic distribution of CRISPR-Cas systems in antibiotic-resistant Pseudomonas aeruginosa,2015,Alex van Belkum and Leah B Soriaga and Matthew C LaFave and Srividya Akella and Jean-Baptiste Veyrieras and E Magda Barbu and Dee Shortridge and Bernadette Blanc and Gregory Hannum and Gilles Zambardi and Kristofer Miller and Mark C Enright and Nathalie Mugnier and Daniel Brami and Stéphane Schicklin and Martina Felderman and Ariel S Schwartz and Toby H Richardson and Todd C Peterson and Bolyn Hubby and Kyle C Cady,6,MBio,6,,American Society for Microbiology,Pseudomonas aeruginosa is an antibiotic-refractory pathogen with a large genome and extensive genotypic diversity. Historically. P. aeruginosa has been a major model system for understanding the molecular mechanisms underlying type I clustered regularly interspaced short palindromic repeat (CRISPR) and CRISPR-associated protein (CRISPR-Cas)-based bacterial immune system function. However. little information on the phylogenetic distribution and potential role of these CRISPR-Cas systems in molding the P. aeruginosa accessory genome and antibiotic resistance elements is known. Computational approaches were used to identify and characterize CRISPR-Cas systems within 672 genomes. and in the process. we identified a previously unreported and putatively mobile type I-C P. aeruginosa CRISPR-Cas system. Furthermore. genomes harboring noninhibited type I-F and I-E CRISPR-Cas systems …,True,eVNtrtgAAAAJ:hQUaER0FWQ4C,119,https://mbio.asm.org/content/6/6/e01796-15.short,12835606435856365273,/scholar?cites=12835606435856365273,,,https://mbio.asm.org/content/mbio/6/6/e01796-15.full.pdf,0,0,0
1281808,Multiple alignment by sequence annealing,2007,Ariel S. Schwartz and Lior Pachter,23,Bioinformatics,2,e24-e29,Oxford University Press, Motivation: We introduce a novel approach to multiple alignment that is based on an algorithm for rapidly checking whether single matches are consistent with a partial multiple alignment. This leads to a sequence annealing algorithm. which is an incremental method for building multiple sequence alignments one match at a time. Our approach improves significantly on the standard progressive alignment approach to multiple alignment. Results: The sequence annealing algorithm performs well on benchmark test sets of protein sequences. It is not only sensitive. but also specific. drastically reducing the number of incorrectly aligned residues in comparison to other programs. The method allows for adjustment of the sensitivity/specificity tradeoff and can be used to reliably identify homologous regions among protein sequences. Availability: An implementation of the sequence annealing …,True,eVNtrtgAAAAJ:d1gkVwhDpl0C,114,https://academic.oup.com/bioinformatics/article-abstract/23/2/e24/202846,67366313021943074,/scholar?cites=67366313021943074,,,https://academic.oup.com/bioinformatics/article/23/2/e24/202846,0,0,0
1281809,Cost-effective strategies for completing the interactome,2009,Ariel S Schwartz and Jingkai Yu and Kyle R Gardenour and Russell L Finley Jr and Trey Ideker,6,Nature methods,1,55-61,Nature Publishing Group,Comprehensive protein-interaction mapping projects are underway for many model species and humans. A key step in these projects is estimating the time. cost and personnel required for obtaining an accurate and complete map. Here we modeled the cost of interaction-map completion for various experimental designs. We showed that current efforts may require up to 20 independent tests covering each protein pair to approach completion. We explored designs for reducing this cost substantially. including prioritization of protein pairs. probability thresholding and interaction prediction. The best experimental designs lowered cost by fourfold overall and> 100-fold in early stages of mapping. We demonstrate the best strategy in an ongoing project in Drosophila melanogaster. in which we mapped 450 high-confidence interactions using 47 microtiter plates. versus thousands of plates expected using current designs …,True,eVNtrtgAAAAJ:UebtZRa9Y70C,103,https://www.nature.com/nmeth/journal/v6/n1/abs/nmeth.1283.html,7314061583132196268,/scholar?cites=7314061583132196268,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2613168/,0,0,0
1281810,MR imaging radiomics signatures for predicting the risk of breast cancer recurrence as given by research versions of MammaPrint. Oncotype DX. and PAM50 gene assays,2016,Hui Li and Yitan Zhu and Elizabeth S Burnside and Karen Drukker and Katherine A Hoadley and Cheng Fan and Suzanne D Conzen and Gary J Whitman and Elizabeth J Sutton and Jose M Net and Marie Ganott and Erich Huang and Elizabeth A Morris and Charles M Perou and Yuan Ji and Maryellen L Giger,281,Radiology,2,382-391,Radiological Society of North America,To investigate relationships between computer-extracted breast magnetic resonance (MR) imaging phenotypes with multigene assays of MammaPrint. Oncotype DX. and PAM50 to assess the role of radiomics in evaluating the risk of breast cancer recurrence.Analysis was conducted on an institutional review board–approved retrospective data set of 84 deidentified. multi-institutional breast MR examinations from the National Cancer Institute Cancer Imaging Archive. along with clinical. histopathologic. and genomic data from The Cancer Genome Atlas. The data set of biopsy-proven invasive breast cancers included 74 (88%) ductal. eight (10%) lobular. and two (2%) mixed cancers. Of these. 73 (87%) were estrogen receptor positive. 67 (80%) were progesterone receptor positive. and 19 (23%) were human epidermal growth factor receptor 2 positive. For each case. computerized …,True,JfEMygUAAAAJ:yD5IFk8b50cC,304,https://pubs.rsna.org/doi/abs/10.1148/radiol.2016152110,15889084376277663752,/scholar?cites=15889084376277663752,,,https://pubs.rsna.org/doi/full/10.1148/radiol.2016152110,0,0,0
1281811,Deep learning in medical imaging and radiation therapy,2019,Berkman Sahiner and Aria Pezeshk and Lubomir M Hadjiiski and Xiaosong Wang and Karen Drukker and Kenny H Cha and Ronald M Summers and Maryellen L Giger,46,,1,e1-e36,,The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges. and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks. survey five major areas of application of DL in medical imaging and radiation therapy. identify common themes. discuss methods for dataset expansion. and conclude by summarizing lessons learned. remaining challenges. and future directions.,True,JfEMygUAAAAJ:0EnyYjriUFMC,255,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.13264,4001789988986047685,/scholar?cites=4001789988986047685,,,https://aapm.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mp.13264,0,0,0
1281812,Computerized lesion detection on breast ultrasound,2002,Karen Drukker and Maryellen L Giger and Karla Horsch and Matthew A Kupinski and Carl J Vyborny and Ellen B Mendelson,29,Medical physics,7,1438-1446,American Association of Physicists in Medicine,We investigated the use of a radial gradient index (RGI) filtering technique to automatically detect lesions on breast ultrasound. After initial RGI filtering. a sensitivity of 87% at 0.76 false‐positive detections per image was obtained on a database of 400 patients (757 images). Next. lesion candidates were segmented from the background by maximizing an average radial gradient (ARD) index for regions grown from the detected points. At an overlap of 0.4 with a radiologist lesion outline. 75% of the lesions were correctly detected. Subsequently. round robin analysis was used to assess the quality of the classification of lesion candidates into actual lesions and false‐positives by a Bayesian neural network. The round robin analysis yielded an  value of 0.84. and an overall performance by case of 94% sensitivity at 0.48 false‐positives per image. Use of computerized analysis of breast sonograms may ultimately facilitate …,True,JfEMygUAAAAJ:-f6ydRqryjwC,231,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.1485995,7460418364735810137,/scholar?cites=7460418364735810137,,,,0,0,0
1281813,Quantitative MRI radiomics in the prediction of molecular classifications of breast cancer subtypes in the TCGA/TCIA data set,2016,Hui Li and Yitan Zhu and Elizabeth S Burnside and Erich Huang and Karen Drukker and Katherine A Hoadley and Cheng Fan and Suzanne D Conzen and Margarita Zuley and Jose M Net and Elizabeth Sutton and Gary J Whitman and Elizabeth Morris and Charles M Perou and Yuan Ji and Maryellen L Giger,2,NPJ breast cancer,1,1-10,Nature Publishing Group,Using quantitative radiomics. we demonstrate that computer-extracted magnetic resonance (MR) image-based tumor phenotypes can be predictive of the molecular classification of invasive breast cancers. Radiomics analysis was performed on 91 MRIs of biopsy-proven invasive breast cancers from National Cancer Institute’s multi-institutional TCGA/TCIA. Immunohistochemistry molecular classification was performed including estrogen receptor. progesterone receptor. human epidermal growth factor receptor 2. and for 84 cases. the molecular subtype (normal-like. luminal A. luminal B. HER2-enriched. and basal-like). Computerized quantitative image analysis included: three-dimensional lesion segmentation. phenotype extraction. and leave-one-case-out cross validation involving stepwise feature selection and linear discriminant analysis. The performance of the classifier model for molecular subtyping was …,True,JfEMygUAAAAJ:_FxGoFyzp5QC,186,https://www.nature.com/articles/npjbcancer201612,3010184604224909030,/scholar?cites=3010184604224909030,,,https://www.nature.com/articles/npjbcancer201612,0,0,0
1281814,Basics of surface hopping in mixed quantum/classical simulations,1999,Karen Drukker,153,,2,225-272,Academic Press,This paper gives an overview of mixed quantum/classical simulation techniques based on the ideas of surface hopping (Tully. 1990). Basics such as the separation of a system into a classical and a quantum mechanical part are addressed. First. the Ehrenfest approach. which relies on a single-configuration approximation to the total wave function. is explained. Then an analogous multi-configurational approach. to which surface hopping is an approximation. is given. The surface hopping method developed by John Tully is explained in detail. Several other methods are summarized and applications are discussed briefly to illustrate the scope of these methods.,True,JfEMygUAAAAJ:CHSYGLWDkRkC,146,https://www.sciencedirect.com/science/article/pii/S0021999199962873,17330430068553890920,/scholar?cites=17330430068553890920,,,https://dl.acm.org/doi/abs/10.1006/jcph.1999.6287,0,0,0
1281815,Model simulations of DNA denaturation dynamics,2001,Karen Drukker and Guosheng Wu and George C Schatz,114,The Journal of Chemical Physics,1,579-590,American Institute of Physics,We present a model of DNA for use in computer simulations. This model is simple enough to allow long-time large-scale dynamics simulations. while. on the other hand. it is sophisticated enough to describe both double stranded and single stranded DNA and the transition between the two. We employed our simple model in the simulation of denaturation of double stranded DNA helices using Langevin dynamics. These are the first simulations of its kind of DNA denaturation. We have studied the melting behavior for several short double-stranded sequences of different composition. Duplexes of different lengths were considered. and also base pair mismatches were included in the study. Results are in good agreement with experimental data.,True,JfEMygUAAAAJ:lSLTfruPkqcC,142,https://aip.scitation.org/doi/abs/10.1063/1.1329137,13160979162321761022,/scholar?cites=13160979162321761022,,,,0,0,0
1281816,Computerized detection and classification of cancer on breast ultrasound1,2004,Karen Drukker and Maryellen L Giger and Carl J Vyborny and Ellen B Mendelson,11,Academic radiology,5,526-535,Elsevier,To develop and evaluate a two-stage computerized method that first detects suspicious regions on ultrasound images. and subsequently distinguishes among different lesion types.The first stage of detecting potential lesions was based on expected lesion shape and margin characteristics. After the detection stage. all candidate lesions were classified by a Bayesian neural net based on computer-extracted lesion features. Two separate tasks were performed and evaluated at the classification stage: the first classification task was the distinction between all actual lesions and false-positive detections; the second classification task was the distinction between actual cancer and all other detected lesion candidates (including false-positive detections). The neural nets were trained on a database of 400 cases (757 images). consisting of complex cysts and benign and …,True,JfEMygUAAAAJ:ULOm3_A8WrAC,133,https://www.sciencedirect.com/science/article/pii/S1076633203007232,4967843922649145253,/scholar?cites=4967843922649145253,,,,0,0,0
1281817,Exploring nonlinear feature space dimension reduction and data representation in breast CADx with Laplacian eigenmaps and‐SNE,2010,Andrew R Jamieson and Maryellen L Giger and Karen Drukker and Hui Li and Yading Yuan and Neha Bhooshan,37,Medical physics,1,339-351,American Association of Physicists in Medicine,In this preliminary study. recently developed unsupervised nonlinear dimension reduction (DR) and data representation techniques were applied to computer‐extracted breast lesion feature spaces across three separate imaging modalities: Ultrasound (U.S.) with 1126 cases. dynamic contrast enhanced magnetic resonance imaging with 356 cases. and full‐field digital mammography with 245 cases. Two methods for nonlinear DR were explored: Laplacian eigenmaps [M. Belkin and P. Niyogi. “Laplacian eigenmaps for dimensionality reduction and data representation.” Neural Comput. 15. 1373–1396 (2003)] and ‐distributed stochastic neighbor embedding (‐SNE) [L. van der Maaten and G. Hinton. “Visualizing data using t‐SNE.” J. Mach. Learn. Res. 9. 2579–2605 (2008)].These methods attempt to map originally high dimensional feature spaces to more human interpretable lower dimensional …,True,JfEMygUAAAAJ:35N4QoGY0k4C,128,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3267037,13375732203399453866,/scholar?cites=13375732203399453866,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2807447/,0,0,0
1281818,Noise injection for training artificial neural networks: A comparison with weight decay and early stopping,2009,Richard M Zur and Yulei Jiang and Lorenzo L Pesce and Karen Drukker,36,Medical physics,10,4810-4818,American Association of Physicists in Medicine,The purpose of this study was to investigate the effect of a noise injection method on the “overfitting” problem of artificial neural networks (ANNs) in two‐class classification tasks. The authors compared ANNs trained with noise injection to ANNs trained with two other methods for avoiding overfitting: weight decay and early stopping. They also evaluated an automatic algorithm for selecting the magnitude of the noise injection. They performed simulation studies of an exclusive‐or classification task with training datasets of 50. 100. and 200 cases (half normal and half abnormal) and an independent testing dataset of 2000 cases. They also compared the methods using a breast ultrasound dataset of 1126 cases. For simulated training datasets of 50 cases. the area under the receiver operating characteristic curve (AUC) was greater (by 0.03) when training with noise injection than when training without any regularization …,True,JfEMygUAAAAJ:xtRiw3GOFMkC,126,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3213517,17263834649910581810,/scholar?cites=17263834649910581810,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2771718/,0,0,0
1281819,Deciphering genomic underpinnings of quantitative MRI-based radiomic phenotypes of invasive breast carcinoma,2015,Yitan Zhu and Hui Li and Wentian Guo and Karen Drukker and Li Lan and Maryellen L Giger and Yuan Ji,5,Scientific reports,1,1-10,Nature Publishing Group,Magnetic Resonance Imaging (MRI) has been routinely used for the diagnosis and treatment of breast cancer. However. the relationship between the MRI tumor phenotypes and the underlying genetic mechanisms remains under-explored. We integrated multi-omics molecular data from The Cancer Genome Atlas (TCGA) with MRI data from The Cancer Imaging Archive (TCIA) for 91 breast invasive carcinomas. Quantitative MRI phenotypes of tumors (such as tumor size. shape. margin and blood flow kinetics) were associated with their corresponding molecular profiles (including DNA mutation. miRNA expression. protein expression. pathway gene expression and copy number variation). We found that transcriptional activities of various genetic pathways were positively associated with tumor size. blurred tumor margin and irregular tumor shape and that miRNA expressions were associated with the tumor size and …,True,JfEMygUAAAAJ:4DMP91E08xMC,110,https://www.nature.com/articles/srep17787,5482568774858715453,/scholar?cites=5482568774858715453,,,https://www.nature.com/articles/srep17787,0,0,0
1281820,Prediction of clinical phenotypes in invasive breast carcinomas from the integration of radiomics and genomics data,2015,Wentian Guo and Hui Li and Yitan Zhu and Li Lan and Shengjie Yang and Karen Drukker and Elizabeth A Morris and Elizabeth S Burnside and Gary J Whitman and Maryellen L Giger and Yuan Ji and TCGA Breast Phenotype Research Group,2,Journal of medical imaging,4,041007,International Society for Optics and Photonics,Genomic and radiomic imaging profiles of invasive breast carcinomas from The Cancer Genome Atlas and The Cancer Imaging Archive were integrated and a comprehensive analysis was conducted to predict clinical outcomes using the radiogenomic features. Variable selection via LASSO and logistic regression were used to select the most-predictive radiogenomic features for the clinical phenotypes. including pathological stage. lymph node metastasis. and status of estrogen receptor (ER). progesterone receptor (PR). and human epidermal growth factor receptor 2 (HER2). Cross-validation with receiver operating characteristic (ROC) analysis was performed and the area under the ROC curve (AUC) was employed as the prediction metric. Higher AUCs were obtained in the prediction of pathological stage. ER. and PR status than for lymph node metastasis and HER2 status. Overall. the prediction performances …,True,JfEMygUAAAAJ:d1gkVwhDpl0C,103,https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-2/issue-4/041007/Prediction-of-clinical-phenotypes-in-invasive-breast-carcinomas-from-the/10.1117/1.JMI.2.4.041007.short,207085193007707088,/scholar?cites=207085193007707088,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4718467/,0,0,0
1281821,Cvl-database: An off-line database for writer retrieval. writer identification and word spotting,2013,Florian Kleber and Stefan Fiel and Markus Diem and Robert Sablatnig,,,,560-564,IEEE,In this paper a public database for writer retrieval. writer identification and word spotting is presented. The CVL-Database consists of 7 different handwritten texts (1 German and 6 English Texts) and 311 different writers. For each text an RGB color image (300 dpi) comprising the handwritten text and the printed text sample are available as well as a cropped version (only handwritten). A unique ID identifies the writer. whereas the bounding boxes for each single word are stored in an XML file. An evaluation of the best algorithms of the ICDAR and ICHFR writer identification contest has been performed on the CVL-database.,True,2u2Lmr4AAAAJ:dhFuZR0502QC,119,https://ieeexplore.ieee.org/abstract/document/6628682/,2769125910546632581,/scholar?cites=2769125910546632581,,,https://www.researchgate.net/profile/Markus_Diem/publication/261282485_CVL-DataBase_An_Off-Line_Database_for_Writer_Retrieval_Writer_Identification_and_Word_Spotting/links/53e870c90cf21cc29fdc4981/CVL-DataBase-An-Off-Line-Database-for-Writer-Retrieval-Writer-Identification-and-Word-Spotting.pdf,0,0,0
1281822,3D MURALE: A multimedia system for archaeology,2001,John Cosmas and Take Itegaki and Damian Green and Edward Grabczewski and Fred Weimer and Luc Van Gool and Alexy Zalesny and Desi Vanrintel and Franz Leberl and Markus Grabner and Konrad Schindler and Konrad Karner and Michael Gervautz and Stefan Hynst and Marc Waelkens and Marc Pollefeys and Roland DeGeest and Robert Sablatnig and Martin Kampel,,,,297-306,,This paper introduces the 3D Measurement and Virtual Reconstruction of Ancient Lost Worlds of Europe system (3D MURALE). It consists of a set of tools for recording. reconstructing. encoding. visualising and database searching/querying that operate on buildings. building parts. statues. statue parts. pottery. stratigraphy. terrain geometry and texture and material texture. The tools are loosely linked together by a common database on which they all have the facility to store and access data. The paper describes the overall architecture of the 3D MURALE system and then briefly describes the functionality of the tools provided by the project. The paper compares the multimedia studio architecture adopted in this project with other multimedia studio architectures.,True,2u2Lmr4AAAAJ:u_35RYKgDlwC,102,https://dl.acm.org/doi/abs/10.1145/584993.585048,6589075850699644703,/scholar?cites=6589075850699644703,,,https://www.academia.edu/download/39278150/0912f510a79fe61cbb000000.pdf,0,0,0
1281823,Writer retrieval and writer identification using local features,2012,Stefan Fiel and Robert Sablatnig,,,,145-149,IEEE,Writer identification determines the writer of one document among a number of known writers where at least one sample is known. Writer retrieval searches all documents of one particular writer by creating a ranking of the similarity of the handwriting in a dataset. This paper presents a method for writer retrieval and writer identification using local features and therefore the proposed method is not dependent on a binarization step. First the local features of the image are calculated and with the help of a predefined codebook an occurrence histogram can be created. This histogram is compared to determine the identity of the writer or the similarity of other handwritten documents. The proposed method has been evaluated on two datasets. namely the IAM dataset which contains 650 writers and the Trigraph Slant dataset which contains 47 writers. Experiments have shown that it can keep up with previous writer …,True,2u2Lmr4AAAAJ:j3f4tGmQtD8C,90,https://ieeexplore.ieee.org/abstract/document/6195352/,4085287213184147559,/scholar?cites=4085287213184147559,,,https://www.researchgate.net/profile/Stefan_Fiel/publication/239762645_Writer_Retrieval_and_Writer_Identification_Using_Local_Features/links/54b7aad50cf2e68eb2803ac3.pdf,0,0,0
1281824,Writer identification and writer retrieval using the fisher vector on visual vocabularies,2013,Stefan Fiel and Robert Sablatnig,,,,545-549,IEEE,In this paper a method for writer identification and writer retrieval is presented. Writer identification is the task of identifying the writer of a document out of a database of known writers. In contrast to identification. writer retrieval is the task of finding documents in a database according to the similarity of handwritings. The approach presented in this paper uses local features for this task. First a vocabulary is calculated by clustering features using a Gaussian Mixture Model and applying the Fisher kernel. For each document image the features are calculated and the Fisher Vector is generated using the vocabulary. The distance of this vector is then used as similarity measurement for the handwriting and can be used for writer identification and writer retrieval. The proposed method is evaluated on two datasets. namely the ICDAR 2011 Writer Identification Contest dataset which consists of 208 documents from 26 writers …,True,2u2Lmr4AAAAJ:bFI3QPDXJZMC,87,https://ieeexplore.ieee.org/abstract/document/6628679/,7241289337509362083,/scholar?cites=7241289337509362083,,,https://www.researchgate.net/profile/Stefan_Fiel/publication/261282817_Writer_Identification_and_Writer_Retrieval_Using_the_Fisher_Vector_on_Visual_Vocabularies/links/55c44ea208aeca747d5fb71b.pdf,0,0,0
1281825,Hierarchical classification of paintings using face-and brush stroke models,1998,Robert Sablatnig and Paul Kammerer and Ernestine Zolda,1,,,172-174,IEEE,"It is often difficult to attribute works of art to a certain artist. In the case of paintings. radiological methods like X-ray and infra-red diagnosis. digital radiography. computer-tomography. etc. and color analyzes are employed to authenticate works of art. But all these methods do not relate certain characteristics of an art work to a specific artist-the artist's personal style. In order to study this personal style. we examine the ""structural signature"" based on brush strokes in particular in portrait miniatures. A computer-aided classification and recognition system for portrait miniatures is developed. which enables a semi-automatic classification based on brush strokes. A hierarchically structured classification scheme is introduced which separates the classification into three different levels of information: color. shape of region. and structure of brush strokes.",True,2u2Lmr4AAAAJ:_kc_bZDykSQC,85,https://ieeexplore.ieee.org/abstract/document/711107/,1986629192231029799,/scholar?cites=1986629192231029799,,,https://www.researchgate.net/profile/Robert_Sablatnig/publication/2857732_Hierarchical_Classification_of_Paintings_Using_Face-_and_Brush_Stroke_Models/links/00b4951e7f968ed73a000000/Hierarchical-Classification-of-Paintings-Using-Face-and-Brush-Stroke-Models.pdf,0,0,0
1281826,A novel image retrieval based on visual words integration of SIFT and SURF,2016,Nouman Ali and Khalid Bashir Bajwa and Robert Sablatnig and Savvas A Chatzichristofis and Zeshan Iqbal and Muhammad Rashid and Hafiz Adnan Habib,11,PloS one,6,e0157428,Public Library of Science,With the recent evolution of technology. the number of image archives has increased exponentially. In Content-Based Image Retrieval (CBIR). high-level visual information is represented in the form of low-level features. The semantic gap between the low-level features and the high-level image concepts is an open research problem. In this paper. we present a novel visual words integration of Scale Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF). The two local features representations are selected for image retrieval because SIFT is more robust to the change in scale and rotation. while SURF is robust to changes in illumination. The visual words integration of SIFT and SURF adds the robustness of both features to image retrieval. The qualitative and quantitative comparisons conducted on Corel-1000. Corel-1500. Corel-2000. Oliva and Torralba and Ground Truth image benchmarks demonstrate the effectiveness of the proposed visual words integration.,True,2u2Lmr4AAAAJ:MLfJN-KU85MC,79,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157428,16696614692136913360,/scholar?cites=16696614692136913360,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157428,0,0,0
1281827,Image retrieval by addition of spatial information based on histograms of triangular regions,2016,Nouman Ali and Khalid Bashir Bajwa and Robert Sablatnig and Zahid Mehmood,54,Computers & Electrical Engineering,,539-550,Pergamon,The compositional and content attributes of images carry information that enhances the performance of image retrieval. Standard images are constructed by following the rule of thirds that divides an image into nine equal parts by placing objects or regions of interest at the intersecting lines of the grid. An image represents regions and objects that are in a spatial semantic relationship with respect to each other. While the Bag of Features (BoF) representation is commonly used for image retrieval. it lacks spatial information. In this paper. we present two novel image representation methods based on the histograms of triangles. which add spatial information to the inverted index of BoF representation. Histograms of triangles are computed at two levels. by dividing an image into two and four triangles that are evaluated separately. Extensive experiments and comparisons conducted on two datasets demonstrate that the …,True,2u2Lmr4AAAAJ:5nxA0vEk-isC,66,https://www.sciencedirect.com/science/article/pii/S0045790616300726,1649765302735492808,/scholar?cites=1649765302735492808,,,https://www.academia.edu/download/46850910/J1.Image_retrieval_by_addition_of_spatial_information_based_on_histograms_of_triangular_regions.pdf,0,0,0
1281828,Writer identification and retrieval using a convolutional neural network,2015,Stefan Fiel and Robert Sablatnig,,,,26-37,Springer. Cham,In this paper a novel method for writer identification and retrieval is presented. Writer identification is the process of finding the author of a specific document by comparing it to documents in a database where writers are known. whereas retrieval is the task of finding similar handwritings or all documents of a specific writer. The method presented is using Convolutional Neural Networks (CNN) to generate a feature vector for each writer. which is then compared with the precalculated feature vectors stored in the database. For the generation of this vector the CNN is trained on a database with known writers and after training the classification layer is cut off and the output of the second last fully connected layer is used as feature vector. For the identification a nearest neighbor classification is used. The evaluation is performed on the ICDAR2013 Competition on Writer Identification. ICDAR 2011 Writer …,True,2u2Lmr4AAAAJ:dTyEYWd-f8wC,66,https://link.springer.com/chapter/10.1007/978-3-319-23117-4_3,11346642702228506136,/scholar?cites=11346642702228506136,,,https://www.researchgate.net/profile/Stefan_Fiel/publication/300474533_Writer_Identification_and_Retrieval_Using_a_Convolutional_Neural_Network/links/5787477408aec5c2e4e4aa6f/Writer-Identification-and-Retrieval-Using-a-Convolutional-Neural-Network.pdf,0,0,0
1281829,A robust SIFT descriptor for multispectral images,2014,Sajid Saleem and Robert Sablatnig,21,IEEE signal processing letters,4,400-403,IEEE,This letter presents a novel method for the description of multispectral image keypoints. The method proposed is based on a modified SIFT algorithm. It uses normalized gradients as local image features for the description of keypoints in order to achieve robustness against non linear intensity changes between multispectral images. The experimental results show that the method proposed achieves a better matching performance and outperforms the SIFT algorithm.,True,2u2Lmr4AAAAJ:yD5IFk8b50cC,64,https://ieeexplore.ieee.org/abstract/document/6730675/,6844507664596926192,/scholar?cites=6844507664596926192,,,,0,0,0
1281830,Binarization-free text line segmentation for historical documents based on interest point clustering,2012,Angelika Garz and Andreas Fischer and Robert Sablatnig and Horst Bunke,,,,95-99,IEEE,Segmenting page images into text lines is a crucial pre-processing step for automated reading of historical documents. Challenging issues in this open research field are given \eg by paper or parchment background noise. ink bleed-through. artifacts due to aging. stains. and touching text lines. In this paper. we present a novel binarization-free line segmentation method that is robust to noise and copes with overlapping and touching text lines. First. interest points representing parts of characters are extracted from gray-scale images. Next. word clusters are identified in high-density regions and touching components such as ascenders and descenders are separated using seam carving. Finally. text lines are generated by concatenating neighboring word clusters. where neighborhood is defined by the prevailing orientation of the words in the document. An experimental evaluation on the Latin manuscript images of …,True,2u2Lmr4AAAAJ:evX43VCCuoAC,64,https://ieeexplore.ieee.org/abstract/document/6195342/,13697231180141045135,/scholar?cites=13697231180141045135,,,https://www.researchgate.net/profile/Angelika_Garz/publication/259346224_Binarization-Free_Text_Line_Segmentation_for_Historical_Documents_Based_on_Interest_Point_Clustering/links/5513c17e0cf283ee08348ebd.pdf,0,0,0
1281831,Icdar 2013 competition on handwritten digit recognition (hdrc 2013),2013,Markus Diem and Stefan Fiel and Angelika Garz and Manuel Keglevic and Florian Kleber and Robert Sablatnig,,,,1422-1427,IEEE,This paper presents the results of the HDRC 2013 competition for recognition of handwritten digits organized in conjunction with ICDAR 2013. The general objective of this competition is to identify. evaluate and compare recent developments in character recognition and to introduce a new challenging dataset for benchmarking. We describe competition details including dataset and evaluation measures used. and give a comparative performance analysis of the nine (9) submitted methods along with a short description of the respective methodologies.,True,2u2Lmr4AAAAJ:aqlVkmm33-oC,61,https://ieeexplore.ieee.org/abstract/document/6628848/,2222918704002165403,/scholar?cites=2222918704002165403,,,https://www.academia.edu/download/50863191/ICDAR_2013_Competition_on_Handwritten_Di20161213-9261-2asy5n.pdf,0,0,0
1281832,Gated Graph Sequence Neural Networks,2016,Yujia Li and Daniel Tarlow and Marc Brockschmidt and Richard Zemel,,,,,,Graph-structured data appears frequently in domains including chemistry. natural language semantics. social networks. and knowledge bases. In this work. we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al.. 2009). which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (eg. LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification. in which subgraphs need to be matched to abstract data structures.,True,pF27eLMAAAAJ:LPZeul_q3PIC,1504,https://arxiv.org/abs/1511.05493,16266567510296342081,/scholar?cites=16266567510296342081,,,https://arxiv.org/pdf/1511.05493,0,0,0
1281833,DeepCoder: Learning to Write Programs,2017,Matej Balog and Alexander L Gaunt and Marc Brockschmidt and Sebastian Nowozin and Daniel Tarlow,,,,,,We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community. including enumerative search and an SMT-based solver. Empirically. we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach. and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.,True,pF27eLMAAAAJ:5ugPr518TE4C,354,https://arxiv.org/abs/1611.01989,14663434925594619820,/scholar?cites=14663434925594619820,,,https://arxiv.org/pdf/1611.01989,0,0,0
1281834,Learning to Represent Programs with Graphs,2018,Miltiadis Allamanis and Marc Brockschmidt and Mahmoud Khademi,,,,,,Learning tasks on source code (ie. formal languages) have been considered recently. but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example. long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.In this work. we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming. in which a network attempts to predict the name of a variable given its usage. and VarMisuse. in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure. and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally. our testing showed that VarMisuse identifies a number of bugs in mature open-source projects.,True,pF27eLMAAAAJ:JoZmwDi-zQgC,308,https://arxiv.org/abs/1711.00740,9342740598325165289,/scholar?cites=9342740598325165289,,,https://arxiv.org/pdf/1711.00740,0,0,0
1281835,Constrained Graph Variational Autoencoders for Molecule Design,2018,Qi Liu and Miltiadis Allamanis and Marc Brockschmidt and Alexander L Gaunt,,,,,,Graphs are ubiquitous data structures for representing interactions between entities. With an emphasis on the use of graphs to represent chemical molecules. we explore the task of learning to generate graphs that conform to a distribution observed in training data. We propose a variational autoencoder model in which both encoder and decoder are graph-structured. Our decoder assumes a sequential ordering of graph extension steps and we discuss and analyze design choices that mitigate the potential downsides of this linearization. Experiments compare our approach with a wide range of baselines on the molecule generation task and show that our method is more successful at matching the statistics of the original dataset on semantically important metrics. Furthermore. we show that by using appropriate shaping of the latent space. our model allows us to design molecules that are (locally) optimal in desired properties.,True,pF27eLMAAAAJ:eq2jaN3J8jMC,160,https://arxiv.org/abs/1805.09076,2838800553083041205,/scholar?cites=2838800553083041205,,,https://arxiv.org/pdf/1805.09076,0,0,0
1281836,TerpreT: A Probabilistic Programming Language for Program Induction,2016,Alexander L Gaunt and Marc Brockschmidt and Rishabh Singh and Nate Kushman and Pushmeet Kohli and Jonathan Taylor and Daniel Tarlow,,arXiv preprint arXiv:1608.04428,,,,We study machine learning formulations of inductive program synthesis; given input-output examples. we try to synthesize source code that maps inputs to corresponding outputs. Our aims are to develop new machine learning approaches based on neural networks and graphical models. and to understand the capabilities of machine learning techniques relative to traditional alternatives. such as those based on constraint solving from the programming languages community.Our key contribution is the proposal of TerpreT. a domain-specific language for expressing program synthesis problems. TerpreT is similar to a probabilistic programming language: a model is composed of a specification of a program representation (declarations of random variables) and an interpreter describing how programs map inputs to outputs (a model connecting unknowns to observations). The inference task is to observe a set of input-output examples and infer the underlying program. TerpreT has two main benefits. First. it enables rapid exploration of a range of domains. program representations. and interpreter models. Second. it separates the model specification from the inference algorithm. allowing like-to-like comparisons between different approaches to inference. From a single TerpreT specification we automatically perform inference using four different back-ends. These are based on gradient descent. linear program (LP) relaxations for graphical models. discrete satisfiability solving. and the Sketch program synthesis system.,True,pF27eLMAAAAJ:q3oQSFYPqjQC,102,https://arxiv.org/abs/1608.04428,6805431752667743477,/scholar?cites=6805431752667743477,,,https://arxiv.org/pdf/1608.04428,0,0,0
1281837,Proving termination of programs automatically with AProVE,2014,J Giesl and M Brockschmidt and F Emmes and F Frohn and C Fuhs and C Otto and M Plücker and P Schneider-Kamp and T Ströder and S Swiderski and R Thiemann,,,,184 - 191,Springer, AProVE is a system for automatic termination and complexity proofs of Java. C. Haskell. Prolog. and term rewrite systems (TRSs). To analyze programs in high-level languages. AProVE automatically converts them to TRSs. Then. a wide range of techniques is employed to prove termination and to infer complexity bounds for the resulting TRSs. The generated proofs can be exported to check their correctness using automatic certifiers. For use in software construction. we present an AProVE plug-in for the popular Eclipse software development environment.,True,pF27eLMAAAAJ:l7t_Zn2s7bgC,97,https://link.springer.com/chapter/10.1007/978-3-319-08587-6_13,15100212302988204861,/scholar?cites=15100212302988204861,,,https://eprints.bbk.ac.uk/id/eprint/13531/1/IJCAR14-aprove-tool.pdf,0,0,0
1281838,Analyzing program termination and complexity automatically with AProVE,2017,Jürgen Giesl and Cornelius Aschermann and Marc Brockschmidt and Fabian Emmes and Florian Frohn and Carsten Fuhs and Jera Hensel and Carsten Otto and Martin Plücker and Peter Schneider-Kamp and Thomas Ströder and Stephanie Swiderski and René Thiemann,58,Journal of Automated Reasoning,1,3-31,Springer Netherlands,In this system description. we present the tool AProVE for automatic termination and complexity proofs of Java. C. Haskell. Prolog. and rewrite systems. In addition to classical term rewrite systems (TRSs). AProVE also supports rewrite systems containing built-in integers (int-TRSs). To analyze programs in high-level languages. AProVE automatically converts them to (int-)TRSs. Then. a wide range of techniques is employed to prove termination and to infer complexity bounds for the resulting rewrite systems. The generated proofs can be exported to check their correctness using automatic certifiers. To use AProVE in software construction. we present a corresponding plug-in for the popular Eclipse software development environment.,True,pF27eLMAAAAJ:V3AGJWp-ZtQC,95,https://link.springer.com/content/pdf/10.1007/s10817-016-9388-y.pdf,2849035098364457423,/scholar?cites=2849035098364457423,,,https://eprints.bbk.ac.uk/16551/1/JAR-AProVE.pdf,0,0,0
1281839,Automated termination analysis of Java Bytecode by term rewriting,2010,Carsten Otto and Marc Brockschmidt and Christian Von Essen and Jurgen Giesl,,,,259-276,LIPIcs,We present an automated approach to prove termination of Java Bytecode (JBC) programs by automatically transforming them to term rewrite systems (TRSs). In this way. the numerous techniques and tools developed for TRS termination can now be used for imperative object-oriented languages like Java. which can be compiled into JBC.,True,pF27eLMAAAAJ:u5HHmVD_uO8C,91,https://drops.dagstuhl.de/opus/volltexte/2010/2657/,17673421805333684644,/scholar?cites=17673421805333684644,,,https://drops.dagstuhl.de/volltexte/2010/2657/pdf/10002.OttoCarsten.2657.pdf,0,0,0
1281840,Better termination proving through cooperation,2013,Marc Brockschmidt and Byron Cook and Carsten Fuhs,,,,413-429,Springer Berlin Heidelberg,One of the difficulties of proving program termination is managing the subtle interplay between the finding of a termination argument and the finding of the argument’s supporting invariant. In this paper we propose a new mechanism that facilitates better cooperation between these two types of reasoning. In an experimental evaluation we find that our new method leads to dramatic performance improvements.,True,pF27eLMAAAAJ:Y0pCki6q_DkC,88,https://link.springer.com/chapter/10.1007/978-3-642-39799-8_28,172458281618087603,/scholar?cites=172458281618087603,,,https://link.springer.com/content/pdf/10.1007/978-3-642-39799-8_28.pdf,0,0,0
1281841,Alternating runtime and size complexity analysis of integer programs,2014,Marc Brockschmidt and Fabian Emmes and Stephan Falke and Carsten Fuhs and Jürgen Giesl,,,,140-155,Springer Berlin Heidelberg,We present a modular approach to automatic complexity analysis. Based on a novel alternation between finding symbolic time bounds for program parts and using these to infer size bounds on program variables. we can restrict each analysis step to a small part of the program while maintaining a high level of precision. Extensive experiments with the implementation of our method demonstrate its performance and power in comparison with other tools.,True,pF27eLMAAAAJ:mvPsJ3kp5DgC,76,https://link.springer.com/chapter/10.1007/978-3-642-54862-8_10,3895270542134637498,/scholar?cites=3895270542134637498,,,https://link.springer.com/content/pdf/10.1007/978-3-642-54862-8_10.pdf,0,0,0
1281842,Generative Code Modeling with Graphs,2019,Marc Brockschmidt and Miltiadis Allamanis and Alexander L Gaunt and Oleksandr Polozov,,,,,,Generative models for source code are an interesting structured prediction problem. requiring to reason about both hard syntactic and semantic constraints as well as about natural. likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. The generative procedure interleaves grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions. outperforming a range of strong baselines.,True,pF27eLMAAAAJ:5awf1xo2G04C,75,https://arxiv.org/abs/1805.08490,2376600485661149991,/scholar?cites=2376600485661149991,,,https://arxiv.org/pdf/1805.08490,0,0,0
1281843,Fast-Classifying. High-Accuracy Spiking Deep Networks Through Weight and Threshold Balancing,2015,Peter U Diehl and Daniel Neil and Jonathan Binas and Matthew Cook and Shih-Chii Liu and Michael Pfeiffer,,,,,,Deep neural networks such as Convolutional Networks (ConvNets) and Deep Belief Networks (DBNs) represent the state-of-the-art for many machine learning and computer vision classification problems. To overcome the large computational cost of deep networks. spiking deep networks have recently been proposed. given the specialized hardware now available for spiking neural networks (SNNs). However. this has come at the cost of performance losses due to the conversion from analog neural networks (ANNs) without a notion of time. to sparsely firing. event-driven SNNs. Here we analyze the effects of converting deep ANNs into SNNs with respect to the choice of parameters for spiking neurons such as firing rates and thresholds. We present a set of optimization techniques to minimize performance loss in the conversion process for ConvNets and fully connected deep networks. These techniques yield …,True,jDE5tIQAAAAJ:kzcSZmkxUKAC,497,https://ieeexplore.ieee.org/abstract/document/7280696/,688816531886309323,/scholar?cites=688816531886309323,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.721.2413&rep=rep1&type=pdf,0,0,0
1281844,Training deep spiking neural networks using backpropagation,2016,Jun Haeng Lee and Tobi Delbruck and Michael Pfeiffer,10,Frontiers in neuroscience,,508,Frontiers,Deep spiking neural networks (SNNs) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However. training such networks is difficult due to the non-differentiable nature of spike events. In this paper. we introduce a novel technique. which treats the membrane potentials of spiking neurons as differentiable signals. where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep SNNs that follows the same principles as in conventional deep networks. but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion. our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original MNIST handwritten digit benchmark. and also on the N-MNIST benchmark recorded with an event-based dynamic vision sensor. in which the proposed method reduces the error rate by a factor of more than three compared to the best previous SNN. and also achieves a higher accuracy than a conventional convolutional neural network (CNN) trained and tested on the same data. We demonstrate in the context of the MNIST task that thanks to their event-driven operation. deep SNNs (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-MNIST example. equivalent accuracy is achieved with about five times fewer computational operations.,True,jDE5tIQAAAAJ:UuEBAcK4md4C,440,https://www.frontiersin.org/articles/10.3389/fnins.2016.00508/full,3302134536928722056,/scholar?cites=3302134536928722056,,,https://www.frontiersin.org/articles/10.3389/fnins.2016.00508/full,0,0,0
1281845,Real-time classification and sensor fusion with a spiking deep belief network,2013,Peter O'Connor and Daniel Neil and Shih-Chii Liu and Tobi Delbruck and Michael Pfeiffer,7,Frontiers in neuroscience,,178,Frontiers,Deep Belief Networks (DBNs) have recently shown impressive performance on a broad range of classification problems. Their generative properties allow better understanding of the performance. and provide a simpler solution for sensor fusion tasks. However. because of their inherent need for feedback and parallel update of large numbers of units. DBNs are expensive to implement on serial computers. This paper proposes a method based on the Siegert approximation for Integrate-and-Fire neurons to map an offline-trained DBN onto an efficient event-driven spiking neural network suitable for hardware implementation. The method is demonstrated in simulation and by a real-time implementation of a 3-layer network with 2694 neurons used for visual classification of MNIST handwritten digits with input from a 128x128 Dynamic Vision Sensor (DVS) silicon retina. and sensory-fusion using additional input from a 64-channel AER-EAR silicon cochlea. The system is implemented through the open-source software in the jAER project and runs in real-time on a laptop computer. It is demonstrated that the system can recognize digits in the presence of distractions. noise. scaling. translation and rotation. and that the degradation of recognition performance by using an event-based approach is less than 1%. Recognition is achieved in an average of 5.8 ms after the onset of the presentation of a digit. By cue integration from both silicon retina and cochlea outputs we show that the system can be biased to select the correct digit from otherwise ambiguous input.,True,jDE5tIQAAAAJ:kNdYIx-mwKoC,387,https://www.frontiersin.org/articles/10.3389/fnins.2013.00178/full,7776536154562292662,/scholar?cites=7776536154562292662,,,https://www.frontiersin.org/articles/10.3389/fnins.2013.00178/full,0,0,0
1281846,Gland segmentation in colon histology images: The glas challenge contest,2017,Korsuk Sirinukunwattana and Josien PW Pluim and Hao Chen and Xiaojuan Qi and Pheng-Ann Heng and Yun Bo Guo and Li Yang Wang and Bogdan J Matuszewski and Elia Bruni and Urko Sanchez and Anton Böhm and Olaf Ronneberger and Bassem Ben Cheikh and Daniel Racoceanu and Philipp Kainz and Michael Pfeiffer and Martin Urschler and David RJ Snead and Nasir M Rajpoot,35,,,489-502,Elsevier,Colorectal adenocarcinoma originating in intestinal glandular structures is the most common form of colon cancer. In clinical practice. the morphology of intestinal glands. including architectural appearance and glandular formation. is used by pathologists to inform prognosis and plan the treatment of individual patients. However. achieving good inter-observer as well as intra-observer reproducibility of cancer grading is still a major challenge in modern pathology. An automated approach which quantifies the morphology of glands is a solution to the problem.This paper provides an overview to the Gland Segmentation in Colon Histology Images Challenge Contest (GlaS) held at MICCAI’2015. Details of the challenge. including organization. dataset and evaluation criteria. are presented. along with the method descriptions and evaluation results from the top performing methods.,True,jDE5tIQAAAAJ:wvYxNZNCP7wC,296,https://www.sciencedirect.com/science/article/pii/S1361841516301542,8655089526173907291,/scholar?cites=8655089526173907291,,,https://arxiv.org/pdf/1603.00275,0,0,0
1281847,Phased LSTM: Accelerating recurrent network training for long or event-based sequences,2016,Daniel Neil and Michael Pfeiffer and Shih-Chii Liu,,,,3882-3890,,Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However. current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur. for example. when the input comes from novel event-driven artificial sensors that generate sparse. asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work. we introduce the Phased LSTM model. which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation. the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates. thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications. and does so with an order-of-magnitude fewer computes at runtime.,True,jDE5tIQAAAAJ:g5Ck-dwhA_QC,277,https://arxiv.org/abs/1610.09513,4526199262641685887,/scholar?cites=4526199262641685887,,,https://arxiv.org/pdf/1610.09513,0,0,0
1281848,Conversion of continuous-valued deep networks to efficient event-driven networks for image classification,2017,Bodo Rueckauer and Iulia-Alexandra Lungu and Yuhuang Hu and Michael Pfeiffer and Shih-Chii Liu,11,Frontiers in neuroscience,,682,Frontiers,Spiking neural networks (SNNs) can potentially offer an efficient way of doing inference because the neurons in the networks are sparsely activated and computations are event-driven. Previous work showed that simple continuous-valued deep Convolutional Neural Networks (CNNs) can be converted into accurate spiking equivalents. These networks did not include certain common operations such as max-pooling. softmax. batch-normalization and Inception-modules. This paper presents spiking equivalents of these operations therefore allowing conversion of nearly arbitrary CNN architectures. We show conversion of popular CNN architectures. including VGG-16 and Inception-v3. into SNNs that produce the best results reported to date on MNIST. CIFAR-10 and the challenging ImageNet dataset. SNNs can trade off classification error rate against the number of available operations whereas deep continuous-valued neural networks require a fixed number of operations to achieve their classification error rate. From the examples of LeNet for MNIST and BinaryNet for CIFAR-10. we show that with an increase in error rate of a few percentage points. the SNNs can achieve more than 2x reductions in operations compared to the original CNNs. This highlights the potential of SNNs in particular when deployed on power-efficient neuromorphic spiking neuron chips. for use in embedded applications.,True,jDE5tIQAAAAJ:T_ojBgVMvoEC,251,https://www.frontiersin.org/articles/10.3389/fnins.2017.00682/full?report=reader,1731281762360810685,/scholar?cites=1731281762360810685,,,https://www.frontiersin.org/articles/10.3389/fnins.2017.00682/full?report=reader,0,0,0
1281849,Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity,2013,Bernhard Nessler and Michael Pfeiffer and Lars Büsing and Wolfgang Maass,9,PLoS Computational Biology,4,e1003037,,The principles by which networks of neurons compute. and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function. are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits. where pyramidal neurons inhibit each other via interneurons. are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact. a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability. since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.,True,jDE5tIQAAAAJ:8k81kl-MbHgC,251,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037,3083406410349944661,/scholar?cites=3083406410349944661,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037,0,0,0
1281850,Deep learning with spiking neurons: opportunities and challenges,2018,Michael Pfeiffer and Thomas Pfeil,12,,,774,Frontiers,Spiking neural networks (SNNs) are inspired by information processing in biology. where sparse and asynchronous binary signals are communicated and processed in a massively parallel fashion. SNNs on neuromorphic hardware exhibit favorable properties such as low power consumption. fast inference. and event-driven information processing. This makes them interesting candidates for the efficient implementation of deep neural networks. the method of choice for many machine learning tasks. In this review. we address the opportunities that deep spiking networks offer and investigate in detail the challenges associated with training SNNs in a way that makes them competitive with conventional deep learning. but simultaneously allows for efficient mapping to hardware. A wide range of training methods for SNNs is presented. ranging from the conversion of conventional deep networks into SNNs. constrained training before conversion. spiking variants of backpropagation. and biologically motivated variants of STDP. The goal of our review is to define a categorization of SNN training methods. and summarize their advantages and drawbacks. We further discuss relationships between SNNs and binary networks. which are becoming popular for efficient digital hardware implementation. Neuromorphic hardware platforms have great potential to enable deep spiking networks in real-world applications. We compare the suitability of various neuromorphic systems that have been developed over the past years. and investigate potential use cases. Neuromorphic approaches and conventional machine learning should not be considered simply two …,True,jDE5tIQAAAAJ:AzKEL7Gb_04C,194,https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full,14311483343205934728,/scholar?cites=14311483343205934728,,,https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full,0,0,0
1281851,STDP enables spiking neurons to detect hidden causes of their inputs,2009,Bernhard Nessler and Michael Pfeiffer and Wolfgang Maass,22,Advances in neural information processing systems,,1357-1365,,The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits. and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain this computational function. are unknown. We show here that STDP. in conjunction with a stochastic soft winner-take-all (WTA) circuit. induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or “causes”) of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits. a common network motif of cortical microcircuits. could therefore be a drastic dimensionality reduction of information streams. together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular. we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.,True,jDE5tIQAAAAJ:u-x6o8ySG0sC,113,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.690.4283&rep=rep1&type=pdf,16972082276322574792,/scholar?cites=16972082276322574792,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.690.4283&rep=rep1&type=pdf,0,0,0
1281852,Robustness of spiking deep belief networks to noise and reduced bit precision of neuro-inspired hardware platforms,2015,Evangelos Stromatias and Daniel Neil and Michael Pfeiffer and Francesco Galluppi and Steve B Furber and Shih-Chii Liu,9,Frontiers in neuroscience,,222,Frontiers,Increasingly large deep learning architectures. such as Deep Belief Networks (DBNs) are the focus of current machine learning research and achieve state-of-the-art results in different domains. However. both training and execution of large-scale Deep Networks requires vast computing resources. leading to high power requirements and communication overheads. The on-going work on design and construction of spike-based hardware platforms offers an alternative for running deep neural networks with significantly lower power consumption. but has to overcome hardware limitations in terms of noise and limited weight precision. as well as noise inherent in the sensor signal. This article investigates how such hardware constraints impact the performance of spiking neural network implementations of DBNs. In particular. the influence of limited bit precision during execution and training. and the impact of silicon mismatch in the synaptic weight parameters of custom hybrid VLSI implementations is studied. Furthermore. the network performance of spiking DBNs is characterized with regard to noise in the spiking input signal. Our results demonstrate that spiking DBNs can tolerate very low levels of hardware bit precision down to almost 2 bits. and shows that their performance can be improved by at least 30\% through an adapted training mechanism that takes the bit precision of the target platform into account. Spiking DBNs thus present an important use-case for large-scale hybrid analog-digital or digital neuromorphic platforms such as SpiNNaker. which can execute large but precision-constrained deep networks in real time.,True,jDE5tIQAAAAJ:eO3_k5sD8BwC,91,https://www.frontiersin.org/articles/10.3389/fnins.2015.00222/full,1573327826896131730,/scholar?cites=1573327826896131730,,,https://www.frontiersin.org/articles/10.3389/fnins.2015.00222/full,0,0,0
1281853,Scalable Energy-Efficient. Low-Latency Implementations of Spiking Deep Belief Networks on SpiNNaker,2015,Evangelos Stromatias and Daniel Neil and Michael Pfeiffer and Francesco Galluppi and Steve Furber and Shih-Chii Liu,,,,,,,True,jDE5tIQAAAAJ:69ZgNCALVd0C,65,,14699372684877997266,/scholar?cites=14699372684877997266,,,,0,0,0
1281854,Voice activity detection based on multiple statistical models,2006,Joon-Hyuk Chang and Nam Soo Kim and Sanjit K Mitra,54,IEEE Transactions on Signal Processing,6,1965-1976,IEEE,One of the key issues in practical speech processing is to achieve robust voice activity detection (VAD) against the background noise. Most of the statistical model-based approaches have tried to employ the Gaussian assumption in the discrete Fourier transform (DFT) domain. which. however. deviates from the real observation. In this paper. we propose a class of VAD algorithms based on several statistical models. In addition to the Gaussian model. we also incorporate the complex Laplacian and Gamma probability density functions to our analysis of statistical properties. With a goodness-of-fit tests. we analyze the statistical properties of the DFT spectra of the noisy speech under various noise conditions. Based on the statistical analysis. the likelihood ratio test under the given statistical models is established for the purpose of VAD. Since the statistical characteristics of the speech signal are differently affected by …,True,uWYsEdUAAAAJ:u5HHmVD_uO8C,286,https://ieeexplore.ieee.org/abstract/document/1634796/,8115629017530552269,/scholar?cites=8115629017530552269,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.456.7610&rep=rep1&type=pdf,0,0,0
1281855,Spectral enhancement based on global soft decision,2000,Nam Soo Kim and Joon-Hyuk Chang,7,IEEE Signal processing letters,5,108-110,IEEE,In this letter. we propose a novel speech enhancement technique based on global soft decision. The proposed approach provides a unified framework for such procedures as speech absence probability (SAP) computation. spectral gain modification. and noise spectrum estimation using the same statistical model assumption. Performances of the proposed enhancement algorithm are evaluated by subjective tests under various environments and show better results compared with the IS-127 standard enhancement method.,True,uWYsEdUAAAAJ:u-x6o8ySG0sC,242,https://ieeexplore.ieee.org/abstract/document/841154/,7355562352335713499,/scholar?cites=7355562352335713499,,,,0,0,0
1281856,Statistical modeling of speech signals based on generalized gamma distribution,2005,Jong Won Shin and Joon-Hyuk Chang and Nam Soo Kim,12,IEEE Signal Processing Letters,3,258-261,IEEE,In this letter. we propose a new statistical model. two-sided generalized gamma distribution (G/spl Gamma/D) for an efficient parametric characterization of speech spectra. G/spl Gamma/D forms a generalized class of parametric distributions. including the Gaussian. Laplacian. and Gamma probability density functions (pdfs) as special cases. We also propose a computationally inexpensive online maximum likelihood (ML) parameter estimation algorithm for G/spl Gamma/D. Likelihoods. coefficients of variation (CVs). and Kolmogorov-Smirnov (KS) tests show that G/spl Gamma/D can model the distribution of the real speech signal more accurately than the conventional Gaussian. Laplacian. Gamma. or generalized Gaussian distribution (GGD).,True,uWYsEdUAAAAJ:d1gkVwhDpl0C,125,https://ieeexplore.ieee.org/abstract/document/1395954/,5549949286592545772,/scholar?cites=5549949286592545772,,,https://sapl.gist.ac.kr/wp-content/uploads/2017/01/Statistical-modeling-of-speech-signals-based-on-generalized-gamma-distribution.pdf,0,0,0
1281857,Voice activity detection based on statistical models and machine learning approaches,2010,Jong Won Shin and Joon-Hyuk Chang and Nam Soo Kim,24,Computer Speech & Language,3,515-530,Academic Press,The voice activity detectors (VADs) based on statistical models have shown impressive performances especially when fairly precise statistical models are employed. Moreover. the accuracy of the VAD utilizing statistical models can be significantly improved when machine-learning techniques are adopted to provide prior knowledge for speech characteristics. In the first part of this paper. we introduce a more accurate and flexible statistical model. the generalized gamma distribution (GΓD) as a new model in the VAD based on the likelihood ratio test. In practice. parameter estimation algorithm based on maximum likelihood principle is also presented. Experimental results show that the VAD algorithm implemented based on GΓD outperform those adopting the conventional Laplacian and Gamma distributions. In the second part of this paper. we introduce machine learning techniques such as a minimum classification …,True,uWYsEdUAAAAJ:zYLM7Y9cAGgC,112,https://www.sciencedirect.com/science/article/pii/S0885230809000072,6798584929613935127,/scholar?cites=6798584929613935127,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.455.7881&rep=rep1&type=pdf,0,0,0
1281858,Removal of N‐terminal methionine from recombinant proteins by engineered E. coli methionine aminopeptidase,2004,You‐Di Liao and Jen‐Chong Jeng and Chiu‐Feng Wang and Sui‐Chi Wang and Shu‐Ting Chang,13,Protein Science,7,1802-1810,Cold Spring Harbor Laboratory Press,The removal of N‐terminal translation initiator Met by methionine aminopeptidase (MetAP) is often crucial for the function and stability of proteins. On the basis of crystal structure and sequence alignment of MetAPs. we have engineered Escherichia coli MetAP by the mutation of three residues. Y168G. M206T. Q233G. in the substrate‐binding pocket. Our engineered MetAPs are able to remove the Met from bulky or acidic penultimate residues. such as Met. His. Asp. Asn. Glu. Gln. Leu. Ile. Tyr. and Trp. as well as from small residues. The penultimate residue. the second residue after Met. was further removed if the antepenultimate residue. the third residue after Met. was small. By the coexpression of engineered MetAP in E. coli through the same or a separate vector. we have successfully produced recombinant proteins possessing an innate N terminus. such as onconase. an antitumor ribonuclease from the frog …,True,uWYsEdUAAAAJ:-ZoC36zw86wC,99,https://onlinelibrary.wiley.com/doi/abs/10.1110/ps.04679104,3554738693842101163,/scholar?cites=3554738693842101163,,,https://onlinelibrary.wiley.com/doi/pdf/10.1110/ps.04679104,0,0,0
1281859,Drosophila Muller F Elements Maintain a Distinct Set of Genomic Properties Over 40 Million Years of Evolution,2015,Wilson Leung and Christopher D Shaffer and Laura K Reed and Sheryl T Smith and William Barshop and William Dirkes and Matthew Dothager and Paul Lee and Jeannette Wong and David Xiong and Han Yuan and James EJ Bedard and Joshua F Machone and Seantay D Patterson and Amber L Price and Bryce A Turner and Srebrenka Robic and Erin K Luippold and Shannon R McCartha and Tezin A Walji and Chelsea A Walker and Kenneth Saville and Marita K Abrams and Andrew R Armstrong and William Armstrong and Robert J Bailey and Chelsea R Barberi and Lauren R Beck and Amanda L Blaker and Christopher E Blunden and Jordan P Brand and Ethan J Brock and Dana W Brooks and Marie Brown and Sarah C Butzler and Eric M Clark and Nicole B Clark and Ashley A Collins and Rebecca J Cotteleer and Peterson R Cullimore and Seth G Dawson and Carter T Docking and Sasha L Dorsett and Grace A Dougherty and Kaitlyn A Downey and Andrew P Drake and Erica K Earl and Trevor G Floyd and Joshua D Forsyth and Jonathan D Foust and Spencer L Franchi and James F Geary and Cynthia K Hanson and Taylor S Harding and Cameron B Harris and Jonathan M Heckman and Heather L Holderness and Nicole A Howey and Dontae A Jacobs and Elizabeth S Jewell and Maria Kaisler and Elizabeth A Karaska and James L Kehoe and Hannah C Koaches and Jessica Koehler and Dana Koenig and Alexander J Kujawski and Jordan E Kus and Jennifer A Lammers and Rachel R Leads and Emily C Leatherman and Rachel N Lippert and Gregory S Messenger and Adam T Morrow and Victoria Newcomb and Haley J Plasman and Stephanie J Potocny and Michelle K Powers and Rachel M Reem and Jonathan P Rennhack and Katherine R Reynolds and Lyndsey A Reynolds and Dong K Rhee and Allyson B Rivard and Adam J Ronk and Meghan B Rooney and Lainey S Rubin and Luke R Salbert and Rasleen K Saluja and Taylor Schauder and Allison R Schneiter and Robert W Schulz and Karl E Smith and Sarah Spencer and Bryant R Swanson and Melissa A Tache and Ashley A Tewilliager and Amanda K Tilot and Eve VanEck and Matthew M Villerot and Megan B Vylonis and David T Watson and Juliana A Wurzler and Lauren M Wysocki and Monica Yalamanchili and Matthew A Zaborowicz and Julia A Emerson and Carlos Ortiz and Frederic J Deuschle and Lauren A DiLorenzo and Katie L Goeller and Christopher R Macchi and Sarah E Muller and Brittany D Pasierb and Joseph E Sable and Jessica M Tucci and Marykathryn Tynon and David A Dunbar and Levent H Beken and Alaina C Conturso and Benjamin L Danner and Gabriella A DeMichele and Justin A Gonzales and Maureen S Hammond and Colleen V Kelley and Elisabeth A Kelly and Danielle Kulich and Catherine M Mageeney and Nikie L McCabe and Alyssa M Newman and Lindsay A Spaeder and Richard A Tumminello and Dennis Revie and Jonathon M Benson and Michael C Cristostomo and Paolo A DaSilva and Katherine S Harker and Jenifer N Jarrell and Luis A Jimenez and Brandon M Katz and William R Kennedy and Kimberly S Kolibas and Mark T LeBlanc and Trung T Nguyen and Daniel S Nicolas and Melissa D Patao and Shane M Patao and Bryan J Rupley and Bridget J Sessions and Jennifer A Weaver,5,"G3: Genes, Genomes, Genetics",5,719-740,Oxford University Press,The Muller F element (4.2 Mb. ~80 protein-coding genes) is an unusual autosome of Drosophila melanogaster; it is mostly heterochromatic with a low recombination rate. To investigate how these properties impact the evolution of repeats and genes. we manually improved the sequence and annotated the genes on the D. erecta. D. mojavensis. and D. grimshawi F elements and euchromatic domains from the Muller D element. We find that F elements have greater transposon density (25–50%) than euchromatic reference regions (3–11%). Among the F elements. D. grimshawi has the lowest transposon density (particularly DINE-1: 2% vs. 11–27%). F element genes have larger coding spans. more coding exons. larger introns. and lower codon bias. Comparison of the Effective Number of Codons with the Codon Adaptation Index shows that. in contrast to the other species. codon bias in D. grimshawi F element …,True,uWYsEdUAAAAJ:1tZ8xJnm2c8C,82,https://academic.oup.com/g3journal/article-abstract/5/5/719/6025546,16787546534874044988,/scholar?cites=16787546534874044988,,,https://academic.oup.com/g3journal/article/5/5/719/6025546,0,0,0
1281860,Voice activity detection based on complex Laplacian model,2003,Joon-Hyuk Chang and Nam Soo Kim,39,Electronics Letters,7,632-634,IET,A voice activity detector (VAD) based on the complex Laplacian model is proposed. The likelihood ratio based on the Laplacian model is computed and then applied to the VAD operation. According to experimental results. it is found that the Laplacian statistical model is more efficient for the VAD algorithm compared to the Gaussian model.,True,uWYsEdUAAAAJ:2osOgNQ5qMEC,73,https://ieeexplore.ieee.org/abstract/document/1194152/,6429454514535203440,/scholar?cites=6429454514535203440,,,,0,0,0
1281861,Statistical model-based voice activity detection using support vector machine,2009,Q-H Jo and J-H Chang and JW Shin and NS Kim,3,IET Signal Processing,3,205-210,IET Digital Library,From an investigation of a statistical model-based voice activity detection (VAD). it is discovered that a simple heuristic way like a geometric mean has been adopted for a decision rule based on the likelihood ratio (LR) test. For a successful VAD operation. the authors first review the behaviour mechanism of support vector machine (SVM) and then propose a novel technique. which employs the decision function of SVM using the LRs. while the conventional techniques perform VAD comparing the geometric mean of the LRs with a given threshold value. The proposed SVM-based VAD is compared to the conventional statistical model-based scheme. and shows better performances in various noise environments.,True,uWYsEdUAAAAJ:WF5omc3nYNoC,72,https://digital-library.theiet.org/content/journals/10.1049/iet-spr.2008.0128,8279046576203481266,/scholar?cites=8279046576203481266,,,https://pdfs.semanticscholar.org/08e7/18f28c6d6904820dd4b266bfe90c28d4fc4f.pdf,0,0,0
1281862,Speech enhancement: new approaches to soft decision,2001,Joon-Hyuk Chang and Nam Soo Kim,84,IEICE TRANSACTIONS on Information and Systems,9,1231-1240,The Institute of Electronics. Information and Communication Engineers,In this paper. we propose new approaches to speech enhancement based on soft decision. In order to enhance the statistical reliability in estimating speech activity. we introduce the concept of a global speech absence probability (GSAP). First. we compute the conventional speech absence probability (SAP) and then modify it according to the newly proposed GSAP. The modification is made in such a way that the SAP has the same value of GSAP in the case of speech absence while it is maintained to its original value when the speech is present. Moreover. for improving the performance of the SAP's at voice tails (transition periods from speech to silence). we revise the SAP's using a hang-over scheme based on the hidden Markov model (HMM). In addition. we suggest a robust noise update algorithm in which the noise power is estimated not only in the periods of speech absence but also during speech activity …,True,uWYsEdUAAAAJ:9yKSN-GCB0IC,61,https://search.ieice.org/bin/summary.php?id=e84-d_9_1231,8777247795423909571,/scholar?cites=8777247795423909571,,,,0,0,0
1281863,Image probability distribution based on generalized gamma function,2005,Joon-Hyuk Chang and Jong Won Shin and Nam Soo Kim and Sanjit K Mitra,12,IEEE Signal Processing Letters,4,325-328,IEEE,In this letter. we propose results of distribution tests that indicate that for many natural images. the statistics of the discrete cosine transform (DCT) coefficients are best approximated by a generalized gamma function (G/spl Gamma/F). which includes the conventional Gaussian. Laplacian. and gamma probability density functions. The major parameter of the G/spl Gamma/F is estimated according to the maximum likelihood (ML) principle. Experimental results on a number of /spl chi//sup 2/ tests indicate that the G/spl Gamma/F can be used effectively for modeling the DCT coefficients compared to the conventional Laplacian and generalized Gaussian function (GGF).,True,uWYsEdUAAAAJ:Y0pCki6q_DkC,58,https://ieeexplore.ieee.org/abstract/document/1407931/,6040381063270993621,/scholar?cites=6040381063270993621,,,https://sapl.gist.ac.kr/wp-content/uploads/2017/01/Image-probability-distribution-based-on-generalized-gamma-function.pdf,0,0,0
1281864,Closed-form localization for distributed MIMO radar systems using time delay measurements,2015,Chee-Hyun Park and Joon-Hyuk Chang,15,IEEE Transactions on Wireless Communications,2,1480-1490,IEEE,This paper presents two closed-form localization algorithms. a general algorithm and a colocated algorithm. for distributed multiple-input multiple-output (MIMO) radar systems. In distributed MIMO radar systems. range sum measurements are used to estimate the location parameter. For this. the range sum error minimization is actually employed to be degenerated into two cases for time-of-arrival (TOA) passive localization. one by employing the distance estimate between the target and the receiver (the general algorithm) and the other by subtracting the distance measurement between the target and the transmitter after the time-delay estimation (the colocated algorithm). The resulting positioning accuracy of the general and colocated techniques is found to perform better than that of the existing closed-form weighted least squares (WLS) algorithm and attain the Cramér-Rao lower bound (CRLB).,True,uWYsEdUAAAAJ:LPtt_HFRSbwC,54,https://ieeexplore.ieee.org/abstract/document/7298457/,7805842272158682089,/scholar?cites=7805842272158682089,,,,0,0,0
1281865,Process mining manifesto,2011,Wil Van Der Aalst and Arya Adriansyah and Ana Karla Alves De Medeiros and Franco Arcieri and Thomas Baier and Tobias Blickle and Jagadeesh Chandra Bose and Peter Van Den Brand and Ronald Brandtjen and Joos Buijs and Andrea Burattin and Josep Carmona and Malu Castellanos and Jan Claes and Jonathan Cook and Nicola Costantini and Francisco Curbera and Ernesto Damiani and Massimiliano De Leoni and Pavlos Delias and Boudewijn F Van Dongen and Marlon Dumas and Schahram Dustdar and Dirk Fahland and Diogo R Ferreira and Walid Gaaloul and Frank Van Geffen and Sukriti Goel and Christian GŘnther and Antonella Guzzo and Paul Harmon and Arthur Ter Hofstede and John Hoogland and Jon Espen Ingvaldsen and Koki Kato and Rudolf Kuhn and Akhil Kumar and Marcello La Rosa and Fabrizio Maggi and Donato Malerba and Ronny S Mans and Alberto Manuel and Martin McCreesh and Paola Mello and Jan Mendling and Marco Montali and Hamid R Motahari-Nezhad and Michael Zur Muehlen and Jorge Munoz-Gama and Luigi Pontieri and Joel Ribeiro and Anne Rozinat and Hugo Seguel PÚrez and Ricardo Seguel PÚrez and Marcos Sep and Jim Sinur and Pnina Soffer and Minseok Song and Alessandro Sperduti and Giovanni Stilo and Casper Stoel and Keith Swenson and Maurizio Talamo and Wei Tan and Chris Turner and Jan Vanthienen and George Varvaressos and Eric Verbeek and Marc Verdonk and Roberto Vigo and Jianmin Wang and Barbara Weber and Matthias Weidlich and Ton Weijters and Lijie Wen and Michael Westergaard and Moe Wynn,,,,169-194,Springer. Berlin. Heidelberg,Process mining techniques are able to extract knowledge from event logs commonly available in today’s information systems. These techniques provide new means to discover. monitor. and improve processes in a variety of application domains. There are two main drivers for the growing interest in process mining. On the one hand. more and more events are being recorded. thus. providing detailed information about the history of processes. On the other hand. there is a need to improve and support business processes in competitive and rapidly changing environments. This manifesto is created by the IEEE Task Force on Process Mining and aims to promote the topic of process mining. Moreover. by defining a set of guiding principles and listing important challenges. this manifesto hopes to serve as a guide for software developers. scientists. consultants. business managers. and end-users. The goal is to …,True,CSEqKy8AAAAJ:8k81kl-MbHgC,1117,https://link.springer.com/chapter/10.1007/978-3-642-28108-2_19,8361161290699373098,/scholar?cites=8361161290699373098,,,https://link.springer.com/content/pdf/10.1007/978-3-642-28108-2_19.pdf,0,0,0
1281866,Preprocessing techniques for context recognition from accelerometer data,2010,Davide Figo and Pedro C Diniz and Diogo R Ferreira and Joao MP Cardoso,14,Personal and Ubiquitous Computing,7,645-662,Springer-Verlag,The ubiquity of communication devices such as smartphones has led to the emergence of context-aware services that are able to respond to specific user activities or contexts. These services allow communication providers to develop new. added-value services for a wide range of applications such as social networking. elderly care and near-emergency early warning systems. At the core of these services is the ability to detect specific physical settings or the context a user is in. using either internal or external sensors. For example. using built-in accelerometers. it is possible to determine whether a user is walking or running at a specific time of day. By correlating this knowledge with GPS data. it is possible to provide specific information services to users with similar daily routines. This article presents a survey of the techniques for extracting this activity information from raw accelerometer data. The …,True,CSEqKy8AAAAJ:qjMakFHDy7sC,598,https://link.springer.com/article/10.1007/s00779-010-0293-9,3940035176016455834,/scholar?cites=3940035176016455834,,,https://www.researchgate.net/profile/Joao_Cardoso12/publication/220141356_Preprocessing_techniques_for_context_recognition_from_accelerometer_data/links/55ee176508aedecb68fc737e/Preprocessing-techniques-for-context-recognition-from-accelerometer-data.pdf,0,0,0
1281867,Business process analysis in healthcare environments: A methodology based on process mining,2012,Álvaro Rebuge and Diogo R Ferreira,37,Information systems,2,99-116,Pergamon,Performing business process analysis in healthcare organizations is particularly difficult due to the highly dynamic. complex. ad hoc. and multi-disciplinary nature of healthcare processes. Process mining is a promising approach to obtain a better understanding about those processes by analyzing event data recorded in healthcare information systems. However. not all process mining techniques perform well in capturing the complex and ad hoc nature of clinical workflows. In this work we introduce a methodology for the application of process mining techniques that leads to the identification of regular behavior. process variants. and exceptional medical cases. The approach is demonstrated in a case study conducted at a hospital emergency service. For this purpose. we implemented the methodology in a tool that integrates the main stages of process analysis. The tool is specific to the case study. but the same …,True,CSEqKy8AAAAJ:5nxA0vEk-isC,522,https://www.sciencedirect.com/science/article/pii/S0306437911000044,15521562616602075778,/scholar?cites=15521562616602075778,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.357.2924&rep=rep1&type=pdf,0,0,0
1281868,Approaching process mining with sequence clustering: Experiments and findings,2007,Diogo Ferreira and Marielba Zacarias and Miguel Malheiros and Pedro Ferreira,,,,360-374,Springer. Berlin. Heidelberg,Sequence clustering is a technique of bioinformatics that is used to discover the properties of sequences by grouping them into clusters and assigning each sequence to one of those clusters. In business process mining. the goal is also to extract sequence behaviour from an event log but the problem is often simplified by assuming that each event is already known to belong to a given process and process instance. In this paper. we describe two experiments where this information is not available. One is based on a real-world case study of observing a software development team for three weeks. The other is based on simulation and shows that it is possible to recover the original behaviour in a fully automated way. In both experiments. sequence clustering plays a central role.,True,CSEqKy8AAAAJ:u5HHmVD_uO8C,154,https://link.springer.com/chapter/10.1007/978-3-540-75183-0_26,7591713209703777444,/scholar?cites=7591713209703777444,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/Business%20Process%20Management,%205%20conf.,%20BPM%202007(LNCS4714,%20Springer,%202007)(ISBN%209783540751823)(429s)_CsLn_.pdf#page=372",0,0,0
1281869,Discovering process models from unlabelled event logs,2009,Diogo R Ferreira and Daniel Gillblad,,,,143-158,Springer. Berlin. Heidelberg,Existing process mining techniques are able to discover process models from event logs where each event is known to have been produced by a given process instance. In this paper we remove this restriction and address the problem of discovering the process model when the event log is provided as an unlabelled stream of events. Using a probabilistic approach. it is possible to estimate the model by means of an iterative Expectaction–Maximization procedure. The same procedure can be used to find the case id in unlabelled event logs. A series of experiments show how the proposed technique performs under varying conditions and in the presence of certain workflow patterns. Results are presented for a running example based on a technical support process.,True,CSEqKy8AAAAJ:u-x6o8ySG0sC,116,https://link.springer.com/chapter/10.1007/978-3-642-03848-8_11,1401628488433335833,/scholar?cites=1401628488433335833,,,http://ndl.ethernet.edu.et/bitstream/123456789/21792/1/321.pdf#page=153,0,0,0
1281870,Understanding spaghetti models with sequence clustering for ProM,2009,Gabriel M Veiga and Diogo R Ferreira,,,,92-103,Springer. Berlin. Heidelberg,The goal of process mining is to discover process models from event logs. However. for processes that are not well structured and have a lot of diverse behavior. existing process mining techniques generate highly complex models that are often difficult to understand; these are called spaghetti models. One way to try to understand these models is to divide the log into clusters in order to analyze reduced sets of cases. However. the amount of noise and ad-hoc behavior present in real-world logs still poses a problem. as this type of behavior interferes with the clustering and complicates the models of the generated clusters. affecting the discovery of patterns. In this paper we present an approach that aims at overcoming these difficulties by extracting only the useful data and presenting it in an understandable manner. The solution has been implemented in ProM and is divided in two stages: preprocessing and …,True,CSEqKy8AAAAJ:UeHWp8X0CEIC,114,https://link.springer.com/chapter/10.1007/978-3-642-12186-9_10,4219179016891017856,/scholar?cites=4219179016891017856,,,http://web.tecnico.ulisboa.pt/diogo.ferreira/papers/veiga10understanding.pdf,0,0,0
1281871,Providing user context for mobile and social networking applications,2010,André C Santos and João MP Cardoso and Diogo R Ferreira and Pedro C Diniz and Paulo Chaínho,6,Pervasive and Mobile Computing,3,324-341,Elsevier,The processing capabilities of mobile devices coupled with portable and wearable sensors provide the basis for new context-aware services and applications tailored to the user environment and daily activities. In this article. we describe the approach developed within the UPCASE project. which makes use of sensors available in the mobile device as well as sensors externally connected via Bluetooth to provide user contexts. We describe the system architecture from sensor data acquisition to feature extraction. context inference and the publication of context information in web-centered servers that support well-known social networking services. In the current prototype. context inference is based on decision trees to learn and to identify contexts dynamically at run-time. but the middleware allows the integration of different inference engines if necessary. Experimental results in a real-world setting suggest that the …,True,CSEqKy8AAAAJ:9yKSN-GCB0IC,102,https://www.sciencedirect.com/science/article/pii/S1574119210000052,16276072048826450473,/scholar?cites=16276072048826450473,,,http://sclab.yonsei.ac.kr/courses/11mobile/11mobile.files/paper/1.pdf,0,0,0
1281872,An integrated life cycle for workflow management based on learning and planning,2006,Hugo M Ferreira and Diogo R Ferreira,15,International Journal of Cooperative Information Systems,04,485-505,World Scientific Publishing Company,The ability to describe business processes as executable models has always been one of the fundamental premises of workflow management. Yet. the tacit nature of human knowledge is often an obstacle to eliciting accurate process models. On the other hand. the result of process modeling is a static plan of action. which is difficult to adapt to changing procedures or to different business goals. In this article. we attempt to address these problems by approaching workflow management with a combination of learning and planning techniques. Assuming that processes cannot be fully described at build-time. we make use of learning techniques. namely Inductive Logic Programming (ILP). in order to discover workflow activities and to describe them as planning operators. These operators will be subsequently fed to a partial-order planner in order to find the process model as a planning solution. The continuous …,True,CSEqKy8AAAAJ:2osOgNQ5qMEC,78,https://www.worldscientific.com/doi/abs/10.1142/S0218843006001463,18289376353615206884,/scholar?cites=18289376353615206884,,,https://www.researchgate.net/profile/Hugo_Ferreira4/publication/220095020_An_Integrated_Life_Cycle_for_Workflow_Management_Based_on_Learning_and_Planning/links/0912f5087ad012c3bc000000.pdf,0,0,0
1281873,Overview of the JET preparation for deuterium–tritium operation with the ITER like-wall,2019,Emmanuel Joffrin and Sadrilla Abduallev and Mitul Abhangi and P Abreu and V Afanasev and M Afzal and KM Aggarwal and T Ahlgren and L Aho-Mantila and N Aiba and M Airila and T Alarcon and R Albanese and D Alegre and S Aleiferis and E Alessi and P Aleynikov and A Alkseev and M Allinson and B Alper and E Alves and G Ambrosino and R Ambrosino and V Amosov and E Andersson Sundén and R Andrews and M Angelone and M Anghel and C Angioni and L Appel and C Appelbee and P Arena and M Ariola and S Arshad and J Artaud and W Arter and A Ash and N Ashikawa and V Aslanyan and O Asunta and O Asztalos and F Auriemma and Y Austin and L Avotina and M Axton and C Ayres and A Baciero and D Baião and I Balboa and M Balden and N Balshaw and VK Bandaru and J Banks and YF Baranov and C Barcellona and T Barnard and M Barnes and R Barnsley and A Baron Wiechec and L Barrera Orte and M Baruzzo and V Basiuk and M Bassan and R Bastow and A Batista and P Batistoni and L Baumane and B Bauvir and L Baylor and PS Beaumont and M Beckers and B Beckett and N Bekris and M Beldishevski and K Bell and F Belli and E Belonohy and J Benayas and H Bergsåker and J Bernardo and M Bernert and M Berry and L Bertalot and C Besiliu and H Betar and M Beurskens and J Bielecki and T Biewer and R Bilato and O Biletskyi and P Bílková and F Binda and G Birkenmeier and JPS Bizarro and C Björkas and J Blackburn and TR Blackman and P Blanchard and P Blatchford and V Bobkov and A Boboc and O Bogar and P Bohm and T Bohm and I Bolshakova and T Bolzonella and N Bonanomi and L Boncagni and D Bonfiglio and X Bonnin and J Boom and D Borba and D Borodin and I Borodkina and C Boulbe and C Bourdelle and M Bowden and C Bowman and T Boyce and H Boyer and SC Bradnam and V Braic and R Bravanec and B Breizman and D Brennan and S Breton and A Brett and S Brezinsek and M Bright and M Brix and W Broeckx and M Brombin and A Brosławski and B Brown and D Brunetti and E Bruno and J Buch and J Buchanan and R Buckingham and M Buckley and M Bucolo and R Budny and H Bufferand and S Buller and P Bunting and P Buratti and A Burckhart and G Burroughes and A Buscarino and A Busse,59,Nuclear Fusion,11,112021,IOP Publishing,Since 2016. the JET scientific programme is engaged in a multi-campaign effort including experiments in D. H and T [1]. leading to 2020 and the first experiments with 50%/50% D–T mixtures since 1997 (DTE1 campaign [2. 3]). where 16 MW of fusion power was achieved transiently and 4 MW in the steady state. and the first ever D–T plasmas with the ITER mix of plasma-facing component materials [4–6]. This effort is also driven by the EUROfusion research roadmap to secure the success of the future operation of ITER via specific preparation and experiments. including D–T operation of JET [7]. For this purpose. a concerted physics and technology programme was launched with a view to prepare the second JET D–T campaign (DTE2)[8]. This overview paper addresses the key elements developed by the JET programme directly contributing to the D–T preparation. JET is a unique device in the sense that it has …,True,CSEqKy8AAAAJ:1qzjygNMrQYC,60,https://iopscience.iop.org/article/10.1088/1741-4326/ab2276/meta,1401568964198855639,/scholar?cites=1401568964198855639,,,https://iopscience.iop.org/article/10.1088/1741-4326/ab2276/meta,0,0,0
1281874,Discovering User Communities in Large Event Logs,2012,Diogo R Ferreira and Cláudia Alves,,,,123-134,Springer,The organizational perspective of process mining supports the discovery of social networks within organizations by analyzing event logs recorded during process execution. However. applying these social network mining techniques to real data generates very complex models that are hard to analyze and understand. In this work we present an approach to overcome these difficulties by focusing on the discovery of communities from such event logs. The clustering of users into communities allows the analysis and visualization of the social network at different levels of abstraction. The proposed approach also makes use of the concept of modularity. which provides an indication of the best division of the social network into community clusters. The approach was implemented in the ProM framework and it was successfully applied in the analysis of the emergency service of a medium-sized hospital.,True,CSEqKy8AAAAJ:Se3iqnhoufwC,42,https://link.springer.com/chapter/10.1007/978-3-642-28108-2_11,10966980085502370857,/scholar?cites=10966980085502370857,,,http://web.ist.utl.pt/~diogo.ferreira/papers/ferreira12discovering.pdf,0,0,0
1281875,Context inference for mobile applications in the UPCASE project,2009,André C Santos and Luís Tarrataca and Joao MP Cardoso and Diogo R Ferreira and Pedro C Diniz and Paulo Chainho,,,,352-365,Springer. Berlin. Heidelberg,The growing processing capabilities of mobile devices coupled with portable and wearable sensors have enabled the development of context-aware services tailored to the user environment and its daily activities. The problem of determining the user context at each particular point in time is one of the main challenges in this area. In this paper. we describe the approach pursued in the UPCASE project. which makes use of sensors available in the mobile device as well as sensors externally connected via Bluetooth. We describe the system architecture from raw data acquisition to feature extraction and context inference. As a proof of concept. the inference of contexts is based on a decision tree to learn and identify contexts automatically and dynamically at runtime. Preliminary results suggest that this is a promising approach for context inference in several application scenarios.,True,CSEqKy8AAAAJ:zYLM7Y9cAGgC,38,https://link.springer.com/chapter/10.1007/978-3-642-01802-2_26,14825203048741993239,/scholar?cites=14825203048741993239,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.2631&rep=rep1&type=pdf,0,0,0
1281876,Delving into transferable adversarial examples and black-box attacks,2016,Yanpei Liu and Xinyun Chen and Chang Liu and Dawn Song,,arXiv preprint arXiv:1611.02770,,,,An intriguing property of deep neural networks is the existence of adversarial examples. which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work. we are the first to conduct an extensive study of the transferability over large models and a large scale dataset. and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples. and show that while transferable non-targeted adversarial examples are easy to find. targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore. we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches. we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally. we show that the adversarial examples generated using ensemble-based approaches can successfully attack this http URL. which is a black-box image classification system.,True,Zrbs8hIAAAAJ:_xSYboBqXhAC,879,https://arxiv.org/abs/1611.02770,11918479105697515542,/scholar?cites=11918479105697515542,,,https://arxiv.org/pdf/1611.02770)%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%A9%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E9%AA%97%E8%BF%87%E5%BA%94%E7%94%A8%E5%9C%A8%E7%8E%B0%E5%AE%9E%E4%B8%96%E7%95%8C%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B,0,0,0
1281877,Targeted backdoor attacks on deep learning systems using data poisoning,2017,Xinyun Chen and Chang Liu and Bo Li and Kimberly Lu and Dawn Song,,arXiv preprint arXiv:1712.05526,,,,Deep learning models have achieved high performance on many tasks. and thus have been applied to many security-critical scenarios. For example. deep learning-based face recognition systems have been used to authenticate users to access many security-sensitive applications like payment apps. Such usages of deep learning systems provide the adversaries with sufficient incentives to perform attacks against these systems for their adversarial purposes. In this work. we consider a new type of attacks. called backdoor attacks. where the attacker's goal is to create a backdoor into a learning-based authentication system. so that he can easily circumvent the system by leveraging the backdoor. Specifically. the adversary aims at creating backdoor instances. so that the victim learning system will be misled to classify the backdoor instances as a target label specified by the adversary. In particular. we study backdoor poisoning attacks. which achieve backdoor attacks using poisoning strategies. Different from all existing work. our studied poisoning strategies can apply under a very weak threat model:(1) the adversary has no knowledge of the model and the training set used by the victim system;(2) the attacker is allowed to inject only a small amount of poisoning samples;(3) the backdoor key is hard to notice even by human beings to achieve stealthiness. We conduct evaluation to demonstrate that a backdoor adversary can inject only around 50 poisoning samples. while achieving an attack success rate of above 90%. We are also the first work to show that a data poisoning attack can create physically implementable backdoors without touching the …,True,Zrbs8hIAAAAJ:nb7KW1ujOQ8C,374,https://arxiv.org/abs/1712.05526,10754564719271014682,/scholar?cites=10754564719271014682,,,https://arxiv.org/pdf/1712.05526.pdf?source=post_page---------------------------,0,0,0
1281878,ObliVM: A Programming Framework for Secure Computation,2015,C Liu and XS Wang and K Nayak and Y Huang and E Shi,,IEEE Symposium on Security and Privacy (S & P),,,,We design and develop ObliVM. a programming framework for secure computation. ObliVM offers a domain specific language designed for compilation of programs into efficient oblivious representations suitable for secure computation. ObliVM offers a powerful. expressive programming language and user-friendly oblivious programming abstractions. We develop various showcase applications such as data mining. streaming algorithms. graph algorithms. genomic data analysis. and data structures. and demonstrate the scalability of ObliVM to bigger data sizes. We also show how ObliVM significantly reduces development effort while retaining competitive performance for a wide range of applications in comparison with hand-crafted solutions. We are in the process of open-sourcing ObliVM and our rich libraries to the community (www.oblivm.com). offering a reusable framework to implement and distribute new …,True,Zrbs8hIAAAAJ:hMod-77fHWUC,289,https://ieeexplore.ieee.org/abstract/document/7163036/,12212246424359308371,/scholar?cites=12212246424359308371,,,http://www.ieee-security.org/TC/SP2015/papers-archived/6949a359.pdf,0,0,0
1281879,Manipulating machine learning: Poisoning attacks and countermeasures for regression learning,2018,Matthew Jagielski and Alina Oprea and Battista Biggio and Chang Liu and Cristina Nita-Rotaru and Bo Li,,,,19-35,IEEE,As machine learning becomes widely used for automated decisions. attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper. we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks. attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally. we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the …,True,Zrbs8hIAAAAJ:UxriW0iASnsC,283,https://ieeexplore.ieee.org/abstract/document/8418594/,8427189551292568466,/scholar?cites=8427189551292568466,,,https://arxiv.org/pdf/1804.00308,0,0,0
1281880,Neural network-based graph embedding for cross-platform binary code similarity detection,2017,Xiaojun Xu and Chang Liu and Qian Feng and Heng Yin and Le Song and Dawn Song,,,,363-376,,The problem of cross-platform binary code similarity detection aims at detecting whether two binary functions coming from different platforms are similar or not. It has many security applications. including plagiarism detection. malware detection. vulnerability search. etc. Existing approaches rely on approximate graph-matching algorithms. which are inevitably slow and sometimes inaccurate. and hard to adapt to a new task. To address these issues. in this work. we propose a novel neural network-based approach to compute the embedding. ie. a numeric vector. based on the control flow graph of each binary function. then the similarity detection can be done efficiently by measuring the distance between the embeddings for two functions. We implement a prototype called Gemini. Our extensive evaluation shows that Gemini outperforms the state-of-the-art approaches by large margins with respect to similarity detection …,True,Zrbs8hIAAAAJ:NhqRSupF_l8C,241,https://dl.acm.org/doi/abs/10.1145/3133956.3134018,3823696646288306286,/scholar?cites=3823696646288306286,,,https://dl.acm.org/doi/pdf/10.1145/3133956.3134018,0,0,0
1281881,Sqlnet: Generating structured queries from natural language without reinforcement learning,2017,Xiaojun Xu and Chang Liu and Dawn Song,,arXiv preprint arXiv:1711.04436,,,,"Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem. the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations. training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the"" order-matters"" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However. we observe that the improvement from reinforcement learning is limited.In this paper. we propose a novel approach. ie. SQLNet. to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular. we employ a sketch-based approach where the sketch contains a dependency graph so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition. we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques. we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.",True,Zrbs8hIAAAAJ:P5F9QuxV20EC,187,https://arxiv.org/abs/1711.04436,17143697547708916221,/scholar?cites=17143697547708916221,,,https://arxiv.org/pdf/1711.04436,0,0,0
1281882,The secret sharer: Evaluating and testing unintended memorization in neural networks,2019,Nicholas Carlini and Chang Liu and Úlfar Erlingsson and Jernej Kos and Dawn Song,,,,267-284,,This paper describes a testing methodology for quantitatively assessing the risk that rare or unique training-data sequences are unintentionally memorized by generative sequence models—a common type of machine-learning model. Because such models are sometimes trained on sensitive data (eg. the text of users' private messages). this methodology can benefit privacy by allowing deep-learning practitioners to select means of training that minimize such memorization.,True,Zrbs8hIAAAAJ:D_sINldO8mEC,148,https://www.usenix.org/conference/usenixsecurity19/presentation/carlini,14719809661253001007,/scholar?cites=14719809661253001007,,,https://www.usenix.org/system/files/sec19-carlini.pdf,0,0,0
1281883,Ghostrider: A hardware-software system for memory trace oblivious computation,2015,Chang Liu and Austin Harris and Martin Maas and Michael Hicks and Mohit Tiwari and Elaine Shi,50,ACM SIGPLAN Notices,4,87-101,ACM,This paper presents a new. co-designed compiler and architecture called GhostRider for supporting privacy preserving computation in the cloud. GhostRider ensures all programs satisfy a property called memory-trace obliviousness (MTO): Even an adversary that observes memory. bus traffic. and access times while the program executes can learn nothing about the program's sensitive inputs and outputs. One way to achieve MTO is to employ Oblivious RAM (ORAM). allocating all code and data in a single ORAM bank. and to also disable caches or fix the rate of memory traffic. This baseline approach can be inefficient. and so GhostRider's compiler uses a program analysis to do better. allocating data to non-oblivious. encrypted RAM (ERAM) and employing a scratchpad when doing so will not compromise MTO. The compiler can also allocate to multiple ORAM banks. which sometimes significantly reduces access …,True,Zrbs8hIAAAAJ:k_IJM867U9cC,147,https://dl.acm.org/doi/abs/10.1145/2775054.2694385,17621816650953550189,/scholar?cites=17621816650953550189,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.699.179&rep=rep1&type=pdf,0,0,0
1281884,Oblivious data structures,2014,Xiao Shaun Wang and Kartik Nayak and Chang Liu and TH Hubert Chan and Elaine Shi and Emil Stefanov and Yan Huang,,,,215-226,,We design novel. asymptotically more efficient data structures and algorithms for programs whose data access patterns exhibit some degree of predictability. To this end. we propose two novel techniques. a pointer-based technique and a locality-based technique. We show that these two techniques are powerful building blocks in making data structures and algorithms oblivious. Specifically. we apply these techniques to a broad range of commonly used data structures. including maps. sets. priority-queues. stacks. deques; and algorithms. including a memory allocator algorithm. max-flow on graphs with low doubling dimension. and shortest-path distance queries on weighted planar graphs. Our oblivious counterparts of the above outperform the best known ORAM scheme both asymptotically and in practice.,True,Zrbs8hIAAAAJ:hFOr9nPyWt4C,144,https://dl.acm.org/doi/abs/10.1145/2660267.2660314,2040052605455248284,/scholar?cites=2040052605455248284,,,https://core.ac.uk/download/pdf/193391959.pdf,0,0,0
1281885,The secret sharer: Measuring unintended neural network memorization & extracting secrets,2018,Nicholas Carlini and Chang Liu and Jernej Kos and Úlfar Erlingsson and Dawn Song,,,,,,Machine learning models based on neural networks and deep learning are being rapidly adopted for many purposes. What those models learn. and what they may share. is a significant concern when the training data may contain secrets and the models are public--eg. when a model helps users compose text messages using models trained on all users' messages. This paper presents exposure: a simple-to-compute metric that can be applied to any deep learning model for measuring the memorization of secrets. Using this metric. we show how to extract those secrets efficiently using black-box API access. Further. we show that unintended memorization occurs early. is not due to over-fitting. and is a persistent issue across different types of models. hyperparameters. and training strategies. We experiment with both real-world models (eg. a state-of-the-art translation model) and datasets (eg. the Enron email dataset …,True,Zrbs8hIAAAAJ:SP6oXDckpogC,141,http://scholar.google.com/scholar?cluster=9975660618813285240&hl=en&oi=scholarr,9975660618813285240,/scholar?cites=9975660618813285240,,,,0,0,0
1281886,Automating efficient RAM-model secure computation,2014,Chang Liu and Yan Huang and Elaine Shi and Jonathan Katz and Michael Hicks,,,,623-638,IEEE,RAM-model secure computation addresses the inherent limitations of circuit-model secure computation considered in almost all previous work. Here. we describe the first automated approach for RAM-model secure computation in the semi-honest model. We define an intermediate representation called SCVM and a corresponding type system suited for RAM-model secure computation. Leveraging compile-time optimizations. our approach achieves order-of-magnitude speedups compared to both circuit-model secure computation and the state-of-art RAM-model secure computation.,True,Zrbs8hIAAAAJ:hC7cP41nSMkC,111,https://ieeexplore.ieee.org/abstract/document/6956591/,11619669631167536455,/scholar?cites=11619669631167536455,,,https://drum.lib.umd.edu/bitstream/handle/1903/15552/CS-TR-5033.pdf?sequence=1&isAllowed=y,0,0,0
1281887,A systematic study of the class imbalance problem in convolutional neural networks,2018,Mateusz Buda and Atsuto Maki and Maciej A Mazurowski,106,Neural Networks,,249-259,Pergamon,In this study. we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning. yet very limited systematic research is available in the context of deep learning. In our study. we use three benchmark datasets of increasing complexity. MNIST. CIFAR-10 and ImageNet. to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling. undersampling. two-phase training. and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with …,True,HlxjJPQAAAAJ:v6i8RKmR8ToC,816,https://www.sciencedirect.com/science/article/pii/S0893608018302107,11202245850277157438,/scholar?cites=11202245850277157438,,,https://arxiv.org/pdf/1710.05381,0,0,0
1281888,Training neural network classifiers for medical decision making: The effects of imbalanced datasets on classification performance,2008,Maciej A Mazurowski and Piotr A Habas and Jacek M Zurada and Joseph Y Lo and Jay A Baker and Georgia D Tourassi,21,Neural Networks,2-3,427-436,Pergamon,This study investigates the effect of class imbalance in training data when developing neural network classifiers for computer-aided medical diagnosis. The investigation is performed in the presence of other characteristics that are typical among medical data. namely small training sample size. large number of features. and correlations between features. Two methods of neural network training are explored: classical backpropagation (BP) and particle swarm optimization (PSO) with clinically relevant training criteria. An experimental study is performed using simulated data and the conclusions are further validated on real clinical data for breast cancer diagnosis. The results show that classifier performance deteriorates with even modest class imbalance in the training data. Further. it is shown that BP is generally preferable over PSO for imbalanced training data especially with small data sample and large number of …,True,HlxjJPQAAAAJ:u5HHmVD_uO8C,747,https://www.sciencedirect.com/science/article/pii/S0893608007002407,18047333990988182008,/scholar?cites=18047333990988182008,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2346433/,0,0,0
1281889,Radiogenomics: What It Is and Why It Is Important,2015,Maciej A Mazurowski,12,Journal of the American College of Radiology,8,862-866,Elsevier,In recent years. a new direction in cancer research has emerged that focuses on the relationship between imaging phenotypes and genomics. This direction is referred to as radiogenomics or imaging genomics. The question that subsequently arises is: What is the practical significance of elucidating this relationship in improving cancer patient outcomes. In this article. I address this question. Although I discuss some limitations of the radiogenomic approach. and describe scenarios in which radiogenomic analysis might not be the best choice. I also argue that radiogenomics will play a significant practical role in cancer research. Specifically. I argue that the significance of radiogenomics is largely related to practical limitations of currently available data that often lack complete characterization of the patients and poor integration of individual datasets. Radiogenomics offers a practical way to leverage limited and …,True,HlxjJPQAAAAJ:mWEH9CqjF64C,174,https://www.sciencedirect.com/science/article/pii/S1546144015003233,2588683774377190750,/scholar?cites=2588683774377190750,,,https://www.jacr.org/article/S1546-1440(15)00323-3/fulltext,0,0,0
1281890,Radiogenomic Analysis of Breast Cancer: Luminal B Molecular Subtype Is Associated with Enhancement Dynamics at MR Imaging,2014,Maciej A Mazurowski and Jing Zhang and Lars J Grimm and Sora C Yoon and James I Silber,273,Radiology,2,365-372,Radiological Society of North America,To investigate associations between breast cancer molecular subtype and semiautomatically extracted magnetic resonance (MR) imaging features.Imaging and genomic data from the Cancer Genome Atlas and the Cancer Imaging Archive for 48 patients with breast cancer from four institutions in the United States were used in this institutional review board approval–exempt study. Computer vision algorithms were applied to extract 23 imaging features from lesions indicated by a breast radiologist on MR images. Morphologic. textural. and dynamic features were extracted. Molecular subtype was determined on the basis of genomic analysis. Associations between the imaging features and molecular subtype were evaluated by using logistic regression and likelihood ratio tests. The analysis controlled for the age of the patients. their menopausal status. and the orientation of the MR …,True,HlxjJPQAAAAJ:kF1pexMAQbMC,171,https://pubs.rsna.org/doi/abs/10.1148/radiol.14132641,1198075569169123379,/scholar?cites=1198075569169123379,,,https://pubs.rsna.org/doi/full/10.1148/radiol.14132641,0,0,0
1281891,Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on MRI,2019,Maciej A Mazurowski and Mateusz Buda and Ashirbani Saha and Mustafa R Bashir,49,Journal of Magnetic Resonance Imaging,4,939-954,,Deep learning is a branch of artificial intelligence where networks of simple interconnected units are used to extract patterns from data in order to solve complex problems. Deep‐learning algorithms have shown groundbreaking performance in a variety of sophisticated tasks. especially those related to images. They have often matched or exceeded human performance. Since the medical field of radiology mainly relies on extracting useful information from images. it is a very natural application area for deep learning. and research in this area has rapidly grown in recent years. In this article. we discuss the general context of radiology and opportunities for application of deep‐learning algorithms. We also introduce basic concepts of deep learning. including convolutional neural networks. Then. we present a survey of the research in deep learning applied to radiology. We organize the studies by the types of specific …,True,HlxjJPQAAAAJ:A8cqit5AE6sC,169,https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.26534,18191171377370240762,/scholar?cites=18191171377370240762,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6483404/,0,0,0
1281892,Computational approach to radiogenomics of breast cancer: luminal A and luminal B molecular subtypes are associated with imaging features on routine breast MRI extracted using …,2015,Lars J Grimm and Jing Zhang and Maciej A Mazurowski,42,Journal of Magnetic Resonance Imaging,4,902-907,,To identify associations between semiautomatically extracted MRI features and breast cancer molecular subtypes.We analyzed routine clinical pre‐operative breast MRIs from 275 breast cancer patients at a single institution in this retrospective. Institutional Review Board‐approved study. Six fellowship‐trained breast imagers reviewed the MRIs and annotated the cancers. Computer vision algorithms were then used to extract 56 imaging features from the cancers including morphologic. texture. and dynamic features. Surrogate markers (estrogen receptor [ER]. progesterone receptor [PR]. human epidermal growth factor receptor‐2 [HER2]) were used to categorize tumors by molecular subtype: ER/PR+. HER2− (luminal A); ER/PR+. HER2+ (luminal B); ER/PR−. HER2+ (HER2); ER/PR/HER2− (basal). A multivariate analysis was used to determine associations between the imaging features and …,True,HlxjJPQAAAAJ:DkZNVXde3BIC,97,https://onlinelibrary.wiley.com/doi/abs/10.1002/jmri.24879,762050888713440230,/scholar?cites=762050888713440230,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/jmri.24879,0,0,0
1281893,Imaging descriptors improve the predictive power of survival models for glioblastoma patients,2013,Maciej Andrzej Mazurowski and Annick Desjardins and Jordan Milton Malof,15,Neuro-oncology,10,1389-1394,Oxford University Press,Because effective prediction of survival time can be highly beneficial for the treatment of glioblastoma patients. the relationship between survival time and multiple patient characteristics has been investigated. In this paper. we investigate whether the predictive power of a survival model based on clinical patient features improves when MRI features are also included in the model.The subjects in this study were 82 glioblastoma patients for whom clinical features as well as MR imaging exams were made available by The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). Twenty-six imaging features in the available MR scans were assessed by radiologists from the TCGA Glioma Phenotype Research Group. We used multivariate Cox proportional hazards regression to construct 2 survival models: one that used 3 clinical features (age …,True,HlxjJPQAAAAJ:w1MjKQ0l0TYC,92,https://academic.oup.com/neuro-oncology/article-abstract/15/10/1389/1309572,2269358987444378114,/scholar?cites=2269358987444378114,,,https://academic.oup.com/neuro-oncology/article/15/10/1389/1309572,0,0,0
1281894,Deep learning for segmentation of brain tumors: Impact of cross‐institutional training and testing,2018,Ehab A AlBadawy and Ashirbani Saha and Maciej A Mazurowski,45,Medical physics,3,1150-1158,Wiley-Blackwell,Convolutional neural networks (CNNs) are commonly used for segmentation of brain tumors. In this work. we assess the effect of cross‐institutional training on the performance of CNNs.We selected 44 glioblastoma (GBM) patients from two institutions in The Cancer Imaging Archive dataset. The images were manually annotated by outlining each tumor component to form ground truth. To automatically segment the tumors in each patient. we trained three CNNs: (a) one using data for patients from the same institution as the test data. (b) one using data for the patients from the other institution and (c) one using data for the patients from both of the institutions. The performance of the trained models was evaluated using Dice similarity coefficients as well as Average Hausdorff Distance between the ground truth and automatic segmentations. The 10‐fold cross‐validation scheme was …,True,HlxjJPQAAAAJ:X9ykpCP0fEIC,76,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12752,2871278506117954445,/scholar?cites=2871278506117954445,,,,0,0,0
1281895,Mutual information-based template matching scheme for detection of breast masses: From mammography to digital breast tomosynthesis,2011,Maciej A Mazurowski and Joseph Y Lo and Brian P Harrawood and Georgia D Tourassi,44,Journal of Biomedical Informatics,5,815-823,Academic Press,Development of a computational decision aid for a new medical imaging modality typically is a long and complicated process. It consists of collecting data in the form of images and annotations. development of image processing and pattern recognition algorithms for analysis of the new images and finally testing of the resulting system. Since new imaging modalities are developed more rapidly than ever before. any effort for decreasing the time and cost of this development process could result in maximizing the benefit of the new imaging modality to patients by making the computer aids quickly available to radiologists that interpret the images. In this paper. we make a step in this direction and investigate the possibility of translating the knowledge about the detection problem from one imaging modality to another. Specifically. we present a computer-aided detection (CAD) system for mammographic masses that uses …,True,HlxjJPQAAAAJ:5nxA0vEk-isC,62,https://www.sciencedirect.com/science/article/pii/S1532046411000724,17965132570987684881,/scholar?cites=17965132570987684881,,,https://www.sciencedirect.com/science/article/pii/S1532046411000724,0,0,0
1281896,Deep Learning for identifying radiogenomic associations in breast cancer,2019,Zhe Zhu and Ehab Albadawy and Ashirbani Saha and Jun Zhang and Michael R Harowicz and Maciej A Mazurowski,109,Computers in biology and medicine,,85-90,Pergamon,To determine whether deep learning models can distinguish between breast cancer molecular subtypes based on dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI).In this institutional review board–approved single-center study. we analyzed DCE-MR images of 270 patients at our institution. Lesions of interest were identified by radiologists. The task was to automatically determine whether the tumor is of the Luminal A subtype or of another subtype based on the MR image patches representing the tumor. Three different deep learning approaches were used to classify the tumor according to their molecular subtypes: learning from scratch where only tumor patches were used for training. transfer learning where networks pre-trained on natural images were fine-tuned using tumor patches. and off-the-shelf deep features where the features extracted …,True,HlxjJPQAAAAJ:27LrP4qxOz0C,55,https://www.sciencedirect.com/science/article/pii/S001048251930126X,14815006031146662394,/scholar?cites=14815006031146662394,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7155381/,0,0,0
1281897,Management of thyroid nodules seen on US images: deep learning may match performance of radiologists,2019,Mateusz Buda and Benjamin Wildman-Tobriner and Jenny K Hoang and David Thayer and Franklin N Tessler and William D Middleton and Maciej A Mazurowski,292,Radiology,3,695-701,Radiological Society of North America,Management of thyroid nodules may be inconsistent between different observers and time consuming for radiologists. An artificial intelligence system that uses deep learning may improve radiology workflow for management of thyroid nodules.To develop a deep learning algorithm that uses thyroid US images to decide whether a thyroid nodule should undergo a biopsy and to compare the performance of the algorithm with the performance of radiologists who adhere to American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS).In this retrospective analysis. studies in patients referred for US with subsequent fine-needle aspiration or with surgical histologic analysis used as the standard were evaluated. The study period was from August 2006 to May 2010. A multitask deep convolutional neural network was trained to provide biopsy …,True,HlxjJPQAAAAJ:ZqE1mSdD_DYC,47,https://pubs.rsna.org/doi/abs/10.1148/radiol.2019181343,4536753668317197035,/scholar?cites=4536753668317197035,,,https://pubs.rsna.org/doi/pdf/10.1148/radiol.2019181343,0,0,0
1281898,Classifying relations via long short term memory networks along shortest dependency paths,2015,Yan Xu and Lili Mou and Ge Li and Yunchuan Chen and Hao Peng and Zhi Jin,,,,1785-1794,,Relation classification is an important research arena in the field of natural language processing (NLP). In this paper. we present SDP-LSTM. a novel neural network to classify the relation of two entities in a sentence. Our neural architecture leverages the shortest dependency path (SDP) between two entities; multichannel recurrent neural networks. with long short term memory (LSTM) units. pick up heterogeneous information along the SDP. Our proposed model has several distinct features:(1) The shortest dependency paths retain most relevant information (to relation classification). while eliminating irrelevant words in the sentence.(2) The multichannel LSTM networks allow effective information integration from heterogeneous sources over the dependency paths.(3) A customized dropout strategy regularizes the neural network to alleviate overfitting. We test our model on the SemEval 2010 relation classification task. and achieve an F1-score of 83.7%. higher than competing methods in the literature.,True,PPqcVRwAAAAJ:hqOjcs7Dif8C,439,https://www.aclweb.org/anthology/D15-1206.pdf,7434923510943166052,/scholar?cites=7434923510943166052,,,https://www.aclweb.org/anthology/D15-1206.pdf,0,0,0
1281899,Convolutional neural networks over tree structures for programming language processing,2016,Lili Mou and Ge Li and Lu Zhang and Tao Wang and Zhi Jin,30,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However. different from a natural language sentence. a program contains rich. explicit. and complicated structural information. Hence. traditional NLP models may be inappropriate for programs. In this paper. we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing. in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality. and detecting code snippets of certain patterns. TBCNN outperforms baseline methods. including several neural models for NLP.,True,PPqcVRwAAAAJ:9ZlFYXVOiuMC,320,https://ojs.aaai.org/index.php/AAAI/article/view/10139,12324937124370515795,/scholar?cites=12324937124370515795,,,https://ojs.aaai.org/index.php/AAAI/article/download/10139/9998,0,0,0
1281900,Natural language inference by tree-based convolution and heuristic matching,2015,Lili Mou and Rui Men and Ge Li and Yan Xu and Lu Zhang and Rui Yan and Zhi Jin,,arXiv preprint arXiv:1512.08422,,,,In this paper. we propose the TBCNN-pair model to recognize entailment and contradiction between two sentences. In our model. a tree-based convolutional neural network (TBCNN) captures sentence-level semantics; then heuristic matching layers like concatenation. element-wise product/difference combine the information in individual sentences. Experimental results show that our model outperforms existing sentence encoding-based approaches by a large margin.,True,PPqcVRwAAAAJ:d1gkVwhDpl0C,265,https://arxiv.org/abs/1512.08422,125294644878662580,/scholar?cites=125294644878662580,,,https://arxiv.org/pdf/1512.08422,0,0,0
1281901,How transferable are neural networks in nlp applications?,2016,Lili Mou and Zhao Meng and Rui Yan and Ge Li and Yan Xu and Lu Zhang and Zhi Jin,,arXiv preprint arXiv:1603.06111,,,,Transfer learning is aimed to make use of valuable knowledge in a source domain to help model performance in a target domain. It is particularly important to neural networks. which are very likely to be overfitting. In some fields like image processing. many studies have shown the effectiveness of neural network-based transfer learning. For neural NLP. however. existing studies have only casually applied transfer learning. and conclusions are inconsistent. In this paper. we conduct systematic case studies and provide an illuminating picture on the transferability of neural networks in NLP.,True,PPqcVRwAAAAJ:0EnyYjriUFMC,236,https://arxiv.org/abs/1603.06111,7464971160910138225,/scholar?cites=7464971160910138225,,,https://arxiv.org/pdf/1603.06111,0,0,0
1281902,Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation,2016,Lili Mou and Yiping Song and Rui Yan and Ge Li and Lu Zhang and Zhi Jin,,arXiv preprint arXiv:1607.00970,,,,"Using neural networks to generate replies in human-computer dialogue systems is attracting increasing attention over the past few years. However. the performance is not satisfactory: the neural network tends to generate safe. universally relevant replies which carry little meaning. In this paper. we propose a content-introducing approach to neural network-based generative dialogue systems. We first use pointwise mutual information (PMI) to predict a noun as a keyword. reflecting the main gist of the reply. We then propose seq2BF. a"" sequence to backward and forward sequences"" model. which generates a reply containing the given keyword. Experimental results show that our approach significantly outperforms traditional sequence-to-sequence models in terms of human evaluation and the entropy measure. and that the predicted keyword can appear at an appropriate position in the reply.",True,PPqcVRwAAAAJ:ZeXyd9-uunAC,182,https://arxiv.org/abs/1607.00970,15322306336642377359,/scholar?cites=15322306336642377359,,,https://arxiv.org/pdf/1607.00970,0,0,0
1281903,Deep code comment generation,2018,Xing Hu and Ge Li and Xin Xia and David Lo and Zhi Jin,,,,200-20010,IEEE,During software maintenance. code comments help developers comprehend programs and reduce additional time spent on reading and navigating source code. Unfortunately. these comments are often mismatched. missing or outdated in the software projects. Developers have to infer the functionality from the source code. This paper proposes a new approach named DeepCom to automatically generate code comments for Java methods. The generated comments aim to help developers understand the functionality of Java methods. DeepCom applies Natural Language Processing (NLP) techniques to learn from a large code corpus and generates comments from learned features. We use a deep neural network that analyzes structural information of Java methods for better comments generation. We conduct experiments on a large-scale Java corpus built from 9.714 open source projects from GitHub. We evaluate …,True,PPqcVRwAAAAJ:e5wmG9Sq2KIC,181,https://ieeexplore.ieee.org/abstract/document/8973050/,1082840393834763657,/scholar?cites=1082840393834763657,,,https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5295&context=sis_research,0,0,0
1281904,Improved relation classification by deep recurrent neural networks with data augmentation,2016,Yan Xu and Ran Jia and Lili Mou and Ge Li and Yunchuan Chen and Yangyang Lu and Zhi Jin,,arXiv preprint arXiv:1601.03651,,,,Nowadays. neural networks play an important role in the task of relation classification. By designing different neural architectures. researchers have improved the performance to a large extent in comparison with traditional methods. However. existing neural networks for relation classification are usually of shallow architectures (eg. one-layer convolutional neural networks or recurrent networks). They may fail to explore the potential representation space in different abstraction levels. In this paper. we propose deep recurrent neural networks (DRNNs) for relation classification to tackle this challenge. Further. we propose a data augmentation method by leveraging the directionality of relations. We evaluated our DRNNs on the SemEval-2010 Task~ 8. and achieve an F1-score of 86.1%. outperforming previous state-of-the-art recorded results.,True,PPqcVRwAAAAJ:-f6ydRqryjwC,167,https://arxiv.org/abs/1601.03651,16373480206076190875,/scholar?cites=16373480206076190875,,,https://arxiv.org/pdf/1601.03651,0,0,0
1281905,Discriminative neural sentence modeling by tree-based convolution,2015,Lili Mou and Hao Peng and Ge Li and Yan Xu and Lu Zhang and Zhi Jin,,arXiv preprint arXiv:1504.01106,,,,This paper proposes a tree-based convolutional neural network (TBCNN) for discriminative sentence modeling. Our models leverage either constituency trees or dependency trees of sentences. The tree-based convolution process extracts sentences' structural features. and these features are aggregated by max pooling. Such architecture allows short propagation paths between the output layer and underlying feature detectors. which enables effective structural feature learning and extraction. We evaluate our models on two tasks: sentiment analysis and question classification. In both experiments. TBCNN outperforms previous state-of-the-art results. including existing neural networks and dedicated feature/rule engineering. We also make efforts to visualize the tree-based convolution process. shedding light on how our models work.,True,PPqcVRwAAAAJ:Wp0gIr-vW9MC,130,https://arxiv.org/abs/1504.01106,11792353655532335112,/scholar?cites=11792353655532335112,,,https://arxiv.org/pdf/1504.01106,0,0,0
1281906,A metamodel for the notation of graphical modeling languages,2007,Xiao He and Zhiyi Ma and Weizhong Shao and Ge Li,1,,,219-224,IEEE,In order to define a graphical modeling language. it is necessary to define the graphical notation of the language in the process of metamodeling. So the defining of the notation has become one of the essential functions in meta-modeling tools. This paper proposed the Notation Definition Metamodel (NDM) for metamodeling tools. NDM is used to define the graphical notation. It consists of three parts: basic figures and layouts. location relations and syntax bridges. NDM has been implemented in PKU Meta- Model Tool (PkuMMT). The paper made a case study to illustrate the feasibility of NDM. Besides. a comparison between PKU MMT and some metamodeling tools is presented to show the capability and advantages of NDM.,True,PPqcVRwAAAAJ:IWHjjKOFINEC,102,https://ieeexplore.ieee.org/abstract/document/4291008/,15767724341824559904,/scholar?cites=15767724341824559904,,,,0,0,0
1281907,Discriminating induced seismicity from natural earthquakes using moment tensors and source spectra,2016,Hongliang Zhang and David W Eaton and Ge Li and Yajing Liu and Rebecca M Harrington,121,Journal of Geophysical Research: Solid Earth,2,972-993,,Earthquake source mechanisms and spectra can provide important clues to aid in discriminating between natural and induced events. In this study. we calculate moment tensors and stress drop values for eight recent induced earthquakes in the Western Canadian Sedimentary Basin with magnitudes between 3.2 and 4.4. as well as a nearby magnitude 5.3 event that is interpreted as a natural earthquake. We calculate full moment tensor solutions by performing a waveform‐fitting procedure based on a 1‐D transversely isotropic velocity model. In addition to a dominant double‐couple (DC) signature that is common to nearly all events. most induced events exhibit significant non‐double‐couple components. A parameter sensitivity analysis indicates that spurious non‐DC components are negligible if the signal to noise ratio (SNR) exceeds 10 and if the 1‐D model differs from the true velocity structure by less than 5 …,True,PPqcVRwAAAAJ:ZHo1McVdvXMC,85,https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2015JB012603,15468531561890928663,/scholar?cites=15468531561890928663,,,https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2015JB012603,0,0,0
1281908,Building program vector representations for deep learning,2015,Hao Peng and Lili Mou and Ge Li and Yuxuan Liu and Lu Zhang and Zhi Jin,,,,547-553,Springer. Cham,Deep learning has made significant breakthroughs in various fields of artificial intelligence. However. it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation. In this pioneering paper. we propose the “coding criterion” to build program vector representations. which are the premise of deep learning for program analysis. We evaluate the learned vector representations both qualitatively and quantitatively. We conclude. based on the experiments. the coding criterion is successful in building program representations. To evaluate whether deep learning is beneficial for program analysis. we feed the representations to deep neural networks. and achieve higher accuracy in the program classification task than “shallow” methods. This result confirms the feasibility of deep learning to analyze programs.,True,PPqcVRwAAAAJ:TQgYirikUcIC,84,https://link.springer.com/chapter/10.1007/978-3-319-25159-2_49,17453886396576210217,/scholar?cites=17453886396576210217,,,,0,0,0
1281909,Block partitioning structure in the HEVC standard,2012,Il-Koo Kim and Junghye Min and Tammy Lee and Woo-Jin Han and JeongHoon Park,22,IEEE transactions on circuits and systems for video technology,12,1697-1706,IEEE,High Efficiency Video Coding (HEVC) is the latest joint standardization effort of ITU-T WP 3/16 and ISO/IEC JTC 1/SC 29/WG 11. The resultant standard will be published as twin text by ITU-T and ISO/IEC; in the latter case. it will also be known as MPEG-H Part 2. This paper describes the block partitioning structure of the draft HEVC standard and presents the results of an analysis of coding efficiency and complexity. Of the many new technical aspects of HEVC. the block partitioning structure has been identified as representing one of the most significant changes relative to previous video coding standards. In contrast to the fixed size 16 × 16 macroblock structure of H.264/AVC. HEVC defines three different units according to their functionalities. The coding unit defines a region sharing the same prediction mode. e.g.. intra and inter. and it is represented by the leaf node of a quadtree structure. The prediction unit …,True,nS5xmw4AAAAJ:9yKSN-GCB0IC,452,https://ieeexplore.ieee.org/abstract/document/6324412/,5788277228730507386,/scholar?cites=5788277228730507386,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.352.1947&rep=rep1&type=pdf,0,0,0
1281910,Samsung’s response to the call for proposals on video compression technology,2010,Nikolay Shlyakhov Ken McCann and Woo-Jin Han and Il-Koo Kim and Jung-Hye Min,,"JCTVC-A124, Dresden, Germany",,,,,True,nS5xmw4AAAAJ:fPk4N6BV_jEC,384,,1726019545303013858,/scholar?cites=1726019545303013858,,,,0,0,0
1281911,Improved video compression efficiency through flexible unit representation and corresponding extension of coding tools,2010,Woo-Jin Han and Junghye Min and Il-Koo Kim and Elena Alshina and Alexander Alshin and Tammy Lee and Jianle Chen and Vadim Seregin and Sunil Lee and Yoon Mi Hong and Min-Su Cheon and Nikolay Shlyakhov and Ken McCann and Thomas Davies and Jeong-Hoon Park,20,IEEE Transactions on Circuits and Systems for Video Technology,12,1709-1720,IEEE,This paper proposes a novel video compression scheme based on a highly flexible hierarchy of unit representation which includes three block concepts: coding unit (CU). prediction unit (PU). and transform unit (TU). This separation of the block structure into three different concepts allows each to be optimized according to its role; the CU is a macroblock-like unit which supports region splitting in a manner similar to a conventional quadtree. the PU supports nonsquare motion partition shapes for motion compensation. while the TU allows the transform size to be defined independently from the PU. Several other coding tools are extended to arbitrary unit size to maintain consistency with the proposed design. e.g.. transform size is extended up to 64 × 64 and intraprediction is designed to support an arbitrary number of angles for variable block sizes. Other novel techniques such as a new noncascading interpolation …,True,nS5xmw4AAAAJ:u5HHmVD_uO8C,222,https://ieeexplore.ieee.org/abstract/document/5638199/,14262383092222787332,/scholar?cites=14262383092222787332,,,,0,0,0
1281912,High efficiency video coding (HEVC) test model 16 (HM 16) encoder description,2014,K McCann and B Bross and WJ Han and IK Kim and K Sugimoto and GJ Sullivan,1002,"JCT-VC, Doc. JCTVC N",,,,,True,nS5xmw4AAAAJ:JWITY9-sCbMC,128,http://scholar.google.com/scholar?cluster=7498016010116710639&hl=en&oi=scholarr,7498016010116710639,/scholar?cites=7498016010116710639,,,,0,0,0
1281913,High efficiency video coding (HEVC) test model 10 (HM10) encoder description,2013,Il-Koo Kim and Ken McCann and Kazuo Sugimoto and Benjamin Bross and Woo-Jin Han and Gary Sullivan,,"Document: JCTVC-O1002, Joint Collaborative Team on Video Coding (JCT-VC) of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11, 15th Meeting: Geneva",,,,,True,nS5xmw4AAAAJ:1tZ8xJnm2c8C,128,http://scholar.google.com/scholar?cluster=11879103971245050843&hl=en&oi=scholarr,11879103971245050843,/scholar?cites=11879103971245050843,,,,0,0,0
1281914,HM9: High efficiency video coding (HEVC) test model 9 encoder description,2012,Il-Koo Kim and Ken McCann and Kazuo Sugimoto and Benjamin Bross and Woo-Jin Han,,Proc. 9th JCT-VC Meeting,,6-11,,The JCT-VC established a 9th HEVC test model (HM9) at its 11th meeting in Shanghai from 10 October to 19 October 2012. This document serves as a source of general tutorial information on HEVC and also provides an encoder-side description of HM9.,True,nS5xmw4AAAAJ:qjMakFHDy7sC,115,http://scholar.google.com/scholar?cluster=1274101147153862773&hl=en&oi=scholarr,1274101147153862773,/scholar?cites=1274101147153862773,,,,0,0,0
1281915,Method and apparatus for encoding video by using block merging. and method and apparatus for decoding video by using block merging,2014,Tammy Lee and Woo-jin Han and Il-koo Kim and Sun-il Lee,,,,,,Provided are a method and apparatus for encoding a video by using block merging and a method and apparatus for decoding a video by using block merging. The method of encoding includes: determining an encoding mode indicating a current data unit for encoding of a picture and an encoding method including prediction encoding performed for the current data unit; determining an occurrence of merging with at least one neighboring data unit based on at least one of the encoding mode and a prediction mode; and determining prediction mode information. merging related information. and prediction related information. and determining encoding information of the data unit including the prediction mode information. the merging related information. and the prediction related information.,True,nS5xmw4AAAAJ:YlPif8NxrbYC,102,https://patents.google.com/patent/US8885727B2/en,9855056173345308246,/scholar?cites=9855056173345308246,,,https://patentimages.storage.googleapis.com/bb/e5/49/f6f67aba37d89d/US8885727.pdf,0,0,0
1281916,Method and apparatus for encoding video. and method and apparatus for decoding video,2013,Jung-hye Min and Woo-jin Han and Il-koo Kim,,,,,,Disclosed are a method and a apparatus for encoding a video. and a method and apparatus for decoding a video. in which neighboring pixels used to perform intra prediction on a current block to be encoded are filtered and intra prediction is performed by using the filtered neighboring pixels.,True,nS5xmw4AAAAJ:qE4H1tSSYIIC,97,https://patents.google.com/patent/US8605784B2/en,16013067610006197218,/scholar?cites=16013067610006197218,,,https://patentimages.storage.googleapis.com/c4/97/66/390ea5b4a687d4/US8605784.pdf,0,0,0
1281917,Method and apparatus for encoding video and method and apparatus for decoding video. based on hierarchical structure of coding unit,2014,Woo-jin Han and Jung-hye Min and Il-koo Kim,,,,,,An apparatus and method for encoding video data and an apparatus and method for decoding video data are provided. The encoding method includes: splitting a current picture into at least one maximum coding unit; determining a coded depth to output an encoding result by encoding at least one split region of the at least one maximum coding unit according to operating mode of coding tool. respectively. based on a relationship among a depth of at least one coding unit of the at least one maximum coding unit. a coding tool. and an operating mode. wherein the at least one split region is generated by hierarchically splitting the at least one maximum coding unit according to depths; and outputting a bitstream including encoded video data of the coded depth. information regarding a coded depth of at least one maximum coding unit. information regarding an encoding mode. and information regarding the relationship.,True,nS5xmw4AAAAJ:8k81kl-MbHgC,75,https://patents.google.com/patent/US8798159B2/en,12081325049706158683,/scholar?cites=12081325049706158683,,,https://patentimages.storage.googleapis.com/6c/ea/a6/5d8e54a39dc2f0/US8798159.pdf,0,0,0
1281918,Method and apparatus for encoding video. and method and apparatus for decoding video,2016,Hak-sup Song and Jung-hye Min,,,,,,Disclosed are method and apparatus for encoding and decoding an image which divides a current picture into blocks with various sizes and varies a number of intra prediction modes according to the sizes of the divided blocks.,True,nS5xmw4AAAAJ:j3f4tGmQtD8C,74,https://patents.google.com/patent/US9313502B2/en,8728528188842931718,/scholar?cites=8728528188842931718,,,https://patentimages.storage.googleapis.com/15/1f/b0/0b0586fad5906f/US9313502.pdf,0,0,0
1281919,Method and apparatus for encoding video in consideration of scanning order of coding units having hierarchical structure. and method and apparatus for decoding video in …,2013,Hae-kyung Jung and Min-su Cheon and Jung-hye Min and Il-koo Kim,,,,,,A method and apparatus for decoding a video and a method and apparatus for encoding a video are provided. The method for decoding the video includes: receiving and parsing a bitstream of an encoded video; extracting. from the bitstream. encoded image data of a current picture of the encoded video assigned to a maximum coding unit. and information about a coded depth and an encoding mode according to the maximum coding unit; and decoding the encoded image data for the maximum coding unit based on the information about the coded depth and the encoding mode for the maximum coding unit. in consideration of a raster scanning order for the maximum coding unit and a zigzag scanning order for coding units of the maximum coding unit according to depths.,True,nS5xmw4AAAAJ:hqOjcs7Dif8C,69,https://patents.google.com/patent/US8532185B2/en,15546607393380689178,/scholar?cites=15546607393380689178,,,https://patentimages.storage.googleapis.com/e5/63/ad/f5c4b1026cf3d1/US8532185.pdf,0,0,0
1281920,SAGA interacting factors confine sub-diffusion of transcribed genes to the nuclear envelope,2006,Ghislain G Cabal and Auguste Genovesio and Susana Rodriguez-Navarro and Christophe Zimmer and Olivier Gadal and Annick Lesne and Henri Buc and Frank Feuerbach-Fournier and Jean-Christophe Olivo-Marin and Eduard C Hurt and Ulf Nehrbass,441,Nature,7094,770-773,Nature Publishing Group,Changes in the transcriptional state of genes have been correlated with their repositioning within the nuclear space 1. Tethering reporter genes to the nuclear envelope alone can impose repression 2 and recent reports have shown that. after activation. certain genes can also be found closer to the nuclear periphery 3. 4. 5. 6. The molecular mechanisms underlying these phenomena have remained elusive. Here. with the use of dynamic three-dimensional tracking of a single locus in live yeast (Saccharomyces cerevisiae) cells. we show that the activation of GAL genes (GAL7. GAL10 and GAL1) leads to a confinement in dynamic motility. We demonstrate that the GAL locus is subject to sub-diffusive movement. which after activation can become constrained to a two-dimensional sliding motion along the nuclear envelope. RNA-fluorescence in situ hybridization analysis after activation reveals a higher transcriptional …,True,hE2StEAAAAAJ:u5HHmVD_uO8C,472,https://www.nature.com/articles/nature04752,1262135480491611933,/scholar?cites=1262135480491611933,,,https://www.researchgate.net/profile/Susana_Rodriguez-Navarro/publication/7022230_SAGA_interacting_factors_confine_sub-diffusion_of_transcribed_genes_to_the_nuclear_envelope/links/0912f5089a07fca4bf000000.pdf,0,0,0
1281921,Quantitative four-dimensional tracking of cytoplasmic and nuclear HIV-1 complexes,2006,Nathalie Arhel and Auguste Genovesio and Kyeong-Ae Kim and Sarah Miko and Emmanuelle Perret and Jean-Christophe Olivo-Marin and Spencer Shorte and Pierre Charneau,3,Nature methods,10,817-824,Nature Publishing Group,Emerging real-time techniques for imaging viral infections provide powerful tools for understanding the dynamics of virus-host cell interactions. Here we labeled human immunodeficiency virus-1 (HIV-1) integrase with a small tetracysteine tag. which preserved the virus' infectivity while allowing it to be labeled with the bis-arsenical fluorescein derivative FlAsH. This labeling allowed us to image both intracytoplasmic and intranuclear HIV-1 complexes in three dimensions over time (4D) in human cells and enabled us to analyze HIV-1 kinetics by automated 4D quantitative particle tracking. In the cytoplasm. HIV-1 complexes underwent directed movements toward the nuclear compartment. kinetically characteristic of both microtubule-and actin-dependent transport. The complexes then adopted smaller movements in a very confined volume once associated with the nuclear membrane and more diffuse movements once …,True,hE2StEAAAAAJ:u-x6o8ySG0sC,329,https://www.nature.com/articles/nmeth928,3431918086482516657,/scholar?cites=3431918086482516657,,,https://www.researchgate.net/profile/Pierre_Charneau/publication/6803372_Quantitative_4D_trascking_of_cytoplasmic_and_nuclear_HIV-1_complexes/links/0c9605322d1ec8a997000000/Quantitative-4D-trascking-of-cytoplasmic-and-nuclear-HIV-1-complexes.pdf,0,0,0
1281922,High content screening identifies decaprenyl-phosphoribose 2′ epimerase as a target for intracellular antimycobacterial inhibitors,2009,Thierry Christophe and Mary Jackson and Hee Kyoung Jeon and Denis Fenistein and Monica Contreras-Dominguez and Jaeseung Kim and Auguste Genovesio and Jean-Philippe Carralot and Fanny Ewann and Eun Hye Kim and Sae Yeon Lee and Sunhee Kang and Min Jung Seo and Eun Jung Park and Henrieta Škovierová and Ha Pham and Giovanna Riccardi and Ji Youn Nam and Laurent Marsollier and Marie Kempf and Marie-Laure Joly-Guillou and Taegwon Oh and Won Kyung Shin and Zaesung No and Ulf Nehrbass and Roland Brosch and Stewart T Cole and Priscille Brodin,5,PLoS Pathog,10,e1000645,Public Library of Science,A critical feature of Mycobacterium tuberculosis. the causative agent of human tuberculosis (TB). is its ability to survive and multiply within macrophages. making these host cells an ideal niche for persisting microbes. Killing the intracellular tubercle bacilli is a key requirement for efficient tuberculosis treatment. yet identifying potent inhibitors has been hampered by labor-intensive techniques and lack of validated targets. Here. we present the development of a phenotypic cell-based assay that uses automated confocal fluorescence microscopy for high throughput screening of chemicals that interfere with the replication of M. tuberculosis within macrophages. Screening a library of 57.000 small molecules led to the identification of 135 active compounds with potent intracellular anti-mycobacterial efficacy and no host cell toxicity. Among these. the dinitrobenzamide derivatives (DNB) showed high activity against M. tuberculosis. including extensively drug resistant (XDR) strains. More importantly. we demonstrate that incubation of M. tuberculosis with DNB inhibited the formation of both lipoarabinomannan and arabinogalactan. attributable to the inhibition of decaprenyl-phospho-arabinose synthesis catalyzed by the decaprenyl-phosphoribose 2′ epimerase DprE1/DprE2. Inhibition of this new target will likely contribute to new therapeutic solutions against emerging XDR-TB. Beyond validating the high throughput/content screening approach. our results open new avenues for finding the next generation of antimicrobials.,True,hE2StEAAAAAJ:9yKSN-GCB0IC,306,https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1000645,3354850012501456337,/scholar?cites=3354850012501456337,,,https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1000645,0,0,0
1281923,Multiple particle tracking in 3-D+ t microscopy: method and application to the tracking of endocytosed quantum dots,2006,Auguste Genovesio and Tim Liedl and Valentina Emiliani and Wolfgang J Parak and Maité Coppey-Moisan and J-C Olivo-Marin,15,IEEE Transactions on Image Processing,5,1062-1070,IEEE,We propose a method to detect and track multiple moving biological spot-like particles showing different kinds of dynamics in image sequences acquired through multidimensional fluorescence microscopy. It enables the extraction and analysis of information such as number. position. speed. movement. and diffusion phases of. e.g.. endosomal particles. The method consists of several stages. After a detection stage performed by a three-dimensional (3-D) undecimated wavelet transform. we compute. for each detected spot. several predictions of its future state in the next frame. This is accomplished thanks to an interacting multiple model (IMM) algorithm which includes several models corresponding to different biologically realistic movement types. Tracks are constructed. thereafter. by a data association algorithm based on the maximization of the likelihood of each IMM. The last stage consists of updating the IMM …,True,hE2StEAAAAAJ:d1gkVwhDpl0C,226,https://ieeexplore.ieee.org/abstract/document/1621229/,16404374295205053448,/scholar?cites=16404374295205053448,,,https://www.researchgate.net/profile/Maite_Coppey-Moisan/publication/7109905_Multiple_particle_tracking_in_3-D_t_microscopy_Method_and_application_to_the_tracking_of_endocytosed_quantum_dots/links/554b19180cf29752ee7c3a73/Multiple-particle-tracking-in-3-D-t-microscopy-Method-and-application-to-the-tracking-of-endocytosed-quantum-dots.pdf,0,0,0
1281924,Telomere tethering at the nuclear periphery is essential for efficient DNA double strand break repair in subtelomeric region,2006,Pierre Therizols and Cécile Fairhead and Ghislain G Cabal and Auguste Genovesio and Jean-Christophe Olivo-Marin and Bernard Dujon and Emmanuelle Fabre,172,The Journal of cell biology,2,189-199,Rockefeller University Press,In the yeast Saccharomyces cerevisiae that lacks lamins. the nuclear pore complex (NPC) has been proposed to serve a role in chromatin organization. Here. using fluorescence microscopy in living cells. we show that nuclear pore proteins of the Nup84 core complex. Nup84p. Nup145Cp. Nup120p. and Nup133p. serve to anchor telomere XI-L at the nuclear periphery. The integrity of this complex is shown to be required for repression of a URA3 gene inserted in the subtelomeric region of this chromosome end. Furthermore. altering the integrity of this complex decreases the efficiency of repair of a DNA double-strand break (DSB) only when it is generated in the subtelomeric region. even though the repair machinery is functional. These effects are specific to the Nup84 complex. Our observations thus confirm and extend the role played by the NPC. through the Nup84 complex. in the functional organization of …,True,hE2StEAAAAAJ:2osOgNQ5qMEC,210,https://rupress.org/jcb/article/172/2/189/52310,2415423549886285059,/scholar?cites=2415423549886285059,,,https://rupress.org/jcb/article/172/2/189/52310,0,0,0
1281925,Increasing the content of high-content screening: an overview,2014,Shantanu Singh and Anne E Carpenter and Auguste Genovesio,19,,5,640-650,Sage Publications,Target-based high-throughput screening (HTS) has recently been critiqued for its relatively poor yield compared to phenotypic screening approaches. One type of phenotypic screening. image-based high-content screening (HCS). has been seen as particularly promising.In this article. we assess whether HCS is as high content as it can be. We analyze HCS publications and find that although the number of HCS experiments published each year continues to grow steadily. the information content lags behind. We find that a majority of high-content screens published so far (60−80%) made use of only one or two image-based features measured from each sample and disregarded the distribution of those features among each cell population. We discuss several potential explanations. focusing on the hypothesis that data analysis traditions are to blame. This includes practical problems related to managing large and …,True,hE2StEAAAAAJ:eQOLeE2rZwMC,182,https://journals.sagepub.com/doi/abs/10.1177/1087057114528537,11249617136051972330,/scholar?cites=11249617136051972330,,,https://journals.sagepub.com/doi/pdf/10.1177/1087057114528537,0,0,0
1281926,High content phenotypic cell-based visual screen identifies Mycobacterium tuberculosis acyltrehalose-containing glycolipids involved in phagosome remodeling,2010,Priscille Brodin and Yannick Poquet and Florence Levillain and Isabelle Peguillet and Gerald Larrouy-Maumus and Martine Gilleron and Fanny Ewann and Thierry Christophe and Denis Fenistein and Jichan Jang and Mi-Seon Jang and Sei-Jin Park and Jean Rauzier and Jean-Philippe Carralot and Rachel Shrimpton and Auguste Genovesio and Jesus A Gonzalo-Asensio and Germain Puzo and Carlos Martin and Roland Brosch and Graham R Stewart and Brigitte Gicquel and Olivier Neyrolles,6,PLoS Pathog,9,e1001100,Public Library of Science,The ability of the tubercle bacillus to arrest phagosome maturation is considered one major mechanism that allows its survival within host macrophages. To identify mycobacterial genes involved in this process. we developed a high throughput phenotypic cell-based assay enabling individual sub-cellular analysis of over 11.000 Mycobacterium tuberculosis mutants. This very stringent assay makes use of fluorescent staining for intracellular acidic compartments. and automated confocal microscopy to quantitatively determine the intracellular localization of M. tuberculosis. We characterised the ten mutants that traffic most frequently into acidified compartments early after phagocytosis. suggesting that they had lost their ability to arrest phagosomal maturation. Molecular analysis of these mutants revealed mainly disruptions in genes involved in cell envelope biogenesis (fadD28). the ESX-1 secretion system (espL/Rv3880). molybdopterin biosynthesis (moaC1 and moaD1). as well as in genes from a novel locus. Rv1503c-Rv1506c. Most interestingly. the mutants in Rv1503c and Rv1506c were perturbed in the biosynthesis of acyltrehalose-containing glycolipids. Our results suggest that such glycolipids indeed play a critical role in the early intracellular fate of the tubercle bacillus. The unbiased approach developed here can be easily adapted for functional genomics study of intracellular pathogens. together with focused discovery of new anti-microbials.,True,hE2StEAAAAAJ:UeHWp8X0CEIC,177,https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1001100,4455414862821323993,/scholar?cites=4455414862821323993,,,https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1001100,0,0,0
1281927,Cerebral microcirculation shear stress levels determine Neisseria meningitidis attachment sites along the blood–brain barrier,2006,Emilie Mairey and Auguste Genovesio and Emmanuel Donnadieu and Christine Bernard and Francis Jaubert and Elisabeth Pinard and Jacques Seylaz and Jean-Christophe Olivo-Marin and Xavier Nassif and Guillaume Duménil,203,The Journal of experimental medicine,8,1939-1950,Rockefeller University Press, Neisseria meningitidis is a commensal bacterium of the human nasopharynx. Occasionally. this bacterium reaches the bloodstream and causes meningitis after crossing the blood–brain barrier by an unknown mechanism. An immunohistological study of a meningococcal sepsis case revealed that neisserial adhesion was restricted to capillaries located in low blood flow regions in the infected organs. This study led to the hypothesis that drag forces encountered by the meningococcus in the bloodstream determine its attachment site in vessels. We therefore investigated the ability of N. meningitidis to bind to endothelial cells in the presence of liquid flow mimicking the bloodstream with a laminar flow chamber. Strikingly. average blood flows reported for various organs strongly inhibited initial adhesion. As cerebral microcirculation is known to be highly heterogeneous. cerebral blood velocity was investigated at …,True,hE2StEAAAAAJ:qjMakFHDy7sC,161,https://rupress.org/jem/article-abstract/203/8/1939/46515,9001684950663440858,/scholar?cites=9001684950663440858,,,https://rupress.org/jem/article/203/8/1939/46515,0,0,0
1281928,An image-based high-content screening assay for compounds targeting intracellular Leishmania donovani amastigotes in human macrophages,2012,Jair L Siqueira-Neto and Seunghyun Moon and Jiyeon Jang and Gyongseon Yang and Changbok Lee and Hong Kee Moon and Eric Chatelain and Auguste Genovesio and Jonathan Cechetto and Lucio H Freitas-Junior,6,PLoS Negl Trop Dis,6,e1671,Public Library of Science,Leishmaniasis is a tropical disease threatening 350 million people from endemic regions. The available drugs for treatment are inadequate. with limitations such as serious side effects. parasite resistance or high cost. Driven by this need for new drugs. we developed a high-content. high-throughput image-based screening assay targeting the intracellular amastigote stage of different species of Leishmania in infected human macrophages. The in vitro infection protocol was adapted to a 384-well-plate format. enabling acquisition of a large amount of readouts by automated confocal microscopy. The reading method was based on DNA staining and required the development of a customized algorithm to analyze the images. which enabled the use of non-modified parasites. The automated analysis generated parameters used to quantify compound activity. including infection ratio as well as the number of intracellular amastigote parasites and yielded cytotoxicity information based on the number of host cells. Comparison of this assay with one that used the promastigote form to screen 26.500 compounds showed that 50% of the hits selected against the intracellular amastigote were not selected in the promastigote screening. These data corroborate the idea that the intracellular amastigote form of the parasite is the most appropriate to be used in primary screening assay for Leishmania.,True,hE2StEAAAAAJ:W7OEmFMy1HYC,135,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0001671,15403932057368014951,/scholar?cites=15403932057368014951,,,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0001671,0,0,0
1281929,Antileishmanial high-throughput drug screening reveals drug candidates with new scaffolds,2010,Jair L Siqueira-Neto and Ok-Ryul Song and Hyunrim Oh and Jeong-Hun Sohn and Gyongseon Yang and Jiyoun Nam and Jiyeon Jang and Jonathan Cechetto and Chang Bok Lee and Seunghyun Moon and Auguste Genovesio and Eric Chatelain and Thierry Christophe and Lucio H Freitas-Junior,4,PLoS Negl Trop Dis,5,e675,Public Library of Science,Drugs currently available for leishmaniasis treatment often show parasite resistance. highly toxic side effects and prohibitive costs commonly incompatible with patients from the tropical endemic countries. In this sense. there is an urgent need for new drugs as a treatment solution for this neglected disease. Here we show the development and implementation of an automated high-throughput viability screening assay for the discovery of new drugs against Leishmania. Assay validation was done with Leishmania promastigote forms. including the screening of 4.000 compounds with known pharmacological properties. In an attempt to find new compounds with leishmanicidal properties. 26.500 structurally diverse chemical compounds were screened. A cut-off of 70% growth inhibition in the primary screening led to the identification of 567 active compounds. Cellular toxicity and selectivity were responsible for the exclusion of 78% of the pre-selected compounds. The activity of the remaining 124 compounds was confirmed against the intramacrophagic amastigote form of the parasite. In vitro microsomal stability and cytochrome P450 (CYP) inhibition of the two most active compounds from this screening effort were assessed to obtain preliminary information on their metabolism in the host. The HTS approach employed here resulted in the discovery of two new antileishmanial compounds. bringing promising candidates to the leishmaniasis drug discovery pipeline.,True,hE2StEAAAAAJ:IjCSPb-OGe4C,134,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0000675,5546006349970607507,/scholar?cites=5546006349970607507,,,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0000675,0,0,0
1281930,Comparison of methods for image-based profiling of cellular morphological responses to small-molecule treatment,2013,Vebjorn Ljosa and Peter D Caie and Rob Ter Horst and Katherine L Sokolnicki and Emma L Jenkins and Sandeep Daya and Mark E Roberts and Thouis R Jones and Shantanu Singh and Auguste Genovesio and Paul A Clemons and Neil O Carragher and Anne E Carpenter,18,Journal of biomolecular screening,10,1321-1329,SAGE Publications,Quantitative microscopy has proven a versatile and powerful phenotypic screening technique. Recently. image-based profiling has shown promise as a means for broadly characterizing molecules’ effects on cells in several drug-discovery applications. including target-agnostic screening and predicting a compound’s mechanism of action (MOA). Several profiling methods have been proposed. but little is known about their comparative performance. impeding the wider adoption and further development of image-based profiling. We compared these methods by applying them to a widely applicable assay of cultured cells and measuring the ability of each method to predict the MOA of a compendium of drugs. A very simple method that is based on population means performed as well as methods designed to take advantage of the measurements of individual cells. This is surprising because many treatments induced a …,True,hE2StEAAAAAJ:LkGwnXOMwfcC,121,https://journals.sagepub.com/doi/abs/10.1177/1087057113503553,16297734567964341589,/scholar?cites=16297734567964341589,,,https://journals.sagepub.com/doi/full/10.1177/1087057113503553,0,0,0
1281931,Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction,2017,Junbo Zhang and Yu Zheng and Dekang Qi,,,,1655-1661,,Forecasting the flow of crowds is of great importance to traffic management and public safety. and very challenging as it is affected by many complex factors. such as inter-region traffic. events. and weather. We propose a deep-learning-based approach. called ST-ResNet. to collectively forecast the inflow and outflow of crowds in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically. we employ the residual neural network framework to model the temporal closeness. period. and trend properties of crowd traffic. For each property. we design a branch of residual convolutional units. each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data. assigning different weights to different branches and regions. The aggregation is further combined with external factors. such as weather and day of the week. to predict the final traffic of crowds in each and every region. Experiments on two types of crowd flows in Beijing and New York City (NYC) demonstrate that the proposed ST-ResNet outperforms six well-known methods.,True,sQpMBqsAAAAJ:0KyAp5RtaNEC,825,https://ojs.aaai.org/index.php/AAAI/article/view/10735,10585174952970430867,/scholar?cites=10585174952970430867,,,https://ojs.aaai.org/index.php/AAAI/article/view/10735/10594,0,0,0
1281932,DNN-based prediction model for spatio-temporal data,2016,Junbo Zhang and Yu Zheng and Dekang Qi and Ruiyuan Li and Xiuwen Yi,,,,1-4,,Advances in location-acquisition and wireless communication technologies have led to wider availability of spatio-temporal (ST) data. which has unique spatial properties (ie. geographical hierarchy and distance) and temporal properties (ie. closeness. period and trend). In this paper. we propose aDeep-learning-based prediction model forS patio-T emporal data (DeepST). We leverage ST domain knowledge to design the architecture of DeepST. which is comprised of two components: spatio-temporal and global. The spatio-temporal component employs the framework of convolutional neural networks to simultaneously model spatial near and distant dependencies. and temporal closeness. period and trend. The global component is used to capture global factors. such as day of the week. weekday or weekend. Using DeepST. we build a real-time crowd flow forecasting system called UrbanFlow 1. Experiment …,True,sQpMBqsAAAAJ:AvfA0Oy_GE0C,337,https://dl.acm.org/doi/abs/10.1145/2996913.2997016,1696978761312959946,/scholar?cites=1696978761312959946,,,http://bucket.kangry.net/paper/%2FDeepST-SIGSPATIAL2016_Zheng-2.compressed.pdf,0,0,0
1281933,Predicting citywide crowd flows using deep spatio-temporal residual networks,2018,Junbo Zhang and Yu Zheng and Dekang Qi and Ruiyuan Li and Xiuwen Yi and Tianrui Li,259,Artificial Intelligence,,147-166,Elsevier,Forecasting the flow of crowds is of great importance to traffic management and public safety. and very challenging as it is affected by many complex factors. including spatial dependencies (nearby and distant). temporal dependencies (closeness. period. trend). and external conditions (e.g. weather and events). We propose a deep-learning-based approach. called ST-ResNet. to collectively forecast two types of crowd flows (i.e. inflow and outflow) in each and every region of a city. We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data. More specifically. we employ the residual neural network framework to model the temporal closeness. period. and trend properties of crowd traffic. For each property. we design a branch of residual convolutional units. each of which models the spatial properties of crowd traffic. ST-ResNet learns to dynamically aggregate the output of the …,True,sQpMBqsAAAAJ:BUYA1_V_uYcC,175,https://www.sciencedirect.com/science/article/pii/S0004370218300973,3075338200776904349,/scholar?cites=3075338200776904349,,,https://arxiv.org/pdf/1701.02543,0,0,0
1281934,GeoMAN: Multi-level Attention Networks for Geo-sensory Time Series Prediction.,2018,Yuxuan Liang and Songyu Ke and Junbo Zhang and Xiuwen Yi and Yu Zheng,,,,3428-3434,,Numerous sensors have been deployed in different geospatial locations to continuously and cooperatively monitor the surrounding environment. such as the air quality. These sensors generate multiple geo-sensory time series. with spatial correlations between their readings. Forecasting geo-sensory time series is of great importance yet very challenging as it is affected by many complex factors. ie. dynamic spatio-temporal correlations and external factors. In this paper. we predict the readings of a geo-sensor over several future hours by using a multi-level attention-based recurrent neural network that considers multiple sensors’ readings. meteorological data. and spatial data. More specifically. our model consists of two major parts: 1) a multi-level attention mechanism to model the dynamic spatio-temporal dependencies. 2) a general fusion module to incorporate the external factors from different domains. Experiments on two types of real-world datasets. viz.. air quality data and water quality data. demonstrate that our method outperforms nine baseline methods.,True,sQpMBqsAAAAJ:L7CI7m0gUJcC,169,http://urban-computing.com/pdf/liang2018geoman.pdf,17879993717219963711,/scholar?cites=17879993717219963711,,,http://urban-computing.com/pdf/liang2018geoman.pdf,0,0,0
1281935,Rough sets based matrix approaches with dynamic attribute variation in set-valued information systems,2012,Junbo Zhang and Tianrui Li and Da Ruan and Dun Liu,53,International Journal of Approximate Reasoning,4,620-635,Elsevier,Set-valued information systems are generalized models of single-valued information systems. The attribute set in the set-valued information system may evolve over time when new information arrives. Approximations of a concept by rough set theory need updating for knowledge discovery or other related tasks. Based on a matrix representation of rough set approximations. a basic vector H(X) is induced from the relation matrix. Four cut matrices of H(X). denoted by H[μ.ν](X). H(μ.ν](X). H[μ.ν)(X) and H(μ.ν)(X). are derived for the approximations. positive. boundary and negative regions intuitively. The variation of the relation matrix is discussed while the system varies over time. The incremental approaches for updating the relation matrix are proposed to update rough set approximations. The algorithms corresponding to the incremental approaches are presented. Extensive experiments on different data sets from UCI …,True,sQpMBqsAAAAJ:UeHWp8X0CEIC,158,https://www.sciencedirect.com/science/article/pii/S0888613X12000023,17838792407244192477,/scholar?cites=17838792407244192477,,,https://www.sciencedirect.com/science/article/pii/S0888613X12000023/pdf?md5=5d5543dce5d8416d91de2b88e714904e&pid=1-s2.0-S0888613X12000023-main.pdf&_valck=1,0,0,0
1281936,Composite rough sets for dynamic data mining,2014,Junbo Zhang and Tianrui Li and Hongmei Chen,,Information Sciences,,,Elsevier,As a soft computing tool. rough set theory has become a popular mathematical framework for pattern recognition. data mining and knowledge discovery. It can only deal with attributes of a specific type in the information system by using a specific binary relation. However. there may be attributes of multiple different types in information systems in real-life applications. Such information systems are called as composite information systems in this paper. A composite relation is proposed to process attributes of multiple different types simultaneously in composite information systems. Then. an extended rough set model. called as composite rough sets. is presented. We also redefine lower and upper approximations. positive. boundary and negative regions in composite rough sets. Through introducing the concepts of the relation matrix. the decision matrix and the basic matrix. we propose matrix-based methods for …,True,sQpMBqsAAAAJ:maZDTaKrznsC,156,https://www.sciencedirect.com/science/article/pii/S0020025513005768,14035692003849967051,/scholar?cites=14035692003849967051,,,,0,0,0
1281937,A fuzzy rough set approach for incremental feature selection on hybrid information systems,2015,Anping Zeng and Tianrui Li and Dun Liu and Junbo Zhang and Hongmei Chen,258,Fuzzy Sets and Systems,,39-60,North-Holland,In real-applications. there may exist many kinds of data (e.g.. boolean. categorical. real-valued and set-valued data) and missing data in an information system which is called as a Hybrid Information System (HIS). A new Hybrid Distance (HD) in HIS is developed based on the value difference metric. and a novel fuzzy rough set is constructed by combining the HD distance and the Gaussian kernel. Considering the information systems often vary with time. the updating mechanisms for attribute reduction (feature selection) are analyzed with the variation of the attribute set. Fuzzy rough set approaches for incremental feature selection on HIS are presented. Then two corresponding incremental algorithms are proposed. respectively. Finally. extensive experiments on eight datasets from UCI and an artificial dataset show that the incremental approaches significantly outperform non-incremental approaches with feature …,True,sQpMBqsAAAAJ:JoZmwDi-zQgC,144,https://www.sciencedirect.com/science/article/pii/S0165011414003819,11165879833483445849,/scholar?cites=11165879833483445849,,,,0,0,0
1281938,When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks,2018,Dong Wang and Junbo Zhang and Wei Cao and Jian Li and Yu Zheng,,,,,,Estimating the travel time of any path (denoted by a sequence of connected road segments) in a city is of great importance to traffic monitoring. route planning. ridesharing. taxi/Uber dispatching. etc. However. it is a very challenging problem. affected by diverse complex factors. including spatial correlations. temporal dependencies. external conditions (eg weather. traffic lights). Prior work usually focuses on estimating the travel times of individual road segments or sub-paths and then summing up these times. which leads to an inaccurate estimation because such approaches do not consider road intersections/traffic lights. and local errors may accumulate. To address these issues. we propose an end-to-end Deep learning framework for Travel Time Estimation called DeepTTE that estimates the travel time of the whole path directly. More specifically. we present a geo-convolution operation by integrating the geographic information into the classical convolution. capable of capturing spatial correlations. By stacking recurrent unit on the geo-convoluton layer. our DeepTTE can capture the temporal dependencies simultaneously. A multi-task learning component is given on the top of DeepTTE. that estimates the travel time of both the entire path and each local path simultaneously during the training phase. The extensive experiments on two large-scale datasets shows our DeepTTE significantly outperforms the state-of-the-art methods.,True,sQpMBqsAAAAJ:vbGhcppDl1QC,138,https://ojs.aaai.org/index.php/AAAI/article/view/11877,4083574176925708256,/scholar?cites=4083574176925708256,,,https://ojs.aaai.org/index.php/AAAI/article/download/11877/11736,0,0,0
1281939,A parallel method for computing rough set approximations,2012,Junbo Zhang and Tianrui Li and Da Ruan and Zizhe Gao and Chengbing Zhao,,Information Sciences,,,Elsevier,Massive data mining and knowledge discovery present a tremendous challenge with the data volume growing at an unprecedented rate. Rough set theory has been successfully applied in data mining. The lower and upper approximations are basic concepts in rough set theory. The effective computation of approximations is vital for improving the performance of data mining or other related tasks. The recently introduced MapReduce technique has gained a lot of attention from the scientific community for its applicability in massive data analysis. This paper proposes a parallel method for computing rough set approximations. Consequently. algorithms corresponding to the parallel method based on the MapReduce technique are put forward to deal with the massive data. An extensive experimental evaluation on different large data sets shows that the proposed parallel method is effective for data mining.,True,sQpMBqsAAAAJ:qjMakFHDy7sC,134,https://www.sciencedirect.com/science/article/pii/S0020025512000163,5072755603066479301,/scholar?cites=5072755603066479301,,,,0,0,0
1281940,Neighborhood rough sets for dynamic data mining,2012,Junbo Zhang and Tianrui Li and Da Ruan and Dun Liu,27,International Journal of Intelligent Systems,4,317-342,Wiley Subscription Services. Inc.. A Wiley Company,Approximations of a concept in rough set theory induce rules and need to update for dynamic data mining and related tasks. Most existing incremental methods based on the classical rough set model can only be used to deal with the categorical data. This paper presents a new dynamic method for incrementally updating approximations of a concept under neighborhood rough sets to deal with numerical data. A comparison of the proposed incremental method with a nonincremental method of dynamic maintenance of rough set approximations is conducted by an extensive experimental evaluation on different data sets from UCI. Experimental results show that the proposed method effectively updates approximations of a concept in practice. © 2012 Wiley Periodicals. Inc.,True,sQpMBqsAAAAJ:u-x6o8ySG0sC,129,https://onlinelibrary.wiley.com/doi/abs/10.1002/int.21523,5667730503403546700,/scholar?cites=5667730503403546700,,,,0,0,0
1281941,Deep distributed fusion network for air quality prediction,2018,Xiuwen Yi and Junbo Zhang and Zhaoyuan Wang and Tianrui Li and Yu Zheng,,,,965-973,ACM,Accompanying the rapid urbanization. many developing countries are suffering from serious air pollution problem. The demand for predicting future air quality is becoming increasingly more important to government's policy-making and people's decision making. In this paper. we predict the air quality of next 48 hours for each monitoring station. considering air quality data. meteorology data. and weather forecast data. Based on the domain knowledge about air pollution. we propose a deep neural network (DNN)-based approach (entitled DeepAir). which consists of a spatial transformation component and a deep distributed fusion network. Considering air pollutants' spatial correlations. the former component converts the spatial sparse air quality data into a consistent input to simulate the pollutant sources. The latter network adopts a neural distributed architecture to fuse heterogeneous urban data for simultaneously …,True,sQpMBqsAAAAJ:EYYDruWGBe4C,114,https://dl.acm.org/doi/abs/10.1145/3219819.3219822,12528455641854483840,/scholar?cites=12528455641854483840,,,http://urban-computing.com/pdf/kdd2018AirPrediction-camera.pdf,0,0,0
1281942,Centernet: Keypoint triplets for object detection,2019,Kaiwen Duan and Song Bai and Lingxi Xie and Honggang Qi and Qingming Huang and Qi Tian,,,,6569-6578,,In object detection. keypoint-based approaches often experience the drawback of a large number of incorrect object bounding boxes. arguably due to the lack of an additional assessment inside cropped regions. This paper presents an efficient solution that explores the visual patterns within individual cropped regions with minimal costs. We build our framework upon a representative one-stage keypoint-based detector named CornerNet. Our approach. named CenterNet. detects each object as a triplet. rather than a pair. of keypoints. which improves both precision and recall. Accordingly. we design two customized modules. cascade corner pooling. and center pooling. that enrich information collected by both the top-left and bottom-right corners and provide more recognizable information from the central regions. On the MS-COCO dataset. CenterNet achieves an AP of 47.0%. outperforming all existing one-stage detectors by at least 4.9%. Furthermore. with a faster inference speed than the top-ranked two-stage detectors. CenterNet demonstrates a comparable performance to these detectors. Code is available at https://github. com/Duankaiwen/CenterNet.,True,EEMm7hwAAAAJ:3_LpOwP6eMYC,470,http://openaccess.thecvf.com/content_ICCV_2019/html/Duan_CenterNet_Keypoint_Triplets_for_Object_Detection_ICCV_2019_paper.html,3594606171683130501,/scholar?cites=3594606171683130501,,,https://openaccess.thecvf.com/content_ICCV_2019/papers/Duan_CenterNet_Keypoint_Triplets_for_Object_Detection_ICCV_2019_paper.pdf,0,0,0
1281943,Genetic CNN,2017,Lingxi Xie and Alan Yuille,,,,,,The deep convolutional neural network (CNN) is the state-of-the-art solution for large-scale visual recognition. Following some basic principles such as increasing network depth and constructing highway connections. researchers have manually designed a lot of fixed network architectures and verified their effectiveness. In this paper. we discuss the possibility of learning deep network structures automatically. Note that the number of possible network structures increases exponentially with the number of layers in the network. which motivates us to adopt the genetic algorithm to efficiently explore this large search space. The core idea is to propose an encoding method to represent each network structure in a fixed-length binary string. The genetic algorithm is initialized by generating a set of randomized individuals. In each generation. we define standard genetic operations. eg. selection. mutation and crossover. to generate competitive individuals and eliminate weak ones. The competitiveness of each individual is defined as its recognition accuracy. which is obtained via a standalone training process on a reference dataset. We run the genetic process on CIFAR10. a small-scale dataset. demonstrating its ability to find high-quality structures which are little studied before. The learned powerful structures are also transferrable to the ILSVRC2012 dataset for large-scale visual recognition.,True,EEMm7hwAAAAJ:KS-xo-ZNxMsC,447,http://openaccess.thecvf.com/content_iccv_2017/html/Xie_Genetic_CNN_ICCV_2017_paper.html,3972137416848470599,/scholar?cites=3972137416848470599,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Xie_Genetic_CNN_ICCV_2017_paper.pdf,0,0,0
1281944,Adversarial Examples for Semantic Segmentation and Object Detection,2017,Cihang Xie and Jianyu Wang and Zhishuai Zhang and Yuyin Zhou and Lingxi Xie and Alan Yuille,,,,,,It has been well demonstrated that adversarial examples. ie. natural images with visually imperceptible perturbations added. cause deep networks to fail on image classification. In this paper. we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (eg. the target is a pixel or a receptive field in segmentation. and an object proposal in detection). This inspires us to optimize a loss function over a set of targets for generating adversarial perturbations. Based on this. we propose a novel algorithm named Dense Adversary Generation (DAG). which applies to the state-of-the-art networks for segmentation and detection. We find that the adversarial perturbations can be transferred across networks with different training data. based on different architectures. and even for different recognition tasks. In particular. the transfer ability across networks with the same architecture is more significant than in other cases. Besides. we show that summing up heterogeneous perturbations often leads to better transfer performance. which provides an effective method of black-box adversarial attack.,True,EEMm7hwAAAAJ:xm0LlTxljI0C,446,http://openaccess.thecvf.com/content_iccv_2017/html/Xie_Adversarial_Examples_for_ICCV_2017_paper.html,4402033815466351900,/scholar?cites=4402033815466351900,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Xie_Adversarial_Examples_for_ICCV_2017_paper.pdf,0,0,0
1281945,Progressive darts: Bridging the optimization gap for nas in the wild,2021,Xin Chen and Lingxi Xie and Jun Wu and Qi Tian,129,International Journal of Computer Vision,3,638-655,Springer US,With the rapid development of neural architecture search (NAS). researchers found powerful network architectures for a wide range of vision tasks. Like the manually designed counterparts. we desire the automatically searched architectures to have the ability of being freely transferred to different scenarios. This paper formally puts forward this problem. referred to as NAS in the wild. which explores the possibility of finding the optimal architecture in a proxy dataset and then deploying it to mostly unseen scenarios. We instantiate this setting using a currently popular algorithm named differentiable architecture search (DARTS). which often suffers unsatisfying performance while being transferred across different tasks. We argue that the accuracy drop originates from the formulation that uses a super-network for search but a sub-network for re-training. The different properties of these stages have resulted in a significant …,True,EEMm7hwAAAAJ:KI9T_ytC6pkC,207,https://link.springer.com/article/10.1007/s11263-020-01396-x,14461581774462820536,/scholar?cites=14461581774462820536,,,https://arxiv.org/pdf/1912.10952,0,0,0
1281946,A fixed-point model for pancreas segmentation in abdominal CT scans,2017,Yuyin Zhou and Lingxi Xie and Wei Shen and Yan Wang and Elliot K Fishman and Alan L Yuille,,,,693-701,Springer. Cham,Deep neural networks have been widely adopted for automatic organ segmentation from abdominal CT scans. However. the segmentation accuracy of some small organs (e.g.. the pancreas) is sometimes below satisfaction. arguably because deep networks are easily disrupted by the complex and variable background regions which occupies a large fraction of the input volume. In this paper. we formulate this problem into a fixed-point model which uses a predicted segmentation mask to shrink the input region. This is motivated by the fact that a smaller input region often leads to more accurate segmentation. In the training process. we use the ground-truth annotation to generate accurate input regions and optimize network weights. On the testing stage. we fix the network parameters and update the segmentation results in an iterative manner. We evaluate our approach on the NIH pancreas segmentation dataset …,True,EEMm7hwAAAAJ:R-LXmdHK_14C,183,https://link.springer.com/chapter/10.1007/978-3-319-66182-7_79,7366219800642844434,/scholar?cites=7366219800642844434,,,https://arxiv.org/pdf/1612.08230,0,0,0
1281947,DisturbLabel: Regularizing CNN on the Loss Layer,2016,Lingxi Xie and Jingdong Wang and Zhen Wei and Meng Wang and Qi Tian,,,,4753-4762,IEEE,During a long period of time we are combating over-fitting in the CNN training process with model regularization. including weight decay. model averaging. data augmentation. etc. In this paper. we present DisturbLabel. an extremely simple algorithm which randomly replaces a part of labels as incorrect values in each iteration. Although it seems weird to intentionally generate incorrect training labels. we show that DisturbLabel prevents the network training from over-fitting by implicitly averaging over exponentially many networks which are trained with different label sets. To the best of our knowledge. DisturbLabel serves as the first work which adds noises on the loss layer. Meanwhile. DisturbLabel cooperates well with Dropout to provide complementary regularization functions. Experiments demonstrate competitive recognition results on several popular image recognition datasets.,True,EEMm7hwAAAAJ:ijdKiLOsEJMC,176,http://openaccess.thecvf.com/content_cvpr_2016/html/Xie_DisturbLabel_Regularizing_CNN_CVPR_2016_paper.html,11976349396086878628,/scholar?cites=11976349396086878628,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Xie_DisturbLabel_Regularizing_CNN_CVPR_2016_paper.pdf,0,0,0
1281948,PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search,2020,Yuhui Xu and Lingxi Xie and Xiaopeng Zhang and Xin Chen and Guo-Jun Qi and Qi Tian and Hongkai Xiong,,,,,,Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures. but suffered from large memory and computing overheads in jointly training a super-network and searching for an optimal architecture. In this paper. we present a novel approach. namely. Partially-Connected DARTS. by sampling a small part of super-network to reduce the redundancy in exploring the network space. thereby performing a more efficient search without comprising the performance. In particular. we perform operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. We alleviate it using edge normalization. which adds a new set of edge-level parameters to reduce uncertainty in search. Thanks to the reduced memory cost. PC-DARTS can be trained with a larger batch size and. consequently. enjoys both faster speed and higher training stability. Experimental results demonstrate the effectiveness of the proposed method. Specifically. we achieve an error rate of 2.57% on CIFAR10 with merely 0.1 GPU-days for architecture search. and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) using 3.8 GPU-days for search. Our code has been made available at: this https URL.,True,EEMm7hwAAAAJ:NtCmTCuxid4C,164,https://arxiv.org/abs/1907.05737,1268458894093697275,/scholar?cites=1268458894093697275,,,https://arxiv.org/pdf/1907.05737,0,0,0
1281949,Image Classification and Retrieval are ONE,2015,Lingxi Xie and Richang Hong and Bo Zhang and Qi Tian,,,,3-10,ACM,In this paper. we demonstrate that the essentials of image classification and retrieval are the same. since both tasks could be tackled by measuring the similarity between images. To this end. we propose ONE (Online Nearest-neighbor Estimation). a unified algorithm for both image classification and retrieval. ONE is surprisingly simple. which only involves manual object definition. regional description and nearest-neighbor search. We take advantage of PCA and PQ approximation and GPU parallelization to scale our algorithm up to large-scale image search. Experimental results verify that ONE achieves state-of-the-art accuracy in a wide range of image classification and retrieval benchmarks.,True,EEMm7hwAAAAJ:X0DADzN9RKwC,142,https://dl.acm.org/doi/abs/10.1145/2671188.2749289,11192000178314116415,/scholar?cites=11192000178314116415,,,http://lingxixie.com/PDFs/Xie_ICMR15_ONE.pdf,0,0,0
1281950,Spatial Pooling of Heterogeneous Features for Image Classification,2014,Lingxi Xie and Qi Tian and Meng Wang and Bo Zhang,23,IEEE Transactions on Image Processing,5,1994-2008,IEEE,In image classification tasks. one of the most successful algorithms is the bag-of-features (BoFs) model. Although the BoF model has many advantages. such as simplicity. generality. and scalability. it still suffers from several drawbacks. including the limited semantic description of local descriptors. lack of robust structures upon single visual words. and missing of efficient spatial weighting. To overcome these shortcomings. various techniques have been proposed. such as extracting multiple descriptors. spatial context modeling. and interest region detection. Though they have been proven to improve the BoF model to some extent. there still lacks a coherent scheme to integrate each individual module together. To address the problems above. we propose a novel framework with spatial pooling of complementary features. Our model expands the traditional BoF model on three aspects. First. we propose a new scheme …,True,EEMm7hwAAAAJ:eI34FqJmdUoC,122,https://ieeexplore.ieee.org/abstract/document/6757045/,1643737106964390279,/scholar?cites=1643737106964390279,,,,0,0,0
1281951,Recurrent saliency transformation network: Incorporating multi-stage visual cues for small organ segmentation,2018,Qihang Yu and Lingxi Xie and Yan Wang and Yuyin Zhou and Elliot K Fishman and Alan L Yuille,,,,8280-8289,,We aim at segmenting small organs (eg. the pancreas) from abdominal CT scans. As the target often occupies a relatively small region in the input image. deep neural networks can be easily confused by the complex and variable background. To alleviate this. researchers proposed a coarse-to-fine approach. which used prediction from the first (coarse) stage to indicate a smaller input region for the second (fine) stage. Despite its effectiveness. this algorithm dealt with two stages individually. which lacked optimizing a global energy function. and limited its ability to incorporate multi-stage visual cues. Missing contextual information led to unsatisfying convergence in iterations. and that the fine stage sometimes produced even lower segmentation accuracy than the coarse stage. This paper presents a Recurrent Saliency Transformation Network. The key innovation is a saliency transformation module. which repeatedly converts the segmentation probability map from the previous iteration as spatial weights and applies these weights to the current iteration. This brings us two-fold benefits. In training. it allows joint optimization over the deep networks dealing with different input scales. In testing. it propagates multi-stage visual information throughout iterations to improve segmentation accuracy. Experiments in the NIH pancreas segmentation dataset demonstrate the state-of-the-art accuracy. which outperforms the previous best by an average of over 2%. Much higher accuracies are also reported on several small organs in a larger dataset collected by ourselves. In addition. our approach enjoys better convergence properties. making it more efficient and …,True,EEMm7hwAAAAJ:hNSvKAmkeYkC,109,http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.html,15155276827385660709,/scholar?cites=15155276827385660709,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.pdf,0,0,0
1281952,Attention-guided unified network for panoptic segmentation,2019,Yanwei Li and Xinze Chen and Zheng Zhu and Lingxi Xie and Guan Huang and Dalong Du and Xingang Wang,,,,7026-7035,,This paper studies panoptic segmentation. a recently proposed task which segments foreground (FG) objects at the instance level as well as background (BG) contents at the semantic level. Existing methods mostly dealt with these two problems separately. but in this paper. we reveal the underlying relationship between them. in particular. FG objects provide complementary cues to assist BG understanding. Our approach. named the Attention-guided Unified Network (AUNet). is a unified framework with two branches for FG and BG segmentation simultaneously. Two sources of attentions are added to the BG branch. namely. RPN and FG segmentation mask to provide object-level and pixel-level attentions. respectively. Our approach is generalized to different backbones with consistent accuracy gain in both FG and BG segmentation. and also sets new state-of-the-arts both in the MS-COCO (46.5% PQ) and Cityscapes (59.0% PQ) benchmarks.,True,EEMm7hwAAAAJ:yTLRzDEmwhEC,107,http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Attention-Guided_Unified_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html,17166891561109850161,/scholar?cites=17166891561109850161,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Attention-Guided_Unified_Network_for_Panoptic_Segmentation_CVPR_2019_paper.pdf,0,0,0
1281953,Don't Decay the Learning Rate. Increase the Batch Size,2018,SL Smith and PJ Kindermans and C Ying and QV Le,,,,,,It is common practice to decay the learning rate. Here we show one can usually obtain the same learning curve on both training and test sets by instead increasing the batch size during training. This procedure is successful for stochastic gradient descent (SGD). SGD with momentum. Nesterov momentum. and Adam. It reaches equivalent test accuracies after the same number of training epochs. but with fewer parameter updates. leading to greater parallelism and shorter training times. We can further reduce the number of parameter updates by increasing the learning rate  and scaling the batch size . Finally. one can increase the momentum coefficient  and scale . although this tends to slightly reduce the test accuracy. Crucially. our techniques allow us to repurpose existing training schedules for large batch training with no hyper-parameter tuning. We train ResNet-50 on ImageNet to  validation accuracy in under 30 minutes.,True,FpI8dFwAAAAJ:tOudhMTPpwUC,523,https://arxiv.org/abs/1711.00489,3840223745264283290,/scholar?cites=3840223745264283290,,,https://arxiv.org/pdf/1711.00489.pdf?source=post_page---------------------------,0,0,0
1281954,SchNet–A deep learning architecture for molecules and materials,2018,Kristof T Schütt and Huziel E Sauceda and P-J Kindermans and Alexandre Tkatchenko and K-R Müller,148,The Journal of Chemical Physics,24,241722,AIP Publishing LLC,Deep learning has led to a paradigm shift in artificial intelligence. including web. text. and image search. speech recognition. as well as bioinformatics. with growing impact in chemical physics. Machine learning. in general. and deep learning. in particular. are ideally suitable for representing quantum-mechanical interactions. enabling us to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for molecules and materials. where our model learns chemically plausible embeddings of atom types across the periodic table. Finally. we employ SchNet to predict potential-energy surfaces and …,True,FpI8dFwAAAAJ:B3FOqHPlNUQC,483,https://aip.scitation.org/doi/abs/10.1063/1.5019779,11193808380144737447,/scholar?cites=11193808380144737447,,,https://arxiv.org/pdf/1712.06113,0,0,0
1281955,Deep dynamic neural networks for multimodal gesture segmentation and recognition,2016,Di Wu and Lionel Pigou and Pieter-Jan Kindermans and Nam Do-Hoang Le and Ling Shao and Joni Dambre and Jean-Marc Odobez,38,IEEE transactions on pattern analysis and machine intelligence,8,1583-1597,IEEE,This paper describes a novel method called Deep Dynamic Neural Networks (DDNN) for multimodal gesture recognition. A semi-supervised hierarchical dynamic framework based on a Hidden Markov Model (HMM) is proposed for simultaneous gesture segmentation and recognition where skeleton joint information. depth and RGB images. are the multimodal input observations. Unlike most traditional approaches that rely on the construction of complex handcrafted features. our approach learns high-level spatiotemporal representations using deep neural networks suited to the input modality: a Gaussian-Bernouilli Deep Belief Network (DBN) to handle skeletal dynamics. and a 3D Convolutional Neural Network (3DCNN) to manage and fuse batches of depth and RGB images. This is achieved through the modeling and learning of the emission probabilities of the HMM required to infer the gesture sequence. This …,True,FpI8dFwAAAAJ:P5F9QuxV20EC,366,https://ieeexplore.ieee.org/abstract/document/7423804/,4104339414201752881,/scholar?cites=4104339414201752881,,,https://ieeexplore.ieee.org/iel7/34/4359286/07423804.pdf,0,0,0
1281956,Understanding and simplifying one-shot architecture search,2018,Gabriel M. Bender and Pieter-jan Kindermans and Barret Zoph and Vijay Vasudevan and Quoc Le,,,,,,There is growing interest in automating neural network architecture design. Existing architecture search methods can be computationally expensive. requiring thousands of different architectures to be trained from scratch. Recent work has explored weight sharing across models to amortize the cost of training. Although previous methods reduced the cost of architecture search by orders of magnitude. they remain complex. requiring hypernetworks or reinforcement learning controllers. We aim to understand weight sharing for one-shot architecture search. With careful experimental analysis. we show that it is possible to efficiently identify promising architectures from a complex search space without either hypernetworks or RL.,True,FpI8dFwAAAAJ:olpn-zPbct0C,321,http://proceedings.mlr.press/v80/bender18a.html,7510080748852519361,/scholar?cites=7510080748852519361,,,http://proceedings.mlr.press/v80/bender18a/bender18a.pdf,0,0,0
1281957,Schnet: A continuous-filter convolutional neural network for modeling quantum interactions,2017,Kristof T Schütt and Pieter-Jan Kindermans and Huziel E Sauceda and Stefan Chmiela and Alexandre Tkatchenko and Klaus-Robert Müller,,arXiv preprint arXiv:1706.08566,,,,Deep learning has the potential to revolutionize quantum chemistry as it is ideally suited to learn representations for structured data and speed up the exploration of chemical space. While convolutional neural networks have proven to be the first choice for images. audio and video data. the atoms in molecules are not restricted to a grid. Instead. their precise locations contain essential physical information. that would get lost if discretized. Thus. we propose to use continuous-filter convolutional layers to be able to model local correlations without requiring the data to lie on a grid. We apply those layers in SchNet: a novel deep learning architecture modeling quantum interactions in molecules. We obtain a joint model for the total energy and interatomic forces that follows fundamental quantum-chemical principles. This includes rotationally invariant energy predictions and a smooth. differentiable potential energy surface. Our architecture achieves state-of-the-art performance for benchmarks of equilibrium molecules and molecular dynamics trajectories. Finally. we introduce a more challenging benchmark with chemical and structural variations that suggests the path for further work.,True,FpI8dFwAAAAJ:738O_yMBCRsC,262,https://arxiv.org/abs/1706.08566,15908722681579728959,/scholar?cites=15908722681579728959,,,https://arxiv.org/pdf/1706.08566,0,0,0
1281958,Sign language recognition using convolutional neural networks,2014,Lionel Pigou and Sander Dieleman and Pieter-Jan Kindermans and Benjamin Schrauwen,,,,572-578,Springer. Cham,There is an undeniable communication problem between the Deaf community and the hearing majority. Innovations in automatic sign language recognition try to tear down this communication barrier. Our contribution considers a recognition system using the Microsoft Kinect. convolutional neural networks (CNNs) and GPU acceleration. Instead of constructing complex handcrafted features. CNNs are able to automate the process of feature construction. We are able to recognize 20 Italian gestures with high accuracy. The predictive model is able to generalize on users and surroundings not occurring during training with a cross-validation accuracy of 91.7%. Our model achieves a mean Jaccard Index of 0.789 in the ChaLearn 2014 Looking at People gesture spotting competition.,True,FpI8dFwAAAAJ:abG-DnoFyZgC,259,https://link.springer.com/chapter/10.1007/978-3-319-16178-5_40,7105559976807502795,/scholar?cites=7105559976807502795,,,https://link.springer.com/content/pdf/10.1007/978-3-319-16178-5_40.pdf,0,0,0
1281959,Learning how to explain neural networks: PatternNet and PatternAttribution,2018,Pieter-Jan Kindermans and Kristof T. Schuett and Maximilian Alber and Klaus-Robert Müller and Dumitru Erhan and Been Kim and Sven Daehne,,,,,,DeConvNet. Guided BackProp. LRP. were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity. the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.,True,FpI8dFwAAAAJ:sSrBHYA8nusC,240,https://arxiv.org/abs/1705.05598,2569380699011746948,/scholar?cites=2569380699011746948,,,https://arxiv.org/pdf/1705.05598,0,0,0
1281960,The (un) reliability of saliency methods,2019,Pieter-Jan Kindermans and Sara Hooker and Julius Adebayo and Maximilian Alber and Kristof T Schütt and Sven Dähne and Dumitru Erhan and Been Kim,,,,267-280,Springer. Cham,Saliency methods aim to explain the predictions of deep neural networks. These methods lack reliability when the explanation is sensitive to factors that do not contribute to the model prediction. We use a simple and common pre-processing step which can be compensated for easily—adding a constant shift to the input data—to show that a transformation with no effect on how the model makes the decision can cause numerous methods to attribute incorrectly. In order to guarantee reliability. we believe that the explanation should not change when we can guarantee that two networks process the images in identical manners. We show. through several examples. that saliency methods that do not satisfy this requirement result in misleading attribution. The approach can be seen as a type of unit test; we construct a narrow ground truth to measure one stated desirable property. As such. we hope the community will …,True,FpI8dFwAAAAJ:08ZZubdj9fEC,239,https://link.springer.com/chapter/10.1007/978-3-030-28954-6_14,14450824162613386137,/scholar?cites=14450824162613386137,,,https://arxiv.org/pdf/1711.00867,0,0,0
1281961,A benchmark for interpretability methods in deep neural networks,2018,Sara Hooker and Dumitru Erhan and Pieter-Jan Kindermans and Been Kim,,arXiv preprint arXiv:1806.10758,,,,We propose an empirical measure of the approximate accuracy of feature importance estimates in deep neural networks. Our results across several large-scale image classification datasets show that many popular interpretability methods produce estimates of feature importance that are not better than a random designation of feature importance. Only certain ensemble based approaches---VarGrad and SmoothGrad-Squared---outperform such a random assignment of importance. The manner of ensembling remains critical. we show that some approaches do no better then the underlying method but carry a far higher computational burden.,True,FpI8dFwAAAAJ:bnK-pcrLprsC,161,https://arxiv.org/abs/1806.10758,5904453032535250834,/scholar?cites=5904453032535250834,,,https://arxiv.org/pdf/1806.10758,0,0,0
1281962,iNNvestigate neural networks!,2019,Maximilian Alber and Sebastian Lapuschkin and Philipp Seegerer and Miriam Hägele and Kristof T Schütt and Grégoire Montavon and Wojciech Samek and Klaus-Robert Müller and Sven Dähne and Pieter-Jan Kindermans,20,J. Mach. Learn. Res.,93,1-8,,In recent years. deep neural networks have revolutionized many application domains of machine learning and are key components of many critical decision or predictive processes. Therefore. it is crucial that domain specialists can understand and analyze actions and predictions. even of the most complex neural network architectures. Despite these arguments neural networks are often treated as black boxes. In the attempt to alleviate this shortcoming many analysis methods were proposed. yet the lack of reference implementations often makes a systematic comparison between the methods a major effort. The presented library iNNvestigate addresses this by providing a common interface and out-of-thebox implementation for many analysis methods. including the reference implementation for PatternNet and PatternAttribution as well as for LRP-methods. To demonstrate the versatility of iNNvestigate. we provide an analysis of image classifications for variety of state-of-the-art neural network architectures. c 2019 Maximilian Alber. Sebastian Lapuschkin. Philipp Seegerer. Miriam Hägele. Kristof T. Schütt. Grégoire Montavon. Wojciech Samek. Klaus-Robert Müller. Sven Dähne. Pieter-Jan Kindermans.,True,FpI8dFwAAAAJ:mvPsJ3kp5DgC,132,https://www.jmlr.org/papers/volume20/18-540/18-540.pdf,8176446435243605465,/scholar?cites=8176446435243605465,,,https://www.jmlr.org/papers/volume20/18-540/18-540.pdf,0,0,0
1281963,Integrating dynamic stopping. transfer learning and language models in an adaptive zero-training ERP speller,2014,Pieter-Jan Kindermans and Michael Tangermann and Klaus-Robert Müller and Benjamin Schrauwen,11,Journal of neural engineering,3,035005,IOP Publishing,Objective. Most BCIs have to undergo a calibration session in which data is recorded to train decoders with machine learning. Only recently zero-training methods have become a subject of study. This work proposes a probabilistic framework for BCI applications which exploit event-related potentials (ERPs). For the example of a visual P300 speller we show how the framework harvests the structure suitable to solve the decoding task by (a) transfer learning.(b) unsupervised adaptation.(c) language model and (d) dynamic stopping. Approach. A simulation study compares the proposed probabilistic zero framework (using transfer learning and task structure) to a state-of-the-art supervised model on n= 22 subjects. The individual influence of the involved components (a)–(d) are investigated. Main results. Without any need for a calibration session. the probabilistic zero-training framework with inter-subject transfer …,True,FpI8dFwAAAAJ:D03iK_w7-QYC,97,https://iopscience.iop.org/article/10.1088/1741-2560/11/3/035005/meta,4816539109518756602,/scholar?cites=4816539109518756602,,,https://iopscience.iop.org/article/10.1088/1741-2560/11/3/035005/pdf,0,0,0
1281964,Volumetric texture analysis of breast lesions on contrast‐enhanced magnetic resonance images,2007,Weijie Chen and Maryellen L Giger and Hui Li and Ulrich Bick and Gillian M Newstead,58,Magnetic Resonance in Medicine: An Official Journal of the International Society for Magnetic Resonance in Medicine,3,562-571,Wiley Subscription Services. Inc.. A Wiley Company,Automated image analysis aims to extract relevant information from contrast‐enhanced magnetic resonance images (CE‐MRI) of the breast and improve the accuracy and consistency of image interpretation. In this work. we extend the traditional 2D gray‐level co‐occurrence matrix (GLCM) method to investigate a volumetric texture analysis approach and apply it for the characterization of breast MR lesions. Our database of breast MR images was obtained using a T1‐weighted 3D spoiled gradient echo sequence and consists of 121 biopsy‐proven lesions (77 malignant and 44 benign). A fuzzy c‐means clustering (FCM) based method is employed to automatically segment 3D breast lesions on CE‐MR images. For each 3D lesion. a nondirectional GLCM is then computed on the first postcontrast frame by summing 13 directional GLCMs. Texture features are extracted from the nondirectional GLCMs and the …,True,mAG9HKoAAAAJ:d1gkVwhDpl0C,329,https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.21347,9575368695750291984,/scholar?cites=9575368695750291984,,,https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.21347,0,0,0
1281965,Digital mammographic tumor classification using transfer learning from deep convolutional neural networks,2016,Benjamin Q Huynh and Hui Li and Maryellen L Giger,3,Journal of Medical Imaging,3,034501,International Society for Optics and Photonics,Convolutional neural networks (CNNs) show potential for computer-aided diagnosis (CADx) by learning features directly from the image data instead of using analytically extracted features. However. CNNs are difficult to train from scratch for medical images due to small sample sizes and variations in tumor presentations. Instead. transfer learning can be used to extract tumor information from medical images via CNNs originally pretrained for nonmedical tasks. alleviating the need for large datasets. Our database includes 219 breast lesions (607 full-field digital mammographic images). We compared support vector machine classifiers based on the CNN-extracted image features and our prior computer-extracted tumor features in the task of distinguishing between benign and malignant breast lesions. Five-fold cross validation (by lesion) was conducted with the area under the receiver operating characteristic (ROC …,True,mAG9HKoAAAAJ:zC3nDrf76jgC,321,https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-3/issue-3/034501/Digital-mammographic-tumor-classification-using-transfer-learning-from-deep-convolutional/10.1117/1.JMI.3.3.034501.short,3885054903777060639,/scholar?cites=3885054903777060639,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4992049/,0,0,0
1281966,MR imaging radiomics signatures for predicting the risk of breast cancer recurrence as given by research versions of MammaPrint. Oncotype DX. and PAM50 gene assays,2016,Hui Li and Yitan Zhu and Elizabeth S Burnside and Karen Drukker and Katherine A Hoadley and Cheng Fan and Suzanne D Conzen and Gary J Whitman and Elizabeth J Sutton and Jose M Net and Marie Ganott and Erich Huang and Elizabeth A Morris and Charles M Perou and Yuan Ji and Maryellen L Giger,281,Radiology,2,382-391,Radiological Society of North America,To investigate relationships between computer-extracted breast magnetic resonance (MR) imaging phenotypes with multigene assays of MammaPrint. Oncotype DX. and PAM50 to assess the role of radiomics in evaluating the risk of breast cancer recurrence.Analysis was conducted on an institutional review board–approved retrospective data set of 84 deidentified. multi-institutional breast MR examinations from the National Cancer Institute Cancer Imaging Archive. along with clinical. histopathologic. and genomic data from The Cancer Genome Atlas. The data set of biopsy-proven invasive breast cancers included 74 (88%) ductal. eight (10%) lobular. and two (2%) mixed cancers. Of these. 73 (87%) were estrogen receptor positive. 67 (80%) were progesterone receptor positive. and 19 (23%) were human epidermal growth factor receptor 2 positive. For each case. computerized …,True,mAG9HKoAAAAJ:70PPymoGXe8C,304,https://pubs.rsna.org/doi/abs/10.1148/radiol.2016152110,15889084376277663752,/scholar?cites=15889084376277663752,,,https://pubs.rsna.org/doi/full/10.1148/radiol.2016152110,0,0,0
1281967,Quantitative MRI radiomics in the prediction of molecular classifications of breast cancer subtypes in the TCGA/TCIA data set,2016,Hui Li and Yitan Zhu and Elizabeth S Burnside and Erich Huang and Karen Drukker and Katherine A Hoadley and Cheng Fan and Suzanne D Conzen and Margarita Zuley and Jose M Net and Elizabeth Sutton and Gary J Whitman and Elizabeth Morris and Charles M Perou and Yuan Ji and Maryellen L Giger,2,NPJ breast cancer,1,1-10,Nature Publishing Group,Using quantitative radiomics. we demonstrate that computer-extracted magnetic resonance (MR) image-based tumor phenotypes can be predictive of the molecular classification of invasive breast cancers. Radiomics analysis was performed on 91 MRIs of biopsy-proven invasive breast cancers from National Cancer Institute’s multi-institutional TCGA/TCIA. Immunohistochemistry molecular classification was performed including estrogen receptor. progesterone receptor. human epidermal growth factor receptor 2. and for 84 cases. the molecular subtype (normal-like. luminal A. luminal B. HER2-enriched. and basal-like). Computerized quantitative image analysis included: three-dimensional lesion segmentation. phenotype extraction. and leave-one-case-out cross validation involving stepwise feature selection and linear discriminant analysis. The performance of the classifier model for molecular subtyping was …,True,mAG9HKoAAAAJ:idXxeK7XYw0C,186,https://www.nature.com/articles/npjbcancer201612,3010184604224909030,/scholar?cites=3010184604224909030,,,https://www.nature.com/articles/npjbcancer201612,0,0,0
1281968,Cancerous breast lesions on dynamic contrast-enhanced MR images: computerized characterization for image-based prognostic markers,2010,Neha Bhooshan and Maryellen L Giger and Sanaz A Jansen and Hui Li and Li Lan and Gillian M Newstead,254,Radiology,3,680-690,Radiological Society of North America. Inc.,To assess the performance of computer-extracted dynamic contrast material–enhanced (DCE) magnetic resonance (MR) imaging kinetic and morphologic features in the differentiation of invasive versus noninvasive breast lesions and metastatic versus nonmetastatic breast lesions.In this institutional review board–approved HIPAA-compliant study. in which the requirement for informed patient consent was waived. breast MR images were retrospectively collected. The images had been obtained with a 1.5-T MR unit by using a gadodiamide-enhanced T1-weighted spoiled gradient-recalled acquisition in the steady state sequence. The breast MR imaging database contained 132 benign. 71 ductal carcinoma in situ (DCIS). and 150 invasive ductal carcinoma (IDC) lesions. Fifty-four IDC lesions were associated with metastasis-positive lymph nodes (LNs). and 64 IDC lesions were …,True,mAG9HKoAAAAJ:UebtZRa9Y70C,182,https://pubs.rsna.org/doi/abs/10.1148/radiol.09090838,292214150521246313,/scholar?cites=292214150521246313,,,https://pubs.rsna.org/doi/full/10.1148/radiol.09090838,0,0,0
1281969,Using selective withdrawal to coat microparticles,2001,Itai Cohen and Hui Li and James L Hougland and Milan Mrksich and Sidney R Nagel,292,Science,5515,265-267,American Association for the Advancement of Science,We report a method that uses the process of selective withdrawal of one fluid through a second immiscible fluid to coat small particles with polymer films. Fluid is withdrawn through a tube with its orifice slightly above a water-oil interface. Upon increasing the flow rate. there is a transition from a state where only oil is withdrawn to a state where the water. containing the particles to be coated and appropriate prepolymer reagents. is entrained in a thin spout along with the oil. The entrained particles eventually cause the spout interface to break. producing a thin coat of controllable thickness around each particle. which can be subsequently polymerized using chemical reagents. light. or heat. This method allows flexibility in the chemical composition and thickness of the conformal coatings.,True,mAG9HKoAAAAJ:isC4tDSrTZIC,174,https://science.sciencemag.org/content/292/5515/265.abstract,15061775896384162281,/scholar?cites=15061775896384162281,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.960.2646&rep=rep1&type=pdf,0,0,0
1281970,Catalytic asymmetric dihydroxylation by gold colloids functionalized with self-assembled monolayers,1999,Hui Li and Yan-Yeung Luk and Milan Mrksich,15,Langmuir,15,4957-4959,American Chemical Society,This Letter demonstrates the design and synthesis of functional nanoparticles based on the assembly of terminally substituted alkanethiols on the surface of colloidal gold. The colloids were modified with alkanethiolates presenting methyl groups and dihydroquinidine ligands (in a ratio of 3:1) for the Sharpless asymmetric dihydroxylation of olefins. Dihydroxylation reactions were performed at room temperature in tert-butyl alcohol/water with functionalized colloid (0.1 equiv based on immobilized ligand) OsO4 (0.005 equiv) and K3Fe(CN)6 (3 equiv) as secondary oxidant. The dihydroxylation of trans-β-methylstyrene proceeded in 80% yield and gave diol with an enantiomeric excess of 90%. The dihydroxylation of trans-stilbene and methyl trans-cinnamate gave similar results and compare favorably with yields and selectivities obtained using polymer-supported alkaloid ligands. The colloids could be isolated from the …,True,mAG9HKoAAAAJ:k_IJM867U9cC,144,https://pubs.acs.org/doi/abs/10.1021/la990578q,13379530980870608752,/scholar?cites=13379530980870608752,,,https://www.mrksichgroup.northwestern.edu/files/2020/05/Li-Catalytic-asymmetric-dihydroxylation-b-1999.pdf,0,0,0
1281971,A dual‐stage method for lesion segmentation on digital mammograms,2007,Yading Yuan and Maryellen L Giger and Hui Li and Kenji Suzuki and Charlene Sennett,34,Medical physics,11,4180-4193,American Association of Physicists in Medicine,Mass lesion segmentation on mammograms is a challenging task since mass lesions are usually embedded and hidden in varying densities of parenchymal tissue structures. In this article. we present a method for automatic delineation of lesion boundaries on digital mammograms. This method utilizes a geometric active contour model that minimizes an energy function based on the homogeneities inside and outside of the evolving contour. Prior to the application of the active contour model. a radial gradient index (RGI)‐based segmentation method is applied to yield an initial contour closer to the lesion boundary location in a computationally efficient manner. Based on the initial segmentation. an automatic background estimation method is applied to identify the effective circumstance of the lesion. and a dynamic stopping criterion is implemented to terminate the contour evolution when it reaches the lesion …,True,mAG9HKoAAAAJ:9yKSN-GCB0IC,133,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.2790837,16213181512235050069,/scholar?cites=16213181512235050069,,,http://mypages.iit.edu/~ksuzuki/pdfs/coauthor/Yuan%20Y%20et%20al-Dual%20stage%20lesion%20segm%20mammo-MedPhys2007.pdf,0,0,0
1281972,Exploring nonlinear feature space dimension reduction and data representation in breast CADx with Laplacian eigenmaps and‐SNE,2010,Andrew R Jamieson and Maryellen L Giger and Karen Drukker and Hui Li and Yading Yuan and Neha Bhooshan,37,Medical physics,1,339-351,American Association of Physicists in Medicine,In this preliminary study. recently developed unsupervised nonlinear dimension reduction (DR) and data representation techniques were applied to computer‐extracted breast lesion feature spaces across three separate imaging modalities: Ultrasound (U.S.) with 1126 cases. dynamic contrast enhanced magnetic resonance imaging with 356 cases. and full‐field digital mammography with 245 cases. Two methods for nonlinear DR were explored: Laplacian eigenmaps [M. Belkin and P. Niyogi. “Laplacian eigenmaps for dimensionality reduction and data representation.” Neural Comput. 15. 1373–1396 (2003)] and ‐distributed stochastic neighbor embedding (‐SNE) [L. van der Maaten and G. Hinton. “Visualizing data using t‐SNE.” J. Mach. Learn. Res. 9. 2579–2605 (2008)].These methods attempt to map originally high dimensional feature spaces to more human interpretable lower dimensional …,True,mAG9HKoAAAAJ:5nxA0vEk-isC,128,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3267037,13375732203399453866,/scholar?cites=13375732203399453866,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2807447/,0,0,0
1281973,Computerized Texture Analysis of Mammographic Parenchymal Patterns of Digitized Mammograms1,2005,Hui Li and Maryellen L Giger and Olufunmilayo I Olopade and Anna Margolis and Li Lan and Michael R Chinander,12,Academic Radiology,7,863-873,Elsevier,Mammographic density and parenchymal patterns have been shown to be related to the risk of developing breast cancer. Thus. computerized texture analysis of breast parenchymal patterns on mammograms may be useful in assessing breast cancer risk.A comparative evaluation was conducted of various computer-extracted texture features of mammographic parenchymal patterns of women with BRCA1/BRCA2 gene mutations and those of women at low risk of developing breast cancer. Mammograms from 172 subjects (30 women with either the BRCA1 or BRCA2 gene mutation and 142 low-risk women) were analyzed. Computerized texture features were extracted from regions-of-interest to assess the mammographic parenchymal patterns in the images. Receiver operating characteristic analysis was used to assess the performance of these features in the task of …,True,mAG9HKoAAAAJ:icE7F1hHz6AC,125,https://www.sciencedirect.com/science/article/pii/S1076633205003478,11577175860454811794,/scholar?cites=11577175860454811794,,,https://www.researchgate.net/profile/Hui_Li226/publication/246336104_Computerized_Texture_Analysis_of_Mammographic_Parenchymal_Patterns_of_Digitized_Mammograms_1/links/59b303960f7e9b37434ead5d/Computerized-Texture-Analysis-of-Mammographic-Parenchymal-Patterns-of-Digitized-Mammograms-1.pdf,0,0,0
1281974,Computerized analysis of mammographic parenchymal patterns for assessing breast cancer risk: effect of ROI size and location,2004,Hui Li and Maryellen L Giger and Zhimin Huo and Olufunmilayo I Olopade and Li Lan and Barbara L Weber and Ioana Bonta,31,Medical Physics,3,549-555,American Association of Physicists in Medicine,The long‐term goal of our research is to develop computerized radiographic markers for assessing breast density and parenchymal patterns that may be used together with clinical measures for determining the risk of breast cancer and assessing the response to preventive treatment. In our earlier studies. we found that women at high risk tended to have dense breasts with mammographic patterns that were coarse and low in contrast. With our method. computerized texture analysis is performed on a region of interest (ROI) within the mammographic image. In our current study. we investigate the effect of ROI size and ROI location on the computerized texture features obtained from 90 subjects (30 BRCA1/BRCA2 gene‐mutation carriers and 60 age‐matched women deemed to be at low risk for breast cancer). Mammograms were digitized at 0.1 mm pixel size and various ROI sizes were extracted from different breast …,True,mAG9HKoAAAAJ:zYLM7Y9cAGgC,119,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.1644514,1216154548607356690,/scholar?cites=1216154548607356690,,,,0,0,0
1281975,A software defined fog node based distributed blockchain cloud architecture for IoT,2017,Pradip Kumar Sharma and Mu-Yen Chen and Jong Hyuk Park,6,Ieee Access,,115-124,IEEE,The recent expansion of the Internet of Things (IoT) and the consequent explosion in the volume of data produced by smart devices have led to the outsourcing of data to designated data centers. However. to manage these huge data stores. centralized data centers. such as cloud storage cannot afford auspicious way. There are many challenges that must be addressed in the traditional network architecture due to the rapid growth in the diversity and number of devices connected to the internet. which is not designed to provide high availability. real-time data delivery. scalability. security. resilience. and low latency. To address these issues. this paper proposes a novel blockchain-based distributed cloud architecture with a software defined networking (SDN) enable controller fog nodes at the edge of the network to meet the required design principles. The proposed model is a distributed cloud architecture based on …,True,3LR7DhgAAAAJ:wbdj-CoPYUoC,405,https://ieeexplore.ieee.org/abstract/document/8053750/,17150773631227153661,/scholar?cites=17150773631227153661,,,https://ieeexplore.ieee.org/iel7/6287639/8274985/08053750.pdf,0,0,0
1281976,Constructing a personalized e-learning system based on genetic algorithm and case-based reasoning approach,2007,Mu-Jung Huang and Hwa-Shan Huang and Mu-Yen Chen,33,Expert Systems with applications,3,551-564,Pergamon,The Internet and the World Wide Web in particular provide a unique platform to connect learners with educational resources. Educational material in hypermedia form in a Web-based educational system makes learning a task-driven process. It motivates learners to explore alternative navigational paths through the domain knowledge and from different resources around the globe. Consequently. many researchers have focused on developing e-learning systems with personalized learning mechanisms to assist on-line Web-based learning and to adaptively provide learning paths. However. although most personalized systems consider learner preferences. interests and browsing behaviors when providing personalized curriculum sequencing services. these systems usually neglect to consider whether learner ability and the difficulty level of the recommended curriculums are matched to each other.Therefore. our …,True,3LR7DhgAAAAJ:mVmsd5A6BfQC,258,https://www.sciencedirect.com/science/article/pii/S0957417406001692,7424336930804269051,/scholar?cites=7424336930804269051,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.5047&rep=rep1&type=pdf,0,0,0
1281977,Knowledge management performance evaluation: a decade review from 1995 to 2004,2006,Mu-Yen Chen and An-Pin Chen,32,,1,17-38,Sage Publications,In this paper. the development of knowledge management (KM) was surveyed. using a                 literature review and classification of articles from 1995 to 2004. With a keyword                 index and article abstract. we explored how KM performance evaluation has developed                 during this period. Based on a scope of 108 articles from 80 academic KM journals                 (retrieved from six online databases). we surveyed and classified methods of KM                 measurement. using the following eight categories: qualitative analysis.                 quantitative analysis. financial indicator analysis. non-financial indicator                 analysis. internal performance analysis. external performance analysis.                 project-orientated analysis and organizationorientated analysis. together with their                 measurement matrices for different research and problem domains. Future development                 directions for KM …,True,3LR7DhgAAAAJ:Wp0gIr-vW9MC,249,https://journals.sagepub.com/doi/abs/10.1177/0165551506059220,6436131734272534799,/scholar?cites=6436131734272534799,,,https://ir.nctu.edu.tw/bitstream/11536/12822/1/000236053800003.pdf,0,0,0
1281978,Integrating data mining with case-based reasoning for chronic diseases prognosis and diagnosis,2007,Mu-Jung Huang and Mu-Yen Chen and Show-Chin Lee,32,Expert systems with applications,3,856-867,Pergamon,The threats to people’s health from chronic diseases are always exist and increasing gradually. How to decrease these threats is an important issue in medical treatment. Thus. this paper suggests a model of a chronic diseases prognosis and diagnosis system integrating data mining (DM) and case-based reasoning (CBR). The main processes of the system include: (1) adopting data mining techniques to discover the implicit meaningful rules from health examination data. (2) using the extracted rules for the specific chronic diseases prognosis. (3) employing CBR to support the chronic diseases diagnosis and treatments. and (4) expanding these processes to work within a system for the convenience of chronic diseases knowledge creating. organizing. refining. and sharing. The experiment data are collected from a professional health examination center. MJ health screening center. and implemented through the …,True,3LR7DhgAAAAJ:hFOr9nPyWt4C,244,https://www.sciencedirect.com/science/article/pii/S095741740600042X,17347707631677183660,/scholar?cites=17347707631677183660,,,,0,0,0
1281979,Measuring knowledge management performance using a competitive perspective: An empirical study,2009,Mu-Yen Chen and Mu-Jung Huang and Yu-Chen Cheng,36,Expert systems with applications,4,8449-8459,Pergamon,This paper proposes an approach of measuring a technology university’s knowledge management (KM) performance from competitive perspective. The approach integrates analytical network process (ANP). which is a theory of multiple criteria decision-making and is good at dealing with tangible and intangible information. with balanced scorecard (BSC) that contains four perspectives. including customer perspective. internal business perspective. innovation and learning perspective. and financial perspective. being adopted as the indicators of KM performance measurement (KMPM). This paper makes three important contributions: (1) it propose a methodology of comparing an organization’s knowledge management performance with its major rivals to offer effective information for improving KM. increasing decision-making quality. and obtaining clear effort direction of attaining competitive advantage; (2) it …,True,3LR7DhgAAAAJ:9ZlFYXVOiuMC,241,https://www.sciencedirect.com/science/article/pii/S095741740800763X,6432272159210582217,/scholar?cites=6432272159210582217,,,,0,0,0
1281980,Predicting corporate financial distress based on integration of decision tree classification and logistic regression,2011,Mu-Yen Chen,38,Expert systems with applications,9,11261-11272,Pergamon,Lately. stock and derivative securities markets continuously and rapidly evolve in the world. As quick market developments. enterprise operating status will be disclosed periodically on financial statement. Unfortunately. if executives of firms intentionally dress financial statements up. it will not be observed any financial distress possibility in the short or long run. Recently. there were occurred many financial crises in the international marketing. such as Enron. Kmart. Global Crossing. WorldCom and Lehman Brothers events. How these financial events affect world’s business. especially for the financial service industry or investors has been public’s concern. To improve the accuracy of the financial distress prediction model. this paper referred to the operating rules of the Taiwan Stock Exchange Corporation (TSEC) and collected 100 listed companies as the initial samples. Moreover. the empirical experiment with a total …,True,3LR7DhgAAAAJ:UeHWp8X0CEIC,204,https://www.sciencedirect.com/science/article/pii/S0957417411003976,12321589161609091410,/scholar?cites=12321589161609091410,,,,0,0,0
1281981,A hybrid ANFIS model for business failure prediction utilizing particle swarm optimization and subtractive clustering,2013,Mu-Yen Chen,220,Information Sciences,,180-195,Elsevier,In recent years. newly-developed data mining and machine learning techniques have been applied to various fields to build intelligent information systems. However. few of these approaches offer online support or are able to flexibly adapt to large and complex financial datasets. Therefore. the present research adopts particle swarm optimization (PSO) techniques to obtain appropriate parameter settings for subtractive clustering (SC) and integrates the adaptive-network-based fuzzy inference system (ANFIS) model to construct a model for predicting business failures. Experiments were conducted based on an initial sample of 160 electronics companies listed on the Taiwan Stock Exchange Corporation (TSEC). Experimental results show that the proposed model is superior to other models. providing a lower mean absolute percentage error (MAPE) and root mean squared error (RMSE). The proposed one-order …,True,3LR7DhgAAAAJ:qjMakFHDy7sC,192,https://www.sciencedirect.com/science/article/pii/S0020025511004701,5208616658173077212,/scholar?cites=5208616658173077212,,,,0,0,0
1281982,A hybrid fuzzy time series model based on granular computing for stock price forecasting,2015,Mu-Yen Chen and Bo-Tsuen Chen,294,Information Sciences,,227-241,Elsevier,Given the high potential benefits and impacts of accurate stock market predictions. considerable research attention has been devoted to time series forecasting for stock markets. Over long periods. the accuracy of fuzzy time series model forecasting is invariably affected by interval length. and formulating effective interval partitioning methods can be very difficult. Previous studies largely relied on distance partitioning. but this approach neglects the distribution of datasets and can only handle scalar forecasting. But the magnitude of stock price movements is often severe and difficult to predict. Thus. the distribution of stock price datasets is always skewed and the straightforward partitioning method is not well suited to these types of time series datasets. In this research. a novel fuzzy time series model is used to forecast stock market prices. The proposed model is based on the granular computing approach with binning …,True,3LR7DhgAAAAJ:8k81kl-MbHgC,178,https://www.sciencedirect.com/science/article/pii/S0020025514009505,10125410776570897608,/scholar?cites=10125410776570897608,,,,0,0,0
1281983,Bankruptcy prediction in firms with statistical and intelligent techniques and a comparison of evolutionary computation approaches,2011,Mu-Yen Chen,62,Computers & Mathematics with Applications,12,4514-4524,Pergamon,In this paper. we compare some traditional statistical methods for predicting financial distress to some more “unconventional” methods. such as decision tree classification. neural networks. and evolutionary computation techniques. using data collected from 200 Taiwan Stock Exchange Corporation (TSEC) listed companies. Empirical experiments were conducted using a total of 42 ratios including 33 financial. 8 non-financial and 1 combined macroeconomic index. using principle component analysis (PCA) to extract suitable variables.This paper makes four critical contributions: (1) with nearly 80% fewer financial ratios by the PCA method. the prediction performance is still able to provide highly-accurate forecasts of financial bankruptcy; (2) we show that traditional statistical methods are better able to handle large datasets without sacrificing prediction performance. while intelligent techniques achieve better …,True,3LR7DhgAAAAJ:4JMBOYKVnBMC,108,https://www.sciencedirect.com/science/article/pii/S0898122111008947,15944313293730745707,/scholar?cites=15944313293730745707,,,https://www.sciencedirect.com/science/article/pii/S0898122111008947,0,0,0
1281984,Integrating option model and knowledge management performance measures: an empirical study,2005,Mu-Yen Chen and An-Pin Chen,31,Journal of Information Science,5,381-393,Sage Publications,The knowledge-based economy is coming. and knowledge management (KM) has rapidly                     disseminated in academic circles as well as in the business world. While an                     increasing number of companies have launched into knowledge management                     initiatives. a large proportion of these initiatives are limited to a technical                     focus. The problem with this type of focus is that it excludes and neglects the                     true potential benefits that can be derived from knowledge management. This                     paper develops a new metric. knowledge management performance index (KMPI). for                     evaluating the performance of a firm in its KM at a point in time. We therefore                     suggest that a KMPI can be used to determine KM activities from the following                     perspectives: knowledge creation. knowledge conversion. knowledge circulation                     and knowledge …,True,3LR7DhgAAAAJ:5nxA0vEk-isC,93,https://journals.sagepub.com/doi/abs/10.1177/0165551505055402,11893924340408495920,/scholar?cites=11893924340408495920,,,https://ir.nctu.edu.tw/bitstream/11536/25143/1/000232107900005.pdf,0,0,0
1281985,A high-order fuzzy time series forecasting model for internet stock trading,2014,Mu-Yen Chen,37,Future Generation Computer Systems,,461-467,North-Holland,Recently. many fuzzy time series models have already been used to solve nonlinear and complexity issues. However. first-order fuzzy time series models have proven to be insufficient for solving these problems. For this reason. many researchers proposed high-order fuzzy time series models and focused on three main issues: fuzzification. fuzzy logical relationships. and defuzzification. This paper presents a novel high-order fuzzy time series model which overcomes the drawback mentioned above. First. it uses entropy-based partitioning to more accurately define the linguistic intervals in the fuzzification procedure. Second. it applies an artificial neural network to compute the complicated fuzzy logical relationships. Third. it uses the adaptive expectation model to adjust the forecasting during the defuzzification procedure. To evaluate the proposed model. we used datasets from both the Taiwanese stock index from …,True,3LR7DhgAAAAJ:YOwf2qJgpHMC,89,https://www.sciencedirect.com/science/article/pii/S0167739X13002045,15151607910370571625,/scholar?cites=15151607910370571625,,,,0,0,0
1281986,A survey on image steganography and steganalysis,2011,Bin Li and Junhui He and Jiwu Huang and Yun Qing Shi,2,Journal of Information Hiding and Multimedia Signal Processing,2,142-172,,Steganography and steganalysis are important topics in information hiding. Steganography refers to the technology of hiding data into digital media without drawing any suspicion. while steganalysis is the art of detecting the presence of steganography. This paper provides a survey on steganography and steganalysis for digital images. mainly covering the fundamental concepts. the progress of steganographic methods for images in spatial representation and in JPEG format. and the development of the corresponding steganalytic schemes. Some commonly used strategies for improving steganographic security and enhancing steganalytic capability are summarized and possible research trends are discussed.,True,g0iR9IkAAAAJ:M3NEmzRMIkIC,544,http://bit.kuas.edu.tw/~jihmsp/2011/vol2/JIH-MSP-2011-03-005.pdf,1324471681381555751,/scholar?cites=1324471681381555751,,,http://bit.kuas.edu.tw/~jihmsp/2011/vol2/JIH-MSP-2011-03-005.pdf,0,0,0
1281987,General framework to histogram-shifting-based reversible data hiding,2013,Xiaolong Li and Bin Li and Bin Yang and Tieyong Zeng,22,IEEE Transactions on image processing,6,2181-2191,IEEE,Histogram shifting (HS) is a useful technique of reversible data hiding (RDH). With HS-based RDH. high capacity and low distortion can be achieved efficiently. In this paper. we revisit the HS technique and present a general framework to construct HS-based RDH. By the proposed framework. one can get a RDH algorithm by simply designing the so-called shifting and embedding functions. Moreover. by taking specific shifting and embedding functions. we show that several RDH algorithms reported in the literature are special cases of this general construction. In addition. two novel and efficient RDH algorithms are also introduced to further demonstrate the universality and applicability of our framework. It is expected that more efficient RDH algorithms can be devised according to the proposed framework by carefully designing the shifting and embedding functions.,True,g0iR9IkAAAAJ:_xSYboBqXhAC,342,https://ieeexplore.ieee.org/abstract/document/6459018/,7458499664407902498,/scholar?cites=7458499664407902498,,,,0,0,0
1281988,A new cost function for spatial image steganography,2014,Bin Li and Ming Wang and Jiwu Huang and Xiaolong Li,,,,4206-4210,IEEE,A well defined cost function is crucial to steganography under the scenario of minimizing embedding distortion. In this paper. we present a new cost function for spatial image steganography. The proposed cost function is designed by using a high-pass filter to locate the less predictable parts in an image. and then using two low-pass filters to make the low cost values more clustered. Experiments show that the steganographic method with the proposed cost function makes the embedding changes more concentrated in texture regions. and thus achieves a better performance on resisting the state-of-the-art steganalysis over prior works. including HUGO. WOW. and S-UNIWARD.,True,g0iR9IkAAAAJ:70eg2SAEIzsC,318,https://ieeexplore.ieee.org/abstract/document/7025854/,17041902127023030408,/scholar?cites=17041902127023030408,,,https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICIP-2014/Papers/1569891955.pdf,0,0,0
1281989,High-fidelity reversible data hiding scheme based on pixel-value-ordering and prediction-error expansion,2013,Xiaolong Li and Jian Li and Bin Li and Bin Yang,93,Signal processing,1,198-205,Elsevier,This paper presents a high-fidelity reversible data hiding scheme for digital images based on a new prediction strategy called pixel-value-ordering (PVO) and the well-known prediction-error expansion (PEE) technique. Specifically. a host image is first divided into non-overlapped equal-sized blocks. Then the maximum and minimum values of each block are predicted by other pixels of the block according to their pixel value orders. With such a PVO-based predictor. data embedding is implemented via PEE. The incorporation of PVO into PEE has an advantage in reducing the number of shifted pixels. and thus it can alleviate the degradation in image quality. Consequently. the proposed method can embed adequate data into a host image with rather limited distortion. The PSNR of a marked image versus its original one is guaranteed to be above 51.14 dB. In addition. a solution is provided to further improve the …,True,g0iR9IkAAAAJ:EUQCXRtRnyEC,306,https://www.sciencedirect.com/science/article/pii/S0165168412002551,8001347576246557543,/scholar?cites=8001347576246557543,,,,0,0,0
1281990,Detecting doubly compressed JPEG images by using mode based first digit features,2008,Bin Li and Yun Q Shi and Jiwu Huang,,,,730-735,IEEE,In this paper. we utilize the probabilities of the first digits of quantized DCT (discrete cosine transform) coefficients from individual AC (alternate current) modes to detect doubly compressed JPEG images. Our proposed features. named by mode based first digit features (MBFDF). have been shown to outperform all previous methods on discriminating doubly compressed JPEG images from singly compressed JPEG images. Furthermore. combining the MBFDF with a multi-class classification strategy can be exploited to identify the quality factor in the primary JPEG compression. thus successfully revealing the double JPEG compression history of a given JPEG image.,True,g0iR9IkAAAAJ:fPk4N6BV_jEC,181,https://ieeexplore.ieee.org/abstract/document/4665171/,16065485626260124260,/scholar?cites=16065485626260124260,,,,0,0,0
1281991,A strategy of clustering modification directions in spatial image steganography,2015,Bin Li and Ming Wang and Xiaolong Li and Shunquan Tan and Jiwu Huang,10,IEEE Transactions on Information Forensics and Security,9,1905-1917,IEEE,Most of the recently proposed steganographic schemes are based on minimizing an additive distortion function defined as the sum of embedding costs for individual pixels. In such an approach. mutual embedding impacts are often ignored. In this paper. we present an approach that can exploit the interactions among embedding changes in order to reduce the risk of detection by steganalysis. It employs a novel strategy. called clustering modification directions (CMDs). based on the assumption that when embedding modifications in heavily textured regions are locally heading toward the same direction. the steganographic security might be improved. To implement the strategy. a cover image is decomposed into several subimages. in which message segments are embedded with well-known schemes using additive distortion functions. The costs of pixels are updated dynamically to take mutual embedding impacts …,True,g0iR9IkAAAAJ:NaGl4SEjCO4C,172,https://ieeexplore.ieee.org/abstract/document/7109899/,10187840243841756467,/scholar?cites=10187840243841756467,,,https://dcmc.ee.ncku.edu.tw/html/2016autumn/paper/A%20Strategy%20of%20Clustering%20Modification%20Directions.pdf,0,0,0
1281992,Large-scale JPEG image steganalysis using hybrid deep-learning framework,2017,Jishen Zeng and Shunquan Tan and Bin Li and Jiwu Huang,13,IEEE Transactions on Information Forensics and Security,5,1200-1214,IEEE,Adoption of deep learning in image steganalysis is still in its initial stage. In this paper. we propose a generic hybrid deep-learning framework for JPEG steganalysis incorporating the domain knowledge behind rich steganalytic models. Our proposed framework involves two main stages. The first stage is hand-crafted. corresponding to the convolution phase and the quantization and truncation phase of the rich models. The second stage is a compound deep-neural network containing multiple deep subnets. in which the model parameters are learned in the training procedure. We provided experimental evidence and theoretical reflections to argue that the introduction of threshold quantizers. though disabling the gradient-descent-based learning of the bottom convolution phase. is indeed cost-effective. We have conducted extensive experiments on a large-scale data set extracted from ImageNet. The primary data set …,True,g0iR9IkAAAAJ:3s1wT3WcHBgC,145,https://ieeexplore.ieee.org/abstract/document/8125774/,6360756489760616085,/scholar?cites=6360756489760616085,,,https://arxiv.org/pdf/1611.03233,0,0,0
1281993,Stacked convolutional auto-encoders for steganalysis of digital images,2014,Shunquan Tan and Bin Li,,,,1-4,IEEE,In this paper. we point out that SRM (Spatial-domain Rich Model). the most successful steganalysis framework of digital images possesses a similar architecture to CNN (convolutional neural network). The reasonable expectation is that the steganalysis performance of a well-trained CNN should be comparable to or even better than that of the hand-coded SRM. However. a CNN without pre-training always get stuck at local plateaus or even diverge which result in rather poor solutions. In order to circumvent this obstacle. we use convolutional auto-encoder in the pre-training procedure. A stack of convolutional auto-encoders forms a CNN. The experimental results show that initializing a CNN with the mixture of the filters from a trained stack of convolutional auto-encoders and feature pooling layers. although still can not compete with SRM. yields superior performance compared to traditional CNN for the detection of …,True,g0iR9IkAAAAJ:NMxIlDl6LWMC,135,https://ieeexplore.ieee.org/abstract/document/7041565/,5266245879301078021,/scholar?cites=5266245879301078021,,,http://www.apsipa.org/proceedings_2014/Data/paper/1089.pdf,0,0,0
1281994,Automatic steganographic distortion learning using a generative adversarial network,2017,Weixuan Tang and Shunquan Tan and Bin Li and Jiwu Huang,24,IEEE Signal Processing Letters,10,1547-1551,IEEE,Generative adversarial network has shown to effectively generate artificial samples indiscernible from their real counterparts with a united framework of two subnetworks competing against each other. In this letter. we first propose an automatic steganographic distortion learning framework using a generative adversarial network. which is composed of a steganographic generative subnetwork and a steganalytic discriminative subnetwork. Via alternately training these two oppositional subnetworks. our proposed framework can automatically learn embedding change probabilities for every pixel in a given spatial cover image. The learnt embedding change probabilities can then be converted to embedding distortions. which can be adopted in the existing framework of minimal-distortion embedding. Under this framework. the distortion function is directly related to the undetectability against the oppositional evolving …,True,g0iR9IkAAAAJ:a0OBvERweLwC,111,https://ieeexplore.ieee.org/abstract/document/8017430/,15182095150475403594,/scholar?cites=15182095150475403594,,,,0,0,0
1281995,Steganalysis of YASS,2009,Bin Li and Jiwu Huang and Yun Qing Shi,4,IEEE Transactions on Information Forensics and Security,3,369-382,IEEE,A promising steganographic method-yet another steganography scheme (YASS)-was designed to resist blind steganalysis via embedding data in randomized locations. In addition to a concrete realization which is named the YASS algorithm in this paper. a few strategies were proposed to work with the YASS algorithm in order to enhance the data embedding rate and security. In this work. the YASS algorithm and these strategies. together referred to as YASS. have been analyzed from a warden's perspective. It is observed that the embedding locations chosen by YASS are not randomized enough and the YASS embedding scheme causes detectable artifacts. We present a steganalytic method to attack the YASS algorithm. which is facilitated by a specifically selected steganalytic observation domain (SO-domain). a term to define the domain from which steganalytic features are extracted. The proposed SO-domain …,True,g0iR9IkAAAAJ:35N4QoGY0k4C,103,https://ieeexplore.ieee.org/abstract/document/5153278/,16720149203541776088,/scholar?cites=16720149203541776088,,,,0,0,0
1281996,Investigation on cost assignment in spatial image steganography,2014,Bin Li and Shunquan Tan and Ming Wang and Jiwu Huang,9,IEEE Transactions on Information Forensics and Security,8,1264-1277,IEEE,Relating the embedding cost in a distortion function to statistical detectability is an open vital problem in modern steganography. In this paper. we take one step forward by formulating the process of cost assignment into two phases: 1) determining a priority profile and 2) specifying a cost-value distribution. We analytically show that the cost-value distribution determines the change rate of cover elements. Furthermore. when the cost-values are specified to follow a uniform distribution. the change rate has a linear relation with the payload. which is a rare property for content-adaptive steganography. In addition. we propose some rules for ranking the priority profile for spatial images. Following such rules. we propose a five-step cost assignment scheme. Previous steganographic schemes. such as HUGO. WOW. S-UNIWARD. and MG. can be integrated into our scheme. Experimental results demonstrate that the …,True,g0iR9IkAAAAJ:JV2RwH3_ST0C,102,https://ieeexplore.ieee.org/abstract/document/6822611/,4091777369581933370,/scholar?cites=4091777369581933370,,,,0,0,0
1281997,On risk. convenience. and Internet shopping behavior,2000,Amit Bhatnagar and Sanjog Misra and H Raghav Rao,43,Communications of the ACM,11,98-105,ACM,Journal of Marketing Research. about a then-revolutionary phenomenon:“... over 90% of those surveyed stated that the major attraction of telephone shopping is its convenience...”[5]. The phenomenon of the Internet shopping today is very much akin to telephone shopping when this comment was originally made. Given that the Internet as a commercial vehicle is a relatively new concept. there is bound to be much uncertainty regarding the value of services it provides. The consumer makes his choices under conditions of uncertainty and therefore maximizes his or her expected benefit. 1 A large number of papers in marketing deal with decisionmaking under conditions of uncertainty [7. 10]. An underlying construct of our approach is that different individuals would have different levels of risk acceptance (or aversion). Again. this could depend on the demographic and characteristics of an individual—an Internet “savvy …,True,PIU4bP8AAAAJ:u5HHmVD_uO8C,1763,https://dl.acm.org/doi/fullHtml/10.1145/353360.353371,2222124597121796689,/scholar?cites=2222124597121796689,,,https://www.researchgate.net/profile/Sanjog_Misra/publication/220420287_On_Risk_Convenience_and_Internet_Shopping_Behavior/links/0c9605293fe02049cb000000.pdf,0,0,0
1281998,Supermarket pricing strategies,2008,Paul B Ellickson and Sanjog Misra,27,Marketing science,5,811-828,INFORMS,Most supermarket firms choose to position themselves by offering either everyday low prices (EDLP) across several items or offering temporary price reductions (promotions) on a limited range of items. While this choice has been addressed from a theoretical perspective in both the marketing and economic literature. relatively little is known about how these decisions are made in practice. especially within a competitive environment. This paper exploits a unique store level data set consisting of every supermarket operating in the United States in 1998. For each of these stores. we observe the pricing strategy the firm has chosen to follow. as reported by the firm itself. Using a system of simultaneous discrete choice models. we estimate each store's choice of pricing strategy as a static discrete game of incomplete information. In contrast to the predictions of the theoretical literature. we find strong evidence that firms …,True,PIU4bP8AAAAJ:u-x6o8ySG0sC,277,https://pubsonline.informs.org/doi/abs/10.1287/mksc.1080.0398,2238208812612987649,/scholar?cites=2238208812612987649,,,https://www.academia.edu/download/43698272/Supermarket_Pricing_Strategies20160313-29021-1errcdx.pdf,0,0,0
1281999,A structural model of sales-force compensation dynamics: Estimation and field implementation,2011,Sanjog Misra and Harikesh S Nair,9,Quantitative Marketing and Economics,3,211-257,Springer US,We present an empirical framework to analyze real-world sales-force compensation schemes. and report on a multi-million dollar. multi-year project involving a large contact lens manufacturer at the US. where the model was used to improve sales-force contracts. The model is built on agency theory. and solved using numerical dynamic programming techniques. The model is flexible enough to handle quotas and bonuses. output-based commission schemes. as well as “ratcheting” of compensation based on past performance. all of which are ubiquitous in actual contracts. The model explicitly incorporates the dynamics induced by these aspects in agent behavior. We apply the model to a rich dataset that comprises the complete details of sales and compensation plans for the firm’s US sales-force. We use the model to evaluate profit-improving. theoretically-preferred changes to the extant compensation …,True,PIU4bP8AAAAJ:YsMSGLbcyi4C,170,https://link.springer.com/article/10.1007/s11129-011-9096-1,17069104813448060576,/scholar?cites=17069104813448060576,,,http://incentival.com/mkt_salesforce.pdf,0,0,0
1282000,Contract duration: evidence from franchising,2006,James A Brickley and Sanjog Misra and R Lawrence Van Horn,49,J. Law & Econ.,,173-681,The University of Chicago The Journal of Law,Economists generally view standard franchise contracts as efficient. while franchisee advocates view them as exploitive. Consistent with the economic view. we find that contract duration is positively and significantly related to the franchisee’s physical and human capital investments (which are often firm specific). In contrast to assertions by franchisee advocates. we find that these relations exist in subsamples containing only the most established franchisors (as measured by size and experience) and that larger. more experienced franchisors tend to offer longer‐term contracts than do newer franchisors. Our evidence also suggests that there is learning across firms about optimal contract terms.,True,PIU4bP8AAAAJ:M3ejUd6NZC8C,143,https://www.journals.uchicago.edu/doi/abs/10.1086/501081,16324780355881391588,/scholar?cites=16324780355881391588,,,https://simon.rochester.edu/fac/misra/JLE_CD.pdf,0,0,0
1282001,Observed and unobserved preference heterogeneity in brand-choice models,2006,Dan Horsky and Sanjog Misra and Paul Nelson,25,Marketing Science,4,322-335,INFORMS,This paper extends the scanner-based choice literature by explicitly incorporating individual-level brand-preference data. We illustrate our model using a unique data set that combines survey and scanner data collected from the same individuals.The addition of individual-specific brand-preference information significantly improves fit and prediction. Furthermore. this “observed” heterogeneity better explains choice than does “unobserved” heterogeneity in the standard scanner model’s parameters. More importantly. we find that the standard model underestimates the importance of consumers’ brand preferences and overestimates both brand loyalties and price sensitivities. Brand loyalty is overestimated because models without preference information confound state dependence. heterogeneity. and preference effects. Price sensitivities are inflated because the “average” preference-based consumer is implicitly …,True,PIU4bP8AAAAJ:9yKSN-GCB0IC,119,https://pubsonline.informs.org/doi/abs/10.1287/mksc.1050.0192,4687681206420138147,/scholar?cites=4687681206420138147,,,https://dl.acm.org/doi/abs/10.1287/mksc.1050.0192,0,0,0
1282002,Repositioning dynamics and pricing strategy,2011,Paul Ellickson and Sanjog Misra and Harikesh Nair,,Journal of Marketing Research,,,,The authors measure the revenue and cost implications to supermarkets of changing their price positioning strategy in oligopolistic downstream retail markets. Their approach formally incorporates the dynamics induced by the repositioning in a model with strategic interaction. They exploit a unique data set containing the price format decisions of all U.S. supermarkets in the 1990s. The data contain the format change decisions of supermarkets in response to a large shock to their local market positions: the entry of Wal-Mart. The authors exploit the responses of retailers to Wal-Mart entry to infer the cost of changing pricing formats using a revealed-preference argument. The interaction between retailers and Wal-Mart in each market is modeled as a dynamic game. The authors find evidence that entry by Wal-Mart had a significant impact on the costs and incidence of switching pricing strategy. Their results add to the …,True,PIU4bP8AAAAJ:UebtZRa9Y70C,94,https://journals.sagepub.com/doi/abs/10.1509/jmr.11.0068,10891384718083088089,/scholar?cites=10891384718083088089,,,http://www.sanjogmisra.com/RepoCosts_Published.pdf,0,0,0
1282003,Understanding firm. physician and consumer choice behavior in the pharmaceutical industry,2005,Puneet Manchanda and Dick R Wittink and Andrew Ching and Paris Cleanthous and Min Ding and Xiaojing J Dong and Peter SH Leeflang and Sanjog Misra and Natalie Mizik and Sridhar Narayanan and Thomas Steenburgh and Jaap E Wieringa and Marta Wosinska and Ying Xie,16,Marketing Letters,3,293-308,Kluwer Academic Publishers,This paper argues that the pharmaceutical industry represents an exciting opportunity to carry out academic research. The nature of the industry allows researchers to answer new questions. develop new methodologies for answering these questions as well as to apply existing methodology to new data. The paper opens with some industry background. then provides a brief overview of some important research areas and discusses the open questions in each area. Issues of data type and availability are also discussed.,True,PIU4bP8AAAAJ:2osOgNQ5qMEC,93,https://link.springer.com/article/10.1007/s11002-005-5893-1,276801606432317782,/scholar?cites=276801606432317782,,,http://incentival.com/mktletters_healthcare.pdf,0,0,0
1282004,Disentangling preferences and learning in brand choice models,2012,Sangwoo Shin and Sanjog Misra and Dan Horsky,31,Marketing Science,1,115-137,INFORMS,In recent years there has been a growing stream of literature in marketing and economics that models consumers as Bayesian learners. Such learning behavior is often embedded within a discrete choice framework that is then calibrated on scanner panel data. At the same time. it is now accepted wisdom that disentangling preference heterogeneity and state dependence is critical in any attempt to understand either construct. We posit that this confounding between state dependence and heterogeneity often carries through to Bayesian learning models. That is. the failure to adequately account for preference heterogeneity may result in over- or underestimation of the learning process because this heterogeneity is also reflected in the initial conditions. Using a unique data set that contains stated preferences (survey) and actual purchase data (scanner panel) for the same group of consumers. we attempt to untangle …,True,PIU4bP8AAAAJ:ZeXyd9-uunAC,88,https://pubsonline.informs.org/doi/abs/10.1287/mksc.1110.0680,14019985468226277342,/scholar?cites=14019985468226277342,,,https://pdfs.semanticscholar.org/381f/0645f71611c914171f4f321fc0f1e834a84d.pdf,0,0,0
1282005,Deep Neural Networks for Estimation and Inference,2021,Max H Farrell and Tengyuan Liang and Sanjog Misra,89,Econometrica,1,181-213,,We study deep neural networks and their use in semiparametric inference. We establish novel nonasymptotic high probability bounds for deep feedforward neural nets. These deliver rates of convergence that are sufficiently fast (in some cases minimax optimal) to allow us to establish valid second‐step inference after first‐step estimation with deep learning. a result also new to the literature. Our nonasymptotic high probability bounds. and the subsequent semiparametric inference. treat the current standard architecture: fully connected feedforward neural networks (multilayer perceptrons). with the now‐common rectified linear unit activation function. unbounded weights. and a depth explicitly diverging with the sample size. We discuss other architectures as well. including fixed‐width. very deep networks. We establish the nonasymptotic bounds for these deep nets for a general class of nonparametric regression‐type …,True,PIU4bP8AAAAJ:1EqfMoDn7-AC,84,https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA16901,7908230695105051366,/scholar?cites=7908230695105051366,,,https://onlinelibrary.wiley.com/doi/full/10.3982/ECTA16901,0,0,0
1282006,Salesforce compensation: An analytical and empirical examination of the agency theoretic approach,2005,Sanjog Misra and Anne T Coughlan and Chakravarthi Narasimhan,3,Quantitative Marketing and Economics,1,5-39,Kluwer Academic Publishers,Since the papers of Basu et al. (1985) and Lal and Srinivasan (1993). marketing academics have been interested in the design and implementation of optimal compensation plans. The literature has focused on agency theory as a foundation to help describe and understand this process. Although there has been much theoretical work on this topic. empirical evidence to support this theory remains sparse. Studies by Coughlan and Narasimhan (1992) and John and Weitz (1988. 1989) have found some early evidence that supports agency theory.In this paper we revisit the issue of salesforce compensation on both theoretical and empirical fronts. On the theory side we build a game theoretic model of salesforce compensation that accounts for risk aversion on the part of both the principal and the agent. We further show that accounting for the firm size within the analytical framework yields new insights …,True,PIU4bP8AAAAJ:UeHWp8X0CEIC,84,https://link.springer.com/content/pdf/10.1007/s11129-005-0164-2.pdf,15162243542899482709,/scholar?cites=15162243542899482709,,,http://www.incentival.com/QME_SF.pdf,0,0,0
1282007,How consumers’ attitudes toward direct-to-consumer advertising of prescription drugs influence ad effectiveness. and consumer and physician behavior,2004,Michal Herzenstein and Sanjog Misra and Steven S Posavac,15,Marketing Letters,4,201-212,Kluwer Academic Publishers,Data from 1081 adults surveyed by the FDA were analyzed to explore consumers’ attitudes toward direct-to-consumer advertising (DTCA) of prescription drugs. and the relation between these attitudes and health related consumption behaviors. We report the favorableness of consumers’ reactions to DTCA. and more importantly. demonstrate that consumers’ attitudes toward DTCA are related to whether they search for more information about a drug that is advertised. and ask their physician about the drug. Finally. we document how consumers’ attitudes towards DTCA relate to the prescription writing behavior of their physicians. Mediation analyses that more fully explicate these findings are discussed.,True,PIU4bP8AAAAJ:qjMakFHDy7sC,81,https://link.springer.com/article/10.1007/s11002-005-0458-x,6328566027439749319,/scholar?cites=6328566027439749319,,,https://www.researchgate.net/profile/Steven_Posavac/publication/5152951_How_Consumers%27_Attitudes_Toward_Direct-to-Consumer_Advertising_of_Prescription_Drugs_Influence_Ad_Effectiveness_and_Consumer_and_Physician_Behavior/links/02e7e5231d4966f703000000/How-Consumers-Attitudes-Toward-Direct-to-Consumer-Advertising-of-Prescription-Drugs-Influence-Ad-Effectiveness-and-Consumer-and-Physician-Behavior.pdf,0,0,0
1282008,Cortical abnormalities in bipolar disorder: an MRI analysis of 6503 individuals from the ENIGMA Bipolar Disorder Working Group,2018,DP Hibar and Lars Tjelta Westlye and Nhat Trung Doan and Neda Jahanshad and JW Cheung and Christopher RK Ching and Amelia Versace and AC Bilderbeck and Anne Uhlmann and B Mwangi and B Krämer and B Overs and Cecilie Bhandari Hartberg and Christoph Abé and Danai Dima and Dominik Grotegerd and Emma Sprooten and Erlend Bøen and Enrique Jimenez and Fleur M Howells and G Delvecchio and H Temmingh and J Starke and JRC Almeida and JM Goikolea and J Houenou and Lauren M Beard and L Rauer and Lucija Abramovic and M Bonnin and MF Ponteduro and M Keil and MM Rive and N Yao and N Yalin and P Najt and PG Rosa and Ronny Redlich and S Trost and Saskia Hagenaars and SC Fears and S Alonso-Lana and TGM Van Erp and Thomas Nickson and TM Chaim-Avancini and TB Meier and Torbjørn Elvsåshagen and UK Haukvik and WH Lee and AH Schene and AJ Lloyd and AH Young and A Nugent and AM Dale and Andrea Pfennig and AM McIntosh and Beny Lafer and BT Baune and CJ Ekman and CA Zarate and CE Bearden and C Henry and Christian Simhandl and C McDonald and C Bourne and DJ Stein and DH Wolf and DM Cannon and DC Glahn and DJ Veltman and E Pomarol-Clotet and E Vieta and EJ Canales-Rodriguez and FG Nery and FLS Duran and GF Busatto and G Roberts and GD Pearlson and GM Goodwin and H Kugel and HC Whalley and HG Ruhe and JC Soares and JM Fullerton and JK Rybakowski and Jonathan Savitz and KT Chaim and Mar Fatjó-Vilas and MG Soeiro-de-Souza and MP Boks and MV Zanetti and MCG Otaduy and MS Schaufelberger and Martin Alda and Martin Ingvar and ML Phillips and MJ Kempton and M Bauer and M Landén and NS Lawrence and NEM Van Haren and NR Horn and NB Freimer and Oliver Gruber and PR Schofield and PB Mitchell and RS Kahn and R Lenroot and R Machado-Vieira and RA Ophoff and S Sarró and Sophia Frangou and TD Satterthwaite and Tomas Hajek and Udo Dannlowski and Ulrik Fredrik Malt and Volker Arolt and WF Gattaz and WC Drevets and Xavier Caseras and Ingrid Agartz and PM Thompson and Ole Andreas Andreassen,23,Molecular psychiatry,4,932-942,Nature Publishing Group,Despite decades of research. the pathophysiology of bipolar disorder (BD) is still not well understood. Structural brain differences have been associated with BD. but results from neuroimaging studies have been inconsistent. To address this. we performed the largest study to date of cortical gray matter thickness and surface area measures from brain magnetic resonance imaging scans of 6503 individuals including 1837 unrelated adults with BD and 2582 unrelated healthy controls for group differences while also examining the effects of commonly prescribed medications. age of illness onset. history of psychosis. mood state. age and sex differences on cortical regions. In BD. cortical gray matter was thinner in frontal. temporal and parietal regions of both brain hemispheres. BD had the strongest effects on left pars opercularis (Cohen’s d=− 0.293; P= 1.71× 10− 21). left fusiform gyrus (d=− 0.288; P= 8.25× 10− 21 …,True,H2whtRcAAAAJ:isC4tDSrTZIC,307,https://www.nature.com/articles/mp201773,10059250592561869790,/scholar?cites=10059250592561869790,,,https://www.nature.com/articles/mp201773,0,0,0
1282009,Subcortical volumetric abnormalities in bipolar disorder,2016,DP Hibar and Lars T Westlye and Theo GM van Erp and J Rasmussen and Cassandra D Leonardo and J Faskowitz and Unn K Haukvik and Cecilie Bhandari Hartberg and Nhat Trung Doan and Ingrid Agartz and Anders M Dale and Oliver Gruber and Bernd Krämer and Sarah Trost and Benny Liberg and Christoph Abé and Carl Johan Ekman and Martin Ingvar and Mikael Landén and Scott C Fears and Nelson B Freimer and Carrie E Bearden and Emma Sprooten and David C Glahn and Godfrey D Pearlson and Louise Emsell and Joanne Kenney and Cathy Scanlon and Colm McDonald and Dara M Cannon and Jorge Almeida and Amelia Versace and Xavier Caseras and Natalia S Lawrence and Mary L Phillips and Danai Dima and Giuseppe Delvecchio and Sophia Frangou and TD Satterthwaite and Daniel Wolf and Josselin Houenou and Chantal Henry and Ulrik F Malt and Erlend Bøen and Torbjørn Elvsåshagen and Allan H Young and Adrian J Lloyd and Guy M Goodwin and Clare E Mackay and Corin Bourne and Amy Bilderbeck and Lucija Abramovic and Marco P Boks and Neeltje EM van Haren and RA Ophoff and RS Kahn and Michael Bauer and Andrea Pfennig and Martin Alda and Tomas Hajek and Benson Mwangi and Jair C Soares and Thomas Nickson and Rali Dimitrova and Jess E Sussmann and Saskia Hagenaars and Heather C Whalley and Andrew M McIntosh and Paul M Thompson and Ole A Andreassen,21,Molecular psychiatry,12,1710-1716,Nature Publishing Group,Considerable uncertainty exists about the defining brain changes associated with bipolar disorder (BD). Understanding and quantifying the sources of uncertainty can help generate novel clinical hypotheses about etiology and assist in the development of biomarkers for indexing disease progression and prognosis. Here we were interested in quantifying case–control differences in intracranial volume (ICV) and each of eight subcortical brain measures: nucleus accumbens. amygdala. caudate. hippocampus. globus pallidus. putamen. thalamus. lateral ventricles. In a large study of 1710 BD patients and 2594 healthy controls. we found consistent volumetric reductions in BD patients for mean hippocampus (Cohen’s d=− 0.232; P= 3.50× 10− 7) and thalamus (d=− 0.148; P= 4.27× 10− 3) and enlarged lateral ventricles (d=− 0.260; P= 3.93× 10− 5) in patients. No significant effect of age at illness onset was detected …,True,H2whtRcAAAAJ:hC7cP41nSMkC,280,https://www.nature.com/articles/mp2015227,5068531540907464226,/scholar?cites=5068531540907464226,,,https://www.nature.com/articles/mp2015227,0,0,0
1282010,Widespread white matter microstructural differences in schizophrenia across 4322 individuals: results from the ENIGMA Schizophrenia DTI Working Group,2018,Sinead Kelly and Neda Jahanshad and A Zalesky and P Kochunov and Ingrid Agartz and C Alloza and OA Andreassen and C Arango and N Banaj and S Bouix and CA Bousman and RM Brouwer and J Bruggemann and J Bustillo and Wiepke Cahn and Vince Calhoun and D Cannon and Vaughan Carr and Stanley Catts and Jx Chen and JX Chen and X Chen and C Chiapponi and Kl K Cho and V Ciullo and AS Corvin and Benedicto Crespo-Facorro and V Cropley and P De Rossi and CM Diaz-Caneja and EW Dickie and Stefan Ehrlich and FM Fan and J Faskowitz and H Fatouros-Bergman and L Flyckt and JM Ford and JP Fouche and Masaki Fukunaga and M Gill and DC Glahn and Randy Gollub and ED Goudzwaard and H Guo and RE Gur and RC Gur and TP Gurholt and Ryota Hashimoto and SN Hatton and FA Henskens and DP Hibar and IB Hickie and LE Hong and J Horacek and FM Howells and HE Hulshoff Pol and CL Hyde and D Isaev and A Jablensky and PR Jansen and JAMJL Janssen and EG Jönsson and LA Jung and RS Kahn and Z Kikinis and K Liu and P Klauser and C Knöchel and M Kubicki and Jim Lagopoulos and Carolyn Langen and Stephen Lawrie and RK Lenroot and KO Lim and C Lopez-Jaramillo and A Lyall and V Magnotta and RCW Mandl and DH Mathalon and RW McCarley and S McCarthy-Jones and Colm McDonald and S McEwen and Andrew McIntosh and T Melicher and RI Mesholam-Gately and PT Michie and B Mowry and BA Mueller and DT Newell and P O'donnell and V Oertel-Knöchel and L Oestreich and SA Paciga and Christos Pantelis and O Pasternak and G Pearlson and GR Pellicano and A Pereira and J Pineda Zapata and F Piras and SG Potkin and A Preda and PE Rasser and DR Roalf and R Roiz and A Roos and D Rotenberg and TD Satterthwaite and P Savadjiev and U Schall and RJ Scott and ML Seal and LJ Seidman and C Shannon Weickert and CD Whelan and ME Shenton and JS Kwon and Gianfranco Spalletta and F Spaniel and E Sprooten and M Stäblein and DJ Stein and S Sundram and Y Tan and S Tan and S Tang and HS Temmingh and LT Westlye and S Tønnesen and Diana Tordesillas-Gutierrez and NT Doan and J Vaidya and NEM Van Haren and CD Vargas and D Vecchio and D Velakoulis and A Voineskos and JQ Voyvodic and Z Wang and P Wan and D Wei and TW Weickert and H Whalley and Tonya White and TJ Whitford and JD Wojcik and H Xiang and Z Xie and H Yamamori,23,Molecular psychiatry,5,1261-1269,Nature Publishing Group,The regional distribution of white matter (WM) abnormalities in schizophrenia remains poorly understood. and reported disease effects on the brain vary widely between studies. In an effort to identify commonalities across studies. we perform what we believe is the first ever large-scale coordinated study of WM microstructural differences in schizophrenia. Our analysis consisted of 2359 healthy controls and 1963 schizophrenia patients from 29 independent international studies; we harmonized the processing and statistical analyses of diffusion tensor imaging (DTI) data across sites and meta-analyzed effects across studies. Significant reductions in fractional anisotropy (FA) in schizophrenia patients were widespread. and detected in 20 of 25 regions of interest within a WM skeleton representing all major WM fasciculi. Effect sizes varied by region. peaking at (d= 0.42) for the entire WM skeleton. driven more by …,True,H2whtRcAAAAJ:NaGl4SEjCO4C,279,https://www.nature.com/articles/mp2017170,10425111573684196363,/scholar?cites=10425111573684196363,,,https://www.nature.com/articles/mp2017170,0,0,0
1282011,Cortical brain abnormalities in 4474 individuals with schizophrenia and 5098 control subjects via the Enhancing Neuro Imaging Genetics Through Meta Analysis (ENIGMA) Consortium,2018,Theo GM Van Erp and Esther Walton and Derrek P Hibar and Lianne Schmaal and Wenhao Jiang and David C Glahn and Godfrey D Pearlson and Nailin Yao and Masaki Fukunaga and Ryota Hashimoto and Naohiro Okada and Hidenaga Yamamori and Juan R Bustillo and Vincent P Clark and Ingrid Agartz and Bryon A Mueller and Wiepke Cahn and Sonja MC de Zwarte and Hilleke E Hulshoff Pol and René S Kahn and Roel A Ophoff and Neeltje EM van Haren and Ole A Andreassen and Anders M Dale and Nhat Trung Doan and Tiril P Gurholt and Cecilie B Hartberg and Unn K Haukvik and Kjetil N Jørgensen and Trine V Lagerberg and Ingrid Melle and Lars T Westlye and Oliver Gruber and Bernd Kraemer and Anja Richter and David Zilles and Vince D Calhoun and Benedicto Crespo-Facorro and Roberto Roiz-Santiañez and Diana Tordesillas-Gutiérrez and Carmel Loughland and Vaughan J Carr and Stanley Catts and Vanessa L Cropley and Janice M Fullerton and Melissa J Green and Frans A Henskens and Assen Jablensky and Rhoshel K Lenroot and Bryan J Mowry and Patricia T Michie and Christos Pantelis and Yann Quidé and Ulrich Schall and Rodney J Scott and Murray J Cairns and Marc Seal and Paul A Tooney and Paul E Rasser and Gavin Cooper and Cynthia Shannon Weickert and Thomas W Weickert and Derek W Morris and Elliot Hong and Peter Kochunov and Lauren M Beard and Raquel E Gur and Ruben C Gur and Theodore D Satterthwaite and Daniel H Wolf and Aysenil Belger and Gregory G Brown and Judith M Ford and Fabio Macciardi and Daniel H Mathalon and Daniel S O’Leary and Steven G Potkin and Adrian Preda and James Voyvodic and Kelvin O Lim and Sarah McEwen and Fude Yang and Yunlong Tan and Shuping Tan and Zhiren Wang and Fengmei Fan and Jingxu Chen and Hong Xiang and Shiyou Tang and Hua Guo and Ping Wan and Dong Wei and Henry J Bockholt and Stefan Ehrlich and Rick PF Wolthusen and Margaret D King and Jody M Shoemaker and Scott R Sponheim and Lieuwe De Haan and Laura Koenders and Marise W Machielsen and Therese van Amelsvoort and Dick J Veltman and Francesca Assogna and Nerisa Banaj and Pietro de Rossi and Mariangela Iorio and Fabrizio Piras and Gianfranco Spalletta and Peter J McKenna and Edith Pomarol-Clotet and Raymond Salvador and Aiden Corvin and Gary Donohoe and Sinead Kelly and Christopher D Whelan and Erin W Dickie and David Rotenberg and Aristotle N Voineskos and Simone Ciufolini and Joaquim Radua and Paola Dazzan and Robin Murray and Tiago Reis Marques and Andrew Simmons and Stefan Borgwardt and Laura Egloff and Fabienne Harrisberger and Anita Riecher-Rössler and Renata Smieskova and Kathryn I Alpert and Lei Wang and Erik G Jönsson and Sanne Koops and Iris EC Sommer and Alessandro Bertolino and Aurora Bonvino and Annabella Di Giorgio and Emma Neilson and Andrew R Mayer and Julia M Stephen and Jun Soo Kwon and Je-Yeon Yun and Dara M Cannon and Colm McDonald and Irina Lebedeva and Alexander S Tomyshev and Tolibjohn Akhadov and Vasily Kaleda and Helena Fatouros-Bergman,84,Biological psychiatry,9,644-654,Elsevier,The profile of cortical neuroanatomical abnormalities in schizophrenia is not fully understood. despite hundreds of published structural brain imaging studies. This study presents the first meta-analysis of cortical thickness and surface area abnormalities in schizophrenia conducted by the ENIGMA (Enhancing Neuro Imaging Genetics through Meta Analysis) Schizophrenia Working Group.The study included data from 4474 individuals with schizophrenia (mean age. 32.3 years; range. 11–78 years; 66% male) and 5098 healthy volunteers (mean age. 32.8 years; range. 10–87 years; 53% male) assessed with standardized methods at 39 centers worldwide.Compared with healthy volunteers. individuals with schizophrenia have widespread thinner cortex (left/right hemisphere: Cohen’s d = −0.530/−0.516) and smaller surface area (left/right hemisphere: Cohen’s d = −0.251/−0.254). with the …,True,H2whtRcAAAAJ:4OULZ7Gr8RgC,250,https://www.sciencedirect.com/science/article/pii/S0006322318315178,5429823137046201044,/scholar?cites=5429823137046201044,,,https://www.sciencedirect.com/science/article/pii/S0006322318315178,0,0,0
1282012,Healthy habits. happy homes: randomized trial to improve household routines for obesity prevention among preschool-aged children,2013,Jess Haines and Julia McDonald and Ashley O’brien and Bettylou Sherry and Clement J Bottino and Marie Evans Schmidt and Elsie M Taveras,167,JAMA pediatrics,11,1072-1079,American Medical Association,Racial/ethnic and socioeconomic disparities exist across risk factors for childhood obesity.To examine the effectiveness of a home-based intervention to improve household routines known to be associated with childhood obesity among a sample of low-income. racial/ethnic minority families with young children.Randomized trial.The intervention was delivered in the families’ homes.The study involved 121 families with children aged 2 to 5 years who had a television (TV) in the room where he or she slept; 111 (92%) had 6-month outcome data (55 intervention and 56 control). The mean (SD) age of the children was 4.0 (1.1) years; 45% were overweight/obese. Fifty-two percent of the children were Hispanic. 34% were black. and 14% were white/other. Nearly 60% of the families had household incomes of $20 000 or less.The 6-month intervention promoted …,True,H2whtRcAAAAJ:35N4QoGY0k4C,208,https://jamanetwork.com/journals/jamapediatrics/article-abstract/1735654,4291865696574291202,/scholar?cites=4291865696574291202,,,https://www.researchgate.net/profile/Jess_Rd/publication/256481537_Healthy_Habits_Happy_Homes_Randomized_Trial_to_Improve_Household_Routines_for_Obesity_Prevention_Among_Preschool-Aged_Children/links/585ac3e808aebf17d384e7bb.pdf,0,0,0
1282013,Novel genetic loci associated with hippocampal volume,2017,Derrek P Hibar and Hieab HH Adams and Neda Jahanshad and Ganesh Chauhan and Jason L Stein and Edith Hofer and Miguel E Renteria and Joshua C Bis and Alejandro Arias-Vasquez and M Kamran Ikram and Sylvane Desrivières and Meike W Vernooij and Lucija Abramovic and Saud Alhusaini and Najaf Amin and Micael Andersson and Konstantinos Arfanakis and Benjamin S Aribisala and Nicola J Armstrong and Lavinia Athanasiu and Tomas Axelsson and Ashley H Beecham and Alexa Beiser and Manon Bernard and Susan H Blanton and Marc M Bohlken and Marco P Boks and Janita Bralten and Adam M Brickman and Owen Carmichael and M Mallar Chakravarty and Qiang Chen and Christopher RK Ching and Vincent Chouraki and Gabriel Cuellar-Partida and Fabrice Crivello and Anouk Den Braber and Nhat Trung Doan and Stefan Ehrlich and Sudheer Giddaluru and Aaron L Goldman and Rebecca F Gottesman and Oliver Grimm and Michael E Griswold and Tulio Guadalupe and Boris A Gutman and Johanna Hass and Unn K Haukvik and David Hoehn and Avram J Holmes and Martine Hoogman and Deborah Janowitz and Tianye Jia and Kjetil N Jørgensen and Nazanin Karbalai and Dalia Kasperaviciute and Sungeun Kim and Marieke Klein and Bernd Kraemer and Phil H Lee and David CM Liewald and Lorna M Lopez and Michelle Luciano and Christine Macare and Andre F Marquand and Mar Matarin and Karen A Mather and Manuel Mattheisen and David R McKay and Yuri Milaneschi and Susana Muñoz Maniega and Kwangsik Nho and Allison C Nugent and Paul Nyquist and Loes M Olde Loohuis and Jaap Oosterlaan and Martina Papmeyer and Lukas Pirpamer and Benno Pütz and Adaikalavan Ramasamy and Jennifer S Richards and Shannon L Risacher and Roberto Roiz-Santiañez and Nanda Rommelse and Stefan Ropele and Emma J Rose and Natalie A Royle and Tatjana Rundek and Philipp G Sämann and Arvin Saremi and Claudia L Satizabal and Lianne Schmaal and Andrew J Schork and Li Shen and Jean Shin and Elena Shumskaya and Albert V Smith and Emma Sprooten and Lachlan T Strike and Alexander Teumer and Diana Tordesillas-Gutierrez and Roberto Toro and Daniah Trabzuni and Stella Trompet and Dhananjay Vaidya and Jeroen Van der Grond and Sven J Van der Lee and Dennis Van der Meer and Marjolein MJ Van Donkelaar and Kristel R Van Eijk and Theo GM Van Erp and Daan Van Rooij and Esther Walton and Lars T Westlye and Christopher D Whelan and Beverly G Windham and Anderson M Winkler and Katharina Wittfeld and Girma Woldehawariat and Christiane Wolf and Thomas Wolfers and Lisa R Yanek and Jingyun Yang and Alex Zijdenbos and Marcel P Zwiers and Ingrid Agartz and Laura Almasy and David Ames and Philippe Amouyel and Ole A Andreassen and Sampath Arepalli and Amelia A Assareh and Sandra Barral and Mark E Bastin and Diane M Becker and James T Becker and David A Bennett and John Blangero and Hans Van Bokhoven and Dorret I Boomsma and Henry Brodaty and Rachel M Brouwer and Han G Brunner and Randy L Buckner and Jan K Buitelaar and Kazima B Bulayeva and Wiepke Cahn and Vince D Calhoun and Dara M Cannon and Gianpiero L Cavalleri,8,Nature communications,1,1-12,Nature Publishing Group,The hippocampal formation is a brain structure integrally involved in episodic memory. spatial navigation. cognition and stress responsiveness. Structural abnormalities in hippocampal volume and shape are found in several common neuropsychiatric disorders. To identify the genetic underpinnings of hippocampal structure here we perform a genome-wide association study (GWAS) of 33.536 individuals and discover six independent loci significantly associated with hippocampal volume. four of them novel. Of the novel loci. three lie within genes (ASTN2. DPP4 and MAST4) and one is found 200 kb upstream of SHH. A hippocampal subfield analysis shows that a locus within the MSRB3 gene shows evidence of a localized effect along the dentate gyrus. subiculum. CA1 and fissure. Further. we show that genetic variants associated with decreased hippocampal volume are also associated with increased risk for …,True,H2whtRcAAAAJ:R3hNpaxXUhUC,182,https://www.nature.com/articles/ncomms13624,1990898103729024360,/scholar?cites=1990898103729024360,,,https://www.nature.com/articles/ncomms13624,0,0,0
1282014,Novel genetic loci underlying human intracranial volume identified through genome-wide association,2016,Hieab HH Adams and Derrek P Hibar and Vincent Chouraki and Jason L Stein and Paul A Nyquist and Miguel E Rentería and Stella Trompet and Alejandro Arias-Vasquez and Sudha Seshadri and Sylvane Desrivières and Ashley H Beecham and Neda Jahanshad and Katharina Wittfeld and Sven J Van der Lee and Lucija Abramovic and Saud Alhusaini and Najaf Amin and Micael Andersson and Konstantinos Arfanakis and Benjamin S Aribisala and Nicola J Armstrong and Lavinia Athanasiu and Tomas Axelsson and Alexa Beiser and Manon Bernard and Joshua C Bis and Laura ME Blanken and Susan H Blanton and Marc M Bohlken and Marco P Boks and Janita Bralten and Adam M Brickman and Owen Carmichael and M Mallar Chakravarty and Ganesh Chauhan and Qiang Chen and Christopher RK Ching and Gabriel Cuellar-Partida and Anouk Den Braber and Nhat Trung Doan and Stefan Ehrlich and Irina Filippi and Tian Ge and Sudheer Giddaluru and Aaron L Goldman and Rebecca F Gottesman and Corina U Greven and Oliver Grimm and Michael E Griswold and Tulio Guadalupe and Johanna Hass and Unn K Haukvik and Saima Hilal and Edith Hofer and David Hoehn and Avram J Holmes and Martine Hoogman and Deborah Janowitz and Tianye Jia and Dalia Kasperaviciute and Sungeun Kim and Marieke Klein and Bernd Kraemer and Phil H Lee and Jiemin Liao and David CM Liewald and Lorna M Lopez and Michelle Luciano and Christine Macare and Andre Marquand and Mar Matarin and Karen A Mather and Manuel Mattheisen and Bernard Mazoyer and David R McKay and Rebekah McWhirter and Yuri Milaneschi and Nazanin Mirza-Schreiber and Ryan L Muetzel and Susana Muñoz Maniega and Kwangsik Nho and Allison C Nugent and Loes M Olde Loohuis and Jaap Oosterlaan and Martina Papmeyer and Irene Pappa and Lukas Pirpamer and Sara Pudas and Benno Pütz and Kumar B Rajan and Adaikalavan Ramasamy and Jennifer S Richards and Shannon L Risacher and Roberto Roiz-Santiañez and Nanda Rommelse and Emma J Rose and Natalie A Royle and Tatjana Rundek and Philipp G Sämann and Claudia L Satizabal and Lianne Schmaal and Andrew J Schork and Li Shen and Jean Shin and Elena Shumskaya and Albert V Smith and Emma Sprooten and Lachlan T Strike and Alexander Teumer and Russell Thomson and Diana Tordesillas-Gutierrez and Roberto Toro and Daniah Trabzuni and Dhananjay Vaidya and Jeroen Van der Grond and Dennis Van der Meer and Marjolein MJ Van Donkelaar and Kristel R Van Eijk and Theo GM Van Erp and Daan Van Rooij and Esther Walton and Lars T Westlye and Christopher D Whelan and Beverly G Windham and Anderson M Winkler and Girma Woldehawariat and Christiane Wolf and Thomas Wolfers and Bing Xu and Lisa R Yanek and Jingyun Yang and Alex Zijdenbos and Marcel P Zwiers and Ingrid Agartz and Neelum T Aggarwal and Laura Almasy and David Ames and Philippe Amouyel and Ole A Andreassen and Sampath Arepalli and Amelia A Assareh and Sandra Barral and Mark E Bastin and Diane M Becker and James T Becker and David A Bennett and John Blangero and Hans Van Bokhoven and Dorret I Boomsma and Henry Brodaty,19,Nature neuroscience,12,1569-1582,Nature Publishing Group,Intracranial volume reflects the maximally attained brain size during development. and remains stable with loss of tissue in late life. It is highly heritable. but the underlying genes remain largely undetermined. In a genome-wide association study of 32.438 adults. we discovered five previously unknown loci for intracranial volume and confirmed two known signals. Four of the loci were also associated with adult human stature. but these remained associated with intracranial volume after adjusting for height. We found a high genetic correlation with child head circumference (ρ genetic= 0.748). which indicates a similar genetic background and allowed us to identify four additional loci through meta-analysis (N combined= 37.345). Variants for intracranial volume were also related to childhood and adult cognitive function. and Parkinson's disease. and were enriched near genes involved in growth pathways. including …,True,H2whtRcAAAAJ:HDshCWvjkbEC,158,https://www.nature.com/articles/nn.4398,11595265414764620850,/scholar?cites=11595265414764620850,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5227112/,0,0,0
1282015,Mapping cortical brain asymmetry in 17.141 healthy individuals worldwide via the ENIGMA Consortium,2018,Xiang-Zhen Kong and Samuel R Mathias and Tulio Guadalupe and David C Glahn and Barbara Franke and Fabrice Crivello and Nathalie Tzourio-Mazoyer and Simon E Fisher and Paul M Thompson and Clyde Francks and ENIGMA Laterality Working Group,115,Proceedings of the National Academy of Sciences,22,E5154-E5163,National Academy of Sciences,Hemispheric asymmetry is a cardinal feature of human brain organization. Altered brain asymmetry has also been linked to some cognitive and neuropsychiatric disorders. Here. the ENIGMA (Enhancing NeuroImaging Genetics through Meta-Analysis) Consortium presents the largest-ever analysis of cerebral cortical asymmetry and its variability across individuals. Cortical thickness and surface area were assessed in MRI scans of 17.141 healthy individuals from 99 datasets worldwide. Results revealed widespread asymmetries at both hemispheric and regional levels. with a generally thicker cortex but smaller surface area in the left hemisphere relative to the right. Regionally. asymmetries of cortical thickness and/or surface area were found in the inferior frontal gyrus. transverse temporal gyrus. parahippocampal gyrus. and entorhinal cortex. These regions are involved in lateralized functions. including language …,True,H2whtRcAAAAJ:RGFaLdJalmkC,141,https://www.pnas.org/content/115/22/E5154.short,8671910637846316024,/scholar?cites=8671910637846316024,,,https://www.pnas.org/content/pnas/115/22/E5154.full.pdf,0,0,0
1282016,Delayed stabilization and individualization in connectome development are related to psychiatric disorders,2017,Tobias Kaufmann and Dag Alnæs and Nhat Trung Doan and Christine Lycke Brandt and Ole A Andreassen and Lars T Westlye,20,Nature neuroscience,4,513-515,Nature Publishing Group,The brain functional connectome constitutes a unique fingerprint allowing identification of individuals among a pool of people. Here we establish that the connectome develops into a more stable. individual wiring pattern during adolescence and demonstrate that a delay in this network tuning process is associated with reduced mental health in the formative years of late neurodevelopment.,True,H2whtRcAAAAJ:j3f4tGmQtD8C,138,https://www.nature.com/articles/nn.4511,13599599038545638291,/scholar?cites=13599599038545638291,,,https://drive.google.com/file/d/1yg_EmF63wUWnLd2v6TXXoF6ZbbI4I_SY/view,0,0,0
1282017,The genetic architecture of the human cerebral cortex,2020,Katrina L Grasby and Neda Jahanshad and Jodie N Painter and Lucía Colodro-Conde and Janita Bralten and Derrek P Hibar and Penelope A Lind and Fabrizio Pizzagalli and Christopher RK Ching and Mary Agnes B McMahon and Natalia Shatokhina and Leo CP Zsembik and Sophia I Thomopoulos and Alyssa H Zhu and Lachlan T Strike and Ingrid Agartz and Saud Alhusaini and Marcio AA Almeida and Dag Alnæs and Inge K Amlien and Micael Andersson and Tyler Ard and Nicola J Armstrong and Allison Ashley-Koch and Joshua R Atkins and Manon Bernard and Rachel M Brouwer and Elizabeth EL Buimer and Robin Bülow and Christian Bürger and Dara M Cannon and Mallar Chakravarty and Qiang Chen and Joshua W Cheung and Baptiste Couvy-Duchesne and Anders M Dale and Shareefa Dalvie and Tânia K De Araujo and Greig I De Zubicaray and Sonja MC de Zwarte and Anouk Den Braber and Nhat Trung Doan and Katharina Dohm and Stefan Ehrlich and Hannah-Ruth Engelbrecht and Susanne Erk and Chun Chieh Fan and Iryna O Fedko and Sonya F Foley and Judith M Ford and Masaki Fukunaga and Melanie E Garrett and Tian Ge and Sudheer Giddaluru and Aaron L Goldman and Melissa J Green and Nynke A Groenewold and Dominik Grotegerd and Tiril P Gurholt and Boris A Gutman and Narelle K Hansell and Mathew A Harris and Marc B Harrison and Courtney C Haswell and Michael Hauser and Stefan Herms and Dirk J Heslenfeld and New Fei Ho and David Hoehn and Per Hoffmann and Laurena Holleran and Martine Hoogman and Jouke-Jan Hottenga and Masashi Ikeda and Deborah Janowitz and Iris E Jansen and Tianye Jia and Christiane Jockwitz and Ryota Kanai and Sherif Karama and Dalia Kasperaviciute and Tobias Kaufmann and Sinead Kelly and Masataka Kikuchi and Marieke Klein and Michael Knapp and Annchen R Knodt and Bernd Krämer and Max Lam and Thomas M Lancaster and Phil H Lee and Tristram A Lett and Lindsay B Lewis and Iscia Lopes-Cendes and Michelle Luciano and Fabio Macciardi and Andre F Marquand and Samuel R Mathias and Tracy R Melzer and Yuri Milaneschi and Nazanin Mirza-Schreiber and Jose CV Moreira and Thomas W Mühleisen and Bertram Müller-Myhsok and Pablo Najt and Soichiro Nakahara and Kwangsik Nho and Loes M Olde Loohuis and Dimitri Papadopoulos Orfanos and John F Pearson and Toni L Pitcher and Benno Pütz and Yann Quidé and Anjanibhargavi Ragothaman and Faisal M Rashid and William R Reay and Ronny Redlich and Céline S Reinbold and Jonathan Repple and Geneviève Richard and Brandalyn C Riedel and Shannon L Risacher and Cristiane S Rocha and Nina Roth Mota and Lauren Salminen and Arvin Saremi and Andrew J Saykin and Fenja Schlag and Lianne Schmaal and Peter R Schofield and Rodrigo Secolin and Chin Yang Shapland and Li Shen and Jean Shin and Elena Shumskaya and Ida E Sønderby and Emma Sprooten and Katherine E Tansey and Alexander Teumer and Anbupalam Thalamuthu and Diana Tordesillas-Gutiérrez and Jessica A Turner and Anne Uhlmann and Costanza Ludovica Vallerga and Dennis Van der Meer and Marjolein MJ Van Donkelaar and Liza Van Eijk and Theo GM Van Erp and Neeltje EM Van Haren and Daan Van Rooij,367,Science,6484,,American Association for the Advancement of Science,The cerebral cortex underlies our complex cognitive capabilities. Variations in human cortical surface area and thickness are associated with neurological. psychological. and behavioral traits and can be measured in vivo by magnetic resonance imaging (MRI). Studies in model organisms have identified genes that influence cortical structure. but little is known about common genetic variants that affect human cortical structure.To identify genetic variants associated with human cortical structure at both global and regional levels. we conducted a genome-wide association meta-analysis of brain MRI data from 51.665 individuals across 60 cohorts. We analyzed the surface area and average thickness of the whole cortex and 34 cortical regions with known functional specializations.We identified 306 nominally genome-wide significant loci (P < 5 × 10−8) associated with cortical …,True,H2whtRcAAAAJ:bFI3QPDXJZMC,125,https://science.sciencemag.org/content/367/6484/eaay6690.abstract,2087509801194225348,/scholar?cites=2087509801194225348,,,https://pure.mpg.de/rest/items/item_3208577/component/file_3215230/content,0,0,0
1282018,Mapping the heterogeneous phenotype of schizophrenia and bipolar disorder using normative models,2018,Thomas Wolfers and Nhat Trung Doan and Tobias Kaufmann and Dag Alnæs and Torgeir Moberget and Ingrid Agartz and Jan K Buitelaar and Torill Ueland and Ingrid Melle and Barbara Franke and Ole A Andreassen and Christian F Beckmann and Lars T Westlye and Andre F Marquand,75,JAMA psychiatry,11,1146-1155,American Medical Association,Schizophrenia and bipolar disorder are severe and complex brain disorders characterized by substantial clinical and biological heterogeneity. However. case-control studies often ignore such heterogeneity through their focus on the average patient. which may be the core reason for a lack of robust biomarkers indicative of an individual’s treatment response and outcome.To investigate the degree to which case-control analyses disguise interindividual differences in brain structure among patients with schizophrenia and bipolar disorder and to map the brain alterations linked to these disorders at the level of individual patients.This study used cross-sectional. T1-weighted magnetic resonance imaging data from participants recruited for the Thematically Organized Psychosis study from October 27. 2004. to October 17. 2012. Data were reanalyzed in 2017 and …,True,H2whtRcAAAAJ:abG-DnoFyZgC,116,https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2705762,13482624919935448689,/scholar?cites=13482624919935448689,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6248110/,0,0,0
1282019,Detailed comparison of amyloid PET and CSF biomarkers for identifying early Alzheimer disease,2015,Sebastian Palmqvist and Henrik Zetterberg and Niklas Mattsson and Per Johansson and Lennart Minthon and Kaj Blennow and Mattias Ohlsson and Oskar Hansson,85,Neurology,14,1240-1249,,To compare the diagnostic accuracy of CSF biomarkers and amyloid PET for diagnosing early-stage Alzheimer disease (AD).From the prospective. longitudinal BioFINDER study. we included 122 healthy elderly and 34 patients with mild cognitive impairment who developed AD dementia within 3 years (MCI-AD). β-Amyloid (Aβ) deposition in 9 brain regions was examined with [18F]-flutemetamol PET. CSF was analyzed with INNOTEST and EUROIMMUN ELISAs. The results were replicated in 146 controls and 64 patients with MCI-AD from the Alzheimer9s Disease Neuroimaging Initiative study.The best CSF measures for identifying MCI-AD were Aβ42/total tau (t-tau) and Aβ42/hyperphosphorylated tau (p-tau) (area under the curve [AUC] 0.93–0.94). The best PET measures performed similarly (AUC 0.92–0.93; anterior cingulate. posterior cingulate/precuneus. and global neocortical …,True,c8BJ06MAAAAJ:Weau3kkTRIMC,208,https://n.neurology.org/content/85/14/1240.short,4327430506127779178,/scholar?cites=4327430506127779178,,,https://n.neurology.org/content/neurology/85/14/1240.full.pdf,0,0,0
1282020,Track finding with deformable templates—the elastic arms approach,1992,Mattias Ohlsson and Carsten Peterson and Alan L Yuille,71,Computer Physics Communications,1-2,77-98,North-Holland,A novel algorithm for particle tracking is presented and evaluated. It is based on deformable templates that converge using a deterministic annealing algorithm. These deformable templates are initialized by Hough transforms. The algorithm. which effectively represents a merger between neuronic decision making and parameter fitting. naturally lends itself to parallel execution. Very good performance is obtained for both non-magnetic and magnetic tracks. For the latter simulated TPC tracks from the CERN DELPHI detector are used.,True,c8BJ06MAAAAJ:u5HHmVD_uO8C,153,https://www.sciencedirect.com/science/article/pii/0010465592900749,5877687876644244402,/scholar?cites=5877687876644244402,,,https://cds.cern.ch/record/227843/files/p888.pdf,0,0,0
1282021,Toward personal eHealth in cardiology. Results from the EPI-MEDICS telemedicine project,2005,Paul Rubel and Jocelyne Fayn and Giandomenico Nollo and Deodato Assanelli and Bo Li and Lioara Restier and Stefano Adami and Sebastien Arod and Hussein Atoui and Mattias Ohlsson and Lucas Simon-Chautemps and David Telisson and Cesare Malossi and Gian-Luca Ziliani and Alfredo Galassi and Lars Edenbrandt and Philippe Chevalier,38,,4,100-106,Churchill Livingstone,Despite many attempts to improve the management of acute myocardial infarction. only small trends to shorter time intervals before treatment have been reported. The self-care solution developed by the European EPI-MEDICS project (2001-2004) is a novel. very affordable. easy-to-use. portable. and intelligent Personal ECG Monitor (PEM) for the early detection of cardiac ischemia and arrhythmia that is able to record a professional-quality. 3-lead electrocardiogram (ECG) based on leads I. II. and V2; derive the missing leads of the standard 12-lead ECG (thanks to either a generic or a patient-specific transform). compare each ECG with a reference ECG by means of advanced neural network–based decision-making methods taking into account the serial ECG measurements and the patient risk factors and clinical data; and generate different levels of alarms and forward the alarm messages with the recorded ECGs …,True,c8BJ06MAAAAJ:u-x6o8ySG0sC,152,https://www.sciencedirect.com/science/article/pii/S0022073605001214,12959668525770022621,/scholar?cites=12959668525770022621,,,https://www.academia.edu/download/50698158/Toward_personal_eHealth_in_cardiology._R20161203-14645-2bhy20.pdf,0,0,0
1282022,A novel automated platform for quantifying the extent of skeletal tumour involvement in prostate cancer patients using the Bone Scan Index,2012,David Ulmert and Reza Kaboteh and Josef J Fox and Caroline Savage and Michael J Evans and Hans Lilja and Per-Anders Abrahamsson and Thomas Björk and Axel Gerdtsson and Anders Bjartell and Peter Gjertsson and Peter Höglund and Milan Lomsky and Mattias Ohlsson and Jens Richter and May Sadik and Michael J Morris and Howard I Scher and Karl Sjöstrand and Alice Yu and Madis Suurküla and Lars Edenbrandt and Steven M Larson,62,European urology,1,78-84,Elsevier,There is little consensus on a standard approach to analysing bone scan images. The Bone Scan Index (BSI) is predictive of survival in patients with progressive prostate cancer (PCa). but the popularity of this metric is hampered by the tedium of the manual calculation.Develop a fully automated method of quantifying the BSI and determining the clinical value of automated BSI measurements beyond conventional clinical and pathologic features.We conditioned a computer-assisted diagnosis system identifying metastatic lesions on a bone scan to automatically compute BSI measurements. A training group of 795 bone scans was used in the conditioning process. Independent validation of the method used bone scans obtained ≤3 mo from diagnosis of 384 PCa cases in two large population-based cohorts. An experienced analyser (blinded to case identity. prior …,True,c8BJ06MAAAAJ:qUcmZB5y_30C,148,https://www.sciencedirect.com/science/article/pii/S0302283812000942,7894216491099451296,/scholar?cites=7894216491099451296,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3402084/,0,0,0
1282023,Comparison between neural networks and multiple logistic regression to predict acute coronary syndrome in the emergency room,2006,Michael Green and Jakob Forberg and Lars Edenbrandt and Mattias Ohlsson,38,Artificial Intelligence in Medicine,3,305-318,Tecklenburg. Federal Republic of Germany,Patients with suspicion of acute coronary syndrome (ACS) are difficult to diagnose and they represent a very heterogeneous group. Some require immediate treatment while others. with only minor disorders. may be sent home. Detecting ACS patients using a machine learning approach would be advantageous in many situations.Artificial neural network (ANN) ensembles and logistic regression models were trained on data from 634 patients presenting an emergency department with chest pain. Only data immediately available at patient presentation were used. including electrocardiogram (ECG) data. The models were analyzed using receiver operating characteristics (ROC) curve analysis. calibration assessments. inter- and intra-method variations. Effective odds ratios for the ANN ensembles were compared with the odds ratios obtained from the logistic model.The ANN …,True,c8BJ06MAAAAJ:_xSYboBqXhAC,115,https://www.sciencedirect.com/science/article/pii/S0933365706001059,11330703226309144863,/scholar?cites=11330703226309144863,,,https://portal.research.lu.se/portal/files/2674506/1034045.pdf,0,0,0
1282024,Detecting acute myocardial infarction in the 12-lead ECG using Hermite expansions and neural networks,2004,Henrik Haraldsson and Lars Edenbrandt and Mattias Ohlsson,32,Artificial Intelligence in Medicine,2,127-136,Elsevier,We use artificial neural networks (ANNs) to detect signs of acute myocardial infarction (AMI) in ECGs. The 12-lead ECG is decomposed into Hermite basis functions. and the resulting coefficients are used as inputs to the ANNs. Furthermore. we present a case-based method that qualitatively explains the operation of the ANNs. by showing regions of each ECG critical for ANN response. Key ingredients in this method are: (i) a cost function used to find local ECG perturbations leading to the largest possible change in ANN output and (ii) a minimization scheme for this cost function using mean field annealing. Our approach was tested on 2238 ECGs recorded at an emergency department. The obtained ROC areas for ANNs trained with the Hermite representation and standard ECG measurements were 83.4 and 84.3% (P=0.4). respectively. We believe that the proposed method has potential as a decision support …,True,c8BJ06MAAAAJ:Tyk-4Ss8FVUC,114,https://www.sciencedirect.com/science/article/pii/S0933365704000144,14124702487817821554,/scholar?cites=14124702487817821554,,,http://particle.thep.lu.se/pub/Preprints/03/lu_tp_03_16.pdf,0,0,0
1282025,Neural networks for optimization problems with inequality constraints: the knapsack problem,1993,Mattias Ohlsson and Carsten Peterson and Bo Söderberg,5,neural computation,2,331-339,MIT Press,A strategy for finding approximate solutions to discrete optimization problems with inequality constraints using mean field neural networks is presented. The constraints x ≤ 0 are encoded by x⊖(x) terms in the energy function. A careful treatment of the mean field approximation for the self-coupling parts of the energy is crucial. and results in an essentially parameter-free algorithm. This methodology is extensively tested on the knapsack problem of size up to 103 items. The algorithm scales like NM for problems with N items and M constraints. Comparisons are made with an exact branch and bound algorithm when this is computationally possible (N ≤ 30). The quality of the neural network solutions consistently lies above 95% of the optimal ones at a significantly lower CPU expense. For the larger problem sizes the algorithm is compared with simulated annealing and a modified linear programming approach. For …,True,c8BJ06MAAAAJ:d1gkVwhDpl0C,113,https://www.mitpressjournals.org/doi/abs/10.1162/neco.1993.5.2.331,3882998604370229624,/scholar?cites=3882998604370229624,,,https://direct.mit.edu/neco/article-pdf/5/2/331/812551/neco.1993.5.2.331.pdf,0,0,0
1282026,Evaluation of a previously suggested plasma biomarker panel to identify Alzheimer's disease,2012,Maria Björkqvist and Mattias Ohlsson and Lennart Minthon and Oskar Hansson,7,PloS one,1,e29868,Public Library of Science,There is an urgent need for biomarkers in plasma to identify Alzheimer's disease (AD). It has previously been shown that a signature of 18 plasma proteins can identify AD during pre-dementia and dementia stages (Ray et al. Nature Medicine. 2007). We quantified the same 18 proteins in plasma from 174 controls. 142 patients with AD. and 88 patients with other dementias. Only three of these proteins (EGF. PDG-BB and MIP-1δ) differed significantly in plasma between controls and AD. The 18 proteins could classify patients with AD from controls with low diagnostic precision (area under the ROC curve was 63%). Moreover. they could not distinguish AD from other dementias. In conclusion. independent validation of results is important in explorative biomarker studies.,True,c8BJ06MAAAAJ:4TOpqqG69KYC,108,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029868,10970248584365469060,/scholar?cites=10970248584365469060,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029868,0,0,0
1282027,Computer-assisted interpretation of planar whole-body bone scans,2008,May Sadik and Iman Hamadeh and Pierre Nordblom and Madis Suurkula and Peter Höglund and Mattias Ohlsson and Lars Edenbrandt,49,Journal of Nuclear Medicine,12,1958-1965,Society of Nuclear Medicine,,True,c8BJ06MAAAAJ:5nxA0vEk-isC,102,https://jnm.snmjournals.org/content/49/12/1958.short,2977289925994346446,/scholar?cites=2977289925994346446,,,https://jnm.snmjournals.org/content/49/12/1958.full.pdf,0,0,0
1282028,Molecular serum portraits in patients with primary breast cancer predict the development of distant metastases,2011,Anders Carlsson and Christer Wingren and Malin Kristensson and Carsten Rose and Mårten Fernö and Håkan Olsson and Helena Jernström and Sara Ek and Elin Gustavsson and Christian Ingvar and Mattias Ohlsson and Carsten Peterson and Carl AK Borrebaeck,108,Proceedings of the National Academy of Sciences,34,14252-14257,National Academy of Sciences,The risk of distant recurrence in breast cancer patients is difficult to assess with current clinical and histopathological parameters. and no validated serum biomarkers currently exist. Using a recently developed recombinant antibody microarray platform containing 135 antibodies against 65 mainly immunoregulatory proteins. we screened 240 sera from 64 patients with primary breast cancer. This unique longitudinal sample material was collected from each patient between 0 and 36 mo after the primary operation. The velocity for each serum protein was determined by comparing the samples collected at the primary operation and then 3–6 mo later. A 21-protein signature was identified. using leave-one-out cross-validation together with a backward elimination strategy in a training cohort. This signature was tested and evaluated subsequently in an independent test cohort (prevalidation). The risk of developing distant …,True,c8BJ06MAAAAJ:Zph67rFs4hoC,94,https://www.pnas.org/content/108/34/14252.short,6633974408570400603,/scholar?cites=6633974408570400603,,,https://www.pnas.org/content/pnas/108/34/14252.full.pdf,0,0,0
1282029,Risk factor identification and mortality prediction in cardiac surgery using artificial neural networks,2006,Johan Nilsson and Mattias Ohlsson and Lars Thulin and Peter Höglund and Samer AM Nashef and Johan Brandt,132,The Journal of thoracic and cardiovascular surgery,1,12-19. e1,Mosby,The artificial neural network model is a nonlinear technology useful for complex pattern recognition problems. This study aimed to develop a method to select risk variables and predict mortality after cardiac surgery by using artificial neural networks.Prospectively collected data from 18.362 patients undergoing cardiac surgery at 128 European institutions in 1995 (the European System for Cardiac Operative Risk Evaluation database) were used. Models to predict the operative mortality were constructed using artificial neural networks. For calibration a sixfold cross-validation technique was used. and for testing a fourfold cross-testing was performed. Risk variables were ranked and minimized in number by calibrated artificial neural networks. Mortality prediction with 95% confidence limits for each patient was obtained by the bootstrap technique. The area under the receiver operating characteristics …,True,c8BJ06MAAAAJ:tOudhMTPpwUC,91,https://www.sciencedirect.com/science/article/pii/S0022522306001243,17354985741135402496,/scholar?cites=17354985741135402496,,,https://www.sciencedirect.com/science/article/pii/S0022522306001243,0,0,0
1282030,Pruning convolutional neural networks for resource efficient inference,2016,Pavlo Molchanov and Stephen Tyree and Tero Karras and Timo Aila and Jan Kautz,,,,,,We propose a new formulation for pruning convolutional kernels in neural networks to enable efficient inference. We interleave greedy criteria-based pruning with fine-tuning by backpropagation-a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. We focus on transfer learning. where large pretrained networks are adapted to specialized tasks. The proposed criterion demonstrates superior performance compared to other criteria. eg the norm of kernel weights or feature map activation. for pruning large CNNs after adaptation to fine-grained classification tasks (Birds-200 and Flowers-102) relaying only on the first order gradient information. We also show that pruning can lead to more than 10x theoretical (5x practical) reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier. Finally. we show results for the large-scale ImageNet dataset to emphasize the flexibility of our approach.,True,J9PoyoIAAAAJ:hC7cP41nSMkC,806,https://arxiv.org/abs/1611.06440,13741786010220230474,/scholar?cites=13741786010220230474,,,https://arxiv.org/pdf/1611.06440,0,0,0
1282031,Hand gesture recognition with 3D convolutional neural networks,2015,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Jan Kautz,,,,1-7,,Touchless hand gesture recognition systems are becoming important in automotive user interfaces as they improve safety and comfort. Various computer vision algorithms have employed color and depth cameras for hand gesture recognition. but robust classification of gestures from different subjects performed under widely varying lighting conditions is still challenging. We propose an algorithm for drivers' hand gesture recognition from challenging depth and intensity data using 3D convolutional neural networks. Our solution combines information from multiple spatial scales for the final prediction. It also employs spatio-temporal data augmentation for more effective training and to reduce potential overfitting. Our method achieves a correct classification rate of 77.5\% on the VIVA challenge dataset.,True,J9PoyoIAAAAJ:QIV2ME_5wuYC,407,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W15/html/Molchanov_Hand_Gesture_Recognition_2015_CVPR_paper.html,13528217692621440063,/scholar?cites=13528217692621440063,,,https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W15/papers/Molchanov_Hand_Gesture_Recognition_2015_CVPR_paper.pdf,0,0,0
1282032,Online detection and classification of dynamic hand gestures with recurrent 3d convolutional neural network,2016,Pavlo Molchanov and Xiaodong Yang and Shalini Gupta and Kihwan Kim and Stephen Tyree and Jan Kautz,,,,4207-4215,,Automatic detection and classification of dynamic hand gestures in real-world systems intended for human computer interaction is challenging as: 1) there is a large diversity in how people perform gestures. making detection and classification difficult; 2) the system must work online in order to avoid noticeable lag between performing a gesture and its classification; in fact. a negative lag (classification before the gesture is finished) is desirable. as feedback to the user can then be truly instantaneous. In this paper. we address these challenges with a recurrent three-dimensional convolutional neural network that performs simultaneous detection and classification of dynamic hand gestures from multi-modal data. We employ connectionist temporal classification to train the network to predict class labels from in-progress gestures in unsegmented input streams. In order to validate our method. we introduce a new challenging multi-modal dynamic hand gesture dataset captured with depth. color and stereo-IR sensors. On this challenging dataset. our gesture recognition system achieves an accuracy of 83.8%. outperforms competing state-of-the-art algorithms. and approaches human accuracy of 88.4%. Moreover. our method achieves state-of-the-art performance on SKIG and ChaLearn2014 benchmarks.,True,J9PoyoIAAAAJ:ZeXyd9-uunAC,375,http://openaccess.thecvf.com/content_cvpr_2016/html/Molchanov_Online_Detection_and_CVPR_2016_paper.html,3040705073843151431,/scholar?cites=3040705073843151431,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Molchanov_Online_Detection_and_CVPR_2016_paper.pdf,0,0,0
1282033,Pruning convolutional neural networks for resource efficient transfer learning,2016,Pavlo Molchanov and Stephen Tyree and Tero Karras and Timo Aila and Jan Kautz,3,arXiv preprint arXiv:1611.06440,,,CoRR,We propose a new framework for pruning convolutional kernels in neural networks to enable efficient inference. focusing on transfer learning where large and potentially unwieldy pretrained networks are adapted to specialized tasks. We interleave greedy criteria-based pruning with fine-tuning by backpropagation—a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on an efficient first-order Taylor expansion to approximate the absolute change in training cost induced by pruning a network component. After normalization. the proposed criterion scales appropriately across all layers of a deep CNN. eliminating the need for per-layer sensitivity analysis. The proposed criterion demonstrates superior performance compared to other criteria. such as the norm of kernel weights or average feature map activation.,True,J9PoyoIAAAAJ:bFI3QPDXJZMC,223,http://scholar.google.com/scholar?cluster=10533781015747260883&hl=en&oi=scholarr,10533781015747260883,/scholar?cites=10533781015747260883,,,,0,0,0
1282034,Multi-sensor system for driver's hand-gesture recognition,2015,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Kari Pulli,1,,,1-8,IEEE,We propose a novel multi-sensor system for accurate and power-efficient dynamic car-driver hand-gesture recognition. using a short-range radar. a color camera. and a depth camera. which together make the system robust against variable lighting conditions. We present a procedure to jointly calibrate the radar and depth sensors. We employ convolutional deep neural networks to fuse data from multiple sensors and to classify the gestures. Our algorithm accurately recognizes 10 different gestures acquired indoors and outdoors in a car during the day and at night. It consumes significantly less power than purely vision-based systems.,True,J9PoyoIAAAAJ:mVmsd5A6BfQC,193,https://ieeexplore.ieee.org/abstract/document/7163132/,5817183552051842322,/scholar?cites=5817183552051842322,,,http://people.csail.mit.edu/kapu/papers/DriverHandGestureFG2015.pdf,0,0,0
1282035,Classification of small UAVs and birds by micro-Doppler signatures,2013,Pavlo Molchanov and K Egiazarian and J Astola and RIA Harmanny and JJM De Wit,,,,172-175,IEEE,The problem of unmanned aerial vehicles classification using continuous wave radar is considered in this paper. Classification features are extracted from micro-Doppler signature. Before the classification. the micro-Doppler signature is filtered and aligned to compensate the Doppler shift caused by the target's body motion. Eigenpairs extracted from the correlation matrix of the signature are used as informative features for classification. The proposed approach is verified on real radar measurements collected with 9.5 GHz radar. Planes. quadrocopter. helicopters and stationary rotors as well as birds are considered for classification. Moreover. a possibility of distinguishing different number of rotors is considered. The obtained results show the effectiveness of the proposed approach. It provides capability of correct classification with a probability of around 95%.,True,J9PoyoIAAAAJ:YOwf2qJgpHMC,179,https://ieeexplore.ieee.org/abstract/document/6689141/,16480040188516700448,/scholar?cites=16480040188516700448,,,https://repository.tudelft.nl/islandora/object/uuid:9b5912e3-4e5f-4396-90fc-808a95aa01f8/datastream/URL/download,0,0,0
1282036,Importance estimation for neural network pruning,2019,Pavlo Molchanov and Arun Mallya and Stephen Tyree and Iuri Frosio and Jan Kautz,,,,11264-11272,,Structural pruning of neural network parameters reduces computational. energy. and memory transfer costs during inference. We propose a novel method that estimates the contribution of a neuron (filter) to the final loss and iteratively removes those with smaller scores. We describe two variations of our method using the first and second-order Taylor expansions to approximate a filter's contribution. Both methods scale consistently across any network layer without requiring per-layer sensitivity analysis and can be applied to any kind of layer. including skip connections. For modern networks trained on ImageNet. we measured experimentally a high (> 93%) correlation between the contribution computed by our methods and a reliable estimate of the true importance. Pruning with the proposed methods led to an improvement over state-of-the-art in terms of accuracy. FLOPs. and parameter reduction. On ResNet-101. we achieve a 40% FLOPS reduction by removing 30% of the parameters. with a loss of 0.02% in the top-1 accuracy on ImageNet.,True,J9PoyoIAAAAJ:RYcK_YlVTxYC,155,http://openaccess.thecvf.com/content_CVPR_2019/html/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.html,11394834411572433707,/scholar?cites=11394834411572433707,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.pdf,0,0,0
1282037,Depth-based 3d hand pose estimation: From current achievements to future goals,2018,Shanxin Yuan and Guillermo Garcia-Hernando and Björn Stenger and Gyeongsik Moon and Ju Yong Chang and Kyoung Mu Lee and Pavlo Molchanov and Jan Kautz and Sina Honari and Liuhao Ge and Junsong Yuan and Xinghao Chen and Guijin Wang and Fan Yang and Kai Akiyama and Yang Wu and Qingfu Wan and Meysam Madadi and Sergio Escalera and Shile Li and Dongheui Lee and Iason Oikonomidis and Antonis Argyros and Tae-Kyun Kim,,,,2636-2645,,In this paper. we strive to answer two questions: What is the current state of 3D hand pose estimation from depth images? And. what are the next challenges that need to be tackled? Following the successful Hands In the Million Challenge (HIM2017). we investigate the top 10 state-of-the-art methods on three tasks: single frame 3D pose estimation. 3D hand tracking. and hand pose estimation during object interaction. We analyze the performance of different CNN structures with regard to hand shape. joint visibility. view point and articulation distributions. Our findings include:(1) isolated 3D hand pose estimation achieves low mean errors (10 mm) in the view point range of [70. 120] degrees. but it is far from being solved for extreme view points;(2) 3D volumetric representations outperform 2D CNNs. better capturing the spatial structure of the depth data;(3) Discriminative methods still generalize poorly to unseen hand shapes;(4) While joint occlusions pose a challenge for most methods. explicit modeling of structure constraints can significantly narrow the gap between errors on visible and occluded joints.,True,J9PoyoIAAAAJ:TFP_iSt0sucC,153,http://openaccess.thecvf.com/content_cvpr_2018/html/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.html,6443905204831695787,/scholar?cites=6443905204831695787,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.pdf,0,0,0
1282038,Short-range FMCW monopulse radar for hand-gesture sensing,2015,Pavlo Molchanov and Shalini Gupta and Kihwan Kim and Kari Pulli,,,,1491-1496,IEEE,Intelligent driver assistance systems have become important in the automotive industry. One key element of such systems is a smart user interface that tracks and recognizes drivers' hand gestures. Hand gesture sensing using traditional computer vision techniques is challenging because of wide variations in lighting conditions. e.g. inside a car. A short-range radar device can provide additional information. including the location and instantaneous radial velocity of moving objects. We describe a novel end-to-end (hardware. interface. and software) short-range FMCW radar-based system designed to effectively sense dynamic hand gestures. We provide an effective method for selecting the parameters of the FMCW waveform and for jointly calibrating the radar system with a depth sensor. Finally. we demonstrate that our system guarantees reliable and robust performance.,True,J9PoyoIAAAAJ:9ZlFYXVOiuMC,150,https://ieeexplore.ieee.org/abstract/document/7131232/,16613778594857123430,/scholar?cites=16613778594857123430,,,https://kihwan23.com/papers/RADAR15/FMCW-RADAR15.pdf,0,0,0
1282039,Hand Pose Estimation via Latent 2.5 D Heatmap Regression,2018,Umar Iqbal and Pavlo Molchanov and Thomas Breuel and Juergen Gall and Jan Kautz,,,,,,Estimating the 3D pose of a hand is an essential part of human-computer interaction. Estimating 3D pose using depth or multi-view sensors has become easier with recent advances in computer vision. however. regressing pose from a single RGB image is much less straightforward. The main difficulty arises from the fact that 3D pose requires some form of depth estimates. which are ambiguous given only an RGB image. In this paper we propose a new method for 3D hand pose estimation from a monocular image through a novel 2.5 D pose representation. Our new representation estimates pose up to a scaling factor. which can be estimated additionally if a prior of the hand size is given. We implicitly learn depth maps and heatmap distributions with a novel CNN architecture. Our system achieves the state-of-the-art estimation of 2D and 3D hand pose on several challenging datasets in presence of severe occlusions.,True,J9PoyoIAAAAJ:k_IJM867U9cC,128,http://openaccess.thecvf.com/content_ECCV_2018/html/Umar_Iqbal_Hand_Pose_Estimation_ECCV_2018_paper.html,11511620299358261339,/scholar?cites=11511620299358261339,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Umar_Iqbal_Hand_Pose_Estimation_ECCV_2018_paper.pdf,0,0,0
1282040,Improving landmark localization with semi-supervised learning,2018,Sina Honari and Pavlo Molchanov and Stephen Tyree and Pascal Vincent and Christopher Pal and Jan Kautz,,,,1546-1555,,We present two techniques to improve landmark localization in images from partially annotated datasets. Our primary goal is to leverage the common situation where precise landmark locations are only provided for a small data subset. but where class labels for classification or regression tasks related to the landmarks are more abundantly available. First. we propose the framework of sequential multitasking and explore it here through an architecture for landmark localization where training with class labels acts as an auxiliary signal to guide the landmark localization on unlabeled data. A key aspect of our approach is that errors can be backpropagated through a complete landmark localization model. Second. we propose and explore an unsupervised learning technique for landmark localization based on having a model predict equivariant landmarks with respect to transformations applied to the image. We show that these techniques. improve landmark prediction considerably and can learn effective detectors even when only a small fraction of the dataset has landmark labels. We present results on two toy datasets and four real datasets. with hands and faces. and report new state-of-the-art on two datasets in the wild. eg with only 5% of labeled images we outperform previous state-of-the-art trained on the AFLW dataset.,True,J9PoyoIAAAAJ:R3hNpaxXUhUC,103,http://openaccess.thecvf.com/content_cvpr_2018/html/Honari_Improving_Landmark_Localization_CVPR_2018_paper.html,17854404677564441487,/scholar?cites=17854404677564441487,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Honari_Improving_Landmark_Localization_CVPR_2018_paper.pdf,0,0,0
1282041,Measuring arthropod biodiversity in the tropical forest canopy.,1995,Terry L Erwin,,Forest canopies.,,109-127,Academic Press,A historical review of what has been achieved with arthropod diversity sampling sampling Subject Category: Techniques. Methodologies and Equipment,True,uO0QH0YAAAAJ:gXFvZ3BI3UoC,104,https://www.cabdirect.org/cabdirect/abstract/19960603745,11090231147645294103,/scholar?cites=11090231147645294103,,,,0,0,0
1282042,Optical microscopic study of surface morphology and filtering efficiency of face masks,2019,Bhanu Bhakta Neupane and Sangita Mainali and Amita Sharma and Basant Giri,7,PeerJ,,e7142,PeerJ Inc.,BackgroundLow-cost face masks made from different cloth materials are very common in developing countries. The cloth masks (CM) are usually double layered with stretchable ear loops. It is common practice to use such masks for months after multiple washing and drying cycles. If a CM is used for long time. the ear loops become stretched. The loop needs to be knotted to make the mask loop fit better on the face. It is not clear how washing and drying and stretching practices change the quality of a CM. The particulate matter (PM) filtering efficiency of a mask depends on multiple parameters. such as pore size. shape. clearance. and pore number density. It is important to understand the effect of these parameters on the filtering efficiency.MethodsWe characterized the surface of twenty different types of CMs using optical image analysis method. The filtering efficiency of selected cloth face masks was measured using the particle counting method. We also studied the effects of washing and drying and stretching on the quality of a mask.ResultsThe pore size of masks ranged from 80 to 500 μm. which was much bigger than particular matter having diameter of 2.5 μm or less (PM 2.5) and 10 μm or less (PM 10) size. The PM 10 filtering efficiency of four of the selected masks ranged from 63% to 84%. The poor filtering efficiency may have arisen from larger and open pores present in the masks. Interestingly. we found that efficiency dropped by 20% after the 4th washing and drying cycle. We observed a change in pore size and shape and a decrease in microfibers within the pores after washing. Stretching of CM surface also altered the pore size and …,True,uO0QH0YAAAAJ:8ddHFWtxbeMC,46,https://peerj.com/articles/7142/,17661493199830746039,/scholar?cites=17661493199830746039,,,https://peerj.com/articles/7142/,0,0,0
1282043,SPAD array with gated histogram construction,2020,Anup K Sharma and Arnaud Laflaquière and Gennadiy A Agranov and Gershon Rosenblum and Shingo Mandai,,,,,,A sensing device includes a first array of sensing elements. which output a signal indicative of a time of incidence of a single photon on the sensing element. A second array of processing circuits are coupled respectively to the sensing elements and comprise a gating generator. which variably sets a start time of the gating interval for each sensing element within each acquisition period. and a memory. which records the time of incidence of the single photon on each sensing element in each acquisition period. A controller controls the gating generator during a first sequence of the acquisition periods so as to sweep the gating interval over the acquisition periods and to identify a respective detection window for the sensing element. and during a second sequence of the acquisition periods. to fix the gating interval for each sensing element to coincide with the respective detection window.,True,uO0QH0YAAAAJ:xV0sImiv5aMC,38,https://patents.google.com/patent/US10620300B2/en,7909657408777719279,/scholar?cites=7909657408777719279,,,https://patentimages.storage.googleapis.com/15/f9/00/6f025d52697df6/US10620300.pdf,0,0,0
1282044,Quark diagram analysis of weak hadronic decays of the  meson,2002,RC Verma and Avinash Sharma,65,Physical Review D,11,114007,American Physical Society,Two-body weak decay modes of the B c+ meson leading to PP. V P. and VV states. where P and V represent the pseudoscalar meson and vector meson. respectively. are analyzed in the quark diagram scheme. Various relations among the decay amplitudes are obtained. and their branching ratios are predicted.,True,uO0QH0YAAAAJ:Ab_9J64Q_yAC,38,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.65.114007,9899541963304496989,/scholar?cites=9899541963304496989,,,https://www.academia.edu/download/45717089/Quark_diagram_analysis_of_weak_hadronic_20160517-1843-nbsc4.pdf,0,0,0
1282045,Stopping power for heavy ions (3⩽ Z⩽ 35) in solids at energies∼ 0.5–2.5 MeV/n,2001,PK Diwan and Annu Sharma and Shyam Kumar,174,Nuclear Instruments and Methods in Physics Research Section B: Beam Interactions with Materials and Atoms,3,267-273,North-Holland,The Hubert et al. formulation for stopping power calculations has been extended below its recommended range of validity. i.e. 2.5–500 MeV/n. It has been established that the extended formulation for projectiles with Z=3–35 provides a good agreement with the experimental data for elemental targets (6⩽Z⩽79) and complex materials e.g. CR-39. LR-115. Mylar. Kapton. polycarbonate and Havar in the energy range 0.5–2.5 MeV/n.,True,uO0QH0YAAAAJ:MBnQv3n-1h8C,30,https://www.sciencedirect.com/science/article/pii/S0168583X00005139,8495099073294225099,/scholar?cites=8495099073294225099,,,,0,0,0
1282046,Molecular dynamics simulation to investigate the orientation effects on nanoscale cutting of single crystal copper,2018,A Sharma and D Datta and R Balasubramaniam,153,Computational Materials Science,,241-250,Elsevier,The present study investigates the effect of six different crystal orientations on the nanoscale cutting operation carried out on single crystal copper (Cu) at various ratios of uncut chip thickness (a) to cutting edge radius (r). The study is focused on various aspects of cutting operation which include the material deformation mechanism. subsurface deformation. cutting forces. specific cutting energy. ploughing effect and surface roughness. Molecular dynamics simulation (MDS) was performed for the six orientations at five different a/r ratios varying from 0.1 to 2. The MDS results reveal that the material removal and shear deformation mechanisms are distinct for different crystal orientations.< 1 1 0> is the slip direction along which the dislocations propagate predominantly. Maximum material removal occurs for the (0 0 1)[1¯ 1 0] orientation which is 45% higher than its minimum counterpart in the (1 1 1)[1 1¯ 0] crystal …,True,uO0QH0YAAAAJ:cqSrFCEPAw0C,24,https://www.sciencedirect.com/science/article/pii/S0927025618304300,18105751638618428306,/scholar?cites=18105751638618428306,,,,0,0,0
1282047,Blockchain-based secured traceability system for textile and clothing supply chain,2018,Tarun Kumar Agrawal and Ajay Sharma and Vijay Kumar,,,,197-208,Springer. Singapore,Blockchain has emerged as a prominent and reliable solution that can enable and ensure secure information sharing over wide area networks. In an era of digitalisation. blockchain technology is finding wide applications in multiple fields including implementing traceability in the supply chain. In this direction. this chapter explores its potential application in implementing a blockchain-based traceability system for textile and clothing (T&C) supply chain. It examines the necessity and concept of a traceability system. followed by enlisting advantages of blockchain technology for implementing traceability. Further. a case-based example has been used to explain blockchain application in implementing traceability in T&C supply chain. Finally. it mentions the challenges and limitations of such blockchain-based traceability system that can be addressed through further research. ,True,uO0QH0YAAAAJ:pmngxq2mVgoC,24,https://link.springer.com/chapter/10.1007/978-981-13-0080-6_10,3492762727967389910,/scholar?cites=3492762727967389910,,,,0,0,0
1282048,1064 nm acoustic resolution photoacoustic microscopy,2019,Vijitha Periyasamy and Nandan Das and Arunima Sharma and Manojit Pramanik,12,Journal of biophotonics,5,e201800357,WILEY‐VCH Verlag GmbH & Co. KGaA,Photoacoustic imaging is a noninvasive imaging technique having the advantages of high‐optical contrast and good acoustic resolution at improved imaging depths. Light transport in biological tissues is mainly characterized by strong optical scattering and absorption. Photoacoustic microscopy is capable of achieving high‐resolution images at greater depth compared to conventional optical microscopy methods. In this work. we have developed a high‐resolution. acoustic resolution photoacoustic microscopy (AR‐PAM) system in the near infra‐red (NIR) window II (NIR‐II. eg. 1064 nm) for deep tissue imaging. Higher imaging depth is achieved as the tissue scattering at 1064 nm is lesser compared to visible or near infrared window‐I (NIR‐I). Our developed system can provide a lateral resolution of 130 μm. axial resolution of 57 μm. and image up to 11 mm deep in biological tissues. This 1064‐AR‐PAM …,True,uO0QH0YAAAAJ:279hWsFo9KEC,20,https://onlinelibrary.wiley.com/doi/abs/10.1002/jbio.201800357,651677470508317605,/scholar?cites=651677470508317605,,,https://aran.library.nuigalway.ie/bitstream/handle/10379/15252/1064ARPAM_jbio_r1_final.pdf?sequence=1&isAllowed=n,0,0,0
1282049,Multidimensional relationships of herbicides with insect-crop food webs,2018,Anamika Sharma and Prashant Jha and Gadi VP Reddy,643,,,1522-1532,Elsevier,Controlling weeds is critical for improving the yield and quality of crops. Herbicides are the most commonly applied pesticides in agro-ecosystems. Herbicides affect insects directly as contact damage and indirectly by influencing food supplies. The innate susceptibility. life stages. and mode of feeding of insects can affect the herbicide–insect interaction. Interaction of herbicides with insect pest and beneficial insects is mainly indirect and absence of weeds either can reduce the insect population or causes switching of host plant and hence can also increase the population. The direct effect of herbicides depends on carrier or surfactant used. Presence of herbicides also provides surfactant to insecticides and increases impact of insecticides. At present. most reports on impact of herbicides indicate alterations in insect survival or egg production due to increase or decrease in host plant population as an indirect affect …,True,uO0QH0YAAAAJ:tC_cyO4PokcC,20,https://www.sciencedirect.com/science/article/pii/S004896971832388X,7500508138889279672,/scholar?cites=7500508138889279672,,,https://www.sciencedirect.com/science/article/am/pii/S004896971832388X,0,0,0
1282050,Switchable Acoustic and Optical Resolution Photoacoustic Microscopy for in vivo small-animal blood vasculature imaging,2017,Mohesh Moothanchery and Arunima Sharma and Manojit Pramanik,,Journal of visualized experiments: JoVE,124,,MyJoVE Corporation,Photoacoustic microscopy (PAM) is a fast-growing invivo imaging modality that combines both optics and ultrasound. providing penetration beyond the optical mean free path (~ 1 mm in skin) with high resolution. By combining optical absorption contrast with the high spatial resolution of ultrasound in a single modality. this technique can penetrate deep tissues. Photoacoustic microscopy systems can have either a low acoustic resolution and probe deeply or a high optical resolution and probe shallowly. It is challenging to achieve high spatial resolution and large depth penetration with a single system. This work presents an AR-OR-PAM system capable of both high-resolution imaging at shallow depths and low-resolution deep-tissue imaging of the same sample in vivo. A lateral resolution of 4 µm with 1.4 mm imaging depth using optical focusing and a lateral resolution of 45 µm with 7.8 mm imaging depth using …,True,uO0QH0YAAAAJ:1DepXQxl6QcC,20,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5608526/,3724350543897836892,/scholar?cites=3724350543897836892,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5608526/,0,0,0
1282051,Measurement of associated Z+ charm production in proton–proton collisions at  s= 8 TeV,2018,Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and Federico Ambrogi and Ece Asilar and Thomas Bergauer and Johannes Brandstetter and Erica Brondolin and Marko Dragicevic and Janos Erö and Martin Flechl and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Johannes Grossmann and N Hörmann and Josef Hrubec and Manfred Jeitler and Axel König and Ilse Krätschmer and Dietrich Liko and Thomas Madlener and Takashi Matsushita and Ivan Mikulec and Elias Pree and Dinyar Rabady and Navid Rad and Herbert Rohringer and Jochen Schieck and Markus Spanring and Daniel Spitzbart and Josef Strauss and Wolfgang Waltenberger and Johannes Wittmann and C-E Wulz and Mateusz Zarucki and Vladimir Chekhovsky and Vladimir Mossolov and J Suarez Gonzalez and Nikolai Shumeiko and Eddi A De Wolf and Xavier Janssen and Jasper Lauwers and Merijn Van De Klundert and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and S Abu Zeid and Freya Blekman and Jorgen D’Hondt and Isabelle De Bruyn and Jarne De Clercq and Kevin Deroover and Giannis Flouris and Steven Lowette and Seth Moortgat and Lieselotte Moreels and Annik Olbrechts and Quentin Python and Kirill Skovpen and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Isis Van Parijs and Hugues Brun and Barbara Clerbaux and Gilles De Lentdecker and Hugo Delannoy and Giuseppe Fasanella and Laurent Favart and Reza Goldouzian and Anastasia Grebenyuk and Georgia Karapostoli and Thomas Lenzi and Jelena Luetic and Thierry Maerschalk and Andrey Marinov and Aidan Randle-Conde and Tomislav Seva and C Vander Velde and P Vanlaer and D Vannerom and R Yonamine and F Zenoni and F Zhang and Anna Cimmino and Tom Cornelis and Didar Dobur and Alexis Fagot and Muhammad Gul and Illia Khvastunov and D Poyraz and Sinem Salva and R Schöfbeck and Michael Tytgat and Ward Van Driessche and Willem Verbeke and Nikolaos Zaganidis and H Bakhshiansohi and O Bondu and S Brochet and G Bruno and A Caudron and S De Visscher and C Delaere and M Delcourt and B Francois and A Giammanco and A Jafari and M Komm and G Krintiras and V Lemaitre and A Magitteri and A Mertens and M Musich and K Piotrzkowski and L Quertenmont and M Vidal Marono and S Wertz and N Beliy and WL Aldá Júnior and FL Alves and GA Alves and L Brito and C Hensel and A Moraes and ME Pol and P Rebello Teles and E Belchior Batista Das Chagas and W Carvalho and J Chinellato and A Custódio and EM Da Costa and GG Da Silveira and D De Jesus Damiao and S Fonseca De Souza and LM Huertas Guativa and H Malbouisson and C Mora Herrera and L Mundim and H Nogima and A Santoro and A Sznajder and EJ Tonelli Manganote and F Torres Da Silva De Araujo and A Vilela Pereira and S Ahuja and CA Bernardes and TR Fernandez Perez Tomei,78,The European Physical Journal C,4,1-34,Springer Berlin Heidelberg,A study of the associated production of a boson and a charm quark jet (). and a comparison to production with a quark jet (). in collisions at a centre-of-mass energy of 8 are presented. The analysis uses a data sample corresponding to an integrated luminosity of 19.7. collected with the CMS detector at the CERN LHC. The boson candidates are identified through their decays into pairs of electrons or muons. Jets originating from heavy flavour quarks are identified using semileptonic decays of or flavoured hadrons and hadronic decays of charm hadrons. The measurements are performed in the kinematic region with two leptons with... and heavy flavour jets with and. The production cross section is measured to be\(\sigma (\mathrm {p}\mathrm {p}\rightarrow\mathrm {Z}+\mathrm {c}+ X)\mathcal {B}(\mathrm {Z}\rightarrow\ell^+\ell^-)= 8.8\pm 0.5\.\text {(stat …,True,uO0QH0YAAAAJ:S8f_GPVCfywC,19,https://link.springer.com/article/10.1140%252Fepjc%252Fs10052-018-5752-x,10195522790350070116,/scholar?cites=10195522790350070116,,,https://link.springer.com/article/10.1140%252Fepjc%252Fs10052-018-5752-x,0,0,0
1282052,Roberta: A robustly optimized bert pretraining approach,2019,Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov,,arXiv preprint arXiv:1907.11692,,,,Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive. often done on private datasets of different sizes. and. as we will show. hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al.. 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained. and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE. RACE and SQuAD. These results highlight the importance of previously overlooked design choices. and raise questions about the source of recently reported improvements. We release our models and code.,True,CRbM_P4AAAAJ:qjMakFHDy7sC,3005,https://arxiv.org/abs/1907.11692,803096065579965194,/scholar?cites=803096065579965194,,,https://arxiv.org/pdf/1907.11692,0,0,0
1282053,Bart: Denoising sequence-to-sequence pre-training for natural language generation. translation. and comprehension,2019,Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer,,https://www.aclweb.org/anthology/2020.acl-main.703/,,,,We present BART. a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function. and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which. despite its simplicity. can be seen as generalizing BERT (due to the bidirectional encoder). GPT (with the left-to-right decoder). and many other more recent pretraining schemes. We evaluate a number of noising approaches. finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme. where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD. achieves new state-of-the-art results on a range of abstractive dialogue. question answering. and summarization tasks. with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation. with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework. to better measure which factors most influence end-task performance.,True,CRbM_P4AAAAJ:zYLM7Y9cAGgC,637,https://arxiv.org/abs/1910.13461,10589398302527104823,/scholar?cites=10589398302527104823,,,https://arxiv.org/pdf/1910.13461,0,0,0
1282054,Unsupervised cross-lingual representation learning at scale,2019,Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzmán and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov,,https://www.aclweb.org/anthology/2020.acl-main.747.pdf,,,,This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages. using more than two terabytes of filtered CommonCrawl data. Our model. dubbed XLM-R. significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks. including+ 14.6% average accuracy on XNLI.+ 13% average F1 score on MLQA. and+ 2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages. improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains. including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally. we show. for the first time. the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code. data and models publicly available.,True,CRbM_P4AAAAJ:Tyk-4Ss8FVUC,532,https://arxiv.org/abs/1911.02116,15150111566933105226,/scholar?cites=15150111566933105226,,,https://arxiv.org/pdf/1911.02116,0,0,0
1282055,Multilingual denoising pre-training for neural machine translation,2020,Yinhan Liu and Jiatao Gu and Naman Goyal and Xian Li and Sergey Edunov and Marjan Ghazvininejad and Mike Lewis and Luke Zettlemoyer,8,Transactions of the Association for Computational Linguistics,,726-742,MIT Press,This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation (MT) tasks. We present mBART—a sequence-to-sequence denoising auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective (Lewis et al.. ). mBART is the first method for pre-training a complete sequence-to-sequence model by denoising full texts in multiple languages. whereas previous approaches have focused only on the encoder. decoder. or reconstructing parts of the text. Pre-training a complete model allows it to be directly fine-tuned for supervised (both sentence-level and document-level) and unsupervised machine translation. with no task- specific modifications. We demonstrate that adding mBART initialization produces performance gains in all but the highest-resource settings. including up to 12 BLEU …,True,CRbM_P4AAAAJ:YsMSGLbcyi4C,119,https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00343,18326940436379840472,/scholar?cites=18326940436379840472,,,https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00343,0,0,0
1282056,Retrieval-augmented generation for knowledge-intensive nlp tasks,2020,Patrick Lewis and Ethan Perez and Aleksandara Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela,,https://papers.nips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html,,,,Large pre-trained language models have been shown to store factual knowledge in their parameters. and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However. their ability to access and precisely manipulate knowledge is still limited. and hence on knowledge-intensive tasks. their performance lags behind task-specific architectures. Additionally. providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue. but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG)--models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia. accessed with a pre-trained neural retriever. We compare two RAG formulations. one which conditions on the same retrieved passages across the whole generated sequence. the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks. outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks. we find that RAG models generate more specific. diverse and factual language than a state-of-the-art parametric-only seq2seq …,True,CRbM_P4AAAAJ:ufrVoPGSRksC,75,https://arxiv.org/abs/2005.11401,10679876450978666441,/scholar?cites=10679876450978666441,,,https://arxiv.org/pdf/2005.11401,0,0,0
1282057,Recipes for building an open-domain chatbot,2020,Stephen Roller and Emily Dinan and Naman Goyal and Da Ju and Mary Williamson and Yinhan Liu and Jing Xu and Myle Ott and Kurt Shuster and Eric M Smith and Y-Lan Boureau and Jason Weston,,EACL 2020,,,,Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results. we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners. and displaying knowledge. empathy and personality appropriately. while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M. 2.7 B and 9.4 B parameter models. and make our models and code publicly available under the collective name Blender. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.,True,CRbM_P4AAAAJ:eQOLeE2rZwMC,75,https://arxiv.org/abs/2004.13637,14419775353832230497,/scholar?cites=14419775353832230497,,,https://arxiv.org/pdf/2004.13637,0,0,0
1282058,The social dynamics of language change in online networks,2016,Rahul Goel and Sandeep Soni and Naman Goyal and John Paparrizos and Hanna Wallach and Fernando Diaz and Jacob Eisenstein,,,,41-57,Springer. Cham,Language change is a complex social phenomenon. revealing pathways of communication and sociocultural influence. But. while language change has long been a topic of study in sociolinguistics. traditional linguistic research methods rely on circumstantial evidence. estimating the direction of change from differences between older and younger speakers. In this paper. we use a data set of several million Twitter users to track language changes in progress. First. we show that language change can be viewed as a form of social influence: we observe complex contagion for phonetic spellings and “netspeak” abbreviations (e.g.. lol). but not for older dialect markers from spoken language. Next. we test whether specific types of social network connections are more influential than others. using a parametric Hawkes process model. We find that tie strength plays an important role: densely embedded social ties …,True,CRbM_P4AAAAJ:u5HHmVD_uO8C,35,https://link.springer.com/chapter/10.1007/978-3-319-47880-7_3,1327807202954623713,/scholar?cites=1327807202954623713,,,https://arxiv.org/pdf/1609.02075,0,0,0
1282059,A joint model of rhetorical discourse structure and summarization,2016,Naman Goyal and Jacob Eisenstein,,,,25-34,,In Rhetorical Structure Theory. discourse units participate in asymmetric relationships. with one element acting as the nucleus and the other as the satellite. In the resulting tree-like nuclearity structure. the importance of each discourse unit can be measured by the number of relations in which it acts as the nucleus or as the satellite. Existing approaches to automatically parsing such structures suffer from two problems: they employ local inference techniques that do not capture documentlevel structural regularities. and they rely on annotated training data. which is expensive to obtain at the discourse level. We investigate the SampleRank structure learning algorithm as a potential solution to both problems. SampleRank allows us to incorporate arbitrary document-level features in a global stochastic inference algorithm. Furthermore. it enables the training of a joint model of discourse structure and summarization. which can be learned from document-level summaries alone. without discourse-level supervision. We obtain mixed results in the fully supervised case. and negative results for the joint model of discourse structure and summarization.,True,CRbM_P4AAAAJ:d1gkVwhDpl0C,13,https://www.aclweb.org/anthology/W16-5903.pdf,10977227424170695425,/scholar?cites=10977227424170695425,,,https://www.aclweb.org/anthology/W16-5903.pdf,0,0,0
1282060,Learningtoquestion at semeval 2017 task 3: Ranking similar questions by learning to rank using rich features,2017,Naman Goyal,,,,310-314,,This paper describes our official entry LearningToQuestion for SemEval 2017 task 3 community question answer. subtask B. The objective is to rerank questions obtained in web forum as per their similarity to original question. Our system uses pairwise learning to rank methods on rich set of hand designed and representation learning features. We use various semantic features that help our system to achieve promising results on the task. The system achieved second highest results on official metrics MAP and good results on other search metrics.,True,CRbM_P4AAAAJ:9yKSN-GCB0IC,11,https://www.aclweb.org/anthology/S17-2050.pdf,13868916707134029419,/scholar?cites=13868916707134029419,,,https://www.aclweb.org/anthology/S17-2050.pdf,0,0,0
1282061,Beyond english-centric multilingual machine translation,2020,Angela Fan and Shruti Bhosale and Holger Schwenk and Zhiyi Ma and Ahmed El-Kishky and Siddharth Goyal and Mandeep Baines and Onur Celebi and Guillaume Wenzek and Vishrav Chaudhary and Naman Goyal and Tom Birch and Vitaliy Liptchinsky and Sergey Edunov and Edouard Grave and Michael Auli and Armand Joulin,,arXiv preprint arXiv:2010.11125,,,,Existing work in translation demonstrated the potential of massively multilingual machine translation by training a single model able to translate between any pair of languages. However. much of this work is English-Centric by training only on data which was translated from or to English. While this is supported by large sources of training data. it does not reflect translation needs worldwide. In this work. we create a true Many-to-Many multilingual translation model that can translate directly between any pair of 100 languages. We build and open source a training dataset that covers thousands of language directions with supervised data. created through large-scale mining. Then. we explore how to effectively increase model capacity through a combination of dense scaling and language-specific sparse parameters to create high quality models. Our focus on non-English-Centric models brings gains of more than 10 BLEU when directly translating between non-English directions while performing competitively to the best single systems of WMT. We open-source our scripts so that others may reproduce the data. evaluation. and final M2M-100 model.,True,CRbM_P4AAAAJ:UebtZRa9Y70C,10,https://arxiv.org/abs/2010.11125,13050598717056970101,/scholar?cites=13050598717056970101,,,https://arxiv.org/pdf/2010.11125,0,0,0
1282062,Better fine-tuning by reducing representational collapse,2020,Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta,,ICLR 2021,,,,Although widely adopted. existing approaches for fine-tuning pre-trained language models have been shown to be unstable across hyper-parameter settings. motivating recent work on trust region methods. In this paper. we present a simplified and efficient method rooted in trust region theory that replaces previously used adversarial objectives with parametric noise (sampling from either a normal or uniform distribution). thereby discouraging representation change during fine-tuning when possible without hurting performance. We also introduce a new analysis to motivate the use of trust region methods more generally. by studying representational collapse; the degradation of generalizable representations from pre-trained models as they are fine-tuned for a specific end task. Extensive experiments show that our fine-tuning method matches or exceeds the performance of previous trust region methods on a range of understanding and generation tasks (including DailyMail/CNN. Gigaword. Reddit TIFU. and the GLUE benchmark). while also being much faster. We also show that it is less prone to representation collapse; the pre-trained models maintain more generalizable representations every time they are fine-tuned.,True,CRbM_P4AAAAJ:LkGwnXOMwfcC,10,https://arxiv.org/abs/2008.03156,17258197096487538069,/scholar?cites=17258197096487538069,,,https://arxiv.org/pdf/2008.03156,0,0,0
1282063,A comparative study on multivariate mathematical morphology,2007,Erchan Aptoula and Sébastien Lefèvre,40,Pattern Recognition,11,2914-2929,Pergamon,The successful application of univariate morphological operators on several domains. along with the increasing need for processing the plethora of available multivalued images. have been the main motives behind the efforts concentrated on extending the mathematical morphology framework to multivariate data. The few theoretical requirements of this extension. consisting primarily of a ranking scheme as well as extrema operators for vectorial data. have led to numerous suggestions with diverse properties. However. none of them has yet been widely accepted. Furthermore. the comparison research work in the current literature. evaluating the results obtained from these approaches. is either outdated or limited to a particular application domain. In this paper. a comprehensive review of the proposed multivariate morphological frameworks is provided. In particular. they are examined mainly with respect to their …,True,C_8NI7IAAAAJ:u5HHmVD_uO8C,308,https://www.sciencedirect.com/science/article/pii/S0031320307000891,8266220151308148699,/scholar?cites=8266220151308148699,,,https://hal.archives-ouvertes.fr/hal-00512660/document,0,0,0
1282064,Semantic Segmentation of Earth Observation Data Using Multimodal and Multi-scale Deep Networks,2016,Nicolas Audebert and Bertrand Le Saux and Sébastien Lefèvre,,,,,,This work investigates the use of deep fully convolutional neural networks (DFCNN) for pixel-wise scene labeling of Earth Observation images. Especially. we train a variant of the SegNet architecture on remote sensing data over an urban area and study different strategies for performing accurate semantic segmentation. Our contributions are the following: (1) we transfer efficiently a DFCNN from generic everyday images to remote sensing images; (2) we introduce a multi-kernel convolutional layer for fast aggregation of predictions at multiple scales; (3) we perform data fusion from heterogeneous sensors (optical and laser) using residual correction. Our framework improves state-of-the-art accuracy on the ISPRS Vaihingen 2D Semantic Labeling dataset.,True,C_8NI7IAAAAJ:fQNAKQ3IYiAC,258,https://link.springer.com/chapter/10.1007/978-3-319-54181-5_12,15205541758176285177,/scholar?cites=15205541758176285177,,,https://arxiv.org/pdf/1609.06846,0,0,0
1282065,Beyond RGB: Very high resolution urban remote sensing with multimodal deep networks,2018,Nicolas Audebert and Bertrand Le Saux and Sébastien Lefèvre,140,ISPRS Journal of Photogrammetry and Remote Sensing,,20-32,Elsevier,In this work. we investigate various methods to deal with semantic labeling of very high resolution multi-modal remote sensing data. Especially. we study how deep fully convolutional networks can be adapted to deal with multi-modal and multi-scale remote sensing data for semantic labeling. Our contributions are threefold: (a) we present an efficient multi-scale approach to leverage both a large spatial context and the high resolution data. (b) we investigate early and late fusion of Lidar and multispectral data. (c) we validate our methods on two public datasets with state-of-the-art results. Our results indicate that late fusion make it possible to recover errors steaming from ambiguous data. while early fusion allows for better joint-feature learning but at the cost of higher sensitivity to missing data.,True,C_8NI7IAAAAJ:eMMeJKvmdy0C,221,https://www.sciencedirect.com/science/article/pii/S0924271617301818,13117715021201987869,/scholar?cites=13117715021201987869,,,https://arxiv.org/pdf/1711.08681,0,0,0
1282066,Segment-before-Detect: Vehicle Detection and Classification through Semantic Segmentation of Aerial Images,2017,Nicolas Audebert and Bertrand Le Saux and Sébastien Lefèvre,9,Remote Sensing,4,368,Multidisciplinary Digital Publishing Institute,Like computer vision before. remote sensing has been radically changed by the introduction of deep learning and. more notably. Convolution Neural Networks. Land cover classification. object detection and scene understanding in aerial images rely more and more on deep networks to achieve new state-of-the-art results. Recent architectures such as Fully Convolutional Networks can even produce pixel level annotations for semantic mapping. In this work. we present a deep-learning based segment-before-detect method for segmentation and subsequent detection and classification of several varieties of wheeled vehicles in high resolution remote sensing images. This allows us to investigate object detection and classification on a complex dataset made up of visually similar classes. and to demonstrate the relevance of such a subclass modeling approach. Especially. we want to show that deep learning is also suitable for object-oriented analysis of Earth Observation data as effective object detection can be obtained as a byproduct of accurate semantic segmentation. First. we train a deep fully convolutional network on the ISPRS Potsdam and the NZAM/ONERA Christchurch datasets and show how the learnt semantic maps can be used to extract precise segmentation of vehicles. Then. we show that those maps are accurate enough to perform vehicle detection by simple connected component extraction. This allows us to study the repartition of vehicles in the city. Finally. we train a Convolutional Neural Network to perform vehicle classification on the VEDAI dataset. and transfer its knowledge to classify the individual vehicle instances that we …,True,C_8NI7IAAAAJ:kRWSkSYxWN8C,151,https://www.mdpi.com/2072-4292/9/4/368,9936163373119438668,/scholar?cites=9936163373119438668,,,https://www.mdpi.com/2072-4292/9/4/368/pdf,0,0,0
1282067,A review of real-time segmentation of uncompressed video sequences for content-based search and retrieval,2003,Sébastien Lefèvre and Jérôme Holler and Nicole Vincent,9,Real-Time Imaging,1,73-98,Academic Press,We present in this paper a review of methods for segmentation of uncompressed video sequences. Video segmentation is usually performed in the temporal domain by shot change detection. In case of real-time segmentation. computational complexity is one of the criteria which has to be taken into account when comparing different methods. When dealing with uncompressed video sequences. this criterion is even more significant. However. previous published reviews did not involve complexity criterion when comparing shot change detection methods. Only recognition rate and ability to classify detected shot changes were considered. So contrary to previous reviews. we give here the complexity of most of the described methods. We review in this paper an extensive set of methods presented in the literature and classify them in several parts. depending on the information used to detect shot changes. The earliest …,True,C_8NI7IAAAAJ:u-x6o8ySG0sC,121,https://www.sciencedirect.com/science/article/pii/S1077201402001158,6512186957250237112,/scholar?cites=6512186957250237112,,,https://hal.archives-ouvertes.fr/hal-00512620/file/rti.pdf,0,0,0
1282068,On lexicographical ordering in multivariate mathematical morphology,2008,Erchan Aptoula and Sébastien Lefèvre,29,Pattern Recognition Letters,2,109-118,North-Holland,Since mathematical morphology is based on complete lattice theory. a vector ordering method becomes indispensable for its extension to multivariate images. Among the several approaches developed with this purpose. lexicographical orderings are by far the most frequent. as they possess certain desirable theoretical properties. However. their main drawback consists of the excessive priority attributed to the first vector dimension. In this paper. the existing solutions to solving this problem are recalled and two new approaches are presented. First. a generalisation of α-modulus lexicographical ordering is introduced. making it possible to accommodate any quantisation function. Additionally. an input specific method is suggested. based on the use of a marker image. Comparative application results on colour noise reduction and texture classification are also provided.,True,C_8NI7IAAAAJ:Y0pCki6q_DkC,95,https://www.sciencedirect.com/science/article/pii/S0167865507002899,6112188412221783416,/scholar?cites=6112188412221783416,,,https://hal.archives-ouvertes.fr/hal-00512667/file/prl2008.pdf,0,0,0
1282069,Deep Learning for Classification of Hyperspectral Data: A Comparative Review,2019,Nicolas Audebert and Bertrand Le Saux and Sébastien Lefèvre,7,IEEE Geoscience and Remote Sensing Magazine,2,159-173,IEEE,In recent years. deep-learning techniques revolutionized the way remote sensing data are processed. The classification of hyperspectral data is no exception to the rule. but it has intrinsic specificities that make the application of deep learning less straightforward than with other optical data. This article presents the state of the art of previous machine-learning approaches. reviews the various deep learning approaches currently proposed for hyperspectral classification. and identifies the problems and difficulties that arise in the implementation of deep neural networks for this task. In particular. the issues of spatial and spectral resolution. data volume. and transfer of models from multimedia images to hyperspectral data are addressed. Additionally. a comparative study of various families of network architectures is provided. and a software toolbox is publicly released to allow experimenting with these methods (https …,True,C_8NI7IAAAAJ:j8SEvjWlNXcC,93,https://ieeexplore.ieee.org/abstract/document/8738045/,3465575068141499997,/scholar?cites=3465575068141499997,,,https://arxiv.org/pdf/1904.10674,0,0,0
1282070,Automatic building extraction in VHR images using advanced morphological operators,2007,Sébastien Lefèvre and Jonathan Weber and David Sheeren,,,,1-5,IEEE,This paper presents a new method for buildings extraction in Very High Resolution (VHR) remotely sensed images based on binary mathematical morphology (MM) operators. The proposed approach involves several advanced morphological operators among which an adaptive hit-or-miss transform with varying sizes and shapes of the structuring element and a bidimensional granulometry intended to determine the optimal filtering parameters automatically. A clustering-based approach for image binarization is also introduced. This one avoids an empirical thresholding of input panchromatic images. Experiments made on a Quickbird VHR-image show the effectiveness of the method.,True,C_8NI7IAAAAJ:UeHWp8X0CEIC,91,https://ieeexplore.ieee.org/abstract/document/4234424/,12229648055853735456,/scholar?cites=12229648055853735456,,,https://hal.archives-ouvertes.fr/hal-00516082/document,0,0,0
1282071,Comparative study with new accuracy metrics for target volume contouring in PET image guided radiation therapy,2012,Tony Shepherd and Mika Teras and Reinhard R Beichel and Ronald Boellaard and Michel Bruynooghe and Volker Dicken and Mark J Gooding and Peter J Julyan and John A Lee and Sébastien Lefèvre and Michael Mix and Valery Naranjo and Xiaodong Wu and Habib Zaidi and Ziming Zeng and Heikki Minn,31,IEEE transactions on medical imaging,11,2006-2024,IEEE,The impact of positron emission tomography (PET) on radiation therapy is held back by poor methods of defining functional volumes of interest. Many new software tools are being proposed for contouring target volumes but the different approaches are not adequately compared and their accuracy is poorly evaluated due to the ill-definition of ground truth. This paper compares the largest cohort to date of established. emerging and proposed PET contouring methods. in terms of accuracy and variability. We emphasize spatial accuracy and present a new metric that addresses the lack of unique ground truth. Thirty methods are used at 13 different institutions to contour functional volumes of interest in clinical PET/CT and a custom-built PET phantom representing typical problems in image guided radiotherapy. Contouring methods are grouped according to algorithmic type. level of interactivity and how they exploit …,True,C_8NI7IAAAAJ:u_35RYKgDlwC,86,https://ieeexplore.ieee.org/abstract/document/6211429/,16459525077649373636,/scholar?cites=16459525077649373636,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570440/,0,0,0
1282072,Supervised image segmentation using watershed transform. fuzzy classification and evolutionary computation,2010,Sébastien Derivaux and Germain Forestier and Cédric Wemmert and Sébastien Lefèvre,31,Pattern Recognition Letters,15,2364-2374,North-Holland,Automatic image interpretation is often achieved by first performing a segmentation of the image (i.e.. gathering neighbouring pixels into homogeneous regions) and then applying a supervised region-based classification. In such a process. the quality of the segmentation step is of great importance in the final classified result. Nevertheless. whereas the classification step takes advantage from some prior knowledge such as learning sample pixels. the segmentation step rarely does. In this paper. we propose to involve such samples through machine learning procedures to improve the segmentation process. More precisely. we consider the watershed transform segmentation algorithm. and rely on both a fuzzy supervised classification procedure and a genetic algorithm in order to respectively build the elevation map used in the watershed paradigm and tune segmentation parameters. We also propose new criteria for …,True,C_8NI7IAAAAJ:ULOm3_A8WrAC,77,https://www.sciencedirect.com/science/article/pii/S0167865510002308,12771995191917039893,/scholar?cites=12771995191917039893,,,https://hal.archives-ouvertes.fr/docs/00/51/27/49/PDF/prl.pdf,0,0,0
1282073,Joint learning from Earth Observation and OpenStreetMap data to get faster better semantic maps,2017,Nicolas Audebert and Bertrand Le Saux and Sébastien Lefèvre,,,,,,We investigate the use of OSM data for semantic labeling of EO images. Deep neural networks have been used in the past for remote sensing data classification from various sensors. including multispectral. hyperspectral. Radar and Lidar data. However. OSM is an abundant data source that has already been used as ground truth data. but rarely exploited as an input information layer. We study different use cases and deep network architectures to leverage this OSM data for semantic labeling of aerial and satellite images. Especially. we look into fusion based architectures and coarse-to-fine segmentation to include the OSM layer into multispectral-based deep fully convolutional networks. We illustrate how these methods can be used successfully on two public datasets: the ISPRS Potsdam and the DFC2017. We show that OSM data can efficiently be integrated into the vision-based deep learning models and that it significantly improves both the accuracy performance and the convergence.,True,C_8NI7IAAAAJ:5ugPr518TE4C,73,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w18/html/Audebert_Joint_Learning_From_CVPR_2017_paper.html,18248241177902230629,/scholar?cites=18248241177902230629,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w18/papers/Audebert_Joint_Learning_From_CVPR_2017_paper.pdf,0,0,0
1282074,Adding sense to the Internet of Things: An architecture framework for Smart Object systems,2012,Tomás Sánchez López and Damith C Ranasinghe and Mark Harrison and Duncan McFarlane,16,Personal and Ubiquitous Computing,3,291-308,Springer Science+ Business Media. Van,The Internet of Things (IoT) concept is being widely presented as the next revolution toward massively distributed information. where any real-world object can automatically participate in the Internet and thus be globally discovered and queried. Despite the consensus on the great potential of the concept and the significant progress in a number of enabling technologies. there is a general lack of an integrated vision on how to realize it. This paper examines the technologies that will be fundamental for realizing the IoT and proposes an architecture that integrates them into a single platform. The architecture introduces the use of the Smart Object framework to encapsulate radio-frequency identification (RFID). sensor technologies. embedded object logic. object ad-hoc networking. and Internet-based information infrastructure. We evaluate the architecture against a number of energy-based performance …,True,oGyoeV0AAAAJ:D03iK_w7-QYC,304,https://link.springer.com/content/pdf/10.1007/s00779-011-0399-8.pdf,5085329445446237757,/scholar?cites=5085329445446237757,,,https://www.researchgate.net/profile/Damith_Ranasinghe2/publication/220141406_Adding_sense_to_the_Internet_of_Things_-_An_architecture_framework_for_Smart_Object_systems/links/5448dcfd0cf22b3c14e33844.pdf,0,0,0
1282075,Taxonomy. technology and applications of smart objects,2011,Tomás Sánchez López and Damith Chinthana Ranasinghe and Bela Patkai and Duncan McFarlane,13,Information Systems Frontiers,2,281-300,Springer US,Deployment of embedded technologies is increasingly being examined in industrial supply chains as a means for improving efficiency through greater control over purchase orders. inventory and product related information. Central to this development has been the advent of technologies such as bar codes. Radio Frequency Identification (RFID) systems. and wireless sensors which when attached to a product. form part of the product’s embedded systems infrastructure. The increasing integration of these technologies dramatically contributes to the evolving notion of a “smart product”. a product which is capable of incorporating itself into both physical and information environments. The future of this revolution in objects equipped with smart embedded technologies is one in which objects can not only identify themselves. but can also sense and store their condition. communicate with other objects and …,True,oGyoeV0AAAAJ:WF5omc3nYNoC,183,https://link.springer.com/content/pdf/10.1007/s10796-009-9218-4.pdf,17801052666403519939,/scholar?cites=17801052666403519939,,,http://autoidlab.cs.adelaide.edu.au/sites/default/files/publications/papers/art%253A10.1007%252Fs10796-009-9218-4.pdf,0,0,0
1282076,Networked RFID Systems and Lightweight Cryptography: Raising Barriers to Product Counterfeiting,2008,Peter H Cole and Damith C Ranasinghe,,,,,Springer,,True,oGyoeV0AAAAJ:fPk4N6BV_jEC,145,,3079375606217743483,/scholar?cites=3079375606217743483,,,,0,0,0
1282077,Low-Cost RFID Systems: Confronting Security and Privacy,2005,Damith C Ranasinghe and Daniel W Engels and Peter H Cole,1,WHITE PAPER SERIES/EDITION,,,Auto-ID Labs,In the implementation of Radio Frequency Identification (RFID) systems concerns have been raised regarding information security and violations of end-user privacy. There is a large collection of literature available on efficient and inexpensive cryptographic engines. but they are still extravagant solutions for low cost RFID systems. Security and privacy provided by low cost RFID is both directly and indirectly limited by a number of factors that are unique to low cost RFID. This paper examines security and privacy issues regarding RFID and presents the challenges that arise in view of the unique environment presented by low cost RFID systems.,True,oGyoeV0AAAAJ:u5HHmVD_uO8C,126,http://autoidlab.cs.adelaide.edu.au/sites/default/files/publications/papers/AUTOIDLABS-WP-SWNET-013.pdf,11570662423788972424,/scholar?cites=11570662423788972424,,,http://autoidlab.cs.adelaide.edu.au/sites/default/files/publications/papers/AUTOIDLABS-WP-SWNET-013.pdf,0,0,0
1282078,Emerging physical unclonable functions with nanotechnology,2016,Yansong Gao and Damith C Ranasinghe and Said F Al-Sarawi and Omid Kavehei and Derek Abbott,4,IEEE access,,61-80,IEEE,Physical unclonable functions (PUFs) are increasingly used for authentication and identification applications as well as the cryptographic key generation. An important feature of a PUF is the reliance on minute random variations in the fabricated hardware to derive a trusted random key. Currently. most PUF designs focus on exploiting process variations intrinsic to the CMOS technology. In recent years. progress in emerging nanoelectronic devices has demonstrated an increase in variation as a consequence of scaling down to the nanoregion. To date. emerging PUFs with nanotechnology have not been fully established. but they are expected to emerge. Initial research in this area aims to provide security primitives for emerging integrated circuits with nanotechnology. In this paper. we review emerging nanotechnology-based PUFs.,True,oGyoeV0AAAAJ:tYavs44e6CUC,114,https://ieeexplore.ieee.org/abstract/document/7420781/,4472111399253983490,/scholar?cites=4472111399253983490,,,https://ieeexplore.ieee.org/iel7/6287639/7419931/07420781.pdf,0,0,0
1282079,STRIP: A defence against trojan attacks on deep neural networks,2019,Yansong Gao and Change Xu and Derui Wang and Shiping Chen and Damith C Ranasinghe and Surya Nepal,,,,113-125,,A recent trojan attack on deep neural network (DNN) models is one insidious variant of data poisoning attacks. Trojan attacks exploit an effective backdoor created in a DNN model by leveraging the difficulty in interpretability of the learned model to misclassify any inputs signed with the attacker's chosen trojan trigger. Since the trojan trigger is a secret guarded and exploited by the attacker. detecting such trojan inputs is a challenge. especially at run-time when models are in active operation. This work buildsSTR ongI ntentionalP erturbation (STRIP) based run-time trojan attack detection system and focuses on vision system. We intentionally perturb the incoming input. for instance by superimposing various image patterns. and observe the randomness of predicted classes for perturbed inputs from a given deployed model---malicious or benign. A low entropy in predicted classes violates the input-dependence …,True,oGyoeV0AAAAJ:uDGL6kOW6j0C,113,https://dl.acm.org/doi/abs/10.1145/3359789.3359790,7514776661877233139,/scholar?cites=7514776661877233139,,,https://arxiv.org/pdf/1902.06531,0,0,0
1282080,RFID opportunity analysis for leaner manufacturing,2010,Alexandra Brintrup and Damith C Ranasinghe and Duncan McFarlane,48,International Journal of Production Research,9,2745-2764,Taylor & Francis Group,Although RFID is seen by many as a revolutionary enabler of automated data capture. confusion still remains as to how manufacturing organisations can identify cost-effective opportunities for its use. Managers view promotional business case estimates as unjustified. simulation based analysis and analytical models as secondary modes of analysis. and case studies are scarce. Further. there is a lack of simple tools to understand how RFID can help to achieve a leaner manufacturing environment. after the use of which practitioners can be routed to grounded forms of analysis. The purpose of this paper is to provide and test such a toolset. which uses the seven Toyota Production System wastes as a template. In our approach. RFID technology is viewed as a vehicle to achieve leaner manufacturing through automated data collection. assurance of data dependencies. and improvements in production and inventory …,True,oGyoeV0AAAAJ:YsMSGLbcyi4C,102,https://www.tandfonline.com/doi/abs/10.1080/00207540903156517,11214416449583818182,/scholar?cites=11214416449583818182,,,https://hal.archives-ouvertes.fr/hal-00577972/file/PEER_stage2_10.1080%252F00207540903156517.pdf,0,0,0
1282081,Security and privacy: Modest proposals for low-cost RFID systems,2004,Damith C Ranasinghe and Daniel Engels and Peter Cole,,"Auto-ID Labs Research Workshop, Zurich, Switzerland",,,,Low cost Radio Frequency Identification (RFID) systems are increasingly being deployed in industry and commerce. These contactless devices have raised public concern regarding violation of privacy and information security. There is a growing need in the RFID community to discover and develop techniques and methods to overcome several problems posed by the above-mentioned concerns. This paper presents proposals on feasible security mechanisms for low cost RFID systems and analyses them from both security and privacy points of view.,True,oGyoeV0AAAAJ:u-x6o8ySG0sC,92,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.9559&rep=rep1&type=pdf,3479904047133900959,/scholar?cites=3479904047133900959,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.9559&rep=rep1&type=pdf,0,0,0
1282082,Sensor enabled wearable RFID technology for mitigating the risk of falls near beds,2013,Roberto L Shinmoto Torres and Damith C Ranasinghe and Qinfeng Shi and Alanson P Sample,,,,191-198,IEEE,The increasing ageing population around the world and the increased risk of falling among this demographic. challenges society and technology to find better ways to mitigate the occurrence of such costly and detrimental events as falls. The most common activity associated with falls is bed transfers; therefore. the most significant high risk activity. Several technological solutions exist for bed exiting detection using a variety of sensors which are attached to the body. bed or floor. However. lack of real life performance studies. technical limitations and acceptability are still key issues. In this research. we present and evaluate a novel method for mitigating the high falls risk associated with bed exits based on using an inexpensive. privacy preserving and passive sensor enabled RFID device. Our approach is based on a classification system built upon conditional random fields that requires no preprocessing of sensorial …,True,oGyoeV0AAAAJ:eflP2zaiRacC,79,https://ieeexplore.ieee.org/abstract/document/6548154/,5056880126388617095,/scholar?cites=5056880126388617095,,,http://autoidlab.cs.adelaide.edu.au/sites/default/files/publications/papers/06548154.pdf,0,0,0
1282083,Smart steel: new paradigms for the reuse of steel enabled by digital tracking and modelling,2015,David Ness and John Swift and Damith C Ranasinghe and Ke Xing and Veronica Soebarto and Mile Terziovski,98,Journal of Cleaner Production,,292-303,,When reconfigured into a cohesive system. a series of existing digital technologies may facilitate disassembly. take back and reuse of structural steel components. thereby improving resource efficiency and opening up new business paradigms. The paper examines whether Radio Frequency Identification (RFID) technology coupled with Building Information Modelling (BIM) may enable components and/or assemblies to be tracked and imported into virtual models for new buildings at the design stage. The addition of stress sensors to components. which provides the capability of quantifying the stress properties of steel over its working life. may also support best practice reuse of resources. The potential to improve resource efficiency in many areas of production and consumption. emerging from a novel combination of such technologies. is highlighted using a theoretical case study scenario. In addition. a case …,True,oGyoeV0AAAAJ:b0M2c_1WBrUC,75,https://www.sciencedirect.com/science/article/pii/S0959652614008786,13163752942544364459,/scholar?cites=13163752942544364459,,,http://autoidlab.cs.adelaide.edu.au/sites/default/files/publications/papers/1-s2.0-S0959652614008786-main.pdf,0,0,0
1282084,Memristive crypto primitive for building highly secure physical unclonable functions,2015,Yansong Gao and Damith C Ranasinghe and Said F Al-Sarawi and Omid Kavehei and Derek Abbott,5,Scientific reports,1,1-14,Nature Publishing Group,Physical unclonable functions (PUFs) exploit the intrinsic complexity and irreproducibility of physical systems to generate secret information. The advantage is that PUFs have the potential to provide fundamentally higher security than traditional cryptographic methods by preventing the cloning of devices and the extraction of secret keys. Most PUF designs focus on exploiting process variations in Complementary Metal Oxide Semiconductor (CMOS) technology. In recent years. progress in nanoelectronic devices such as memristors has demonstrated the prevalence of process variations in scaling electronics down to the nano region. In this paper. we exploit the extremely large information density available in nanocrossbar architectures and the significant resistance variations of memristors to develop an on-chip memristive device based strong PUF (mrSPUF). Our novel architecture demonstrates desirable …,True,oGyoeV0AAAAJ:Z5m8FVwuT1cC,73,https://www.nature.com/articles/srep12785?source=techstories.org,9573937507190461670,/scholar?cites=9573937507190461670,,,https://www.nature.com/articles/srep12785?source=techstories.org,0,0,0
1282085,Learning from simulated and unsupervised images through adversarial training,2017,Ashish Shrivastava and Tomas Pfister and Oncel Tuzel and Joshua Susskind and Wenda Wang and Russell Webb,,,,2107-2116,,With recent progress in graphics. it has become more tractable to train models on synthetic images. potentially avoiding the need for expensive annotations. However. learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap. we propose Simulated+ Unsupervised (S+ U) learning. where the task is to learn a model to improve the realism of a simulator's output using unlabeled real data. while preserving the annotation information from the simulator. We develop a method for S+ U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs). but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations. avoid artifacts. and stabilize training:(i) a'self-regularization'term.(ii) a local adversarial loss. and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images. which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images. and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.,True,ahSpJOAAAAAJ:L7CI7m0gUJcC,1359,http://openaccess.thecvf.com/content_cvpr_2017/html/Shrivastava_Learning_From_Simulated_CVPR_2017_paper.html,5960837935511106924,/scholar?cites=5960837935511106924,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Shrivastava_Learning_From_Simulated_CVPR_2017_paper.pdf,0,0,0
1282086,Flowing convnets for human pose estimation in videos,2015,Tomas Pfister and James Charles and Andrew Zisserman,,,,1913-1921,,The objective of this work is human pose estimation in videos. where multiple frames are available. We investigate a ConvNet architecture that is able to benefit from temporal context by combining information across the multiple frames using optical flow. To this end we propose a network architecture with the following novelties:(i) a deeper network than previously investigated for regressing heatmaps;(ii) spatial fusion layers that learn an implicit spatial model;(iii) optical flow is used to align heatmap predictions from neighbouring frames; and (iv) a final parametric pooling layer which learns to combine the aligned heatmaps into a pooled confidence map. We show that this architecture outperforms a number of others. including one that uses optical flow solely at the input layers. one that regresses joint coordinates directly. and one that predicts heatmaps without spatial fusion. The new architecture outperforms the state of the art by a large margin on three video pose estimation datasets. including the very challenging Poses in the Wild dataset. and outperforms other deep methods that don't use a graphical model on the single-image FLIC benchmark (and also Chen & Yuille and Tompson et al. in the high precision region).,True,ahSpJOAAAAAJ:Z5m8FVwuT1cC,466,http://openaccess.thecvf.com/content_iccv_2015/html/Pfister_Flowing_ConvNets_for_ICCV_2015_paper.html,13561683774802539240,/scholar?cites=13561683774802539240,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Pfister_Flowing_ConvNets_for_ICCV_2015_paper.pdf,0,0,0
1282087,Recognising Spontaneous Facial Micro-expressions,2011,Tomas Pfister and Xiaobai Li and Guoying Zhao and Matti Pietikäinen,,,3,,International Conference on Computer Vision (ICCV),Facial micro-expressions are rapid involuntary facial expressions which reveal suppressed affect. To the best knowledge of the authors. there is no previous work that successfully recognises spontaneous facial micro-expressions. In this paper we show how a temporal interpolation model together with the first comprehensive spontaneous micro-expression corpus enable us to accurately recognise these very short expressions. We designed an induced emotion suppression experiment to collect the new corpus using a high-speed camera. The system is the first to recognise spontaneous facial micro-expressions and achieves very promising results that compare favourably with the human micro-expression detection accuracy.,True,ahSpJOAAAAAJ:d1gkVwhDpl0C,334,https://ieeexplore.ieee.org/abstract/document/6126401/,3102867626267371582,/scholar?cites=3102867626267371582,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.700.8477&rep=rep1&type=pdf,0,0,0
1282088,A Spontaneous Micro-expression Database: Inducement. Collection and Baseline,2013,Xiaobai Li and Tomas Pfister and Xiaohua Huang and Guoying Zhao and Matti Pietikäinen,,Automatic Face and Gesture Recognition (FG),,,,Micro-expressions are short. involuntary facial expressions which reveal hidden emotions. Micro-expressions are important for understanding humans' deceitful behavior. Psychologists have been studying them since the 1960's. Currently the attention is elevated in both academic fields and in media. However. while general facial expression recognition (FER) has been intensively studied for years in computer vision. little research has been done in automatically analyzing micro-expressions. The biggest obstacle to date has been the lack of a suitable database. In this paper we present a novel Spontaneous Micro-expression Database SMIC. which includes 164 micro-expression video clips elicited from 16 participants. Micro-expression detection and recognition performance are provided as baselines. SMIC provides sufficient source material for comprehensive testing of automatic systems for analyzing micro …,True,ahSpJOAAAAAJ:eQOLeE2rZwMC,294,https://ieeexplore.ieee.org/abstract/document/6553717/,2577248313212119381,/scholar?cites=2577248313212119381,,,https://tomas.pfister.fi/files/li2013microexpressions.pdf,0,0,0
1282089,Towards reading hidden emotions: A comparative study of spontaneous micro-expression spotting and recognition methods,2017,Xiaobai Li and Xiaopeng Hong and Antti Moilanen and Xiaohua Huang and Tomas Pfister and Guoying Zhao and Matti Pietikäinen,9,IEEE transactions on affective computing,4,563-577,IEEE,Micro-expressions (MEs) are rapid. involuntary facial expressions which reveal emotions that people do not intend to show. Studying MEs is valuable as recognizing them has many important applications. particularly in forensic science and psychotherapy. However. analyzing spontaneous MEs is very challenging due to their short duration and low intensity. Automatic ME analysis includes two tasks: ME spotting and ME recognition. For ME spotting. previous studies have focused on posed rather than spontaneous videos. For ME recognition. the performance of previous studies is low. To address these challenges. we make the following contributions: (i) We propose the first method for spotting spontaneous MEs in long videos (by exploiting feature difference contrast). This method is training free and works on arbitrary unseen videos. (ii) We present an advanced ME recognition framework. which outperforms …,True,ahSpJOAAAAAJ:ILKRHgRFtOwC,182,https://ieeexplore.ieee.org/abstract/document/7851001/,13718059185449749153,/scholar?cites=13718059185449749153,,,https://arxiv.org/pdf/1511.00423,0,0,0
1282090,Deep Convolutional Neural Networks for Efficient Pose Estimation in Gesture Videos,2014,Tomas Pfister and Karen Simonyan and James Charles and Andrew Zisserman,,,,,,Our objective is to efficiently and accurately estimate the upper body pose of humans in gesture videos. To this end. we build on the recent successful applications of deep convolutional neural networks (ConvNets). Our novelties are: (i) our method is the first to our knowledge to use ConvNets for estimating human pose in videos; (ii) a new network that exploits temporal information from multiple frames. leading to better performance; (iii) showing that pre-segmenting the foreground of the video improves performance; and (iv) demonstrating that even without foreground segmentations. the network learns to abstract away from the background and can estimate the pose even in the presence of a complex. varying background.We evaluate our method on the BBC TV Signing dataset and show that our pose predictions are significantly better. and an order of magnitude faster to compute. than the state …,True,ahSpJOAAAAAJ:BUYA1_V_uYcC,142,https://link.springer.com/chapter/10.1007/978-3-319-16865-4_35,1266742947097631454,/scholar?cites=1266742947097631454,,,https://www.researchgate.net/profile/James_Charles3/publication/273316746_Deep_Convolutional_Neural_Networks_for_Efficient_Pose_Estimation_in_Gesture_Videos/links/54fdbb3f0cf2c3f524254867.pdf,0,0,0
1282091,Differentiating Spontaneous From Posed Facial Expressions Within a Generic Facial Expression Recognition Framework,2011,Tomas Pfister and Xiaobai Li and Guoying Zhao and Matti Pietikäinen,,,,,,In this paper we propose the first method known to the authors that successfully differentiates spontaneous from posed facial expressions using a realistic training corpus. We propose a new spatiotemporal local texture descriptor (CLBP-TOP) that outperforms other descriptors. We demonstrate that our temporal interpolation and visual/near-infrared fusion methods improve the differentiation performance. Finally. we propose a new generic facial expression recognition framework that subdivides the facial expression recognition problem into a cascade of smaller tasks that are simpler to tackle. The system is the first to differentiate spontaneous from posed facial expressions with a realistic corpus and achieves promising results.,True,ahSpJOAAAAAJ:9yKSN-GCB0IC,95,https://ieeexplore.ieee.org/abstract/document/6130343/,2894843653370980788,/scholar?cites=2894843653370980788,,,https://cvhci.anthropomatik.kit.edu/download/fipaseminar11/Pfister2011b.pdf,0,0,0
1282092,Personalizing human video pose estimation,2016,James Charles and Tomas Pfister and Derek Magee and David Hogg and Andrew Zisserman,,,,3063-3072,,We propose a personalized ConvNet pose estimator that automatically adapts itself to the uniqueness of a person's appearance to improve pose estimation in long videos. We make the following contributions:(i) we show that given a few high-precision pose annotations. eg from a generic ConvNet pose estimator. additional annotations can be generated throughout the video using a combination of image-based matching for temporally distant frames. and dense optical flow for temporally local frames;(ii) we develop an occlusion aware self-evaluation model that is able to automatically select the high-quality and reject the erroneous additional annotations; and (iii) we demonstrate that these high-quality annotations can be used to fine-tune a ConvNet pose estimator and thereby personalize it to lock on to key discriminative features of the person's appearance. The outcome is a substantial improvement in the pose estimates for the target video using the personalized ConvNet compared to the original generic ConvNet. Our method outperforms the state of the art (including top ConvNet methods) by a large margin on three standard benchmarks. as well as on a new challenging YouTube video dataset. Furthermore. we show that training from the automatically generated annotations can be used to improve the performance of a generic ConvNet on other benchmarks.,True,ahSpJOAAAAAJ:p__nRnzSRKYC,76,http://openaccess.thecvf.com/content_cvpr_2016/html/Charles_Personalizing_Human_Video_CVPR_2016_paper.html,2239726860122880856,/scholar?cites=2239726860122880856,,,https://openaccess.thecvf.com/content_cvpr_2016/papers/Charles_Personalizing_Human_Video_CVPR_2016_paper.pdf,0,0,0
1282093,Real-Time Recognition of Affective States from Nonverbal Features of Speech and Its Application for Public Speaking Skill Analysis,2011,Tomas Pfister and Peter Robinson,2,IEEE Transactions on Affective Computing,2,66-78,IEEE,This paper presents a new classification algorithm for real-time inference of affect from nonverbal features of speech and applies it to assessing public speaking skills. The classifier identifies simultaneously occurring affective states by recognizing correlations between emotions and over 6.000 functional-feature combinations. Pairwise classifiers are constructed for nine classes from the Mind Reading emotion corpus. yielding an average cross-validation accuracy of 89 percent for the pairwise machines and 86 percent for the fused machine. The paper also shows a novel application of the classifier for assessing public speaking skills. achieving an average cross-validation accuracy of 81 percent and a leave-one-speaker-out classification accuracy of 61 percent. Optimizing support vector machine coefficients using grid parameter search is shown to improve the accuracy by up to 25 percent. The emotion classifier …,True,ahSpJOAAAAAJ:u-x6o8ySG0sC,65,https://ieeexplore.ieee.org/abstract/document/5740838/,1781166251330307969,/scholar?cites=1781166251330307969,,,https://www.researchgate.net/profile/Tomas_Pfister/publication/220395367_Real-Time_Recognition_of_Affective_States_from_Nonverbal_Features_of_Speech_and_Its_Application_for_Public_Speaking_Skill_Analysis/links/09e41510834bc3f7ab000000.pdf,0,0,0
1282094,Domain-adaptive discriminative one-shot learning of gestures,2014,Tomas Pfister and James Charles and Andrew Zisserman,,,,814-829,Springer. Cham,The objective of this paper is to recognize gestures in videos – both localizing the gesture and classifying it into one of multiple classes.We show that the performance of a gesture classifier learnt from a single (strongly supervised) training example can be boosted significantly using a ‘reservoir’ of weakly supervised gesture examples (and that the performance exceeds learning from the one-shot example or reservoir alone). The one-shot example and weakly supervised reservoir are from different ‘domains’ (different people. different videos. continuous or non-continuous gesturing. etc). and we propose a domain adaptation method for human pose and hand shape that enables gesture learning methods to generalise between them. We also show the benefits of using the recently introduced Global Alignment Kernel [12]. instead of the standard Dynamic Time Warping that is generally used for time …,True,ahSpJOAAAAAJ:URolC5Kub84C,60,https://link.springer.com/chapter/10.1007/978-3-319-10599-4_52,15972184506802418753,/scholar?cites=15972184506802418753,,,https://link.springer.com/content/pdf/10.1007/978-3-319-10599-4_52.pdf,0,0,0
1282095,Automatic and Efficient Human Pose Estimation for Sign Language Videos,2013,James Charles and Tomas Pfister and Mark Everingham and Andrew Zisserman,,International Journal of Computer Vision,,1-21,Springer US,We present a fully automatic arm and hand tracker that detects joint positions over continuous sign language video sequences of more than an hour in length. To achieve this. we make contributions in four areas: (i) we show that the overlaid signer can be separated from the background TV broadcast using co-segmentation over all frames with a layered model; (ii) we show that joint positions (shoulders. elbows. wrists) can be predicted per-frame using a random forest regressor given only this segmentation and a colour model; (iii) we show that the random forest can be trained from an existing semi-automatic. but computationally expensive. tracker; and. (iv) introduce an evaluator to assess whether the predicted joint positions are correct for each frame. The method is applied to 20 signing footage videos with changing background. challenging imaging conditions. and for different signers. Our framework …,True,ahSpJOAAAAAJ:roLk4NBRz8UC,60,https://link.springer.com/article/10.1007/s11263-013-0672-6,16697824382213357121,/scholar?cites=16697824382213357121,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.700.2489&rep=rep1&type=pdf,0,0,0
1282096,Corpus-based and knowledge-based measures of text semantic similarity,2006,Rada Mihalcea and Courtney Corley and Carlo Strapparava,6,Aaai,2006,775-780,,This paper presents a method for measuring the semantic similarity of texts. using corpus-based and knowledge-based measures of similarity. Previous work on this problem has focused mainly on either large documents (eg text classification. information retrieval) or individual words (eg synonymy tests). Given that a large fraction of the information available today. on the Web and elsewhere. consists of short text snippets (eg abstracts of scientific documents. imagine captions. product descriptions). in this paper we focus on measuring the semantic similarity of short texts. Through experiments performed on a paraphrase data set. we show that the semantic similarity method outperforms methods based on simple lexical matching. resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric.,True,98JOm8wAAAAJ:u5HHmVD_uO8C,1512,https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf,8896621269427321104,/scholar?cites=8896621269427321104,,,https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf,0,0,0
1282097,Measuring the semantic similarity of texts,2005,Courtney D Corley and Rada Mihalcea,,,,13-18,,This paper presents a knowledge-based method for measuring the semanticsimilarity of texts. While there is a large body of previous work focused on finding the semantic similarity of concepts and words. the application of these wordoriented methods to text similarity has not been yet explored. In this paper. we introduce a method that combines wordto-word similarity metrics into a text-totext metric. and we show that this method outperforms the traditional text similarity metrics based on lexical matching.,True,98JOm8wAAAAJ:u-x6o8ySG0sC,426,https://www.aclweb.org/anthology/W05-1203.pdf,2332811126270765788,/scholar?cites=2332811126270765788,,,https://www.aclweb.org/anthology/W05-1203.pdf,0,0,0
1282098,Text and structural data mining of influenza mentions in web and social media,2010,Courtney D Corley and Diane J Cook and Armin R Mikler and Karan P Singh,7,International journal of environmental research and public health,2,596-615,Molecular Diversity Preservation International,Text and structural data mining of web and social media (WSM) provides a novel disease surveillance resource and can identify online communities for targeted public health communications (PHC) to assure wide dissemination of pertinent information. WSM that mention influenza are harvested over a 24-week period. 5 October 2008 to 21 March 2009. Link analysis reveals communities for targeted PHC. Text mining is shown to identify trends in flu posts that correlate to real-world influenza-like illness patient report data. We also bring to bear a graph-based data mining technique to detect anomalies among flu blogs connected by publisher type. links. and user-tags. View Full-Text,True,98JOm8wAAAAJ:d1gkVwhDpl0C,296,https://www.mdpi.com/1660-4601/7/2/596,18050426964013307115,/scholar?cites=18050426964013307115,,,https://www.mdpi.com/1660-4601/7/2/596/pdf,0,0,0
1282099,Using social media for actionable disease surveillance and outbreak management: a systematic literature review,2015,Lauren E Charles-Smith and Tera L Reynolds and Mark A Cameron and Mike Conway and Eric HY Lau and Jennifer M Olsen and Julie A Pavlin and Mika Shigematsu and Laura C Streichert and Katie J Suda and Courtney D Corley,10,,10,e0139701,Public Library of Science,Objective Research studies show that social media may be valuable tools in the disease surveillance toolkit used for improving public health professionals’ ability to detect disease outbreaks faster than traditional methods and to enhance outbreak response. A social media work group. consisting of surveillance practitioners. academic researchers. and other subject matter experts convened by the International Society for Disease Surveillance. conducted a systematic primary literature review using the PRISMA framework to identify research. published through February 2013. answering either of the following questions:  Can social media be integrated into disease surveillance practice and outbreak management to support and improve public health? Can social media be used to effectively target populations. specifically vulnerable populations. to test an intervention and interact with a community to improve health outcomes?  Examples of social media included are Facebook. MySpace. microblogs (e.g.. Twitter). blogs. and discussion forums. For Question 1. 33 manuscripts were identified. starting in 2009 with topics on Influenza-like Illnesses (n = 15). Infectious Diseases (n = 6). Non-infectious Diseases (n = 4). Medication and Vaccines (n = 3). and Other (n = 5). For Question 2. 32 manuscripts were identified. the first in 2000 with topics on Health Risk Behaviors (n = 10). Infectious Diseases (n = 3). Non-infectious Diseases (n = 9). and Other (n = 10).   Conclusions The literature on the use of social media to support public health practice has identified many gaps and biases in current knowledge. Despite the potential for success identified in …,True,98JOm8wAAAAJ:j3f4tGmQtD8C,227,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0139701,13390982459770271219,/scholar?cites=13390982459770271219,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0139701,0,0,0
1282100,Massive social network analysis: Mining twitter for social good,2010,David Ediger and Karl Jiang and Jason Riedy and David A Bader and Courtney Corley and Rob Farber and William N Reynolds,,,,583-593,IEEE,Social networks produce an enormous quantity of data. Facebook consists of over 400 million active users sharing over 5 billion pieces of information each month. Analyzing this vast quantity of unstructured data presents challenges for software and hardware. We present GraphCT. a Graph Characterization Toolkit for massive graphs representing social network data. On a 128-processor Cray XMT. GraphCT estimates the betweenness centrality of an artificially generated (R-MAT) 537 million vertex. 8.6 billion edge graph in 55 minutes and a real-world graph (Kwak. et al.) with 61.6 million vertices and 1.47 billion edges in 105 minutes. We use GraphCT to analyze public data from Twitter. a microblogging network. Twitter's message connections appear primarily tree-structured as a news dissemination system. Within the public data. however. are clusters of conversations. Using GraphCT. we can rank actors within …,True,98JOm8wAAAAJ:9yKSN-GCB0IC,197,https://ieeexplore.ieee.org/abstract/document/5599247/,1396707397337295022,/scholar?cites=1396707397337295022,,,http://lovesgoodfood.com/jason/cv/material/ICPP10-GraphCT.pdf,0,0,0
1282101,Social Web mining and exploitation for serious applications: Technosocial Predictive Analytics and related technologies for public health. environmental and national security …,2010,Maged N Kamel Boulos and Antonio P Sanfilippo and Courtney D Corley and Steve Wheeler,100,Computer methods and programs in biomedicine,1,16-23,Elsevier,This paper explores Technosocial Predictive Analytics (TPA) and related methods for Web “data mining” where users’ posts and queries are garnered from Social Web (“Web 2.0”) tools such as blogs. micro-blogging and social networking sites to form coherent representations of real-time health events. The paper includes a brief introduction to commonly used Social Web tools such as mashups and aggregators. and maps their exponential growth as an open architecture of participation for the masses and an emerging way to gain insight about people's collective health status of whole populations. Several health related tool examples are described and demonstrated as practical means through which health professionals might create clear location specific pictures of epidemiological data such as flu outbreaks.,True,98JOm8wAAAAJ:2osOgNQ5qMEC,113,https://www.sciencedirect.com/science/article/pii/S0169260710000386,17044171350171970035,/scholar?cites=17044171350171970035,,,https://www.academia.edu/download/39251911/00b7d528b65b98f155000000.pdf,0,0,0
1282102,Few-shot learning with metric-agnostic conditional embeddings,2018,Nathan Hilliard and Lawrence Phillips and Scott Howland and Artëm Yankov and Courtney D Corley and Nathan O Hodas,,arXiv preprint arXiv:1802.04376,,,,Learning high quality class representations from few examples is a key problem in metric-learning approaches to few-shot learning. To accomplish this. we introduce a novel architecture where class representations are conditioned for each few-shot trial based on a target image. We also deviate from traditional metric-learning approaches by training a network to perform comparisons between classes rather than relying on a static metric comparison. This allows the network to decide what aspects of each class are important for the comparison at hand. We find that this flexible architecture works well in practice. achieving state-of-the-art performance on the Caltech-UCSD birds fine-grained classification task.,True,98JOm8wAAAAJ:RYcK_YlVTxYC,80,https://arxiv.org/abs/1802.04376,14195272357144127278,/scholar?cites=14195272357144127278,,,https://arxiv.org/pdf/1802.04376,0,0,0
1282103,An overview of internet biosurveillance,2013,David M Hartley and Noele P Nelson and RR Arthur and P Barboza and Nigel Collier and Nigel Lightfoot and JP Linge and E van der Goot and A Mawudeku and LC Madoff and L Vaillant and R Walters and Roman Yangarber and Jas Mantero and Courtney D Corley and John S Brownstein,19,,11,1006-1013,Elsevier,Internet biosurveillance utilizes unstructured data from diverse web-based sources to provide early warning and situational awareness of public health threats. The scope of source coverage ranges from local media in the vernacular to international media in widely read languages. Internet biosurveillance is a timely modality that is available to government and public health officials. healthcare workers. and the public and private sector. serving as a real-time complementary approach to traditional indicator-based public health disease surveillance methods. Internet biosurveillance also supports the broader activity of epidemic intelligence. This overview covers the current state of the field of Internet biosurveillance. and provides a perspective on the future of the field.,True,98JOm8wAAAAJ:M3ejUd6NZC8C,77,https://www.sciencedirect.com/science/article/pii/S1198743X14630020,7445000869005355247,/scholar?cites=7445000869005355247,,,https://www.sciencedirect.com/science/article/pii/S1198743X14630020,0,0,0
1282104,A pandemic influenza modeling and visualization tool,2011,Ross Maciejewski and Philip Livengood and Stephen Rudolph and Timothy F Collins and David S Ebert and Robert T Brigantic and Courtney D Corley and George A Muller and Stephen W Sanders,22,Journal of Visual Languages & Computing,4,268-278,Academic Press,The National Strategy for Pandemic Influenza outlines a plan for community response to a potential pandemic. In this outline. state and local communities are charged with enhancing their preparedness. In order to help public health officials better understand these charges. we have developed a visual analytics toolkit (PanViz) for analyzing the effect of decision measures implemented during a simulated pandemic influenza scenario. Spread vectors based on the point of origin and distance traveled over time are calculated and the factors of age distribution and population density are taken into effect. Healthcare officials are able to explore the effects of the pandemic on the population through a geographical spatiotemporal view. moving forward and backward through time and inserting decision points at various days to determine the impact. Linked statistical displays are also shown. providing county level …,True,98JOm8wAAAAJ:roLk4NBRz8UC,55,https://www.sciencedirect.com/science/article/pii/S1045926X11000292,16509087804870849236,/scholar?cites=16509087804870849236,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc7128504/,0,0,0
1282105,Using Web and social media for influenza surveillance,2010,Courtney D Corley and Diane J Cook and Armin R Mikler and Karan P Singh,,,,559-564,Springer. New York. NY,Analysis of Google influenza-like-illness (ILI) search queries has shown a strongly correlated pattern with Centers for Disease Control (CDC) and Prevention seasonal ILI reporting data. Web and social media provide another resource to detect increases in ILI. This paper evaluates trends in blog posts that discuss influenza. Our key finding is that from 5th October 2008 to 31st January 2009. a high correlation exists between the frequency of posts. containing influenza keywords. per week and CDC influenza-like-illness surveillance data.,True,98JOm8wAAAAJ:UeHWp8X0CEIC,55,https://link.springer.com/chapter/10.1007/978-1-4419-5913-3_61,979284103539217021,/scholar?cites=979284103539217021,,,https://link.springer.com/chapter/10.1007/978-1-4419-5913-3_61,0,0,0
1282106,Seeing through noise: Visually driven speaker separation and enhancement,2018,Aviv Gabbay and Ariel Ephrat and Tavi Halperin and Shmuel Peleg,,,,3051-3055,IEEE,Isolating the voice of a specific person while filtering out other voices or background noises is challenging when video is shot in noisy environments. We propose audio-visual methods to isolate the voice of a single speaker and eliminate unrelated sounds. First. face motions captured in the video are used to estimate the speaker's voice. by passing the silent video frames through a video-to-speech neural network-based model. Then the speech predictions are applied as a filter on the noisy input audio. This approach avoids using mixtures of sounds in the learning process. as the number of such possible mixtures is huge. and would inevitably bias the trained model. We evaluate our method on two audio-visual datasets. GRID and TCD-TIMIT. and show that our method attains significant SDR and PESQ improvements over the raw video-to-speech predictions. and a well-known audio-only method.,True,98JOm8wAAAAJ:2P1L_qKh6hAC,52,https://ieeexplore.ieee.org/abstract/document/8462527/,15782857409409460209,/scholar?cites=15782857409409460209,,,https://arxiv.org/pdf/1708.06767,0,0,0
1282107,Tracking across multiple cameras with disjoint views,2003,Omar Javed and Zeeshan Rasheed and Khurram Shafique and Mubarak Shah,,,,952,IEEE Computer Society,Conventional tracking approaches assume proximity inspace. time and appearance of objects in successive observations. However. observations of objects are often widelyseparated in time and space when viewed from multiplenon-overlapping cameras. To address this problem. wepresent a novel approach for establishing object correspondenceacross non-overlapping cameras. Our multi-cameratracking algorithm exploits the redundance in paths thatpeople and cars tend to follow. eg roads. walk-ways orcorridors. by using motion trends and appearance of objects. to establish correspondence. Our system does notrequire any inter-camera calibration. instead the systemlearns the camera topology and path probabilities of objectsusing Parzen windows. during a training phase. Oncethe training is complete. correspondences are assigned usingthe maximum a posteriori (MAP) estimation framework. The learned …,True,2mCUlIoAAAAJ:M3ejUd6NZC8C,519,https://dl.acm.org/doi/abs/10.5555/946247.946710,10493204990377259614,/scholar?cites=10493204990377259614,,,,0,0,0
1282108,Modeling inter-camera space–time and appearance relationships for tracking across non-overlapping views,2008,Omar Javed and Khurram Shafique and Zeeshan Rasheed and Mubarak Shah,109,Computer Vision and Image Understanding,2,146-162,Academic Press,Tracking across cameras with non-overlapping views is a challenging problem. Firstly. the observations of an object are often widely separated in time and space when viewed from non-overlapping cameras. Secondly. the appearance of an object in one camera view might be very different from its appearance in another camera view due to the differences in illumination. pose and camera properties. To deal with the first problem. we observe that people or vehicles tend to follow the same paths in most cases. i.e.. roads. walkways. corridors etc. The proposed algorithm uses this conformity in the traversed paths to establish correspondence. The algorithm learns this conformity and hence the inter-camera relationships in the form of multivariate probability density of space–time variables (entry and exit locations. velocities. and transition times) using kernel density estimation. To handle the appearance change of an …,True,2mCUlIoAAAAJ:QIV2ME_5wuYC,362,https://www.sciencedirect.com/science/article/pii/S1077314207000100,12262748966537793055,/scholar?cites=12262748966537793055,,,https://www.academia.edu/download/31923472/CVIU08.pdf,0,0,0
1282109,Detection and representation of scenes in videos,2005,Zeeshan Rasheed and Mubarak Shah,7,IEEE transactions on Multimedia,6,1097-1105,IEEE,This paper presents a method to perform a high-level segmentation of videos into scenes. A scene can be defined as a subdivision of a play in which either the setting is fixed. or when it presents continuous action in one place. We exploit this fact and propose a novel approach for clustering shots into scenes by transforming this task into a graph partitioning problem. This is achieved by constructing a weighted undirected graph called a shot similarity graph (SSG). where each node represents a shot and the edges between the shots are weighted by their similarity based on color and motion information. The SSG is then split into subgraphs by applying the normalized cuts for graph partitioning. The partitions so obtained represent individual scenes in the video. When clustering the shots. we consider the global similarities of shots rather than the individual shot pairs. We also propose a method to describe the content …,True,2mCUlIoAAAAJ:Tyk-4Ss8FVUC,303,https://ieeexplore.ieee.org/abstract/document/1542086/,5190523317885618308,/scholar?cites=5190523317885618308,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.881&rep=rep1&type=pdf,0,0,0
1282110,On the use of computable features for film classification,2005,Zeeshan Rasheed and Yaser Sheikh and Mubarak Shah,15,IEEE Transactions on Circuits and Systems for Video Technology,1,52-64,IEEE,This work presents a framework for the classification of feature films into genres. based only on computable visual cues. We view the work as a step toward high-level semantic film interpretation. currently using low-level video features and knowledge of ubiquitous cinematic practices. Our current domain of study is the movie preview. commercial advertisements primarily created to attract audiences. A preview often emphasizes the theme of a film and hence provides suitable information for classification. In our approach. we classify movies into four broad categories: Comedies. Action. Dramas. or Horror films. Inspired by cinematic principles. four computable video features (average shot length. color variance. motion content and lighting key) are combined in a framework to provide a mapping to these four high-level semantic classes. Mean shift classification is used to discover the structure between the computed …,True,2mCUlIoAAAAJ:hqOjcs7Dif8C,246,https://ieeexplore.ieee.org/abstract/document/1377360/,7883021172676198448,/scholar?cites=7883021172676198448,,,http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/yaser/RasheedSheikhShah_CVST_2005.pdf,0,0,0
1282111,Scene detection in Hollywood movies and TV shows,2003,Zeeshan Rasheed and Mubarak Shah,2,,,II-343,IEEE,A scene can be defined as one of the subdivisions of a play in which the setting is fixed. or when it presents continuous action in one place. We propose a novel two-pass algorithm for scene boundary detection. which utilizes the motion content. shot length and color properties of shots as the features. In our approach. shots are first clustered by computing Backward Shot Coherence (BSC) - a shot color similarity measure that detects Potential Scene Boundaries (PSBs) in the videos. In the second pass we compute Scene Dynamics (SD). a function of shot length and the motion content in the potential scenes. In this pass. a scene merging criteria has been developed to remove weak PSBs in order to reduce over segmentation. We also propose a method to describe the content of each scene by selecting one representative image. The segmentation of video data into number of scenes facilitates an improved browsing …,True,2mCUlIoAAAAJ:UebtZRa9Y70C,203,https://ieeexplore.ieee.org/abstract/document/1211489/,7857931567878530078,/scholar?cites=7857931567878530078,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.152.8574&rep=rep1&type=pdf,0,0,0
1282112,KNIGHT/spl trade: a real time surveillance system for multiple and non-overlapping cameras,2003,Omar Javed and Zeeshan Rasheed and Orkun Alatas and Mubarak Shah,1,,,I-649,IEEE,In this paper. we present a wide area surveillance system that detects. tracks and classifies moving objects across multiple cameras. At the single camera level. tracking is performed using a voting based approach that utilizes color and shape cues to establish correspondence. The system uses the single camera tracking results along with the relationship between camera field of view (FOV) boundaries to establish correspondence between views of the same object in multiple cameras. To this end. a novel approach is described to find the relationships between the FOV lines of cameras. The proposed approach combines tracking in cameras with overlapping and/or non-overlapping FOVs in a unified framework. without requiring explicit calibration. The proposed algorithm has been implemented in a real time system. The system uses a client-server architecture and runs at 10 Hz with three cameras.,True,2mCUlIoAAAAJ:qjMakFHDy7sC,199,https://ieeexplore.ieee.org/abstract/document/1221001/,2847020629334575082,/scholar?cites=2847020629334575082,,,https://www.crcv.ucf.edu/papers/KnightM_ICME2003.pdf,0,0,0
1282113,Human tracking in multiple cameras,2001,Sohaib Khan and Omar Javed and Zeeshan Rasheed and Mubarak Shah,1,,,331-336,IEEE,Multiple cameras are needed to cover large environments for monitoring activity. To track people successfully in multiple perspective imagery. one needs to establish correspondence between objects captured in multiple cameras. We present a system for tracking people in multiple uncalibrated cameras. The system is able to discover spatial relationships between the camera fields of view and use this information to correspond between different perspective views of the same person. We employ the novel approach of finding the limits of field of view (FOV) of a camera as visible in the other cameras. Using this information. when a person is seen in one camera. we are able to predict all the other cameras in which this person will be visible. Moreover. we apply the FOV constraint to disambiguate between possible candidates of correspondence. We present results on sequences of up to three cameras with multiple …,True,2mCUlIoAAAAJ:Y0pCki6q_DkC,181,https://ieeexplore.ieee.org/abstract/document/937537/,5331814812294951768,/scholar?cites=5331814812294951768,,,https://www.academia.edu/download/30699298/handoff-iccv.pdf,0,0,0
1282114,Multi-state target tracking,2010,Zhong Zhang and Haiying Liu and Alan J Lipton and Zeeshan Rasheed and Paul C Brewer and Andrew J Chosak and Niels Haering and Peter L Venetianer and Weihong Yin,,,,,,A method of video analysis may comprise tracking a state of each target in a video through multiple frames of said video. each state indicating a visibility condition of a target.,True,2mCUlIoAAAAJ:UeHWp8X0CEIC,141,https://patents.google.com/patent/US7825954B2/en,3460095086514505642,/scholar?cites=3460095086514505642,,,https://patentimages.storage.googleapis.com/eb/f2/f3/7502150c255bb3/US7825954.pdf,0,0,0
1282115,Video segmentation using statistical pixel modeling,2013,Alan J Lipton and Niels Haering and Zeeshan Rasheed and Omar Javed and Zhong Zhang and Weihong Yin and Peter L Venetianer and Gary W Myers,,,,,,A method for segmenting video data into foreground and background (324) portions utilizes statistical modeling of the pixels Λ statistical model of the background is built for each pixel. and each pixel in an incoming video frame is compared (326) with the background statistical model for that pixel. Pixels are determined to be foreground or background based on the comparisons. The method for segmenting video data may be further incorporated into a method for implementing an intelligent video surveillance system The method for segmenting video data may be implemented in hardware.,True,2mCUlIoAAAAJ:_Qo2XoVZTnwC,120,https://patents.google.com/patent/US8457401B2/en,16896491384499892119,/scholar?cites=16896491384499892119,,,https://patentimages.storage.googleapis.com/18/cb/34/cc747259c3b4a1/US8457401.pdf,0,0,0
1282116,Target detection and tracking from overhead video streams,2010,Alan J Lipton and Peter L Venetianer and Zhong Zhang and Haiying Liu and Zeeshan Rasheed and Himaanshu Gupta and Li Yu,,,,,,A technique for video processing includes: receiving video from an overhead view of a scene; detecting moving pixels in the video; detecting line segments in the video based on detected moving pixels; identifying targets in the video based on the detected line segments; tracking targets in the video based on the identified targets; and managing tracked targets in the video.,True,2mCUlIoAAAAJ:hFOr9nPyWt4C,119,https://patents.google.com/patent/US7796780B2/en,14471348041561515250,/scholar?cites=14471348041561515250,,,https://patentimages.storage.googleapis.com/75/fd/e6/6cdb73687a0520/US7796780.pdf,0,0,0
1282117,Tracking across multiple cameras with disjoint views,2008,Mubarak Shah and Omar Javed and Khurram Shafique and Zeeshan Rasheed,,,,,,Tracking and surveillance methods and systems for monitoring objects passing in front of non-overlapping cameras. Invention finds corresponding tracks from different cameras and works out which object passing in front of the camera (s) made the tracks. in order to track the object from camera to camera. The invention uses an algorithm to learn inter-camera spatial temporal probability using Parzen windows. learns inter-camera appearance probabilities using distribution of Bhattacharyya distances between appearance models. establishes correspondences based on Maximum A Posteriori (MAP) framework combining both spatial temporal and appearance probabilities. and updates learned probabilities throughout the lifetime of the system.,True,2mCUlIoAAAAJ:_kc_bZDykSQC,106,https://patents.google.com/patent/US7450735B1/en,10287218865585960082,/scholar?cites=10287218865585960082,,,https://patentimages.storage.googleapis.com/c7/0c/8e/e3a8b55f6a3878/US7450735.pdf,0,0,0
1282118,Gans trained by a two time-scale update rule converge to a local nash equilibrium,2017,Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter,,,,6626-6637,,"Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However. the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation. we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization. for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation. we introduce the"" Fréchet Inception Distance""(FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments. TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA. CIFAR-10. SVHN. LSUN Bedrooms. and the One Billion Word Benchmark.",True,H_ICOW4AAAAJ:gKiMpY-AVTkC,2604,https://arxiv.org/abs/1706.08500,15143899073250151317,/scholar?cites=15143899073250151317,,,https://arxiv.org/pdf/1706.08500.pdf?source=post_page---------------------------,0,0,0
1282119,GANs trained by a two time-scale update rule converge to a local nash equilibrium,2017,Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter,,,,6629-6640,,"Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However. the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation. we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization. for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation. we introduce the"" Fréchet Inception Distance""(FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments. TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA. CIFAR-10. SVHN. LSUN Bedrooms. and the One Billion Word Benchmark.",True,H_ICOW4AAAAJ:u-coK7KVo8oC,2604,https://arxiv.org/abs/1706.08500,15143899073250151317,/scholar?cites=15143899073250151317,,,https://arxiv.org/pdf/1706.08500.pdf?source=post_page---------------------------,0,0,0
1282120,Neural dynamics as sampling: A model for stochastic computation in recurrent networks of spiking neurons,2011,Lars Buesing and Johannes Bill and Bernhard Nessler and Wolfgang Maass,7,PLoS Computational Biology,11,e1002211,Public Library of Science,The organization of computations in networks of spiking neurons in the brain is still largely unknown. in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations. probabilistic inference by sampling. which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems. such as Gibbs sampling. are inconsistent with the dynamics of spiking neurons. we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution. both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.,True,H_ICOW4AAAAJ:u-x6o8ySG0sC,377,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002211,3698439004004899531,/scholar?cites=3698439004004899531,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002211,0,0,0
1282121,GANs Trained by a Two Time-Scale Update Rule Converge to a Nash Equilibrium.,2017,Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Günter Klambauer and Sepp Hochreiter,,,,,,"Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However. the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation. we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization. for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation. we introduce the"" Fréchet Inception Distance""(FID) which captures the similarity of generated …",True,H_ICOW4AAAAJ:otzGkya1bYkC,265,https://openreview.net/forum?id=IiwSettbCwA,54268214411324516,/scholar?cites=54268214411324516,,,,0,0,0
1282122,Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity,2013,Bernhard Nessler and Michael Pfeiffer and Lars Buesing and Wolfgang Maass,9,PLoS computational biology,4,e1003037,Public Library of Science,The principles by which networks of neurons compute. and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function. are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits. where pyramidal neurons inhibit each other via interneurons. are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact. a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability. since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.,True,H_ICOW4AAAAJ:hqOjcs7Dif8C,251,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037,3083406410349944661,/scholar?cites=3083406410349944661,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037,0,0,0
1282123,Speeding up Semantic Segmentation for Autonomous Driving,2016,Michael Treml and José Arjona-Medina and Thomas Unterthiner and Rupesh Durgesh and Felix Friedmann and Peter Schuberth and Andreas Mayr and Martin Heusel and Markus Hofmarcher and Michael Widrich and Ulrich Bodenhofer and Bernhard Nessler and Sepp Hochreiter,,,,,,Deep learning has considerably improved semantic image segmentation. However. its high accuracy is traded against larger computational costs which makes it unsuitable for embedded devices in self-driving cars. We propose a novel deep network architecture for image segmentation that keeps the high accuracy while being efficient enough for embedded devices. The architecture consists of ELU activation functions. a SqueezeNet-like encoder. followed by parallel dilated convolutions. and a decoder with SharpMask-like refinement modules. On the Cityscapes dataset. the new network achieves higher segmentation accuracy than other networks that are tailored to embedded devices. Simultaneously the frame-rate is still sufficiently high for the deployment in autonomous vehicles.,True,H_ICOW4AAAAJ:GFxP56DSvIMC,161,https://www.researchgate.net/profile/Thomas_Unterthiner2/publication/309935608_Speeding_up_Semantic_Segmentation_for_Autonomous_Driving/links/58524adf08ae7d33e01a58a7.pdf,7283249027656549183,/scholar?cites=7283249027656549183,,,https://www.researchgate.net/profile/Thomas_Unterthiner2/publication/309935608_Speeding_up_Semantic_Segmentation_for_Autonomous_Driving/links/58524adf08ae7d33e01a58a7.pdf,0,0,0
1282124,STDP enables spiking neurons to detect hidden causes of their inputs,2009,Bernhard Nessler and Michael Pfeiffer and Wolfgang Maass,22,Advances in Neural Information Processing Systems,,1357-1365,,The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits. and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain this computational function. are unknown. We show here that STDP. in conjunction with a stochastic soft winner-take-all (WTA) circuit. induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or “causes”) of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits. a common network motif of cortical microcircuits. could therefore be a drastic dimensionality reduction of information streams. together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular. we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.,True,H_ICOW4AAAAJ:u5HHmVD_uO8C,113,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.690.4283&rep=rep1&type=pdf,16972082276322574792,/scholar?cites=16972082276322574792,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.690.4283&rep=rep1&type=pdf,0,0,0
1282125,STDP installs in winner-take-all circuits an online approximation to hidden markov model learning,2014,David Kappel and Bernhard Nessler and Wolfgang Maass,10,PLoS computational biology,3,e1003511,Public Library of Science,In order to cross a street without being run over. we need to be able to extract very fast hidden causes of dynamically changing multi-modal sensory stimuli. and to predict their future evolution. We show here that a generic cortical microcircuit motif. pyramidal cells with lateral excitation and inhibition. provides the basis for this difficult but all-important information processing capability. This capability emerges in the presence of noise automatically through effects of STDP on connections between pyramidal cells in Winner-Take-All circuits with lateral excitation. In fact. one can show that these motifs endow cortical microcircuits with functional properties of a hidden Markov model. a generic model for solving such tasks through probabilistic inference. Whereas in engineering applications this model is adapted to specific tasks through offline learning. we show here that a major portion of the functionality of hidden Markov models arises already from online applications of STDP. without any supervision or rewards. We demonstrate the emergent computing capabilities of the model through several computer simulations. The full power of hidden Markov model learning can be attained through reward-gated STDP. This is due to the fact that these mechanisms enable a rejection sampling approximation to theoretically optimal learning. We investigate the possible performance gain that can be achieved with this more accurate learning method for an artificial grammar task.,True,H_ICOW4AAAAJ:0EnyYjriUFMC,95,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003511,9094051103050308730,/scholar?cites=9094051103050308730,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003511,0,0,0
1282126,Coulomb GANs: Provably optimal nash equilibria via potential fields,2017,Thomas Unterthiner and Bernhard Nessler and Calvin Seward and Günter Klambauer and Martin Heusel and Hubert Ramsauer and Sepp Hochreiter,,arXiv preprint arXiv:1708.08819,,,,Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges. GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs. which pose the GAN learning problem as a potential field of charged particles. where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy. the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA. Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.,True,H_ICOW4AAAAJ:Aul-kAQHnToC,50,https://arxiv.org/abs/1708.08819,14788505867309328713,/scholar?cites=14788505867309328713,,,https://arxiv.org/pdf/1708.08819,0,0,0
1282127,Where’s the noise? key features of spontaneous activity and neural variability arise through learning in a deterministic network,2015,Christoph Hartmann and Andreea Lazar and Bernhard Nessler and Jochen Triesch,11,PLoS computational biology,12,e1004640,Public Library of Science,Even in the absence of sensory stimulation the brain is spontaneously active. This background “noise” seems to be the dominant cause of the notoriously high trial-to-trial variability of neural recordings. Recent experimental observations have extended our knowledge of trial-to-trial variability and spontaneous activity in several directions: 1. Trial-to-trial variability systematically decreases following the onset of a sensory stimulus or the start of a motor act. 2. Spontaneous activity states in sensory cortex outline the region of evoked sensory responses. 3. Across development. spontaneous activity aligns itself with typical evoked activity patterns. 4. The spontaneous brain activity prior to the presentation of an ambiguous stimulus predicts how the stimulus will be interpreted. At present it is unclear how these observations relate to each other and how they arise in cortical circuits. Here we demonstrate that all of these phenomena can be accounted for by a deterministic self-organizing recurrent neural network model (SORN). which learns a predictive model of its sensory environment. The SORN comprises recurrently coupled populations of excitatory and inhibitory threshold units and learns via a combination of spike-timing dependent plasticity (STDP) and homeostatic plasticity mechanisms. Similar to balanced network architectures. units in the network show irregular activity and variable responses to inputs. Additionally. however. the SORN exhibits sequence learning abilities matching recent findings from visual cortex and the network’s spontaneous activity reproduces the experimental findings mentioned above. Intriguingly. the network’s behaviour …,True,H_ICOW4AAAAJ:Ehil0879vHcC,42,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004640,16447959996337465510,/scholar?cites=16447959996337465510,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004640,0,0,0
1282128,Homeostatic plasticity in Bayesian spiking networks as Expectation Maximization with posterior constraints,2012,Stefan Habenschuss and Johannes Bill and Bernhard Nessler,,,,773-781,,Recent spiking network models of Bayesian inference and unsupervised learning frequently assume either inputs to arrive in a special format or employ complex computations in neuronal activation functions and synaptic plasticity rules. Here we show in a rigorous mathematical treatment how homeostatic processes. which have previously received little attention in this context. can overcome common theoretical limitations and facilitate the neural implementation and performance of existing models. In particular. we show that homeostatic plasticity can be understood as the enforcement of a’balancing’posterior constraint during probabilistic inference and learning with Expectation Maximization. We link homeostatic dynamics to the theory of variational inference. and show that nontrivial terms. which typically appear during probabilistic inference in a large class of models. drop out. We demonstrate the feasibility of our approach in a spiking Winner-Take-All architecture of Bayesian inference and learning. Finally. we sketch how the mathematical framework can be extended to richer recurrent network architectures. Altogether. our theory provides a novel perspective on the interplay of homeostatic processes and synaptic plasticity in cortical microcircuits. and points to an essential role of homeostasis during inference and learning in spiking networks.,True,H_ICOW4AAAAJ:roLk4NBRz8UC,32,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8325&rep=rep1&type=pdf,3404387141335517445,/scholar?cites=3404387141335517445,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.420.8325&rep=rep1&type=pdf,0,0,0
1282129,Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering,2018,Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang,,,,,,Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. In this work. we propose a combined bottom-up and top-down attention mechanism that enables attention to be calculated at the level of objects and other salient image regions. This is the natural basis for attention to be considered. Within our approach. the bottom-up mechanism (based on Faster R-CNN) proposes image regions. each with an associated feature vector. while the top-down mechanism determines feature weightings. Applying this approach to image captioning. our results on the MSCOCO test server establish a new state-of-the-art for the task. achieving CIDEr/SPICE/BLEU-4 scores of 117.9. 21.5 and 36.9. respectively. Demonstrating the broad applicability of the method. applying the same approach to VQA we obtain first place in the 2017 VQA Challenge.,True,r5mA7Q8AAAAJ:ULOm3_A8WrAC,1773,http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html,7383633913245131178,/scholar?cites=7383633913245131178,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.pdf,0,0,0
1282130,SPICE: Semantic Propositional Image Caption Evaluation,2016,Peter Anderson and Basura Fernando and Mark Johnson and Stephen Gould,,,,,,There is considerable interest in the task of automatically generating image captions. However. evaluation is challenging. Existing automatic evaluation metrics are primarily sensitive to n-gram overlap. which is neither necessary nor sufficient for the task of simulating human judgment. We hypothesize that semantic propositional content is an important component of human caption evaluation. and propose a new automated caption evaluation metric defined over scene graphs coined SPICE. Extensive evaluations across a range of models and datasets indicate that SPICE captures human judgments over model-generated captions better than other automatic metrics (e.g.. system-level correlation of 0.88 with human judgments on the MS COCO dataset. versus 0.43 for CIDEr and 0.53 for METEOR). Furthermore. SPICE can answer questions such as which caption-generator best understands colors? and …,True,r5mA7Q8AAAAJ:0EnyYjriUFMC,635,https://link.springer.com/chapter/10.1007/978-3-319-46454-1_24,8345837387819021644,/scholar?cites=8345837387819021644,,,https://arxiv.org/pdf/1607.08822,0,0,0
1282131,Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments,2018,Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko Sünderhauf and Ian Reid and Stephen Gould and Anton van den Hengel,,Computer Vision and Pattern Recognition (CVPR),,,,A robot that can carry out a natural-language instruction has been a dream since before the Jetsons cartoon series imagined a life of leisure mediated by a fleet of attentive robot helpers. It is a dream that remains stubbornly distant. However. recent advances in vision and language methods have made incredible progress in closely related areas. This is significant because a robot interpreting a natural-language navigation instruction on the basis of what it sees is carrying out a vision and language process that is similar to Visual Question Answering. Both tasks can be interpreted as visually grounded sequence-to-sequence translation problems. and many of the same methods are applicable. To enable and encourage the application of vision and language methods to the problem of interpreting visually-grounded navigation instructions. we present the Matterport3D Simulator--a large-scale reinforcement learning environment based on real imagery. Using this simulator. which can in future support a range of embodied vision and language tasks. we provide the first benchmark dataset for visually-grounded natural language navigation in real buildings--the Room-to-Room (R2R) dataset.,True,r5mA7Q8AAAAJ:_kc_bZDykSQC,397,http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html,11715302607690282214,/scholar?cites=11715302607690282214,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.pdf,0,0,0
1282132,Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge,2018,Damien Teney and Peter Anderson and Xiaodong He and Anton van den Hengel,,Computer Vision and Pattern Recognition (CVPR),,,,This paper presents a state-of-the-art model for visual question answering (VQA). which won the first place in the 2017 VQA Challenge. VQA is a task of significant importance for research in artificial intelligence. given its multimodal nature. clear evaluation protocol. and potential real-world applications. The performance of deep neural networks for VQA is very dependent on choices of architectures and hyperparameters. To help further research in the area. we describe in detail our high-performing. though relatively simple model. Through a massive exploration of architectures and hyperparameters representing more than 3.000 GPU-hours. we identified tips and tricks that lead to its success. namely: sigmoid outputs. soft training targets. image features from bottom-up attention. gated tanh activations. output embeddings initialized using GloVe and Google Images. large mini-batches. and smart shuffling of training data. We provide a detailed analysis of their impact on performance to assist others in making an appropriate selection.,True,r5mA7Q8AAAAJ:YOwf2qJgpHMC,238,http://openaccess.thecvf.com/content_cvpr_2018/html/Teney_Tips_and_Tricks_CVPR_2018_paper.html,1128702951190962561,/scholar?cites=1128702951190962561,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Teney_Tips_and_Tricks_CVPR_2018_paper.pdf,0,0,0
1282133,On Evaluation of Embodied Navigation Agents,2018,Peter Anderson and Angel Chang and Devendra Singh Chaplot and Alexey Dosovitskiy and Saurabh Gupta and Vladlen Koltun and Jana Kosecka and Jitendra Malik and Roozbeh Mottaghi and Manolis Savva and Amir R Zamir,,arXiv preprint arXiv:1807.06757,,,,Skillful mobile operation in three-dimensional environments is a primary topic of study in Artificial Intelligence. The past two years have seen a surge of creative work on navigation. This creative output has produced a plethora of sometimes incompatible task definitions and evaluation protocols. To coordinate ongoing and future research in this area. we have convened a working group to study empirical methodology in navigation research. The present document summarizes the consensus recommendations of this working group. We discuss different problem statements and the role of generalization. present evaluation measures. and provide standard scenarios that can be used for benchmarking.,True,r5mA7Q8AAAAJ:mVmsd5A6BfQC,188,https://arxiv.org/abs/1807.06757,8291975021733630139,/scholar?cites=8291975021733630139,,,https://arxiv.org/pdf/1807.06757,0,0,0
1282134,Discriminative hierarchical rank pooling for activity recognition,2016,B Fernando and P Anderson and M Hutter and S Gould,,,,,,We present hierarchical rank pooling. a video sequence encoding method for activity recognition. It consists of a network of rank pooling functions which captures the dynamics of rich convolutional neural network features within a video sequence. By stacking non-linear feature functions and rank pooling over one another. we obtain a high capacity dynamic encoding mechanism. which is used for action recognition. We present a method for jointly learning the video representation and activity classifier parameters. Our method obtains state-of-the art results on three important activity recognition benchmarks: 76.7% on Hollywood2. 66.9% on HMDB51 and. 91.4% on UCF101.,True,r5mA7Q8AAAAJ:hqOjcs7Dif8C,119,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Fernando_Discriminative_Hierarchical_Rank_CVPR_2016_paper.html,684080648808305036,/scholar?cites=684080648808305036,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Fernando_Discriminative_Hierarchical_Rank_CVPR_2016_paper.pdf,0,0,0
1282135,Guided Open Vocabulary Image Captioning with Constrained Beam Search,2017,Peter Anderson and Basura Fernando and Mark Johnson and Stephen Gould,,,,,,Existing image captioning models do not generalize well to out-of-domain images containing novel scenes or objects. This limitation severely hinders the use of these models in real world applications dealing with images in the wild. We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time. without re-training. Our method uses constrained beam search to force the inclusion of selected tag words in the output. and fixed. pretrained word embeddings to facilitate vocabulary expansion to previously unseen tag words. Using this approach we achieve state of the art results for out-of-domain captioning on MSCOCO (and improved results for in-domain captioning). Perhaps surprisingly. our results significantly outperform approaches that incorporate the same tag predictions into the learning algorithm. We also show that we can significantly improve the quality of generated ImageNet captions by leveraging ground-truth labels.,True,r5mA7Q8AAAAJ:MXK_kJrjxJIC,88,https://arxiv.org/abs/1612.00576,10827803067189546296,/scholar?cites=10827803067189546296,,,https://arxiv.org/pdf/1612.00576,0,0,0
1282136,On differentiating parameterized argmin and argmax problems with application to bi-level optimization,2016,Stephen Gould and Basura Fernando and Anoop Cherian and Peter Anderson and Rodrigo Santa Cruz and Edison Guo,,arXiv preprint arXiv:1607.05447,,,,Some recent works in machine learning and computer vision involve the solution of a bi-level optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems. including gradient descent. which is popular with current end-to-end learning approaches. In this technical report we collect some results on differentiating argmin and argmax optimization problems with and without constraints and provide some insightful motivating examples.,True,r5mA7Q8AAAAJ:5nxA0vEk-isC,76,https://arxiv.org/abs/1607.05447,5949217143566838662,/scholar?cites=5949217143566838662,,,https://arxiv.org/pdf/1607.05447,0,0,0
1282137,Audio Visual Scene-Aware Dialog,2019,Huda Alamri and Vincent Cartillier and Abhishek Das and Jue Wang and Anoop Cherian and Irfan Essa and Dhruv Batra and Tim K Marks and Chiori Hori and Peter Anderson and Stefan Lee and Devi Parikh,,,,,,We introduce the task of scene-aware dialog. Our goal is to generate a complete and natural response to a question about a scene. given video and audio of the scene and the history of previous turns in the dialog. To answer successfully. agents must ground concepts from the question in the video while leveraging contextual cues from the dialog history. To benchmark this task. we introduce the Audio Visual Scene-Aware Dialog (AVSD) Dataset. For each of more than 11.000 videos of human actions from the Charades dataset. our dataset contains a dialog about the video. plus a final summary of the video by one of the dialog participants. We train several baseline systems for this task and evaluate the performance of the trained models using both qualitative and quantitative metrics. Our results indicate that models must utilize all the available inputs (video. audio. question. and dialog history) to perform best on this dataset.,True,r5mA7Q8AAAAJ:L8Ckcad2t8MC,35,http://openaccess.thecvf.com/content_CVPR_2019/html/Alamri_Audio_Visual_Scene-Aware_Dialog_CVPR_2019_paper.html,2795667614315183688,/scholar?cites=2795667614315183688,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Alamri_Audio_Visual_Scene-Aware_Dialog_CVPR_2019_paper.pdf,0,0,0
1282138,REVERIE: Remote Embodied Visual referring Expressions in Real Indoor Environments,2020,Yuankai Qi and Qi Wu and Peter Anderson and Xin Wang and Chunhua Liu and Wang and Wiliam Yang and Anton van den Hengel,,,,,,One of the long-term challenges of robotics is to enable robots to interact with humans in the visual world via natural language. as humans are visual animals that communicate through language. Overcoming this challenge requires the ability to perform a wide variety of complex tasks in response to multifarious instructions from humans. In the hope that it might drive progress towards more flexible and powerful human interactions with robots. we propose a dataset of varied and complex robot tasks. described in natural language. in terms of objects visible in a large set of real images. Given an instruction. success requires navigating through a previously-unseen environment to identify an object. This represents a practical challenge. but one that closely reflects one of the core visual problems in robotics. Several state-of-the-art vision-and-language navigation. and referring-expression models are tested to verify the difficulty of this new task. but none of them show promising results because there are many fundamental differences between our task and previous ones. A novel Interactive Navigator-Pointer model is also proposed that provides a strong baseline on the task. The proposed model especially achieves the best performance on the unseen test split. but still leaves substantial room for improvement compared to the human performance. Repository: https://github. com/YuankaiQi/REVERIE.,True,r5mA7Q8AAAAJ:-f6ydRqryjwC,31,http://openaccess.thecvf.com/content_CVPR_2020/html/Qi_REVERIE_Remote_Embodied_Visual_Referring_Expression_in_Real_Indoor_Environments_CVPR_2020_paper.html,4771496151208510874,/scholar?cites=4771496151208510874,,,http://openaccess.thecvf.com/content_CVPR_2020/papers/Qi_REVERIE_Remote_Embodied_Visual_Referring_Expression_in_Real_Indoor_Environments_CVPR_2020_paper.pdf,0,0,0
1282139,Chasing ghosts: Instruction following as bayesian state tracking,2019,Peter Anderson and Ayush Shrivastava and Devi Parikh and Dhruv Batra and Stefan Lee,,,,,,A visually-grounded navigation instruction can be interpreted as a sequence of expected observations and actions an agent following the correct trajectory would encounter and perform. Based on this intuition. we formulate the problem of finding the goal location in Vision-and-Language Navigation (VLN) within the framework of Bayesian state tracking-learning observation and motion models conditioned on these expectable events. Together with a mapper that constructs a semantic spatial map on-the-fly during navigation. we formulate an end-to-end differentiable Bayes filter and train it to identify the goal by predicting the most likely trajectory through the map according to the instructions. The resulting navigation policy constitutes a new approach to instruction following that explicitly models a probability distribution over states. encoding strong geometric and algorithmic priors while enabling greater explainability. Our experiments show that our approach outperforms a strong LingUNet baseline when predicting the goal location on the map. On the full VLN task. ie navigating to the goal location. our approach achieves promising results with less reliance on navigation constraints.,True,r5mA7Q8AAAAJ:r0BpntZqJG4C,19,https://arxiv.org/abs/1907.02022,11914100459452617998,/scholar?cites=11914100459452617998,,,https://arxiv.org/pdf/1907.02022,0,0,0
1282140,Efficient contrast enhancement using adaptive gamma correction with weighting distribution,2012,Shih-Chia Huang and Fan-Chieh Cheng and Yi-Sheng Chiu,22,IEEE transactions on image processing,3,1032-1041,IEEE,This paper proposes an efficient method to modify histograms and enhance contrast in digital images. Enhancement plays a significant role in digital image processing. computer vision. and pattern recognition. We present an automatic transformation technique that improves the brightness of dimmed images via the gamma correction and probability distribution of luminance pixels. To enhance video. the proposed image-enhancement method uses temporal information regarding the differences between each frame to reduce computational complexity. Experimental results demonstrate that the proposed method produces enhanced images of comparable or higher quality than those produced using previous state-of-the-art methods.,True,w9hgfnkAAAAJ:qjMakFHDy7sC,619,https://ieeexplore.ieee.org/abstract/document/6336819/,2627068632982497177,/scholar?cites=2627068632982497177,,,http://viplab.fudan.edu.cn/vip/attachments/download/3404/Efficient_Contrast_Enhancement_Using_Adaptive_Gamma_Correction_With_Weighting_Distribution.pdf,0,0,0
1282141,An advanced motion detection algorithm with video quality analysis for video surveillance systems,2010,Shih-Chia Huang,21,IEEE transactions on circuits and systems for video technology,1,1-14,IEEE,Motion detection is the first essential process in the extraction of information regarding moving objects and makes use of stabilization in functional areas. such as tracking. classification. recognition. and so on. In this paper. we propose a novel and accurate approach to motion detection for the automatic video surveillance system. Our method achieves complete detection of moving objects by involving three significant proposed modules: a background modeling (BM) module. an alarm trigger (AT) module. and an object extraction (OE) module. For our proposed BM module. a unique two-phase background matching procedure is performed using rapid matching followed by accurate matching in order to produce optimum background pixels for the background model. Next. our proposed AT module eliminates the unnecessary examination of the entire background region. allowing the subsequent OE module to only …,True,w9hgfnkAAAAJ:u5HHmVD_uO8C,224,https://ieeexplore.ieee.org/abstract/document/5605242/,11357081544597482367,/scholar?cites=11357081544597482367,,,,0,0,0
1282142,Visibility restoration of single hazy images captured in real-world weather conditions,2014,Shih-Chia Huang and Bo-Hao Chen and Wei-Jheng Wang,24,IEEE Transactions on Circuits and Systems for Video Technology,10,1814-1824,IEEE,The visibility of outdoor images captured in inclement weather is often degraded due to the presence of haze. fog. sandstorms. and so on. Poor visibility caused by atmospheric phenomena in turn causes failure in computer vision applications. such as outdoor object recognition systems. obstacle detection systems. video surveillance systems. and intelligent transportation systems. In order to solve this problem. visibility restoration (VR) techniques have been developed and play an important role in many computer vision applications that operate in various weather conditions. However. removing haze from a single image with a complex structure and color distortion is a difficult task for VR techniques. This paper proposes a novel VR method that uses a combination of three major modules: 1) a depth estimation (DE) module; 2) a color analysis (CA) module; and 3) a VR module. The proposed DE module takes …,True,w9hgfnkAAAAJ:ZHo1McVdvXMC,162,https://ieeexplore.ieee.org/abstract/document/6799227/,2280916890040062244,/scholar?cites=2280916890040062244,,,,0,0,0
1282143,Illumination-sensitive background modeling approach for accurate moving object detection,2011,Fan-Chieh Cheng and Shih-Chia Huang and Shanq-Jang Ruan,57,IEEE Transactions on broadcasting,4,794-801,IEEE,Background subtraction involves generating the background model from the video sequence to detect the foreground and object for many computer vision applications. including traffic security. human-machine interaction. object recognition. and so on. In general. many background subtraction approaches cannot update the current status of the background image in scenes with sudden illumination change. This is especially true in regard to motion detection when light is suddenly switched on or off. This paper proposes an illumination-sensitive background modeling approach to analyze the illumination change and detect moving objects. For the sudden illumination change. an illumination evaluation is used to determine two background candidates. including a light background image and a dark background image. Based on the background model and illumination evaluation. the binary mask of moving objects can …,True,w9hgfnkAAAAJ:9yKSN-GCB0IC,106,https://ieeexplore.ieee.org/abstract/document/5960809/,1065788163445132672,/scholar?cites=1065788163445132672,,,https://www.academia.edu/download/37708066/05960809.pdf,0,0,0
1282144,A genetic-algorithm-based approach to solve carpool service problems in cloud computing,2014,Shih-Chia Huang and Ming-Kai Jiau and Chih-Hsiang Lin,16,IEEE Transactions on intelligent transportation systems,1,352-364,IEEE,Traffic congestion has been a serious problem in many urban areas around the world. Carpooling is one of the most effective solutions to traffic congestion. It consists of increasing the occupancy rate of cars by reducing the empty seats in these vehicles effectively. In this paper. an advanced carpool system is described in detail and called the intelligent carpool system (ICS). which provides carpoolers the use of the carpool services via a smart handheld device anywhere and at any time. The carpool service agency in the ICS is integrated with the abundant geographical. traffic. and societal information and used to manage requests. For help in coordinating the ride matches via the carpool service agency. we apply the genetic algorithm to propose the genetic-based carpool route and matching algorithm (GCRMA) for this multiobjective optimization problem called the carpool service problem (CSP). The experimental …,True,w9hgfnkAAAAJ:cFHS6HbyZ2cC,91,https://ieeexplore.ieee.org/abstract/document/6866900/,3742815280634653254,/scholar?cites=3742815280634653254,,,http://www.ijrdt.org/upload/26023IJRDTVLIS6-5615.pdf,0,0,0
1282145,An efficient visibility enhancement algorithm for road scenes captured by intelligent transportation systems,2014,Shih-Chia Huang and Bo-Hao Chen and Yi-Jui Cheng,15,IEEE Transactions on Intelligent Transportation Systems,5,2321-2332,IEEE,The visibility of images of outdoor road scenes will generally become degraded when captured during inclement weather conditions. Drivers often turn on the headlights of their vehicles and streetlights are often activated. resulting in localized light sources in images capturing road scenes in these conditions. Additionally. sandstorms are also weather events that are commonly encountered when driving in some regions. In sandstorms. atmospheric sand has a propensity to irregularly absorb specific portions of a spectrum. thereby causing color-shift problems in the captured image. Traditional state-of-the-art restoration techniques are unable to effectively cope with these hazy road images that feature localized light sources or color-shift problems. In response. we present a novel and effective haze removal approach to remedy problems caused by localized light sources and color shifts. which thereby achieves …,True,w9hgfnkAAAAJ:zA6iFVUQeVQC,91,https://ieeexplore.ieee.org/abstract/document/6815971/,14388424058470333804,/scholar?cites=14388424058470333804,,,,0,0,0
1282146,Image contrast enhancement for preserving mean brightness without losing image features,2013,Shih-Chia Huang and Chien-Hui Yeh,26,Engineering Applications of Artificial Intelligence,5-6,1487-1492,Pergamon,Histogram equalization is a well-known and effective technique for improving the contrast of images. However. the traditional histogram equalization (HE) method usually results in extreme contrast enhancement. which causes an unnatural look and visual artifacts of the processed image. In this paper. we propose a novel histogram equalization method that is composed of an automatic histogram separation module and an intensity transformation module. First. the proposed histogram separation module is a combination of the proposed prompt multiple thresholding procedure and an optimum peak signal-to-noise ratio (PSNR) calculation to separate the histogram in small-scale detail. As the final step of the proposed process. the use of the intensity transformation module can enhance the image with complete brightness preservation for each generated sub-histogram. Experimental results show that the proposed …,True,w9hgfnkAAAAJ:_FxGoFyzp5QC,86,https://www.sciencedirect.com/science/article/pii/S0952197612003065,9687829734724784893,/scholar?cites=9687829734724784893,,,,0,0,0
1282147,Multimedia services in cloud-based vehicular networks,2015,Ming-Kai Jiau and Shih-Chia Huang and Jenq-Neng Hwang and Athanasios V Vasilakos,7,IEEE Intelligent Transportation Systems Magazine,3,62-79,IEEE,Research into the requirements for mobile services has seen a growing interest in the fields of cloud technology and vehicular applications. Integrating cloud computing and storage with vehicles is a way to increase accessibility to multimedia services. and inspire myriad potential applications and research topics. This paper presents an overview of the characteristics of cloud computing. and introduces the basic concepts of vehicular networks. An architecture for multimedia cloud computing is proposed to suit subscription service mechanisms. The tendency to equip vehicles with advanced and embedded devices such as diverse sensors increases the capabilities of vehicles to provide computation and collection of multimedia content in the form of the vehicular network. Then. the taxonomy of cloud-based vehicular networks is addressed from the standpoint of the service relationship between the cloud computing …,True,w9hgfnkAAAAJ:wbdj-CoPYUoC,78,https://ieeexplore.ieee.org/abstract/document/7166430/,4075346483333517598,/scholar?cites=4075346483333517598,,,,0,0,0
1282148,Efficient contrast enhancement using adaptive gamma correction and cumulative intensity distribution,2011,Yi-Sheng Chiu and Fan-Chieh Cheng and Shih-Chia Huang,,,,2946-2950,IEEE,This paper proposes an efficient histogram modification method for contrast enhancement. which plays a significant role in digital image processing. computer vision. and pattern recognition. We present an automatic transformation technique to improve the brightness of dimmed images based on the gamma correction and probability distribution of the luminance pixel. Experimental results show that the proposed method produces enhanced images of comparable or higher quality than previous state-of-the-art methods.,True,w9hgfnkAAAAJ:zYLM7Y9cAGgC,73,https://ieeexplore.ieee.org/abstract/document/6084119/,17083057170601221152,/scholar?cites=17083057170601221152,,,http://viplab.fudan.edu.cn/vip/attachments/download/3403/Efficient_Contrast_Enhancement_Using_Adaptive_Gamma_Correction_and_Cumulative_Intensity_Distribution.pdf,0,0,0
1282149,An advanced single-image visibility restoration algorithm for real-world hazy scenes,2014,Shih-Chia Huang and Jian-Hui Ye and Bo-Hao Chen,62,IEEE Transactions on Industrial Electronics,5,2962-2972,IEEE,Images captured during sandstorm conditions frequently feature degraded visibility and undesirable color cast effects. In such situations. traditional visibility restoration approaches usually cannot adequately restore images due to poor estimation of haze thickness and the persistence of color cast problems. In this paper. we present a novel Laplacian-based visibility restoration approach to effectively solve inadequate haze thickness estimation and alleviate color cast problems. By doing so. a high-quality image with clear visibility and vivid color can be generated. Experimental results via qualitative and quantitative evaluations demonstrate that the proposed method can dramatically improve images captured during inclement weather conditions and produce results superior to those of other state-of-the-art methods.,True,w9hgfnkAAAAJ:1sJd4Hv_s6UC,65,https://ieeexplore.ieee.org/abstract/document/6936314/,5988546396240065417,/scholar?cites=5988546396240065417,,,,0,0,0
1282150,Highly accurate moving object detection in variable bit rate video-based traffic monitoring systems,2013,Shih-Chia Huang and Bo-Hao Chen,24,IEEE transactions on neural networks and learning systems,12,1920-1931,IEEE,Automated motion detection. which segments moving objects from video streams. is the key technology of intelligent transportation systems for traffic management. Traffic surveillance systems use video communication over real-world networks with limited bandwidth. which frequently suffers because of either network congestion or unstable bandwidth. Evidence supporting these problems abounds in publications about wireless video communication. Thus. to effectively perform the arduous task of motion detection over a network with unstable bandwidth. a process by which bit-rate is allocated to match the available network bandwidth is necessitated. This process is accomplished by the rate control scheme. This paper presents a new motion detection approach that is based on the cerebellar-model-articulation-controller (CMAC) through artificial neural networks to completely and accurately detect moving objects in …,True,w9hgfnkAAAAJ:2P1L_qKh6hAC,63,https://ieeexplore.ieee.org/abstract/document/6557507/,5909738914025519912,/scholar?cites=5909738914025519912,,,,0,0,0
1282151,Convergence of the Lloyd algorithm for computing centroidal Voronoi tessellations,2006,Qiang Du and Maria Emelianenko and Lili Ju,44,SIAM Journal on Numerical Analysis,1,102-119,Society for Industrial and Applied Mathematics,Centroidal Voronoi tessellations (CVTs) are Voronoi tessellations of a bounded geometric domain such that the generating points of the tessellations are also the centroids (mass centers) of the corresponding Voronoi regions with respect to a given density function. Centroidal Voronoi tessellations may also be defined in more abstract and more general settings. Due to the natural optimization properties enjoyed by CVTs. they have many applications in diverse fields. The Lloyd algorithm is one of the most popular iterative schemes for computing the CVTs but its theoretical analysis is far from complete. In this paper. some new analytical results on the local and global convergence of the Lloyd algorithm are presented. These results are derived through careful utilization of the optimization properties shared by CVTs. Numerical experiments are also provided to substantiate the theoretical analysis.,True,JkKUWoAAAAAJ:d1gkVwhDpl0C,327,https://epubs.siam.org/doi/abs/10.1137/040617364,11394523214433051593,/scholar?cites=11394523214433051593,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.4294&rep=rep1&type=pdf,0,0,0
1282152,Constrained centroidal Voronoi tessellations for surfaces,2003,Qiang Du and Max D Gunzburger and Lili Ju,24,SIAM Journal on Scientific Computing,5,1488-1506,Society for Industrial and Applied Mathematics,"Centroidal Voronoi tessellations are useful for subdividing a region in Euclidean space into Voronoi regions whose generators are also the centers of mass. with respect to a prescribed density function. of the regions. Their extensions to general spaces and sets are also available; for example. tessellations of surfaces in a Euclidean space may be considered. In this paper. a precise definition of such constrained centroidal Voronoi tessellations (CCVTs) is given and a number of their properties are derived. including their characterization as minimizers of an ""energy."" Deterministic and probabilistic algorithms for the construction of CCVTs are presented and some analytical results for one of the algorithms are given. Computational examples are provided which serve to illustrate the high quality of CCVT point sets. Finally. CCVT point sets are applied to polynomial interpolation and numerical integration on the sphere.",True,JkKUWoAAAAAJ:u5HHmVD_uO8C,275,https://epubs.siam.org/doi/abs/10.1137/S1064827501391576,12225245010874528085,/scholar?cites=12225245010874528085,,,http://www.personal.psu.edu/users/q/u/qud2/Res/Pre/dgj03sisc.pdf,0,0,0
1282153,Probabilistic methods for centroidal Voronoi tessellations and their parallel implementations,2002,Lili Ju and Qiang Du and Max Gunzburger,28,Parallel Computing,10,1477-1500,North-Holland,Centroidal Voronoi tessellations (CVTs) are Voronoi tessellations of a region such that the generating points of the tessellations are also the centroids of the corresponding Voronoi cells. In this paper. some probabilistic methods for determining CVTs and their parallel implementations on distributed memory systems are presented. By using multi-sampling in a new probabilistic algorithm we introduce. more accurate and efficient approximations of CVTs are obtained without the need to explicit construct Voronoi diagrams. The new algorithm lends itself well to parallelization. i.e.. near prefect linear speed up in the number of processors is achieved. The results of computational experiments performed on a CRAY T3E−600 system are provided which illustrate the superior sequential and parallel performance of the new algorithm when compared to existing algorithms. In particular. for the same amount of work. the new …,True,JkKUWoAAAAAJ:u-x6o8ySG0sC,221,https://www.sciencedirect.com/science/article/pii/S0167819102001515,3347944834120180713,/scholar?cites=3347944834120180713,,,http://test.scripts.psu.edu/users/q/u/qud2/Res/Pre/jdg02para.pdf,0,0,0
1282154,A multiresolution method for climate system modeling: Application of spherical centroidal Voronoi tessellations,2008,Todd Ringler and Lili Ju and Max Gunzburger,58,Ocean Dynamics,5-6,475-498,Springer-Verlag,During the next decade and beyond. climate system models will be challenged to resolve scales and processes that are far beyond their current scope. Each climate system component has its prototypical example of an unresolved process that may strongly influence the global climate system. ranging from eddy activity within ocean models. to ice streams within ice sheet models. to surface hydrological processes within land system models. to cloud processes within atmosphere models. These new demands will almost certainly result in the develop of multiresolution schemes that are able. at least regionally. to faithfully simulate these fine-scale processes. Spherical centroidal Voronoi tessellations (SCVTs) offer one potential path toward the development of a robust. multiresolution climate system model components. SCVTs allow for the generation of high-quality Voronoi diagrams and Delaunay …,True,JkKUWoAAAAAJ:Y0pCki6q_DkC,127,https://link.springer.com/content/pdf/10.1007/s10236-008-0157-2.pdf,9485849431571134466,/scholar?cites=9485849431571134466,,,https://www.osti.gov/servlets/purl/1090845,0,0,0
1282155,Advances in studies and applications of centroidal Voronoi tessellations,2010,Qiang Du and Max Gunzburger and Lili Ju,3,,2,119-142,,Centroidal Voronoi tessellations (CVTs) have become a useful tool in many applications ranging from geometric modeling. image and data analysis. and numerical partial differential equations. to problems in physics. astrophysics. chemistry. and biology. In this paper. we briefly review the CVT concept and a few of its generalizations and well-known properties. We then present an overview of recent advances in both mathematical and computational studies and in practical applications of CVTs. Whenever possible. we point out some outstanding issues that still need investigating.,True,JkKUWoAAAAAJ:YsMSGLbcyi4C,109,http://php.scripts.psu.edu/staff/q/u/qud2/Res/Pre/dgj10nmtma.pdf,10801607028065379758,/scholar?cites=10801607028065379758,,,http://php.scripts.psu.edu/staff/q/u/qud2/Res/Pre/dgj10nmtma.pdf,0,0,0
1282156,Exploring a multiresolution modeling approach within the shallow-water equations,2011,Todd D Ringler and Doug Jacobsen and Max Gunzburger and Lili Ju and Michael Duda and William Skamarock,139,Monthly Weather Review,11,3348-3368,,The ability to solve the global shallow-water equations with a conforming. variable-resolution mesh is evaluated using standard shallow-water test cases. While the long-term motivation for this study is the creation of a global climate modeling framework capable of resolving different spatial and temporal scales in different regions. the process begins with an analysis of the shallow-water system in order to better understand the strengths and weaknesses of the approach developed herein. The multiresolution meshes are spherical centroidal Voronoi tessellations where a single. user-supplied density function determines the region(s) of fine- and coarse-mesh resolution. The shallow-water system is explored with a suite of meshes ranging from quasi-uniform resolution meshes. where the grid spacing is globally uniform. to highly variable resolution meshes. where the grid spacing varies by a factor of 16 between the …,True,JkKUWoAAAAAJ:LkGwnXOMwfcC,105,https://journals.ametsoc.org/view/journals/mwre/139/11/mwr-d-10-05049.1.xml,9312366805847364826,/scholar?cites=9312366805847364826,,,https://journals.ametsoc.org/view/journals/mwre/139/11/mwr-d-10-05049.1.xml,0,0,0
1282157,Efficient linear schemes with unconditional energy stability for the phase field elastic bending energy model,2017,Xiaofeng Yang and Lili Ju,315,Computer Methods in Applied Mechanics and Engineering,,691-712,North-Holland,In this paper. we study efficient numerical schemes of the classical phase field elastic bending energy model that has been widely used to describe the shape deformation of biological lipid vesicles. in which the free energy of the system consists of an elastic bending energy. a surface area constraint and a volume constraint. One major challenge in solving such model numerically is how to design appropriate temporal discretizations in order to preserve energy stability with large time step sizes at the semi-discrete level. We develop a first order and a second order time stepping scheme for this highly nonlinear and stiff parabolic PDE system based on the “Invariant Energy Quadratization” approach. In particular. the resulted semi-discretizations lead to linear systems in space with symmetric positive definite operators at each time step. thus can be efficiently solved. In addition. the proposed schemes are rigorously …,True,JkKUWoAAAAAJ:_xSYboBqXhAC,104,https://www.sciencedirect.com/science/article/pii/S0045782516306016,7800177985542765202,/scholar?cites=7800177985542765202,,,https://people.math.sc.edu/xfyang/Research/Vesicle_CMAME2016.pdf,0,0,0
1282158,Voronoi-based finite volume methods. optimal Voronoi meshes. and PDEs on the sphere,2003,Qiang Du and Max D Gunzburger and Lili Ju,192,Computer Methods in Applied Mechanics and Engineering,35,3933-3957,North-Holland,We first develop and analyze a finite volume scheme for the discretization of partial differential equations (PDEs) on the sphere; the scheme uses Voronoi tessellations of the sphere. For a model convection–diffusion problem. the finite volume scheme is shown to produce first-order accurate approximations with respect to a mesh-dependent discrete first-derivative norm. Then. we introduce the notion of constrained centroidal Voronoi tessellations (CCVTs) of the sphere; these are special Voronoi tessellation of the sphere for which the generators of the Voronoi cells are also the constrained centers of mass. with respect to a prescribed density function. of the cells. After discussing an algorithm for determining CCVT meshes on the sphere. we discuss and illustrate several desirable properties possessed by these meshes. In particular. it is shown that CCVT meshes define very high-quality uniform and non-uniform …,True,JkKUWoAAAAAJ:9yKSN-GCB0IC,98,https://www.sciencedirect.com/science/article/pii/S0045782503003943,4613501798777564396,/scholar?cites=4613501798777564396,,,http://www.personal.psu.edu/~qud2/Res/Pre/dgj03cmame.pdf,0,0,0
1282159,An edge-weighted centroidal Voronoi tessellation model for image segmentation,2009,Jie Wang and Lili Ju and Xiaoqiang Wang,18,IEEE Transactions on Image Processing,8,1844-1858,IEEE,Centroidal Voronoi tessellations (CVTs) are special Voronoi tessellations whose generators are also the centers of mass (centroids) of the Voronoi regions with respect to a given density function and CVT-based methodologies have been proven to be very useful in many diverse applications in science and engineering. In the context of image processing and its simplest form. CVT-based algorithms reduce to the well-known  k  -means clustering and are easy to implement. In this paper. we develop an edge-weighted centroidal Voronoi tessellation (EWCVT) model for image segmentation and propose some efficient algorithms for its construction. Our EWCVT model can overcome some deficiencies possessed by the basic CVT model; in particular. the new model appropriately combines the image intensity information together with the length of cluster boundaries. and can handle very sophisticated situations. We …,True,JkKUWoAAAAAJ:W7OEmFMy1HYC,93,https://ieeexplore.ieee.org/abstract/document/5109687/,7766381604535927979,/scholar?cites=7766381604535927979,,,https://web.imaging.utk.edu/research/traglan4/tasks/task1/references/Segmentation/An%20Edge-Weighted%20Centroidal%20Voronoi%20Tessellation%20Model%20for%20Image%20Segmentation.pdf,0,0,0
1282160,Meshfree. probabilistic determination of point sets and support regions for meshless computing,2002,Qiang Du and Max Gunzburger and Lili Ju,191,Computer Methods in Applied Mechanics and Engineering,13,1349-1366,North-Holland,New algorithms are presented for the determination of point sets and associated support regions that can then be used in meshless computing methods. The algorithms are probabilistic in nature so that they are totally meshfree. i.e.. they do not require. at any stage. the use of any coarse or fine boundary conforming or superimposed meshes. Computational examples are provided that show. for both uniform and non-uniform point distributions. that the algorithms result in high-quality point sets and high-quality support regions. Furthermore. the algorithms lend themselves well to parallelization.,True,JkKUWoAAAAAJ:2osOgNQ5qMEC,93,https://www.sciencedirect.com/science/article/pii/S0045782501003279,466146140315483161,/scholar?cites=466146140315483161,,,http://test.scripts.psu.edu/users/q/u/qud2/Res/Pre/dgj02cmame.pdf,0,0,0
1282161,Linear and unconditionally energy stable schemes for the binary fluid–surfactant phase field model,2017,Xiaofeng Yang and Lili Ju,318,Computer Methods in Applied Mechanics and Engineering,,1005-1029,North-Holland,In this paper. we consider the numerical solution of a binary fluid–surfactant phase field model. in which the free energy contains a nonlinear coupling entropy. a Ginzburg–Landau double well potential. and a logarithmic Flory–Huggins potential. The resulting system consists of two nonlinearly coupled Cahn–Hilliard type equations. We develop a first and a second order time stepping schemes for this system using the “Invariant Energy Quadratization” approach; in particular. the system is transformed into an equivalent one by introducing appropriate auxiliary variables and all nonlinear terms are then treated semi-explicitly. Both schemes are linear and lead to symmetric positive definite systems in space at each time step. thus they can be efficiently solved. We further prove that these schemes are unconditionally energy stable in the discrete sense. Various 2D and 3D numerical experiments are performed to …,True,JkKUWoAAAAAJ:CHSYGLWDkRkC,85,https://www.sciencedirect.com/science/article/pii/S0045782516317856,3905040200250505360,/scholar?cites=3905040200250505360,,,https://arxiv.org/pdf/1701.07446,0,0,0
1282162,Graph attention networks,2017,Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Lio and Yoshua Bengio,,arXiv preprint arXiv:1710.10903,,,,We present graph attention networks (GATs). novel neural network architectures that operate on graph-structured data. leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features. we enable (implicitly) specifying different weights to different nodes in a neighborhood. without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way. we address several key challenges of spectral-based graph neural networks simultaneously. and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora. Citeseer and Pubmed citation network datasets. as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).,True,dEtv5r4AAAAJ:9yKSN-GCB0IC,3580,https://arxiv.org/abs/1710.10903,5609128480281463225,/scholar?cites=5609128480281463225,,,https://arxiv.org/pdf/1710.10903,0,0,0
1282163,Deep pain: Exploiting long short-term memory networks for facial expression classification,2017,Pau Rodriguez and Guillem Cucurull and Jordi Gonzàlez and Josep M Gonfaus and Kamal Nasrollahi and Thomas B Moeslund and F Xavier Roca,,IEEE transactions on cybernetics,,,IEEE,Pain is an unpleasant feeling that has been shown to be an important factor for the recovery of patients. Since this is costly in human resources and difficult to do objectively. there is the need for automatic systems to measure it. In this paper. contrary to current state-of-the-art techniques in pain assessment. which are based on facial features only. we suggest that the performance can be enhanced by feeding the raw frames to deep learning models. outperforming the latest state-of-the-art results while also directly facing the problem of imbalanced data. As a baseline. our approach first uses convolutional neural networks (CNNs) to learn facial features from VGG_Faces. which are then linked to a long short-term memory to exploit the temporal relation between video frames. We further compare the performances of using the so popular schema based on the canonically normalized appearance versus taking into …,True,dEtv5r4AAAAJ:IjCSPb-OGe4C,159,https://ieeexplore.ieee.org/abstract/document/7849133/,8263300559026854568,/scholar?cites=8263300559026854568,,,https://vbn.aau.dk/ws/files/293129334/Deep_Pain_Exploiting_Long_Short_Term_Memory_Networks_for_Facial_Expression_Classification.pdf,0,0,0
1282164,Regularizing cnns with locally constrained decorrelations,2016,Pau Rodríguez and Jordi Gonzalez and Guillem Cucurull and Josep M Gonfaus and Xavier Roca,,arXiv preprint arXiv:1611.01967,,,,Regularization is key for deep learning since it allows training more complex models while keeping lower levels of overfitting. However. the most prevalent regularizations do not leverage all the capacity of the models since they rely on reducing the effective number of parameters. Feature decorrelation is an alternative for using the full capacity of the models but the overfitting reduction margins are too narrow given the overhead it introduces. In this paper. we show that regularizing negatively correlated features is an obstacle for effective decorrelation and present OrthoReg. a novel regularization technique that locally enforces feature orthogonality. As a result. imposing locality constraints in feature decorrelation removes interferences between negatively correlated feature weights. allowing the regularizer to reach higher decorrelation bounds. and reducing the overfitting more effectively. In particular. we show that the models regularized with OrthoReg have higher accuracy bounds even when batch normalization and dropout are present. Moreover. since our regularization is directly performed on the weights. it is especially suitable for fully convolutional neural networks. where the weight space is constant compared to the feature map space. As a result. we are able to reduce the overfitting of state-of-the-art CNNs on CIFAR-10. CIFAR-100. and SVHN.,True,dEtv5r4AAAAJ:u-x6o8ySG0sC,90,https://arxiv.org/abs/1611.01967,3840535160739502869,/scholar?cites=3840535160739502869,,,https://arxiv.org/pdf/1611.01967,0,0,0
1282165,Age and gender recognition in the wild with deep attention,2017,Pau Rodríguez and Guillem Cucurull and Josep M Gonfaus and F Xavier Roca and Jordi Gonzalez,72,Pattern Recognition,,563-571,Pergamon,Face analysis in images in the wild still pose a challenge for automatic age and gender recognition tasks. mainly due to their high variability in resolution. deformation. and occlusion. Although the performance has highly increased thanks to Convolutional Neural Networks (CNNs). it is still far from optimal when compared to other image recognition tasks. mainly because of the high sensitiveness of CNNs to facial variations. In this paper. inspired by biology and the recent success of attention mechanisms on visual question answering and fine-grained recognition. we propose a novel feedforward attention mechanism that is able to discover the most informative and reliable parts of a given face for improving age and gender classification. In particular. given a downsampled facial image. the proposed model is trained based on a novel end-to-end learning framework to extract the most discriminative patches from the …,True,dEtv5r4AAAAJ:d1gkVwhDpl0C,63,https://www.sciencedirect.com/science/article/pii/S0031320317302546,4405277899466558225,/scholar?cites=4405277899466558225,,,https://www.researchgate.net/profile/Jordi_Gonzalez/publication/318084198_Age_and_Gender_Recognition_in_the_Wild_with_Deep_Attention/links/59e9fec9a6fdccef8b08c66b/Age-and-Gender-Recognition-in-the-Wild-with-Deep-Attention.pdf,0,0,0
1282166,Context-aware visual compatibility prediction,2019,Guillem Cucurull and Perouz Taslakian and David Vazquez,,,,12617-12626,,How do we determine whether two or more clothing items are compatible or visually appealing? Part of the answer lies in understanding of visual aesthetics. and is biased by personal preferences shaped by social attitudes. time. and place. In this work we propose a method that predicts compatibility between two items based on their visual features. as well as their context. We define context as the products that are known to be compatible with each of these item. Our model is in contrast to other metric learning approaches that rely on pairwise comparisons between item features alone. We address the compatibility prediction problem using a graph neural network that learns to generate product embeddings conditioned on their context. We present results for two prediction tasks (fill in the blank and outfit compatibility) tested on two fashion datasets Polyvore and Fashion-Gen. and on a subset of the Amazon dataset; we achieve state of the art results when using context information and show how test performance improves as more context is used.,True,dEtv5r4AAAAJ:Tyk-4Ss8FVUC,28,http://openaccess.thecvf.com/content_CVPR_2019/html/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.html,1286153186862259945,/scholar?cites=1286153186862259945,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.pdf,0,0,0
1282167,Attend and rectify: a gated attention mechanism for fine-grained recovery,2018,Pau Rodríguez and Josep M Gonfaus and Guillem Cucurull and F XavierRoca and Jordi Gonzalez,,,,349-364,,We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. It learns to attend to lower-level feature activations without requiring part annotations and uses these activations to update and rectify the output likelihood distribution. In contrast to other approaches. the proposed mechanism is modular. architecture-independent and efficient both in terms of parameters and computation required. Experiments show that networks augmented with our approach systematically improve their classification accuracy and become more robust to clutter. As a result. Wide Residual Networks augmented with our proposal surpasses the state of the art classification accuracies in CIFAR-10. the Adience gender recognition task. Stanford dogs. and UEC Food-100.,True,dEtv5r4AAAAJ:WF5omc3nYNoC,25,http://openaccess.thecvf.com/content_ECCV_2018/html/Pau_Rodriguez_Lopez_Attend_and_Rectify_ECCV_2018_paper.html,13738598675286043975,/scholar?cites=13738598675286043975,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Pau_Rodriguez_Lopez_Attend_and_Rectify_ECCV_2018_paper.pdf,0,0,0
1282168,BigBrain 3D atlas of cortical layers: Cortical and laminar thickness gradients diverge in sensory and motor cortices,2020,Konrad Wagstyl and Stéphanie Larocque and Guillem Cucurull and Claude Lepage and Joseph Paul Cohen and Sebastian Bludau and Nicola Palomero-Gallagher and Lindsay B Lewis and Thomas Funck and Hannah Spitzer and Timo Dickscheid and Paul C Fletcher and Adriana Romero and Karl Zilles and Katrin Amunts and Yoshua Bengio and Alan C Evans,18,PLoS biology,4,e3000678,Public Library of Science,Histological atlases of the cerebral cortex. such as those made famous by Brodmann and von Economo. are invaluable for understanding human brain microstructure and its relationship with functional organization in the brain. However. these existing atlases are limited to small numbers of manually annotated samples from a single cerebral hemisphere. measured from 2D histological sections. We present the first whole-brain quantitative 3D laminar atlas of the human cerebral cortex. It was derived from a 3D histological atlas of the human brain at 20-micrometer isotropic resolution (BigBrain). using a convolutional neural network to segment. automatically. the cortical layers in both hemispheres. Our approach overcomes many of the historical challenges with measurement of histological thickness in 2D. and the resultant laminar atlas provides an unprecedented level of precision and detail. We utilized this BigBrain cortical atlas to test whether previously reported thickness gradients. as measured by MRI in sensory and motor processing cortices. were present in a histological atlas of cortical thickness and which cortical layers were contributing to these gradients. Cortical thickness increased across sensory processing hierarchies. primarily driven by layers III. V. and VI. In contrast. motor-frontal cortices showed the opposite pattern. with decreases in total and pyramidal layer thickness from motor to frontal association cortices. These findings illustrate how this laminar atlas will provide a link between single-neuron morphology. mesoscale cortical layering. macroscopic cortical thickness. and. ultimately. functional neuroanatomy.,True,dEtv5r4AAAAJ:YsMSGLbcyi4C,22,https://journals.plos.org/plosbiology/article?rev=2&id=10.1371/journal.pbio.3000678,12836228446625091838,/scholar?cites=12836228446625091838,,,https://journals.plos.org/plosbiology/article?rev=2&id=10.1371/journal.pbio.3000678,0,0,0
1282169,Pay Attention to the Activations: A Modular Attention Mechanism for Fine-Grained Image Recognition,2020,Pau Rodriguez and Diego Velazquez and Guillem Cucurull and Josep M Gonfaus and E Xavier Roca and Jordi Gonzalez,22,IEEE TRANSACTIONS ON MULTIMEDIA,2,502-514,IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC,Fine-grained image recognition is central to many multimedia tasks such as search. retrieval. and captioning. Unfortunately. these tasks are still challenging since the appearance of samples of the same class can be more different than those from different classes. This issue is mainly due to changes in deformation. pose. and the presence of clutter. In the literature. attention has been one of the most successful strategies to handle the aforementioned problems. Attention has been typically implemented in neural networks by selecting the most informative regions of the image that improve classification. In contrast. in this paper. attention is not applied at the image level but to the convolutional feature activations. In essence. with our approach. the neural model learns to attend to lower-level feature activations without requiring part annotations and uses those activations to update and rectify the output likelihood …,True,dEtv5r4AAAAJ:Y0pCki6q_DkC,17,https://ieeexplore.ieee.org/abstract/document/8762109/,16667256350004377208,/scholar?cites=16667256350004377208,,,https://arxiv.org/pdf/1907.13075,0,0,0
1282170,On the iterative refinement of densely connected representation levels for semantic segmentation,2018,Arantxa Casanova and Guillem Cucurull and Michal Drozdzal and Adriana Romero and Yoshua Bengio,,,,978-987,,State-of-the-art semantic segmentation approaches increase the receptive field of their models by using either a downsampling path composed of poolings/strided convolutions or successive dilated convolutions. However. it is not clear which operation leads to best results. In this paper. we systematically study the differences introduced by distinct receptive field enlargement methods and their impact on the performance of a novel architecture. called Fully Convolutional DenseResNet (FC-DRN). FC-DRN has a densely connected backbone composed of residual networks. Following standard image segmentation architectures. receptive field enlargement operations that change the representation level are interleaved among residual networks. This allows the model to exploit the benefits of both residual and dense connectivity patterns. namely: gradient flow. iterative refinement of representations. multi-scale feature combination and deep supervision. In order to highlight the potential of our model. we test it on the challenging CamVid urban scene understanding benchmark and make the following observations: 1) downsampling operations outperform dilations when the model is trained from scratch. 2) dilations are useful during the finetuning step of the model. 3) coarser representations require less refinement steps. and 4) ResNets (by model construction) are good regularizers. since they can reduce the model capacity when needed. Finally. we compare our architecture to alternative methods and report state-of-the-art result on the Camvid dataset. with at least twice fewer parameters.,True,dEtv5r4AAAAJ:u5HHmVD_uO8C,17,http://openaccess.thecvf.com/content_cvpr_2018_workshops/w14/html/Casanova_On_the_Iterative_CVPR_2018_paper.html,1805387520703647023,/scholar?cites=1805387520703647023,,,http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w14/Casanova_On_the_Iterative_CVPR_2018_paper.pdf,0,0,0
1282171,Convolutional neural networks for mesh-based parcellation of the cerebral cortex,2018,Guillem Cucurull and Konrad Wagstyl and Arantxa Casanova and Petar Veličković and Estrid Jakobsen and Michal Drozdzal and Adriana Romero and Alan Evans and Yoshua Bengio,,,,,,In order to understand the organization of the cerebral cortex. it is necessary to create a map or parcellation of cortical areas. Reconstructions of the cortical surface created from structural MRI scans. are frequently used in neuroimaging as a common coordinate space for representing multimodal neuroimaging data. These meshes are used to investigate healthy brain organization as well as abnormalities in neurological and psychiatric conditions. We frame cerebral cortex parcellation as a mesh segmentation task. and address it by taking advantage of recent advances in generalizing convolutions to the graph domain. In particular. we propose to assess graph convolutional networks and graph attention networks. which. in contrast to previous mesh parcellation models. exploit the underlying structure of the data to make predictions. We show experimentally on the Human Connectome Project dataset that the proposed graph convolutional models outperform current state-of-the-art and baselines. highlighting the potential and applicability of these methods to tackle neuroimaging challenges. paving the road towards a better characterization of brain diseases.,True,dEtv5r4AAAAJ:UeHWp8X0CEIC,14,https://openreview.net/forum?id=rkKvBAiiz,7849218969583241809,/scholar?cites=7849218969583241809,,,https://openreview.net/pdf?id=rkKvBAiiz,0,0,0
1282172,Automated segmentation of cortical layers in BigBrain reveals divergent cortical and laminar thickness gradients in sensory and motor cortices,2019,Konrad Wagstyl and Stéphanie Larocque and Guillem Cucurull and Claude Lepage and Joseph Paul Cohen and Sebastian Bludau and Nicola Palomero-Gallagher and Thomas Funck and Hannah Spitzer and Timo Dicksheid and Paul C Fletcher and Adriana Romero and Karl Zilles and Katrin Amunts and Yoshua Bengio and Alan C Evans,,bioRxiv,,580597,Cold Spring Harbor Laboratory,Large-scale in vivo neuroimaging datasets offer new possibilities for reliable. well-powered measures of interregional structural differences and biomarkers of pathological changes in a wide variety of neurological and psychiatric diseases. However. so far studies have been structurally and functionally imprecise. being unable to relate pathological changes to specific cortical layers or neurobiological processes. We developed artificial neural networks to segment cortical and laminar surfaces in the BigBrain. a 3D histological model of the human brain. We sought to test whether previously-reported thickness gradients. as measured by MRI. in sensory and motor processing cortices. were present in a histological atlas of cortical thickness. and which cortical layers were contributing to these gradients. Identifying common gradients of cortical organisation enables us to meaningfully relate microstructural. macrostructural and functional cortical parameters.Analysis of thickness gradients across sensory cortices. using our fully segmented six-layered model. was consistent with MRI findings. showing increasing thickness moving up the processing hierarchy. In contrast. fronto-motor cortices showed the opposite pattern with changes in thickness of layers III. V and VI being the primary drivers of these gradients. As well as identifying key differences between sensory and motor gradients. our findings show how the use of this laminar atlas offers insights that will be key to linking single-neuron morphological changes. mesoscale cortical layers and macroscale cortical thickness.,True,dEtv5r4AAAAJ:W7OEmFMy1HYC,6,https://www.biorxiv.org/content/10.1101/580597v2.full-text,8127714773894862673,/scholar?cites=8127714773894862673,,,https://www.biorxiv.org/content/10.1101/580597v2.full-text,0,0,0
1282173,A large-scale model of the functioning brain,2012,Chris Eliasmith and Terrence C Stewart and Xuan Choo and Trevor Bekolay and Travis DeWolf and Yichuan Tang and Daniel Rasmussen,338,science,6111,1202-1205,American Association for the Advancement of Science,A central challenge for cognitive and systems neuroscience is to relate the incredibly complex behavior of animals to the equally complex activity of their brains. Recently described. large-scale neural models have not bridged this gap between neural activity and biological function. In this work. we present a 2.5-million-neuron model of the brain (called “Spaun”) that bridges this gap by exhibiting many different behaviors. The model is presented only with visual image sequences. and it draws all of its responses with a physically modeled arm. Although simplified. the model captures many aspects of neuroanatomy. neurophysiology. and psychological behavior. which we demonstrate via eight diverse tasks.,True,aka4LuAAAAAJ:u5HHmVD_uO8C,816,https://science.sciencemag.org/content/338/6111/1202.abstract,13785812527754963458,/scholar?cites=13785812527754963458,,,http://clm.utexas.edu/compjclub/papers/Eliasmith2012.pdf,0,0,0
1282174,Deep learning using linear support vector machines,2013,Yichuan Tang,,arXiv preprint arXiv:1306.0239,,,,"Recently. fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition. image classification. natural language processing. and bioinformatics. For classification tasks. most of these"" deep learning"" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper. we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art. our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST. CIFAR-10. and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.",True,aka4LuAAAAAJ:u-x6o8ySG0sC,798,https://arxiv.org/abs/1306.0239,15737743364903648230,/scholar?cites=15737743364903648230,,,https://arxiv.org/pdf/1306.0239,0,0,0
1282175,Challenges in representation learning: A report on three machine learning contests,2013,Ian J Goodfellow and Dumitru Erhan and Pierre Luc Carrier and Aaron Courville and Mehdi Mirza and Ben Hamner and Will Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee and Yingbo Zhou and Chetan Ramaiah and Fangxiang Feng and Ruifan Li and Xiaojie Wang and Dimitris Athanasakis and John Shawe-Taylor and Maxim Milakov and John Park and Radu Ionescu and Marius Popescu and Cristian Grozea and James Bergstra and Jingjing Xie and Lukasz Romaszko and Bing Xu and Zhang Chuang and Yoshua Bengio,,,,117-124,Springer. Berlin. Heidelberg,The ICML 2013 Workshop on Challenges in Representation Learning focused on three challenges: the black box learning challenge. the facial expression recognition challenge. and the multimodal learning challenge. We describe the datasets created for these challenges and summarize the results of the competitions. We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions.,True,aka4LuAAAAAJ:qjMakFHDy7sC,721,https://link.springer.com/chapter/10.1007/978-3-642-42051-1_16,8616805753242216943,/scholar?cites=8616805753242216943,,,https://arxiv.org/pdf/1307.0414,0,0,0
1282176,Challenges in representation learning: A report on three machine learning contests,2013,Ian J Goodfellow and Dumitru Erhan and Pierre Luc Carrier and Aaron Courville and Mehdi Mirza and Ben Hamner and Will Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee and Yingbo Zhou and Chetan Ramaiah and Fangxiang Feng and Ruifan Li and Xiaojie Wang and Dimitris Athanasakis and John Shawe-Taylor and Maxim Milakov and John Park and Radu Ionescu and Marius Popescu and Cristian Grozea and James Bergstra and Jingjing Xie and Lukasz Romaszko and Bing Xu and Zhang Chuang and Yoshua Bengio,,,,117-124,Springer. Berlin. Heidelberg,The ICML 2013 Workshop on Challenges in Representation Learning focused on three challenges: the black box learning challenge. the facial expression recognition challenge. and the multimodal learning challenge. We describe the datasets created for these challenges and summarize the results of the competitions. We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions.,True,aka4LuAAAAAJ:eQOLeE2rZwMC,716,https://link.springer.com/chapter/10.1007/978-3-642-42051-1_16,8616805753242216943,/scholar?cites=8616805753242216943,,,https://arxiv.org/pdf/1307.0414,0,0,0
1282177,Robust boltzmann machines for recognition and denoising,2012,Yichuan Tang and Ruslan Salakhutdinov and Geoffrey Hinton,,,,2264-2271,IEEE,While Boltzmann Machines have been successful at unsupervised learning and density modeling of images and speech data. they can be very sensitive to noise in the data. In this paper. we introduce a novel model. the Robust Boltzmann Machine (RoBM). which allows Boltzmann Machines to be robust to corruptions. In the domain of visual recognition. the RoBM is able to accurately deal with occlusions and noise by using multiplicative gating to induce a scale mixture of Gaussians over pixels. Image denoising and in-painting correspond to posterior inference in the RoBM. Our model is trained in an unsupervised fashion with unlabeled noisy data and can learn the spatial structure of the occluders. Compared to standard algorithms. the RoBM is significantly better at recognition and denoising on several face databases.,True,aka4LuAAAAAJ:d1gkVwhDpl0C,186,https://ieeexplore.ieee.org/abstract/document/6247936/,1550782262241352453,/scholar?cites=1550782262241352453,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.9000&rep=rep1&type=pdf,0,0,0
1282178,Deep learning using support vector machines,2013,Yichuan Tang,2,"CoRR, abs/1306.0239",,,,Recently. fully-connected and convolutional neural networks have been trained to reach state-of-the-art performance on a wide variety of tasks such as speech recognition. image classification. natural language processing. and bioinformatics data. For classification tasks. much of these “deep learning” models employ the softmax activation functions to learn output labels in 1-of-K format. In this paper. we demonstrate a small but consistent advantage of replacing softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. In almost all of the previous works. hidden representation of deep networks are first learned using supervised or unsupervised techniques. and then are fed into SVMs as inputs. In contrast to those models. we are proposing to train all layers of the deep networks by backpropagating gradients through the top level SVM. learning features of all layers. Our experiments show that simply replacing softmax with linear SVMs gives significant gains on datasets MNIST. CIFAR-10. and the ICML 2013 Representation Learning Workshop’s face expression recognition challenge.,True,aka4LuAAAAAJ:KlAtU1dfN6UC,167,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1080.396&rep=rep1&type=pdf,15796176624514815568,/scholar?cites=15796176624514815568,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1080.396&rep=rep1&type=pdf,0,0,0
1282179,Learning stochastic feedforward neural networks,2013,Charlie Tang and Russ R Salakhutdinov,,,,530-538,,Multilayer perceptrons (MLPs) or neural networks are popular models used for nonlinear regression and classification tasks. As regressors. MLPs model the conditional distribution of the predictor variables Y given the input variables X. However. this predictive distribution is assumed to be unimodal (eg Gaussian). For tasks involving structured prediction. the conditional distribution should be multi-modal. resulting in one-to-many mappings. By using stochastic hidden variables rather than deterministic ones. Sigmoid Belief Nets (SBNs) can induce a rich multimodal distribution in the output space. However. previously proposed learning algorithms for SBNs are not efficient and unsuitable for modeling real-valued data. In this paper. we propose a stochastic feedforward network with hidden layers composed of both deterministic and stochastic variables. A new Generalized EM training procedure using importance sampling allows us to efficiently learn complicated conditional distributions. Our model achieves superior performance on synthetic and facial expressions datasets compared to conditional Restricted Boltzmann Machines and Mixture Density Networks. In addition. the latent features of our model improves classification and can learn to generate colorful textures of objects.,True,aka4LuAAAAAJ:2osOgNQ5qMEC,126,https://www.cs.cmu.edu/~rsalakhu/papers/sfnn.pdf,1525066280497987731,/scholar?cites=1525066280497987731,,,https://www.cs.cmu.edu/~rsalakhu/papers/sfnn.pdf,0,0,0
1282180,Deep networks for robust visual recognition,2010,Yichuan Tang and Chris Eliasmith,,,,,,Deep Belief Networks (DBNs) are hierarchical generative models which have been used successfully to model high dimensional visual data. However. they are not robust to common variations such as occlusion and random noise. We explore two strategies for improving the robustness of DBNs. First. we show that a DBN with sparse connections in the first layer is more robust to variations that are not in the training set. Second. we develop a probabilistic denoising algorithm to determine a subset of the hidden layer nodes to unclamp. We show that this can be applied to any feedforward network classifier with localized first layer connections. Recognition results after denoising are significantly better over the standard DBN implementations for various sources of noise.,True,aka4LuAAAAAJ:9yKSN-GCB0IC,116,https://openreview.net/forum?id=SJWyFiWdbH,718679269502871855,/scholar?cites=718679269502871855,,,https://openreview.net/pdf?id=SJWyFiWdbH,0,0,0
1282181,Learning generative models with visual attention,2013,Yichuan Tang and Nitish Srivastava and Ruslan Salakhutdinov,,arXiv preprint arXiv:1312.6110,,,,Attention has long been proposed by psychologists as important for effectively dealing with the enormous sensory stimulus available in the neocortex. Inspired by the visual attention models in computational neuroscience and the need of object-centric data for generative models. we describe for generative learning framework using attentional mechanisms. Attentional mechanisms can propagate signals from region of interest in a scene to an aligned canonical representation. where generative modeling takes place. By ignoring background clutter. generative models can concentrate their resources on the object of interest. Our model is a proper graphical model where the 2D Similarity transformation is a part of the top-down process. A ConvNet is employed to provide good initializations during posterior inference which is based on Hamiltonian Monte Carlo. Upon learning images of faces. our model can robustly attend to face regions of novel test subjects. More importantly. our model can learn generative models of new faces from a novel dataset of large images where the face locations are not known.,True,aka4LuAAAAAJ:IjCSPb-OGe4C,87,https://arxiv.org/abs/1312.6110,10397446431025745719,/scholar?cites=10397446431025745719,,,https://arxiv.org/pdf/1312.6110,0,0,0
1282182,Deep lambertian networks,2012,Yichuan Tang and Ruslan Salakhutdinov and Geoffrey Hinton,,arXiv preprint arXiv:1206.6445,,,,Visual perception is a challenging problem in part due to illumination variations. A possible solution is to first estimate an illumination invariant representation before using it for recognition. The object albedo and surface normals are examples of such representations. In this paper. we introduce a multilayer generative model where the latent variables include the albedo. surface normals. and the light source. Combining Deep Belief Nets with the Lambertian reflectance assumption. our model can learn good priors over the albedo from 2D images. Illumination variations can be explained by changing only the lighting latent variable in our model. By transferring learned knowledge from similar objects. albedo and surface normals estimation from a single image is possible in our model. Experiments demonstrate that our model is able to generalize as well as improve over standard baselines in one-shot face recognition.,True,aka4LuAAAAAJ:YsMSGLbcyi4C,86,https://arxiv.org/abs/1206.6445,3507484024351649261,/scholar?cites=3507484024351649261,,,https://arxiv.org/pdf/1206.6445,0,0,0
1282183,Multiple futures prediction,2019,Yichuan Charlie Tang and Ruslan Salakhutdinov,,arXiv preprint arXiv:1911.00997,,,,Temporal prediction is critical for making intelligent and robust decisions in complex dynamic environments. Motion prediction needs to model the inherently uncertain future which often contains multiple potential outcomes. due to multi-agent interactions and the latent goals of others. Towards these goals. we introduce a probabilistic framework that efficiently learns latent variables to jointly model the multi-step future motions of agents in a scene. Our framework is data-driven and learns semantically meaningful latent variables to represent the multimodal future. without requiring explicit labels. Using a dynamic attention-based state encoder. we learn to encode the past as well as the future interactions among agents. efficiently scaling to any number of agents. Finally. our model can be used for planning via computing a conditional probability density over the trajectories of other agents given a hypothetical rollout of the'self'agent. We demonstrate our algorithms by predicting vehicle trajectories of both simulated and real data. demonstrating the state-of-the-art results on several vehicle trajectory datasets.,True,aka4LuAAAAAJ:ULOm3_A8WrAC,84,https://arxiv.org/abs/1911.00997,13314964675169531830,/scholar?cites=13314964675169531830,,,https://arxiv.org/pdf/1911.00997,0,0,0
1282184,High voltage generation and regulation system for digital multilevel nonvolatile memory,2005,William John Saiki and Hieu Van Tran and Sakhawat M Khan,,,,,,A high voltage generator provides high voltage signals with different regulated voltage levels. A charge pump generates the high voltage. and includes a quadrature phase forward and backward Vt-canceling high-voltage self-biasing charge pump with a powerup-assist diode. A high voltage series regulator generates the high voltage supply levels. and includes slew rate enhancement and trimmable diode regulation. A nested loop regulator eliminates shunt regulation.,True,1xBeHbAAAAAJ:ZuybSZzF8UAC,247,https://patents.google.com/patent/US6867638B2/en,16903756833154619088,/scholar?cites=16903756833154619088,,,https://patentimages.storage.googleapis.com/84/51/9f/6cd294de883e5d/US6867638.pdf,0,0,0
1282185,Array architecture and operating methods for digital multilevel nonvolatile memory integrated circuit system,2001,Hieu Van Tran and Sakhawat M Khan and George J Korsh,,,,,,Memory array architectures and operating methods suitable for super high density in the giga bits for multilevel nonvolatile memory integrated circuit system. The array architectures and operating methods include:(1) an Inhibit and Select Segmentation Scheme;(2) a Multilevel Memory Decoding Scheme that includes a Power Supply Decoded Decoding Scheme. a Feedthrough-to-Memory Decoding Scheme. a Feedthrough-to-Driver Decoding Scheme. and a Winner-Take-All Kelvin Memory Decoding Scheme;(3) a constant-total-current-program scheme;(4) includes fast-slow and 2-step ramp rate control programming; and a reference system method and apparatus. which includes a Positional Linear Reference System. a Positional Geometric Reference System. and a Geometric Compensation Reference System. The apparatus and method enable multilevel programming. reading. and margining.,True,1xBeHbAAAAAJ:IWHjjKOFINEC,133,https://patents.google.com/patent/US6282145B1/en,4204111354332207034,/scholar?cites=4204111354332207034,,,https://patentimages.storage.googleapis.com/96/62/8e/a6ba8cd5de0c2b/US6282145.pdf,0,0,0
1282186,Multistage autozero sensing for a multilevel non-volatile memory integrated circuit system,2005,Hieu Van Tran,,,,,,A digital multibit non-volatile memory integrated system includes autozero multistage sensing. One stage may provide local sensing with autozero. Another stage may provide global sensing with autozero. A twisted bitline may be used for array arrangement. Segment reference may be used for each segment. The system may read data cells using a current sensing one or two step binary search. The system may use inverse voltage mode or inverse current mode sensing. The system may use no current multilevel sensing. The system may use memory cell replica sensing. The system may use dynamic sensing. The system may use built-in byte redundancy. Sense amplifiers capable of sub-volt (<< 1V) sensing are described.,True,1xBeHbAAAAAJ:-f6ydRqryjwC,123,https://patents.google.com/patent/US6956779B2/en,4389190728164331822,/scholar?cites=4389190728164331822,,,https://patentimages.storage.googleapis.com/76/48/2f/c48112468e4abb/US6956779.pdf,0,0,0
1282187,Digital multilevel memory system having multistage autozero sensing,2006,Hieu Van Tran,,,,,,A digital multibit non-volatile memory integrated system includes autozero multistage sensing. One stage may provide local sensing with autozero. Another stage may provide global sensing with autozero. A twisted bitline may be used for array arrangement. Segment reference may be used for each segment. The system may read data cells using a current sensing one or two step binary search. The system may use inverse voltage mode or inverse current mode sensing. The system may use no current multilevel sensing. The system may use memory cell replica sensing. The system may use dynamic sensing. The system may use built-in byte redundancy. Sense amplifiers capable of sub-volt (<< 1V) sensing are described.,True,1xBeHbAAAAAJ:nb7KW1ujOQ8C,120,https://patents.google.com/patent/US7031214B2/en,11854204724449708001,/scholar?cites=11854204724449708001,,,https://patentimages.storage.googleapis.com/69/2a/89/b8b97bb6fc46d5/US7031214.pdf,0,0,0
1282188,Systems and methods of non-volatile memory sensing including selective/differential threshold voltage features,2013,Hieu Van Tran and Samar Saha,,,,,,Systems and methods are disclosed for providing selective threshold voltage characteristics via use of MOS transistors having differential threshold voltages. In one exemplary embodiment. there is provided a metal oxide semiconductor device comprising a substrate of semiconductor material having a source region. a drain region and a channel region therebetween. an insulating layer over the channel region. and a gate portion of the insulating layer. Moreover. with regard to the device. the shape of the insulating layer and/or the shape or implantation of a junction region are of varied dimension as between the gate-to-drain and gate-to-source junctions to provide differential threshold voltages between them.,True,1xBeHbAAAAAJ:tS2w5q8j5-wC,112,https://patents.google.com/patent/US8385147B2/en,13104763787414046950,/scholar?cites=13104763787414046950,,,https://patentimages.storage.googleapis.com/73/ee/0e/a66dddafc0106a/US8385147.pdf,0,0,0
1282189,Testing of multilevel semiconductor memory,2002,George J Korsh and Sakhawat M Khan and Hieu Van Tran,,,,,,In accordance with an embodiment of the present invention. a method for testing a multilevel memory includes: performing an erase operation to place a plurality of memory cells in an erased state; programming a state of each cell in a group of the plurality of cells to within a first range of voltages; if a state of each of one or more of the cells in the group of cells does not verify to within the first range of voltages. identifying at least the one or more cells as failing; and if a state of each cell in the group of cells verifies to within the first range of voltages: applying a predetermined number of programming pulses to further program the state of each cell in the group of cells to within a second range of voltages; and verifying whether a state of each cell in the group of cells is programmed beyond the second range of voltages.,True,1xBeHbAAAAAJ:0EnyYjriUFMC,110,https://patents.google.com/patent/US6396742B1/en,2284018857901819158,/scholar?cites=2284018857901819158,,,https://patentimages.storage.googleapis.com/fa/42/c1/6053ae1e425edf/US6396742.pdf,0,0,0
1282190,Array architecture and operating methods for digital multilevel nonvolatile memory integrated circuit system,2003,Hieu Van Tran and Sakhawat M Khan and George J Korsh,,,,,,Memory array architectures and operating methods suitable for super high density in the giga bits for multilevel nonvolatile memory integrated circuit system. The array architectures and operating methods include:(1) an Inhibit and Select Segmentation Scheme;(2) a Multilevel Memory Decoding Scheme that includes a Power Supply Decoded Decoding Scheme. a Feedthrough-to-Memory Decoding Scheme. a Feedthrough-to-Driver Decoding Scheme. and a Winner-Take-All Kelvin Memory Decoding Scheme;(3) a constant-total-current-program scheme;(4) includes fast-slow and 2-step ramp rate control programming; and a reference system method and apparatus. which includes a Positional Linear Reference System. a Positional Geometric Reference System. and a Geometric Compensation Reference System. The apparatus and method enable multilevel programming. reading. and margining.,True,1xBeHbAAAAAJ:yD5IFk8b50cC,108,https://patents.google.com/patent/US6519180B2/en,10164368330729106330,/scholar?cites=10164368330729106330,,,https://patentimages.storage.googleapis.com/8d/e3/75/67aec37ed7bb0d/US6519180.pdf,0,0,0
1282191,Digital multilevel non-volatile memory system,2005,Hieu Van Tran,,,,,,A digital multibit non-volatile memory integrated system includes autozero multistage sensing. One stage may provide local sensing with autozero. Another stage may provide global sensing with autozero. A twisted bitline may be used for array arrangement. Segment reference may be used for each segment. The system may read data cells using a current sensing one or two step binary search. The system may use inverse voltage mode or inverse current mode sensing. The system may use no current multilevel sensing. The system may use memory cell replica sensing. The system may use dynamic sensing. The system may use built-in byte redundancy. Sense amplifiers capable of sub-volt (<< 1V) sensing are described.,True,1xBeHbAAAAAJ:7T2F9Uy0os0C,104,https://patents.google.com/patent/US6975539B2/en,18249661459445942420,/scholar?cites=18249661459445942420,,,https://patentimages.storage.googleapis.com/99/4d/76/3a6f266e595126/US6975539.pdf,0,0,0
1282192,Wide dynamic range and high speed voltage mode sensing for a multilevel digital non-volatile memory,2008,Hieu Van Tran and Sakhawat M Khan,,,,,,A high speed voltage mode sensing is provided for a digital multibit non-volatile memory integrated system. An embodiment has a local source follower stage followed by a high speed common source stage. Another embodiment has a local source follower stage followed by a high speed source follower stage. Another embodiment has a common source stage followed by a source follower. An auto zeroing scheme is used. A capacitor sensing scheme is used. Multilevel parallel operation is described.,True,1xBeHbAAAAAJ:blknAaTinKkC,84,https://patents.google.com/patent/US7471581B2/en,6823715032125707235,/scholar?cites=6823715032125707235,,,https://patentimages.storage.googleapis.com/40/88/65/2a00d498a18ebe/US7471581.pdf,0,0,0
1282193,Method and apparatus for analog reading values stored in floating gate structures,1998,Hieu Van Tran and James Brennan Jr and Trevor Blyth and Sukyoon Yoon,,,,,,This invention utilizes the small cell size of the NAND storage cell structure in an analog storage and playback device. This is achieved. in part. by using a special. zero current storage cell. in which in the read mode. the cell loading current is waveshaped to attain an optimal dynamic range and to avoid the resistive effects of series parasitic resistances of other transistors in the source node or drain node. and to avoid the transistor conductance variations of all the transistors in the read path. The loading current is waveshaped to reduce possible overshoot and settling effects to achieve the fine output voltage resolution in an optimal sensing time. Details of the method and alternate embodiments are disclosed.,True,1xBeHbAAAAAJ:roLk4NBRz8UC,74,https://patents.google.com/patent/US5726934A/en,1990229975073524444,/scholar?cites=1990229975073524444,,,https://patentimages.storage.googleapis.com/9a/d8/8f/dfba7cbbed988d/US5726934.pdf,0,0,0
1282194,Seek window verify program system and method for a multilevel non-volatile memory integrated circuit system,2006,Hieu Van Tran and Hung Q Nguyen and Amitay Levi and Isao Nojima,,,,,,A memory comprises a plurality of digital multilevel memory cells. A window of valid data voltages for accessing the said plurality of digital multilevel memory cells is detected. The window may be detected by incrementing a first programming voltage to program data in the plurality of memory cells and verifying whether the data in at least one of said plurality of memory cells is properly programmed. The incrementing and verifying may be repeated until data is verified to be properly programmed in one of said plurality of memory cells. The data in each memory cell of said plurality of memory cells is verified. The verification may be by incrementing a second programming voltage. and verifying whether data in each memory cell is properly programmed within a margin. The incrementing and verifying is repeated for each memory cell outside of the margin.,True,1xBeHbAAAAAJ:Tiz5es2fbqcC,69,https://patents.google.com/patent/US7149110B2/en,12735895616784551004,/scholar?cites=12735895616784551004,,,https://patentimages.storage.googleapis.com/b7/5e/e9/21fb11fbb1e041/US7149110.pdf,0,0,0
1282195,YFCC100M: The New Data in Multimedia Research,2016,Bart Thomee and Benjamin Elizalde and David A Shamma and Karl Ni and Gerald Friedland and Douglas Poland and Damian Borth and Li-Jia Li,59,Communications of the ACM,2,64-73,ACM,This publicly available curated dataset of almost 100 million photos and videos is free and legal for all.,True,J-8Z038AAAAJ:6ZxmRoH8BuwC,840,https://dl.acm.org/doi/abs/10.1145/2812802,14043864602427315927,/scholar?cites=14043864602427315927,,,https://dl.acm.org/doi/pdf/10.1145/2812802,0,0,0
1282196,Large-scale Visual Sentiment Ontology and Detectors using Adjective Noun Pairs,2013,Damian Borth and Rongrong Ji and Tao Chen and Thomas Breuel and Shih-Fu Chang,,,,223-232,ACM,We address the challenge of sentiment analysis from visual content. In contrast to existing methods which infer sentiment or emotion directly from visual low-level features. we propose a novel approach based on understanding of the visual concepts that are strongly related to sentiments. Our key contribution is two-fold: first. we present a method built upon psychological theories and web mining to automatically construct a large-scale Visual Sentiment Ontology (VSO) consisting of more than 3.000 Adjective Noun Pairs (ANP). Second. we propose SentiBank. a novel visual concept detector library that can be used to detect the presence of 1.200 ANPs in an image. The VSO and SentiBank are distinct from existing work and will open a gate towards various applications enabled by automatic sentiment analysis. Experiments on detecting sentiment of image tweets demonstrate significant improvement in detection …,True,J-8Z038AAAAJ:Se3iqnhoufwC,585,https://dl.acm.org/doi/abs/10.1145/2502081.2502282,12383518950832285515,/scholar?cites=12383518950832285515,,,http://www.ee.columbia.edu/ln/dvmm/publications/13/visual_sentiment_ontology_final.pdf,0,0,0
1282197,The New Data and New Challenges in Multimedia Research,2015,Bart Thomee and David A Shamma and Gerald Friedland and Benjamin Elizalde and Karl Ni and Douglas Poland and Damian Borth and Li-Jia Li,,arXiv preprint arXiv:1503.01817,,,,We present the Yahoo Flickr Creative Commons 100 Million Dataset (YFCC100M). the largest public multimedia collection that has ever been released. The dataset contains a total of 100 million media objects. of which approximately 99.2 million are photos and 0.8 million are videos. all of which carry a Creative Commons license. Each media object in the dataset is represented by several pieces of metadata. eg Flickr identifier. owner name. camera. title. tags. geo. media source. The collection provides a comprehensive snapshot of how photos and videos were taken. described. and shared over the years. from the inception of Flickr in 2004 until early 2014. In this article we explain the rationale behind its creation. as well as the implications the dataset has for science. research. engineering. and development. We further present several new challenges in multimedia research that can now be expanded upon with our dataset.,True,J-8Z038AAAAJ:LO7wyVUgiFcC,274,https://www.researchgate.net/profile/David-Shamma/publication/273327809_The_New_Data_and_New_Challenges_in_Multimedia_Research/links/5741fc1508aea45ee84a35f7/The-New-Data-and-New-Challenges-in-Multimedia-Research.pdf,4354016429651667158,/scholar?cites=4354016429651667158,,,https://www.researchgate.net/profile/David-Shamma/publication/273327809_The_New_Data_and_New_Challenges_in_Multimedia_Research/links/5741fc1508aea45ee84a35f7/The-New-Data-and-New-Challenges-in-Multimedia-Research.pdf,0,0,0
1282198,DeepSentibank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks,2014,Tao Chen and Damian Borth and Trevor Darrell and Shih-Fu Chang,,arXiv preprint arXiv:1410.8586,,,,This paper introduces a visual sentiment concept classification method based on deep convolutional neural networks (CNNs). The visual sentiment concepts are adjective noun pairs (ANPs) automatically discovered from the tags of web photos. and can be utilized as effective statistical cues for detecting emotions depicted in the images. Nearly one million Flickr images tagged with these ANPs are downloaded to train the classifiers of the concepts. We adopt the popular model of deep convolutional neural networks which recently shows great performance improvement on classifying large-scale web-based image dataset such as ImageNet. Our deep CNNs model is trained based on Caffe. a newly developed deep learning framework. To deal with the biased training data which only contains images with strong sentiment and to prevent overfitting. we initialize the model with the model weights trained from ImageNet. Performance evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called DeepSentiBank) is significantly improved in both annotation accuracy and retrieval performance. compared to its predecessors which mainly use binary SVM classification models.,True,J-8Z038AAAAJ:4fGpz3EwCPoC,263,https://arxiv.org/abs/1410.8586,14312756787450920194,/scholar?cites=14312756787450920194,,,https://arxiv.org/pdf/1410.8586,0,0,0
1282199,The data on diversity,2014,Beryl Nelson,57,,11,86-95,ACM,It's not just about being fair.,True,J-8Z038AAAAJ:yqoGN6RLRZoC,216,https://dl.acm.org/doi/abs/10.1145/2597886,15797128436216543370,/scholar?cites=15797128436216543370,,,https://dl.acm.org/doi/pdf/10.1145/2597886,0,0,0
1282200,Eurosat: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification,2019,Patrick Helber and Benjamin Bischke and Andreas Dengel and Damian Borth,12,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,7,2217-2226,IEEE,In this paper. we present a patch-based land use and land cover classification approach using Sentinel-2 satellite images. The Sentinel-2 satellite images are openly and freely accessible. and are provided in the earth observation program Copernicus. We present a novel dataset. based on these images that covers 13 spectral bands and is comprised of ten classes with a total of 27 000 labeled and geo-referenced images. Benchmarks are provided for this novel dataset with its spectral bands using state-of-the-art deep convolutional neural networks. An overall classification accuracy of 98.57% was achieved with the proposed novel dataset. The resulting classification system opens a gate toward a number of earth observation applications. We demonstrate how this classification system can be used for detecting land use and land cover changes. and how it can assist in improving geographical maps. The geo …,True,J-8Z038AAAAJ:6yz0xqPARnAC,184,https://ieeexplore.ieee.org/abstract/document/8736785/,6398731324257884195,/scholar?cites=6398731324257884195,,,https://arxiv.org/pdf/1709.00029,0,0,0
1282201,Sentibank: Large-scale Ontology and Classifiers for Detecting Sentiment and Emotions in Visual Content,2013,Damian Borth and Tao Chen and Rongrong Ji and Shih-Fu Chang,,,,459-460,ACM,A picture is worth one thousand words. but what words should be used to describe the sentiment and emotions conveyed in the increasingly popular social multimedia? We demonstrate a novel system which combines sound structures from psychology and the folksonomy extracted from social multimedia to develop a large visual sentiment ontology consisting of 1.200 concepts and associated classifiers called SentiBank. Each concept. defined as an Adjective Noun Pair (ANP). is made of an adjective strongly indicating emotions and a noun corresponding to objects or scenes that have a reasonable prospect of automatic detection. We believe such large-scale visual classifiers offer a powerful mid-level semantic representation enabling high-level sentiment analysis of social multimedia. We demonstrate novel applications made possible by SentiBank including live sentiment prediction of social media and …,True,J-8Z038AAAAJ:hqOjcs7Dif8C,164,https://dl.acm.org/doi/abs/10.1145/2502081.2502268,3306077269872405951,/scholar?cites=3306077269872405951,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.394.499&rep=rep1&type=pdf,0,0,0
1282202,Multi-task Learning for Segmentation of Building Footprints with Deep Neural Networks,2019,Benjamin Bischke and Patrick Helber and Joachim Folz and Damian Borth and Andreas Dengel,,,,1480-1484,IEEE,The increased availability of high-resolution satellite imagery allows to sense very detailed structures on the surface of our planet. Access to such information opens up new directions in the analysis of remote sensing imagery. While deep neural networks have achieved significant advances in semantic segmentation of high-resolution images. most of the existing approaches tend to produce predictions with poor boundaries. In this paper. we address the problem of preserving semantic segmentation boundaries in high-resolution satellite imagery by introducing a novel multi-task loss. The loss leverages multiple output representations of the segmentation mask and biases the network to focus more on pixels near boundaries. We evaluate our approach on the large-scale Inria Aerial Image Labeling Dataset which contains high-resolution images. Our results show that we are able to outperform state-of-the-art …,True,J-8Z038AAAAJ:fFSKOagxvKUC,118,https://ieeexplore.ieee.org/abstract/document/8803050/,12590216915186613478,/scholar?cites=12590216915186613478,,,https://arxiv.org/pdf/1709.05932,0,0,0
1282203,The Multimedia Satellite Task at MediaEval 2018.,2018,Benjamin Bischke and Patrick Helber and Zhengyu Zhao and Jens De Bruijn and Damian Borth,,,,,,This paper provides a description of the MediaEval 2018 Multimedia Satellite Task. The primary goal of the task is to extract and fuse content associated with events represent in Satellite Imagery and Social Media. Establishing a link from Satellite Imagery to Social Multimedia can yield to a comprehensive event representation which is vital for numerous applications. Focusing on natural disaster events. the main objective of the task is to leverage the combined event representation within the context of emergency response and environmental monitoring. In particular. our task focuses on flooding events and consists of two subtasks. The first Image Classification from Social Media subtask requires participants to retrieve images from Social Media that show a direct evidence for road passability during flooding events. The second task Flood Detection from Satellite Images aims to extract potentially flooded road sections from satellite images. The task seeks to go beyond state-of-the-art flooding map generation by focusing on information about road passability and the accessibility of urban infrastructure. Such information shows a clear potential to complement information from social images with satellite imagery for emergency management.,True,J-8Z038AAAAJ:PaBasH6fAo0C,63,https://www.dfki.de/fileadmin/user_upload/import/10104_bischke_mmsat2018.pdf,8002840892944634638,/scholar?cites=8002840892944634638,,,https://www.dfki.de/fileadmin/user_upload/import/10104_bischke_mmsat2018.pdf,0,0,0
1282204,Detection of Anomalies in Large Scale Accounting Data using Deep Autoencoder Networks,2017,Marco Schreyer and Timur Sattarov and Damian Borth and Andreas Dengel and Bernd Reimer,,arXiv preprint arXiv:1709.05254,,,,Learning to detect fraud in large-scale accounting data is one of the long-standing challenges in financial statement audits or fraud investigations. Nowadays. the majority of applied techniques refer to handcrafted rules derived from known fraud scenarios. While fairly successful. these rules exhibit the drawback that they often fail to generalize beyond known fraud scenarios and fraudsters gradually find ways to circumvent them. To overcome this disadvantage and inspired by the recent success of deep learning we propose the application of deep autoencoder neural networks to detect anomalous journal entries. We demonstrate that the trained network's reconstruction error obtainable for a journal entry and regularized by the entry's individual attribute probabilities can be interpreted as a highly adaptive anomaly assessment. Experiments on two real-world datasets of journal entries. show the effectiveness of the approach resulting in high f1-scores of 32.93 (dataset A) and 16.95 (dataset B) and less false positive alerts compared to state of the art baseline methods. Initial feedback received by chartered accountants and fraud examiners underpinned the quality of the approach in capturing highly relevant accounting anomalies.,True,J-8Z038AAAAJ:3htObqc8RwsC,58,https://arxiv.org/abs/1709.05254,347564299994659265,/scholar?cites=347564299994659265,,,https://arxiv.org/pdf/1709.05254,0,0,0
1282205,Keyframe Extraction for Video Tagging & Summarization.,2008,Damian Borth and Adrian Ulges and Christian Schulze and Thomas M Breuel,2008,Informatiktage,,45-48,,Currently. online video distributed via online video platforms like YouTube experiences more and more popularity. We propose an approach of keyframe extraction based on unsupervised learning for video retrieval and video summarization. Our approach uses shot boundary detection to segment the video into shots and the k-means algorithm to determine cluster representatives for each shot that are used as keyframes. Furthermore we performed an additional clustering on the extracted keyframes to provide a video summarization. To test our methods we used a database of videos downloaded from YouTube where our results show (1) an improvement of retrieval and (2) compact summarization examples.,True,J-8Z038AAAAJ:u5HHmVD_uO8C,56,https://www.academia.edu/download/53662567/Keyframe_Extraction_for_Video_Tagging__S20170626-2683-pyljdq.pdf,6816496787549320078,/scholar?cites=6816496787549320078,,,https://www.academia.edu/download/53662567/Keyframe_Extraction_for_Video_Tagging__S20170626-2683-pyljdq.pdf,0,0,0
1282206,Learning multi-label scene classification,2004,Matthew R Boutell and Jiebo Luo and Xipeng Shen and Christopher M Brown,37,Pattern recognition,9,1757-1771,Pergamon,In classic pattern recognition problems. classes are mutually exclusive by definition. Classification errors occur when the classes overlap in the feature space. We examine a different situation. occurring when the classes are. by definition. not mutually exclusive. Such problems arise in semantic scene and document classification and in medical diagnosis. We present a framework to handle such problems and apply it to the problem of semantic scene classification. where a natural scene may contain multiple objects such that the scene can be described by multiple class labels (e.g.. a field scene with a mountain in the background). Such a problem poses challenges to the classic pattern recognition paradigm and demands a different treatment. We discuss approaches for training and testing in this scenario and introduce new metrics for evaluating individual examples. class recall and precision. and overall accuracy …,True,LB5QBY4AAAAJ:ufrVoPGSRksC,2193,https://www.sciencedirect.com/science/article/pii/S0031320304001074,7162249900858911951,/scholar?cites=7162249900858911951,,,http://people.engr.ncsu.edu/xshen5/Publications/pr04.pdf,0,0,0
1282207,Beyond pixels: Exploiting camera metadata for photo classification,2005,Matthew Boutell and Jiebo Luo,38,Pattern recognition,6,935-946,Pergamon,Semantic scene classification based only on low-level vision cues has had limited success on unconstrained image sets. On the other hand. camera metadata related to capture conditions provide cues independent of the captured scene content that can be used to improve classification performance. We consider three problems. indoor–outdoor classification. sunset detection. and manmade–natural classification. Analysis of camera metadata statistics for images of each class revealed that metadata fields. such as exposure time. flash fired. and subject distance. are most discriminative for each problem. A Bayesian network is employed to fuse content-based and metadata cues in the probability domain and degrades gracefully even when specific metadata inputs are missing (a practical concern). Finally. we provide extensive experimental results on the three problems using content-based and metadata cues to …,True,LB5QBY4AAAAJ:2osOgNQ5qMEC,128,https://www.sciencedirect.com/science/article/pii/S0031320304003978,2394264886038214475,/scholar?cites=2394264886038214475,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.87.5058&rep=rep1&type=pdf,0,0,0
1282208,Method of using temporal context for image classification,2010,Jiebo Luo and Matthew R Boutell,,,,,,A method for improving scene classification of a sequence of digital images is disclosed herein. Such a method may include providing a sequence of images captured in temporal succession;(b) classifying each of the images individually based on information contained in the image alone to generate a first image classification; and (c) imposing a pre-determined temporal context model on the sequence of images to generate a final image classification for each image in the sequence.,True,LB5QBY4AAAAJ:hC7cP41nSMkC,126,https://patents.google.com/patent/US7680340B2/en,17342038643527646074,/scholar?cites=17342038643527646074,,,https://patentimages.storage.googleapis.com/63/2e/d2/6381ee882b97d9/US7680340B2.pdf,0,0,0
1282209,Multilabel machine learning and its application to semantic scene classification,2003,Xipeng Shen and Matthew Boutell and Jiebo Luo and Christopher Brown,5307,,,188-199,International Society for Optics and Photonics,In classic pattern recognition problems. classes are mutually exclusive by definition. Classification errors occur when the classes overlap in the feature space. We examine a different situation. occurring when the classes are. by definition. not mutually exclusive. Such problems arise in scene and document classification and in medical diagnosis. We present a framework to handle such problems and apply it to the problem of semantic scene classification. where a natural scene may contain multiple objects such that the scene can be described by multiple class labels (e.g.. a field scene with a mountain in the background). Such a problem poses challenges to the classic pattern recognition paradigm and demands a different treatment. We discuss approaches for training and testing in this scenario and introduce new metrics for evaluating individual examples. class recall and precision. and overall accuracy …,True,LB5QBY4AAAAJ:3fE2CSJIrl8C,106,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5307/0000/Multilabel-machine-learning-and-its-application-to-semantic-scene-classification/10.1117/12.523428.short,10715160588264353120,/scholar?cites=10715160588264353120,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.5839&rep=rep1&type=pdf,0,0,0
1282210,Bayesian fusion of camera metadata cues in semantic scene classification,2004,Matthew Boutell and Jiebo Luo,2,,,II-II,IEEE,Semantic scene classification based only on low-level vision cues has had limited success on unconstrained image sets. On the other hand. camera metadata related to capture conditions provides cues independent of the captured scene content that can be used to improve classification performance. We consider two problems: indoor-outdoor classification and sunset detection. Analysis of camera metadata statistics for images of each class revealed that metadata fields. such as exposure time. flash fired. and subject distance. is most discriminative for both indoor-outdoor and sunset classification. A Bayesian network is employed to fuse content-based and metadata cues in the probability domain and degrades gracefully. even when specific metadata inputs are missing (a practical concern). Finally. we provide extensive experimental results on the two problems. using content-based and metadata cues to …,True,LB5QBY4AAAAJ:_FxGoFyzp5QC,97,https://ieeexplore.ieee.org/abstract/document/1315222/,7221049810194606642,/scholar?cites=7221049810194606642,,,https://www.rose-hulman.edu/class/cs/csse463/201720/Papers/CVPR04-metadata.pdf,0,0,0
1282211,Method for semantic scene classification using camera metadata and content-based cues,2009,Jiebo Luo and Matthew R Boutell,,,,,,A method for scene classification of a digital image includes extracting pre-determined camera metadata tags from the digital image. The method also includes obtaining estimates of image class based on the extracted metadata tags. In addition. the method includes obtaining estimates of image class based on image and producing a final estimate of image class based on a combination of metadata-based estimates and image content-based estimates.,True,LB5QBY4AAAAJ:dhFuZR0502QC,89,https://patents.google.com/patent/US7555165B2/en,15573317758530659631,/scholar?cites=15573317758530659631,,,https://patentimages.storage.googleapis.com/be/ce/a8/05036ac54ee4cc/US7555165.pdf,0,0,0
1282212,Photo classification by integrating image content and camera metadata,2004,Matthew Boutell and Jiebo Luo,4,,,901-904,IEEE,Despite years of research. semantic classification of unconstrained photos is still an open problem. Existing systems have only used features derived from the image content. However. Exif metadata recorded by the camera provides cues independent of the scene content that can be exploited to improve classification accuracy. Using the problem of indoor-outdoor classification as an example. analysis of metadata statistics for each class revealed that exposure time. flash use. and subject distance are salient cues. We use a Bayesian network to integrate heterogeneous (content-based and metadata) cues in a robust fashion. Based on extensive experimental results. we make two observations: (1) adding metadata to content-based cues gives highest accuracies; and (2) metadata cues alone can outperform content-based cues alone for certain applications. leading to a system with high performance. yet requiring …,True,LB5QBY4AAAAJ:Wp0gIr-vW9MC,89,https://ieeexplore.ieee.org/abstract/document/1333918/,14849148484884607002,/scholar?cites=14849148484884607002,,,,0,0,0
1282213,Pictures are not taken in a vacuum-an overview of exploiting context for semantic scene content understanding,2006,Jiebo Luo and Matthew Boutell and Christopher Brown,23,,2,101-114,IEEE,Considerable research has been devoted to the problem of multimedia indexing and retrieval in the past decade. However. limited by state-of-the-art in image understanding. the majority of the existing content-based image retrieval (CBIR) systems have taken a relatively low-level approach and fallen short of higher-level interpretation and knowledge. Recent research has begun to focus on bridging the semantic and conceptual gap that exists between man and computer by integrating knowledge-based techniques. human perception. scene content understanding. psychology. and linguistics. In this article. we provide an overview of exploiting context for semantic scene content and understanding,True,LB5QBY4AAAAJ:YsMSGLbcyi4C,80,https://ieeexplore.ieee.org/abstract/document/1598086/,5597767956334082467,/scholar?cites=5597767956334082467,,,,0,0,0
1282214,Automatic image orientation detection via confidence-based integration of low-level and semantic cues,2005,Jiebo Luo and Matthew Boutell,27,IEEE transactions on pattern analysis and machine intelligence,5,715-726,IEEE,Automatic image orientation detection for natural images is a useful. yet challenging research topic. Humans use scene context and semantic object recognition to identify the correct image orientation. However. it is difficult for a computer to perform the task in the same way because current object recognition algorithms are extremely limited in their scope and robustness. As a result. existing orientation detection methods were built upon low-level vision features such as spatial distributions of color and texture. Discrepant detection rates have been reported for these methods in the literature. We have developed a probabilistic approach to image orientation detection via confidence-based integration of low-level and semantic cues within a Bayesian framework. Our current accuracy is 90 percent for unconstrained consumer photos. impressive given the findings of a psychophysical study conducted recently. The …,True,LB5QBY4AAAAJ:qxL8FJ1GzNcC,58,https://ieeexplore.ieee.org/abstract/document/1407875/,14655287153033384630,/scholar?cites=14655287153033384630,,,,0,0,0
1282215,Scene parsing using region-based generative models,2006,Matthew R Boutell and Jiebo Luo and Christopher M Brown,9,IEEE transactions on multimedia,1,136-146,IEEE,"Semantic scene classification is a challenging problem in computer vision. In contrast to the common approach of using low-level features computed from the whole scene. we propose ""scene parsing"" utilizing semantic object detectors (e.g.. sky. foliage. and pavement) and region-based scene-configuration models. Because semantic detectors are faulty in practice. it is critical to develop a region-based generative model of outdoor scenes based on characteristic objects in the scene and spatial relationships between them. Since a fully connected scene configuration model is intractable. we chose to model pairwise relationships between regions and estimate scene probabilities using loopy belief propagation on a factor graph. We demonstrate the promise of this approach on a set of over 2000 outdoor photographs. comparing it with existing discriminative approaches and those using low-level features",True,LB5QBY4AAAAJ:WF5omc3nYNoC,52,https://ieeexplore.ieee.org/abstract/document/4032602/,5708982596786078125,/scholar?cites=5708982596786078125,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.225.688&rep=rep1&type=pdf,0,0,0
1282216,Multi-label Semantic Scene Classfication,2003,Matthew Boutell and Xipeng Shen and Jiebo Luo and Christopher Brown,,,,,,In classic pattern recognition problems. classes are mutually exclusive by definition. Classification errors occur when the classes overlap in the feature space. We examine a different situation. occurring when the classes are. by definition. not mutually exclusive. Such problems arise in scene and document classification and in medical diagnosis. We present a framework to handle such problems and apply it to the problem of semantic scene classification. where a natural scene may contain multiple objects such that the scene can be described by multiple class labels (eg. a field scene with a mountain in the background). Such a problem poses challenges to the classic pattern recognition paradigm and demands a different treatment. We discuss approaches for training and testing in this scenario and introduce new metrics for evaluating individual examples. class recall and precision. and overall accuracy. Experiments show that our methods are suitable for scene classification; furthermore. our work appears to generalize to other classification problems of the same nature.,True,LB5QBY4AAAAJ:u5HHmVD_uO8C,48,https://urresearch.rochester.edu/institutionalPublicationPublicView.action?institutionalItemId=186,4575044220682174399,/scholar?cites=4575044220682174399,,,https://urresearch.rochester.edu/fileDownloadForInstitutionalItem.action?itemId=186&itemFileId=269,0,0,0
1282217,Visual tracking: An experimental survey,2013,Arnold WM Smeulders and Dung M Chu and Rita Cucchiara and Simone Calderara and Afshin Dehghan and Mubarak Shah,36,IEEE transactions on pattern analysis and machine intelligence,7,1442-1468,IEEE,There is a large variety of trackers. which have been proposed in the literature during the last two decades with some mixed success. Object tracking in realistic scenarios is a difficult problem. therefore. it remains a most active area of research in computer vision. A good tracker should perform well in a large number of videos involving illumination changes. occlusion. clutter. camera motion. low contrast. specularities. and at least six more aspects. However. the performance of proposed trackers have been evaluated typically on less than ten videos. or on the special purpose datasets. In this paper. we aim to evaluate trackers systematically and experimentally on 315 video fragments covering above aspects. We selected a set of nineteen trackers to include a wide variety of algorithms often cited in literature. supplemented with trackers appearing in 2010 and 2011 for which the code was publicly available. We …,True,wcX-UW4AAAAJ:_FxGoFyzp5QC,1595,https://ieeexplore.ieee.org/abstract/document/6671560/,14230020724052037515,/scholar?cites=14230020724052037515,,,https://ieeexplore.ieee.org/iel7/34/4359286/06671560.pdf,0,0,0
1282218,Part-based multiple-person tracking with partial occlusion handling,2012,Guang Shu and Afshin Dehghan and Omar Oreifej and Emily Hand and Mubarak Shah,,,,1815-1821,IEEE,Single camera-based multiple-person tracking is often hindered by difficulties such as occlusion and changes in appearance. In this paper. we address such problems by proposing a robust part-based tracking-by-detection framework. Human detection using part models has become quite popular. yet its extension in tracking has not been fully explored. Our approach learns part-based person-specific SVM classifiers which capture the articulations of the human bodies in dynamically changing appearance and background. With the part-based model. our approach is able to handle partial occlusions in both the detection and the tracking stages. In the detection stage. we select the subset of parts which maximizes the probability of detection. which significantly improves the detection performance in crowded scenes. In the tracking stage. we dynamically handle occlusions by distributing the score of the learned person …,True,wcX-UW4AAAAJ:UeHWp8X0CEIC,424,https://ieeexplore.ieee.org/abstract/document/6247879/,13479098705233914673,/scholar?cites=13479098705233914673,,,https://www.crcv.ucf.edu/papers/cvpr2012/1439.pdf,0,0,0
1282219,Gmcp-tracker: Global multi-object tracking using generalized minimum clique graphs,2012,Amir Roshan Zamir and Afshin Dehghan and Mubarak Shah,,,,343-356,Springer. Berlin. Heidelberg,Data association is an essential component of any human tracking system. The majority of current methods. such as bipartite matching. incorporate a limited-temporal-locality of the sequence into the data association problem. which makes them inherently prone to IDswitches and difficulties caused by long-term occlusion. cluttered background. and crowded scenes.We propose an approach to data association which incorporates both motion and appearance in a global manner. Unlike limited-temporal-locality methods which incorporate a few frames into the data association problem. we incorporate the whole temporal span and solve the data association problem for one object at a time. while implicitly incorporating the rest of the objects. In order to achieve this. we utilize Generalized Minimum Clique Graphs to solve the optimization problem of our data association method. Our proposed method yields a …,True,wcX-UW4AAAAJ:IjCSPb-OGe4C,413,https://link.springer.com/chapter/10.1007/978-3-642-33709-3_25,14147383061302564518,/scholar?cites=14147383061302564518,,,https://link.springer.com/content/pdf/10.1007/978-3-642-33709-3_25.pdf,0,0,0
1282220,GMMCP Tracker: Globally Optimal Generalized Maximum Multi Clique Problem for Multiple Object Tracking,2015,Afshin Dehghan and Modiri Assari Shayan and Mubarak Shah,1,CVPR,,2,,Data association is the backbone to many multiple object tracking (MOT) methods. In this paper we formulate data association as a Generalized Maximum Multi Clique problem (GMMCP). We show that this is the ideal case of modeling tracking in real world scenario where all the pairwise relationships between targets in a batch of frames are taken into account. Previous works assume simplified version of our tracker either in problem formulation or problem optimization. However. we propose a solution using GMMCP where no simplification is assumed in either steps. We show that the NP hard problem of GMMCP can be formulated through Binary-Integer Program where for small and medium size MOT problems the solution can be found efficiently. We further propose a speed-up method. employing Aggregated Dummy Nodes for modeling occlusion and miss-detection. which reduces the size of the input graph without using any heuristics. We show that. using the speedup method. our tracker lends itself to real-time implementation which is plausible in many applications. We evaluated our tracker on six challenging sequences of Town Center. TUD-Crossing. TUD-Stadtmitte. Parking-lot 1. Parking-lot 2 and Parking-lot pizza and show favorable improvement against state of art.,True,wcX-UW4AAAAJ:5nxA0vEk-isC,276,http://openaccess.thecvf.com/content_cvpr_2015/html/Dehghan_GMMCP_Tracker_Globally_2015_CVPR_paper.html,16887157392110437458,/scholar?cites=16887157392110437458,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Dehghan_GMMCP_Tracker_Globally_2015_CVPR_paper.pdf,0,0,0
1282221,Target identity-aware network flow for online multiple target tracking,2015,Afshin Dehghan and Yicong Tian and Philip HS Torr and Mubarak Shah,,,,1146-1154,,In this paper we show that multiple object tracking (MOT) can be formulated in a framework. where the detection and data-association are performed simultaneously. Our method allows us to overcome the confinements of data association based MOT approaches; where the performance is dependent on the object detection results provided at input level. At the core of our method lies structured learning which learns a model for each target and infers the best location of all targets simultaneously in a video clip. The inference of our structured learning is done through a new Target Identity-aware Network Flow (TINF). where each node in the network encodes the probability of each target identity belonging to that node. The proposed Lagrangian relaxation optimization finds the high quality solution to the network. During optimization a soft spatial constraint is enforced between the nodes of the graph which helps reducing the ambiguity caused by nearby targets with similar appearance in crowded scenarios. We show that automatically detecting and tracking targets in a single framework can help resolve the ambiguities due to frequent occlusion and heavy articulation of targets. Our experiments involve challenging yet distinct datasets and show that our method can achieve results better than the state-of-art.,True,wcX-UW4AAAAJ:0EnyYjriUFMC,120,http://openaccess.thecvf.com/content_cvpr_2015/html/Dehghan_Target_Identity-Aware_Network_2015_CVPR_paper.html,3566029965655435587,/scholar?cites=3566029965655435587,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Dehghan_Target_Identity-Aware_Network_2015_CVPR_paper.pdf,0,0,0
1282222,Who do i look like? determining parent-offspring resemblance via gated autoencoders,2014,Afshin Dehghan and Enrique G Ortiz and Ruben Villegas and Mubarak Shah,,,,1757-1764,,"Recent years have seen a major push for face recognition technology due to the large expansion of image sharing on social networks. In this paper. we consider the difficult task of determining parent-offspring resemblance using deep learning to answer the question"" Who do I look like?"" Although humans can perform this job at a rate higher than chance. it is not clear how they do it [2]. However. recent studies in anthropology [24] have determined which features tend to be the most discriminative. In this study. we aim to not only create an accurate system for resemblance detection. but bridge the gap between studies in anthropology with computer vision techniques. Further. we aim to answer two key questions: 1) Do offspring resemble their parents? and 2) Do offspring resemble one parent more than the other? We propose an algorithm that fuses the features and metrics discovered via gated autoencoders with a discriminative neural network layer that learns the optimal. or what we call genetic. features to delineate parent-offspring relationships. We further analyze the correlation between our automatically detected features and those found in anthropological studies. Meanwhile. our method outperforms the state-of-the-art in kinship verification by 3-10% depending on the relationship using specific (father-son. mother-daughter. etc.) and generic models.",True,wcX-UW4AAAAJ:UebtZRa9Y70C,106,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Dehghan_Who_Do_I_2014_CVPR_paper.html,10490574519224790209,/scholar?cites=10490574519224790209,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Dehghan_Who_Do_I_2014_CVPR_paper.pdf,0,0,0
1282223,License plate detection and recognition using deeply learned convolutional neural networks,2017,Syed Zain Masood and Guang Shu and Afshin Dehghan and Enrique G Ortiz,,arXiv preprint arXiv:1703.07330,,,,This work details Sighthounds fully automated license plate detection and recognition system. The core technology of the system is built using a sequence of deep Convolutional Neural Networks (CNNs) interlaced with accurate and efficient algorithms. The CNNs are trained and fine-tuned so that they are robust under different conditions (eg variations in pose. lighting. occlusion. etc.) and can work across a variety of license plate templates (eg sizes. backgrounds. fonts. etc). For quantitative analysis. we show that our system outperforms the leading license plate detection and recognition technology ie ALPR on several benchmarks. Our system is available to developers through the Sighthound Cloud API at this https URL,True,wcX-UW4AAAAJ:L8Ckcad2t8MC,102,https://arxiv.org/abs/1703.07330,16793648768912246522,/scholar?cites=16793648768912246522,,,https://arxiv.org/pdf/1703.07330,0,0,0
1282224,Dager: Deep age. gender and emotion recognition using convolutional neural network,2017,Afshin Dehghan and Enrique G Ortiz and Guang Shu and Syed Zain Masood,,arXiv preprint arXiv:1702.04280,,,,This paper describes the details of Sighthound's fully automated age. gender and emotion recognition system. The backbone of our system consists of several deep convolutional neural networks that are not only computationally inexpensive. but also provide state-of-the-art results on several competitive benchmarks. To power our novel deep networks. we collected large labeled datasets through a semi-supervised pipeline to reduce the annotation effort/time. We tested our system on several public benchmarks and report outstanding results. Our age. gender and emotion recognition models are available to developers through the Sighthound Cloud API at this https URL,True,wcX-UW4AAAAJ:7PzlFSSx8tAC,89,https://arxiv.org/abs/1702.04280,1018180795833023840,/scholar?cites=1018180795833023840,,,https://arxiv.org/pdf/1702.04280,0,0,0
1282225,Improving an object detector and extracting regions using superpixels,2013,Guang Shu and Afshin Dehghan and Mubarak Shah,,,,3721-3727,,We propose an approach to improve the detection performance of a generic detector when it is applied to a particular video. The performance of offline-trained objects detectors are usually degraded in unconstrained video environments due to variant illuminations. backgrounds and camera viewpoints. Moreover. most object detectors are trained using Haar-like features or gradient features but ignore video specific features like consistent color patterns. In our approach. we apply a Superpixel-based Bag-of-Words (BoW) model to iteratively refine the output of a generic detector. Compared to other related work. our method builds a video-specific detector using superpixels. hence it can handle the problem of appearance variation. Most importantly. using Conditional Random Field (CRF) along with our super pixel-based BoW model. we develop and algorithm to segment the object from the background. Therefore our method generates an output of the exact object regions instead of the bounding boxes generated by most detectors. In general. our method takes detection bounding boxes of a generic detector as input and generates the detection output with higher average precision and precise object regions. The experiments on four recent datasets demonstrate the effectiveness of our approach and significantly improves the state-of-art detector by 5-16% in average precision.,True,wcX-UW4AAAAJ:Tyk-4Ss8FVUC,89,http://openaccess.thecvf.com/content_cvpr_2013/html/Shu_Improving_an_Object_2013_CVPR_paper.html,1419254064397969812,/scholar?cites=1419254064397969812,,,http://openaccess.thecvf.com/content_cvpr_2013/papers/Shu_Improving_an_Object_2013_CVPR_paper.pdf,0,0,0
1282226,Automatic detection and tracking of pedestrians in videos with various crowd densities,2014,Afshin Dehghan and Haroon Idrees and Amir Roshan Zamir and Mubarak Shah,,,,3-19,Springer. Cham,Manual analysis of pedestrians and crowds is often impractical for massive datasets of surveillance videos. Automatic tracking of humans is one of the essential abilities for computerized analysis of such videos. In this keynote paper. we present two state of the art methods for automatic pedestrian tracking in videos with low and high crowd density. For videos with low density. first we detect each person using a part-based human detector. Then. we employ a global data association method based on Generalized Graphs for tracking each individual in the whole video. In videos with high crowd-density. we track individuals using a scene structured force model and crowd flow modeling. Additionally. we present an alternative approach which utilizes contextual information without the need to learn the structure of the scene. Performed evaluations show the presented methods outperform the currently available …,True,wcX-UW4AAAAJ:roLk4NBRz8UC,55,https://link.springer.com/chapter/10.1007/978-3-319-02447-9_1,9297624076140771557,/scholar?cites=9297624076140771557,,,http://www.eecs.ucf.edu/~haroon/datafiles/Idrees_CrowdPED_Springer_2014.pdf,0,0,0
1282227,TRECVID 2012 GENIE: Multimedia event detection and recounting,2012,AG Amitha Perera and Sangmin Oh and P Megha and Tianyang Ma and Anthony Hoogs and Arash Vahdat and Kevin Cannons and Greg Mori and Scott Mccloskey and Ben Miller and Sharath Venkatesh and Pedro Davalos and Pradipto Das and Chenliang Xu and Jason Corso and Rohini Srihari and Ilseo Kim and You-chi Cheng and Zhen Huang and Chin-hui Lee and Kevin Tang and L Fei-Fei and Daphne Koller,,,,,,Our MED 12 system is an extension of our MED 11 system [11]. and consists of a collection of low-level and high-level features. feature-specific classifiers built upon those features. and a fusion system that combines features both through mid-level kernel fusion and score fusion. We have incorporated large number of audio-visual features in our new system and incorporated diverse types of standard and newly developed event agents which learn the salient audio-visual characteristics of event classes. The combination of additional features and newly developed powerful event agents improve our MED performance substantially beyond our MED 11 results. In addition. our MER 12 submissions reported recounting of specified clips for all five MER events and additionally provided MER results for all the clips detected by MED system. Our MER system generated recounting of detections based on CDR features and synopsis provided as part of the EventKits and DEV-T datasets. The MER evaluation results are promising for event-level discrimination. and indicated further improvement to be made for clip-level discrimination. 1,True,wcX-UW4AAAAJ:YsMSGLbcyi4C,38,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.723.6639,633117836250733754,/scholar?cites=633117836250733754,,,,0,0,0
1282228,On using very large target vocabulary for neural machine translation,2014,Sébastien Jean and Kyunghyun Cho and Roland Memisevic and Yoshua Bengio,,arXiv preprint arXiv:1412.2007,,,,Neural machine translation. a recently proposed approach to machine translation based purely on neural networks. has shown promising results compared to the existing approaches such as phrase-based statistical machine translation. Despite its recent success. neural machine translation has its limitation in handling a larger vocabulary. as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper. we propose a method that allows us to use a very large target vocabulary without increasing training complexity. based on importance sampling. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore. when we use the ensemble of a few models with very large target vocabularies. we achieve the state-of-the-art translation performance (measured by BLEU) on the English-> German translation and almost as high performance as state-of-the-art English-> French translation system.,True,8x8FUr8AAAAJ:W7OEmFMy1HYC,876,https://arxiv.org/abs/1412.2007,13222564911222792417,/scholar?cites=13222564911222792417,,,https://arxiv.org/pdf/1412.2007,0,0,0
1282229,Theano: A Python framework for fast computation of mathematical expressions,2016,Rami Al-Rfou and Guillaume Alain and Amjad Almahairi and Christof Angermueller and Dzmitry Bahdanau and Nicolas Ballas and Frédéric Bastien and Justin Bayer and Anatoly Belikov and Alexander Belopolsky and Yoshua Bengio and Arnaud Bergeron and James Bergstra and Valentin Bisson and Josh Bleecher Snyder and Nicolas Bouchard and Nicolas Boulanger-Lewandowski and Xavier Bouthillier and Alexandre de Brébisson and Olivier Breuleux and Pierre-Luc Carrier and Kyunghyun Cho and Jan Chorowski and Paul Christiano and Tim Cooijmans and Marc-Alexandre Côté and Myriam Côté and Aaron Courville and Yann N Dauphin and Olivier Delalleau and Julien Demouth and Guillaume Desjardins and Sander Dieleman and Laurent Dinh and Melanie Ducoffe and Vincent Dumoulin and Samira Ebrahimi Kahou and Dumitru Erhan and Ziye Fan and Orhan Firat and Mathieu Germain and Xavier Glorot and Ian Goodfellow and Matt Graham and Caglar Gulcehre and Philippe Hamel and Iban Harlouchet and Jean-Philippe Heng and Balázs Hidasi and Sina Honari and Arjun Jain and Sébastien Jean and Kai Jia and Mikhail Korobov and Vivek Kulkarni and Alex Lamb and Pascal Lamblin and Eric Larsen and César Laurent and Sean Lee and Simon Lefrançois and Simon Lemieux and Nicholas Léonard and Zhouhan Lin and Jesse A Livezey and Cory Lorenz and Jeremiah Lowin and Qianli Ma and Pierre-Antoine Manzagol and Olivier Mastropietro and Robert T McGibbon and Roland Memisevic and Bart van Merriënboer and Vincent Michalski and Mehdi Mirza and Alberto Orlandi and Christopher Pal and Razvan Pascanu and Mohammad Pezeshki and Colin Raffel and Daniel Renshaw and Matthew Rocklin and Adriana Romero and Markus Roth and Peter Sadowski and John Salvatier and François Savard and Jan Schlüter and John Schulman and Gabriel Schwartz and Iulian Vlad Serban and Dmitriy Serdyuk and Samira Shabanian and Étienne Simon and Sigurd Spieckermann and S Ramana Subramanyam and Jakub Sygnowski and Jérémie Tanguay and Gijs van Tulder and Joseph Turian and Sebastian Urban and Pascal Vincent and Francesco Visin and Harm de Vries and David Warde-Farley and Dustin J Webb and Matthew Willson and Kelvin Xu and Lijun Xue and Li Yao and Saizheng Zhang and Ying Zhang,,arXiv e-prints,,arXiv: 1605.02688,,Theano is a Python library that allows to define. optimize. and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction. it has been one of the most used CPU and GPU mathematical compilers-especially in the machine learning community-and has shown steady performance improvements. Theano is being actively and continuously developed since 2008. multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them. and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and …,True,8x8FUr8AAAAJ:u-x6o8ySG0sC,797,https://ui.adsabs.harvard.edu/abs/2016arXiv160502688T/abstract,3168617625725328375,/scholar?cites=3168617625725328375,,,https://www.researchgate.net/profile/Dumitru-Erhan/publication/302569301_Theano_A_Python_framework_for_fast_computation_of_mathematical_expressions/links/57335bc808ae298602dce993/Theano-A-Python-framework-for-fast-computation-of-mathematical-expressions.pdf,0,0,0
1282230,Adversarial learning for neural dialogue generation,2017,Jiwei Li and Will Monroe and Tianlin Shi and Sébastien Jean and Alan Ritter and Dan Jurafsky,,arXiv preprint arXiv:1701.06547,,,,In this paper. drawing intuition from the Turing test. we propose using adversarial training for open-domain dialogue generation: the system is trained to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning (RL) problem where we jointly train two systems. a generative model to produce response sequences. and a discriminator---analagous to the human evaluator in the Turing test---to distinguish between the human-generated dialogues and the machine-generated ones. The outputs from the discriminator are then used as rewards for the generative model. pushing the system to generate dialogues that mostly resemble human dialogues.In addition to adversarial training we describe a model for adversarial {\em evaluation} that uses success in fooling an adversary as a dialogue evaluation metric. while avoiding a number of potential pitfalls. Experimental results on several metrics. including adversarial evaluation. demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines.,True,8x8FUr8AAAAJ:u5HHmVD_uO8C,708,https://arxiv.org/abs/1701.06547,2709411320030823497,/scholar?cites=2709411320030823497,,,https://arxiv.org/pdf/1701.06547,0,0,0
1282231,Emonets: Multimodal deep learning approaches for emotion recognition in video,2016,Samira Ebrahimi Kahou and Xavier Bouthillier and Pascal Lamblin and Caglar Gulcehre and Vincent Michalski and Kishore Konda and Sébastien Jean and Pierre Froumenty and Yann Dauphin and Nicolas Boulanger-Lewandowski and Raul Chandias Ferrari and Mehdi Mirza and David Warde-Farley and Aaron Courville and Pascal Vincent and Roland Memisevic and Christopher Pal and Yoshua Bengio,10,Journal on Multimodal User Interfaces,2,99-111,Springer International Publishing,The task of the Emotion Recognition in the Wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination. making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques. each focusing on one modality. Among these are a convolutional neural network. focusing on capturing visual information in detected faces. a deep belief net focusing on the representation of the audio stream. a K-Means based “bag-of-mouths” model. which extracts visual features around the mouth region and a relational autoencoder. which addresses spatio-temporal …,True,8x8FUr8AAAAJ:UeHWp8X0CEIC,338,https://link.springer.com/article/10.1007/s12193-015-0195-2,5171780425389527285,/scholar?cites=5171780425389527285,,,https://arxiv.org/pdf/1503.01800,0,0,0
1282232,Combining modality specific deep neural networks for emotion recognition in video,2013,Samira Ebrahimi Kahou and Christopher Pal and Xavier Bouthillier and Pierre Froumenty and Çaglar Gülçehre and Roland Memisevic and Pascal Vincent and Aaron Courville and Yoshua Bengio and Raul Chandias Ferrari and Mehdi Mirza and Sébastien Jean and Pierre-Luc Carrier and Yann Dauphin and Nicolas Boulanger-Lewandowski and Abhishek Aggarwal and Jeremie Zumer and Pascal Lamblin and Jean-Philippe Raymond and Guillaume Desjardins and Razvan Pascanu and David Warde-Farley and Atousa Torabi and Arjun Sharma and Emmanuel Bengio and Myriam Côté and Kishore Reddy Konda and Zhenzhou Wu,,,,543-550,,In this paper we present the techniques used for the University of Montréal's team submissions to the 2013 Emotion Recognition in the Wild Challenge. The challenge is to classify the emotions expressed by the primary human subject in short video clips extracted from feature length movies. This involves the analysis of video clips of acted scenes lasting approximately one-two seconds. including the audio track which may contain human voices as well as background music. Our approach combines multiple deep neural networks for different data modalities. including:(1) a deep convolutional neural network for the analysis of facial expressions within video frames;(2) a deep belief net to capture audio information;(3) a deep autoencoder to model the spatio-temporal information produced by the human actions depicted within the entire scene; and (4) a shallow network architecture focused on extracted features of the …,True,8x8FUr8AAAAJ:zYLM7Y9cAGgC,299,https://dl.acm.org/doi/abs/10.1145/2522848.2531745,10489157767107369829,/scholar?cites=10489157767107369829,,,https://www.iro.umontreal.ca/~memisevr/pubs/icmi_emotiw.pdf,0,0,0
1282233,Montreal neural machine translation systems for WMT’15,2015,Sébastien Jean and Orhan Firat and Kyunghyun Cho and Roland Memisevic and Yoshua Bengio,,,,134-140,,Neural machine translation (NMT) systems have recently achieved results comparable to the state of the art on a few translation tasks. including English→ French and English→ German. The main purpose of the Montreal Institute for Learning Algorithms (MILA) submission to WMT’15 is to evaluate this new approach on a greater variety of language pairs. Furthermore. the human evaluation campaign may help us and the research community to better understand the behaviour of our systems. We use the RNNsearch architecture. which adds an attention mechanism to the encoderdecoder. We also leverage some of the recent developments in NMT. including the use of large vocabularies. unknown word replacement and. to a limited degree. the inclusion of monolingual language models.,True,8x8FUr8AAAAJ:Y0pCki6q_DkC,138,https://www.aclweb.org/anthology/W15-3014.pdf,12929504932969493366,/scholar?cites=12929504932969493366,,,https://www.aclweb.org/anthology/W15-3014.pdf,0,0,0
1282234,Does neural machine translation benefit from larger context?,2017,Sebastien Jean and Stanislas Lauly and Orhan Firat and Kyunghyun Cho,,arXiv preprint arXiv:1704.05135,,,,We propose a neural machine translation architecture that models the surrounding text in addition to the source sentence. These models lead to better performance. both in terms of general translation quality and pronoun prediction. when trained on small corpora. although this improvement largely disappears when trained with a larger corpus. We also discover that attention-based neural machine translation is well suited for pronoun prediction and compares favorably with other approaches that were specifically designed for this task.,True,8x8FUr8AAAAJ:YsMSGLbcyi4C,86,https://arxiv.org/abs/1704.05135,13901378207293945946,/scholar?cites=13901378207293945946,,,https://arxiv.org/pdf/1704.05135,0,0,0
1282235,Lingvo: a modular and scalable framework for sequence-to-sequence modeling,2019,Jonathan Shen and Patrick Nguyen and Yonghui Wu and Zhifeng Chen and Mia X Chen and Ye Jia and Anjuli Kannan and Tara Sainath and Yuan Cao and Chung-Cheng Chiu and Yanzhang He and Jan Chorowski and Smit Hinsu and Stella Laurenzo and James Qin and Orhan Firat and Wolfgang Macherey and Suyog Gupta and Ankur Bapna and Shuyuan Zhang and Ruoming Pang and Ron J Weiss and Rohit Prabhavalkar and Qiao Liang and Benoit Jacob and Bowen Liang and HyoukJoong Lee and Ciprian Chelba and Sébastien Jean and Bo Li and Melvin Johnson and Rohan Anil and Rajat Tibrewal and Xiaobing Liu and Akiko Eriguchi and Navdeep Jaitly and Naveen Ari and Colin Cherry and Parisa Haghani and Otavio Good and Youlong Cheng and Raziel Alvarez and Isaac Caswell and Wei-Ning Hsu and Zongheng Yang and Kuan-Chieh Wang and Ekaterina Gonina and Katrin Tomanek and Ben Vanik and Zelin Wu and Llion Jones and Mike Schuster and Yanping Huang and Dehao Chen and Kazuki Irie and George Foster and John Richardson and Klaus Macherey and Antoine Bruguier and Heiga Zen and Colin Raffel and Shankar Kumar and Kanishka Rao and David Rybach and Matthew Murray and Vijayaditya Peddinti and Maxim Krikun and Michiel AU Bacchiani and Thomas B Jablin and Rob Suderman and Ian Williams and Benjamin Lee and Deepti Bhatia and Justin Carlson and Semih Yavuz and Yu Zhang and Ian McGraw and Max Galkin and Qi Ge and Golan Pundak and Chad Whipkey and Todd Wang and Uri Alon and Dmitry Lepikhin and Ye Tian and Sara Sabour and William Chan and Shubham Toshniwal and Baohua Liao and Michael Nirschl and Pat Rondon,,arXiv preprint arXiv:1902.08295,,,,Lingvo is a Tensorflow framework offering a complete solution for collaborative deep learning research. with a particular focus towards sequence-to-sequence models. Lingvo models are composed of modular building blocks that are flexible and easily extensible. and experiment configurations are centralized and highly customizable. Distributed training and quantized inference are supported directly within the framework. and it contains existing implementations of a large number of utilities. helper functions. and the newest research ideas. Lingvo has been used in collaboration by dozens of researchers in more than 20 papers over the last two years. This document outlines the underlying design of Lingvo and serves as an introduction to the various pieces of the framework. while also offering examples of advanced features that showcase the capabilities of the framework.,True,8x8FUr8AAAAJ:_FxGoFyzp5QC,83,https://arxiv.org/abs/1902.08295,13450952338806064098,/scholar?cites=13450952338806064098,,,https://arxiv.org/pdf/1902.08295,0,0,0
1282236,Not all neural embeddings are born equal,2014,Felix Hill and KyungHyun Cho and Sebastien Jean and Coline Devin and Yoshua Bengio,,arXiv preprint arXiv:1410.0718,,,,Neural language models learn word representations that capture rich linguistic and conceptual information. Here we investigate the embeddings learned by neural machine translation models. We show that translation-based embeddings outperform those learned by cutting-edge monolingual models at single-language tasks requiring knowledge of conceptual similarity and/or syntactic role. The findings suggest that. while monolingual models learn information about how concepts are related. neural-translation models better capture their true ontological status.,True,8x8FUr8AAAAJ:9yKSN-GCB0IC,51,https://arxiv.org/abs/1410.0718,4199240934846890336,/scholar?cites=4199240934846890336,,,https://arxiv.org/pdf/1410.0718,0,0,0
1282237,Embedding word similarity with neural machine translation,2014,Felix Hill and Kyunghyun Cho and Sebastien Jean and Coline Devin and Yoshua Bengio,,arXiv preprint arXiv:1412.6448,,,,Neural language models learn word representations. or embeddings. that capture rich linguistic and conceptual information. Here we investigate the embeddings learned by neural machine translation models. a recently-developed class of neural language model. We show that embeddings from translation models outperform those learned by monolingual models at tasks that require knowledge of both conceptual similarity and lexical-syntactic role. We further show that these effects hold when translating from both English to French and English to German. and argue that the desirable properties of translation embeddings should emerge largely independently of the source and target languages. Finally. we apply a new method for training neural translation models with very large vocabularies. and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality. Our embedding spaces can be queried in an online demo and downloaded from our web page. Overall. our analyses indicate that translation-based embeddings should be used in applications that require concepts to be organised according to similarity and/or lexical function. while monolingual embeddings are better suited to modelling (nonspecific) inter-word relatedness.,True,8x8FUr8AAAAJ:d1gkVwhDpl0C,48,https://arxiv.org/abs/1412.6448,3941248209566557946,/scholar?cites=3941248209566557946,,,https://arxiv.org/pdf/1412.6448,0,0,0
1282238,The representational geometry of word meanings acquired by neural machine translation models,2017,Felix Hill and Kyunghyun Cho and Sébastien Jean and Yoshua Bengio,31,Machine Translation,1,3-18,Springer Netherlands,This work is the first comprehensive analysis of the properties of word embeddings learned by neural machine translation (NMT) models trained on bilingual texts. We show the word representations of NMT models outperform those learned from monolingual text by established algorithms such as Skipgram and CBOW on tasks that require knowledge of semantic similarity and/or lexical–syntactic role. These effects hold when translating from English to French and English to German. and we argue that the desirable properties of NMT word embeddings should emerge largely independently of the source and target languages. Further. we apply a recently-proposed heuristic method for training NMT models with very large vocabularies. and show that this vocabulary expansion method results in minimal degradation of embedding quality. This allows us to make a large vocabulary of NMT embeddings available …,True,8x8FUr8AAAAJ:IjCSPb-OGe4C,27,https://link.springer.com/article/10.1007/s10590-017-9194-2,5317881773503327616,/scholar?cites=5317881773503327616,,,,0,0,0
1282239,Canopy closure estimates with greenorbs: Sustainable sensing in the forest,2009,Lufeng Mo and Yuan He and Yunhao Liu and Jizhong Zhao and Shao-Jie Tang and Xiang-Yang Li and Guojun Dai,,,,99-112,,Motivated by the needs of precise forest inventory and real-time surveillance for ecosystem management. in this paper we present GreenOrbs [2]. a wireless sensor network system and its application for canopy closure estimates. Both the hardware and software designs of GreenOrbs are tailored for sensing in wild environments without human supervision. including a firm weatherproof enclosure of sensor motes and a light-weight mechanism for node state monitoring and data collection. By incorporating a pre-deployment training process as well as a distributed calibration method. the estimates of canopy closure stay accurate and consistent against uncertain sensory data and dynamic environments. We have implemented a prototype system of GreenOrbs and carried out multiple rounds of deployments. The evaluation results demonstrate that GreenOrbs outperforms the conventional approaches for canopy …,True,CbGjM58AAAAJ:SP6oXDckpogC,422,https://dl.acm.org/doi/abs/10.1145/1644038.1644049,15902075593859356088,/scholar?cites=15902075593859356088,,,http://www.cse.ust.hk/~liu/GreenOrbs.pdf,0,0,0
1282240,Electronic frog eye: Counting crowd using WiFi,2014,Wei Xi and Jizhong Zhao and Xiang-Yang Li and Kun Zhao and Shaojie Tang and Xue Liu and Zhiping Jiang,,,,361-369,IEEE,Crowd counting. which count or accurately estimate the number of human beings within a region. is critical in many applications. such as guided tour. crowd control and marketing research and analysis. A crowd counting solution should be scalable and be minimally intrusive (i.e.. device-free) to users. Image-based solutions are device-free. but cannot work well in a dim or dark environment. Non-image based solutions usually require every human being carrying device. and are inaccurate and unreliable in practice. In this paper. we present FCC. a device-Free Crowd Counting approach based on Channel State Information (CSI). Our design is motivated by our observation that CSI is highly sensitive to environment variation. like a frog eye. We theoretically discuss the relationship between the number of moving people and the variation of wireless channel state. A major challenge in our design of FCC is to find a …,True,CbGjM58AAAAJ:qUcmZB5y_30C,353,https://ieeexplore.ieee.org/abstract/document/6847958/,5649499033863373648,/scholar?cites=5649499033863373648,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.640.1968&rep=rep1&type=pdf,0,0,0
1282241,Twins: Device-free object tracking using passive tags,2015,Jinsong Han and Chen Qian and Xing Wang and Dan Ma and Jizhong Zhao and Wei Xi and Zhiping Jiang and Zhi Wang,24,IEEE/ACM Transactions on Networking,3,1605-1617,IEEE,Device-free object tracking provides a promising solution for many localization and tracking systems to monitor non-cooperative objects. such as intruders. which do not carry any transceiver. However. existing device-free solutions mainly use special sensors or active RFID tags. which are much more expensive compared to passive tags. In this paper. we propose a novel motion detection and tracking method using passive RFID tags. named Twins. The method leverages a newly observed phenomenon called critical state caused by interference among passive tags. We contribute to both theory and practice of this phenomenon by presenting a new interference model that precisely explains it and using extensive experiments to validate it. We design a practical Twins based intrusion detection system and implement a real prototype by commercial off-the-shelf RFID reader and tags. Experimental results show that …,True,CbGjM58AAAAJ:UeHWp8X0CEIC,139,https://ieeexplore.ieee.org/abstract/document/7112553/,5504673020324715084,/scholar?cites=5504673020324715084,,,https://arxiv.org/pdf/1308.6805,0,0,0
1282242,Reliable diversity-based spatial crowdsourcing by moving workers,2014,Peng Cheng and Xiang Lian and Zhao Chen and Rui Fu and Lei Chen and Jinsong Han and Jizhong Zhao,,arXiv preprint arXiv:1412.0223,,,,With the rapid development of mobile devices and the crowdsourcig platforms. the spatial crowdsourcing has attracted much attention from the database community. specifically. spatial crowdsourcing refers to sending a location-based request to workers according to their positions. In this paper. we consider an important spatial crowdsourcing problem. namely reliable diversity-based spatial crowdsourcing (RDB-SC). in which spatial tasks (such as taking videos/photos of a landmark or firework shows. and checking whether or not parking spaces are available) are time-constrained. and workers are moving towards some directions. Our RDB-SC problem is to assign workers to spatial tasks such that the completion reliability and the spatial/temporal diversities of spatial tasks are maximized. We prove that the RDB-SC problem is NP-hard and intractable. Thus. we propose three effective approximation approaches. including greedy. sampling. and divide-and-conquer algorithms. In order to improve the efficiency. we also design an effective cost-model-based index. which can dynamically maintain moving workers and spatial tasks with low cost. and efficiently facilitate the retrieval of RDB-SC answers. Through extensive experiments. we demonstrate the efficiency and effectiveness of our proposed approaches over both real and synthetic data sets.,True,CbGjM58AAAAJ:P5F9QuxV20EC,135,https://arxiv.org/abs/1412.0223,13196915364800433526,/scholar?cites=13196915364800433526,,,https://arxiv.org/pdf/1412.0223,0,0,0
1282243,Footprint: detecting Sybil attacks in urban vehicular networks,2011,Shan Chang and Yong Qi and Hongzi Zhu and Jizhong Zhao and Xuemin Shen,23,IEEE Transactions on Parallel and Distributed Systems,6,1103-1114,IEEE,In urban vehicular networks. where privacy. especially the location privacy of anonymous vehicles is highly concerned. anonymous verification of vehicles is indispensable. Consequently. an attacker who succeeds in forging multiple hostile identifies can easily launch a Sybil attack. gaining a disproportionately large influence. In this paper. we propose a novel Sybil attack detection mechanism. Footprint. using the trajectories of vehicles for identification while still preserving their location privacy. More specifically. when a vehicle approaches a road-side unit (RSU). it actively demands an authorized message from the RSU as the proof of the appearance time at this RSU. We design a location-hidden authorized message generation scheme for two objectives: first. RSU signatures on messages are signer ambiguous so that the RSU location information is concealed from the resulted authorized message; second. two …,True,CbGjM58AAAAJ:rO6llkc54NcC,128,https://ieeexplore.ieee.org/abstract/document/6060810/,12066625433784296858,/scholar?cites=12066625433784296858,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.5493&rep=rep1&type=pdf,0,0,0
1282244,Localization of wireless sensor networks in the wild: Pursuit of ranging quality,2012,Jizhong Zhao and Wei Xi and Yuan He and Yunhao Liu and Xiang-Yang Li and Lufeng Mo and Zheng Yang,21,IEEE/ACM Transactions on Networking,1,311-323,IEEE,Localization is a fundamental issue of wireless sensor networks that has been extensively studied in the literature. Our real-world experience from GreenOrbs. a sensor network system deployed in a forest. shows that localization in the wild remains very challenging due to various interfering factors. In this paper. we propose CDL. a Combined and Differentiated Localization approach for localization that exploits the strength of range-free approaches and range-based approaches using received signal strength indicator (RSSI). A critical observation is that ranging quality greatly impacts the overall localization accuracy. To achieve a better ranging quality. our method CDL incorporates virtual-hop localization. local filtration. and ranging-quality aware calibration. We have implemented and evaluated CDL by extensive real-world experiments in GreenOrbs and large-scale simulations. Our experimental and simulation …,True,CbGjM58AAAAJ:JV2RwH3_ST0C,124,https://ieeexplore.ieee.org/abstract/document/6216461/,4882543772002342103,/scholar?cites=4882543772002342103,,,http://tns.thss.tsinghua.edu.cn/sun/publications/2013.7.pdf,0,0,0
1282245,Femo: A platform for free-weight exercise monitoring with rfids,2015,Han Ding and Longfei Shangguan and Zheng Yang and Jinsong Han and Zimu Zhou and Panlong Yang and Wei Xi and Jizhong Zhao,,,,141-154,,Regular free-weight exercise helps to strengthen the body's natural movements and stabilize muscles that are important to strength. balance. and posture of human beings. Prior works have exploited wearable sensors or RF signal changes (eg. WiFi and Blue tooth) for activity sensing. recognition and countingetc.. However. none of them have incorporate three key factors necessary for a practical free-weight exercise monitoring system: recognizing free-weight activities on site. assessing their qualities. and providing useful feedbacks to the bodybuilder promptly. Our FEMO system responds to these demands. providing an integrated free-weight exercise monitoring service that incorporates all the essential functionalities mentioned above. FEMO achieves this by attaching passive RFID tags on the dumbbells and leveraging the Doppler shift profile of the reflected backscatter signals for on-site free-weight activity …,True,CbGjM58AAAAJ:pyW8ca7W8N0C,117,https://dl.acm.org/doi/abs/10.1145/2809695.2809708,13287218992985381188,/scholar?cites=13287218992985381188,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.6965&rep=rep1&type=pdf,0,0,0
1282246,Task assignment on multi-skill oriented spatial crowdsourcing,2016,Peng Cheng and Xiang Lian and Lei Chen and Jinsong Han and Jizhong Zhao,28,IEEE Transactions on Knowledge and Data Engineering,8,2201-2215,IEEE,With the rapid development of mobile devices and crowdsourcing platforms. the spatial crowdsourcing has attracted much attention from the database community. Specifically. the spatial crowdsourcing refers to sending location-based requests to workers. based on their current positions. In this paper. we consider a spatial crowdsourcing scenario. in which each worker has a set of qualified skills. whereas each spatial task (e.g.. repairing a house. decorating a room. and performing entertainment shows for a ceremony) is time-constrained. under the budget constraint. and required a set of skills. Under this scenario. we will study an important problem. namely  multi-skill spatial crowdsourcing  (MS-SC). which finds an optimal worker-and-task assignment strategy. such that skills between workers and tasks match with each other. and workers’ benefits are maximized under the budget constraint. We prove that the MS-SC …,True,CbGjM58AAAAJ:fPk4N6BV_jEC,115,https://ieeexplore.ieee.org/abstract/document/7446292/,12256729627633105424,/scholar?cites=12256729627633105424,,,https://arxiv.org/pdf/1510.03149,0,0,0
1282247,Cbid: A customer behavior identification system using passive tags,2015,Jinsong Han and Han Ding and Chen Qian and Wei Xi and Zhi Wang and Zhiping Jiang and Longfei Shangguan and Jizhong Zhao,24,IEEE/ACM Transactions on Networking,5,2885-2898,IEEE,Different from online shopping. in-store shopping has few ways to collect the customer behaviors before purchase. In this paper. we present the design and implementation of an on-site Customer Behavior IDentification system based on passive RFID tags. named CBID. By collecting and analyzing wireless signal features. CBID can detect and track tag movements and further infer corresponding customer behaviors. We model three main objectives of behavior identification by concrete problems and solve them using novel protocols and algorithms. The design innovations of this work include a Doppler effect based protocol to detect tag movements. an accurate Doppler frequency estimation algorithm. an image-based human count estimation protocol and a tag clustering algorithm using cosine similarity. We have implemented a prototype of CBID in which all components are built by off-the-shelf devices. We have …,True,CbGjM58AAAAJ:GnPB-g6toBAC,101,https://ieeexplore.ieee.org/abstract/document/7343754/,9750892667325500380,/scholar?cites=9750892667325500380,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.711.4336&rep=rep1&type=pdf,0,0,0
1282248,Efficient data aggregation in multi-hop wireless sensor networks under physical interference model,2009,Xiang-Yang Li and XiaoHua Xu and ShiGuang Wang and ShaoJie Tang and GuoJun Dai and JiZhong Zhao and Yong Qi,,,,353-362,IEEE,Efficient aggregation of data collected by sensors is crucial for a successful application of wireless sensor networks (WSNs). Both minimizing the energy cost and reducing the time duration (or called latency) of data aggregation have been extensively studied for WSNs. Algorithms with theoretical performance guarantees are only known under the protocol interference model. or graph-based interference models generally. In this paper. we study the problem of designing time efficient aggregation algorithm under the physical interference model. To the best of our knowledge. no algorithms with theoretical performance guarantees are known for this problem in the literature. We propose an efficient algorithm that produces a data aggregation tree and a collision-free aggregation schedule. We theoretically prove that the latency of our aggregation schedule is bounded by O(R + Delta) time-slots. Here R is the network …,True,CbGjM58AAAAJ:M3NEmzRMIkIC,92,https://ieeexplore.ieee.org/abstract/document/5336978/,8208833529213529374,/scholar?cites=8208833529213529374,,,http://mypages.iit.edu/~swang44/05336978.pdf,0,0,0
1282249,Rejecting the attack: Source authentication for wi-fi management frames using csi information,2013,Zhiping Jiang and Jizhong Zhao and Xiang-Yang Li and Jinsong Han and Wei Xi,,,,2544-2552,IEEE,Comparing to well protected data frames. Wi-Fi management frames (MFs) are extremely vulnerable to various attacks. Since MFs are transmitted without encryption or authentication. attackers can easily launch various attacks by forging the MFs. In a collaborative environment with many Wi-Fi sniffers. such attacks can be easily detected by sensing the anomaly RSS changes. However. it is quite difficult to identify these spoofing attacks without assistance from other nodes. By exploiting some unique characteristics (e.g.. rapid spatial decorrelation. independence of Txpower. and much richer dimensions) of 802.11n Channel State Information (CSI). we design and implement CSITE. a prototype system to authenticate the Wi-Fi management frames on PHY layer merely by one station. Our system CSITE. built upon off-the-shelf hardware. achieves precise spoofing detection without collaboration and in-advance …,True,CbGjM58AAAAJ:KxtntwgDAa4C,78,https://ieeexplore.ieee.org/abstract/document/6567061/,15617147486473238864,/scholar?cites=15617147486473238864,,,https://arxiv.org/pdf/1208.0412,0,0,0
1282250,Identifying geochemical anomalies associated with Cu and Pb–Zn skarn mineralization using principal component analysis and spectrum–area fractal modeling in the Gangdese Belt …,2011,Renguang Zuo,111,Journal of Geochemical Exploration,1-2,13-22,Elsevier,The Gangdese Belt is now recognized as an important Cu polymetallic mineralization belt. Recent studies suggest that apart from porphyry copper deposits. polymetallic skarn deposits are another significant deposit type in this belt. In this paper. principal component analysis (PCA) and spectrum–area (S–A) fractal modeling are used to identify geochemical anomalies associated with Cu and Pb–Zn skarn mineralization based on Cu. Pb. Zn and Ag stream sediment data. Firstly. the raster maps of Cu. Pb. Zn and Ag were obtained by multifractal inverse distance weighted (MIDW). Secondly. PCA was used to combine the Cu. Pb. Zn and Ag concentration values. Finally. S–A analysis was used to decompose the first component pattern obtained by the PCA. The results show that major anomalies of Cu. Pb. Zn and Ag are mostly located around mapped intrusions. and along E–W trending faults. where Cu and Pb–Zn …,True,8zvKIyAAAAAJ:zYLM7Y9cAGgC,197,https://www.sciencedirect.com/science/article/pii/S0375674211001051,3558286075193548261,/scholar?cites=3558286075193548261,,,,0,0,0
1282251,Application of singularity mapping technique to identify local anomalies using stream sediment geochemical data. a case study from Gangdese. Tibet. western China,2009,Renguang Zuo and Qiuming Cheng and FP Agterberg and Qinglin Xia,101,Journal of Geochemical Exploration,3,225-235,Elsevier,Identifying geochemical anomalies from background is a fundamental task in exploration geochemistry. The Gangdese mineral district in western China has complex geochemical surface expression due to complex geological background and was chosen as a study area for recognition of the spatial distribution of geochemical elements and separating anomalies from background using stream sediment geochemical data. The results illustrate that weak anomalies are hidden within the strong variance of background and are not well identified by means of inverse distance weighted; neither are they clearly identified by the C–A method if this method is applied to the whole study area. On the other hand. singularity values provide new information that complements use of original concentration values and can quantify the properties of enrichment and depletion caused by mineralization. In general. producing maps of …,True,8zvKIyAAAAAJ:u5HHmVD_uO8C,192,https://www.sciencedirect.com/science/article/pii/S0375674208000873,17256935466495548640,/scholar?cites=17256935466495548640,,,,0,0,0
1282252,Support vector machine: a tool for mapping mineral prospectivity,2011,Renguang Zuo and Emmanuel John M Carranza,37,Computers & Geosciences,12,1967-1975,Pergamon,In this contribution. we describe an application of support vector machine (SVM). a supervised learning algorithm. to mineral prospectivity mapping. The free R package e1071 is used to construct a SVM with sigmoid kernel function to map prospectivity for Au deposits in western Meguma Terrain of Nova Scotia (Canada). The SVM classification accuracies of ‘deposit’ are 100%. and the SVM classification accuracies of the ‘non-deposit’ are greater than 85%. The SVM classifications of mineral prospectivity have 5–9% lower total errors. 13–14% higher false-positive errors and 25–30% lower false-negative errors compared to those of the WofE prediction. The prospective target areas predicted by both SVM and WofE reflect. nonetheless. controls of Au deposit occurrence in the study area by NE–SW trending anticlines and contact zones between Goldenville and Halifax Formations. The results of the study indicate the …,True,8zvKIyAAAAAJ:eQOLeE2rZwMC,184,https://www.sciencedirect.com/science/article/pii/S0098300410003249,1217539139111159316,/scholar?cites=1217539139111159316,,,https://www.academia.edu/download/55120436/1-s2.0-S0098300410003249-main.pdf,0,0,0
1282253,Fractal/multifractal modeling of geochemical data: A review,2016,Renguang Zuo and Jian Wang,164,,,33-41,Elsevier,Over the past several decades. a wide range of complex structures or phenomena of interest to geologists and geochemists has been quantitatively characterized using fractal/multifractal theory and models. With respect to the application of fractal/multifractal models to geochemical data. the focus has been on how to decompose geochemical populations or quantify the spatial distribution of geochemical data. A variety of fractal/multifractal models for this purpose have been proposed on the basis of the scaling characteristics of geochemical data. These include the concentration–area (C-A) fractal model. concentration–distance (C-D) fractal model. spectrum–area (S-A) multifractal model. multifractal singularity analysis. and the concentration–volume (C-V) fractal model. These fractal models have been widely demonstrated to be useful. as indicated by the increasing number of published papers. In this study. fractal …,True,8zvKIyAAAAAJ:r0BpntZqJG4C,179,https://www.sciencedirect.com/science/article/pii/S0375674215000746,8972417169229674791,/scholar?cites=8972417169229674791,,,https://www.researchgate.net/profile/Jian_Wang167/publication/276413763_Fractalmultifractal_modeling_of_geochemical_data_A_review/links/5dad660d4585155e27f77ca8/Fractal-multifractal-modeling-of-geochemical-data-A-review.pdf,0,0,0
1282254,Application of fractal models to characterization of vertical distribution of geochemical element concentration,2009,Renguang Zuo and Qiuming Cheng and Qinglin Xia,102,Journal of Geochemical Exploration,1,37-43,Elsevier,Characterization of the vertical distribution of geochemical element concentration is essential for economic planning in the mining industry. 10 mineralized boreholes and 1 non-mineralized borehole from the Qulong copper deposit. Tibet. western China. were collected to identify the vertical distribution properties of Cu values using fractal models. The vertical distribution of Cu values in mineralized and non-mineralized boreholes shows a positive skewed distribution in the former and multimodal distribution in the latter. The results obtained by the box counting method show that the vertical distributions of Cu values in mineralized and non-mineralized boreholes exhibit self-similarity with box dimensions ranging from 1.28 to 1.37. The box dimensions of mineralized boreholes are greater than that of Cu values in the non-mineralized borehole. indicating that the mineralization makes the distribution of Cu values more …,True,8zvKIyAAAAAJ:u-x6o8ySG0sC,143,https://www.sciencedirect.com/science/article/pii/S0375674208001416,17324866269366874881,/scholar?cites=17324866269366874881,,,http://ir.nsfc.gov.cn/paperDownload/1000000869399.pdf,0,0,0
1282255,A comparison study of the C–A and S–A models with singularity analysis to identify geochemical anomalies in covered areas,2013,Renguang Zuo and Qinglin Xia and Daojun Zhang,33,Applied geochemistry,,165-172,Pergamon,Fractal/multifractal modeling of geochemical data is an interesting topic in the field of applied geochemistry. Identification of weak anomalies for mineral exploration in covered areas is one of the most challenging tasks for utilization of geochemical data. In this study. three fractal models. consisting of the concentration–area (C–A). spectrum–area (S–A) and singularity index models were applied to identify geochemical anomalies in the covered area located in the Chaobuleng Fe polymetallic district. Inner Mongolia (China). The results show that (1) the grassland cover weakens the concentrations of geochemical elements; (2) the C–A model has a limitation to identify weak anomalies in covered areas; (3) the S–A model is a powerful tool to decompose mixed geochemical patterns into a geochemical anomaly map and a varied geochemical background map but suffers edge effects in an irregular shaped study area …,True,8zvKIyAAAAAJ:KlAtU1dfN6UC,119,https://www.sciencedirect.com/science/article/pii/S0883292713000425,6696194073597853165,/scholar?cites=6696194073597853165,,,,0,0,0
1282256,Compositional data analysis in the study of integrated geochemical anomalies associated with mineralization,2013,Renguang Zuo and Qinglin Xia and Haicheng Wang,28,Applied geochemistry,,202-211,Pergamon,Geochemical data are typical compositional data which should be opened prior to univariate and multivariate data analysis. In this study. a frequency-based method (robust principal component analysis. RPCA) and a frequency-space-based method (spectrum–area fractal model. S–A) are applied to explore the effects of the data closure problem and to study the integrated geochemical anomalies associated with polymetallic Cu mineralization using a stream sediment geochemical dataset collected from the Zhongteng district. Fujian Province (China). The results show that: (1) geochemical data should be opened prior to RPCA to avoid spurious correlation between variables; (2) geochemical pattern is a superimposition of multi-processes and should be decomposed; and (3) the S–A fractal model is a powerful tool for decomposing the mixed geochemical pattern.,True,8zvKIyAAAAAJ:5nxA0vEk-isC,110,https://www.sciencedirect.com/science/article/pii/S0883292712003137,13430495086202298305,/scholar?cites=13430495086202298305,,,,0,0,0
1282257,Decomposing of mixed pattern of arsenic using fractal model in Gangdese belt. Tibet. China,2011,Renguang Zuo,26,Applied geochemistry,,S271-S273,Pergamon,Decomposing mixed geochemical patterns is a challenge in geochemical exploration and environmental assessment. In this paper. the spectrum–area technique (S–A) is used to decompose a mixed pattern of arsenic in Gangdese belt based on stream sediment data. S–A is a multifractal model based on power–law relationships between area of the set consisting of wave numbers with spectral energy density above S[A(>S)] on the 2D frequency domain. The original spatial distribution map of arsenic obtained by inverse distance weighted (IDW) shows a mixed pattern due to superposition of different geological processes or events and is converted into the frequency domain by means of Fourier transformation. Two components. including power spectrum density and phases. are obtained. The spectrum energy density (S) and the area (A) enclosed by the above-threshold spectrum energy density is plotted on a log …,True,8zvKIyAAAAAJ:Y0pCki6q_DkC,109,https://www.sciencedirect.com/science/article/pii/S0883292711002010,864722642625581851,/scholar?cites=864722642625581851,,,,0,0,0
1282258,Recognition of geochemical anomalies using a deep autoencoder network,2016,Yihui Xiong and Renguang Zuo,86,Computers & Geosciences,,75-82,Pergamon,In this paper. we train an autoencoder network to encode and reconstruct a geochemical sample population with unknown complex multivariate probability distributions. During the training. small probability samples contribute little to the autoencoder network. These samples can be recognized by the trained model as anomalous samples due to their comparatively higher reconstructed errors. The southwestern Fujian district (China) is chosen as a case study area. A variety of learning rates. iterations. and the size of each hidden layer are constructing and training the deep autoencoder networks on all the geochemical samples. The reconstruction error (or. anomaly score) of each training sample is used to recognize multivariate geochemical anomalies associated with Fe polymetallic mineralization. By comparing the results obtained with a continuous restricted Boltzmann machine. we conclude that the autoencoder …,True,8zvKIyAAAAAJ:hMod-77fHWUC,107,https://www.sciencedirect.com/science/article/pii/S0098300415300728,279801877298550377,/scholar?cites=279801877298550377,,,http://zarmesh.ir/wp-content/uploads/2017/04/Recognition-of-eochemical-anomalies-using-a-deep-autoencoder-network-2016.pdf,0,0,0
1282259,Fractal/multifractal modelling of geochemical exploration data,2012,Renguang Zuo and Emmanuel John M Carranza and Qiuming Cheng,122,Journal of Geochemical Exploration,,1-3,Elsevier,[Extract] Geochemical data analysis plays an important role in mineral exploration and environmental studies. For these purposes. one or all of the following aspects of geochemical data (mainly element concentrations) must be considered (Cheng. 1999) — frequency distributions. correlations and variances. geometrical properties (shape and orientation) of anomalies. and scale independence of patterns. Within the past six decades. the frequency and spatial distributions of geochemical data have been widely studied (e.g.. Agterberg. 2007. Ahrens. 1954. Ahrens. 1957. Ahrens. 1963a. Ahrens. 1963b. Ahrens. 1966. Allègre and Lewin. 1995. Carranza. 2008. Cheng et al.. 1994. De Wijs. 1951. De Wijs. 1953. Krige. 1966. Krige. 1978. Turcotte. 1986. Turcotte. 1997 and Vistelius. 1960) since they are the basis for delineating geochemical anomalies and for determining geochemical baselines in the fields of mineral exploration and environmental studies.,True,8zvKIyAAAAAJ:UebtZRa9Y70C,105,http://eprints.jcu.edu.au/27327/,15728650763641909503,/scholar?cites=15728650763641909503,,,,0,0,0
1282260,Identification of weak anomalies: A multifractal perspective,2015,Renguang Zuo and Jian Wang and Guoxiong Chen and Mingguo Yang,148,Journal of Geochemical Exploration,,12-24,Elsevier,Attention has increasingly been focused on weak geochemical anomalies. In this paper. the singularity mapping technique. a powerful multifractal tool to identify weak anomalies. is presented. The original algorithm for estimation of the singularity index could not directly process the data containing negative values. and the resulting singularity index is influenced by the background value. A modified algorithm for estimation of the singularity index is introduced to overcome these shortcomings. and a Matlab program is coded for estimation of the singularity index. using both the original and modified algorithms. The advantage of the modified algorithm is demonstrated using a case study from Chaobuleng Fe polymetallic district. covered with grassland. in Inner Mongolia of northern China.,True,8zvKIyAAAAAJ:b0M2c_1WBrUC,81,https://www.sciencedirect.com/science/article/pii/S037567421400171X,11224597119202074141,/scholar?cites=11224597119202074141,,,,0,0,0
1282261,Enhanced Deep Residual Networks for Single Image Super-Resolution,2017,Bee Lim and Sanghyun Son and Heewon Kim and Seungjun Nah and Kyoung Mu Lee,,,,136-144,,Recent research on super-resolution has progressed with the development of deep convolutional neural networks (DCNN). In particular. residual learning techniques exhibit improved performance. In this paper. we develop an enhanced deep super-resolution network (EDSR) with performance exceeding those of current state-of-the-art SR methods. The significant performance improvement of our model is due to optimization by removing unnecessary modules in conventional residual networks. The performance is further improved by expanding the model size while we stabilize the training procedure. We also propose a new multi-scale deep super-resolution system (MDSR) and training method. which can reconstruct high-resolution images of different upscaling factors in a single model. The proposed methods show superior performance over the state-of-the-art methods on benchmark datasets and prove its excellence by winning the NTIRE2017 Super-Resolution Challenge.,True,hEr2AKsAAAAJ:9yKSN-GCB0IC,2149,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Lim_Enhanced_Deep_Residual_CVPR_2017_paper.html,2018780490255888892,/scholar?cites=2018780490255888892,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Lim_Enhanced_Deep_Residual_CVPR_2017_paper.pdf,0,0,0
1282262,Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring,2017,Seungjun Nah and Tae Hyun Kim and Kyoung Mu Lee,,,,,,Non-uniform blind deblurring for general dynamic scenes is a challenging computer vision problem as blurs arise not only from multiple object motions but also from camera shake. scene depth variation. To remove these complicated motion blurs. conventional energy optimization based methods rely on simple assumptions such that blur kernel is partially uniform or locally linear. Moreover. recent machine learning based methods also depend on synthetic blur datasets generated under these assumptions. This makes conventional deblurring methods fail to remove blurs where blur kernel is difficult to approximate or parameterize (eg object motion boundaries). In this work. we propose a multi-scale convolutional neural network that restores sharp images in an end-to-end manner where blur is caused by various sources. Together. we present multi-scale loss function that mimics conventional coarse-to-fine approaches. Furthermore. we propose a new large-scale dataset that provides pairs of realistic blurry image and the corresponding ground truth sharp image that are obtained by a high-speed camera. With the proposed model trained on this dataset. we demonstrate empirically that our method achieves the state-of-the-art performance in dynamic scene deblurring not only qualitatively. but also quantitatively.,True,hEr2AKsAAAAJ:d1gkVwhDpl0C,723,http://openaccess.thecvf.com/content_cvpr_2017/html/Nah_Deep_Multi-Scale_Convolutional_CVPR_2017_paper.html,5306020987846368461,/scholar?cites=5306020987846368461,,,https://openaccess.thecvf.com/content_cvpr_2017/papers/Nah_Deep_Multi-Scale_Convolutional_CVPR_2017_paper.pdf,0,0,0
1282263,NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang,,,,114-125,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,hEr2AKsAAAAJ:u-x6o8ySG0sC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1282264,NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study,2019,Seungjun Nah and Sungyong Baik and Seokil Hong and Gyeongsik Moon and Sanghyun Son and Radu Timofte and Kyoung Mu Lee,,,,0-0,,This paper introduces a novel large dataset for video deblurring. video super-resolution and studies the state-of-the-art as emerged from the NTIRE 2019 video restoration challenges. The video deblurring and video super-resolution challenges are each the first challenge of its kind. with 4 competitions. hundreds of participants and tens of proposed solutions. Our newly collected REalistic and Diverse Scenes dataset (REDS) was employed by the challenges. In our study. we compare the solutions from the challenges to a set of representative methods from the literature and evaluate them on our proposed REDS dataset. We find that the NTIRE 2019 challenges push the state-of-the-art in video deblurring and super-resolution. reaching compelling performance on our newly proposed REDS dataset.,True,hEr2AKsAAAAJ:W7OEmFMy1HYC,63,http://openaccess.thecvf.com/content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_and_Super-Resolution_Dataset_and_CVPRW_2019_paper.html,16526563876244404287,/scholar?cites=16526563876244404287,,,http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_and_Super-Resolution_Dataset_and_CVPRW_2019_paper.pdf,0,0,0
1282265,Dynamic Video Deblurring Using a Locally Adaptive Blur Model,2017,Tae Hyun Kim and Seungjun Nah and Kyoung Mu Lee,40,IEEE transactions on pattern analysis and machine intelligence,10,2374-2387,IEEE,State-of-the-art video deblurring methods cannot handle blurry videos recorded in dynamic scenes since they are built under a strong assumption that the captured scenes are static. Contrary to the existing methods. we propose a new video deblurring algorithm that can deal with general blurs inherent in dynamic scenes. To handle general and locally varying blurs caused by various sources. such as moving objects. camera shake. depth variation. and defocus. we estimate pixel-wise varying non-uniform blur kernels. We infer bidirectional optical flows to handle motion blurs. and also estimate Gaussian blur maps to remove optical blur from defocus. Therefore. we propose a single energy model that jointly estimates optical flows. defocus blur maps and latent frames. We also provide a framework and efficient solvers to minimize the proposed energy model. By optimizing the energy model. we achieve significant …,True,hEr2AKsAAAAJ:qjMakFHDy7sC,42,https://ieeexplore.ieee.org/abstract/document/8063973/,7337828797336081981,/scholar?cites=7337828797336081981,,,,0,0,0
1282266,Clustering Convolutional Kernels to Compress Deep Neural Networks,2018,Sanghyun Son and Seungjun Nah and Kyoung Mu Lee,,,,216-232,,In this paper. we propose a novel method to compress CNNs by reconstructing the network from a small set of spatial convolution kernels. Starting from a pre-trained model. we extract representative 2D kernel centroids using k-means clustering. Each centroid replaces the corresponding kernels of the same cluster. and we use indexed representations instead of saving whole kernels. Kernels in the same cluster share their weights. and we fine-tune the model while keeping the compressed state. Furthermore. we also suggest an efficient way of removing redundant calculations in the compressed convolutional layers. We experimentally show that our technique works well without harming the accuracy of widely-used CNNs. Also. our ResNet-18 even outperforms its uncompressed counterpart at ILSVRC2012 classification task with over 10x compression ratio.,True,hEr2AKsAAAAJ:IjCSPb-OGe4C,34,http://openaccess.thecvf.com/content_ECCV_2018/html/Sanghyun_Son_Clustering_Kernels_for_ECCV_2018_paper.html,12419171226701641771,/scholar?cites=12419171226701641771,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Son_Clustering_Kernels_for_ECCV_2018_paper.pdf,0,0,0
1282267,Recurrent Neural Networks with Intra-Frame Iterations for Video Deblurring,2019,Seungjun Nah and Sanghyun Son and Kyoung Mu Lee,,,,8102-8111,,Recurrent neural networks (RNNs) are widely used for sequential data processing. Recent state-of-the-art video deblurring methods bank on convolutional recurrent neural network architectures to exploit the temporal relationship between neighboring frames. In this work. we aim to improve the accuracy of recurrent models by adapting the hidden states transferred from past frames to the frame being processed so that the relations between video frames could be better used. We iteratively update the hidden state via re-using RNN cell parameters before predicting an output deblurred frame. Since we use existing parameters to update the hidden state. our method improves accuracy without additional modules. As the architecture remains the same regardless of iteration number. fewer iteration models can be considered as a partial computational path of the models with more iterations. To take advantage of this property. we employ a stochastic method to optimize our iterative models better. At training time. we randomly choose the iteration number on the fly and apply a regularization loss that favors less computation unless there are considerable reconstruction gains. We show that our method exhibits state-of-the-art video deblurring performance while operating in real-time speed.,True,hEr2AKsAAAAJ:Y0pCki6q_DkC,32,http://openaccess.thecvf.com/content_CVPR_2019/html/Nah_Recurrent_Neural_Networks_With_Intra-Frame_Iterations_for_Video_Deblurring_CVPR_2019_paper.html,412105262799421119,/scholar?cites=412105262799421119,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Nah_Recurrent_Neural_Networks_With_Intra-Frame_Iterations_for_Video_Deblurring_CVPR_2019_paper.pdf,0,0,0
1282268,NTIRE 2019 Challenge on Video Deblurring: Methods and Results,2019,Seungjun Nah and Radu Timofte and Sungyong Baik and Seokil Hong and Gyeongsik Moon and Sanghyun Son and Kyoung Mu Lee,,,,0-0,,This paper reviews the first NTIRE challenge on video deblurring (restoration of rich details and high frequency components from blurred video frames) with focus on the proposed solutions and results. A new REalistic and Diverse Scenes dataset (REDS) was employed. The challenge was divided into 2 tracks. Track 1 employed dynamic motion blurs while Track 2 had additional MPEG video compression artifacts. Each competition had 109 and 93 registered participants. Total 13 teams competed in the final testing phase. They gauge the state-of-the-art in video deblurring problem.,True,hEr2AKsAAAAJ:ufrVoPGSRksC,18,http://openaccess.thecvf.com/content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_Methods_and_Results_CVPRW_2019_paper.html,18052613751158514991,/scholar?cites=18052613751158514991,,,http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_Methods_and_Results_CVPRW_2019_paper.pdf,0,0,0
1282269,NTIRE 2020 Challenge on Image and Video Deblurring,2020,Seungjun Nah and Sanghyun Son and Radu Timofte and Kyoung Mu Lee,,,,416-417,,Motion blur is one of the most common degradation artifacts in dynamic scene photography. This paper reviews the NTIRE 2020 Challenge on Image and Video Deblurring. In this challenge. we present the evaluation results from 3 competition tracks as well as the proposed solutions. Track 1 aims to develop single-image deblurring methods focusing on restoration quality. On Track 2. the image deblurring methods are executed on a mobile platform to find the balance of the running speed and the restoration accuracy. Track 3 targets developing video deblurring methods that exploit the temporal relation between input frames. In each competition. there were 163. 135. and 102 registered participants and in the final testing phase. 9. 4. and 7 teams competed. The winning methods demonstrate the state-of-the-art performance on image and video deblurring tasks.,True,hEr2AKsAAAAJ:8k81kl-MbHgC,16,http://openaccess.thecvf.com/content_CVPRW_2020/html/w31/Nah_NTIRE_2020_Challenge_on_Image_and_Video_Deblurring_CVPRW_2020_paper.html,15337749084710269014,/scholar?cites=15337749084710269014,,,http://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Nah_NTIRE_2020_Challenge_on_Image_and_Video_Deblurring_CVPRW_2020_paper.pdf,0,0,0
1282270,NTIRE 2019 Challenge on Video Super-Resolution: Methods and Results,2019,Seungjun Nah and Radu Timofte and Shuhang Gu and Sungyong Baik and Seokil Hong and Gyeongsik Moon and Sanghyun Son and Kyoung Mu Lee,,,,0-0,,This paper reviews the first NTIRE challenge on video super-resolution (restoration of rich details in low-resolution video frames) with focus on proposed solutions and results. A new REalistic and Diverse Scenes dataset (REDS) was employed. The challenge was divided into 2 tracks. Track 1 employed standard bicubic downscaling setup while Track 2 had realistic dynamic motion blurs. Each competition had 124 and 104 registered participants. There were total 14 teams in the final testing phase. They gauge the state-of-the-art in video super-resolution.,True,hEr2AKsAAAAJ:_FxGoFyzp5QC,15,http://openaccess.thecvf.com/content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Super-Resolution_Methods_and_Results_CVPRW_2019_paper.html,11510217929398098222,/scholar?cites=11510217929398098222,,,http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Super-Resolution_Methods_and_Results_CVPRW_2019_paper.pdf,0,0,0
1282271,AIM 2020 Challenge on Video Temporal Super-Resolution,2020,Sanghyun Son and Jaerin Lee and Seungjun Nah and Radu Timofte and Kyoung Mu Lee,,arXiv preprint arXiv:2009.12987,,,,Videos in the real-world contain various dynamics and motions that may look unnaturally discontinuous in time when the recorded frame rate is low. This paper reports the second AIM challenge on Video Temporal Super-Resolution (VTSR). a.k.a. frame interpolation. with a focus on the proposed solutions. results. and analysis. From low-frame-rate (15 fps) videos. the challenge participants are required to submit higher-frame-rate (30 and 60 fps) sequences by estimating temporally intermediate frames. To simulate realistic and challenging dynamics in the real-world. we employ the REDS_VTSR dataset derived from diverse videos captured in a hand-held camera for training and evaluation purposes. There have been 68 registered participants in the competition. and 5 teams (one withdrawn) have competed in the final testing phase. The winning team proposes the enhanced quadratic video interpolation …,True,hEr2AKsAAAAJ:MXK_kJrjxJIC,10,https://link.springer.com/chapter/10.1007/978-3-030-66823-5_2,2167328415055344129,/scholar?cites=2167328415055344129,,,https://arxiv.org/pdf/2009.12987,0,0,0
1282272,Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning,2015,Babak Alipanahi and Andrew Delong and Matthew T Weirauch and Brendan J Frey,33,Nature biotechnology,,831-838,Nature Publishing Group,Knowing the sequence specificities of DNA-and RNA-binding proteins is essential for developing models of the regulatory processes in biological systems and for identifying causal disease variants. Here we show that sequence specificities can be ascertained from experimental data with'deep learning'techniques. which offer a scalable. flexible and unified computational approach for pattern discovery. Using a diverse array of experimental data and evaluation metrics. we find that deep learning outperforms other state-of-the-art methods. even when training on in vitro data and testing on in vivo data. We call this approach DeepBind and have built a stand-alone software tool that is fully automatic and handles millions of sequences per experiment. Specificities determined by DeepBind are readily visualized as a weighted ensemble of position weight matrices or as a'mutation map'that indicates how variations affect …,True,-FEYIEMAAAAJ:NXb4pA-qfm4C,1702,https://www.nature.com/articles/nbt.3300.,15227025011012801704,/scholar?cites=15227025011012801704,,,https://u.osu.edu/bmbl/files/2019/01/2016-03-18-Predicting-the-sequence-specificities-of-DNA-and-RNA-binding-proteins-by-deep-learning-1xugui1.pdf,0,0,0
1282273,Fast Approximate Energy Minimization with Label Costs,2012,Andrew Delong and Anton Osokin and Hossam N Isack and Yuri Boykov,96,International Journal of Computer Vision (IJCV),1,1-27,Springer,The α-expansion algorithm has had a significant impact in computer vision due to its generality. effectiveness. and speed. It is commonly used to minimize energies that involve unary. pairwise. and specialized higher-order terms. Our main algorithmic contribution is an extension of α-expansion that also optimizes “label costs” with well-characterized optimality bounds. Label costs penalize a solution based on the set of labels that appear in it. for example by simply penalizing the number of labels in the solution.Our energy has a natural interpretation as minimizing description length (MDL) and sheds light on classical algorithms like K-means and expectation-maximization (EM). Label costs are useful for multi-model fitting and we demonstrate several such applications: homography detection. motion segmentation. image segmentation. and compression. Our C++ and MATLAB code is publicly …,True,-FEYIEMAAAAJ:zYLM7Y9cAGgC,613,https://link.springer.com/article/10.1007/s11263-011-0437-z,3779287559323718435,/scholar?cites=3779287559323718435,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.296.9767&rep=rep1&type=pdf,0,0,0
1282274,Fast Approximate Energy Minimization with Label Costs,2010,Andrew Delong and Anton Osokin and Hossam N Isack and Yuri Boykov,,,,2173-2180,IEEE,The α-expansion algorithm has had a significant impact in computer vision due to its generality. effectiveness. and speed. It is commonly used to minimize energies that involve unary. pairwise. and specialized higher-order terms. Our main algorithmic contribution is an extension of α-expansion that also optimizes “label costs” with well-characterized optimality bounds. Label costs penalize a solution based on the set of labels that appear in it. for example by simply penalizing the number of labels in the solution.Our energy has a natural interpretation as minimizing description length (MDL) and sheds light on classical algorithms like K-means and expectation-maximization (EM). Label costs are useful for multi-model fitting and we demonstrate several such applications: homography detection. motion segmentation. image segmentation. and compression. Our C++ and MATLAB code is publicly …,True,-FEYIEMAAAAJ:u-x6o8ySG0sC,613,https://link.springer.com/article/10.1007/s11263-011-0437-z,3779287559323718435,/scholar?cites=3779287559323718435,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.296.9767&rep=rep1&type=pdf,0,0,0
1282275,Deep learning in biomedicine,2018,Michael Wainberg and Daniele Merico and Andrew Delong and Brendan J Frey,36,Nature biotechnology,,,829–838,Deep learning is beginning to impact biological research and biomedical applications as a result of its ability to integrate vast datasets. learn arbitrarily complex relationships and incorporate existing knowledge. Already. deep learning models can predict. with varying degrees of success. how genetic variation alters cellular processes involved in pathogenesis. which small molecules will modulate the activity of therapeutically relevant proteins. and whether radiographic images are indicative of disease. However. the flexibility of deep learning creates new challenges in guaranteeing the performance of deployed systems and in establishing trust with stakeholders. clinicians and regulators. who require a rationale for decision making. We argue that these challenges will be overcome using the same flexibility that created them; for example. by training deep models so that they can output a rationale for their predictions …,True,-FEYIEMAAAAJ:QYdC8u9Cj1oC,192,https://www.nature.com/articles/nbt.4233.pdf?origin=ppub,5670417573484158608,/scholar?cites=5670417573484158608,,,http://listserv-archives.org/attachments/20180913/7f0e3dbf/attachment.pdf,0,0,0
1282276,Machine learning in genomic medicine: a review of computational problems and data sets,2015,Michael KK Leung and Andrew Delong and Babak Alipanahi and Brendan J Frey,104,,1,176-197,IEEE,In this paper. we provide an introduction to machine learning tasks that address important problems in genomic medicine. One of the goals of genomic medicine is to determine how variations in the DNA of individuals can affect the risk of different diseases. and to find causal explanations so that targeted therapies can be designed. Here we focus on how machine learning can help to model the relationship between DNA and the quantities of key molecules in the cell. with the premise that these quantities. which we refer to as cell variables. may be associated with disease risks. Modern biology allows high-throughput measurement of many such cell variables. including gene expression. splicing. and proteins binding to nucleic acids. which can all be treated as training targets for predictive models. With the growing availability of large-scale data sets and advanced computational techniques such as deep learning …,True,-FEYIEMAAAAJ:HtEfBTGE9r8C,181,https://ieeexplore.ieee.org/abstract/document/7347331/,15640628251497119215,/scholar?cites=15640628251497119215,,,https://ieeexplore.ieee.org/iel7/5/4357935/07347331.pdf,0,0,0
1282277,Globally Optimal Segmentation of Multi-Region Objects,2009,Andrew Delong and Yuri Boykov,,,,285-292,IEEE,Many objects contain spatially distinct regions. each with a unique colour/texture model. Mixture models ignore the spatial distribution of colours within an object. and thus cannot distinguish between coherent parts versus randomly distributed colours. We show how to encode geometric interactions between distinct region+boundary models. such as regions being interior/exterior to each other along with preferred distances between their boundaries. With a single graph cut. our method extracts only those multi-region objects that satisfy such a combined model. We show applications in medical segmentation and scene layout estimation. Unlike Li et al. we do not need “domain unwrapping” nor do we have topological limits on shapes.,True,-FEYIEMAAAAJ:9yKSN-GCB0IC,175,https://ieeexplore.ieee.org/abstract/document/5459263/,7697481217179901210,/scholar?cites=7697481217179901210,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.332.3794&rep=rep1&type=pdf,0,0,0
1282278,A Scalable Graph-Cut Algorithm for ND Grids,2008,Andrew Delong and Yuri Boykov,,,,,IEEE,Global optimisation via s-t graph cuts is widely used in computer vision and graphics. To obtain high-resolution output. graph cut methods must construct massive N-D grid-graphs containing billions of vertices. We show that when these graphs do not fit into physical memory. current max-flow/min-cut algorithms-the workhorse of graph cut methods-are totally impractical. Others have resorted to banded or hierarchical approximation methods that get trapped in local minima. which loses the main benefit of global optimisation. We enhance the push-relabel algorithm for maximum flow [14] with two practical contributions. First. true global minima can now be computed on immense grid-like graphs too large for physical memory. These graphs are ubiquitous in computer vision. medical imaging and graphics. Second. for commodity multi-core platforms our algorithm attains near-linear speedup with respect to number of …,True,-FEYIEMAAAAJ:u5HHmVD_uO8C,165,https://ieeexplore.ieee.org/abstract/document/4587464/,2801450956597601180,/scholar?cites=2801450956597601180,,,https://www.csd.uwo.ca/~yboykov/Papers/cvpr08.pdf,0,0,0
1282279,An integral solution to surface evolution PDEs via geo-cuts,2006,Yuri Boykov and Vladimir Kolmogorov and Daniel Cremers and Andrew Delong,,,,409-422,Springer Berlin/Heidelberg,We introduce a new approach to modelling gradient flows of contours and surfaces. While standard variational methods (e.g. level sets) compute local interface motion in a differential fashion by estimating local contour velocity via energy derivatives. we propose to solve surface evolution PDEs by explicitly estimating integral motion of the whole surface. We formulate an optimization problem directly based on an integral characterization of gradient flow as an infinitesimal move of the (whole) surface giving the largest energy decrease among all moves of equal size. We show that this problem can be efficiently solved using recent advances in algorithms for global hypersurface optimization [4.2.11]. In particular. we employ the geo-cuts method [4] that uses ideas from integral geometry to represent continuous surfaces as cuts on discrete graphs. The resulting interface evolution algorithm is validated on some …,True,-FEYIEMAAAAJ:d1gkVwhDpl0C,115,https://link.springer.com/chapter/10.1007/11744078_32,12190081576647048340,/scholar?cites=12190081576647048340,,,https://link.springer.com/content/pdf/10.1007/11744078_32.pdf,0,0,0
1282280,Generating and designing DNA with deep generative models,2017,Nathan Killoran and Leo J Lee and Andrew Delong and David Duvenaud and Brendan J Frey,,,,,,"We propose generative neural network methods to generate DNA sequences and tune them to have desired properties. We present three approaches: creating synthetic DNA sequences using a generative adversarial network; a DNA-based variant of the activation maximization ("" deep dream"") design method; and a joint procedure which combines these two approaches together. We show that these tools capture important structures of the data and. when applied to designing probes for protein binding microarrays. allow us to generate new sequences whose properties are estimated to be superior to those found in the training data. We believe that these results open the door for applying deep generative models to advance genomics research.",True,-FEYIEMAAAAJ:_5tno0g5mFcC,63,https://arxiv.org/abs/1712.06148,449659670246523710,/scholar?cites=449659670246523710,,,https://arxiv.org/pdf/1712.06148.pdf?source=post_page---------------------------,0,0,0
1282281,Minimizing Energies with Hierarchical Costs,2012,Andrew Delong and Lena Gorelick and Olga Veksler and Yuri Boykov,100,International Journal of Computer Vision (IJCV),1,38-58,Springer,Computer vision is full of problems elegantly expressed in terms of energy minimization. We characterize a class of energies with hierarchical costs and propose a novel hierarchical fusion algorithm. Hierarchical costs are natural for modeling an array of difficult problems. For example. in semantic segmentation one could rule out unlikely object combinations via hierarchical context. In geometric model estimation. one could penalize the number of unique model families in a solution. not just the number of models—a kind of hierarchical MDL criterion. Hierarchical fusion uses the well-known α-expansion algorithm as a subroutine. and offers a much better approximation bound in important cases.,True,-FEYIEMAAAAJ:W7OEmFMy1HYC,52,https://link.springer.com/content/pdf/10.1007/s11263-012-0531-x.pdf,8755291881564773835,/scholar?cites=8755291881564773835,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.1419&rep=rep1&type=pdf,0,0,0
1282282,Submodularization for Binary Pairwise Energies,2014,Lena Gorelick and Yuri Boykov and Olga Veksler and Ismail Ben Ayed and Andrew Delong,,,,,IEEE,Many computer vision problems require optimization of binary non-submodular energies. We propose a general optimization framework based on local submodular approximations (LSA). Unlike standard LP relaxation methods that linearize the whole energy globally. our approach iteratively approximates the energies locally. On the other hand. unlike standard local optimization methods (eg gradient descent or projection techniques) we use non-linear submodular approximations and optimize them without leaving the domain of integer solutions. We discuss two specific LSA algorithms based on trust region and auxiliary function principles. LSA-TR and LSA-AUX. These methods obtain state-of-the-art results on a wide range of applications outperforming many standard techniques such as LBP. QPBO. and TRWS. While our paper is focused on pairwise energies. our ideas extend to higher-order problems. The code is available online,True,-FEYIEMAAAAJ:FPJr55Dyh1AC,41,http://openaccess.thecvf.com/content_cvpr_2014/html/Gorelick_Submodularization_for_Binary_2014_CVPR_paper.html,3454813311866336702,/scholar?cites=3454813311866336702,,,http://openaccess.thecvf.com/content_cvpr_2014/papers/Gorelick_Submodularization_for_Binary_2014_CVPR_paper.pdf,0,0,0
1282283,Towards fully autonomous driving: Systems and algorithms,2011,Jesse Levinson and Jake Askeland and Jan Becker and Jennifer Dolson and David Held and Soeren Kammel and J Zico Kolter and Dirk Langer and Oliver Pink and Vaughan Pratt and Michael Sokolsky and Ganymed Stanek and David Stavens and Alex Teichman and Moritz Werling and Sebastian Thrun,,,,163-168,IEEE,In order to achieve autonomous operation of a vehicle in urban situations with unpredictable traffic. several realtime systems must interoperate. including environment perception. localization. planning. and control. In addition. a robust vehicle platform with appropriate sensors. computational hardware. networking. and software infrastructure is essential. We previously published an overview of Junior. Stanford's entry in the 2007 DARPA Urban Challenge. This race was a closed-course competition which. while historic and inciting much progress in the field. was not fully representative of the situations that exist in the real world. In this paper. we present a summary of our recent research towards the goal of enabling safe and robust autonomous operation in more realistic situations. First. a trio of unsupervised algorithms automatically calibrates our 64-beam rotating LIDAR with accuracy superior to tedious hand …,True,0QtU-NsAAAAJ:u5HHmVD_uO8C,1032,https://ieeexplore.ieee.org/abstract/document/5940562/,17031501958017159937,/scholar?cites=17031501958017159937,,,https://www.academia.edu/download/42549884/Towards_fully_autonomous_driving_Systems20160210-9182-1rhaq0n.pdf,0,0,0
1282284,Learning to track at 100 fps with deep regression networks,2016,David Held and Sebastian Thrun and Silvio Savarese,,,,749-765,Springer. Cham,Machine learning techniques are often used in computer vision due to their ability to leverage large amounts of training data to improve performance. Unfortunately. most generic object trackers are still trained from scratch online and do not benefit from the large number of videos that are readily available for offline training. We propose a method for offline training of neural networks that can track novel objects at test-time at 100 fps. Our tracker is significantly faster than previous methods that use neural networks for tracking. which are typically very slow to run and not practical for real-time applications. Our tracker uses a simple feed-forward network with no online training required. The tracker learns a generic relationship between object motion and appearance and can be used to track novel objects that do not appear in the training set. We test our network on a standard tracking benchmark to demonstrate …,True,0QtU-NsAAAAJ:5nxA0vEk-isC,947,https://link.springer.com/chapter/10.1007/978-3-319-46448-0_45,2517440561757741723,/scholar?cites=2517440561757741723,,,https://arxiv.org/pdf/1604.01802),0,0,0
1282285,Constrained policy optimization,2017,Joshua Achiam and David Held and Aviv Tamar and Pieter Abbeel,,,,22-31,PMLR,For many applications of reinforcement learning it can be more convenient to specify both a reward function and constraints. rather than trying to design behavior through the reward function. For example. systems that physically interact with or around humans should satisfy safety constraints. Recent advances in policy search algorithms (Mnih et al.. 2016. Schulman et al.. 2015. Lillicrap et al.. 2016. Levine et al.. 2016) have enabled new capabilities in high-dimensional control. but do not consider the constrained setting. We propose Constrained Policy Optimization (CPO). the first general-purpose policy search algorithm for constrained reinforcement learning with guarantees for near-constraint satisfaction at each iteration. Our method allows us to train neural network policies for high-dimensional control while making guarantees about policy behavior all throughout training. Our guarantees are based on a new theoretical result. which is of independent interest: we prove a bound relating the expected returns of two policies to an average divergence between them. We demonstrate the effectiveness of our approach on simulated robot locomotion tasks where the agent must satisfy constraints motivated by safety.,True,0QtU-NsAAAAJ:M3ejUd6NZC8C,371,http://proceedings.mlr.press/v70/achiam17a,6114366704163518185,/scholar?cites=6114366704163518185,,,http://proceedings.mlr.press/v70/achiam17a/achiam17a.pdf,0,0,0
1282286,Reverse curriculum generation for reinforcement learning,2017,Carlos Florensa and David Held and Markus Wulfmeier and Michael Zhang and Pieter Abbeel,,,,482-495,PMLR,"Many relevant tasks require an agent to reach a certain state. or to manipulate objects into a desired configuration. For example. we might want a robot to align and assemble a gear onto an axle or insert and turn a key in a lock. These goal-oriented tasks present a considerable challenge for reinforcement learning. since their natural reward function is sparse and prohibitive amounts of exploration are required to reach the goal and receive some learning signal. Past approaches tackle these problems by exploiting expert demonstrations or by manually designing a task-specific reward shaping function to guide the learning agent. Instead. we propose a method to learn these tasks without requiring any prior knowledge other than obtaining a single state in which the task is achieved. The robot is trained in “reverse"". gradually learning to reach the goal from a set of starting positions increasingly far from the goal. Our method automatically generates a curriculum of starting positions that adapts to the agent’s performance. leading to efficient training on goal-oriented tasks. We demonstrate our approach on difficult simulated navigation and fine-grained manipulation problems. not solvable by state-of-the-art reinforcement learning methods.",True,0QtU-NsAAAAJ:qxL8FJ1GzNcC,208,http://proceedings.mlr.press/v78/florensa17a.html,7189762229599882527,/scholar?cites=7189762229599882527,,,http://proceedings.mlr.press/v78/florensa17a/florensa17a.pdf,0,0,0
1282287,Automatic goal generation for reinforcement learning agents,2018,Carlos Florensa and David Held and Xinyang Geng and Pieter Abbeel,,,,1515-1528,PMLR,Reinforcement learning (RL) is a powerful technique to train an agent to perform a task; however. an agent that is trained using RL is only capable of achieving the single task that is specified via its reward function. Such an approach does not scale well to settings in which an agent needs to perform a diverse set of tasks. such as navigating to varying positions in a room or moving objects to varying locations. Instead. we propose a method that allows an agent to automatically discover the range of tasks that it is capable of performing in its environment. We use a generator network to propose tasks for the agent to try to accomplish. each task being specified as reaching a certain parametrized subset of the state-space. The generator network is optimized using adversarial training to produce tasks that are always at the appropriate level of difficulty for the agent. thus automatically producing a curriculum. We show that. by using this framework. an agent can efficiently and automatically learn to perform a wide set of tasks without requiring any prior knowledge of its environment. even when only sparse rewards are available. Videos and code available at https://sites. google. com/view/goalgeneration4rl.,True,0QtU-NsAAAAJ:Wp0gIr-vW9MC,183,http://proceedings.mlr.press/v80/florensa18a.html,5836114268256047177,/scholar?cites=5836114268256047177,,,http://proceedings.mlr.press/v80/florensa18a/florensa18a.pdf,0,0,0
1282288,Pcn: Point completion network,2018,Wentao Yuan and Tejas Khot and David Held and Christoph Mertz and Martial Hebert,,,,728-737,IEEE,Shape completion. the problem of estimating the complete geometry of objects from partial observations. lies at the core of many vision and robotics applications. In this work. we propose Point Completion Network (PCN). a novel learning-based approach for shape completion. Unlike existing shape completion methods. PCN directly operates on raw point clouds without any structural assumption (e.g. symmetry) or annotation (e.g. semantic class) about the underlying shape. It features a decoder design that enables the generation of fine-grained completions while maintaining a small number of parameters. Our experiments show that PCN produces dense. complete point clouds with realistic structures in the missing regions on inputs with various levels of incompleteness and noise. including cars from LiDAR scans in the KITTI dataset.,True,0QtU-NsAAAAJ:9ZlFYXVOiuMC,140,https://ieeexplore.ieee.org/abstract/document/8491026/,14112077023353007227,/scholar?cites=14112077023353007227,,,https://arxiv.org/pdf/1808.00671,0,0,0
1282289,Combining 3D Shape. Color. and Motion for Robust Anytime Tracking,2014,David Held and Jesse Levinson and Sebastian Thrun and Silvio Savarese,,,,,,Although object tracking has been studied for decades. real-time tracking algorithms often suffer from low accuracy and poor robustness when confronted with difficult. realworld data. We present a tracker that combines 3D shape. color (when available). and motion cues to accurately track moving objects in real-time. Our tracker allocates computational effort based on the shape of the posterior distribution. Starting with a coarse approximation to the posterior. the tracker successively refines this distribution. increasing in tracking accuracy over time. The tracker can thus be run for any amount of time. after which the current approximation to the posterior is returned. Even at a minimum runtime of 0.7 milliseconds. our method outperforms all of the baseline methods of similar speed by at least 10%. If our tracker is allowed to run for longer. the accuracy continues to improve. and it continues to outperform all baseline methods. Our tracker is thus anytime. allowing the speed or accuracy to be optimized based on the needs of the application.,True,0QtU-NsAAAAJ:eQOLeE2rZwMC,102,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.125&rep=rep1&type=pdf,5756917599573435470,/scholar?cites=5756917599573435470,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.651.125&rep=rep1&type=pdf,0,0,0
1282290,MVWT-II: The second generation caltech multi-vehicle wireless testbed,2004,Zhipu Jin and Stephen Waydo and Elisabeth B Wildanger and Michael Lammers and Hans Scholze and Peter Foley and David Held and Richard M Murray,6,,,5321-5326,IEEE,The Caltech Multi-Vehicle Wireless Testbed is an experimental platform for validating theoretical advances in multiple-vehicle coordination and cooperation. real-time networked control system. and distributed computation. This paper describes the design and development of an additional fleet of 12 second-generation vehicles. These vehicles are hovercrafts and designed to have lower mass and friction as well as smaller size than the first generation vehicles. These hovercrafts combined with the outdoor wireless testbed provide a perfect hardware platform for RoboFlag competition.,True,0QtU-NsAAAAJ:d1gkVwhDpl0C,71,https://ieeexplore.ieee.org/abstract/document/1384698/,14294527273435168202,/scholar?cites=14294527273435168202,,,http://www.cds.caltech.edu/~murray/wiki/images/0/09/Jin_etal04-acc.pdf,0,0,0
1282291,Robust single-view instance recognition,2016,David Held and Sebastian Thrun and Silvio Savarese,,,,2152-2159,IEEE,Some robots must repeatedly interact with a fixed set of objects in their environment. To operate correctly. it is helpful for the robot to be able to recognize the object instances that it repeatedly encounters. However. current methods for recognizing object instances require that. during training. many pictures are taken of each object from a large number of viewing angles. This procedure is slow and requires much manual effort before the robot can begin to operate in a new environment. We have developed a novel procedure for training a neural network to recognize a set of objects from just a single training image per object. To obtain robustness to changes in viewpoint. we take advantage of a supplementary dataset in which we observe a separate (non-overlapping) set of objects from multiple viewpoints. After pre-training the network in a novel multi-stage fashion. the network can robustly recognize new object …,True,0QtU-NsAAAAJ:8k81kl-MbHgC,66,https://ieeexplore.ieee.org/abstract/document/7487365/,2548729629534719006,/scholar?cites=2548729629534719006,,,https://www.ri.cmu.edu/wp-content/uploads/2017/12/held_icra16.pdf,0,0,0
1282292,Precision Tracking with Sparse 3D and Dense Color 2D Data,2013,David Held and Jesse Levinson and Sebastian Thrun,,,,,,Precision tracking is important for predicting the behavior of other cars in autonomous driving. We present a novel method to combine laser and camera data to achieve accurate velocity estimates of moving vehicles. We combine sparse laser points with a high-resolution camera image to obtain a dense colored point cloud. We use a color-augmented search algorithm to align the dense color point clouds from successive time frames for a moving vehicle. thereby obtaining a precise estimate of the tracked vehicle's velocity. Using this alignment method. we obtain velocity estimates at a much higher accuracy than previous methods. Through pre-filtering. we are able to achieve near real time results. We also present an online method for real-time use with accuracies close to that of the full method. We present a novel approach to quantitatively evaluate our velocity estimates by tracking a parked car in a local reference …,True,0QtU-NsAAAAJ:IjCSPb-OGe4C,66,https://ieeexplore.ieee.org/abstract/document/6630715/,5553105667259863297,/scholar?cites=5553105667259863297,,,https://www.ri.cmu.edu/wp-content/uploads/2017/12/ICRA2013.pdf,0,0,0
1282293,Enabling robots to communicate their objectives,2019,Sandy H Huang and David Held and Pieter Abbeel and Anca D Dragan,43,Autonomous Robots,2,309-326,Springer US,The overarching goal of this work is to efficiently enable end-users to correctly anticipate a robot’s behavior in novel situations. And since a robot’s behavior is often a direct result of its underlying objective function. our insight is that end-users need to have an accurate mental model of this objective function in order to understand and predict what the robot will do. While people naturally develop such a mental model over time through observing the robot act. this familiarization process may be lengthy. Our approach reduces this time by having the robot model how people infer objectives from observed behavior. in order to then show those behaviors that are maximally informative. We introduce two factors to define candidate models of human inference. and show that certain models indeed produce example robot behaviors that better enable users to anticipate what it will do in novel situations. Our results …,True,0QtU-NsAAAAJ:ULOm3_A8WrAC,57,https://link.springer.com/article/10.1007/s10514-018-9771-0,15771042375005543749,/scholar?cites=15771042375005543749,,,https://arxiv.org/pdf/1702.03465,0,0,0
1282294,PubChem substance and compound databases,2016,Sunghwan Kim and Paul A Thiessen and Evan E Bolton and Jie Chen and Gang Fu and Asta Gindulyte and Lianyi Han and Jane He and Siqian He and Benjamin A Shoemaker and Jiyao Wang and Bo Yu and Jian Zhang and Stephen H Bryant,44,Nucleic acids research,D1,D1202-D1213,Oxford University Press,PubChem (https://pubchem.ncbi.nlm.nih.gov) is a public repository for information on chemical substances and their biological activities. launched in 2004 as a component of the Molecular Libraries Roadmap Initiatives of the US National Institutes of Health (NIH). For the past 11 years. PubChem has grown to a sizable system. serving as a chemical information resource for the scientific research community. PubChem consists of three inter-linked databases. Substance. Compound and BioAssay. The Substance database contains chemical information deposited by individual data contributors to PubChem. and the Compound database stores unique chemical structures extracted from the Substance database. Biological activity data of chemical substances tested in assay experiments are contained in the BioAssay database. This paper provides an overview of the PubChem Substance and Compound …,True,hoYBBPMAAAAJ:KlAtU1dfN6UC,2547,https://academic.oup.com/nar/article-abstract/44/D1/D1202/2503131,7847099277060264658,/scholar?cites=7847099277060264658,,,https://academic.oup.com/nar/article-pdf/44/D1/D1202/9484096/gkv951.pdf,0,0,0
1282295,Disease Ontology 2015 update: an expanded and updated database of human diseases for linking biomedical knowledge through disease data,2015,Warren A Kibbe and Cesar Arze and Victor Felix and Elvira Mitraka and Evan Bolton and Gang Fu and Christopher J Mungall and Janos X Binder and James Malone and Drashtti Vasant and Helen Parkinson and Lynn M Schriml,43,Nucleic acids research,D1,D1071-D1078,Oxford University Press,The current version of the Human Disease Ontology (DO) (http://www.disease-ontology.org) database expands the utility of the ontology for the examination and comparison of genetic variation. phenotype. protein. drug and epitope data through the lens of human disease. DO is a biomedical resource of standardized common and rare disease concepts with stable identifiers organized by disease etiology. The content of DO has had 192 revisions since 2012. including the addition of 760 terms. Thirty-two percent of all terms now include definitions. DO has expanded the number and diversity of research communities and community members by 50+ during the past two years. These community members actively submit term requests. coordinate biomedical resource disease representation and provide expert curation guidance. Since the DO 2012 NAR paper. there have been hundreds of term requests and a …,True,hoYBBPMAAAAJ:hqOjcs7Dif8C,500,https://academic.oup.com/nar/article-abstract/43/D1/D1071/2435381,8714343241814152236,/scholar?cites=8714343241814152236,,,https://academic.oup.com/nar/article/43/D1/D1071/2435381,0,0,0
1282296,Predicting drug target interactions using meta-path-based semantic network analysis,2016,Gang Fu and Ying Ding and Abhik Seal and Bin Chen and Yizhou Sun and Evan Bolton,17,BMC bioinformatics,1,1-10,BioMed Central,In the context of drug discovery. drug target interactions (DTIs) can be predicted based on observed topological features of a semantic network across the chemical and biological space. In a semantic network. the types of the nodes and links are different. In order to take into account the heterogeneity of the semantic network. meta-path-based topological patterns were investigated for link prediction. Supervised machine learning models were constructed based on meta-path topological features of an enriched semantic network. which was derived from Chem2Bio2RDF. and was expanded by adding compound and protein similarity neighboring links obtained from the PubChem databases. The additional semantic links significantly improved the predictive performance of the supervised learning models. The binary classification model built upon the enriched feature space using the Random Forest algorithm significantly outperformed an existing semantic link prediction algorithm. Semantic Link Association Prediction (SLAP). to predict unknown links between compounds and protein targets in an evolving network. In addition to link prediction. Random Forest also has an intrinsic feature ranking algorithm. which can be used to select the important topological features that contribute to link prediction. The proposed framework has been demonstrated as a powerful alternative to SLAP in order to predict DTIs using the semantic network that integrates chemical. pharmacological. genomic. biological. functional. and biomedical information into a unified framework. It offers the flexibility to enrich the feature space by using different normalization processes …,True,hoYBBPMAAAAJ:ULOm3_A8WrAC,79,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1005-x,6098979294935108619,/scholar?cites=6098979294935108619,,,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1005-x,0,0,0
1282297,PubChemRDF: towards the semantic annotation of PubChem compound and substance databases,2015,Gang Fu and Colin Batchelor and Michel Dumontier and Janna Hastings and Egon Willighagen and Evan Bolton,7,Journal of cheminformatics,1,1-15,BioMed Central,PubChem is an open repository for chemical structures. biological activities and biomedical annotations. Semantic Web technologies are emerging as an increasingly important approach to distribute and integrate scientific data. Exposing PubChem data to Semantic Web services may help enable automated data integration and management. as well as facilitate interoperable web applications. This work. one of a series covering the PubChemRDF project. describes an approach to translate PubChem Substance and Compound information into Resource Description Framework (RDF) format. Basic examples are provided to demonstrate its use. The aim of this effort is to provide two new primary benefits to researchers in a cost-effective manner. Firstly. we aim to remove the inherent limitations of using the web-based resource PubChem by allowing a researcher to use readily available semantic technologies (namely. RDF triple stores and their corresponding SPARQL query engines) to query and analyze PubChem data on local computing resources. Secondly. this work intends to help improve data sharing. analysis. and integration of PubChem data to resources external to NCBI and across scientific domains. by means of the association of PubChem data to existing ontological frameworks. including CHEMical INFormation ontology. Semanticscience Integrated Ontology. and others. With the goal of semantically describing information available in the PubChem archive. pre-existing ontological frameworks were used. rather than creating new ones. Semantic relationships between compounds and substances. chemical descriptors associated with …,True,hoYBBPMAAAAJ:MXK_kJrjxJIC,62,https://jcheminf.biomedcentral.com/articles/10.1186/s13321-015-0084-4,5171752062698925747,/scholar?cites=5171752062698925747,,,https://jcheminf.biomedcentral.com/articles/10.1186/s13321-015-0084-4,0,0,0
1282298,Liquid chromatography–tandem mass spectrometry analysis of protocatechuic aldehyde and its phase I and II metabolites in rat,2007,Man Xu and Zichuan Zhang and Gang Fu and Shifeng Sun and Jianghao Sun and Min Yang and Aihua Liu and Jian Han and Dean Guo,856,Journal of Chromatography B,1-2,100-107,Elsevier,A method using liquid chromatography–electrospray ionization tandem mass spectrometry (LC–MS/MS) analysis was established for the identification of metabolites in rat after oral administration of protocatechuic aldehyde. a major bioactive phenolic acid in the roots of Salvia miltiorrhiza. Eleven metabolites in rat plasma and urine were firstly identified as protocatechuic aldehyde. protocatechuic acid and their methylated. glucuronized or glycine conjugates on the basis of their MS fragmentation behaviors. while nine of these metabolites (except protocatechuic aldehyde and protocatechuic acid) were detected in rat bile. In addition. the possible metabolic pathway was proposed for the first time. In the phase I metabolism. protocatechuic aldehyde could be oxidized to protocatechuic acid. The conjugates would be formed in rat intestine. liver and kidney and excreted from rat urine and bile. Enthrohepatic circulation …,True,hoYBBPMAAAAJ:ufrVoPGSRksC,56,https://www.sciencedirect.com/science/article/pii/S1570023207004047,6591606539064606335,/scholar?cites=6591606539064606335,,,,0,0,0
1282299,Implementation of multiple-instance learning in drug activity prediction,2012,Gang Fu and Xiaofei Nan and Haining Liu and Ronak Y Patel and Pankaj R Daga and Yixin Chen and Dawn E Wilkins and Robert J Doerksen,13,,15,1-12,BioMed Central,In the context of drug discovery and development. much effort has been exerted to determine which conformers of a given molecule are responsible for the observed biological activity. In this work we aimed to predict bioactive conformers using a variant of supervised learning. named multiple-instance learning. A single molecule. treated as a bag of conformers. is biologically active if and only if at least one of its conformers. treated as an instance. is responsible for the observed bioactivity; and a molecule is inactive if none of its conformers is responsible for the observed bioactivity. The implementation requires instance-based embedding. and joint feature selection and classification. The goal of the present project is to implement multiple-instance learning in drug activity prediction. and subsequently to identify the bioactive conformers for each molecule. We encoded the 3-dimensional structures using pharmacophore fingerprints which are binary strings. and accomplished instance-based embedding using calculated dissimilarity distances. Four dissimilarity measures were employed and their performances were compared. 1-norm SVM was used for joint feature selection and classification. The approach was applied to four data sets. and the best proposed model for each data set was determined by using the dissimilarity measure yielding the smallest number of selected features. The predictive abilities of the proposed approach were compared with three classical predictive models without instance-based embedding. The proposed approach produced the best predictive models for one data set and second best predictive models for the rest of …,True,hoYBBPMAAAAJ:u-x6o8ySG0sC,39,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S15-S3,12906414121235910700,/scholar?cites=12906414121235910700,,,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S15-S3,0,0,0
1282300,Design and synthesis of a novel class of furan-based molecules as potential 20S proteasome inhibitors,2007,Yiqiu Fu and Bo Xu and Xiaomin Zou and Chao Ma and Xiaoming Yang and Ke Mou and Gang Fu and Yang Lü and Ping Xu,17,Bioorganic & medicinal chemistry letters,4,1102-1106,Pergamon,A novel class of furan-based compounds as potential 20S proteasome inhibitors have been designed and synthesized. among which nine compounds are peptide derivatives and six molecules are statine peptidomimetics. The C-terminal furanyl moiety was introduced to target molecules as furan-based amino acids. All the compounds were obtained steadily with moderate to high yield. Compound 12 was a selective moderate potent proteasome peptidomimetic inhibitor. It inhibited HepG2 and HL-60 proliferation effectively.,True,hoYBBPMAAAAJ:LkGwnXOMwfcC,36,https://www.sciencedirect.com/science/article/pii/S0960894X06013084,17684906377507551943,/scholar?cites=17684906377507551943,,,,0,0,0
1282301,Combined rule extraction and feature elimination in supervised classification,2012,Sheng Liu and Ronak Y Patel and Pankaj R Daga and Haining Liu and Gang Fu and Robert J Doerksen and Yixin Chen and Dawn E Wilkins,11,IEEE transactions on nanobioscience,3,228-236,IEEE,There are a vast number of biology related research problems involving a combination of multiple sources of data to achieve a better understanding of the underlying problems. It is important to select and interpret the most important information from these sources. Thus it will be beneficial to have a good algorithm to simultaneously extract rules and select features for better interpretation of the predictive model. We propose an efficient algorithm. Combined Rule Extraction and Feature Elimination (CRF). based on 1-norm regularized random forests. CRF simultaneously extracts a small number of rules generated by random forests and selects important features. We applied CRF to several drug activity prediction and microarray data sets. CRF is capable of producing performance comparable with state-of-the-art prediction algorithms using a small number of decision rules. Some of the decision rules are biologically …,True,hoYBBPMAAAAJ:UeHWp8X0CEIC,29,https://ieeexplore.ieee.org/abstract/document/6298044/,12524961691280820334,/scholar?cites=12524961691280820334,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6295448/,0,0,0
1282302,HPLC method for comparative study on tissue distribution in rat after oral administration of salvianolic acid B and phenolic acids from Salvia miltiorrhiza,2007,Man Xu and Gang Fu and Xue Qiao and Wan‐Ying Wu and Hui Guo and Ai‐Hua Liu and Jiang‐Hao Sun and De‐An Guo,21,Biomedical Chromatography,10,1052-1063,John Wiley & Sons. Ltd.,A sensitive and selective high‐performance liquid chromatography method was developed and validated to determine the prototype of salvianolic acid B and the metabolites of phenolic acids (protocatechuic acid. vanillic acid and ferulic acid) in rat tissues after oral administration of total phenolic acids and salvianolic acid B extracted from the roots of Salvia miltiorrhiza. respectively. The tissue samples were treated with a simple liquid–liquid extraction prior to HPLC. Analysis of the extract was performed on a reverse‐phase C18 column with a mobile phase consisting of acetonitrile and 0.05% trifluoracetic acid. The calibration curves for the four phenolic acids were linear in the given concentration ranges. The intra‐day and inter‐day relative standard deviations in the measurement of quality control samples were less than 10% and the accuracies were in the range of 88–115%. The average recoveries of all the …,True,hoYBBPMAAAAJ:_FxGoFyzp5QC,28,https://onlinelibrary.wiley.com/doi/abs/10.1002/bmc.852,815839827450160885,/scholar?cites=815839827450160885,,,,0,0,0
1282303,Molecular modeling to provide insight into the substrate binding and catalytic mechanism of human biliverdin-IXα reductase,2012,Gang Fu and Haining Liu and Robert J Doerksen,116,The Journal of Physical Chemistry B,32,9580-9594,American Chemical Society,Human biliverdin-IXα reductase (hBVR-A) catalyzes the conversion of biliverdin-IXα to bilirubin-IXα in the last step of heme degradation and is a key enzyme in regulating a wide range of cellular responses. Though the X-ray structure of hBVR-A is available including cofactor. a crystal structure with a bound substrate would be even more useful as a starting point for protein-structure-based inhibitor design. but none have been reported. The present study employed induced fit docking (IFD) to study the substrate binding modes to hBVR-A of biliverdin-IXα and four analogues. The proposed substrate binding modes were examined further by performing molecular dynamics (MD) simulations followed by molecular mechanics Poisson–Boltzmann surface area (MM-PBSA) calculations. The predicted binding free energies for the five biliverdin-IXα analogues match well with the relative potency of their reported …,True,hoYBBPMAAAAJ:9yKSN-GCB0IC,25,https://pubs.acs.org/doi/abs/10.1021/jp301456j,2792795424472809578,/scholar?cites=2792795424472809578,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3505555/,0,0,0
1282304,edge2vec: Representation learning using edge semantics for biomedical knowledge discovery,2019,Zheng Gao and Gang Fu and Chunping Ouyang and Satoshi Tsutsui and Xiaozhong Liu and Jeremy Yang and Christopher Gessner and Brian Foote and David Wild and Ying Ding and Qi Yu,20,BMC bioinformatics,1,1-15,BioMed Central,Representation learning provides new and powerful graph analytical approaches and tools for the highly valued data science challenge of mining knowledge graphs. Since previous graph analytical methods have mostly focused on homogeneous graphs. an important current challenge is extending this methodology for richly heterogeneous graphs and knowledge domains. The biomedical sciences are such a domain. reflecting the complexity of biology. with entities such as genes. proteins. drugs. diseases. and phenotypes. and relationships such as gene co-expression. biochemical regulation. and biomolecular inhibition or activation. Therefore. the semantics of edges and nodes are critical for representation learning and knowledge discovery in real world biomedical problems. In this paper. we propose the edge2vec model. which represents graphs considering edge semantics. An edge-type transition matrix is trained by an Expectation-Maximization approach. and a stochastic gradient descent model is employed to learn node embedding on a heterogeneous graph via the trained transition matrix. edge2vec is validated on three biomedical domain tasks: biomedical entity classification. compound-gene bioactivity prediction. and biomedical information retrieval. Results show that by considering edge-types into node embedding learning in heterogeneous graphs. edge2vec significantly outperforms state-of-the-art models on all three tasks. We propose this method for its added value relative to existing graph analytical methodology. and in the real world context of biomedical knowledge discovery applicability.,True,hoYBBPMAAAAJ:aqlVkmm33-oC,22,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2914-2,15510280315961906590,/scholar?cites=15510280315961906590,,,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2914-2,0,0,0
1282305,Classification with an edge: Improving semantic image segmentation with boundary detection,2018,Dimitrios Marmanis and Konrad Schindler and Jan Dirk Wegner and Silvano Galliani and Mihai Datcu and Uwe Stilla,135,ISPRS Journal of Photogrammetry and Remote Sensing,,158-172,Elsevier,We present an end-to-end trainable deep convolutional neural network (DCNN) for semantic segmentation with built-in awareness of semantically meaningful boundaries. Semantic segmentation is a fundamental remote sensing task. and most state-of-the-art methods rely on DCNNs as their workhorse. A major reason for their success is that deep networks learn to accumulate contextual information over very large receptive fields. However. this success comes at a cost. since the associated loss of effective spatial resolution washes out high-frequency details and leads to blurry object boundaries. Here. we propose to counter this effect by combining semantic segmentation with semantically informed edge detection. thus making class boundaries explicit in the model. First. we construct a comparatively simple. memory-efficient model by adding boundary detection to the segnet encoder-decoder architecture. Second …,True,sxLG1rgAAAAJ:M3NEmzRMIkIC,319,https://www.sciencedirect.com/science/article/pii/S092427161630572X,1089241264706192835,/scholar?cites=1089241264706192835,,,https://arxiv.org/pdf/1612.01337,0,0,0
1282306,Semantic3d. net: A new large-scale point cloud classification benchmark,2017,Timo Hackel and Nikolay Savinov and Lubor Ladicky and Jan D Wegner and Konrad Schindler and Marc Pollefeys,,arXiv preprint arXiv:1704.03847,,,,This paper presents a new 3D point cloud classification benchmark data set with over four billion manually labelled points. meant as input for data-hungry (deep) learning methods. We also discuss first submissions to the benchmark that use deep convolutional neural networks (CNNs) as a work horse. which already show remarkable performance improvements over state-of-the-art. CNNs have become the de-facto standard for many tasks in computer vision and machine learning like semantic segmentation or object detection in images. but have no yet led to a true breakthrough for 3D point cloud labelling tasks due to lack of training data. With the massive data set presented in this paper. we aim at closing this data gap to help unleash the full potential of deep learning methods for 3D labelling tasks. Our this http URL data set consists of dense point clouds acquired with static terrestrial laser scanners. It contains 8 semantic classes and covers a wide range of urban outdoor scenes: churches. streets. railroad tracks. squares. villages. soccer fields and castles. We describe our labelling interface and show that our data set provides more dense and complete point clouds with much higher overall number of labelled points compared to those already available to the research community. We further provide baseline method descriptions and comparison between methods submitted to our online system. We hope this http URL will pave the way for deep learning methods in 3D point cloud labelling to learn richer. more general 3D representations. and first submissions after only a few months indicate that this might indeed be the case.,True,sxLG1rgAAAAJ:hMod-77fHWUC,279,https://arxiv.org/abs/1704.03847,13982894996901447532,/scholar?cites=13982894996901447532,,,https://arxiv.org/pdf/1704.03847,0,0,0
1282307,The ISPRS benchmark on urban object classification and 3D building reconstruction,2012,Franz Rottensteiner and Gunho Sohn and Jaewook Jung and Markus Gerke and Caroline Baillard and Sebastien Benitez and Uwe Breitkopf,1,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences I-3 (2012), Nr. 1",1,293-298,Göttingen: Copernicus GmbH,For more than two decades. many efforts have been made to develop methods for extracting urban objects from data acquired by airborne sensors. In order to make the results of such algorithms more comparable. benchmarking data sets are of paramount importance. Such a data set. consisting of airborne image and laserscanner data. has been made available to the scientific community. Researchers were encouraged to submit results of urban object detection and 3D building reconstruction. which were evaluated based on reference data. This paper presents the outcomes of the evaluation for building detection. tree detection. and 3D building reconstruction. The results achieved by different methods are compared and analysed to identify promising strategies for automatic urban object extraction from current airborne sensor data. but also common problems of state-of-the-art methods.,True,sxLG1rgAAAAJ:W7OEmFMy1HYC,277,https://www.repo.uni-hannover.de/handle/123456789/5086,9938829769613752079,/scholar?cites=9938829769613752079,,,https://www.repo.uni-hannover.de/bitstream/handle/123456789/5086/isprsannals-I-3-293-2012.pdf?sequence=1,0,0,0
1282308,Results of the ISPRS benchmark on urban object detection and 3D building reconstruction,2014,Franz Rottensteiner and Gunho Sohn and Markus Gerke and Jan Dirk Wegner and Uwe Breitkopf and Jaewook Jung,93,ISPRS journal of photogrammetry and remote sensing,,256-271,Elsevier,For more than two decades. many efforts have been made to develop methods for extracting urban objects from data acquired by airborne sensors. In order to make the results of such algorithms more comparable. benchmarking data sets are of paramount importance. Such a data set. consisting of airborne image and laserscanner data. has been made available to the scientific community by ISPRS WGIII/4. Researchers were encouraged to submit their results of urban object detection and 3D building reconstruction. which were evaluated based on reference data. This paper presents the outcomes of the evaluation for building detection. tree detection. and 3D building reconstruction. The results achieved by different methods are compared and analysed to identify promising strategies for automatic urban object extraction from current airborne sensor data. but also common problems of state-of-the-art methods.,True,sxLG1rgAAAAJ:5nxA0vEk-isC,266,https://www.sciencedirect.com/science/article/pii/S0924271613002268,4559214232434756962,/scholar?cites=4559214232434756962,,,http://www.cvlibs.net/projects/autonomous_vision_survey/literature/Rottensteiner2014JPRS.pdf,0,0,0
1282309,Semantic segmentation of aerial images with an ensemble of CNSS,2016,Dimitrios Marmanis and Jan D Wegner and Silvano Galliani and Konrad Schindler and Mihai Datcu and Uwe Stilla,3,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2016",,473-480,Copernicus Publications,This paper describes a deep learning approach to semantic segmentation of very high resolution (aerial) images. Deep neural architectures hold the promise of end-to-end learning from raw images. making heuristic feature design obsolete. Over the last decade this idea has seen a revival. and in recent years deep convolutional neural networks (CNNs) have emerged as the method of choice for a range of image interpretation tasks like visual recognition and object detection. Still. standard CNNs do not lend themselves to per-pixel semantic segmentation. mainly because one of their fundamental principles is to gradually aggregate information over larger and larger image regions. making it hard to disentangle contributions from different pixels. Very recently two extensions of the CNN framework have made it possible to trace the semantic information back to a precise pixel position: deconvolutional network layers undo the spatial downsampling. and Fully Convolution Networks (FCNs) modify the fully connected classification layers of the network in such a way that the location of individual activations remains explicit. We design a FCN which takes as input intensity and range data and. with the help of aggressive deconvolution and recycling of early network layers. converts them into a pixelwise classification at full resolution. We discuss design choices and intricacies of such a network. and demonstrate that an ensemble of several networks achieves excellent results on challenging data such as the ISPRS semantic labeling benchmark. using only the raw data as input.,True,sxLG1rgAAAAJ:TFP_iSt0sucC,234,https://elib.dlr.de/108960/,131706539157909224,/scholar?cites=131706539157909224,,,https://elib.dlr.de/108960/1/Marmanis_isprs-annals-III-3-473-2016.pdf,0,0,0
1282310,Fast semantic segmentation of 3D point clouds with strongly varying density,2016,Timo Hackel and Jan D Wegner and Konrad Schindler,3,"ISPRS annals of the photogrammetry, remote sensing and spatial information sciences",,177-184,Copernicus,We describe an effective and efficient method for point-wise semantic classification of 3D point clouds. The method can handle unstructured and inhomogeneous point clouds such as those derived from static terrestrial LiDAR or photogammetric reconstruction; and it is computationally efficient. making it possible to process point clouds with many millions of points in a matter of minutes. The key issue. both to cope with strong variations in point density and to bring down computation time. turns out to be careful handling of neighborhood relations. By choosing appropriate definitions of a point’s (multi-scale) neighborhood. we obtain a feature set that is both expressive and fast to compute. We evaluate our classification method both on benchmark data from a mobile mapping platform and on a variety of large. terrestrial laser scans with greatly varying point density. The proposed feature set outperforms the state of the art with respect to per-point classification accuracy. while at the same time being much faster to compute.,True,sxLG1rgAAAAJ:r0BpntZqJG4C,219,https://www.research-collection.ethz.ch/handle/20.500.11850/126659,340146548912858159,/scholar?cites=340146548912858159,,,https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/126659/isprs-annals-III-3-177-2016.pdf?sequence=2,0,0,0
1282311,Learning aerial image segmentation from online maps,2017,Pascal Kaiser and Jan Dirk Wegner and Aurélien Lucchi and Martin Jaggi and Thomas Hofmann and Konrad Schindler,55,IEEE Transactions on Geoscience and Remote Sensing,11,6054-6068,IEEE,This paper deals with semantic segmentation of high-resolution (aerial) images where a semantic class label is assigned to each pixel via supervised classification as a basis for automatic map generation. Recently. deep convolutional neural networks (CNNs) have shown impressive performance and have quickly become the de-facto standard for semantic segmentation. with the added benefit that task-specific feature design is no longer necessary. However. a major downside of deep learning methods is that they are extremely data hungry. thus aggravating the perennial bottleneck of supervised classification. to obtain enough annotated training data. On the other hand. it has been observed that they are rather robust against noise in the training labels. This opens up the intriguing possibility to avoid annotating huge amounts of training data. and instead train the classifier from existing legacy data or crowd …,True,sxLG1rgAAAAJ:O3NaXMp0MMsC,163,https://ieeexplore.ieee.org/abstract/document/7987710/,16652059209783173663,/scholar?cites=16652059209783173663,,,https://arxiv.org/pdf/1707.06879,0,0,0
1282312,A higher-order CRF model for road network extraction,2013,Jan D Wegner and Javier A Montoya-Zegarra and Konrad Schindler,,,,1698-1705,,The aim of this work is to extract the road network from aerial images. What makes the problem challenging is the complex structure of the prior: roads form a connected network of smooth. thin segments which meet at junctions and crossings. This type of a-priori knowledge is more difficult to turn into a tractable model than standard smoothness or co-occurrence assumptions. We develop a novel CRF formulation for road labeling. in which the prior is represented by higher-order cliques that connect sets of superpixels along straight line segments. These long-range cliques have asymmetric P es-potentials. which express a preference to assign all rather than just some of their constituent superpixels to the road class. Thus. the road likelihood is amplified for thin chains of superpixels. while the CRF is still amenable to optimization with graph cuts. Since the number of such cliques of arbitrary length is huge. we furthermore propose a sampling scheme which concentrates on those cliques which are most relevant for the optimization. In experiments on two different databases the model significantly improves both the per-pixel accuracy and the topological correctness of the extracted roads. and outperforms both a simple smoothness prior and heuristic rulebased road completion.,True,sxLG1rgAAAAJ:3fE2CSJIrl8C,155,http://openaccess.thecvf.com/content_cvpr_2013/html/Wegner_A_Higher-Order_CRF_2013_CVPR_paper.html,3850445793335688091,/scholar?cites=3850445793335688091,,,http://openaccess.thecvf.com/content_cvpr_2013/papers/Wegner_A_Higher-Order_CRF_2013_CVPR_paper.pdf,0,0,0
1282313,Keypoint-based 4-points congruent sets–automated marker-less registration of laser scans,2014,Pascal Willy Theiler and Jan Dirk Wegner and Konrad Schindler,96,ISPRS journal of photogrammetry and remote sensing,,149-163,Elsevier,We propose a method to automatically register two point clouds acquired with a terrestrial laser scanner without placing any markers in the scene. What makes this task challenging are the strongly varying point densities caused by the line-of-sight measurement principle. and the huge amount of data. The first property leads to low point densities in potential overlap areas with scans taken from different viewpoints while the latter calls for highly efficient methods in terms of runtime and memory requirements.A crucial yet largely unsolved step is the initial coarse alignment of two scans without any simplifying assumptions. that is. point clouds are given in arbitrary local coordinates and no knowledge about their relative orientation is available. Once coarse alignment has been solved. scans can easily be fine-registered with standard methods like least-squares surface or Iterative Closest Point matching. In order to …,True,sxLG1rgAAAAJ:ZeXyd9-uunAC,118,https://www.sciencedirect.com/science/article/pii/S0924271614001701,7199285635411787819,/scholar?cites=7199285635411787819,,,,0,0,0
1282314,Cataloging public objects using aerial and street-level images-urban trees,2016,Jan D Wegner and Steven Branson and David Hall and Konrad Schindler and Pietro Perona,,,,6014-6023,,"Each corner of the inhabited world is imaged from multiple viewpoints with increasing frequency. Online map services like Google Maps or Here Maps provide direct access to huge amounts of densely sampled. georeferenced images from street view and aerial perspective. There is an opportunity to design computer vision systems that will help us search. catalog and monitor public infrastructure. buildings and artifacts. We explore the architecture and feasibility of such a system. The main technical challenge is combining test time information from multiple views of each geographic location (eg. aerial and street views). We implement two modules: det2geo. which detects the set of loca-tions of objects belonging to a given category. and geo2cat. which computes the fine-grained category of the object at a given location. We introduce a solution that adapts state-of-the-art CNN-based object detectors and classifiers. We test our method on"" Pasadena Urban Trees"". a new dataset of 80.000 trees with geographic and species annotations. and show that combining multiple views significantly improves both tree detection and tree species classification. rivaling human performance.",True,sxLG1rgAAAAJ:bEWYMUwI8FkC,109,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Wegner_Cataloging_Public_Objects_CVPR_2016_paper.html,17236403473716715960,/scholar?cites=17236403473716715960,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Wegner_Cataloging_Public_Objects_CVPR_2016_paper.pdf,0,0,0
1282315,Building detection from one orthophoto and high-resolution InSAR data using conditional random fields,2010,Jan Dirk Wegner and Ronny Hänsch and Antje Thiele and Uwe Soergel,4,IEEE Journal of selected topics in applied Earth Observations and Remote Sensing,1,83-91,IEEE,Today's airborne SAR sensors provide geometric resolution in the order well below half a meter. Many features of urban objects become visible in such data. However. layover and occlusion issues inevitably arise in urban areas complicating automated object detection. In order to support interpretation. SAR data may be analyzed using complementary information from maps or optical imagery. In this paper. an approach for building detection in urban areas based on object features extracted from high-resolution interferometric SAR (InSAR) data and one orthophoto is presented. Features describing local evidence as well as context information are used. Buildings are detected by classification of those feature vectors within a Conditional Random Field (CRF) framework. Although as graphical model similar to Markov Random Fields (MRF). CRFs have the advantage of incorporating global context information. of …,True,sxLG1rgAAAAJ:u5HHmVD_uO8C,99,https://ieeexplore.ieee.org/abstract/document/5549987/,16349333900487542961,/scholar?cites=16349333900487542961,,,,0,0,0
1282316,Visual saliency based on multiscale deep features,2015,Guanbin Li and Yizhou Yu,,,,5455-5463,,Visual saliency is a fundamental problem in both cognitive and computational sciences. including computer vision. In this paper. we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks (CNN). which have had many successes in visual recognition tasks. For learning such saliency models. we introduce a neural network architecture. which has fully connected layers on top of CNNs responsible for extracting features at three different scales. Our learned saliency model is capable of achieving state-of-the-art performance on all public benchmarks. We then propose a refinement method to enhance the spatial coherence of our saliency results. Finally. we point out that aggregating multiple saliency maps computed for different levels of image segmentation can further boost the performance. yielding saliency maps better than those generated from a single region decomposition. To promote further research and evaluation of visual saliency models. we also construct a large database of 4447 challenging images and their pixelwise saliency annotation. Experimental results demonstrate that our proposed method significantly outperforms all existing saliency estimation techniques. improving the F-Measure by 5.0% and 13.2% respectively on the MSRA-B dataset and our new dataset. and lowering the mean absolute error by 5.7% and 35.1% respectively on the same two datasets.,True,2A2Bx2UAAAAJ:mB3voiENLucC,825,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Li_Visual_Saliency_Based_2015_CVPR_paper.html,17997083431600641924,/scholar?cites=17997083431600641924,,,https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Visual_Saliency_Based_2015_CVPR_paper.pdf,0,0,0
1282317,Deep contrast learning for salient object detection,2016,Guanbin Li and Yizhou Yu,,,,478-487,,Salient object detection has recently witnessed substantial progress due to powerful features extracted using deep convolutional neural networks (CNNs). However. existing CNN-based methods operate at the patch level instead of the pixel level. Resulting saliency maps are typically blurry. especially near the boundary of salient objects. Furthermore. image patches are treated as independent samples even when they are overlapping. giving rise to significant redundancy in computation and storage. In this paper. we propose an end-to-end deep contrast network to overcome the aforementioned limitations. Our deep network consists of two complementary components. a pixel-level fully convolutional stream and a segment-wise spatial pooling stream. The first stream directly produces a saliency map with pixel-level accuracy from an input image. The second stream extracts segment-wise features very efficiently. and better models saliency discontinuities along object boundaries. Finally. a fully connected CRF model can be optionally incorporated to improve spatial coherence and contour localization in the fused result from these two streams. Experimental results demonstrate that our deep model significantly improves the state of the art.,True,2A2Bx2UAAAAJ:bEWYMUwI8FkC,619,http://openaccess.thecvf.com/content_cvpr_2016/html/Li_Deep_Contrast_Learning_CVPR_2016_paper.html,9364796585299081371,/scholar?cites=9364796585299081371,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Li_Deep_Contrast_Learning_CVPR_2016_paper.pdf,0,0,0
1282318,Visual saliency detection based on multiscale deep CNN features,2016,Guanbin Li and Yizhou Yu,25,IEEE transactions on image processing,11,5012-5024,IEEE,Visual saliency is a fundamental problem in both cognitive and computational sciences. including computer vision. In this paper. we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks (CNNs). which have had many successes in visual recognition tasks. For learning such saliency models. we introduce a neural network architecture. which has fully connected layers on top of CNNs responsible for feature extraction at three different scales. The penultimate layer of our neural network has been confirmed to be a discriminative high-level feature vector for saliency detection. which we call deep contrast feature. To generate a more robust feature. we integrate handcrafted low-level features with our deep contrast feature. To promote further research and evaluation of visual saliency models. we also construct a new large database …,True,2A2Bx2UAAAAJ:hMod-77fHWUC,251,https://ieeexplore.ieee.org/abstract/document/7548372/,7981177100781065078,/scholar?cites=7981177100781065078,,,https://arxiv.org/pdf/1609.02077,0,0,0
1282319,Instance-level salient object segmentation,2017,Guanbin Li and Yuan Xie and Liang Lin and Yizhou Yu,,,,2386-2395,,Image saliency detection has recently witnessed rapid progress due to deep convolutional neural networks. However. none of the existing methods is able to identify object instances in the detected salient regions. In this paper. we present a salient instance segmentation method that produces a saliency mask with distinct object instance labels for an input image. Our method consists of three steps. estimating saliency map. detecting salient object contours and identifying salient object instances. For the first two steps. we propose a multiscale saliency refinement network. which generates high-quality salient region masks and salient object contours. Once integrated with multiscale combinatorial grouping and a MAP-based subset optimization framework. our method can generate very promising salient object instance segmentation results. To promote further research and evaluation of salient instance segmentation. we also construct a new database of 1000 images and their pixelwise salient instance annotations. Experimental results demonstrate that our proposed method is capable of achieving state-of-the-art performance on all public benchmarks for salient region detection as well as on our new dataset for salient instance segmentation.,True,2A2Bx2UAAAAJ:YFjsv_pBGBYC,187,http://openaccess.thecvf.com/content_cvpr_2017/html/Li_Instance-Level_Salient_Object_CVPR_2017_paper.html,6983359107805957213,/scholar?cites=6983359107805957213,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Instance-Level_Salient_Object_CVPR_2017_paper.pdf,0,0,0
1282320,Multi-label image recognition by recurrently discovering attentional regions,2017,Zhouxia Wang and Tianshui Chen and Guanbin Li and Ruijia Xu and Liang Lin,,,,464-472,,This paper proposes a novel deep architecture to address multi-label image recognition. a fundamental and practical task towards general visual understanding. Current solutions for this task usually rely on an extra step of extracting hypothesis regions (ie. region proposals). resulting in redundant computation and sub-optimal performance. In this work. we achieve the interpretable and contextualized multi-label image classification by developing a recurrent memorized-attention module. This module consists of two alternately performed components: i) a spatial transformer layer to locate attentional regions from the convolutional feature maps in a region-proposal-free way and ii) a LSTM (Long-Short Term Memory) sub-network to sequentially predict semantic labeling scores on the located regions while capturing the global dependencies of these regions. The LSTM also output the parameters for computing the spatial transformer. On large-scale benchmarks of multi-label image classification (eg. MS-COCO and PASCAL VOC 07). our approach demonstrates superior performances over other existing state-of-the-arts in both accuracy and efficiency.,True,2A2Bx2UAAAAJ:O3NaXMp0MMsC,144,http://openaccess.thecvf.com/content_iccv_2017/html/Wang_Multi-Label_Image_Recognition_ICCV_2017_paper.html,4778423842014350368,/scholar?cites=4778423842014350368,,,https://openaccess.thecvf.com/content_ICCV_2017/papers/Wang_Multi-Label_Image_Recognition_ICCV_2017_paper.pdf,0,0,0
1282321,Attention-aware face hallucination via deep reinforcement learning,2017,Qingxing Cao and Liang Lin and Yukai Shi and Xiaodan Liang and Guanbin Li,,,,690-698,,,True,2A2Bx2UAAAAJ:GnPB-g6toBAC,136,,2553223462943257945,/scholar?cites=2553223462943257945,,,,0,0,0
1282322,Crowd counting using deep recurrent spatial-aware network,2018,Lingbo Liu and Hongjun Wang and Guanbin Li and Wanli Ouyang and Liang Lin,,arXiv preprint arXiv:1807.00601,,,,,True,2A2Bx2UAAAAJ:ldfaerwXgEUC,111,,12492276552224642531,/scholar?cites=12492276552224642531,,,,0,0,0
1282323,Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation,2019,Ruijia Xu and Guanbin Li and Jihan Yang and Liang Lin,,,,1426-1435,,,True,2A2Bx2UAAAAJ:dshw04ExmUIC,106,,10056502475685332330,/scholar?cites=10056502475685332330,,,,0,0,0
1282324,Non-locally enhanced encoder-decoder network for single image de-raining,2018,Guanbin Li and Xiang He and Wei Zhang and Huiyou Chang and Le Dong and Liang Lin,,,,1056-1064,,,True,2A2Bx2UAAAAJ:M05iB0D1s5AC,96,,2056142829216867866,/scholar?cites=2056142829216867866,,,,0,0,0
1282325,Crowd counting with deep structured scale integration network,2019,Lingbo Liu and Zhilin Qiu and Guanbin Li and Shufan Liu and Wanli Ouyang and Liang Lin,,,,1774-1783,,,True,2A2Bx2UAAAAJ:NhqRSupF_l8C,92,,2975625718320626027,/scholar?cites=2975625718320626027,,,,0,0,0
1282326,Flow guided recurrent neural encoder for video salient object detection,2018,Guanbin Li and Yuan Xie and Tianhao Wei and Keze Wang and Liang Lin,,,,3243-3252,,,True,2A2Bx2UAAAAJ:35N4QoGY0k4C,74,,7865294969137192170,/scholar?cites=7865294969137192170,,,,0,0,0
1282327,Generative image inpainting with contextual attention,2018,Jiahui Yu and Zhe Lin and Jimei Yang and Xiaohui Shen and Xin Lu and Thomas S Huang,,"Computer Vision and Pattern Recognition (CVPR), 2018",,,,Recent deep learning based approaches have shown promising results for the challenging task of inpainting large missing regions in an image. These methods can generate visually plausible image structures and textures. but often create distorted structures or blurry textures inconsistent with surrounding areas. This is mainly due to ineffectiveness of convolutional neural networks in explicitly borrowing or copying information from distant spatial locations. On the other hand. traditional texture and patch synthesis approaches are particularly suitable when it needs to borrow textures from the surrounding regions. Motivated by these observations. we propose a new deep generative model-based approach which can not only synthesize novel image structures but also explicitly utilize surrounding image features as references during network training to make better predictions. The model is a feed-forward. fully convolutional neural network which can process images with multiple holes at arbitrary locations and with variable sizes during the test time. Experiments on multiple datasets including faces (CelebA. CelebA-HQ). textures (DTD) and natural images (ImageNet. Places2) demonstrate that our proposed approach generates higher-quality inpainting results than existing ones. Code. demo and models are available at: https://github. com/JiahuiYu/generative_inpainting.,True,-CLCMk4AAAAJ:ufrVoPGSRksC,919,http://openaccess.thecvf.com/content_cvpr_2018/html/Yu_Generative_Image_Inpainting_CVPR_2018_paper.html,11541279513087894235,/scholar?cites=11541279513087894235,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf,0,0,0
1282328,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang and Bee Lim and Sanghyun Son and Heewon Kim and Seungjun Nah and Kyoung Mu Lee and Xintao Wang and Yapeng Tian and Ke Yu and Yulun Zhang and Shixiang Wu and Chao Dong and Liang Lin and Yu Qiao and Chen Change Loy and Woong Bae and Jaejun Yoo and Yoseob Han and Jong Chul Ye and Jae-Seok Choi and Munchurl Kim and Yuchen Fan and Jiahui Yu and Wei Han and Ding Liu and Haichao Yu and Zhangyang Wang and Honghui Shi and Xinchao Wang and Thomas S Huang and Yunjin Chen and Kai Zhang and Wangmeng Zuo and Zhimin Tang and Linkai Luo and Shaohui Li and Min Fu and Lei Cao and Wen Heng and Giang Bui and Le Truc and Ye Duan and Dacheng Tao and Ruxin Wang and Xu Lin and Jianxin Pang and Jinchang Xu and Yu Zhao and Xiangyu Xu and Jinshan Pan and Deqing Sun and Yujin Zhang and Xibin Song and Yuchao Dai and Xueying Qin and Huynh Xuan-Phung and Tiantong Guo and Hojjat Seyed Mousavi and Huu Vu Tiep and Vishal Monga and Cristovao Cruz and Karen Egiazarian and Vladimir Katkovnik,,,,1110-1121,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,-CLCMk4AAAAJ:k_IJM867U9cC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1282329,Slimmable Neural Networks,2018,Jiahui Yu and Linjie Yang and Ning Xu and Jianchao Yang and Thomas Huang,,"International Conference on Learning Representations (ICLR), 2019",,,,We present a simple and general method to train a single neural network executable at different widths (number of channels in a layer). permitting instant and adaptive accuracy-efficiency trade-offs at runtime. Instead of training individual networks with different width configurations. we train a shared network with switchable batch normalization. At runtime. the network can adjust its width on the fly according to on-device benchmarks and resource constraints. rather than downloading and offloading different models. Our trained networks. named slimmable neural networks. achieve similar (and in many cases better) ImageNet classification accuracy than individually trained models of MobileNet v1. MobileNet v2. ShuffleNet and ResNet-50 at different widths respectively. We also demonstrate better performance of slimmable models compared with individual ones across a wide range of applications including COCO bounding-box object detection. instance segmentation and person keypoint detection without tuning hyper-parameters. Lastly we visualize and discuss the learned features of slimmable networks. Code and models are available at: this https URL,True,-CLCMk4AAAAJ:_kc_bZDykSQC,571,https://arxiv.org/abs/1812.08928,15212173000600372424,/scholar?cites=15212173000600372424,,,https://arxiv.org/pdf/1812.08928,0,0,0
1282330,Free-form image inpainting with gated convolution,2019,Jiahui Yu and Zhe Lin and Jimei Yang and Xiaohui Shen and Xin Lu and Thomas S Huang,,,,,,We present a generative image inpainting system to complete images with free-form mask and guidance. The system is based on gated convolutions learned from millions of images without additional labelling efforts. The proposed gated convolution solves the issue of vanilla convolution that treats all input pixels as valid ones. generalizes partial convolution by providing a learnable dynamic feature selection mechanism for each channel at each spatial location across all layers. Moreover. as free-form masks may appear anywhere in images with any shape. global and local GANs designed for a single rectangular mask are not applicable. Thus. we also present a patch-based GAN loss. named SN-PatchGAN. by applying spectral-normalized discriminator on dense image patches. SN-PatchGAN is simple in formulation. fast and stable in training. Results on automatic image inpainting and user-guided extension demonstrate that our system generates higher-quality and more flexible results than previous methods. Our system helps user quickly remove distracting objects. modify image layouts. clear watermarks and edit faces. Code. demo and models are available at: https://github. com/JiahuiYu/generative_inpainting.,True,-CLCMk4AAAAJ:NMxIlDl6LWMC,429,http://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.html,10791632868951282786,/scholar?cites=10791632868951282786,,,http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Free-Form_Image_Inpainting_With_Gated_Convolution_ICCV_2019_paper.pdf,0,0,0
1282331,Unitbox: An advanced object detection network,2016,Jiahui Yu and Yuning Jiang and Zhangyang Wang and Zhimin Cao and Thomas Huang,,,,,ACM,In present object detection systems. the deep convolutional neural networks (CNNs) are utilized to predict bounding boxes of object candidates. and have gained performance advantages over the traditional region proposal methods. However. existing deep CNN methods assume the object bounds to be four independent variables. which could be regressed by the l 2 loss separately. Such an oversimplified assumption is contrary to the well-received observation. that those variables are correlated. resulting to less accurate localization. To address the issue. we firstly introduce a novel Intersection over Union (IoU) loss function for bounding box prediction. which regresses the four bounds of a predicted box as a whole unit. By taking the advantages of IoU loss and deep fully convolutional networks. the UnitBox is introduced. which performs accurate and efficient localization. shows robust to objects of varied shapes …,True,-CLCMk4AAAAJ:u5HHmVD_uO8C,337,https://dl.acm.org/doi/abs/10.1145/2964284.2967274,15783604540977060935,/scholar?cites=15783604540977060935,,,https://arxiv.org/pdf/1608.01471,0,0,0
1282332,Wide activation for efficient and accurate image super-resolution,2018,Jiahui Yu and Yuchen Fan and Jianchao Yang and Ning Xu and Zhaowen Wang and Xinchao Wang and Thomas Huang,,"BMVC 2019 (challenge report of the winning solution in NTIRE Challenge on Single Image Super-Resolution, CVPR 2018)",,,,In this report we demonstrate that with same parameters and computational budgets. models with wider features before ReLU activation have significantly better performance for single image super-resolution (SISR). The resulted SR residual network has a slim identity mapping pathway with wider ( to) channels before activation in each residual block. To further widen activation ( to) without computational overhead. we introduce linear low-rank convolution into SR networks and achieve even better accuracy-efficiency tradeoffs. In addition. compared with batch normalization or no normalization. we find training with weight normalization leads to better accuracy for deep super-resolution networks. Our proposed SR network\textit {WDSR} achieves better results on large-scale DIV2K image super-resolution benchmark in terms of PSNR with same or lower computational complexity. Based on WDSR. our method also won 1st places in NTIRE 2018 Challenge on Single Image Super-Resolution in all three realistic tracks. Experiments and ablation studies support the importance of wide activation for image super-resolution. Code is released at: this https URL,True,-CLCMk4AAAAJ:LkGwnXOMwfcC,160,https://arxiv.org/abs/1808.08718,5944262375413705347,/scholar?cites=5944262375413705347,,,https://arxiv.org/pdf/1808.08718,0,0,0
1282333,Ntire 2018 challenge on single image super-resolution: Methods and results,2018,Radu Timofte and Shuhang Gu and Jiqing Wu and Luc Van Gool and Lei Zhang and Ming-Hsuan Yang and Muhammad Haris and Greg Shakhnarovich and Norimichi Ukita and Shijia Hu and Yijie Bei and Zheng Hui and Xiao Jiang and Yanan Gu and Jie Liu and Yifan Wang and Federico Perazzi and Brian McWilliams and Alexander Sorkin-Hornung and Olga Sorkine-Hornung and Christopher Schroers and Jiahui Yu and Yuchen Fan and Jianchao Yang and Ning Xu and Zhaowen Wang and Xinchao Wang and Thomas S Huang and Xintao Wang and Ke Yu and Tak-Wai Hui and Chao Dong and Liang Lin and Chen Change Loy and Dongwon Park and Kwanyoung Kim and Se Young Chun and Kai Zhang and Pengjv Liu and Wangmeng Zuo and Shi Guo and Jiye Liu and Jinchang Xu and Yijiao Liu and Fengye Xiong and Yuan Dong and Hongliang Bai and Alexandru Damian and Nikhil Ravi and Sachit Menon and Cynthia Rudin and Junghoon Seo and Taegyun Jeon and Jamyoung Koo and Seunghyun Jeon and Soo Ye Kim and Jae-Seok Choi and Sehwan Ki and Soomin Seo and Hyeonjun Sim and Saehun Kim and Munchurl Kim and Rong Chen and Kun Zeng and Jinkang Guo and Yanyun Qu and Cuihua Li and Namhyuk Ahn,,,,852-863,,This paper reviews the 2nd NTIRE challenge on single image super-resolution (restoration of rich details in a low resolution image) with focus on proposed solutions and results. The challenge had 4 tracks. Track 1 employed the standard bicubic downscaling setup. while Tracks 2. 3 and 4 had realistic unknown downgrading operators simulating camera image acquisition pipeline. The operators were learnable through provided pairs of low and high resolution train images. The tracks had 145. 114. 101. and 113 registered participants. resp.. and 31 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,-CLCMk4AAAAJ:isC4tDSrTZIC,158,http://openaccess.thecvf.com/content_cvpr_2018_workshops/w13/html/Timofte_NTIRE_2018_Challenge_CVPR_2018_paper.html,308702806833114296,/scholar?cites=308702806833114296,,,http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Timofte_NTIRE_2018_Challenge_CVPR_2018_paper.pdf,0,0,0
1282334,Foreground-aware Image Inpainting,2019,Wei Xiong and Jiahui Yu and Zhe Lin and Jimei Yang and Xin Lu and Connelly Barnes and Jiebo Luo,,"Computer Vision and Pattern Recognition (CVPR), 2019",,,,Existing image inpainting methods typically fill holes by borrowing information from surrounding pixels. They often produce unsatisfactory results when the holes overlap with or touch foreground objects due to lack of information about the actual extent of foreground and background regions within the holes. These scenarios. however. are very important in practice. especially for applications such as distracting object removal. To address the problem. we propose a foreground-aware image inpainting system that explicitly disentangles structure inference and content completion. Specifically. our model learns to predict the foreground contour first. and then inpaints the missing region using the predicted contour as guidance. We show that by such disentanglement. the contour completion model predicts reasonable contours of objects. and further substantially improves the performance of image inpainting. Experiments show that our method significantly outperforms existing methods and achieves superior inpainting results on challenging cases with complex compositions.,True,-CLCMk4AAAAJ:Zph67rFs4hoC,118,http://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Foreground-Aware_Image_Inpainting_CVPR_2019_paper.html,7041126867879643904,/scholar?cites=7041126867879643904,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiong_Foreground-Aware_Image_Inpainting_CVPR_2019_paper.pdf,0,0,0
1282335,Conformer: Convolution-augmented transformer for speech recognition,2020,Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang,,arXiv preprint arXiv:2005.08100,,,,Recently Transformer and Convolution neural network (CNN) based models have shown promising results in Automatic Speech Recognition (ASR). outperforming Recurrent neural networks (RNNs). Transformer models are good at capturing content-based global interactions. while CNNs exploit local features effectively. In this work. we achieve the best of both worlds by studying how to combine convolution neural networks and transformers to model both local and global dependencies of an audio sequence in a parameter-efficient way. To this regard. we propose the convolution-augmented transformer for speech recognition. named Conformer. Conformer significantly outperforms the previous Transformer and CNN based models achieving state-of-the-art accuracies. On the widely used LibriSpeech benchmark. our model achieves WER of 2.1%/4.3% without using a language model and 1.9%/3.9% with an external language model on test/testother. We also observe competitive performance of 2.7%/6.3% with a small model of only 10M parameters.,True,-CLCMk4AAAAJ:HoB7MX3m0LUC,97,https://arxiv.org/abs/2005.08100,9289975417026727568,/scholar?cites=9289975417026727568,,,https://arxiv.org/pdf/2005.08100,0,0,0
1282336,Universally slimmable networks and improved training techniques,2019,Jiahui Yu and Thomas Huang,,"International Conference on Computer Vision (ICCV), 2019",,,,Slimmable networks are a family of neural networks that can instantly adjust the runtime width. The width can be chosen from a predefined widths set to adaptively optimize accuracy-efficiency trade-offs at runtime. In this work. we propose a systematic approach to train universally slimmable networks (US-Nets). extending slimmable networks to execute at arbitrary width. and generalizing to networks both with and without batch normalization layers. We further propose two improved training techniques for US-Nets. named the sandwich rule and inplace distillation. to enhance training process and boost testing accuracy. We show improved performance of universally slimmable MobileNet v1 and MobileNet v2 on ImageNet classification task. compared with individually trained ones and 4-switch slimmable network baselines. We also evaluate the proposed US-Nets and improved training techniques on tasks of image super-resolution and deep reinforcement learning. Extensive ablation experiments on these representative tasks demonstrate the effectiveness of our proposed methods. Our discovery opens up the possibility to directly evaluate FLOPs-Accuracy spectrum of network architectures. Code and models are available at: https://github. com/JiahuiYu/slimmable_networks.,True,-CLCMk4AAAAJ:4DMP91E08xMC,88,http://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Universally_Slimmable_Networks_and_Improved_Training_Techniques_ICCV_2019_paper.html,4596016406456770344,/scholar?cites=4596016406456770344,,,http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Universally_Slimmable_Networks_and_Improved_Training_Techniques_ICCV_2019_paper.pdf,0,0,0
1282337,AutoSlim: Towards One-Shot Architecture Search for Channel Numbers,2019,Jiahui Yu and Thomas Huang,,NeurIPS 2019 Workshop on Energy Efficient Machine Learning and Cognitive Computing,,,,We study how to set channel numbers in a neural network to achieve better accuracy under constrained resources (eg. FLOPs. latency. memory footprint or model size). A simple and one-shot solution. named AutoSlim. is presented. Instead of training many network samples and searching with reinforcement learning. we train a single slimmable network to approximate the network accuracy of different channel configurations. We then iteratively evaluate the trained slimmable model and greedily slim the layer with minimal accuracy drop. By this single pass. we can obtain the optimized channel configurations under different resource constraints. We present experiments with MobileNet v1. MobileNet v2. ResNet-50 and RL-searched MNasNet on ImageNet classification. We show significant improvements over their default channel configurations. We also achieve better accuracy than recent channel pruning methods and neural architecture search methods.Notably. by setting optimized channel numbers. our AutoSlim-MobileNet-v2 at 305M FLOPs achieves 74.2% top-1 accuracy. 2.4% better than default MobileNet-v2 (301M FLOPs). and even 0.2% better than RL-searched MNasNet (317M FLOPs). Our AutoSlim-ResNet-50 at 570M FLOPs. without depthwise convolutions. achieves 1.3% better accuracy than MobileNet-v1 (569M FLOPs). Code and models will be available at: this https URL,True,-CLCMk4AAAAJ:RYcK_YlVTxYC,56,https://arxiv.org/abs/1903.11728,3816618836903814619,/scholar?cites=3816618836903814619,,,https://arxiv.org/pdf/1903.11728,0,0,0
1282338,Mutan: Multimodal tucker fusion for visual question answering,2017,Hedi Ben-Younes and Rémi Cadene and Matthieu Cord and Nicolas Thome,,,,2612-2620,,Bilinear models provide an appealing framework for mixing and merging information in Visual Question Answering (VQA) tasks. They help to learn high level associations between question meaning and visual concepts in the image. but they suffer from huge dimensionality issues. We introduce MUTAN. a multimodal tensor-based Tucker decomposition to efficiently parametrize bilinear interactions between visual and textual representations. Additionally to the Tucker framework. we design a low-rank matrix-based decomposition to explicitly constrain the interaction rank. With MUTAN. we control the complexity of the merging scheme while keeping nice interpretable fusion relations. We show how the Tucker decomposition framework generalizes some of the latest VQA architectures. providing state-of-the-art results.,True,3f3Zq-8AAAAJ:lSLTfruPkqcC,329,http://openaccess.thecvf.com/content_iccv_2017/html/Ben-younes_MUTAN_Multimodal_Tucker_ICCV_2017_paper.html,7053181340342045630,/scholar?cites=7053181340342045630,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Ben-younes_MUTAN_Multimodal_Tucker_ICCV_2017_paper.pdf,0,0,0
1282339,Wildcat: Weakly supervised learning of deep convnets for image classification. pointwise localization and segmentation,2017,Thibaut Durand and Taylor Mordan and Nicolas Thome and Matthieu Cord,,,,642-651,,This paper introduces WILDCAT. a deep learning method which jointly aims at aligning image regions for gaining spatial invariance and learning strongly localized features. Our model is trained using only global image labels and is devoted to three main visual recognition tasks: image classification. weakly supervised object localization and semantic segmentation. WILDCAT extends state-of-the-art Convolutional Neural Networks at three main levels: the use of Fully Convolutional Networks for maintaining spatial resolution. the explicit design in the network of local features related to different class modalities. and a new way to pool these features to provide a global image prediction required for weakly supervised training. Extensive experiments show that our model significantly outperforms state-of-the-art methods.,True,3f3Zq-8AAAAJ:RYcK_YlVTxYC,234,http://openaccess.thecvf.com/content_cvpr_2017/html/Durand_WILDCAT_Weakly_Supervised_CVPR_2017_paper.html,5997063811530804850,/scholar?cites=5997063811530804850,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Durand_WILDCAT_Weakly_Supervised_CVPR_2017_paper.pdf,0,0,0
1282340,Pooling in image representation: The visual codeword point of view,2013,Sandra Avila and Nicolas Thome and Matthieu Cord and Eduardo Valle and Arnaldo De A AraúJo,117,Computer Vision and Image Understanding,5,453-465,Academic Press,In this work. we propose BossaNova. a novel representation for content-based concept detection in images and videos. which enriches the Bag-of-Words model. Relying on the quantization of highly discriminant local descriptors by a codebook. and the aggregation of those quantized descriptors into a single pooled feature vector. the Bag-of-Words model has emerged as the most promising approach for concept detection on visual documents. BossaNova enhances that representation by keeping a histogram of distances between the descriptors found in the image and those in the codebook. preserving thus important information about the distribution of the local descriptors around each codeword. Contrarily to other approaches found in the literature. the non-parametric histogram representation is compact and simple to compute. BossaNova compares well with the state-of-the-art in several standard datasets …,True,3f3Zq-8AAAAJ:M3ejUd6NZC8C,203,https://www.sciencedirect.com/science/article/pii/S1077314212001737,7836593192753784698,/scholar?cites=7836593192753784698,,,http://www-ia.lip6.fr/~cord/pdfs/publis/BossaNova.pdf,0,0,0
1282341,Weldon: Weakly supervised learning of deep convolutional neural networks,2016,Thibaut Durand and Nicolas Thome and Matthieu Cord,,,,4743-4752,,In this paper. we introduce a novel framework for WEakly supervised Learning of Deep cOnvolutional neural Networks (WELDON). Our method is dedicated to automatically selecting relevant image regions from weak annotations. eg global image labels. and encompasses the following contributions. Firstly. WELDON leverages recent improvements on the Multiple Instance Learning paradigm. ie negative evidence scoring and top instance selection. Secondly. the deep CNN is trained to optimize Average Precision. and fine-tuned on the target dataset with efficient computations due to convolutional feature sharing. A thorough experimental validation shows that WELDON outperforms state-of-the-art results on six different datasets.,True,3f3Zq-8AAAAJ:M3NEmzRMIkIC,141,http://openaccess.thecvf.com/content_cvpr_2016/html/Durand_WELDON_Weakly_Supervised_CVPR_2016_paper.html,2489903275528689521,/scholar?cites=2489903275528689521,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Durand_WELDON_Weakly_Supervised_CVPR_2016_paper.pdf,0,0,0
1282342,A real-time. multiview fall detection system: A LHMM-based approach,2008,Nicolas Thome and Serge Miguet and Sébastien Ambellouis,18,IEEE transactions on circuits and systems for video technology,11,1522-1532,IEEE,Automatic detection of a falling person in video sequences has interesting applications in video-surveillance and is an important part of future pervasive home monitoring systems. In this paper. we propose a multiview approach to achieve this goal. where motion is modeled using a layered hidden Markov model (LHMM). The posture classification is performed by a fusion unit. merging the decision provided by the independently processing cameras in a fuzzy logic context. In each view. the fall detection is optimized in a given plane by performing a metric image rectification. making it possible to extract simple and robust features. and being convenient for real-time purpose. A theoretical analysis of the chosen descriptor enables us to define the optimal camera placement for detecting people falling in unspecified situations. and we prove that two cameras are sufficient in practice. Regarding event detection. the LHMM …,True,3f3Zq-8AAAAJ:u5HHmVD_uO8C,135,https://ieeexplore.ieee.org/abstract/document/4633638/,16615392799866635141,/scholar?cites=16615392799866635141,,,https://www.academia.edu/download/48217897/A_real-time_multiview_fall_detection_sys20160821-14361-v9pm9e.pdf,0,0,0
1282343,Murel: Multimodal relational reasoning for visual question answering,2019,Remi Cadene and Hedi Ben-Younes and Matthieu Cord and Nicolas Thome,,,,1989-1998,,Multimodal attentional networks are currently state-of-the-art models for Visual Question Answering (VQA) tasks involving real images. Although attention allows to focus on the visual content relevant to the question. this simple mechanism is arguably insufficient to model complex reasoning features required for VQA or other high-level tasks. In this paper. we propose MuRel. a multimodal relational network which is learned end-to-end to reason over real images. Our first contribution is the introduction of the MuRel cell. an atomic reasoning primitive representing interactions between question and image regions by a rich vectorial representation. and modeling region relations with pairwise combinations. Secondly. we incorporate the cell into a full MuRel network. which progressively refines visual and question interactions. and can be leveraged to define visualization schemes finer than mere attention maps. We validate the relevance of our approach with various ablation studies. and show its superiority to attention-based methods on three datasets: VQA 2.0. VQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms state-of-the-art results in this challenging context. Our code is available: github. com/Cadene/murel. bootstrap. pytorch,True,3f3Zq-8AAAAJ:EUQCXRtRnyEC,115,http://openaccess.thecvf.com/content_CVPR_2019/html/Cadene_MUREL_Multimodal_Relational_Reasoning_for_Visual_Question_Answering_CVPR_2019_paper.html,1186094337208548043,/scholar?cites=1186094337208548043,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Cadene_MUREL_Multimodal_Relational_Reasoning_for_Visual_Question_Answering_CVPR_2019_paper.pdf,0,0,0
1282344,Recipe recognition with large multimodal food dataset,2015,Xin Wang and Devinder Kumar and Nicolas Thome and Matthieu Cord and Frederic Precioso,,,,1-6,IEEE,This paper deals with automatic systems for image recipe recognition. For this purpose. we compare and evaluate leading vision-based and text-based technologies on a new very large multimodal dataset (UPMC Food-101) containing about 100.000 recipes for a total of 101 food categories. Each item in this dataset is represented by one image plus textual information. We present deep experiments of recipe recognition on our dataset using visual. textual information and fusion. Additionally. we present experiments with text-based embedding technology to represent any food word in a semantical continuous space. We also compare our dataset features with a twin dataset provided by ETHZ university: we revisit their data collection protocols and carry out transfer learning schemes to highlight similarities and differences between both datasets. Finally. we propose a real application for daily users to identify recipes …,True,3f3Zq-8AAAAJ:r0BpntZqJG4C,108,https://ieeexplore.ieee.org/abstract/document/7169757/,4686785099672656388,/scholar?cites=4686785099672656388,,,https://hal.archives-ouvertes.fr/hal-01196959/document,0,0,0
1282345,Learning deep hierarchical visual feature coding,2014,Hanlin Goh and Nicolas Thome and Matthieu Cord and Joo-Hwee Lim,25,IEEE transactions on neural networks and learning systems,12,2212-2225,IEEE,In this paper. we propose a hybrid architecture that combines the image modeling strengths of the bag of words framework with the representational power and adaptability of learning deep architectures. Local gradient-based descriptors. such as SIFT. are encoded via a hierarchical coding scheme composed of spatial aggregating restricted Boltzmann machines (RBM). For each coding layer. we regularize the RBM by encouraging representations to fit both sparse and selective distributions. Supervised fine-tuning is used to enhance the quality of the visual representation for the categorization task. We performed a thorough experimental evaluation using three image categorization data sets. The hierarchical coding scheme achieved competitive categorization accuracies of 79.7% and 86.4% on the Caltech-101 and 15-Scenes data sets. respectively. The visual representations learned are compact and the model's …,True,3f3Zq-8AAAAJ:IWHjjKOFINEC,104,https://ieeexplore.ieee.org/abstract/document/6763041/,9997231968202590026,/scholar?cites=9997231968202590026,,,http://oar.a-star.edu.sg/jspui/bitstream/123456789/1542/1/TNNLS_Manuscript_final.pdf,0,0,0
1282346,T-HOG: An effective gradient-based descriptor for single line text regions,2013,Rodrigo Minetto and Nicolas Thome and Matthieu Cord and Neucimar J Leite and Jorge Stolfi,46,Pattern recognition,3,1078-1090,Pergamon,We discuss the use of histogram of oriented gradients (HOG) descriptors as an effective tool for text description and recognition. Specifically. we propose a HOG-based texture descriptor (T-HOG) that uses a partition of the image into overlapping horizontal cells with gradual boundaries. to characterize single-line texts in outdoor scenes. The input of our algorithm is a rectangular image presumed to contain a single line of text in Roman-like characters. The output is a relatively short descriptor that provides an effective input to an SVM classifier. Extensive experiments show that the T-HOG is more accurate than Dalal and Triggs's original HOG-based classifier. for any descriptor size. In addition. we show that the T-HOG is an effective tool for text/non-text discrimination and can be used in various text detection applications. In particular. combining T-HOG with a permissive bottom-up text detector is shown to outperform …,True,3f3Zq-8AAAAJ:4TOpqqG69KYC,101,https://www.sciencedirect.com/science/article/pii/S0031320312004438,15514781147884628683,/scholar?cites=15514781147884628683,,,http://webia.lip6.fr/~thomen/papers/Minetto_PR_T-HOG_final.pdf,0,0,0
1282347,Cross-modal retrieval in the cooking context: Learning semantic text-image embeddings,2018,Micael Carvalho and Rémi Cadène and David Picard and Laure Soulier and Nicolas Thome and Matthieu Cord,,,,35-44,,Designing powerful tools that support cooking activities has rapidly gained popularity due to the massive amounts of available data. as well as recent advances in machine learning that are capable of analyzing them. In this paper. we propose a cross-modal retrieval model aligning visual and textual data (like pictures of dishes and their recipes) in a shared representation space. We describe an effective learning scheme. capable of tackling large-scale problems. and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs. We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.,True,3f3Zq-8AAAAJ:HoB7MX3m0LUC,87,https://dl.acm.org/doi/abs/10.1145/3209978.3210036,13326861740182107451,/scholar?cites=13326861740182107451,,,https://arxiv.org/pdf/1804.11146,0,0,0
1282348,Quadruplet-wise image similarity learning,2013,Marc T Law and Nicolas Thome and Matthieu Cord,,,,249-256,,This paper introduces a novel similarity learning framework. Working with inequality constraints involving quadruplets of images. our approach aims at efficiently modeling similarity from rich or complex semantic label relationships. From these quadruplet-wise constraints. we propose a similarity learning framework relying on a convex optimization scheme. We then study how our metric learning scheme can exploit specific class relationships. such as class ranking (relative attributes). and class taxonomy. We show that classification using the learned metrics gets improved performance over state-of-the-art methods on several datasets. We also evaluate our approach in a new application to learn similarities between webpage screenshots in a fully unsupervised way.,True,3f3Zq-8AAAAJ:dhFuZR0502QC,87,http://openaccess.thecvf.com/content_iccv_2013/html/Law_Quadruplet-Wise_Image_Similarity_2013_ICCV_paper.html,14848262153744517114,/scholar?cites=14848262153744517114,,,https://openaccess.thecvf.com/content_iccv_2013/papers/Law_Quadruplet-Wise_Image_Similarity_2013_ICCV_paper.pdf,0,0,0
1282349,Immediate early and early lytic cycle proteins are frequent targets of the Epstein-Barr virus–induced cytotoxic T cell response,1997,NM Steven and NE Annels and A Kumar and AM Leese and MG Kurilla and AB Rickinson,185,The Journal of experimental medicine,9,1605-1618,The Rockefeller University Press,Epstein-Barr virus (EBV). a human γ-herpesvirus. can establish both nonproductive (latent) and productive (lytic) infections. Although the CD8+ cytotoxic T lymphocyte (CTL) response to latently infected cells is well characterized. very little is known about T cell controls over lytic infection; this imbalance in our understanding belies the importance of virus-replicative lesions in several aspects of EBV disease pathogenesis. The present work shows that the primary CD8+ CTL response to EBV in infectious mononucleosis patients contains multiple lytic antigen-specific reactivities at levels at least as high as those seen against latent antigens; similar reactivities are also detectable in CTL memory. Clonal analysis revealed individual responses to the two immediate early proteins BZLF1 and BRLF1. and to three (BMLF1. BMRF1. and BALF2) of the six early proteins tested. In several cases. the peptide epitope and HLA …,True,1bSxBDwAAAAJ:y2egTTA-ddEC,377,https://rupress.org/jem/article-abstract/185/9/1605/25443,6074017887358646662,/scholar?cites=6074017887358646662,,,https://rupress.org/jem/article/185/9/1605/25443,0,0,0
1282350,Electromagnetic and microwave absorption properties of  substituted barium hexaferrites and its polymer composite,2007,SM Abbas and R Chatterjee and AK Dixit and AVR Kumar and TC Goel,101,Journal of applied physics,7,074105,American Institute of Physics,The electromagnetic (EM) and microwave absorption properties of (Co2+–Si4+) substituted barium hexaferrite compositions BaCox2+Fey+2Six+y4+Fe12−2x−2y+3O19 (x=0.9 and y=0.0. 0.05. and 0.2) and its polymer composites prepared from hexaferrite. polyaniline. and carbon powders dispersed in polyurethane matrix have been investigated at the microwave frequency range of the X band (8.2–12.4GHz). The hexaferrite compositions were synthesized by solid-state reaction technique. whereas polyaniline. by chemical route. The permeabilities of a ferrite are drastically reduced at higher gigahertz frequencies. The permittivities. however. can be enhanced by appropriate choice of composition and processing temperature. In the present ferrite composition. silicon content is taken in excess so as to convert some of the Fe3+ ions to Fe2+ ions. This conversion has been shown to enhance EM and absorption …,True,1bSxBDwAAAAJ:DG0Btp6lGL8C,131,https://aip.scitation.org/doi/abs/10.1063/1.2716379,11544269867699642324,/scholar?cites=11544269867699642324,,,https://www.researchgate.net/profile/Ratnamala_Chatterjee/publication/234053511_Electromagnetic_and_microwave_absorption_properties_of_Co2_-_Si4_substituted_Ba-Hexaferrites_and_its_polymer_composites/links/0deec51a9e9e6d5554000000/Electromagnetic-and-microwave-absorption-properties-of-Co2-Si4-substituted-Ba-Hexaferrites-and-its-polymer-composites.pdf,0,0,0
1282351,The bipyridyl herbicide paraquat produces oxidative stress-mediated toxicity in human neuroblastoma SH-SY5Y cells: relevance to the dopaminergic pathogenesis,2005,Wonsuk Yang and Evelyn Tiffany-Castiglioni,68,"Journal of Toxicology and Environmental Health, Part A",22,1939-1961,Taylor & Francis Group,Paraquat (PQ) is a cationic nonselective bipyridyl herbicide widely used to control weeds and grasses in agriculture. Epidemiologic studies indicate that exposure to pesticides can be a risk factor in the incidence of Parkinson's disease (PD). A strong correlation has been reported between exposure to paraquat and PD incidence in Canada. Taiwan. and the United States. This correlation is supported by animal studies showing that paraquat produces toxicity in dopaminergic neurons of the rat and mouse brain. However. it is unclear how paraquat triggers toxicity in dopaminergic neurons. Based on the prooxidant properties of paraquat. it was hypothesized that paraquat may induce oxidative stress-mediated toxicity in dopaminergic neurons. To explore this possibility. dopaminergic SH-SY5Y cells were treated with paraquat. and several biomarkers of oxidativestress were measured. First. a specific dopamine …,True,1bSxBDwAAAAJ:J2VLEJC5QowC,118,https://www.tandfonline.com/doi/abs/10.1080/15287390500226987,9385232734263048537,/scholar?cites=9385232734263048537,,,https://www.researchgate.net/profile/Evelyn_Tiffany-Castiglioni/publication/7503032_The_Bipyridyl_Herbicide_Paraquat_Produces_Oxidative_Stress-Mediated_Toxicity_in_Human_Neuroblastoma_SH-SY5Y_Cells_Relevance_to_the_Dopaminergic_Pathogenesis/links/56fd88fd08ae650a64f54f9c.pdf,0,0,0
1282352,Recent progress of N-heterocyclic carbenes in heterogeneous catalysis,2013,Kalluri VS Ranganath and Satoaki Onitsuka and A Kiran Kumar and Junji Inanaga,3,,9,2161-2181,Royal Society of Chemistry,The aim of this tutorial review is to highlight the potential application of N-heterocyclic carbenes (NHC) in heterogeneous catalysis. The unique combination of the high reactivity of NHCs together with the ease of separation. purification and recyclability of the solid catalyst makes the heterogeneous system one of the most promising strategies for the synthesis of fine chemicals on an industrial scale. This tutorial review focuses on the most representative examples of this nascent research area and highlights recent achievements of NHCs in heterogeneous catalysis (other than metathesis reactions). We hope this serves as inspiration for further progress in this field.,True,1bSxBDwAAAAJ:K0avj1FDtHUC,106,https://pubs.rsc.org/en/content/articlehtml/2013/cy/c3cy00118k,11248967313219577970,/scholar?cites=11248967313219577970,,,,0,0,0
1282353,Antioxidant and antibacterial activity of six edible wild plants (Sonchus spp.) in China,2011,Dao-Zong Xia and Xin-Fen Yu and Zhuo-Ying Zhu and Zhuang-Dan Zou,25,Natural product research,20,1893-1901,Taylor & Francis Group,The total phenolic and flavonoid. antioxidant and antibacterial activities of six Sonchus wild vegetables (Sonchus oleraceus L.. Sonchus arvensis L.. Sonchus asper (L.) Hill.. Sonchus uliginosus M.B.. Sonchus brachyotus DC. and Sonchus lingianus Shih) in China were investigated. The results revealed that S. arvensis extract and S. oleraceus extract contained the highest amount of phenolic and flavonoid. respectively. Among the methanol extracts of six Sonchus species. S. arvensis extract exhibited the highest radical (DPPH and ABTS+) scavenging power and lipid peroxidation inhibitory power. It also exhibited the highest reducing power at 500 µg mL−1 by A 700 = 0.80. The results of antibacterial test indicated that the S. oleraceus extract showed higher activity than the other five Sonchus wild vegetables extracts. both in Gram-negative bacteria (Escherichia coli. Salmonella enterica and Vibrio …,True,1bSxBDwAAAAJ:wUCFpcnEedwC,101,https://www.tandfonline.com/doi/abs/10.1080/14786419.2010.534093,3445030750831045030,/scholar?cites=3445030750831045030,,,https://www.researchgate.net/profile/Daozong-Xia/publication/51525433_Antioxidant_and_antibacterial_activity_of_six_edible_wild_plants_Sonchus_spp_in_China/links/5ed3b572299bf1c67d2cd036/Antioxidant-and-antibacterial-activity-of-six-edible-wild-plants-Sonchus-spp-in-China.pdf,0,0,0
1282354,Decomposing transverse momentum balance contributions for quenched jets in PbPb collisions at s NN= 2.76 TeV,2016,Vardan Khachatryan and Albert M Sirunyan and Armen Tumasyan and Wolfgang Adam and E Asilar and Thomas Bergauer and Johannes Brandstetter and Erica Brondolin and Marko Dragicevic and Janos Erö and Martin Flechl and Markus Friedl and Rudolf Fruehwirth and Vasile Mihai Ghete and Christian Hartl and Natascha Hörmann and Josef Hrubec and Manfred Jeitler and Axel König and Ilse Krätschmer and Dietrich Liko and Takashi Matsushita and Ivan Mikulec and Dinyar Rabady and Navid Rad and Babak Rahbaran and Herbert Rohringer and Jochen Schieck and Josef Strauss and Wolfgang Treberer-Treberspurg and Wolfgang Waltenberger and C-E Wulz and Vladimir Mossolov and Nikolai Shumeiko and J Suarez Gonzalez and Sara Alderweireldt and Eddi A De Wolf and Xavier Janssen and Jasper Lauwers and Merijn Van De Klundert and Hans Van Haevermaet and Pierre Van Mechelen and Nick Van Remortel and Alex Van Spilbeeck and S Abu Zeid and Freya Blekman and Jorgen D’Hondt and Nadir Daci and Isabelle De Bruyn and Kevin Deroover and Natalie Heracleous and Steven Lowette and Seth Moortgat and Lieselotte Moreels and Annik Olbrechts and Quentin Python and Stefaan Tavernier and Walter Van Doninck and Petra Van Mulders and Isis Van Parijs and Hugues Brun and Cécile Caillol and Barbara Clerbaux and Gilles De Lentdecker and Hugo Delannoy and Giuseppe Fasanella and Laurent Favart and Reza Goldouzian and Anastasia Grebenyuk and Georgia Karapostoli and Thomas Lenzi and Alexandre Léonard and Jelena Luetic and Thierry Maerschalk and Andrey Marinov and Aidan Randle-conde and Tomislav Seva and C Vander Velde and P Vanlaer and R Yonamine and F Zenoni and F Zhang and A Cimmino and T Cornelis and D Dobur and A Fagot and G Garcia and M Gul and D Poyraz and S Salva and R Schöfbeck and M Tytgat and W Van Driessche and E Yazgan and N Zaganidis and H Bakhshiansohi and C Beluffi and O Bondu and S Brochet and Graziella Bruno and A Caudron and S De Visscher and C Delaere and M Delcourt and L Forthomme and B Francois and A Giammanco and A Jafari and P Jez and M Komm and V Lemaitre and A Magitteri and A Mertens and M Musich and C Nuttens and K Piotrzkowski and L Quertenmont and M Selvaggi and M Vidal Marono and S Wertz and N Beliy and WL Aldá Júnior and FL Alves and GA Alves and L Brito and C Hensel and A Moraes and ME Pol and P Rebello Teles and E Belchior Batista Das Chagas and W Carvalho and J Chinellato and A Custódio and EM Da Costa and GG Da Silveira and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and LM Huertas Guativa and H Malbouisson and D Matos Figueiredo and C Mora Herrera and L Mundim and H Nogima and WL Prado Da Silva and A Santoro and A Sznajder and EJ Tonelli Manganote and A Vilela Pereira and S Ahuja,2016,Journal of High Energy Physics,11,1-43,Springer Berlin Heidelberg,Interactions between jets and the quark-gluon plasma produced in heavy ion collisions are studied via the angular distributions of summed charged-particle transverse momenta (p T) with respect to both the leading and subleading jet axes in high-p T dijet events. The contributions of charged particles in different momentum ranges to the overall event p T balance are decomposed into short-range jet peaks and a long-range azimuthal asymmetry in charged-particle p T. The results for PbPb collisions are compared to those in pp collisions using data collected in 2011 and 2013. at collision energy TeV with integrated luminosities of 166 μb− 1 and 5.3 pb− 1. respectively. by the CMS experiment at the LHC. Measurements are presented as functions of PbPb collision centrality. charged-particle p T. relative azimuth. and radial distance from the jet axis for balanced and unbalanced dijets.,True,1bSxBDwAAAAJ:GPTxl2ZukFYC,72,https://link.springer.com/article/10.1007/JHEP11(2016)055,11351142798087027519,/scholar?cites=11351142798087027519,,,https://link.springer.com/article/10.1007/JHEP11(2016)055,0,0,0
1282355,Geo-economic variations in epidemiology. patterns of care. and outcomes in patients with acute respiratory distress syndrome: insights from the LUNG SAFE prospective cohort study,2017,John G Laffey and Fabiana Madotto and Giacomo Bellani and Tài Pham and Eddy Fan and Laurent Brochard and Pravin Amin and Yaseen Arabi and Ednan K Bajwa and Alejandro Bruhn and Vladimir Cerny and Kevin Clarkson and Leo Heunks and Kiyoyasu Kurahashi and Jon Henrik Laake and Jose A Lorente and Lia McNamee and Nicolas Nin and Jose Emmanuel Palo and Lise Piquilloud and Haibo Qiu and Juan Ignacio Silesky Jiménez and Andres Esteban and Daniel F McAuley and Frank van Haren and Marco Ranieri and Gordon Rubenfeld and Hermann Wrigge and Arthur S Slutsky and Antonio Pesenti and John G Laffey and Tai Pham and Luciano Gattinoni and Anders Larsson and Daniel F McAuley and B Taylor Thompson and Arthur S Slutsky and Fernando Rios and Thierry Sottiaux and Pieter Depuydt and Fredy S Lora and Luciano C Azevedo and Guillermo Bugedo and Marcos Gonzalez and Juan Silesky and Jonas Nielsen and Manuel Jibaja and Dimitrios Matamis and Jorge L Ranero and SM Hashemian and Asisclo Villagomez and Amine Ali Zeggwagh and Leo M Heunks and Antero do Vale Fernandes and Dorel Sandesc and Yaasen Arabi and Vesna Bumbasierevic and Jose A Lorente and Fekri Abroug and Javier Hurtado and Ed Bajwa and Gabriel Démpaire and Hektor Sula and Lordian Nunci and Alma Cani and Alan Zazu and Christian Dellera and Risso V Alejandro and Julio Daldin and Ruben O Fernandez and Luis P Cardonnet and Lisandro R Bettini and Mariano Carboni Bisso and Emilio M Osman and Mariano G Setten and Pablo Lovazzano and Javier Alvarez and Veronica Villar and Norberto C Pozo and Nicolas Grubissich and Gustavo A Plotnikow and Daniela N Vasquez and Santiago Ilutovich and Norberto Tiribelli and Ariel Chena and Carlos A Pellegrini and María G Saenz and Elisa Estenssoro and Matias Brizuela and Hernan Gianinetto and Pablo E Gomez and Valeria I Cerrato and Marco G Bezzi and Silvina A Borello and Flavia A Loiacono and Adriana M Fernandez and Serena Knowles and Claire Reynolds and Deborah M Inskip and Jennene J Miller and Jing Kong and Christina Whitehead and Shailesh Bihari and Aylin Seven and Amanda Krstevski and Helen Rodgers and Rebecca Millar and Toni Mckenna and Irene Bailey and Gabrielle Hanlon and Anders Aneman and Joan Lynch and Raman Azad and John Neal and Paul Woods and Brigit Roberts and Mark Kol and Helen Wong and Katharina Riss and Thomas Staudinger and Xavier Wittebole and Caroline Berghe and Pierre Bulpa and Alain Dive and Rik Verstraete and Herve Lebbinck and Joris Vermassen and Philippe Meersseman and Helga Ceunen and Jonas Rosa and Daniel Beraldo and Claudio Piras and Adenilton Rampinelli and Antonio Nassar and Sergio Mataloun and Marcelo Moock and Marlus Thompson and Claudio Gonçalves and Ana Antônio and Aline Ascoli and Rodrigo Biondi and Danielle Fontenele and Danielle Nobrega and Vanessa Sales and Suresh Shindhe and Dk Ismail and Francois Beloncle and Kyle Davies and Rob Cirone and Venika Manoharan,5,The Lancet Respiratory Medicine,8,627-638,Elsevier,Background Little information is available about the geo-economic variations in demographics. management. and outcomes of patients with acute respiratory distress syndrome (ARDS). We aimed to characterise the effect of these geo-economic variations in patients enrolled in the Large Observational Study to Understand the Global Impact of Severe Acute Respiratory Failure (LUNG SAFE). Methods LUNG SAFE was done during 4 consecutive weeks in winter. 2014. in a convenience sample of 459 intensive-care units in 50 countries across six continents. Inclusion criteria were admission to a participating intensive-care unit (including transfers) within the enrolment window and receipt of invasive or non-invasive ventilation. One of the trial's secondary aims was to characterise variations in the demographics. management. and outcome of patients with ARDS. We used the 2016 World Bank countries classification to …,True,1bSxBDwAAAAJ:lOLSY4hLU6kC,67,https://www.sciencedirect.com/science/article/pii/S2213260017302138,3458676806699930553,/scholar?cites=3458676806699930553,,,https://research.vumc.nl/en/publications/geo-economic-variations-in-epidemiology-patterns-of-care-and-outc,0,0,0
1282356,Opportunities for Napier grass (Pennisetum purpureum) improvement using molecular genetics,2017,Alemayehu Teressa Negawo and Abel Teshome and Alok Kumar and Jean Hanson and Chris S Jones,7,,2,28,Multidisciplinary Digital Publishing Institute,Napier grass (Pennisetum purpureum Schumach.) is a fast-growing perennial grass native to Sub-Saharan Africa that is widely grown across the tropical and subtropical regions of the world. It is a multipurpose forage crop. primarily used to feed cattle in cut and carry feeding systems. Characterization and diversity studies on a small collection of Napier grasses have identified a moderate level of genetic variation and highlighted the availability of some good agronomic traits. particularly high biomass production. as a forage crop. However. very little information exists on precise phenotyping. genotyping and the application of molecular technologies to Napier grass improvement using modern genomic tools which have been applied in advancing the selection and breeding of important food crops. In this review paper. existing information on genetic resources. molecular diversity. yield and nutritional quality of Napier grass will be discussed. Recent findings on characterizing disease resistance and abiotic stress (drought) tolerance will also be highlighted. Finally. opportunities and future prospects for better conservation and use arising from the application of modern genomic tools in Napier grass phenotyping and genotyping will be discussed. View Full-Text,True,1bSxBDwAAAAJ:x-IcQEm-ju4C,64,https://www.mdpi.com/2073-4395/7/2/28,17994204015576373963,/scholar?cites=17994204015576373963,,,https://www.mdpi.com/2073-4395/7/2/28/pdf,0,0,0
1282357,Genotypic Differences in Leaf Water Relations between Brassica juncea and B. napus,1992,A Kumar and J Elston,70,Annals of Botany,1,3-9,Oxford University Press,Various kinds of measurement of tissue water status were made several times during water stress and recovery in Brassica juncea (cv Canadian Black) and B napus (cv Drakkar) Unstressed plants of the two species had similar leaf water potentials (ψw). solute (ψs) and turgor potentials (ψp) Values of relative water content (RWC) and the slope of the linear relationship between ψp and RWC (Δψp/ΔRWC) were greater in B napus than in B junceaStatistical correlations of pooled data for the watered and stressed treatments differentiated the relationships among RWC. ψw and its components in the two species The major statistical difference was that Δψp/ΔRWC was related to RWC in B napus and to ψw and ψs in B juncea A decline in Δψp/RWC with decreasing ψs in B juncea may be a mechanism for maintaining ψp at low soil water potentials through maintenance of more elastic cell walls.,True,1bSxBDwAAAAJ:aMQnNzTHVu4C,64,https://academic.oup.com/aob/article-abstract/70/1/3/129057,11852227410489630321,/scholar?cites=11852227410489630321,,,,0,0,0
1282358,                                          π            0 and                               η meson production in proton-proton collisions at                                                        s …,2018,Shreyasi Acharya and Jaroslav Adam and Dagmar Adamová and Jonatan Adolfsson and Madan M Aggarwal and G Aglieri Rinella and Michelangelo Agnello and Nikita Agrawal and Zubayer Ahammed and Nazeer Ahmad and Sang Un Ahn and Salvatore Aiola and Alexander Akindinov and Mohammad Al-Turany and Sk Noor Alam and Jose Luis Bazo Alba and DSD Albuquerque and Dmitry Aleksandrov and Bruno Alessandro and R Alfaro Molina and Andrea Alici and Anton Alkin and Johan Alme and Torsten Alt and Lucas Altenkamper and Igor Altsybeev and C Alves Garcia Prado and Cristian Andrei and Dimitra Andreou and Harry Arthur Andrews and Anton Andronic and Venelin Anguelov and C Anson and T Antičić and Federico Antinori and Pietro Antonioli and Rafay Anwar and L Aphecetche and Harald Appelshäuser and Silvia Arcelli and Roberta Arnaldi and Oliver Werner Arnold and Ionut Cristian Arsene and Mesut Arslandok and Benjamin Audurier and Andre Augustinus and R Averbeck and Mohd Danish Azmi and Angela Badalà and Yong Wook Baek and Stefano Bagnasco and R Bailhache and Renu Bala and Alberto Baldisseri and Markus Ball and Rama Chandra Baral and Anastasia Maria Barbano and Roberto Barbera and Francesco Barile and Luca Barioglio and GG Barnaföldi and Lee Stuart Barnby and V Barret and Paolo Bartalini and Klaus Barth and Esther Bartsch and Maurizio Basile and Nicole Bastid and Sumit Basu and Guillaume Batigne and Boris Batyunya and Paul Christoph Batzing and Ian Gardner Bearden and Hans Beck and Cristina Bedda and Nirbhay Kumar Behera and Iouri Belikov and Francesca Bellini and H Bello Martinez and Rene Bellwied and Lucina Gabriela Espinoza Beltran and Vladimir Belyaev and Gyula Bencedi and Stefania Beole and Alexandru Bercuci and Yaroslav Berdnikov and Daniel Berenyi and Redmer Alexander Bertens and Dario Berzano and Latchezar Betev and Anju Bhasin and Inayat Rasool Bhat and Ashok Kumar Bhati and Buddhadeb Bhattacharjee and Jihyun Bhom and Antonio Bianchi and Livio Bianchi and Nicola Bianchi and Chiara Bianchin and J Bielčík and J Bielčíková and Ante Bilandzic and Gabor Biro and Rathijit Biswas and Saikat Biswas and Justin Thomas Blair and Dmitry Blau and Christoph Blume and Gianluigi Boca and Friederike Bock and Alexey Bogdanov and Laszlo Boldizsár and Marek Bombara and Germano Bonomi and Matthias Bonora and J Book and Herve Borel and Alexander Borissov and Marcello Borri and Elena Botta and Christian Bourjau and Lars Bratrud and Peter Braun-Munzinger and Marco Bregant and Theo Alexander Broker and Michal Broz and Erik Jens Brucken and Elena Bruna and Giuseppe Eugenio Bruno and Dmitry Budnikov and Henner Buesching and Stefania Bufalino and Paul Buhler and Predrag Buncic and Oliver Busch and Z Buthelezi and Jamila Bashir Butt and Jesse Thomas Buxton and Jan Cabala and Davide Caffarri and H Caines and Alberto Caliva and E Calvo Villar and Paolo Camerini and Aaron Allan Capon and Francesco Carena and Wisla Carena and Francesca Carnesecchi and J Castillo Castellanos and Andrew John Castro,78,The European Physical Journal C,3,1-26,Springer Berlin Heidelberg,An invariant differential cross section measurement of inclusive and meson production at mid-rapidity in pp collisions at TeV was carried out by the ALICE experiment at the LHC. The spectra of and mesons were measured in transverse momentum ranges of and. respectively. Next-to-leading order perturbative QCD calculations using fragmentation functions DSS14 for the and AESSS for the overestimate the cross sections of both neutral mesons. although such calculations agree with the measured ratio within uncertainties. The results were also compared with PYTHIA 8.2 predictions for which the Monash 2013 tune yields the best agreement with the measured neutral meson spectra. The measurements confirm a universal behavior of the ratio seen for NA27. PHENIX and ALICE data for pp collisions from GeV to TeV within experimental uncertainties. A relation between the and …,True,1bSxBDwAAAAJ:XZvG1uL-wj0C,52,https://link.springer.com/article/10.1140/epjc/s10052-018-5612-8,12737519735977672449,/scholar?cites=12737519735977672449,,,https://link.springer.com/article/10.1140/epjc/s10052-018-5612-8,0,0,0
1282359,Elemental status of grazing animals located adjacent to the London Orbital (M25) motorway,1994,NI Ward and JM Savage,146,Science of the Total Environment,,185-189,Elsevier,The elemental (Br. Cd. Cr. Cu. Mn. Ni. Pb. Se. V. and Zn) content of blood and wool or hair from animals (sheep. horses and alpacas) exposed to motor vehicle emissions alongside the London Orbital (M25) motorway is reported. Elemental values were determined by inductively coupled plasma mass spectrometry (ICP-MS) quality control assessment using flameless atomic absorption spectroscopy (for Pb. correlation coefficients of whole blood r = +0.87. and hair r = +0.82). and replicate (n = 10) analysis of the international reference material IAEA A13 Animal Blood. For Pb very good agreement was obtained between ICP-MS values 0.16 ± 0.002 μg/g and non-certified values 0.18 μg/g. Only Pb and Cd showed significantly elevated blood levels in sheep grazing alongside the M25 motorway when compared with control (background) animals. The range of Pb blood values was 0.15–0.51 μg/ml (M25) and 0.04–0.18 …,True,1bSxBDwAAAAJ:nrS8eym_YfUC,52,https://www.sciencedirect.com/science/article/pii/0048969794902364,9869942009657536424,/scholar?cites=9869942009657536424,,,,0,0,0
1282360,Respiratory Motion Models: A Review,2012,JR McClelland and DJ Hawkes and T Schaeffter and AP King,,Medical Image Analysis,,,Elsevier,The problem of respiratory motion has proved a serious obstacle in developing techniques to acquire images or guide interventions in abdominal and thoracic organs. Motion models offer a possible solution to these problems. and as a result the field of respiratory motion modelling has become an active one over the past 15 years. A motion model can be defined as a process that takes some surrogate data as input and produces a motion estimate as output. Many techniques have been proposed in the literature. differing in the data used to form the models. the type of model employed. how this model is computed. the type of surrogate data used as input to the model in order to make motion estimates and what form this output should take. In addition. a wide range of different application areas have been proposed. In this paper we summarise the state of the art in this important field and in the process highlight the …,True,mA_tZpMAAAAJ:isC4tDSrTZIC,354,https://www.sciencedirect.com/science/article/pii/S136184151200134X,3742370048555697103,/scholar?cites=3742370048555697103,,,http://kclpure.kcl.ac.uk/portal/files/6175986/cover_main.pdf,0,0,0
1282361,Design and evaluation of a system for microscope-assisted guided interventions (MAGI),2000,Philip J Edwards and Andrew P King and Calvin R Maurer and Darryl A De Cunha and David J Hawkes and Derek LG Hill and Ronald P Gaston and Michael R Fenlon and A Jusczyzck and Anthony J Strong and Christopher L Chandler and Michael J Gleeson,19,IEEE Transactions on Medical Imaging,11,1082-1093,IEEE,The problem of providing surgical navigation using image overlays on the operative scene can be split into four main tasks-calibration of the optical system; registration of preoperative images to the patient; system and patient tracking. and display using a suitable visualization scheme. To achieve a convincing result in the magnified microscope view a very high alignment accuracy is required. The authors have simulated an entire image overlay system to establish the most significant sources of error and improved each of the stages involved. The microscope calibration process has been automated. The authors have introduced bone-implanted markers for registration and incorporated a locking acrylic dental stent (LADS) for patient tracking. The LADS can also provide a less-invasive registration device with mean target error of 0.7 mm in volunteer experiments. These improvements have significantly increased the …,True,mA_tZpMAAAAJ:u5HHmVD_uO8C,241,https://ieeexplore.ieee.org/abstract/document/896784/,9731819353376408127,/scholar?cites=9731819353376408127,,,,0,0,0
1282362,Thoracic respiratory motion estimation from MRI using a statistical model and a 2-D image navigator,2012,Andrew P King and Christian Buerger and Charalampos Tsoumpas and Paul K Marsden and Tobias Schaeffter,16,Medical image analysis,1,252-264,Elsevier,Respiratory motion models have potential application for estimating and correcting the effects of motion in a wide range of applications. for example in PET-MR imaging. Given that motion cycles caused by breathing are only approximately repeatable. an important quality of such models is their ability to capture and estimate the intra- and inter-cycle variability of the motion. In this paper we propose and describe a technique for free-form nonrigid respiratory motion correction in the thorax. Our model is based on a principal component analysis of the motion states encountered during different breathing patterns. and is formed from motion estimates made from dynamic 3-D MRI data. We apply our model using a data-driven technique based on a 2-D MRI image navigator. Unlike most previously reported work in the literature. our approach is able to capture both intra- and inter-cycle motion variability. In addition. the 2-D …,True,mA_tZpMAAAAJ:4TOpqqG69KYC,138,https://www.sciencedirect.com/science/article/pii/S1361841511001150,12225767839764249454,/scholar?cites=12225767839764249454,,,https://core.ac.uk/download/pdf/29906183.pdf,0,0,0
1282363,Semi-supervised learning for network-based cardiac MR image segmentation,2017,Wenjia Bai and Ozan Oktay and Matthew Sinclair and Hideaki Suzuki and Martin Rajchl and Giacomo Tarroni and Ben Glocker and Andrew King and Paul M Matthews and Daniel Rueckert,,,,253-260,Springer. Cham,Training a fully convolutional network for pixel-wise (or voxel-wise) image segmentation normally requires a large number of training images with corresponding ground truth label maps. However. it is a challenge to obtain such a large training set in the medical imaging domain. where expert annotations are time-consuming and difficult to obtain. In this paper. we propose a semi-supervised learning approach. in which a segmentation network is trained from both labelled and unlabelled data. The network parameters and the segmentations for the unlabelled data are alternately updated. We evaluate the method for short-axis cardiac MR image segmentation and it has demonstrated a high performance. outperforming a baseline supervised method. The mean Dice overlap metric is 0.92 for the left ventricular cavity. 0.85 for the myocardium and 0.89 for the right ventricular cavity. It also outperforms a state-of-the-art …,True,mA_tZpMAAAAJ:p2g8aNsByqUC,137,https://link.springer.com/chapter/10.1007/978-3-319-66185-8_29,3256543443305755383,/scholar?cites=3256543443305755383,,,https://spiral.imperial.ac.uk/bitstream/10044/1/49165/2/bai2017miccai.pdf,0,0,0
1282364,Alignment of sparse freehand 3-D ultrasound with preoperative images of the liver using models of respiratory motion and deformation,2005,Jane M Blackall and Graeme P Penney and Andrew P King and David J Hawkes,24,IEEE transactions on medical imaging,11,1405-1416,IEEE,We present a method for alignment of an interventional plan to optically tracked two-dimensional intraoperative ultrasound (US) images of the liver. Our clinical motivation is to enable the accurate transfer of information from three-dimensional (3D) preoperative imaging modalities [magnetic resonance (MR) or computed tomography (CT)] to intraoperative US to aid needle placement for thermal ablation of liver metastases. An initial rigid registration to intraoperative coordinates is obtained using a set of US images acquired at maximum exhalation. A preprocessing step is applied to both the preoperative images and the US images to produce evidence of corresponding structures. This yields two sets of images representing classification of regions as vessels. The registration then proceeds using these images. The preoperative images and plan are then warped to correspond to a single US slice acquired at an …,True,mA_tZpMAAAAJ:u-x6o8ySG0sC,132,https://ieeexplore.ieee.org/abstract/document/1525177/,16824127829385663920,/scholar?cites=16824127829385663920,,,https://www.researchgate.net/profile/Andrew_King5/publication/3221891_Alignment_of_sparse_freehand_3-D_ultrasound_with_preoperative_images_of_the_liver_using_models_of_respiratory_motion_and_deformation/links/00b7d518f6660e42b7000000/Alignment-of-sparse-freehand-3-D-ultrasound-with-preoperative-images-of-the-liver-using-models-of-respiratory-motion-and-deformation.pdf,0,0,0
1282365,Hierarchical adaptive local affine registration for fast and robust respiratory motion estimation,2011,Christian Buerger and Tobias Schaeffter and Andrew P King,15,Medical image analysis,4,551-564,Elsevier,Non-rigid image registration techniques are commonly used to estimate complex tissue deformations in medical imaging. A range of non-rigid registration algorithms have been proposed. but they typically have high computational complexity. To reduce this complexity. combinations of multiple less complex deformations have been proposed such as hierarchical techniques which successively split the non-rigid registration problem into multiple locally rigid or affine components. However. to date the splitting has been regular and the underlying image content has not been considered in the splitting process. This can lead to errors and artefacts in the resulting motion fields. In this paper. we propose three novel adaptive splitting techniques. an image-based. a similarity-based. and a motion-based technique within a hierarchical framework which attempt to process regions of similar motion and/or image structure in …,True,mA_tZpMAAAAJ:YsMSGLbcyi4C,108,https://www.sciencedirect.com/science/article/pii/S1361841511000314,13884824000229035148,/scholar?cites=13884824000229035148,,,https://kclpure.kcl.ac.uk/portal/files/9586302/main.pdf,0,0,0
1282366,Fast generation of 4D PET-MR data from real dynamic MR acquisitions,2011,C Tsoumpas and C Buerger and AP King and Pieter Mollet and Vincent Keereman and Stefaan Vandenberghe and V Schulz and P Schleyer and T Schaeffter and PK Marsden,56,Physics in Medicine & Biology,20,6597,IOP Publishing,We have implemented and evaluated a framework for simulating simultaneous dynamic PET-MR data using the anatomic and dynamic information from real MR acquisitions. PET radiotracer distribution is simulated by assigning typical FDG uptake values to segmented MR images with manually inserted additional virtual lesions. PET projection data and images are simulated using analytic forward projections (including attenuation and Poisson statistics) implemented within the image reconstruction package STIR. PET image reconstructions are also performed with STIR. The simulation is validated with numerical simulation based on Monte Carlo (GATE) which uses more accurate physical modelling. but has 150× slower computation time compared to the analytic method for ten respiratory positions and is 7000× slower when performing multiple realizations. Results are validated in terms of region of interest mean …,True,mA_tZpMAAAAJ:8k81kl-MbHgC,98,https://iopscience.iop.org/article/10.1088/0031-9155/56/20/005/meta,17627146342057431374,/scholar?cites=17627146342057431374,,,https://www.researchgate.net/profile/Stefaan_Vandenberghe/publication/51661516_Fast_generation_of_4D_PET-MR_data_from_real_dynamic_MR_acquisitions/links/0912f50b75bd02b2f1000000/Fast-generation-of-4D-PET-MR-data-from-real-dynamic-MR-acquisitions.pdf,0,0,0
1282367,Simultaneous PET–MR acquisition and MR-derived motion fields for correction of non-rigid motion in PET,2010,Charalampos Tsoumpas and Jane E Mackewn and Philip Halsted and Andrew P King and Christian Buerger and John J Totman and Tobias Schaeffter and Paul K Marsden,24,Annals of nuclear medicine,10,745-750,Springer Japan,Positron emission tomography (PET) provides an accurate measurement of radiotracer concentration in vivo. but performance can be limited by subject motion which degrades spatial resolution and quantitative accuracy. This effect may become a limiting factor for PET studies in the body as PET scanner technology improves. In this work. we propose a new approach to address this problem by employing motion information from images measured simultaneously using a magnetic resonance (MR) scanner.The approach is demonstrated using an MR-compatible PET scanner and PET–MR acquisition with a purpose-designed phantom capable of non-rigid deformations. Measured. simultaneously acquired MR data were used to correct for motion in PET. and results were compared with those obtained using motion information from PET …,True,mA_tZpMAAAAJ:kNdYIx-mwKoC,86,https://link.springer.com/article/10.1007/s12149-010-0418-2,10209664248516517230,/scholar?cites=10209664248516517230,,,,0,0,0
1282368,A subject-specific technique for respiratory motion correction in image-guided cardiac catheterisation procedures,2009,Andrew P King and Redha Boubertakh and Kawal S Rhode and YingLiang Ma and Phani Chinchapatnam and Gang Gao and T Tangcharoen and Matthew Ginks and Michael Cooklin and Jaswinder S Gill and David J Hawkes and RS Razavi and Tobias Schaeffter,13,Medical image analysis,3,419-431,Elsevier,We describe a system for respiratory motion correction of MRI-derived roadmaps for use in X-ray guided cardiac catheterisation procedures. The technique uses a subject-specific affine motion model that is quickly constructed from a short pre-procedure MRI scan. We test a dynamic MRI sequence that acquires a small number of high resolution slices. rather than a single low resolution volume. Additionally. we use prior knowledge of the nature of cardiac respiratory motion by constraining the model to use only the dominant modes of motion. During the procedure the motion of the diaphragm is tracked in X-ray fluoroscopy images. allowing the roadmap to be updated using the motion model. X-ray image acquisition is cardiac gated. Validation is performed on four volunteer datasets and three patient datasets. The accuracy of the model in 3D was within 5 mm in 97.6% of volunteer validations. For the patients. 2D …,True,mA_tZpMAAAAJ:UeHWp8X0CEIC,85,https://www.sciencedirect.com/science/article/pii/S1361841509000048,18149971461568818215,/scholar?cites=18149971461568818215,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.726.8628&rep=rep1&type=pdf,0,0,0
1282369,A system for microscope-assisted guided interventions,1999,AP King and PJ Edwards and CR Maurer Jr and DA De Cunha and DJ Hawkes and DLG Hill and RP Gaston and MR Fenlon and AJ Strong and CL Chandler and A Richards and MJ Gleeson,72,Stereotactic and functional neurosurgery,2-4,107-111,Karger Publishers,We present a system for surgical navigation using stereo overlays in the operating microscope aligned to the operative scene. This augmented reality system provides 3D information about nearby structures and offers a significant advancement over pointer-based guidance. which provides only the location of one point and requires the surgeon to look away from the operative scene. With a previous version of this system. we demonstrated feasibility. but it became clear that to achieve convincing guidance through the magnified microscope view. a very high alignment accuracy was required. We have made progress with several aspects of the system. including automated calibration. error simulation. bone-implanted fiducials and a dental attachment for tracking. We have performed experiments to establish the visual display parameters required to perceive overlaid structures beneath the operative surface. Easy …,True,mA_tZpMAAAAJ:2osOgNQ5qMEC,73,https://www.karger.com/Article/Abstract/29708,5011317426654000033,/scholar?cites=5011317426654000033,,,,0,0,0
1282370,Nonrigid motion modeling of the liver from 3-D undersampled self-gated golden-radial phase encoded MRI,2012,Christian Buerger and Rachel E Clough and Andrew P King and Tobias Schaeffter and Claudia Prieto,31,IEEE transactions on medical imaging,3,805-815,IEEE,Magnetic resonance imaging (MRI) has been commonly used for guiding and planning image guided interventions since it provides excellent soft tissue visualization of anatomy and allows motion modeling to predict the position of target tissues during the procedure. However. MRI-based motion modeling remains challenging due to the difficulty of acquiring multiple motion-free 3-D respiratory phases with adequate contrast and spatial resolution. Here. we propose a novel retrospective respiratory gating scheme from a 3-D undersampled high-resolution MRI acquisition combined with fast and robust image registrations to model the nonrigid deformation of the liver. The acquisition takes advantage of the recently introduced golden-radial phase encoding (G-RPE) trajectory. G-RPE is self-gated. i.e.. the respiratory signal can be derived from the acquired data itself. and allows retrospective reconstructions of multiple …,True,mA_tZpMAAAAJ:mVmsd5A6BfQC,70,https://ieeexplore.ieee.org/abstract/document/6134675/,3383133386697867023,/scholar?cites=3383133386697867023,,,,0,0,0
1282371,Probabilistic relations between words: Evidence from reduction in lexical production,2001,Daniel Jurafsky and Alan Bell and Michelle Gregory and William D Raymond,45,Typological studies in language,,229-254,,The ideas of frequency and predictability have played a fundamental role in models of human language processing for well over a hundred years (Schuchardt 1885; Jespersen 1923; Zipf 1929; Martinet 1960; Oldﬁeld and Wingﬁeld 1965; Fidelholz 1975; Jescheniak and Levelt 1994; Bybee 2000). While most psycholinguistic mod—els have thus long included word frequency as a component. recent models have proposed more generally that probabilistic information about words. phrases. and other linguistic structure is represented in the minds of language users and plays a role in language comprehension (Bybee and Scheibman 1999; MacDonald 1993; McRae et al. 1998; Narayanan and J urafsky 1998; Trueswell and Tanenhaus 1994) production (Gregory et al. 1999; Roland and Jurafsky to appear). and learning (Brent and Cartwright 1996; Landauer and Dumais 1997; Saffran et al. 1996; Seidenberg and MacDonald 1999). In recent papers (Bell et al. 1999; Gregory et al. 1999; Jurafsky et al. 1998). we have been studying the role of predictability and frequency in lexical production. Our goal is to understand the many factors that affect production variability as reﬂected in reduction processes such as vowel reduction. durational shortening. or ﬁnal segmental deletion of words in spontaneous speech. One proposal that has resulted from this work is the Probabilistic Reduction Hypothesis: word forms are reduced when they have a higher probability. The probability of a word is conditioned on many aspects of its context. including neighboring words. syntactic and lexical structure. semantic expectations. and discourse factors. This proposal thus …,True,71Qr2DsAAAAJ:TFP_iSt0sucC,769,http://books.google.com/books?hl=en&lr=&id=Tt-w2gAYFRAC&oi=fnd&pg=PA229&dq=info:l9mk0TfYqtYJ:scholar.google.com&ots=V0LIbxkA3Q&sig=EzwrX2RGYvDgu3zqMWO__ARuTIY,15468413604409432471,/scholar?cites=15468413604409432471,,,https://www.researchgate.net/profile/William_Raymond2/publication/2612680_Probabilistic_Relations_between_Words_Evidence_from_Reduction_in_Lexical_Production/links/0f3175302622854dc8000000/Probabilistic-Relations-between-Words-Evidence-from-Reduction-in-Lexical-Production.pdf,0,0,0
1282372,Predictability effects on durations of content and function words in conversational English,2009,Alan Bell and Jason M Brenier and Michelle Gregory and Cynthia Girand and Dan Jurafsky,60,Journal of Memory and Language,1,92-111,Academic Press,In a regression study of conversational speech. we show that frequency. contextual predictability. and repetition have separate contributions to word duration. despite their substantial correlations. We also found that content- and function-word durations are affected differently by their frequency and predictability. Content words are shorter when more frequent. and shorter when repeated. while function words are not so affected. Function words have shorter pronunciations. after controlling for frequency and predictability. While both content and function words are strongly affected by predictability from the word following them. sensitivity to predictability from the preceding word is largely limited to very frequent function words. The results support the view that content and function words are accessed differently in production. We suggest a lexical-access-based model of our results. in which frequency or repetition leads …,True,71Qr2DsAAAAJ:eQOLeE2rZwMC,629,https://www.sciencedirect.com/science/article/pii/S0749596X08000600,4062792329431301485,/scholar?cites=4062792329431301485,,,https://www.hlp.rochester.edu/resources/workshop_materials/EVELIN12/BellETAL09.pdf,0,0,0
1282373,Effects of disfluencies. predictability. and utterance position on word form variation in English conversation,2003,Alan Bell and Daniel Jurafsky and Eric Fosler-Lussier and Cynthia Girand and Michelle Gregory and Daniel Gildea,113,The Journal of the Acoustical Society of America,2,1001-1024,Acoustical Society of America,Function words. especially frequently occurring ones such as (the. that. and. and of ). vary widely in pronunciation. Understanding this variation is essential both for cognitive modeling of lexical production and for computer speech recognition and synthesis. This study investigates which factors affect the forms of function words. especially whether they have a fuller pronunciation (e.g.. ði. ðæt. ænd. ʌv) or a more reduced or lenited pronunciation (e.g.. ðə. ðīt. n. ə). It is based on over 8000 occurrences of the ten most frequent English function words in a 4-h sample from conversations from the Switchboard corpus. Ordinary linear and logistic regression models were used to examine variation in the length of the words. in the form of their vowel (basic. full. or reduced). and whether final obstruents were present or not. For all these measures. after controlling for segmental context. rate of speech. and other important …,True,71Qr2DsAAAAJ:mB3voiENLucC,471,https://asa.scitation.org/doi/abs/10.1121/1.1534836,13003927894581836817,/scholar?cites=13003927894581836817,,,http://web.stanford.edu/~jurafsky/jasa03.pdf,0,0,0
1282374,Topicalization and left-dislocation: A functional opposition revisited,2001,Michelle L Gregory and Laura A Michaelis,33,Journal of pragmatics,11,1665-1706,North-Holland,In this case study. we use conversational data from the Switchboard corpus to investigate the functional opposition between two pragmatically specialized constructions of English: Topicalization and Left-Dislocation. Specifically. we use distribution trends in the Switchboard corpus to revise several conclusions reached by Prince (1981a.b. 1997) concerning the function of Left-Dislocation. While Prince holds that Left-Dislocation has no unitary functionn. we argue that the distinct uses of the construction identified by Prince can be subsumed under the general function of topic promotion. While Prince holds that Topicalization is a more pragmatically specialized construction than Left-Dislocation. we argue that Left-Dislocation has equally restrictive and distinct use conditions. which reflect its status as a topic-promoting device. We conclude that computational corpus methods provide an important check on the validity of …,True,71Qr2DsAAAAJ:ZeXyd9-uunAC,232,https://www.sciencedirect.com/science/article/pii/S0378216600000631,12350224616033990263,/scholar?cites=12350224616033990263,,,https://spot.colorado.edu/~michaeli/documents/Gregory_Michaelis_Top_LD.pdf,0,0,0
1282375,The effects of collocational strength and contextual predictability in lexical production,1999,Michelle L Gregory and William D Raymond and Alan Bell and Eric Fosler-Lussier and Daniel Jurafsky,35,Chicago Linguistic Society,,151-166,,Word frequency and word predictability have both been proposed in the literature as explanations for word shortening or reduction. Traditionally. these two explanations have been modeled separately. Frequency models focus on the fact that words with high use frequency are shortened compared to low frequency words. whether in the lexicon (Zipf 1929) or during phonetic production (Fidelholtz 1975. Bybee 1999a). Predictability models focus on the fact that words that are highly predictable from the context are shortened during production (Jespersen 1922. Bolinger 1981. Fowler & Housum 1987). We propose that these “predictability” and “frequency” affects are actually variants of the same basic factor: the informativeness of a word as measured by its probability. In this account. words which are highly predictable or very frequent are highly probable. and hence have a lower information value. 2 A consequence of considering frequency and predictability as probabilities is that they can be unified into a probabilistic model of processing together with other types of probabilistic knowledge. ultimately providing a more complete explanation of language use. Probabilistic models of human language comprehension claim that probabilistic information about words. phrases. and other linguistic structure is represented in the minds of language users and plays a role in language comprehension (Jurafsky 1996. Narayanan & Jurafsky 1998). This paper extends this probabilistic hypothesis to language production. suggesting that speakers use their knowledge of the probability of a word or combinations of words in sentence production. In particular. we …,True,71Qr2DsAAAAJ:bEWYMUwI8FkC,228,https://www.researchgate.net/profile/William_Raymond2/publication/2595692_The_Effects_of_Collocational_Strength_and_Contextual_Predictability_in_Lexical_Production/links/0f3175302622875432000000/The-Effects-of-Collocational-Strength-and-Contextual-Predictability-in-Lexical-Production.pdf,15434500140577357169,/scholar?cites=15434500140577357169,,,https://www.researchgate.net/profile/William_Raymond2/publication/2595692_The_Effects_of_Collocational_Strength_and_Contextual_Predictability_in_Lexical_Production/links/0f3175302622875432000000/The-Effects-of-Collocational-Strength-and-Contextual-Predictability-in-Lexical-Production.pdf,0,0,0
1282376,Pliability rules,2002,Abraham Bell and Gideon Parchomovsky,101,,1,1-79,The Michigan Law Review Association,In 1543. the Polish astronomer. Nicolas Copernicus. determined the heliocentric design of the solar system. 1 Copernicus was motivated in large part by the conviction that Claudius Ptolemy's geocentric astronomical model. which dominated scientific thought at that time. was too incoherent. complex. and convoluted to be true. 2 Hence. Copernicus made a point of making his model coherent. simple. and elegant. Nearly three and a half centuries later. at the height of the impressionist movement. the French painter Claude Monet set out to depict the Ruen Cathedral in a series of twenty paintings. 3 each pre-senting the cathedral in a different light. Monet's goal was to demonstrate how his object of study may be perceived by observers differently depending on the circumstances of the observation. In the spirit of these two projects. in 1972. Guido Calabresi and Douglas Melamed resolved to craft a comprehensive. yet …,True,71Qr2DsAAAAJ:ns9cj8rnVeAC,192,https://www.jstor.org/stable/1290417,16962142434591301017,/scholar?cites=16962142434591301017,,,https://scholarship.law.upenn.edu/cgi/viewcontent.cgi?article=2341&context=faculty_scholarship,0,0,0
1282377,User-directed sentiment analysis: Visualizing the affective content of documents,2006,Michelle Gregory and Nancy Chinchor and Paul Whitney and Richard Carter and Elizabeth Hetzler and Alan Turner,,,,23-30,,Recent advances in text analysis have led to finer-grained semantic analysis. including automatic sentiment analysis—the task of measuring documents. or chunks of text. based on emotive categories. such as positive or negative. However. considerably less progress has been made on efficient ways of exploring these measurements. This paper discusses approaches for visualizing the affective content of documents and describes an interactive capability for exploring emotion in a large document collection.,True,71Qr2DsAAAAJ:LkGwnXOMwfcC,98,https://www.aclweb.org/anthology/W06-0304.pdf,4929703088206303117,/scholar?cites=4929703088206303117,,,https://www.aclweb.org/anthology/W06-0304.pdf,0,0,0
1282378,Using conditional random fields to predict pitch accents in conversational speech,2004,Michelle Gregory and Yasemin Altun,,,,677-683,,The detection of prosodic characteristics is an important aspect of both speech synthesis and speech recognition. Correct placement of pitch accents aids in more natural sounding speech. while automatic detection of accents can contribute to better wordlevel recognition and better textual understanding. In this paper we investigate probabilistic. contextual. and phonological factors that influence pitch accent placement in natural. conversational speech in a sequence labeling setting. We introduce Conditional Random Fields (CRFs) to pitch accent prediction task in order to incorporate these factors efficiently in a sequence model. We demonstrate the usefulness and the incremental effect of these factors in a sequence model by performing experiments on hand labeled data from the Switchboard Corpus. Our model outperforms the baseline and previous models of pitch accent prediction on the Switchboard Corpus.,True,71Qr2DsAAAAJ:hFOr9nPyWt4C,78,https://www.aclweb.org/anthology/P04-1086.pdf,12853292614466232971,/scholar?cites=12853292614466232971,,,https://www.aclweb.org/anthology/P04-1086.pdf,0,0,0
1282379,PNNL: A supervised maximum entropy approach to word sense disambiguation,2007,Stephen Tratz and Antonio Sanfilippo and Michelle Gregory and Alan Chappell and Christian Posse and Paul Whitney,,,,264-267,,In this paper. we described the PNNL Word Sense Disambiguation system as applied to the English all-word task in SemEval 2007. We use a supervised learning approach. employing a large number of features and using Information Gain for dimension reduction. The rich feature set combined with a Maximum Entropy classifier produces results that are significantly better than baseline and are the highest F-score for the fined-grained English allwords subtask of SemEval.,True,71Qr2DsAAAAJ:UeHWp8X0CEIC,57,https://www.aclweb.org/anthology/S07-1057.pdf,1662416594804968493,/scholar?cites=1662416594804968493,,,https://www.aclweb.org/anthology/S07-1057.pdf,0,0,0
1282380,Describing story evolution from dynamic information streams,2009,Stuart Rose and Scott Butner and Wendy Cowley and Michelle Gregory and Julia Walker,,,,99-106,IEEE,Sources of streaming information. such as news syndicates. publish information continuously. Information portals and news aggregators list the latest information from around the world enabling information consumers to easily identify events in the past 24 hours. The volume and velocity of these streams causes information from prior days to quickly vanish despite its utility in providing an informative context for interpreting new information. Few capabilities exist to support an individual attempting to identify or understand trends and changes from streaming information over time. The burden of retaining prior information and integrating with the new is left to the skills. determination. and discipline of each individual. In this paper we present a visual analytics system for linking essential content from information streams over time into dynamic stories that develop and change over multiple days. We describe particular …,True,71Qr2DsAAAAJ:_Qo2XoVZTnwC,50,https://ieeexplore.ieee.org/abstract/document/5333437/,13846811923061180115,/scholar?cites=13846811923061180115,,,https://www.researchgate.net/profile/Michelle_Gregory/publication/224080781_Describing_story_evolution_from_dynamic_information_streams/links/54e63e640cf277664ff4c9c9/Describing-story-evolution-from-dynamic-information-streams.pdf,0,0,0
1282381,Prosodic correlates of directly reported speech: Evidence from conversational speech,2001,Wouter Jansen and Michelle L Gregory and Jason M Brenier,,,,,,This paper investigates the prosodic characteristics of reported speech in the Switchboard corpus. We find that directly reported speech is signalled by a greater overall pitch range than the surrounding narrative material and is typically preceded by intonational phrase boundaries. By contrast. prosody does not seem to distinguish indirectly reported speech from ordinary narrative speech. The implications of these findings for ASR are discussed.,True,71Qr2DsAAAAJ:ULOm3_A8WrAC,45,https://www.isca-speech.org/archive_open/archive_papers/prosody_2001/prsr_014.pdf,7988824385443873688,/scholar?cites=7988824385443873688,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.6325&rep=rep1&type=pdf,0,0,0
1282382,Deformable convolutional networks,2017,Jifeng Dai and Haozhi Qi and Yuwen Xiong and Yi Li and Guodong Zhang and Han Hu and Yichen Wei,,,,764-773,,Convolutional neural networks (CNNs) are inherently limited to model geometric transformations due to the fixed geometric structures in its building modules. In this work. we introduce two new modules to enhance the transformation modeling capacity of CNNs. namely. deformable convolution and deformable RoI pooling. Both are based on the idea of augmenting the spatial sampling locations in the modules with additional offsets and learning the offsets from target tasks. without additional supervision. The new modules can readily replace their plain counterparts in existing CNNs and can be easily trained end-to-end by standard back-propagation. giving rise to deformable convolutional networks. Extensive experiments validate the effectiveness of our approach on sophisticated vision tasks of object detection and semantic segmentation. The code would be released.,True,Jkss014AAAAJ:Zph67rFs4hoC,1702,http://openaccess.thecvf.com/content_iccv_2017/html/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.html,6058204364274666350,/scholar?cites=6058204364274666350,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.pdf,0,0,0
1282383,Relation networks for object detection,2018,Han Hu and Jiayuan Gu and Zheng Zhang and Jifeng Dai and Yichen Wei,,,,3588-3597,,Although it is well believed for years that modeling relations between objects would help object recognition. there has not been evidence that the idea is working in the deep learning era. All state-of-the-art object detection systems still rely on recognizing object instances extbf {individually}. without exploiting their relations during learning. This work proposes an object relation module. It processes a set of objects extbf {simultaneously} through interaction between their appearance feature and geometry. thus allowing modeling of their relations. It is lightweight and in-place. It does not require additional supervision and is easy to embed in existing networks. It is shown effective on improving object recognition and duplicate removal steps in the modern object detection pipeline. It verifies the efficacy of modeling object relations in CNN based detection. It gives rise to the extbf {first fully end-to-end object detector}.,True,Jkss014AAAAJ:YOwf2qJgpHMC,507,http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Relation_Networks_for_CVPR_2018_paper.html,6312471696354344603,/scholar?cites=6312471696354344603,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Relation_Networks_for_CVPR_2018_paper.pdf,0,0,0
1282384,Deformable convnets v2: More deformable. better results,2019,Xizhou Zhu and Han Hu and Stephen Lin and Jifeng Dai,,,,9308-9316,,The superior performance of Deformable Convolutional Networks arises from its ability to adapt to the geometric variations of objects. Through an examination of its adaptive behavior. we observe that while the spatial support for its neural features conforms more closely than regular ConvNets to object structure. this support may nevertheless extend well beyond the region of interest. causing features to be influenced by irrelevant image content. To address this problem. we present a reformulation of Deformable ConvNets that improves its ability to focus on pertinent image regions. through increased modeling power and stronger training. The modeling power is enhanced through a more comprehensive integration of deformable convolution within the network. and by introducing a modulation mechanism that expands the scope of deformation modeling. To effectively harness this enriched modeling capability. we guide network training via a proposed feature mimicking scheme that helps the network to learn features that reflect the object focus and classification power of R-CNN features. With the proposed contributions. this new version of Deformable ConvNets yields significant performance gains over the original model and produces leading results on the COCO benchmark for object detection and instance segmentation.,True,Jkss014AAAAJ:4TOpqqG69KYC,414,http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Deformable_ConvNets_V2_More_Deformable_Better_Results_CVPR_2019_paper.html,7168214980579319728,/scholar?cites=7168214980579319728,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Deformable_ConvNets_V2_More_Deformable_Better_Results_CVPR_2019_paper.pdf,0,0,0
1282385,Gcnet: Non-local networks meet squeeze-excitation networks and beyond,2019,Yue Cao and Jiarui Xu and Stephen Lin and Fangyun Wei and Han Hu,,,,0-0,,The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies. via aggregating query-specific global context to each query position. However. through a rigorous empirical analysis. we have found that the global contexts modeled by non-local network are almost the same for different query positions within an image. In this paper. we take advantage of this finding to create a simplified network based on a query-independent formulation. which maintains the accuracy of NLNet but with significantly less computation. We further observe that this simplified design shares similar structure with Squeeze-Excitation Network (SENet). Hence we unify them into a three-step general framework for global context modeling. Within the general framework. we design a better instantiation. called the global context (GC) block. which is lightweight and can effectively model the global context. The lightweight property allows us to apply it for multiple layers in a backbone network to construct a global context network (GCNet). which generally outperforms both simplified NLNet and SENet on major benchmarks for various recognition tasks.,True,Jkss014AAAAJ:Wp0gIr-vW9MC,282,http://openaccess.thecvf.com/content_ICCVW_2019/html/NeurArch/Cao_GCNet_Non-Local_Networks_Meet_Squeeze-Excitation_Networks_and_Beyond_ICCVW_2019_paper.html,7155667207045161378,/scholar?cites=7155667207045161378,,,http://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Cao_GCNet_Non-Local_Networks_Meet_Squeeze-Excitation_Networks_and_Beyond_ICCVW_2019_paper.pdf,0,0,0
1282386,Smooth representation clustering,2014,Han Hu and Zhouchen Lin and Jianjiang Feng and Jie Zhou,,,,3834-3841,,Subspace clustering is a powerful technology for clustering data according to the underlying subspaces. Representation based methods are the most popular subspace clustering approach in recent years. In this paper. we analyze the grouping effect of representation based methods in depth. In particular. we introduce the enforced grouping effect conditions. which greatly facilitate the analysis of grouping effect. We further find that grouping effect is important for subspace clustering. which should be explicitly enforced in the data self-representation model. rather than implicitly implied by the model as in some prior work. Based on our analysis. we propose the SMooth Representation (SMR) model. We also propose a new affinity measure based on the grouping effect. which proves to be much more effective than the commonly used one. As a result. our SMR significantly outperforms the state-of-the-art ones on benchmark datasets.,True,Jkss014AAAAJ:d1gkVwhDpl0C,212,http://openaccess.thecvf.com/content_cvpr_2014/html/Hu_Smooth_Representation_Clustering_2014_CVPR_paper.html,6025940988018926929,/scholar?cites=6025940988018926929,,,http://openaccess.thecvf.com/content_cvpr_2014/papers/Hu_Smooth_Representation_Clustering_2014_CVPR_paper.pdf,0,0,0
1282387,Reppoints: Point set representation for object detection,2019,Ze Yang and Shaohui Liu and Han Hu and Liwei Wang and Stephen Lin,,,,9657-9666,,Modern object detectors rely heavily on rectangular bounding boxes. such as anchors. proposals and the final predictions. to represent objects at various recognition stages. The bounding box is convenient to use but provides only a coarse localization of objects and leads to a correspondingly coarse extraction of object features. In this paper. we present RepPoints (representative points). a new finer representation of objects as a set of sample points useful for both localization and recognition. Given ground truth localization and recognition targets for training. RepPoints learn to automatically arrange themselves in a manner that bounds the spatial extent of an object and indicates semantically significant local areas. They furthermore do not require the use of anchors to sample a space of bounding boxes. We show that an anchor-free object detector based on RepPoints can be as effective as the state-of-the-art anchor-based detection methods. with 46.5 AP and 67.4 AP_ 50 on the COCO test-dev detection benchmark. using ResNet-101 model. Code is available at https://github. com/microsoft/RepPoints\color cyan https://github. com/microsoft/RepPoints.,True,Jkss014AAAAJ:4DMP91E08xMC,152,http://openaccess.thecvf.com/content_ICCV_2019/html/Yang_RepPoints_Point_Set_Representation_for_Object_Detection_ICCV_2019_paper.html,6731983785945015219,/scholar?cites=6731983785945015219,,,https://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_RepPoints_Point_Set_Representation_for_Object_Detection_ICCV_2019_paper.pdf,0,0,0
1282388,Wordsup: Exploiting word annotations for character based text detection,2017,Han Hu and Chengquan Zhang and Yuxuan Luo and Yuzhuo Wang and Junyu Han and Errui Ding,,,,4940-4949,,Imagery texts are usually organized as a hierarchy of several visual elements. ie characters. words. text lines and text blocks. Among these elements. character is the most basic one for various languages such as Western. Chinese. Japanese. mathematical expression and etc. It is natural and convenient to construct a common text detection engine based on character detectors. However. training character detectors requires a vast of location annotated characters. which are expensive to obtain. Actually. the existing real text datasets are mostly annotated in word or line level. To remedy this dilemma. we propose a weakly supervised framework that can utilize word annotations. either in tight quadrangles or the more loose bounding boxes. for character detector training. When applied in scene text detection. we are thus able to train a robust character detector by exploiting word annotations in the rich large-scale real scene text datasets. eg ICDAR15 [??] and COCO-text [??]. The character detector acts as a key role in the pipeline of our text detection engine. It achieves the state-of-the-art performance on several challenging scene text detection benchmarks. We also demonstrate the flexibility of our pipeline by various scenarios. including deformed text detection and math expression recognition.,True,Jkss014AAAAJ:ULOm3_A8WrAC,144,http://openaccess.thecvf.com/content_iccv_2017/html/Hu_WordSup_Exploiting_Word_ICCV_2017_paper.html,15930937644105203439,/scholar?cites=15930937644105203439,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Hu_WordSup_Exploiting_Word_ICCV_2017_paper.pdf,0,0,0
1282389,Local Relation Networks for Image Recognition,2019,Han Hu and Zheng Zhang and Zhenda Xie and Stephen Lin,,arXiv preprint arXiv:1904.11491,,,,The convolution layer has been the dominant feature extractor in computer vision for years. However. the spatial aggregation in convolution is basically a pattern matching process that applies fixed filters which are inefficient at modeling visual elements with varying spatial distributions. This paper presents a new image feature extractor. called the local relation layer. that adaptively determines aggregation weights based on the compositional relationship of local pixel pairs. With this relational approach. it can composite visual elements into higher-level entities in a more efficient manner that benefits semantic inference. A network built with local relation layers. called the Local Relation Network (LR-Net). is found to provide greater modeling capacity than its counterpart built with regular convolution on large-scale recognition tasks such as ImageNet classification.,True,Jkss014AAAAJ:9ZlFYXVOiuMC,70,http://openaccess.thecvf.com/content_ICCV_2019/html/Hu_Local_Relation_Networks_for_Image_Recognition_ICCV_2019_paper.html,12553284540982363625,/scholar?cites=12553284540982363625,,,http://openaccess.thecvf.com/content_ICCV_2019/papers/Hu_Local_Relation_Networks_for_Image_Recognition_ICCV_2019_paper.pdf,0,0,0
1282390,Spatial-temporal relation networks for multi-object tracking,2019,Jiarui Xu and Yue Cao and Zheng Zhang and Han Hu,,,,3988-3998,,Recent progress in multiple object tracking (MOT) has shown that a robust similarity score is a key to the success of trackers. A good similarity score is expected to reflect multiple cues. eg appearance. location. and topology. over a long period of time. However. these cues are heterogeneous. making them hard to be combined in a unified network. As a result. existing methods usually encode them in separate networks or require a complex training approach. In this paper. we present a unified framework for similarity measurement based on spatial-temporal relation network which could simultaneously encode various cues and perform reasoning across both spatial and temporal domains. We also study the feature representation of a tracklet-object pair in depth. showing a proper design of the pair features can well empower the trackers. The resulting approach is named spatial-temporal relation networks (STRN). It runs in a feed-forward way and can be trained in an end-to-end manner. The state-of-the-art accuracy was achieved on all of the MOT15~ 17 benchmarks using public detection and online settings.,True,Jkss014AAAAJ:mVmsd5A6BfQC,67,http://openaccess.thecvf.com/content_ICCV_2019/html/Xu_Spatial-Temporal_Relation_Networks_for_Multi-Object_Tracking_ICCV_2019_paper.html,14212868233462632427,/scholar?cites=14212868233462632427,,,http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Spatial-Temporal_Relation_Networks_for_Multi-Object_Tracking_ICCV_2019_paper.pdf,0,0,0
1282391,Pose from flow and flow from pose,2013,Katerina Fragkiadaki and Han Hu and Jianbo Shi,,,,2059-2066,,Human pose detectors. although successful in localising faces and torsos of people. often fail with lower arms. Motion estimation is often inaccurate under fast movements of body parts. We build a segmentation-detection algorithm that mediates the information between body parts recognition. and multi-frame motion grouping to improve both pose detection and tracking. Motion of body parts. though not accurate. is often sufficient to segment them from their backgrounds. Such segmentations are crucial for extracting hard to detect body parts out of their interior body clutter. By matching these segments to exemplars we obtain pose labeled body segments. The pose labeled segments and corresponding articulated joints are used to improve the motion flow fields by proposing kinematically constrained affine displacements on body parts. The pose-based articulated motion model is shown to handle large limb rotations and displacements. Our algorithm can detect people under rare poses. frequently missed by pose detectors. showing the benefits of jointly reasoning about pose. segmentation and motion in videos.,True,Jkss014AAAAJ:2osOgNQ5qMEC,61,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Fragkiadaki_Pose_from_Flow_2013_CVPR_paper.html,485357168785805698,/scholar?cites=485357168785805698,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Fragkiadaki_Pose_from_Flow_2013_CVPR_paper.pdf,0,0,0
1282392,Learning region features for object detection,2018,Jiayuan Gu and Han Hu and Liwei Wang and Yichen Wei and Jifeng Dai,,,,381-395,,While most steps in the modern object detection methods are learnable. the region feature extraction step remains largely hand-crafted. featured by RoI pooling methods. This work proposes a general viewpoint that unifies existing region feature extraction methods and a novel method that is end-to-end learnable. The proposed method removes most heuristic choices and outperforms its RoI pooling counterparts. It moves further towards emph {fully learnable object detection}.,True,Jkss014AAAAJ:_kc_bZDykSQC,37,http://openaccess.thecvf.com/content_ECCV_2018/html/Jiayuan_Gu_Learning_Region_Features_ECCV_2018_paper.html,3221133347741042066,/scholar?cites=3221133347741042066,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Jiayuan_Gu_Learning_Region_Features_ECCV_2018_paper.pdf,0,0,0
1282393,Radiographic imaging with cosmic-ray muons,2003,Konstantin N Borozdin and Gary E Hogan and Christopher Morris and William C Priedhorsky and Alexander Saunders and Larry J Schultz and Margaret E Teasdale,422,Nature,6929,277-277,Nature Publishing Group,Despite its enormous success. X-ray radiography 1 has its limitations: an inability to penetrate dense objects. the need for multiple projections to resolve three-dimensional structure. and health risks from radiation. Here we show that natural background muons. which are generated by cosmic rays and are highly penetrating. can be used for radiographic imaging of medium-to-large. dense objects. without these limitations and with a reasonably short exposure time. This inexpensive and harmless technique may offer a useful alternative for detecting dense materials—for example. a block of uranium concealed inside a truck full of sheep.,True,SO0undgAAAAJ:3s1wT3WcHBgC,348,https://www.nature.com/articles/422277a,8771801234853401741,/scholar?cites=8771801234853401741,,,https://www.nature.com/articles/422277a,0,0,0
1282394,Image reconstruction and material Z discrimination via cosmic ray muon radiography,2004,Larry Joe Schultz and Konstantin N Borozdin and John J Gomez and Gary E Hogan and JA McGill and CL Morris and WC Priedhorsky and A Saunders and ME Teasdale,519,"Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",3,687-694,North-Holland,Highly penetrating cosmic ray muons shower the Earth at the rate of 10.000 m−2 min−1 at sea level. In our previous work (Nature 422 (2003) 277; Rev. Sci. Instr. 74(10) (2003) 4294; Cosmic Ray Muon Radiography for Contraband Detection. in: Proceedings of AccApp’03. San Diego. CA. June 2003). we presented a novel muon radiography technique which exploits the multiple Coulomb scattering of these particles for nondestructive inspection without the use of artificial radiation. In this paper. we describe the concept of and theory behind cosmic ray muon radiography. We discuss the information carried by the scattered muons and our approaches for exploiting that information with image reconstruction algorithms. We discuss preliminary and advanced reconstruction algorithms. which take advantage of the scattering angle. scattering location. and locations where strongly scattered muons cross paths. Our …,True,SO0undgAAAAJ:MXK_kJrjxJIC,226,https://www.sciencedirect.com/science/article/pii/S0168900203028808,2561401362799658636,/scholar?cites=2561401362799658636,,,http://www.publichenko.ru/i/file/Image%20reconstruction%20and%20material%20Z%20discrimination.pdf,0,0,0
1282395,Statistical reconstruction for cosmic ray muon tomography,2007,Larry J Schultz and Gary S Blanpied and Konstantin N Borozdin and Andrew M Fraser and Nicolas W Hengartner and Alexei V Klimenko and Christopher L Morris and Chris Orum and Michael J Sossong,16,IEEE transactions on Image Processing,8,1985-1993,IEEE,Highly penetrating cosmic ray muons constantly shower the earth at a rate of about 1 muon per cm 2  per minute. We have developed a technique which exploits the multiple Coulomb scattering of these particles to perform nondestructive inspection without the use of artificial radiation. In prior work . we have described heuristic methods for processing muon data to create reconstructed images. In this paper. we present a maximum likelihood/expectation maximization tomographic reconstruction algorithm designed for the technique. This algorithm borrows much from techniques used in medical imaging. particularly emission tomography. but the statistics of muon scattering dictates differences. We describe the statistical model for multiple scattering. derive the reconstruction algorithm. and present simulated examples. We also propose methods to improve the robustness of the algorithm to experimental errors and …,True,SO0undgAAAAJ:eJXPG6dFmWUC,164,https://ieeexplore.ieee.org/abstract/document/4271541/,12818897898316825346,/scholar?cites=12818897898316825346,,,https://www.hep.phy.cam.ac.uk/~hommels/CosmicConcrete_dir/MuonPapersForBart/Paper_IEEE_16_8_Aug2007_StatImageReco.pdf,0,0,0
1282396,Tomographic imaging with cosmic ray muons,2008,CL Morris and CC Alexander and JD Bacon and KN Borozdin and DJ Clark and R Chartrand and CJ Espinoza and AM Fraser and MC Galassi and JA Green and JS Gonzales and JJ Gomez and NW Hengartner and GE Hogan and AV Klimenko and MF Makela and P McGaughey and JJ Medina and FE Pazuchanics and WC Priedhorsky and JC Ramsey and A Saunders and RC Schirato and LJ Schultz and MJ Sossong and GS Blanpied,16,Science & Global Security,1-2,37-53,Taylor & Francis Group,Over 120 million vehicles enter the United States each year. Many are capable of transporting hidden nuclear weapons or nuclear material. Currently deployed X-ray radiography systems are limited because they cannot be used on occupied vehicles and the energy and dose are too low to penetrate many cargos. We present a new technique that overcomes these limitations by obtaining tomographic images using the multiple scattering of cosmic radiation as it transits each vehicle. When coupled with passive radiation detection. muon interrogation could contribute to safe and robust border protection against nuclear devices or material in occupied vehicles and containers.,True,SO0undgAAAAJ:BrmTIyaxlBUC,126,https://www.tandfonline.com/doi/abs/10.1080/08929880802335758,12939719799831551009,/scholar?cites=12939719799831551009,,,http://scienceandglobalsecurity.org/archive/sgs16morris.pdf,0,0,0
1282397,XMM-Newton observations of NGC 253: Resolving the emission components in the disk and nuclear area,2001,W Pietsch and TP Roberts and M Sako and MJ Freyberg and AM Read and KN Borozdin and G Branduardi-Raymont and M Cappi and M Ehle and P Ferrando and SM Kahn and TJ Ponman and A Ptak and RE Shirey and M Ward,365,Astronomy & Astrophysics,1,L174-L180,EDP Sciences,We describe the first XMM-Newton observations of the starburst galaxy NGC 253. As known from previous X-ray observations. NGC 253 shows a mixture of extended (disk and halo) and point-source emission. The high XMM-Newton throughput allows a detailed investigation of the spatial. spectral and variability properties of these components simultaneously. We characterize the brightest sources by their hardness ratios. detect a bright X-ray transient ~70´´SSW of the nucleus. and show the spectrum and light curve of the brightest point source (~30´´S of the nucleus. most likely a black-hole X-ray binary. BHXRB). The unresolved emission of two disk regions can be modeled by two thin thermal plasma components (temperatures of ~0.13 and 0.4 keV) plus residual harder emission. with the lower temperature component originating from above the disk. The nuclear spectrum can be modeled by a three temperature …,True,SO0undgAAAAJ:UHK10RUVsp4C,118,https://www.aanda.org/articles/aa/abs/2001/01/aaxmm18/aaxmm18.html,16797695359821750328,/scholar?cites=16797695359821750328,,,https://www.aanda.org/articles/aa/pdf/2001/01/aaxmm18.pdf,0,0,0
1282398,Detection of high-Z objects using multiple scattering of cosmic ray muons,2003,William C Priedhorsky and Konstantin N Borozdin and Gary E Hogan and Christopher Morris and Alexander Saunders and Larry J Schultz and Margaret E Teasdale,74,Review of Scientific Instruments,10,4294-4297,American Institute of Physics,We demonstrate that high-Z material can be detected and located in three dimensions using radiographs formed by cosmic-ray muons. Detection of high-Z material hidden inside large volume of ordinary cargo is an important and timely task given the danger associated with illegal transport of uranium and heavier elements. Existing radiography techniques are inefficient for shielded material. often expensive and involve radiation hazards. real and perceived. We recently demonstrated that radiographs can be formed using cosmic-ray muons [K. N. Borozdin et al.. Nature (London) 422. 277 (2003)]. Here. we show that compact. high-Z objects can be detected and located in three dimensions with muon radiography. The natural flux of cosmic-ray muons [P. K. F. Grieder. Cosmic Rays at Earth (Elsevier. New York. 2001)]. approximately 10 000 m−2 min−1. can form useful images in ∼1 min. using large-area muon …,True,SO0undgAAAAJ:HoB7MX3m0LUC,109,https://aip.scitation.org/doi/abs/10.1063/1.1606536,8536620063653487089,/scholar?cites=8536620063653487089,,,https://www.researchgate.net/profile/Konstantin_Borozdin/publication/228450467_Detection_of_high-Z_objects_using_multiple_scattering_of_cosmic_ray_muons/links/09e4150f5a3727c361000000.pdf,0,0,0
1282399,The central region of M 31 observed with XMM-Newton-I. Group properties and diffuse emission,2001,R Shirey and R Soria and K Borozdin and JP Osborne and A Tiengo and M Guainazzi and C Hayter and N La Palombara and K Mason and S Molendi and F Paerels and W Pietsch and W Priedhorsky and AM Read and MG Watson and RG West,365,Astronomy & Astrophysics,1,L195-L201,EDP Sciences,We present the results of a study based on an XMM-Newton  Performance Verification observation of the central 30´of the nearby spiral galaxy M 31. In the 34-ks European Photon Imaging Camera (EPIC) exposure. we detect 116 sources down to a limiting luminosity of #1 10#2 erg s-1 (0.3-12 keV. kpc). The luminosity distribution of the sources detected with XMM-Newton  flattens at luminosities below ~2.5 1037 erg s-1 . We make use of hardness ratios for the detected sources in order to distinguish between classes of objects such as super-soft sources and intrinsically hard or highly absorbed sources. We demonstrate that the spectrum of the unresolved emission in the bulge of M 31 contains a soft excess which can be fitted with a ~0.35-keV optically-thin thermal-plasma component clearly distinct from the composite point-source spectrum. We suggest that this may represent diffuse gas in the centre of M 31. and …,True,SO0undgAAAAJ:Tiz5es2fbqcC,94,https://www.aanda.org/articles/aa/abs/2001/01/aaxmm53/aaxmm53.html,11038324298392820327,/scholar?cites=11038324298392820327,,,https://www.aanda.org/articles/aa/pdf/2001/01/aaxmm53.pdf,0,0,0
1282400,LOBSTER-ISS: an imaging x-ray all-sky monitor for the International Space Station,2002,George W Fraser and Adam N Brunton and Nigel P Bannister and James F Pearson and Martin Ward and Tim J Stevenson and DJ Watson and Bob Warwick and S Whitehead and Paul O'Brian and Nicholas White and Keith Jahoda and Kevin Black and Stanley D Hunter and Phil Deines-Jones and William C Priedhorsky and Steven P Brumby and Konstantin N Borozdin and Thomas Vestrand and AC Fabian and Keith A Nugent and Andrew G Peele and Thomas HK Irving and Steve Price and Steve Eckersley and Ian Renouf and Mark Smith and Arvind N Parmar and IM McHardy and P Uttley and Andrew Lawrence,4497,,,115-126,International Society for Optics and Photonics,We describe the design of Lobster-ISS. an X-ray imaging all-sky monitor (ASM) to be flown as an attached payload on the International Space Station. Lobster-ISS is the subject of an ESA Phase-A study which will begin in December 2001. With an instantaneous field of view 162 x 22.5 degrees. Lobster-ISS will map almost the complete sky every 90 minute ISS orbit. generating a confusion-limited catalogue of ~250.000 sources every 2 months. Lobster-ISS will use focusing microchannel plate optics and imaging gas proportional micro-well detectors; work is currently underway to improve the MCP optics and to develop proportional counter windows with enhanced transmission and negligible rates of gas leakage. thus improving instrument throughput and reducing mass. Lobster-ISS provides an order of magnitude improvement in the sensitivity of X-ray ASMs. and will. for the first time. provide continuous monitoring …,True,SO0undgAAAAJ:1yQoGdGgb4wC,92,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4497/0000/LOBSTER-ISS--an-imaging-x-ray-all-sky-monitor/10.1117/12.454217.short,16655934597862105505,/scholar?cites=16655934597862105505,,,,0,0,0
1282401,Do the spectra of soft X-ray transients reveal bulk-motion inflow phenomenon?,1999,Konstantin Borozdin and Mikhail Revnivtsev and Sergey Trudolyubov and Chris Shrader and Lev Titarchuk,517,The Astrophysical Journal,1,367,IOP Publishing,We present our analysis of the high-energy radiation from black hole (BH) transients using archival data obtained primarily with RXTE and a comprehensive test of the bulk-motion Comptonization (BMC) model for the high-soft state continuum. The emergent spectra of over 30 separate measurements of the GRO J1655-40. GRS 1915+ 105. GRS 1739-278. 4U 1630-47 XTE J1755-32. and EXO 1846-031 X-ray sources are successfully fitted by the BMC model. which has been derived from basic physical principles in previous work. This in turn provides direct physical insight into the innermost observable regions. where matter impinging on the event horizon can effectively be directly viewed. The BMC model is characterized by three parameters: the disk color temperature. a geometric factor related to the illumination of the BH site by the disk. and a spectral index related to the efficiency of the bulk-motion upscattering …,True,SO0undgAAAAJ:V3AGJWp-ZtQC,88,https://iopscience.iop.org/article/10.1086/307186/meta,13743201429762881899,/scholar?cites=13743201429762881899,,,https://iopscience.iop.org/article/10.1086/307186/pdf,0,0,0
1282402,Cosmic ray radiography of the damaged cores of the Fukushima reactors,2012,Konstantin Borozdin and Steven Greene and Zarija Lukić and Edward Milner and Haruo Miyadera and Christopher Morris and John Perry,109,Physical review letters,15,152501,American Physical Society,The passage of muons through matter is dominated by the Coulomb interaction with electrons and nuclei. The interaction with the electrons leads to continuous energy loss and stopping of the muons. The interaction with nuclei leads to angle “diffusion.” Two muon-imaging methods that use flux attenuation and multiple Coulomb scattering of cosmic-ray muons are being studied as tools for diagnosing the damaged cores of the Fukushima reactors. Here. we compare these two methods. We conclude that the scattering method can provide detailed information about the core. Attenuation has low contrast and little sensitivity to the core.,True,SO0undgAAAAJ:35N4QoGY0k4C,87,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.109.152501,7734625579776753840,/scholar?cites=7734625579776753840,,,https://link.aps.org/pdf/10.1103/PhysRevLett.109.152501,0,0,0
1282403,The central region of M 31 observed with--II. Variability of the individual sources,2001,JP Osborne and KN Borozdin and SP Trudolyubov and WC Priedhorsky and R Soria and R Shirey and C Hayter and N La Palombara and K Mason and S Molendi and F Paerels and W Pietsch and AM Read and A Tiengo and MG Watson and RG West,378,Astronomy & Astrophysics,3,800-805,EDP Sciences,We present the results of a study of the variability of X-ray sources in the central 30´of the nearby Andromeda Galaxy (M 31) based on XMM-Newton  Performance Verification observations. Two observations of this field. with a total exposure time of about 50 ks. were performed in June and December of 2000. We found 116 sources brighter than a limiting luminosity of 61035 erg s-1 (0.3-12 keV. kpc). For the ~60 brightest sources. we searched for periodic and non-periodic variability; at least 15% of these sources appear to be variable on a time scale of several months. We discovered a new bright transient source ~2.9´from the nucleus in the June observation; this source faded significantly and was no longer detected in December. The behaviour of the object is similar to a handful of Galactic LMXB transients. most of which are supposed to harbor black holes. We detected pulsations with a period of ~865 s from a source with a supersoft spectrum. The flux of this source decreased significantly between the two XMM  observations. The detected period is unusually short and points to a rapidly spinning magnetized white dwarf. The high luminosity and transient nature of the source suggest its possible identification with classical or symbiotic nova. some of which were observed earlier as supersoft sources.,True,SO0undgAAAAJ:D03iK_w7-QYC,85,https://www.aanda.org/articles/aa/full/2001/42/aah3101/node2.html,9513855587983345404,/scholar?cites=9513855587983345404,,,https://www.aanda.org/articles/aa/pdf/2001/42/aah3101.pdf,0,0,0
1282404,Tensorizing neural networks,2015,Alexander Novikov and Dmitry Podoprikhin and Anton Osokin and Dmitry Vetrov,,arXiv preprint arXiv:1509.06569,,,,Deep neural networks currently demonstrate state-of-the-art performance in several domains. At the same time. models of this class are very demanding in terms of computational resources. In particular. a large amount of memory is required by commonly used fully-connected layers. making it hard to use the models on low-end devices and stopping the further increase of the model size. In this paper we convert the dense weight matrices of the fully-connected layers to the Tensor Train format such that the number of parameters is reduced by a huge factor and at the same time the expressive power of the layer is preserved. In particular. for the Very Deep VGG networks we report the compression factor of the dense weight matrix of a fully-connected layer up to 200000 times leading to the compression factor of the whole network up to 7 times.,True,7HU0UoUAAAAJ:ns9cj8rnVeAC,523,https://arxiv.org/abs/1509.06569,15959182859518738418,/scholar?cites=15959182859518738418,,,https://arxiv.org/pdf/1509.06569,0,0,0
1282405,Variational dropout sparsifies deep neural networks,2017,Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov,,,,2498-2507,PMLR,We explore a recently proposed Variational Dropout technique that provided an elegant Bayesian interpretation to Gaussian Dropout. We extend Variational Dropout to the case when dropout rates are unbounded. propose a way to reduce the variance of the gradient estimator and report first experimental results with individual dropout rates per weight. Interestingly. it leads to extremely sparse solutions both in fully-connected and convolutional layers. This effect is similar to automatic relevance determination effect in empirical Bayes but has a number of advantages. We reduce the number of parameters up to 280 times on LeNet architectures and up to 68 times on VGG-like networks with a negligible decrease of accuracy.,True,7HU0UoUAAAAJ:pqnbT2bcN3wC,465,http://proceedings.mlr.press/v70/molchanov17a.html,11014728550012194230,/scholar?cites=11014728550012194230,,,http://proceedings.mlr.press/v70/molchanov17a/molchanov17a.pdf,0,0,0
1282406,Evaluation of stability of k-means cluster ensembles with respect to random initialization,2006,Ludmila I Kuncheva and Dmitry P Vetrov,28,IEEE transactions on pattern analysis and machine intelligence,11,1798-1808,IEEE,Many clustering algorithms. including cluster ensembles. rely on a random component. Stability of the results across different runs is considered to be an asset of the algorithm. The cluster ensembles considered here are based on k-means clusterers. Each clusterer is assigned a random target number of clusters. k and is started from a random initialization. Here. we use 10 artificial and 10 real data sets to study ensemble stability with respect to random k. and random initialization. The data sets were chosen to have a small number of clusters (two to seven) and a moderate number of data points (up to a few hundred). Pairwise stability is defined as the adjusted Rand index between pairs of clusterers in the ensemble. averaged across all pairs. Nonpairwise stability is defined as the entropy of the consensus matrix of the ensemble. An experimental comparison with the stability of the standard k-means algorithm was …,True,7HU0UoUAAAAJ:u5HHmVD_uO8C,348,https://ieeexplore.ieee.org/abstract/document/1704835/,12405556465091400158,/scholar?cites=12405556465091400158,,,http://www.vetrovd.narod.ru/pdfs/ClusterEnsembles.PDF,0,0,0
1282407,Averaging weights leads to wider optima and better generalization,2018,Pavel Izmailov and Dmitrii Podoprikhin and Timur Garipov and Dmitry Vetrov and Andrew Gordon Wilson,,arXiv preprint arXiv:1803.05407,,,,Deep neural networks are typically trained by optimizing a loss function with an SGD variant. in conjunction with a decaying learning rate. until convergence. We show that simple averaging of multiple points along the trajectory of SGD. with a cyclical or constant learning rate. leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD. and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks. PyramidNets. DenseNets. and Shake-Shake networks on CIFAR-10. CIFAR-100. and ImageNet. In short. SWA is extremely easy to implement. improves generalization. and has almost no computational overhead.,True,7HU0UoUAAAAJ:D03iK_w7-QYC,319,https://arxiv.org/abs/1803.05407,2440249622275435711,/scholar?cites=2440249622275435711,,,https://arxiv.org/pdf/1803.05407,0,0,0
1282408,Spatially Adaptive Computation Time for Residual Networks,2017,Michael Figurnov and Maxwell Collins and Yukun Zhu and Li Zhang and Jonathan Huang and Dmitry P Vetrov and Ruslan Salakhutdinov,,,,,,This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable. deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification. object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally. we evaluate the computation time maps on the visual saliency dataset cat2000 and find that they correlate surprisingly well with human eye fixation positions.,True,7HU0UoUAAAAJ:rO6llkc54NcC,203,http://openaccess.thecvf.com/content_cvpr_2017/html/Figurnov_Spatially_Adaptive_Computation_CVPR_2017_paper.html,13202224366050669196,/scholar?cites=13202224366050669196,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Figurnov_Spatially_Adaptive_Computation_CVPR_2017_paper.pdf,0,0,0
1282409,Loss surfaces. mode connectivity. and fast ensembling of dnns,2018,Timur Garipov and Pavel Izmailov and Dmitrii Podoprikhin and Dmitry Vetrov and Andrew Gordon Wilson,,arXiv preprint arXiv:1802.10026,,,,The loss functions of deep neural networks are complex and their geometric properties are not well understood. We show that the optima of these complex loss functions are in fact connected by simple curves over which training and test accuracy are nearly constant. We introduce a training procedure to discover these high-accuracy pathways between modes. Inspired by this new geometric insight. we also propose a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we can train high-performing ensembles in the time required to train a single model. We achieve improved performance compared to the recent state-of-the-art Snapshot Ensembles. on CIFAR-10. CIFAR-100. and ImageNet.,True,7HU0UoUAAAAJ:yD5IFk8b50cC,174,https://arxiv.org/abs/1802.10026,7857512178594187445,/scholar?cites=7857512178594187445,,,https://arxiv.org/pdf/1802.10026;Loss,0,0,0
1282410,A simple baseline for bayesian uncertainty in deep learning,2019,Wesley J Maddox and Pavel Izmailov and Timur Garipov and Dmitry P Vetrov and Andrew Gordon Wilson,32,Advances in Neural Information Processing Systems,,13153-13164,,We propose SWA-Gaussian (SWAG). a simple. scalable. and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA). which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule. has recently been shown to improve generalization in deep learning. With SWAG. we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates. forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior. in accordance with results describing the stationary distribution of SGD iterates. Moreover. we demonstrate that SWAG performs well on a wide variety of tasks. including out of sample detection. calibration. and transfer learning. in comparison to many popular alternatives including variational inference. MC dropout. KFAC Laplace. and temperature scaling.,True,7HU0UoUAAAAJ:XiSMed-E-HIC,167,https://proceedings.neurips.cc/paper/2019/file/118921efba23fc329e6560b27861f0c2-Paper.pdf,4938182174332558509,/scholar?cites=4938182174332558509,,,https://proceedings.neurips.cc/paper/2019/file/118921efba23fc329e6560b27861f0c2-Paper.pdf,0,0,0
1282411,Breaking sticks and ambiguities with adaptive skip-gram,2016,Sergey Bartunov and Dmitry Kondrashkin and Anton Osokin and Dmitry Vetrov,,,,130-138,PMLR,The recently proposed Skip-gram model is a powerful method for learning high-dimensional word representations that capture rich semantic relationships between words. However. Skip-gram as well as most prior work on learning word representations does not take into account word ambiguity and maintain only single representation per word. Although a number of Skip-gram modifications were proposed to overcome this limitation and learn multi-prototype word representations. they either require a known number of word meanings or learn them using greedy heuristic approaches. In this paper we propose the Adaptive Skip-gram model which is a nonparametric Bayesian extension of Skip-gram capable to automatically learn the required number of representations for all words at desired semantic resolution. We derive efficient online variational learning algorithm for the model and empirically demonstrate its efficiency on word-sense induction task.,True,7HU0UoUAAAAJ:BqipwSGYUEgC,159,http://proceedings.mlr.press/v51/bartunov16.html,14554278354317141694,/scholar?cites=14554278354317141694,,,http://proceedings.mlr.press/v51/bartunov16.pdf,0,0,0
1282412,Perforatedcnns: Acceleration through elimination of redundant convolutions,2016,Mikhail Figurnov and Aizhan Ibraimova and Dmitry P Vetrov and Pushmeet Kohli,29,Advances in neural information processing systems,,947-955,,We propose a novel approach to reduce the computational cost of evaluation of convolutional neural networks. a factor that has hindered their deployment in low-power devices such as mobile phones. Inspired by the loop perforation technique from source code optimization. we speed up the bottleneck convolutional layers by skipping their evaluation in some of the spatial positions. We propose and analyze several strategies of choosing these positions. We demonstrate that perforation can accelerate modern convolutional networks such as AlexNet and VGG-16 by a factor of 2x-4x. Additionally. we show that perforation is complementary to the recently proposed acceleration method of Zhang et al.,True,7HU0UoUAAAAJ:GnPB-g6toBAC,133,http://papers.nips.cc/paper/6463-learning-deep-embeddings-with-histogram-loss,555676852530582844,/scholar?cites=555676852530582844,,,https://papers.nips.cc/paper/6463-learning-deep-embeddings-with-histogram-loss.pdf,0,0,0
1282413,Structured bayesian pruning via log-normal multiplicative noise,2017,Kirill Neklyudov and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov,,arXiv preprint arXiv:1705.07283,,,,Dropout-based regularization methods can be regarded as injecting random noise with pre-defined magnitude to different parts of the neural network during training. It was recently shown that Bayesian dropout procedure not only improves generalization but also leads to extremely sparse neural architectures by automatically setting the individual noise magnitude per weight. However. this sparsity can hardly be used for acceleration since it is unstructured. In the paper. we propose a new Bayesian model that takes into account the computational structure of neural networks and provides structured sparsity. eg removes neurons and/or convolutional channels in CNNs. To do this we inject noise to the neurons outputs while keeping the weights unregularized. We establish the probabilistic model with a proper truncated log-uniform prior over the noise and truncated log-normal variational approximation that ensures that the KL-term in the evidence lower bound is computed in closed-form. The model leads to structured sparsity by removing elements with a low SNR from the computation graph and provides significant acceleration on a number of deep neural architectures. The model is easy to implement as it can be formulated as a separate dropout-like layer.,True,7HU0UoUAAAAJ:HoB7MX3m0LUC,120,https://arxiv.org/abs/1705.07283,397771198683206613,/scholar?cites=397771198683206613,,,https://arxiv.org/pdf/1705.07283,0,0,0
1282414,Ultimate tensorization: compressing convolutional and fc layers alike,2016,Timur Garipov and Dmitry Podoprikhin and Alexander Novikov and Dmitry Vetrov,,arXiv preprint arXiv:1611.03214,,,,Convolutional neural networks excel in image recognition tasks. but this comes at the cost of high computational and memory complexity. To tackle this problem.[1] developed a tensor factorization framework to compress fully-connected layers. In this paper. we focus on compressing convolutional layers. We show that while the direct application of the tensor framework [1] to the 4-dimensional kernel of convolution does compress the layer. we can do better. We reshape the convolutional kernel into a tensor of higher order and factorize it. We combine the proposed approach with the previous work to compress both convolutional and fully-connected layers of a network and achieve 80x network compression rate with 1.1% accuracy drop on the CIFAR-10 dataset.,True,7HU0UoUAAAAJ:35N4QoGY0k4C,96,https://arxiv.org/abs/1611.03214,14141301253834230318,/scholar?cites=14141301253834230318,,,https://arxiv.org/pdf/1611.03214,0,0,0
1282415,Continual lifelong learning with neural networks: A review,2019,German I Parisi and Ronald Kemker and Jose L Part and Christopher Kanan and Stefan Wermter,,Neural Networks,,,,Humans and animals have the ability to continually acquire. fine-tune. and transfer knowledge and skills throughout their lifespan. This ability. referred to as lifelong learning. is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently. lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However. lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural …,True,jMxZjBoAAAAJ:mB3voiENLucC,737,https://www.sciencedirect.com/science/article/pii/S0893608019300231,10072780883208894000,/scholar?cites=10072780883208894000,,,https://www.sciencedirect.com/science/article/pii/S0893608019300231,0,0,0
1282416,SUN: Top-down saliency using natural statistics,2009,Christopher Kanan and Mathew H Tong and Lingyun Zhang and Garrison W Cottrell,17,Visual Cognition,6-7,979-1003,Taylor & Francis Group,When people try to find particular objects in natural scenes they make extensive use of knowledge about how and where objects tend to appear in a scene. Although many forms of such “top-down” knowledge have been incorporated into saliency map models of visual search. surprisingly. the role of object appearance has been infrequently investigated. Here we present an appearance-based saliency model derived in a Bayesian framework. We compare our approach with both bottom-up saliency algorithms as well as the state-of-the-art Contextual Guidance model of Torralba et al. (2006) at predicting human fixations. Although both top-down approaches use very different types of information. they achieve similar performance; each substantially better than the purely bottom-up models. Our experiments reveal that a simple model of object appearance can predict human fixations quite well. even making the same …,True,jMxZjBoAAAAJ:u5HHmVD_uO8C,300,https://www.tandfonline.com/doi/abs/10.1080/13506280902771138,6622326190854692406,/scholar?cites=6622326190854692406,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2967792/,0,0,0
1282417,Color-to-grayscale: does the method matter in image recognition?,2012,Christopher Kanan and Garrison W Cottrell,7,PLOS ONE,1,e29740,Public Library of Science,In image recognition it is often assumed the method used to convert color images to grayscale has little impact on recognition performance. We compare thirteen different grayscale algorithms with four types of image descriptors and demonstrate that this assumption is wrong: not all color-to-grayscale algorithms work equally well. even when using descriptors that are robust to changes in illumination. These methods are tested using a modern descriptor-based image recognition framework. on face. object. and texture datasets. with relatively few training instances. We identify a simple method that generally works best for face and object recognition. and two that work well for recognizing textures.,True,jMxZjBoAAAAJ:Tyk-4Ss8FVUC,277,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029740,10060385164219231552,/scholar?cites=10060385164219231552,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029740,0,0,0
1282418,Measuring catastrophic forgetting in neural networks,2018,Ronald Kemker and Marc McClure and Angelina Abitino and Tyler L Hayes and Christopher Kanan,,,,,,Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task. eg. bird classification. it cannot easily be trained to do new tasks. eg. incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added. typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally. much like how humans form new memories over time. will be more efficient than re-training the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting. but these methods have not been directly compared. the tests used to evaluate them vary considerably. and these methods have only been evaluated on small-scale problems (eg. MNIST). In this paper. we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization. ensembling. rehearsal. dual-memory. and sparse-coding. Our experiments on real-world images and sounds show that the mechanism (s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used. but they all demonstrate that the catastrophic forgetting problem is not yet solved.,True,jMxZjBoAAAAJ:BqipwSGYUEgC,258,https://ojs.aaai.org/index.php/AAAI/article/view/11651,1358572155151187767,/scholar?cites=1358572155151187767,,,https://ojs.aaai.org/index.php/AAAI/article/download/11651/11510,0,0,0
1282419,Robust classification of objects. faces. and flowers using natural image statistics,2010,Christopher Kanan and Garrison Cottrell,,,,2472-2479,IEEE,Classification of images in many category datasbets has rapidly improved in recent years. However. systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g.. requiring a face detector or extensive retuning of parameters). insufficient translation invariance. inability to cope with partial views and occlusion. or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type. our approach achieves 78.5% accuracy on Caltech-101 and 75.2% on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7% accuracy …,True,jMxZjBoAAAAJ:u-x6o8ySG0sC,220,https://ieeexplore.ieee.org/abstract/document/5539947/,9340147723575849122,/scholar?cites=9340147723575849122,,,http://cseweb.ucsd.edu/~gary/pubs/robust-classification-final.pdf,0,0,0
1282420,Robotic grasp detection using deep convolutional neural networks,2017,Sulabh Kumra and Christopher Kanan,,,,769-776,IEEE,Deep learning has significantly advanced computer vision and natural language processing. While there have been some successes in robotics using deep learning. it has not been widely adopted. In this paper. we present a novel robotic grasp detection system that predicts the best grasping pose of a parallel-plate robotic gripper for novel objects using the RGB-D image of the scene. The proposed model uses a deep convolutional neural network to extract features from the scene and then uses a shallow convolutional neural network to predict the grasp configuration for the object of interest. Our multi-modal model achieved an accuracy of 89.21% on the standard Cornell Grasp Dataset and runs at real-time speeds. This redefines the state-of-the-art for robotic grasp detection.,True,jMxZjBoAAAAJ:GnPB-g6toBAC,193,https://ieeexplore.ieee.org/abstract/document/8202237/,1586195187146027370,/scholar?cites=1586195187146027370,,,https://arxiv.org/pdf/1611.08036.pdf?source=post_page---------------------------,0,0,0
1282421,FearNet: Brain-Inspired Model for Incremental Learning,2018,Ronald Kemker and Christopher Kanan,,,,,,Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie methods for training standard deep neural networks. and will cause them to suffer from catastrophic forgetting. Arguably. the best method for incremental class learning is iCaRL. but it requires storing training examples for each class. making it challenging to scale. Here. we propose FearNet for incremental class learning. FearNet is a generative model that does not store previous examples. making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall. FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100. CUB-200) and audio classification (AudioSet) benchmarks.,True,jMxZjBoAAAAJ:dhFuZR0502QC,183,https://arxiv.org/abs/1711.10563,3792376045058171047,/scholar?cites=3792376045058171047,,,https://arxiv.org/pdf/1711.10563,0,0,0
1282422,Algorithms for semantic segmentation of multispectral remote sensing imagery using deep learning,2018,Ronald Kemker and Carl Salvaggio and Christopher Kanan,145,ISPRS journal of photogrammetry and remote sensing,,60-77,Elsevier,Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g.. object recognition. object detection. semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities. e.g.. multispectral imagery (MSI). are not available due to the large cost and manpower required. In this paper. we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data. we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting …,True,jMxZjBoAAAAJ:R3hNpaxXUhUC,180,https://www.sciencedirect.com/science/article/pii/S0924271618301229,15308505491795391066,/scholar?cites=15308505491795391066,,,https://arxiv.org/pdf/1703.06452,0,0,0
1282423,Visual Question Answering: Datasets. Algorithms. and Future Challenges,2017,Kushal Kafle and Christopher Kanan,,Computer Vision and Image Understanding (CVIU),,,,Visual Question Answering (VQA) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning. computer vision. and natural language processing communities. In VQA. an algorithm needs to answer text-based questions about images. Since the release of the first VQA dataset in 2014. additional datasets have been released and many algorithms have been proposed. In this review. we critically examine the current state of VQA in terms of problem formulation. existing datasets. evaluation metrics. and algorithms. In particular. we discuss the limitations of current datasets with regard to their ability to properly train and assess VQA algorithms. We then exhaustively review existing algorithms for VQA. Finally. we discuss possible future directions for VQA and image understanding research.,True,jMxZjBoAAAAJ:kNdYIx-mwKoC,129,https://www.sciencedirect.com/science/article/pii/S1077314217301170,3658847749127613787,/scholar?cites=3658847749127613787,,,https://arxiv.org/pdf/1610.01465,0,0,0
1282424,An Analysis of Visual Question Answering Algorithms,2017,Kushal Kafle and Christopher Kanan,,,,,,In visual question answering (VQA). an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014. they all have flaws in both their content and the way algorithms are evaluated on them. As a result. evaluation scores are inflated and predominantly determined by answering easier questions. making it difficult to compare different methods. In this paper. we analyze existing VQA algorithms using a new dataset called the Task Driven Image Understanding Challenge (TDIUC). which has over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models. including multi-modal compact bilinear pooling (MCB). neural module networks. and recurrent answering units. Our experiments establish how attention helps certain categories more than others. determine which models work better than others. and explain how simple models (eg MLP) can surpass more complex models (MCB) by simply learning to answer large. easy question categories.,True,jMxZjBoAAAAJ:M3ejUd6NZC8C,119,http://openaccess.thecvf.com/content_iccv_2017/html/Kafle_An_Analysis_of_ICCV_2017_paper.html,5953461899170317660,/scholar?cites=5953461899170317660,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Kafle_An_Analysis_of_ICCV_2017_paper.pdf,0,0,0
1282425,Answer-type prediction for visual question answering,2016,Kushal Kafle and Christopher Kanan,,,,4976-4984,,Recently. algorithms for object recognition and related tasks have become sufficiently proficient that new vision tasks can now be pursued. In this paper. we build a system capable of answering open-ended text-based questions about images. which is known as Visual Question Answering (VQA). Our approach's key insight is that we can predict the form of the answer from the question. We formulate our solution in a Bayesian framework. When our approach is combined with a discriminative model. the combined model achieves state-of-the-art results on four benchmark datasets for open-ended VQA: DAQUAR. COCO-QA. The VQA Dataset. and Visual7W.,True,jMxZjBoAAAAJ:MXK_kJrjxJIC,97,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Kafle_Answer-Type_Prediction_for_CVPR_2016_paper.html,9180624711728764399,/scholar?cites=9180624711728764399,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kafle_Answer-Type_Prediction_for_CVPR_2016_paper.pdf,0,0,0
1282426,Collaborative filtering and deep learning based recommendation system for cold start items,2017,Jian Wei and Jianhua He and Kai Chen and Yi Zhou and Zuoyin Tang,69,Expert Systems with Applications,,29-39,Pergamon,Recommender system is a specific type of intelligent systems. which exploits historical user ratings on items and/or auxiliary information to make recommendations on items to the users. It plays a critical role in a wide range of online shopping. e-commercial services and social networking applications. Collaborative filtering (CF) is the most popular approaches used for recommender systems. but it suffers from complete cold start (CCS) problem where no rating record are available and incomplete cold start (ICS) problem where only a small number of rating records are available for some new items or users in the system. In this paper. we propose two recommendation models to solve the CCS and ICS problems for new items. which are based on a framework of tightly coupled CF approach and deep learning neural network. A specific deep neural network SADE is used to extract the content features of the items. The …,True,4SUAgfAAAAAJ:MXK_kJrjxJIC,405,https://www.sciencedirect.com/science/article/pii/S0957417416305309,4042913562618672398,/scholar?cites=4042913562618672398,,,https://discovery.dundee.ac.uk/ws/files/39285097/Recommendation_system_for_cold_start_items.pdf,0,0,0
1282427,Energy efficient radio access architectures for green radio: Large versus small cell size deployment,2009,Biljana Badic and T O'farrrell and Pavel Loskot and Jianhua He,,,,1-5,IEEE,In this paper new architectural approaches that improve the energy efficiency of a cellular radio access network (RAN) are investigated. The aim of the paper is to characterize both the energy consumption ratio (ECR) and the energy consumption gain (ECG) of a cellular RAN when the cell size is reduced for a given user density and service area. The paper affirms that reducing the cell size reduces the cell ECR as desired while increasing the capacity density but the overall RAN energy consumption remains unchanged. In order to trade the increase in capacity density with RAN energy consumption. without degrading the cell capacity provision. a sleep mode is introduced. In sleep mode. cells without active users are powered-off. thereby saving energy. By combining a sleep mode with a small-cell deployment architecture. the paper shows that the ECG can be increased by the factor n = (R large /R small ) 2  while …,True,4SUAgfAAAAAJ:blknAaTinKkC,250,https://ieeexplore.ieee.org/abstract/document/5379035/,11157708836455871364,/scholar?cites=11157708836455871364,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.463.725&rep=rep1&type=pdf,0,0,0
1282428,A survey on mobile ad hoc wireless network,2004,Samba Sesay and Zongkai Yang and Jianhua He,3,Information Technology Journal,2,168-175,,This paper presents a coherent survey on ad hoc wireless networks. with the intent of serving as a quick reference to the current research issues in ad hoc networking. It starts with a background on the origin and development stages of ad hoc network. then summaries the characteristics. capabilities. applications and design constraints of ad hoc network fully distinguishing it from traditional networks. The paper discuses a broad range of research issues such as Routing. Medium Access. Multicasting. Quality of service. TCP performance. Energy. Security and Bluetooth. outlining the major challenges which have to be solved before widespread deployment of the technology is possible. Through this survey it would be seen that Ad hoc Networking presence an interesting research area inheriting the problems of wireless and mobile communications in their most difficult form.,True,4SUAgfAAAAAJ:e5wmG9Sq2KIC,218,https://www.researchgate.net/profile/Samba_Sesay/publication/45949360_A_Survey_on_Mobile_Ad_Hoc_Wireless_Network/links/55d74fed08ae9d65948d8a6e/A-Survey-on-Mobile-Ad-Hoc-Wireless-Network.pdf,9313127312710957867,/scholar?cites=9313127312710957867,,,https://www.researchgate.net/profile/Samba_Sesay/publication/45949360_A_Survey_on_Mobile_Ad_Hoc_Wireless_Network/links/55d74fed08ae9d65948d8a6e/A-Survey-on-Mobile-Ad-Hoc-Wireless-Network.pdf,0,0,0
1282429,A multihop peer-communication protocol with fairness guarantee for IEEE 802.16-based vehicular networks,2007,Kun Yang and Shumao Ou and Hsiao-Hwa Chen and Jianghua He,56,IEEE Transactions on Vehicular Technology,6,3358-3370,IEEE,Wireless-communication technology can be used to improve road safety and to provide Internet access inside vehicles. This paper proposes a cross-layer protocol called coordinated external peer communication (CEPEC) for Internet-access services and peer communications for vehicular networks. We assume that IEEE 802.16 base stations (BS) are installed along highways and that the same air interface is equipped in vehicles. Certain vehicles locating outside of the limited coverage of their nearest BSs can still get access to the Internet via a multihop route to their BSs. For Internet-access services. the objective of CEPEC is to increase the end-to-end throughput while providing a fairness guarantee in bandwidth usage among road segments. To achieve this goal. the road is logically partitioned into segments of equal length. A relaying head is selected in each segment that performs both local-packet collecting …,True,4SUAgfAAAAAJ:sSrBHYA8nusC,150,https://ieeexplore.ieee.org/abstract/document/4357364/,12576832899737591248,/scholar?cites=12576832899737591248,,,,0,0,0
1282430,Multitier fog computing with large-scale iot data analytics for smart cities,2017,Jianhua He and Jian Wei and Kai Chen and Zuoyin Tang and Yi Zhou and Yan Zhang,5,IEEE Internet of Things Journal,2,677-686,IEEE,Analysis of Internet of Things (IoT) sensor data is a key for achieving city smartness. In this paper a multitier fog computing model with large-scale data analytics service is proposed for smart cities applications. The multitier fog is consisted of ad-hoc fogs and dedicated fogs with opportunistic and dedicated computing resources. respectively. The proposed new fog computing model with clear functional modules is able to mitigate the potential problems of dedicated computing infrastructure and slow response in cloud computing. We run analytics benchmark experiments over fogs formed by Rapsberry Pi computers with a distributed computing engine to measure computing performance of various analytics tasks. and create easy-to-use workload models. Quality of services (QoS) aware admission control. offloading. and resource allocation schemes are designed to support data analytics services. and maximize …,True,4SUAgfAAAAAJ:2P1L_qKh6hAC,145,https://ieeexplore.ieee.org/abstract/document/7972945/,13303202919315127035,/scholar?cites=13303202919315127035,,,https://discovery.dundee.ac.uk/ws/files/39210756/Multi_tier_fog_computing_with_large_scale_IoT_data_analytics_for_smart_cities.pdf,0,0,0
1282431,A localization scheme for underwater wireless sensor networks,2009,Kai Chen and Yi Zhou and Jianhua He,4,International Journal of Advanced Science and Technology,,,,In this paper. we study the localization problem in large-scale Underwater Wireless Sensor Networks (UWSNs). Unlike in the terrestrial positioning. the global positioning system (GPS) can not work efficiently underwater. The limited bandwidth. the severely impaired channel and the cost of underwater equipment all makes the localization problem very challenging. Most current localization schemes are not well suitable for deep underwater environment. We propose a hierarchical localization scheme to address the challenging problems. The new scheme mainly consists of four types of nodes. which are surface buoys. Detachable Elevator Transceivers (DETs). anchor nodes and ordinary nodes. Surface buoy is assumed to be equipped with GPS on the water surface. A DET is attached to a surface buoy and can rise and down to broadcast its position. The anchor nodes can compute their positions based on the position information from the DETs and the measurements of distance to the DETs. The hierarchical localization scheme is scalable. and can be used to make balances on the cost and localization accuracy. Initial simulation results show the advantages of our proposed scheme.,True,4SUAgfAAAAAJ:abG-DnoFyZgC,113,http://vtuplus.byethost7.com/assets/seminar/A%20Localization%20Scheme%20for%20Underwater%20Wireless%20Sensor%20Networks.pdf,16202868615786061098,/scholar?cites=16202868615786061098,,,http://vtuplus.byethost7.com/assets/seminar/A%20Localization%20Scheme%20for%20Underwater%20Wireless%20Sensor%20Networks.pdf,0,0,0
1282432,Modeling contention based bandwidth request scheme for IEEE 802.16 networks,2007,Jianhua He and Ken Guild and Kun Yang and Hsiao-Hwa Chen,11,IEEE communications letters,8,689-700,IEEE,IEEE 802.16 standard specifies a contention based bandwidth request scheme for best-effort and non-real time polling services in point-to-multipoint (PMP) architecture. In this letter we propose an analytical model for the scheme and study how the performances of bandwidth efficiency and channel access delay change with the contention window size. the number of contending subscriber stations. the number of slots allocated for bandwidth request and data transmission. Simulations validate its high accuracy.,True,4SUAgfAAAAAJ:XiSMed-E-HIC,101,https://ieeexplore.ieee.org/abstract/document/4290007/,17277248548893247584,/scholar?cites=17277248548893247584,,,https://www.researchgate.net/profile/Ken_Guild/publication/3418156_Modeling_Contention_Based_Bandwidth_Request_Scheme_for_IEEE_80216_Networks/links/00b4953c7307adfda7000000.pdf,0,0,0
1282433,An accurate and scalable analytical model for IEEE 802.15. 4 slotted CSMA/CA networks,2009,Jianhua He and Zuoyin Tang and Hsiao-Hwa Chen and Qian Zhang,8,IEEE Transactions on Wireless Communications,1,440-448,IEEE,In this paper a Markov chain based analytical model is proposed to evaluate the slotted CSMA/CA algorithm specified in the MAC layer of IEEE 802.15.4 standard. The analytical model consists of two two-dimensional Markov chains. used to model the state transition of an 802.15.4 device. during the periods of a transmission and between two consecutive frame transmissions. respectively. By introducing the two Markov chains a small number of Markov states are required and the scalability of the analytical model is improved. The analytical model is used to investigate the impact of the CSMA/CA parameters. the number of contending devices. and the data frame size on the network performance in terms of throughput and energy efficiency. It is shown by simulations that the proposed analytical model can accurately predict the performance of slotted CSMA/CA algorithm for uplink. downlink and bi-direction traffic …,True,4SUAgfAAAAAJ:f2IySw72cVMC,100,https://ieeexplore.ieee.org/abstract/document/4786525/,15951579635936784773,/scholar?cites=15951579635936784773,,,,0,0,0
1282434,Simulation Comparison of Four VVireless Ad hoc Routing Protocols,2004,Samba Sesay and Zongkai Yang and Biao Qi and Jianhua He,3,Information technology journal,3,219-226,,Mobile Ad hoc-networking (MANET) is becoming increasingly important in today's world and a number of protocols have been developed for them. However a comparison between them is lacking to help determine an optimal one. This study addresses this issue by comparing the relative performance of four key Ad hoc routing protocols; Destination-sequenced distance vector (DSDV). Temporally ordered routing algorithm (TORA). Dynamic source routing (DSR) and Ad hoc on-demand distance vector (AODV). This study subjected the protocols to identical loads and environmental conditions and evaluate their relative performance with respect to end-to-end throughput and delay. control packet overhead and route acquisition time. From the detailed simulation results and analysis of presented. an appropriate choice of routing protocol can be made for given network context and goal.,True,4SUAgfAAAAAJ:pqnbT2bcN3wC,89,https://www.researchgate.net/profile/Samba_Sesay/publication/26556571_Simulation_Comparison_of_Four_Wireless_Ad_hoc_Routing_Protocols/links/55d74fed08aeb38e8a85a6d3/Simulation-Comparison-of-Four-Wireless-Ad-hoc-Routing-Protocols.pdf,13967401676786361083,/scholar?cites=13967401676786361083,,,https://www.researchgate.net/profile/Samba_Sesay/publication/26556571_Simulation_Comparison_of_Four_Wireless_Ad_hoc_Routing_Protocols/links/55d74fed08aeb38e8a85a6d3/Simulation-Comparison-of-Four-Wireless-Ad-hoc-Routing-Protocols.pdf,0,0,0
1282435,Adaptive congestion control for DSRC vehicle networks,2010,Jianhua He and Hsiao-hwa Chen and Thomas M Chen and Wenqing Cheng,14,IEEE communications letters,2,127-129,IEEE,Dedicated short range communications (DSRC) was proposed for collaborative safety applications (CSA) in vehicle communications. In this article we propose two adaptive congestion control schemes for DSRC-based CSA. A cross-layer design approach is used with congestion detection at the MAC layer and traffic rate control at the application layer. Simulation results show the effectiveness of the proposed rate control scheme for adapting to dynamic traffic loads.,True,4SUAgfAAAAAJ:4DMP91E08xMC,79,https://ieeexplore.ieee.org/abstract/document/5403609/,6357668224587129466,/scholar?cites=6357668224587129466,,,,0,0,0
1282436,A new approach for fast generalized sphere decoding in MIMO systems,2004,Zongkai Yang and Chao Liu and Jianhua He,12,IEEE Signal Processing Letters,1,41-44,IEEE,A new generalized sphere decoder (GSD). called a double-layer sphere decoder (DLSD). is proposed for under-determined MIMO systems with fewer receive antennas N than transmit antennas M. The proposed algorithm is significantly faster than those introduced in and . The basic idea is to partition the transmitted signal vector into two subvectors with M-N+1 and N-1 elements. After some simple transformations. we can use an outer layer sphere decoder (SD) to choose proper subvectors of length M-N+1 and then use an inner layer SD to decide the other subvector of length N-1. thus the whole transmitted signal vector is obtained. Simulation results show that DLSD has far less complexity than the existing GSDs.,True,4SUAgfAAAAAJ:nb7KW1ujOQ8C,72,https://ieeexplore.ieee.org/abstract/document/1369270/,16729396469346879087,/scholar?cites=16729396469346879087,,,,0,0,0
1282437,Automatic evaluation of topic coherence,2010,David Newman and Jey Han Lau and Karl Grieser and Timothy Baldwin,,,,100-108,,This paper introduces the novel task of topic coherence evaluation. whereby a set of words. as generated by a topic model. is rated for coherence or interpretability. We apply a range of topic scoring models to the evaluation task. drawing on WordNet. Wikipedia and the Google search engine. and existing research on lexical similarity/relatedness. In comparison with human scores for a set of learned topics over two distinct datasets. we show a simple co-occurrence measure based on pointwise mutual information over Wikipedia data is able to achieve results for the task at or nearing the level of inter-annotator correlation. and that other Wikipedia-based lexical relatedness methods also achieve strong results. Google produces strong. if less consistent. results. while our results over WordNet are patchy at best.,True,MFi65f4AAAAJ:u5HHmVD_uO8C,880,https://www.aclweb.org/anthology/N10-1012.pdf,2519763044915835950,/scholar?cites=2519763044915835950,,,https://www.aclweb.org/anthology/N10-1012.pdf,0,0,0
1282438,An empirical evaluation of doc2vec with practical insights into document embedding generation,2016,Jey Han Lau and Timothy Baldwin,,arXiv preprint arXiv:1607.05368,,,,Recently. Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al.. 2013a) to learn document-level embeddings. Despite promising results in the original paper. others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora. and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications. and release source code to induce document embeddings using our trained doc2vec models.,True,MFi65f4AAAAJ:_kc_bZDykSQC,491,https://arxiv.org/abs/1607.05368,18055614086067683623,/scholar?cites=18055614086067683623,,,https://arxiv.org/pdf/1607.05368.pdf?source=post_page---------------------------,0,0,0
1282439,Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality,2014,Jey Han Lau and David Newman and Timothy Baldwin,,,,530-539,,Topic models based on latent Dirichlet allocation and related methods are used in a range of user-focused tasks including document navigation and trend analysis. but evaluation of the intrinsic quality of the topic model and topics remains an open research area. In this work. we explore the two tasks of automatic evaluation of single topics and automatic evaluation of whole topic models. and provide recommendations on the best strategy for performing the two tasks. in addition to providing an open-source toolkit for topic and topic model evaluation.,True,MFi65f4AAAAJ:WF5omc3nYNoC,383,https://www.aclweb.org/anthology/E14-1056.pdf,15931045621530276059,/scholar?cites=15931045621530276059,,,https://www.aclweb.org/anthology/E14-1056.pdf,0,0,0
1282440,Automatic labelling of topic models,2011,Jey Han Lau and Karl Grieser and David Newman and Timothy Baldwin,,,,1536-1545,,We propose a method for automatically labelling topics learned via LDA topic models. We generate our label candidate set from the top-ranking topic terms. titles of Wikipedia articles containing the top-ranking topic terms. and sub-phrases extracted from the Wikipedia article titles. We rank the label candidates using a combination of association measures and lexical features. optionally fed into a supervised ranking model. Our method is shown to perform strongly over four independent sets of topics. significantly better than a benchmark method.,True,MFi65f4AAAAJ:u-x6o8ySG0sC,266,https://www.aclweb.org/anthology/P11-1154.pdf,12848868858959549459,/scholar?cites=12848868858959549459,,,https://www.aclweb.org/anthology/P11-1154.pdf,0,0,0
1282441,On-line trend analysis with topic models:# twitter trends detection topic model online,2012,Jey Han Lau and Nigel Collier and Timothy Baldwin,,,,1519-1534,,We present a novel topic modelling-based methodology to track emerging events in microblogs such as Twitter. Our topic model has an in-built update mechanism based on time slices and implements a dynamic vocabulary. We first show that the method is robust in detecting events using a range of datasets with injected novel events. and then demonstrate its application in identifying trending topics in Twitter.,True,MFi65f4AAAAJ:UeHWp8X0CEIC,231,https://www.aclweb.org/anthology/C12-1093.pdf,5165109288379937277,/scholar?cites=5165109288379937277,,,https://www.aclweb.org/anthology/C12-1093.pdf,0,0,0
1282442,Word sense induction for novel sense detection,2012,Jey Han Lau and Paul Cook and Diana McCarthy and David Newman and Timothy Baldwin,,,,591-601,,We apply topic modelling to automatically induce word senses of a target word. and demonstrate that our word sense induction method can be used to automatically detect words with emergent novel senses. as well as token occurrences of those senses. We start by exploring the utility of standard topic models for word sense induction (WSI). with a pre-determined number of topics (= senses). We next demonstrate that a non-parametric formulation that learns an appropriate number of senses per word actually performs better at the WSI task. We go on to establish state-of-the-art results over two WSI datasets. and apply the proposed model to a novel sense detection task.,True,MFi65f4AAAAJ:9yKSN-GCB0IC,148,https://www.aclweb.org/anthology/E12-1060.pdf,11161763437980084532,/scholar?cites=11161763437980084532,,,https://www.aclweb.org/anthology/E12-1060.pdf,0,0,0
1282443,Best topic word selection for topic labelling,2010,Jey Han Lau and David Newman and Sarvnaz Karimi and Timothy Baldwin,,,,605-613,,This paper presents the novel task of best topic word selection. that is the selection of the topic word that is the best label for a given topic. as a means of enhancing the interpretation and visualisation of topic models. We propose a number of features intended to capture the best topic word. and show that. in combination as inputs to a reranking model. we are able to consistently achieve results above the baseline of simply selecting the highest-ranked topic word. This is the case both when training in-domain over other labelled topics for that topic model. and cross-domain. using only labellings from independent topic models learned over document collections from different domains and genres.,True,MFi65f4AAAAJ:d1gkVwhDpl0C,120,https://www.aclweb.org/anthology/C10-2069.pdf,9880702594315278482,/scholar?cites=9880702594315278482,,,https://www.aclweb.org/anthology/C10-2069.pdf,0,0,0
1282444,Grammaticality. acceptability. and probability: A probabilistic view of linguistic knowledge,2017,Jey Han Lau and Alexander Clark and Shalom Lappin,41,Cognitive science,5,1202-1241,,The question of whether humans represent grammatical knowledge as a binary condition on membership in a set of well‐formed sentences. or as a probabilistic property has been the subject of debate among linguists. psychologists. and cognitive scientists for many decades. Acceptability judgments present a serious problem for both classical binary and probabilistic theories of grammaticality. These judgements are gradient in nature. and so cannot be directly accommodated in a binary formal grammar. However. it is also not possible to simply reduce acceptability to probability. The acceptability of a sentence is not the same as the likelihood of its occurrence. which is. in part. determined by factors like sentence length and lexical frequency. In this paper. we present the results of a set of large‐scale experiments using crowd‐sourced acceptability judgments that demonstrate gradience to be a pervasive feature in …,True,MFi65f4AAAAJ:M3ejUd6NZC8C,119,https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12414,12466300700324727794,/scholar?cites=12466300700324727794,,,https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/cogs.12414,0,0,0
1282445,Automatic detection and language identification of multilingual documents,2014,Marco Lui and Jey Han Lau and Timothy Baldwin,2,Transactions of the Association for Computational Linguistics,,27-40,MIT Press,Language identification is the task of automatically detecting the language(s)                     present in a document based on the content of the document. In this work. we                     address the problem of detecting documents that contain text from more than one                     language (multilingual documents). We introduce a                     method that is able to detect that a document is multilingual. identify the                     languages present. and estimate their relative proportions. We demonstrate the                     effectiveness of our method over synthetic data. as well as real-world                     multilingual documents collected from the web.,True,MFi65f4AAAAJ:eQOLeE2rZwMC,106,https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00163,8122041644317097484,/scholar?cites=8122041644317097484,,,https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00163,0,0,0
1282446,On collocations and topic models,2013,Jey Han Lau and Timothy Baldwin and David Newman,10,ACM Transactions on Speech and Language Processing (TSLP),3,1-14,ACM,We investigate the impact of preextracting and tokenizing bigram collocations on topic models. Using extensive experiments on four different corpora. we show that incorporating bigram collocations in the document representation creates more parsimonious models and improves topic coherence. We point out some problems in interpreting test likelihood and test perplexity to compare model fit. and suggest an alternate measure that penalizes model complexity. We show how the Akaike information criterion is a more appropriate measure. which suggests that using a modest number (up to 1000) of top-ranked bigrams is the optimal topic modelling configuration. Using these 1000 bigrams also results in improved topic quality over unigram tokenization. Further increases in topic quality can be achieved by using up to 10.000 bigrams. but this is at the cost of a more complex model. We also show that multiword …,True,MFi65f4AAAAJ:Tyk-4Ss8FVUC,65,https://dl.acm.org/doi/abs/10.1145/2483969.2483972,7209831077523515343,/scholar?cites=7209831077523515343,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.9298&rep=rep1&type=pdf,0,0,0
1282447,Bayesian text segmentation for index term identification and keyphrase extraction,2012,David Newman and Nagendra Koilada and Jey Han Lau and Timothy Baldwin,,,,2077-2092,,Automatically extracting terminology and index terms from scientific literature is useful for a variety of digital library. indexing and search applications. This task is non-trivial. complicated by domain-specific terminology and a steady introduction of new terminology. Correctly identifying nested terminology further adds to the challenge. We present a Dirichlet Process (DP) model of word segmentation where multiword segments are either retrieved from a cache or newly generated. We show how this DP-Segmentation model can be used to successfully extract nested terminology. outperforming previous methods for solving this problem.,True,MFi65f4AAAAJ:qjMakFHDy7sC,59,https://www.aclweb.org/anthology/C12-1127.pdf,2491279115202924460,/scholar?cites=2491279115202924460,,,https://www.aclweb.org/anthology/C12-1127.pdf,0,0,0
1282448,Exploring generalization in deep learning,2017,Behnam Neyshabur and Srinadh Bhojanapalli and David McAllester and Nathan Srebro,,arXiv preprint arXiv:1706.08947,,,,With a goal of understanding what drives generalization in deep networks. we consider several recently suggested explanations. including norm-based control. sharpness and robustness. We study how these measures can ensure generalization. highlighting the importance of scale normalization. and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.,True,e1ucbCYAAAAJ:XiSMed-E-HIC,559,https://arxiv.org/abs/1706.08947,16285731102067380229,/scholar?cites=16285731102067380229,,,https://arxiv.org/pdf/1706.08947,0,0,0
1282449,Norm-Based Capacity Control in Neural Networks,2015,Behnam Neyshabur and Ryota Tomioka and Nathan Srebro,,,,1376–1401,,We investigate the capacity. convexity and characterization of a general family of norm-constrained feed-forward networks.,True,e1ucbCYAAAAJ:b0M2c_1WBrUC,317,http://proceedings.mlr.press/v40/Neyshabur15.pdf,6683231698507768780,/scholar?cites=6683231698507768780,,,http://proceedings.mlr.press/v40/Neyshabur15.pdf,0,0,0
1282450,Stronger generalization bounds for deep nets via a compression approach,2018,Sanjeev Arora and Rong Ge and Behnam Neyshabur and Yi Zhang,,The 35th International Conference on Machine Learning,,,,Deep nets generalize well despite having more parameters than the number of training samples. Recent works try to give an explanation using PAC-Bayes and Margin-based analyses. but do not as yet result in sample complexity bounds better than naive parameter counting. The current paper shows generalization bounds that are orders of magnitude better in practice. These rely upon new succinct reparametrizations of the trained net—a compression that is explicit and efficient. These yield generalization bounds via a simple compression-based framework introduced here. Our results also provide some theoretical justification for widespread empirical success in compressing deep nets. Analysis of correctness of our compression relies upon some newly identified noise stability properties of trained deep nets. which are also experimentally verified. The study of these properties and resulting generalization bounds are also extended to convolutional nets. which had eluded earlier attempts on proving generalization.,True,e1ucbCYAAAAJ:K3LRdlH-MEoC,311,http://proceedings.mlr.press/v80/arora18b.html,2741843082009546935,/scholar?cites=2741843082009546935,,,http://proceedings.mlr.press/v80/arora18b/arora18b.pdf,0,0,0
1282451,Global Optimality of Local Search for Low Rank Matrix Recovery,2016,Srinadh Bhojanapalli and Behnam Neyshabur and Nathan Srebro,,Advances in Neural Information Processing Systems,,,,We show that there are no spurious local minima in the non-convex factorized parametrization of low-rank matrix recovery from incoherent linear measurements. With noisy measurements we show all local minima are very close to a global optimum. Together with a curvature bound at saddle points. this yields a polynomial time global convergence guarantee for stochastic gradient descent {\em from random initialization}.,True,e1ucbCYAAAAJ:1sJd4Hv_s6UC,303,https://arxiv.org/abs/1605.07221,13377495735395555335,/scholar?cites=13377495735395555335,,,https://arxiv.org/pdf/1605.07221,0,0,0
1282452,A pac-bayesian approach to spectrally-normalized margin bounds for neural networks,2018,Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro,,International Conference on Learning Representations,,,,We present a generalization bound for feedforward neural networks in terms of the product of the spectral norm of the layers and the Frobenius norm of the weights. The generalization bound is derived using a PAC-Bayes analysis.,True,e1ucbCYAAAAJ:Tiz5es2fbqcC,283,https://arxiv.org/abs/1707.09564,13808344181878972186,/scholar?cites=13808344181878972186,,,https://arxiv.org/pdf/1707.09564,0,0,0
1282453,In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning,2015,Behnam Neyshabur and Ryota Tomioka and Nathan Srebro,,,,,,We present experiments demonstrating that some other form of capacity control. different from network size. plays a central role in learning multilayer feed-forward networks. We argue. partially through analogy to matrix factorization. that this is an inductive bias that can help shed light on deep learning.,True,e1ucbCYAAAAJ:qjMakFHDy7sC,281,https://arxiv.org/abs/1412.6614,8011606804885210624,/scholar?cites=8011606804885210624,,,https://arxiv.org/pdf/1412.6614,0,0,0
1282454,Towards understanding the role of over-parametrization in generalization of neural networks,2019,Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro,,International Conference on Learning Representations,,,,Despite existing work on ensuring generalization of neural networks in terms of scale sensitive complexity measures. such as norms. margin and sharpness. these complexity measures do not offer an explanation of why neural networks generalize better with over-parametrization. In this work we suggest a novel complexity measure based on unit-wise capacities resulting in a tighter generalization bound for two layer ReLU networks. Our capacity bound correlates with the behavior of test error with increasing network sizes. and could potentially explain the improvement in generalization with over-parametrization. We further present a matching lower bound for the Rademacher complexity that improves over previous capacity lower bounds for neural networks.,True,e1ucbCYAAAAJ:l7t_Zn2s7bgC,251,https://arxiv.org/abs/1805.12076,2151067408903394186,/scholar?cites=2151067408903394186,,,https://arxiv.org/pdf/1805.12076,0,0,0
1282455,Path-SGD: Path-Normalized Optimization in Deep Neural Networks,2015,Behnam Neyshabur and Ruslan R Salakhutdinov and Nati Srebro,,,,2413-2421,,We revisit the choice of SGD for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights. We argue for a geometry invariant to rescaling of weights that does not affect the output of the network. and suggest Path-SGD. which is an approximate steepest descent method with respect to a path-wise regularizer related to max-norm regularization. Path-SGD is easy and efficient to implement and leads to empirical gains over SGD and AdaGrad.,True,e1ucbCYAAAAJ:abG-DnoFyZgC,204,https://arxiv.org/abs/1506.02617,12301555299485246692,/scholar?cites=12301555299485246692,,,https://arxiv.org/pdf/1506.02617,0,0,0
1282456,Implicit regularization in matrix factorization,2018,Suriya Gunasekar and Blake Woodworth and Srinadh Bhojanapalli and Behnam Neyshabur and Nathan Srebro,,,,1-10,IEEE,We study implicit regularization when optimizing an underdetermined quadratic objective over a matrix X with gradient descent on a factorization of X. We conjecture and provide empirical and theoretical evidence that with small enough step sizes and initialization close enough to the origin. gradient descent on a full dimensional factorization converges to the minimum nuclear norm solution.,True,e1ucbCYAAAAJ:u9iWguZQMMsC,191,https://ieeexplore.ieee.org/abstract/document/8503198/,3067147835319733002,/scholar?cites=3067147835319733002,,,https://arxiv.org/pdf/1705.09280,0,0,0
1282457,NETAL: a new graph-based method for global alignment of protein–protein interaction networks,2013,Behnam Neyshabur and Ahmadreza Khadem and Somaye Hashemifar and Seyed Shahriar Arab,29,Bioinformatics,13,1654-1662,Oxford University Press, Motivation: The interactions among proteins and the resulting networks of such interactions have a central role in cell biology. Aligning these networks gives us important information. such as conserved complexes and evolutionary relationships. Although there have been several publications on the global alignment of protein networks; however. none of proposed methods are able to produce a highly conserved and meaningful alignment. Moreover. time complexity of current algorithms makes them impossible to use for multiple alignment of several large networks together. Results: We present a novel algorithm for the global alignment of protein–protein interaction networks. It uses a greedy method. based on the alignment scoring matrix. which is derived from both biological and topological information of input networks to find the best global network alignment. NETAL outperforms other global …,True,e1ucbCYAAAAJ:9yKSN-GCB0IC,163,https://academic.oup.com/bioinformatics/article-abstract/29/13/1654/185807,8408227120897136155,/scholar?cites=8408227120897136155,,,https://academic.oup.com/bioinformatics/article/29/13/1654/185807,0,0,0
1282458,On Symmetric and Asymmetric LSHs for Inner Product Search,2015,Behnam Neyshabur and Nathan Srebro,,,,1926–1934,,We consider the problem of designing locality sensitive hashes (LSH) for inner product similarity. and of the power of asymmetric hashes in this context. Shrivastava and Li (2014a) argue that there is no symmetric LSH for the problem and propose an asymmetric LSH based on different mappings for query and database points. However. we show there does exist a simple symmetric LSH that enjoys stronger guarantees and better empirical performance than the asymmetric LSH they suggest. We also show a variant of the settings where asymmetry is in-fact needed. but there a different asymmetric LSH is required.,True,e1ucbCYAAAAJ:2osOgNQ5qMEC,144,http://proceedings.mlr.press/v37/neyshabur15.html,7573098365541111759,/scholar?cites=7573098365541111759,,,http://proceedings.mlr.press/v37/neyshabur15.pdf,0,0,0
1282459,Cloudlets: Bringing the cloud to the mobile user,2012,Tim Verbelen and Pieter Simoens and Filip De Turck and Bart Dhoedt,,,,29-36,,Although mobile devices are gaining more and more capabilities (ie CPU power. memory. connectivity....). they still fall short to execute complex rich media and data analysis applications. Offloading to the cloud is not always a solution. because of the high WAN latencies. especially for applications with real-time constraints such as augmented reality. Therefore the cloud has to be moved closer to the mobile user in the form of cloudlets. Instead of moving a complete virtual machine from the cloud to the cloudlet. we propose a more fine grained cloudlet concept that manages applications on a component level. Cloudlets do not have to be fixed infrastructure close to the wireless access point. but can be formed in a dynamic way with any device in the LAN network with available resources. We present a cloudlet architecture together with a prototype implementation. showing the advantages and capabilities for a mobile …,True,vAPWme0AAAAJ:iH-uZ7U-co4C,434,https://dl.acm.org/doi/abs/10.1145/2307849.2307858,13855361026585648836,/scholar?cites=13855361026585648836,,,https://biblio.ugent.be/publication/2984272/file/2984273.pdf,0,0,0
1282460,Edge analytics in the internet of things,2015,Mahadev Satyanarayanan and Pieter Simoens and Yu Xiao and Padmanabhan Pillai and Zhuo Chen and Kiryong Ha and Wenlu Hu and Brandon Amos,14,IEEE Pervasive Computing,2,24-31,IEEE,High-data-rate sensors. such as video cameras. are becoming ubiquitous in the Internet of Things. This article describes GigaSight. an Internet-scale repository of crowd-sourced video content. with strong enforcement of privacy preferences and access controls. The GigaSight architecture is a federated system of VM-based cloudlets that perform video analytics at the edge of the Internet. thus reducing the demand for ingress bandwidth into the cloud. Denaturing. which is an owner-specific reduction in fidelity of video content to preserve privacy. is one form of analytics on cloudlets. Content-based indexing for search is another form of cloudlet-based analytics. This article is part of a special issue on smart spaces.,True,vAPWme0AAAAJ:fPk4N6BV_jEC,405,https://ieeexplore.ieee.org/abstract/document/7093020/,13452249657153372859,/scholar?cites=13452249657153372859,,,https://biblio.ugent.be/publication/8037874/file/8037883,0,0,0
1282461,Scalable crowd-sourcing of video from mobile devices,2013,Pieter Simoens and Yu Xiao and Padmanabhan Pillai and Zhuo Chen and Kiryong Ha and Mahadev Satyanarayanan,,,,139-152,,We propose a scalable Internet system for continuous collection of crowd-sourced video from devices such as Google Glass. Our hybrid cloud architecture. GigaSight. is effectively a Content Delivery Network (CDN) in reverse. It achieves scalability by decentralizing the collection infrastructure using cloudlets based on virtual machines~(VMs). Based on time. location. and content. privacy sensitive information is automatically removed from the video. This process. which we refer to as denaturing. is executed in a user-specific VM on the cloudlet. Users can perform content-based searches on the total catalog of denatured videos. Our experiments reveal the bottlenecks for video upload. denaturing. indexing. and content-based search. They also provide insight on how parameters such as frame rate and resolution impact scalability.,True,vAPWme0AAAAJ:blknAaTinKkC,191,https://dl.acm.org/doi/abs/10.1145/2462456.2464440,2298789583900678096,/scholar?cites=2298789583900678096,,,https://biblio.ugent.be/publication/4235406/file/4235424.pdf,0,0,0
1282462,Lowering the barriers to large-scale mobile crowdsensing,2013,Yu Xiao and Pieter Simoens and Padmanabhan Pillai and Kiryong Ha and Mahadev Satyanarayanan,,,,1-6,,Mobile crowdsensing is becoming a vital technique for environment monitoring. infrastructure management. and social computing. However. deploying mobile crowdsensing applications in large-scale environments is not a trivial task. It creates a tremendous burden on application developers as well as mobile users. In this paper we try to reveal the barriers hampering the scale-up of mobile crowdsensing applications. and to offer our initial thoughts on the potential solutions to lowering the barriers.,True,vAPWme0AAAAJ:JV2RwH3_ST0C,135,https://dl.acm.org/doi/abs/10.1145/2444776.2444789,17665226253661008457,/scholar?cites=17665226253661008457,,,https://biblio.ugent.be/publication/3259159/file/3259160.pdf,0,0,0
1282463,The Internet of Robotic Things: A review of concept. added value and applications,2018,Pieter Simoens and Mauro Dragone and Alessandro Saffiotti,15,,1,1729881418759424,Sage Publications,The Internet of Robotic Things is an emerging vision that brings together pervasive sensors and objects with robotic and autonomous systems. This survey examines how the merger of robotic and Internet of Things technologies will advance the abilities of both the current Internet of Things and the current robotic systems. thus enabling the creation of new. potentially disruptive services. We discuss some of the new technological challenges created by this merger and conclude that a truly holistic view is needed but currently lacking.,True,vAPWme0AAAAJ:V3AGJWp-ZtQC,112,https://journals.sagepub.com/doi/abs/10.1177/1729881418759424,488730368284135512,/scholar?cites=488730368284135512,,,https://journals.sagepub.com/doi/pdf/10.1177/1729881418759424,0,0,0
1282464,Remote display solutions for mobile cloud computing,2011,Pieter Simoens and Filip De Turck and Bart Dhoedt and Piet Demeester,44,Computer,8,46-53,IEEE,Proposed optimization techniques address the major challenges that varying wireless channel conditions. short battery lifetime. and interaction latency pose for the remote display of cloud applications on mobile devices.,True,vAPWme0AAAAJ:hqOjcs7Dif8C,111,https://ieeexplore.ieee.org/abstract/document/5722945/,17298716555492873714,/scholar?cites=17298716555492873714,,,https://www.researchgate.net/profile/Piet_Demeester/publication/220478488_Remote_Display_Solutions_for_Mobile_Cloud_Computing/links/53ea28bc0cf2fb1b9b67671c.pdf,0,0,0
1282465,A hybrid thin-client protocol for multimedia streaming and interactive gaming applications,2006,Davy De Winter and Pieter Simoens and Lien Deboosere and Filip De Turck and Joris Moreau and Bart Dhoedt and Piet Demeester,,,,1-6,,Despite the growing popularity and advantages of thin-client systems. they still have some important shortcomings. Current thin-client systems are ideally suited to be used with classic office-applications but as soon as multimedia and 3D gaming applications are used they require a large amount of bandwidth and processing power. Furthermore. most of these applications heavily rely on the Graphical Processing Unit (GPU). Due to the architectural design of thin-client systems. they cannot profit from the GPU resulting in slow performance and bad image quality. In this paper. we propose a thin-client system which addresses these problems: we introduce a realtime desktopstreamer using a videocodec to stream the graphical output of applications after GPU-processing to a thin-client device. capable of decoding a videostream. We compare this approach to a number of popular classic thin-client systems in terms of …,True,vAPWme0AAAAJ:u5HHmVD_uO8C,110,https://dl.acm.org/doi/abs/10.1145/1378191.1378210,3974867141453081993,/scholar?cites=3974867141453081993,,,https://biblio.ugent.be/publication/340395/file/566552.pdf,0,0,0
1282466,AIOLOS: Middleware for improving mobile application performance through cyber foraging,2012,Tim Verbelen and Pieter Simoens and Filip De Turck and Bart Dhoedt,85,Journal of Systems and Software,11,2629-2639,Elsevier,As the popularity of smartphones and tablets increases. the mobile platform is becoming a very important target for application developers. Despite recent advances in mobile hardware. most mobile devices fail to execute complex multimedia applications (such as image processing) with an acceptable level of user experience. Cyber foraging is a well-known computing technique to enhance the capabilities of mobile devices. where the mobile device offloads parts of the application to a nearby discovered server in the network.Although first introduced in 2001. cyber foraging is still not widely adopted in current smartphone platforms or applications. In this respect. two major challenges are to be tackled. First. a suitable adaptive decision engine is needed to determine the optimal offloading decision. that takes into account the potentially high and variable latency between the device and the server. Second. an …,True,vAPWme0AAAAJ:j3f4tGmQtD8C,104,https://www.sciencedirect.com/science/article/pii/S0164121212001641,16347764145464628037,/scholar?cites=16347764145464628037,,,https://biblio.ugent.be/publication/3003886/file/3003888.pdf,0,0,0
1282467,Interoperability for industrial cyber-physical systems: An approach for legacy systems,2017,Omid Givehchi and Klaus Landsdorf and Pieter Simoens and Armando Walter Colombo,13,IEEE Transactions on Industrial Informatics,6,3370-3378,IEEE,Contemporary industrial systems are challenged by fast-growing requirements for agile and effective reactivity to rapidly changing market demands. To achieve this set of requirements. new technologies and paradigms like Internet-of-Things (IoT). Big Data Analytics. Internet-of-Services (IoS). and service-oriented architecture (SOA) are being introduced into the industrial environments. These advances result in the confluence of two dissimilar. but complementary domains: the physical operational technologies (OT) and the cyber information technologies (IT) domains. Convergence of these two domains in a cross-layer fashion implies a new set of two major requirements of components and systems: 1) structural connectivity and 2) functional interoperability. However. the wide variety and heterogeneity of industrial systems-especially in the factory floor-entails integration complexity. which is in contrast with the …,True,vAPWme0AAAAJ:eflP2zaiRacC,90,https://ieeexplore.ieee.org/abstract/document/8012471/,7246825723585769163,/scholar?cites=7246825723585769163,,,,0,0,0
1282468,Design and implementation of a hybrid remote display protocol to optimize multimedia experience on thin client devices,2008,Pieter Simoens and Paul Praet and Bert Vankeirsbilck and Jeroen De Wachter and Lien Deboosere and Filip De Turck and Bart Dhoedt and Piet Demeester,,,,391-396,IEEE,In a thin client computing architecture. application processing is delegated to a remote server rather than running the application locally. User input is forwarded to the server. and the rendered images are relayed through a dedicated remote display protocol to the user's device. Existing remote display protocols have been successfully optimized for applications with only minor and low-frequent screen updates. such as a spreadsheet or a text editor. However. they are not designed to cope with the fine-grained and complex color patterns of multimedia applications. leading to high bandwidth requirements and an irresponsive user interface. In this article. a hybrid remote display protocol approach is presented. The existing Remote FrameBuffer protocol of Virtual Network Computing (VNC-RFB) protocol is leveraged with a video streaming mode to transport the rendered images of multimedia applications to the client …,True,vAPWme0AAAAJ:u-x6o8ySG0sC,78,https://ieeexplore.ieee.org/abstract/document/4783356/,3559265569212077379,/scholar?cites=3559265569212077379,,,,0,0,0
1282469,An autonomic architecture for optimizing QoE in multimedia access networks,2009,Steven Latré and Pieter Simoens and Bart De Vleeschauwer and Wim Van de Meerssche and Filip De Turck and Bart Dhoedt and Piet Demeester and Steven Van den Berghe and Edith Gilon de Lumley,53,Computer Networks,10,1587-1602,Elsevier,The recent emergence of multimedia services. such as Broadcast TV and Video on Demand over traditional twisted pair access networks. has complicated the network management in order to guarantee a decent Quality of Experience (QoE) for each user. The huge amount of services and the wide variety of service specifics require a QoE management on a per-user and per-service basis. This complexity can be tackled through the design of an autonomic QoE management architecture. In this article. the Knowledge Plane is presented as an autonomic layer that optimizes the QoE in multimedia access networks from the service originator to the user. It autonomously detects network problems. e.g. a congested link. bit errors on a link. etc. and determines an appropriate corrective action. e.g. switching to a lower bit rate video. adding an appropriate number of FEC packets. etc. The generic Knowledge Plane …,True,vAPWme0AAAAJ:UeHWp8X0CEIC,63,https://www.sciencedirect.com/science/article/pii/S138912860800385X,9006328340166320226,/scholar?cites=9006328340166320226,,,https://www.academia.edu/download/47778118/An_autonomic_architecture_for_optimizing20160804-9414-rxmvq0.pdf,0,0,0
1282470,SignalP 5.0 improves signal peptide predictions using deep neural networks,2019,José Juan Almagro Armenteros and Konstantinos D Tsirigos and Casper Kaae Sønderby and Thomas Nordahl Petersen and Ole Winther and Søren Brunak and Gunnar von Heijne and Henrik Nielsen,37,Nature biotechnology,4,420-423,Nature Publishing Group,Signal peptides (SPs) are short amino acid sequences in the amino terminus of many newly synthesized proteins that target proteins into. or across. membranes. Bioinformatic tools can predict SPs from amino acid sequences. but most cannot distinguish between various types of signal peptides. We present a deep neural network-based approach that improves SP prediction across all domains of life and distinguishes between three types of prokaryotic SPs.,True,yzGdbKoAAAAJ:t6usbXjVLHcC,1044,https://www.nature.com/articles/s41587-019-0036-z,2655486919304765530,/scholar?cites=2655486919304765530,,,https://static-curis.ku.dk/portal/files/248820641/SignalP_5.0_improves_signal_peptide_predictions_using_deep_neural_networks_accepted_version_.pdf,0,0,0
1282471,Ladder variational autoencoders,2016,Casper Kaae Sønderby and Tapani Raiko and Lars Maaløe and Søren Kaae Sønderby and Ole Winther,,Neural Information Processing Systems,,,,Variational Autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difficult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model. the Ladder Variational Autoencoder. that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally. we observe that batch normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.,True,yzGdbKoAAAAJ:geHnlv5EZngC,549,https://arxiv.org/abs/1602.02282,1323199474868567922,/scholar?cites=1323199474868567922,,,https://arxiv.org/pdf/1602.02282,0,0,0
1282472,DeepLoc: prediction of protein subcellular localization using deep learning,2017,José Juan Almagro Armenteros and Casper Kaae Sønderby and Søren Kaae Sønderby and Henrik Nielsen and Ole Winther,33,Bioinformatics,21,3387-3395,Oxford University Press,The prediction of eukaryotic protein subcellular localization is a well-studied topic in bioinformatics due to its relevance in proteomics research. Many machine learning methods have been successfully applied in this task. but in most of them. predictions rely on annotation of homologues from knowledge databases. For novel proteins where no annotated homologues exist. and for predicting the effects of sequence variants. it is desirable to have methods for predicting protein properties from sequence information only.Here. we present a prediction algorithm using deep neural networks to predict protein subcellular localization relying only on sequence information. At its core. the prediction model uses a recurrent neural network that processes the entire protein sequence and an attention mechanism identifying protein regions important for the subcellular …,True,yzGdbKoAAAAJ:eflP2zaiRacC,383,https://academic.oup.com/bioinformatics/article-abstract/33/21/3387/3931857,7413692343247828180,/scholar?cites=7413692343247828180,,,https://academic.oup.com/bioinformatics/article/33/21/3387/3931857,0,0,0
1282473,Auxiliary deep generative models,2016,Lars Maaløe and Casper Kaae Sønderby and Søren Kaae Sønderby and Ole Winther,,,,1445-1453,PMLR,Deep generative models parameterized by neural networks have recently achieved state-of-the-art performance in unsupervised and semi-supervised learning. We extend deep generative models with auxiliary variables which improves the variational approximation. The auxiliary variables leave the generative model unchanged but make the variational distribution more expressive. Inspired by the structure of the auxiliary variable we also propose a model with two stochastic layers and skip connections. Our findings suggest that more expressive and properly specified deep generative models converge faster with better results. We show state-of-the-art performance within semi-supervised learning on MNIST. SVHN and NORB datasets.,True,yzGdbKoAAAAJ:B3FOqHPlNUQC,361,http://proceedings.mlr.press/v48/maaloe16.html,9120124950708918697,/scholar?cites=9120124950708918697,,,http://proceedings.mlr.press/v48/maaloe16.pdf,0,0,0
1282474,Amortised map inference for image super-resolution,2016,Casper Kaae Sønderby and Jose Caballero and Lucas Theis and Wenzhe Shi and Ferenc Huszár,,International Conference on Learning Representations (ICLR),,,,Image super-resolution (SR) is an underdetermined inverse problem. where a large number of plausible high-resolution images can explain the same downsampled image. Most current single image SR methods use empirical risk minimisation. often with a pixel-wise mean squared error (MSE) loss. However. the outputs from such methods tend to be blurry. over-smoothed and generally appear implausible. A more desirable approach would employ Maximum a Posteriori (MAP) inference. preferring solutions that always have a high probability under the image prior. and thus appear more plausible. Direct MAP estimation for SR is non-trivial. as it requires us to build a model for the image prior from samples. Furthermore. MAP inference is often performed via optimisation-based iterative algorithms which don't compare well with the efficiency of neural-network-based alternatives. Here we introduce new methods for amortised MAP inference whereby we calculate the MAP estimate directly using a convolutional neural network. We first introduce a novel neural network architecture that performs a projection to the affine subspace of valid SR solutions ensuring that the high resolution output of the network is always consistent with the low resolution input. We show that. using this architecture. the amortised MAP inference problem reduces to minimising the cross-entropy between two distributions. similar to training generative models. We propose three methods to solve this optimisation problem:(1) Generative Adversarial Networks (GAN)(2) denoiser-guided SR which backpropagates gradient-estimates from denoising to train the network. and (3) a …,True,yzGdbKoAAAAJ:BrmTIyaxlBUC,345,https://arxiv.org/abs/1610.04490,14286004747394736744,/scholar?cites=14286004747394736744,,,https://arxiv.org/pdf/1610.04490,0,0,0
1282475,BloodSpot: a database of gene expression profiles and transcriptional programs for healthy and malignant haematopoiesis,2016,Frederik Otzen Bagger and Damir Sasivarevic and Sina Hadi Sohi and Linea Gøricke Laursen and Sachin Pundhir and Casper Kaae Sønderby and Ole Winther and Nicolas Rapin and Bo T Porse,44,Nucleic acids research,D1,D917-D924,Oxford University Press,Research on human and murine haematopoiesis has resulted in a vast number of gene-expression data sets that can potentially answer questions regarding normal and aberrant blood formation. To researchers and clinicians with limited bioinformatics experience. these data have remained available. yet largely inaccessible. Current databases provide information about gene-expression but fail to answer key questions regarding co-regulation. genetic programs or effect on patient survival. To address these shortcomings. we present BloodSpot (www.bloodspot.eu). which includes and greatly extends our previously released database HemaExplorer. a database of gene expression profiles from FACS sorted healthy and malignant haematopoietic cells. A revised interactive interface simultaneously provides a plot of gene expression along with a Kaplan–Meier analysis and a hierarchical tree depicting the …,True,yzGdbKoAAAAJ:UxriW0iASnsC,181,https://academic.oup.com/nar/article-abstract/44/D1/D917/2502611,115595938798467566,/scholar?cites=115595938798467566,,,https://academic.oup.com/nar/article/44/D1/D917/2502611,0,0,0
1282476,Orientationally invariant metrics of apparent compartment eccentricity from double pulsed field gradient diffusion experiments,2013,Sune Nørhøj Jespersen and Henrik Lundell and Casper Kaae Sønderby and Tim B Dyrby,26,NMR in Biomedicine,12,1647-1662,,Pulsed field gradient diffusion sequences (PFG) with multiple diffusion encoding blocks have been indicated to offer new microstructural tissue information. such as the ability to detect nonspherical compartment shapes in macroscopically isotropic samples. i.e. samples with negligible directional signal dependence on diffusion gradients in standard diffusion experiments. However. current acquisition schemes are not rotationally invariant in the sense that the derived metrics depend on the orientation of the sample. and are affected by the interplay of sampling directions and compartment orientation dispersion when applied to macroscopically anisotropic systems. Here we propose a new framework. the d‐PFG 5‐design. to enable rotationally invariant estimation of double wave vector diffusion metrics (d‐PFG). The method is based on the idea that an appropriate orientational average of the signal emulates the …,True,yzGdbKoAAAAJ:u5HHmVD_uO8C,167,https://onlinelibrary.wiley.com/doi/abs/10.1002/nbm.2999,10376072512665415826,/scholar?cites=10376072512665415826,,,https://www.academia.edu/download/45600012/Orientationally_invariant_metrics_of_app20160513-24524-1r59078.pdf,0,0,0
1282477,NetSurfP‐2.0: Improved prediction of protein structural features by integrated deep learning,2019,Michael Schantz Klausen and Martin Closter Jespersen and Henrik Nielsen and Kamilla Kjærgaard Jensen and Vanessa Isabell Jurtz and Casper Kaae Sønderby and Morten Otto Alexander Sommer and Ole Winther and Morten Nielsen and Bent Petersen and Paolo Marcatili,87,"Proteins: Structure, Function, and Bioinformatics",6,520-527,John Wiley & Sons. Inc.,The ability to predict local structural features of a protein from the primary sequence is of paramount importance for unraveling its function in absence of experimental structural information. Two main factors affect the utility of potential prediction tools: their accuracy must enable extraction of reliable structural information on the proteins of interest. and their runtime must be low to keep pace with sequencing data being generated at a constantly increasing speed. Here. we present NetSurfP‐2.0. a novel tool that can predict the most important local structural features with unprecedented accuracy and runtime. NetSurfP‐2.0 is sequence‐based and uses an architecture composed of convolutional and long short‐term memory neural networks trained on solved protein structures. Using a single integrated model. NetSurfP‐2.0 predicts solvent accessibility. secondary structure. structural disorder. and backbone dihedral …,True,yzGdbKoAAAAJ:V3AGJWp-ZtQC,160,https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.25674,14097196541272641248,/scholar?cites=14097196541272641248,,,https://www.biorxiv.org/content/biorxiv/early/2018/09/03/311209.full.pdf,0,0,0
1282478,Convolutional LSTM networks for subcellular localization of proteins,2015,Søren Kaae Sønderby and Casper Kaae Sønderby and Henrik Nielsen and Ole Winther,,,,68-80,Springer. Cham,Machine learning is widely used to analyze biological sequence data. Non-sequential models such as SVMs or feed-forward neural networks are often used although they have no natural way of handling sequences of varying length. Recurrent neural networks such as the long short term memory (LSTM) model on the other hand are designed to handle sequences. In this study we demonstrate that LSTM networks predict the subcellular location of proteins given only the protein sequence with high accuracy (0.902) outperforming current state of the art algorithms. We further improve the performance by introducing convolutional filters and experiment with an attention mechanism which lets the LSTM focus on specific parts of the protein. Lastly we introduce new visualizations of both the convolutional filters and the attention mechanisms and show how they can be used to extract biologically relevant …,True,yzGdbKoAAAAJ:abG-DnoFyZgC,103,https://link.springer.com/chapter/10.1007/978-3-319-21233-3_6,3681337782952482108,/scholar?cites=3681337782952482108,,,https://arxiv.org/pdf/1503.01919,0,0,0
1282479,An introduction to deep learning on biological sequence data: examples and solutions,2017,Vanessa Isabell Jurtz and Alexander Rosenberg Johansen and Morten Nielsen and Jose Juan Almagro Armenteros and Henrik Nielsen and Casper Kaae Sønderby and Ole Winther and Søren Kaae Sønderby,33,,22,3685-3690,Oxford University Press,Deep neural network architectures such as convolutional and long short-term memory networks have become increasingly popular as machine learning tools during the recent years. The availability of greater computational resources. more data. new algorithms for training deep models and easy to use libraries for implementation and training of neural networks are the drivers of this development. The use of deep learning has been especially successful in image recognition; and the development of tools. applications and code examples are in most cases centered within this field rather than within biology.Here. we aim to further the development of deep learning methods within biology by providing application examples and ready to apply and adapt code templates. Given such examples. we illustrate how architectures consisting of convolutional and long …,True,yzGdbKoAAAAJ:mvPsJ3kp5DgC,93,https://academic.oup.com/bioinformatics/article-abstract/33/22/3685/4092933,11369794735073244453,/scholar?cites=11369794735073244453,,,https://academic.oup.com/bioinformatics/article/33/22/3685/4092933,0,0,0
1282480,scVAE: Variational auto-encoders for single-cell gene expression data,2020,Christopher Heje Grønbech and Maximillian Fornitz Vording and Pascal N Timshel and Casper Kaae Sønderby and Tune H Pers and Ole Winther,36,Bioinformatics,16,4415-4422,Oxford University Press,Models for analysing and making relevant biological inferences from massive amounts of complex single-cell transcriptomic data typically require several individual data-processing steps. each with their own set of hyperparameter choices. With deep generative models one can work directly with count data. make likelihood-based model comparison. learn a latent representation of the cells and capture more of the variability in different cell populations.We propose a novel method based on variational auto-encoders (VAEs) for analysis of single-cell RNA sequencing (scRNA-seq) data. It avoids data preprocessing by using raw count data as input and can robustly estimate the expected gene expression levels and a latent representation for each cell. We tested several count likelihood functions and a variant of the VAE that has a priori clustering in the latent …,True,yzGdbKoAAAAJ:1qzjygNMrQYC,53,https://academic.oup.com/bioinformatics/article-abstract/36/16/4415/5838187,4625826432318554320,/scholar?cites=4625826432318554320,,,https://www.biorxiv.org/content/biorxiv/early/2018/05/16/318295.full.pdf,0,0,0
1282481,The loss surfaces of multilayer networks,2015,Anna Choromanska and Mikael Henaff and Michael Mathieu and Gérard Ben Arous and Yann LeCun,,,,192-204,PMLR,We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence. ii) redundancy in network parametrization. and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations. despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points. and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large-and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally. we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.,True,bX__wkYAAAAJ:zYLM7Y9cAGgC,1064,http://proceedings.mlr.press/v38/choromanska15.html,143561950809092309,/scholar?cites=143561950809092309,,,http://proceedings.mlr.press/v38/choromanska15.pdf,0,0,0
1282482,Deep convolutional networks on graph-structured data,2015,Mikael Henaff and Joan Bruna and Yann LeCun,,arXiv preprint arXiv:1506.05163,,,,Deep Learning's recent successes have mostly relied on Convolutional Networks. which exploit fundamental statistical properties of images. sounds and video data: the local stationarity and multi-scale compositional structure. that allows expressing long range interactions in terms of shorter. localized interactions. However. there exist other important examples. such as text documents or bioinformatic data. that may lack some or all of these strong statistical regularities.In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains. which are typically unknown and need to be estimated from the data. In particular. we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure. that we test on large-scale classification problems. matching or improving over Dropout Networks with far less parameters to estimate.,True,bX__wkYAAAAJ:Tyk-4Ss8FVUC,1030,https://arxiv.org/abs/1506.05163,4459997809532831395,/scholar?cites=4459997809532831395,,,https://arxiv.org/pdf/1506.05163,0,0,0
1282483,Fast Training of Convolutional Networks through FFTs,2013,Michael Mathieu and Mikael Henaff and Yann LeCun,,,,,,Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions. large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks. even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work. we present a simple algorithm which accelerates training and inference by a significant factor. and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.,True,bX__wkYAAAAJ:d1gkVwhDpl0C,508,https://arxiv.org/abs/1312.5851,13155039712048671611,/scholar?cites=13155039712048671611,,,https://arxiv.org/pdf/1312.5851,0,0,0
1282484,Tracking the World State with Recurrent Entity Networks,2017,Mikael Henaff and Jason Weston and Arthur Szlam and Antoine Bordes and Yann LeCun,,,,,,We introduce a new model. the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks. it can reason on-the-fly as it reads text. not just when it is required to answer a question or respond as is the case for a Memory Network (Sukhbaatar et al.. 2015). Like a Neural Turing Machine or Differentiable Neural Computer (Graves et al.. 2014; 2016) it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However. unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks. and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts. which other methods are not able to solve. and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test. where it obtains competitive performance. reading the story in a single pass.,True,bX__wkYAAAAJ:WF5omc3nYNoC,178,https://arxiv.org/abs/1612.03969,15954480746316535959,/scholar?cites=15954480746316535959,,,https://arxiv.org/pdf/1612.03969,0,0,0
1282485,Unsupervised learning of sparse features for scalable audio classification.,2011,Mikael Henaff and Kevin Jarrett and Koray Kavukcuoglu and Yann LeCun,11,ISMIR,445,2011,,In this work we present a system to automatically learn features from audio in an unsupervised manner. Our method first learns an overcomplete dictionary which can be used to sparsely decompose log-scaled spectrograms. It then trains an efficient encoder which quickly maps new inputs to approximations of their sparse representations using the learned dictionary. This avoids expensive iterative procedures usually required to infer sparse codes. We then use these sparse codes as inputs for a linear Support Vector Machine (SVM). Our system achieves 83.4% accuracy in predicting genres on the GTZAN dataset. which is competitive with current state-of-the-art approaches. Furthermore. the use of a simple linear classifier combined with a fast feature extraction system allows our approach to scale well to large datasets.,True,bX__wkYAAAAJ:u5HHmVD_uO8C,155,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.4659&rep=rep1&type=pdf,16183838811575312102,/scholar?cites=16183838811575312102,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.4659&rep=rep1&type=pdf,0,0,0
1282486,Recurrent Orthogonal Networks and Long-Memory Tasks,2016,Mikael Henaff and Arthur Szlam and Yann LeCun,,,,2034-2042,,Although RNNs have been shown to be power-ful tools for processing sequential data. finding architectures or optimization strategies that al-low them to model very long term dependencies is still an active area of research. In this work. we carefully analyze two synthetic datasets orig-inally outlined in (Hochreiter & Schmidhuber. 1997) which are used to evaluate the ability of RNNs to store information over many time steps. We explicitly construct RNN solutions to these problems. and using these constructions. illumi-nate both the problems themselves and the way in which RNNs store different types of information in their hidden states. These constructions fur-thermore explain the success of recent methods that specify unitary initializations or constraints on the transition matrices.,True,bX__wkYAAAAJ:YsMSGLbcyi4C,119,http://proceedings.mlr.press/v48/henaff16.html,7350202006332720546,/scholar?cites=7350202006332720546,,,http://proceedings.mlr.press/v48/henaff16.pdf,0,0,0
1282487,A comprehensive evaluation of multicategory classification methods for microbiomic data,2013,Alexander Statnikov and Mikael Henaff and Varun Narendra and Kranti Konganti and Zhiguo Li and Liying Yang and Zhiheng Pei and Martin J Blaser and Constantin F Aliferis and Alexander V Alekseyenko,1,Microbiome,1,1-12,BioMed Central,Recent advances in next-generation DNA sequencing enable rapid high-throughput quantitation of microbial community composition in human samples. opening up a new field of microbiomics. One of the promises of this field is linking abundances of microbial taxa to phenotypic and physiological states. which can inform development of new diagnostic. personalized medicine. and forensic modalities. Prior research has demonstrated the feasibility of applying machine learning methods to perform body site and subject classification with microbiomic data. However. it is currently unknown which classifiers perform best among the many available alternatives for classification with microbiomic data. In this work. we performed a systematic comparison of 18 major classification methods. 5 feature selection methods. and 2 accuracy metrics using 8 datasets spanning 1.802 human samples and various classification tasks: body site and subject classification and diagnosis. We found that random forests. support vector machines. kernel ridge regression. and Bayesian logistic regression with Laplace priors are the most effective machine learning techniques for performing accurate classification from these microbiomic data.,True,bX__wkYAAAAJ:9yKSN-GCB0IC,115,https://microbiomejournal.biomedcentral.com/articles/10.1186/2049-2618-1-11,12778481921148688584,/scholar?cites=12778481921148688584,,,https://microbiomejournal.biomedcentral.com/articles/10.1186/2049-2618-1-11,0,0,0
1282488,Microbiomic signatures of psoriasis: feasibility and methodology comparison,2013,Alexander Statnikov and Alexander V Alekseyenko and Zhiguo Li and Mikael Henaff and Guillermo I Perez-Perez and Martin J Blaser and Constantin F Aliferis,3,Scientific reports,1,1-7,Nature Publishing Group,Psoriasis is a common chronic inflammatory disease of the skin. We sought to use bacterial community abundance data to assess the feasibility of developing multivariate molecular signatures for differentiation of cutaneous psoriatic lesions. clinically unaffected contralateral skin from psoriatic patients and similar cutaneous loci in matched healthy control subjects. Using 16S rRNA high-throughput DNA sequencing. we assayed the cutaneous microbiome for 51 such matched specimen triplets including subjects of both genders. different age groups. ethnicities and multiple body sites. None of the subjects had recently received relevant treatments or antibiotics. We found that molecular signatures for the diagnosis of psoriasis result in significant accuracy ranging from 0.75 to 0.89 AUC. depending on the classification task. We also found a significant effect of DNA sequencing and downstream analysis protocols on the …,True,bX__wkYAAAAJ:2osOgNQ5qMEC,74,https://www.nature.com/articles/srep02620,18007573978859186222,/scholar?cites=18007573978859186222,,,https://www.nature.com/articles/srep02620,0,0,0
1282489,Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic,2019,Mikael Henaff and Alfredo Canziani and Yann LeCun,,,,,,Learning a policy using only observational data is challenging because the distribution of states it induces at execution time may differ from the distribution observed during training. We propose to train a policy by unrolling a learned model of the environment dynamics over multiple time steps while explicitly penalizing two costs: the original cost the policy seeks to optimize. and an uncertainty cost which represents its divergence from the states it is trained on. We measure this second cost by using the uncertainty of the dynamics model about its own predictions. using recent ideas from uncertainty estimation for deep networks. We evaluate our approach using a large-scale observational dataset of driving behavior recorded from traffic cameras. and show that we are able to learn effective driving policies from purely observational data. with no environment interaction.,True,bX__wkYAAAAJ:0EnyYjriUFMC,51,https://arxiv.org/abs/1901.02705,5048415252406845644,/scholar?cites=5048415252406845644,,,https://arxiv.org/pdf/1901.02705,0,0,0
1282490,Model-Based Planning with Discrete and Continuous Actions,2018,Mikael Henaff and William F Whitney and Yann LeCun,,arXiv preprint arXiv:1705.07177,,,,Action planning using learned and differentiable forward models of the world is a general approach which has a number of desirable properties. including improved sample complexity over model-free RL methods. reuse of learned models across different tasks. and the ability to perform efficient gradient-based optimization in continuous action spaces. However. this approach does not apply straightforwardly when the action space is discrete. In this work. we show that it is in fact possible to effectively perform planning via backprop in discrete action spaces. using a simple paramaterization of the actions vectors on the simplex combined with input noise when training the forward model. Our experiments show that this approach can match or outperform model-free RL and discrete planning methods on gridworld navigation tasks in terms of performance and/or planning time while using limited environment interactions. and can additionally be used to perform model-based control in a challenging new task where the action space combines discrete and continuous actions. We furthermore propose a policy distillation approach which yields a fast policy network which can be used at inference time. removing the need for an iterative planning procedure.,True,bX__wkYAAAAJ:_FxGoFyzp5QC,38,https://arxiv.org/abs/1705.07177,993821491969566870,/scholar?cites=993821491969566870,,,https://arxiv.org/pdf/1705.07177,0,0,0
1282491,Information content and analysis methods for multi-modal high-throughput biomedical data,2014,Bisakha Ray and Mikael Henaff and Sisi Ma and Efstratios Efstathiadis and Eric R Peskin and Marco Picone and Tito Poli and Constantin F Aliferis and Alexander Statnikov,4,Scientific reports,1,1-10,Nature Publishing Group,The spectrum of modern molecular high-throughput assaying includes diverse technologies such as microarray gene expression. miRNA expression. proteomics. DNA methylation. among many others. Now that these technologies have matured and become increasingly accessible. the next frontier is to collect “multi-modal” data for the same set of subjects and conduct integrative. multi-level analyses. While multi-modal data does contain distinct biological information that can be useful for answering complex biology questions. its value for predicting clinical phenotypes and contributions of each type of input remain unknown. We obtained 47 datasets/predictive tasks that in total span over 9 data modalities and executed analytic experiments for predicting various clinical phenotypes and outcomes. First. we analyzed each modality separately using uni-modal approaches based on several state-of-the-art supervised …,True,bX__wkYAAAAJ:UeHWp8X0CEIC,37,https://www.nature.com/articles/srep04411,9497667325229537393,/scholar?cites=9497667325229537393,,,https://www.nature.com/articles/srep04411,0,0,0
1282492,Flownet: Learning optical flow with convolutional networks,2015,Alexey Dosovitskiy and Philipp Fischer and Eddy Ilg and Philip Hausser and Caner Hazirbas and Vladimir Golkov and Patrick van der Smagt and Daniel Cremers and Thomas Brox,,,,2758-2766,,Convolutional neural networks (CNNs) have recently been very successful in a variety of computer vision tasks. especially on those linked to recognition. Optical flow estimation has not been among the tasks CNNs succeeded at. In this paper we construct CNNs which are capable of solving the optical flow estimation problem as a supervised learning task. We propose and compare two architectures: a generic architecture and another one including a layer that correlates feature vectors at different image locations. Since existing ground truth data sets are not sufficiently large to train a CNN. we generate a large synthetic Flying Chairs dataset. We show that networks trained on this unrealistic data still generalize very well to existing datasets such as Sintel and KITTI. achieving competitive accuracy at frame rates of 5 to 10 fps.,True,JEiXKpcAAAAJ:UeHWp8X0CEIC,2507,http://openaccess.thecvf.com/content_iccv_2015/html/Dosovitskiy_FlowNet_Learning_Optical_ICCV_2015_paper.html,14306873502916215398,/scholar?cites=14306873502916215398,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Dosovitskiy_FlowNet_Learning_Optical_ICCV_2015_paper.pdf,0,0,0
1282493,Image-based localization using LSTMs for structured feature correlation,2017,Florian Walch and Caner Hazirbas and Laura Leal-Taixé and Torsten Sattler and Sebastian Hilsenbeck and Daniel Cremers,,,,,,In this work we propose a new CNN+ LSTM architecture for camera pose regression for indoor and outdoor scenes. CNNs allow us to learn suitable feature representations for localization that are robust against motion blur and illumination changes. We make use of LSTM units on the CNN output. which play the role of a structured dimensionality reduction on the feature vector. leading to drastic improvements in localization performance. We provide extensive quantitative comparison of CNN-based and SIFT-based localization methods. showing the weaknesses and strengths of each. Furthermore. we present a new large-scale indoor dataset with accurate ground truth from a laser scanner. Experimental results on both indoor and outdoor public datasets show our method outperforms existing deep architectures. and can localize images in hard conditions. eg. in the presence of mostly textureless surfaces. where classic SIFT-based methods fail.,True,JEiXKpcAAAAJ:zYLM7Y9cAGgC,314,http://openaccess.thecvf.com/content_iccv_2017/html/Walch_Image-Based_Localization_Using_ICCV_2017_paper.html,7641720320082495183,/scholar?cites=7641720320082495183,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Walch_Image-Based_Localization_Using_ICCV_2017_paper.pdf,0,0,0
1282494,FuseNet: Incorporating Depth into Semantic Segmentation via Fusion-based CNN Architecture,2016,Caner Hazirbas and Lingni Ma and Csaba Domokos and Daniel Cremers,,,,,Springer International Publishing,In this paper we address the problem of semantic labeling of indoor scenes on RGB-D data. With the availability of RGB-D cameras. it is expected that additional depth measurement will improve the accuracy. Here we investigate a solution how to incorporate complementary depth information into a semantic segmentation framework by making use of convolutional neural networks (CNNs). Recently encoder-decoder type fully convolutional CNN architectures have achieved a great success in the field of semantic segmentation. Motivated by this observation we propose an encoder-decoder type network. where the encoder part is composed of two branches of networks that simultaneously extract features from RGB and depth images and fuse depth features into the RGB feature maps as the network goes deeper. Comprehensive experimental evaluations demonstrate that the proposed fusion-based …,True,JEiXKpcAAAAJ:IjCSPb-OGe4C,310,https://link.springer.com/chapter/10.1007/978-3-319-54181-5_14,2730493974836369366,/scholar?cites=2730493974836369366,,,https://www.researchgate.net/profile/Caner_Hazirbas/publication/308311897_FuseNet_Incorporating_Depth_into_Semantic_Segmentation_via_Fusion-Based_CNN_Architecture/links/5a436d7d458515f6b050cb7f/FuseNet-Incorporating-Depth-into-Semantic-Segmentation-via-Fusion-Based-CNN-Architecture.pdf,0,0,0
1282495,Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems,2017,Tim Meinhardt and Michael Möller and Caner Hazirbas and Daniel Cremers,,,,,,While variational methods have been among the most powerful tools for solving linear inverse problems in imaging. deep (convolutional) neural networks have recently taken the lead in many challenging benchmarks. A remaining drawback of deep learning approaches is their requirement for an expensive retraining whenever the specific problem. the noise level. noise type. or desired measure of fidelity changes. On the contrary. variational methods have a plug-and-play nature as they usually consist of separate data fidelity and regularization terms. In this paper we study the possibility of replacing the proximal operator of the regularization used in many convex energy minimization algorithms by a denoising neural network. The latter therefore serves as an implicit natural image prior. while the data term can still be chosen independently. Using a fixed denoising neural network in exemplary problems of image deconvolution with different blur kernels and image demosaicking. we obtain state-of-the-art reconstruction results. These indicate the high generalizability of our approach and a reduction of the need for problem-specific training. Additionally. we discuss novel results on the analysis of possible optimization algorithms to incorporate the network into. as well as the choices of algorithm parameters and their relation to the noise level the neural network is trained on.,True,JEiXKpcAAAAJ:W7OEmFMy1HYC,173,http://openaccess.thecvf.com/content_iccv_2017/html/Meinhardt_Learning_Proximal_Operators_ICCV_2017_paper.html,3281885417592197744,/scholar?cites=3281885417592197744,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Meinhardt_Learning_Proximal_Operators_ICCV_2017_paper.pdf,0,0,0
1282496,What makes good synthetic training data for learning disparity and optical flow estimation?,2018,Nikolaus Mayer and Eddy Ilg and Philipp Fischer and Caner Hazirbas and Daniel Cremers and Alexey Dosovitskiy and Thomas Brox,,International Journal of Computer Vision (IJCV),,1-19,Springer US,The finding that very large networks can be trained efficiently and reliably has led to a paradigm shift in computer vision from engineered solutions to learning formulations. As a result. the research challenge shifts from devising algorithms to creating suitable and abundant training data for supervised learning. How to efficiently create such training data? The dominant data acquisition method in visual recognition is based on web data and manual annotation. Yet. for many computer vision problems. such as stereo or optical flow estimation. this approach is not feasible because humans cannot manually enter a pixel-accurate flow field. In this paper. we promote the use of synthetically generated data for the purpose of training deep networks on such tasks. We suggest multiple ways to generate such data and evaluate the influence of dataset properties on the performance and generalization properties of the …,True,JEiXKpcAAAAJ:LkGwnXOMwfcC,112,https://link.springer.com/article/10.1007/s11263-018-1082-6,7751152421004443982,/scholar?cites=7751152421004443982,,,https://arxiv.org/pdf/1801.06397,0,0,0
1282497,CAPTCHA Recognition with Active Deep Learning,2015,Fabian Stark and Caner Hazirbas and Rudolph Triebel and Daniel Cremers,,,New Challenges in Neural Computation,94,,CAPTCHAs are automated tests to tell computers and humans apart. They are designed to be easily solvable by humans. but unsolvable by machines. With Convolutional Neural Networks these tests can also be solved automatically. However. the strength of CNNs relies on the training data that the classifier is learnt on and especially on the size of the training set. Hence. it is intractable to solve the problem with CNNs in case of insufficient training data. We propose an Active Deep Learning strategy that makes use of the ability to gain new training data for free without any human intervention which is possible in the special case of CAPTCHAs. We discuss how to choose the new samples to re-train the network and present results on an auto-generated CAPTCHA dataset. Our approach dramatically improves the performance of the network if we initially have only few labeled training data.,True,JEiXKpcAAAAJ:qjMakFHDy7sC,91,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.1085&rep=rep1&type=pdf#page=94,8962832654500148442,/scholar?cites=8962832654500148442,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.1085&rep=rep1&type=pdf#page=94,0,0,0
1282498,Deep depth from focus,2018,Caner Hazirbas and Sebastian Georg Soyer and Maximilian Christian Staab and Laura Leal-Taixé and Daniel Cremers,,,arXiv preprint arXiv:1704.01085,,,Depth from focus (DFF) is one of the classical ill-posed inverse problems in computer vision. Most approaches recover the depth at each pixel based on the focal setting which exhibits maximal sharpness. Yet. it is not obvious how to reliably estimate the sharpness level. particularly in low-textured areas. In this paper. we propose ‘Deep Depth From Focus (DDFF)’ as the first end-to-end learning approach to this problem. One of the main challenges we face is the hunger for data of deep neural networks. In order to obtain a significant amount of focal stacks with corresponding groundtruth depth. we propose to leverage a light-field camera with a co-calibrated RGB-D sensor. This allows us to digitally create focal stacks of varying sizes. Compared to existing benchmarks our dataset is 25 times larger. enabling the use of machine learning for this inverse problem. We compare our results with state-of-the-art …,True,JEiXKpcAAAAJ:Y0pCki6q_DkC,36,https://link.springer.com/chapter/10.1007/978-3-030-20893-6_33,4448366297404681566,/scholar?cites=4448366297404681566,,,https://arxiv.org/pdf/1704.01085,0,0,0
1282499,Interactive Multi-label Segmentation of RGB-D Images,2015,Julia Diebold and Nikolaus Demmel and Caner Hazirbas and Michael Möller and Daniel Cremers,,,,294-306,Springer International Publishing,We propose a novel interactive multi-label RGB-D image segmentation method by extending spatially varying color distributions [14] to additionally utilize depth information in two different ways. On the one hand. we consider the depth image as an additional data channel. On the other hand. we extend the idea of spatially varying color distributions in a plane to volumetrically varying color distributions in 3D. Furthermore. we improve the data fidelity term by locally adapting the influence of nearby scribbles around each pixel. Our approach is implemented for parallel hardware and evaluated on a novel interactive RGB-D image segmentation benchmark with pixel-accurate ground truth. We show that depth information leads to considerably more precise segmentation results. At the same time significantly less user scribbles are required for obtaining the same segmentation accuracy as without using depth …,True,JEiXKpcAAAAJ:u-x6o8ySG0sC,13,https://link.springer.com/chapter/10.1007/978-3-319-18461-6_24,16968441367889717728,/scholar?cites=16968441367889717728,,,https://www.researchgate.net/profile/Caner_Hazirbas/publication/301620275_Interactive_Multi-label_Segmentation_of_RGB-D_Images/links/571dde9908ae7f552a4a735a/Interactive-Multi-label-Segmentation-of-RGB-D-Images.pdf,0,0,0
1282500,Deep Learning for Image-Based Localization,2016,Florian Walch and Daniel Cremers and Sebastian Hilsenbeck and Caner Hazirbas and Laura Leal-Taix,,Master’s thesis,,,Technische Universität München. Department of Informatics. Semantic Scholar,“Where was this image taken?” is an intriguing question that has been posed in the literature and is of interest for many applications. from localization of smartphone images to automatic geo-tagging on an online photo platform.Traditional content-based image retrieval (CBIR) systems typically localize images with a pipeline based on hand-crafted feature descriptors such as SIFT. Convolutional neural networks (CNNs). on the other hand. can be trained end-to-end to learn appropriate features from training data. CNNs have been very successful on many computer vision tasks such as image classification. optical flow prediction. and image superresolution. Recent neural network models such as PoseNet and PlaNet have considered localization of images as regression or classification tasks.,True,JEiXKpcAAAAJ:8k81kl-MbHgC,7,https://vision.in.tum.de/_media/members/hazirbas/teaching/walch2016msc.pdf,4475541955758016219,/scholar?cites=4475541955758016219,,,https://vision.in.tum.de/_media/members/hazirbas/teaching/walch2016msc.pdf,0,0,0
1282501,Optimizing the Relevance-Redundancy Tradeoff for Efficient Semantic Segmentation,2015,Caner Hazirbas and Julia Diebold and Daniel Cremers,9087,,,243-255,Springer International Publishing,,True,JEiXKpcAAAAJ:d1gkVwhDpl0C,5,,4172710758438640793,/scholar?cites=4172710758438640793,,,,0,0,0
1282502,Towards measuring fairness in AI: the Casual Conversations dataset,2021,Caner Hazirbas and Joanna Bitton and Brian Dolhansky and Jacqueline Pan and Albert Gordo and Cristian Canton Ferrer,,arXiv preprint arXiv:2104.02821,,,,This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age. genders. apparent skin tones and ambient lighting conditions. Our dataset is composed of 3.011 subjects and contains over 45.000 videos. with an average of 15 videos per person. The videos were recorded in multiple US states with a diverse set of adults in various age. gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally. our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects' apparent skin tone using the Fitzpatrick skin type scale. Moreover. annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes. we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people. such as subjects with darker skin tones and thus may not generalize to all people. In addition. we also evaluate the state-of-the-art apparent age and gender classification methods. Our experiments provides a through analysis on these models in terms of fair treatment of people from various backgrounds.,True,JEiXKpcAAAAJ:3fE2CSJIrl8C,0,https://arxiv.org/abs/2104.02821,,,,,https://arxiv.org/pdf/2104.02821,0,0,0
1282503,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang,,,,114-125,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,fddAbqsAAAAJ:5MTHONV0fEkC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1282504,Rotation averaging,2013,Richard Hartley and Jochen Trumpf and Yuchao Dai and Hongdong Li,103,International journal of computer vision,3,267-305,Springer US,This paper is conceived as a tutorial on rotation averaging. summarizing the research that has been carried out in this area; it discusses methods for single-view and multiple-view rotation averaging. as well as providing proofs of convergence and convexity in many cases. However. at the same time it contains many new results. which were developed to fill gaps in knowledge. answering fundamental questions such as radius of convergence of the algorithms. and existence of local minima. These matters. or even proofs of correctness have in many cases not been considered in the Computer Vision literature. We consider three main problems: single rotation averaging. in which a single rotation is computed starting from several measurements; multiple-rotation averaging. in which absolute orientations are computed from several relative orientation measurements; and conjugate rotation averaging. which …,True,fddAbqsAAAAJ:UebtZRa9Y70C,420,https://link.springer.com/content/pdf/10.1007/s11263-012-0601-0.pdf,9674589020175484662,/scholar?cites=9674589020175484662,,,https://users.cecs.anu.edu.au/~hartley/Papers/PDF/Hartley-Trumpf:Rotation-averaging:IJCV.pdf,0,0,0
1282505,Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs,2015,Bo Li and Chunhua Shen and Yuchao Dai and Anton Van Den Hengel and Mingyi He,,,,1119-1127,,Predicting the depth (or surface normal) of a scene from single monocular color images is a challenging task. This paper tackles this challenging and essentially under-determined problem by regression on deep convolutional neural network (DCNN) features. combined with a post-processing refining step using conditional random fields (CRF). Our framework works at two levels. super-pixel level and pixel level. First. we design a DCNN model to learn the mapping from multi-scale image patches to depth or surface normal values at the super-pixel level. Second. the estimated super-pixel depth or surface normal is refined to the pixel level by exploiting various potentials on the depth or surface normal map. which includes a data term. a smoothness term among super-pixels and an auto-regression term characterizing the local structure of the estimation map. The inference problem can be efficiently solved because it admits a closed-form solution. Experiments on the Make3D and NYU Depth V2 datasets show competitive results compared with recent state-of-the-art methods.,True,fddAbqsAAAAJ:9c2xU6iGI7YC,418,http://openaccess.thecvf.com/content_cvpr_2015/html/Li_Depth_and_Surface_2015_CVPR_paper.html,16739609104988810509,/scholar?cites=16739609104988810509,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Li_Depth_and_Surface_2015_CVPR_paper.pdf,0,0,0
1282506,A simple prior-free method for non-rigid structure-from-motion factorization,2014,Yuchao Dai and Hongdong Li and Mingyi He,107,International Journal of Computer Vision,2,101-122,Springer US,This paper proposes a simple “prior-free” method for solving the non-rigid structure-from-motion (NRSfM) factorization problem. Other than using the fundamental low-order linear combination model assumption. our method does not assume any extra prior knowledge either about the non-rigid structure or about the camera motions. Yet. it works effectively and reliably. producing optimal results. and not suffering from the inherent basis ambiguity issue which plagued most conventional NRSfM factorization methods. Our method is very simple to implement. which involves solving a very small SDP (semi-definite programming) of fixed size. and a nuclear-norm minimization problem. We also present theoretical analysis on the uniqueness and the relaxation gap of our solutions. Extensive experiments on both synthetic and real motion capture data (assuming following the low-order linear combination model) are …,True,fddAbqsAAAAJ:eQOLeE2rZwMC,248,https://link.springer.com/content/pdf/10.1007/s11263-013-0684-2.pdf,16819218398403393900,/scholar?cites=16819218398403393900,,,https://www.researchgate.net/profile/Mingyi_HE/publication/261200440_A_Simple_Prior-Free_Method_for_Non-rigid_Structure-from-Motion_Factorization/links/5596951608ae21086d21990b.pdf,0,0,0
1282507,Self-supervised learning for stereo matching with self-improving ability,2017,Yiran Zhong and Yuchao Dai and Hongdong Li,,arXiv preprint arXiv:1709.00930,,,,Exiting deep-learning based dense stereo matching methods often rely on ground-truth disparity maps as the training signals. which are however not always available in many situations. In this paper. we design a simple convolutional neural network architecture that is able to learn to compute dense disparity maps directly from the stereo inputs. Training is performed in an end-to-end fashion without the need of ground-truth disparity maps. The idea is to use image warping error (instead of disparity-map residuals) as the loss function to drive the learning process. aiming to find a depth-map that minimizes the warping error. While this is a simple concept well-known in stereo matching. to make it work in a deep-learning framework. many non-trivial challenges must be overcome. and in this work we provide effective solutions. Our network is self-adaptive to different unseen imageries as well as to different camera settings. Experiments on KITTI and Middlebury stereo benchmark datasets show that our method outperforms many state-of-the-art stereo matching methods with a margin. and at the same time significantly faster.,True,fddAbqsAAAAJ:lvd772isFD0C,96,https://arxiv.org/abs/1709.00930,10993849913952788713,/scholar?cites=10993849913952788713,,,https://arxiv.org/pdf/1709.00930,0,0,0
1282508,Skeleton based action recognition using translation-scale invariant image mapping and multi-scale deep CNN,2017,Bo Li and Yuchao Dai and Xuelian Cheng and Huahui Chen and Yi Lin and Mingyi He,,,,601-604,IEEE,We present an image classification based approach to large scale action recognition from 3D skeleton videos. Firstly. we map the 3D skeleton videos to color images. where the transformed action images are translation-scale invariance and dataset independent. Secondly. we propose a multi-scale deep convolutional neural network (CNN) for the image classification task. which could enhance the temporal frequency adjustment of our model. Even though the action images are very different from natural images. the fine-tune strategy still works well. Finally. we exploit various kinds of data augmentation methods to improve the generalization ability of the network. Experimental results on the largest and most challenging benchmark NTU RGB-D dataset show that our method achieves the state-of-the-art performance and outperforms other methods by a large margin.,True,fddAbqsAAAAJ:KbBQZpvPDL4C,88,https://ieeexplore.ieee.org/abstract/document/8026282/,5514152061832287131,/scholar?cites=5514152061832287131,,,https://arxiv.org/pdf/1704.05645,0,0,0
1282509,Monocular Depth Estimation with Hierarchical Fusion of Dilated CNNs and Soft-Weighted-Sum Inference,2018,Bo Li and Yuchao Dai and Mingyi He,,Pattern Recognition,,,Pergamon,Monocular depth estimation is very challenging in complex compositions depicting multiple objects of diverse scales. Albeit the recent great progress thanks to the deep convolutional neural networks. the state-of-the-art monocular depth estimation methods still fall short to handle such real-world challenging scenarios. In this paper. we propose a deep end-to-end learning framework to tackle these challenges. which learns the direct mapping from a color image to the corresponding depth map. First. we represent monocular depth estimation as a multi-category dense labeling task by contrast to the regression-based formulation. In this way. we could build upon the recent progress in dense labeling such as semantic segmentation. Second. we fuse different side-outputs from our front-end dilated convolutional neural network in a hierarchical way to exploit the multi-scale depth cues for monocular depth estimation …,True,fddAbqsAAAAJ:_OXeSy2IsFwC,86,https://www.sciencedirect.com/science/article/pii/S0031320318302097,4694926675782235671,/scholar?cites=4694926675782235671,,,https://arxiv.org/pdf/1708.02287,0,0,0
1282510,Efficient Global 2D-3D Matching for Camera Localization in a Large-Scale 3D Map,2017,Liu Liu and Hongdong Li and Yuchao Dai,,,,2372-2381,,Given an image of a street scene in a city. this paper develops a new method that can quickly and precisely pinpoint at which location (as well as viewing direction) the image was taken. against a pre-stored large-scale 3D point-cloud map of the city. We adopt the recently developed 2D-3D direct feature matching framework for this task [23. 31. 32. 42-44]. This is a challenging task especially for large-scale problems. As the map size grows bigger. many 3D points in the wider geographical area can be visually very similar-or even identical-causing severe ambiguities in 2D-3D feature matching. The key is to quickly and unambiguously find the correct matches between a query image and the large 3D map. Existing methods solve this problem mainly via comparing individual features' visual similarities in a local and per feature manner. thus only local solutions can be found. inadequate for large-scale applications. In this paper. we introduce a global method which harnesses global contextual information exhibited both within the query image and among all the 3D points in the map. This is achieved by a novel global ranking algorithm. applied to a Markov network built upon the 3D map. which takes account of not only visual similarities between individual 2D-3D matches. but also their global compatibilities (as measured by co-visibility) among all matching pairs found in the scene. Tests on standard benchmark datasets show that our method achieved both higher precision and comparable recall. compared with the state-of-the-art.,True,fddAbqsAAAAJ:5icHVeHT4IsC,74,http://openaccess.thecvf.com/content_iccv_2017/html/Liu_Efficient_Global_2D-3D_ICCV_2017_paper.html,12641241876762756528,/scholar?cites=12641241876762756528,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Efficient_Global_2D-3D_ICCV_2017_paper.pdf,0,0,0
1282511,Deep unsupervised saliency detection: A multiple noisy labeling perspective,2018,Jing Zhang and Tong Zhang and Yuchao Dai and Mehrtash Harandi and Richard Hartley,,,,9029-9038,,The success of current deep saliency detection methods heavily depends on the availability of large-scale supervision in the form of per-pixel labeling. Such supervision. while labor-intensive and not always possible. tends to hinder the generalization ability of the learned models. By contrast. traditional handcrafted features based unsupervised saliency detection methods. even though have been surpassed by the deep supervised methods. are generally dataset-independent and could be applied in the wild. This raises a natural question that``Is it possible to learn saliency maps without using labeled data while improving the generalization ability?''. To this end. we present a novel perspective to unsupervised saliency detection through learning from multiple noisy labeling generated by``weak''and``noisy''unsupervised handcrafted saliency methods. Our end-to-end deep learning framework for unsupervised saliency detection consists of a latent saliency prediction module and a noise modeling module that work collaboratively and are optimized jointly. Explicit noise modeling enables us to deal with noisy saliency maps in a probabilistic way. Extensive experimental results on various benchmarking datasets show that our model not only outperforms all the unsupervised saliency methods with a large margin but also achieves comparable performance with the recent state-of-the-art supervised deep saliency methods.,True,fddAbqsAAAAJ:LgRImbQfgY4C,73,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.html,13626736994737254005,/scholar?cites=13626736994737254005,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.pdf,0,0,0
1282512,Deep Stacked Hierarchical Multi-patch Network for Image Deblurring,2019,Hongguang Zhang and Yuchao Dai and Hongdong Li and Piotr Koniusz,,IEEE CVPR 2019. arXiv preprint arXiv:1904.03468,,,,Despite deep end-to-end learning methods have shown their superiority in removing non-uniform motion blur. there still exist major challenges with the current multi-scale and scale-recurrent models: 1) Deconvolution/upsampling operations in the coarse-to-fine scheme result in expensive runtime; 2) Simply increasing the model depth with finer-scale levels cannot improve the quality of deblurring. To tackle the above problems. we present a deep hierarchical multi-patch network inspired by Spatial Pyramid Matching to deal with blurry images via a fine-to-coarse hierarchical representation. To deal with the performance saturation wrt depth. we propose a stacked version of our multi-patch model. Our proposed basic multi-patch model achieves the state-of-the-art performance on the GoPro dataset while enjoying a 40xfaster runtime compared to current multi-scale methods. With 30ms to process an image at 1280x720 resolution. it is the first real-time deep motion deblurring model for 720p images at 30fps. For stacked networks. significant improvements (over 1.2 dB) are achieved on the GoPro dataset by increasing the network depth. Moreover. by varying the depth of the stacked model. one can adapt the performance and runtime of the same network for different application scenarios.,True,fddAbqsAAAAJ:ubry08Y2EpUC,71,http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Stacked_Hierarchical_Multi-Patch_Network_for_Image_Deblurring_CVPR_2019_paper.html,817552767831025812,/scholar?cites=817552767831025812,,,https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deep_Stacked_Hierarchical_Multi-Patch_Network_for_Image_Deblurring_CVPR_2019_paper.pdf,0,0,0
1282513,UC-Net: Uncertainty inspired RGB-D saliency detection via conditional variational autoencoders,2020,Jing Zhang and Deng-Ping Fan and Yuchao Dai and Saeed Anwar and Fatemeh Sadat Saleh and Tong Zhang and Nick Barnes,,,,8582-8591,,In this paper. we propose the first framework (UCNet) to employ uncertainty for RGB-D saliency detection by learning from the data labeling process. Existing RGB-D saliency detection methods treat the saliency detection task as a point estimation problem. and produce a single saliency map following a deterministic learning pipeline. Inspired by the saliency data labeling process. we propose probabilistic RGB-D saliency detection network via conditional variational autoencoders to model human annotation uncertainty and generate multiple saliency maps for each input image by sampling in the latent space. With the proposed saliency consensus process. we are able to generate an accurate saliency map based on these multiple predictions. Quantitative and qualitative evaluations on six challenging benchmark datasets against 18 competing algorithms demonstrate the effectiveness of our approach in learning the distribution of saliency maps. leading to a new state-of-the-art in RGB-D saliency detection.,True,fddAbqsAAAAJ:7wO8s98CvbsC,66,http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_UC-Net_Uncertainty_Inspired_RGB-D_Saliency_Detection_via_Conditional_Variational_Autoencoders_CVPR_2020_paper.html,3257562511183813052,/scholar?cites=3257562511183813052,,,https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_UC-Net_Uncertainty_Inspired_RGB-D_Saliency_Detection_via_Conditional_Variational_Autoencoders_CVPR_2020_paper.pdf,0,0,0
1282514,DeepFlow: Large displacement optical flow with deep matching,2013,Philippe Weinzaepfel and Jerome Revaud and Zaid Harchaoui and Cordelia Schmid,,,,1385-1392,,Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition. However. despite several major advances over the last decade. handling large displacement in optical flow remains an open problem. Inspired by the large displacement optical flow of Brox & Malik [6]. our approach. termed DeepFlow. blends a matching algorithm with a variational approach for optical flow. We propose a descriptor matching algorithm. tailored to the optical flow problem. that allows to boost performance on fast motions. The matching algorithm builds upon a multi-stage architecture with 6 layers. interleaving convolutions and max-pooling. a construction akin to deep convolutional nets. Using dense sampling. it allows to efficiently retrieve quasi-dense correspondences. and enjoys a built-in smoothing effect on descriptors matches. a valuable asset for integration into an energy minimization framework for optical flow estimation. DeepFlow efficiently handles large displacements occurring in realistic videos. and shows competitive performance on optical flow benchmarks. Furthermore. it sets a new state-of-the-art on the MPI-Sintel dataset [8].,True,LSxIJ5cAAAAJ:u-x6o8ySG0sC,955,http://openaccess.thecvf.com/content_iccv_2013/html/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.html,2209579584144969938,/scholar?cites=2209579584144969938,,,https://openaccess.thecvf.com/content_iccv_2013/papers/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.pdf,0,0,0
1282515,Epicflow: Edge-preserving interpolation of correspondences for optical flow,2015,Jerome Revaud and Philippe Weinzaepfel and Zaid Harchaoui and Cordelia Schmid,,,,1164-1172,,We propose a novel approach for optical flow estimation. targeted at large displacements with significant occlusions. It consists of two steps: i) dense matching by edge-preserving interpolation from a sparse set of matches; ii) variational energy minimization initialized with the dense matches. The sparse-to-dense interpolation relies on an appropriate choice of the distance. namely an edge-aware geodesic distance. This distance is tailored to handle occlusions and motion boundaries-two common and difficult issues for optical flow computation. We also propose an approximation scheme for the geodesic distance to allow fast computation without loss of performance. Subsequent to the dense interpolation step. standard one-level variational energy minimization is carried out on the dense matches to obtain the final flow estimation. The proposed approach. called Edge-Preserving Interpolation of Correspondences (EpicFlow) is fast and robust to large displacements. It significantly outperforms the state of the art on MPI-Sintel and performs on par on Kitti and Middlebury.,True,LSxIJ5cAAAAJ:d1gkVwhDpl0C,709,http://openaccess.thecvf.com/content_cvpr_2015/html/Revaud_EpicFlow_Edge-Preserving_Interpolation_2015_CVPR_paper.html,5600914496244269397,/scholar?cites=5600914496244269397,,,http://openaccess.thecvf.com/content_cvpr_2015/papers/Revaud_EpicFlow_Edge-Preserving_Interpolation_2015_CVPR_paper.pdf,0,0,0
1282516,Learning to track for spatio-temporal action localization,2015,Philippe Weinzaepfel and Zaid Harchaoui and Cordelia Schmid,,,,3164-3172,,We propose an effective approach for spatio-temporal action localization in realistic videos. The approach first detects proposals at the frame-level and scores them with a combination of static and motion CNN features. It then tracks high-scoring proposals throughout the video using a tracking-by-detection approach. Our tracker relies simultaneously on instance-level and class-level detectors. The tracks are scored using a spatio-temporal motion histogram. a descriptor at the track level. in combination with the CNN features. Finally. we perform temporal localization of the action using a sliding-window approach at the track level. We present experimental results for spatio-temporal localization on the UCF-Sports. J-HMDB and UCF-101 action localization datasets. where our approach outperforms the state of the art with a margin of 15%. 7% and 12% respectively in mAP.,True,LSxIJ5cAAAAJ:2osOgNQ5qMEC,285,http://openaccess.thecvf.com/content_iccv_2015/html/Weinzaepfel_Learning_to_Track_ICCV_2015_paper.html,1893083230530095061,/scholar?cites=1893083230530095061,,,http://openaccess.thecvf.com/content_iccv_2015/papers/Weinzaepfel_Learning_to_Track_ICCV_2015_paper.pdf,0,0,0
1282517,Deepmatching: Hierarchical deformable dense matching,2016,Jerome Revaud and Philippe Weinzaepfel and Zaid Harchaoui and Cordelia Schmid,120,International Journal of Computer Vision,3,300-323,Springer US,We introduce a novel matching algorithm. called DeepMatching. to compute dense correspondences between images. DeepMatching relies on a hierarchical. multi-layer. correlational architecture designed for matching images and was inspired by deep convolutional approaches. The proposed matching algorithm can handle non-rigid deformations and repetitive textures and efficiently determines dense correspondences in the presence of significant changes between images. We evaluate the performance of DeepMatching. in comparison with state-of-the-art matching algorithms. on the Mikolajczyk (Mikolajczyk et al. A comparison of affine region detectors. 2005). the MPI-Sintel (Butler et al. A naturalistic open source movie for optical flow evaluation. 2012) and the Kitti (Geiger et al. Vision meets robotics: The KITTI dataset. 2013) datasets. DeepMatching outperforms the state-of-the-art algorithms and …,True,LSxIJ5cAAAAJ:IjCSPb-OGe4C,239,https://link.springer.com/article/10.1007/s11263-016-0908-3,4134438272343122204,/scholar?cites=4134438272343122204,,,https://arxiv.org/pdf/1506.07656,0,0,0
1282518,Action tubelet detector for spatio-temporal action localization,2017,Vicky Kalogeiton and Philippe Weinzaepfel and Vittorio Ferrari and Cordelia Schmid,,,,4405-4413,,Current state-of-the-art approaches for spatio-temporal action localization rely on detections at the frame level that are then linked or tracked across time. In this paper. we leverage the temporal continuity of videos instead of operating at the frame level. We propose the ACtion Tubelet detector (ACT-detector) that takes as input a sequence of frames and outputs tubelets. ie. sequences of bounding boxes with associated scores. The same way state-of-the-art object detectors rely on anchor boxes. our ACT-detector is based on anchor cuboids. We build upon the SSD framework. Convolutional features are extracted for each frame. while scores and regressions are based on the temporal stacking of these features. thus exploiting information from a sequence. Our experimental results show that leveraging sequences of frames significantly improves detection performance over using individual frames. The gain of our tubelet detector can be explained by both more accurate scores and more precise localization. Our ACT-detector outperforms the state-of-the-art methods for frame-mAP and video-mAP on the J-HMDB and UCF-101 datasets. in particular at high overlap thresholds.,True,LSxIJ5cAAAAJ:W7OEmFMy1HYC,211,http://openaccess.thecvf.com/content_iccv_2017/html/Kalogeiton_Action_Tubelet_Detector_ICCV_2017_paper.html,6345251186537892330,/scholar?cites=6345251186537892330,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Kalogeiton_Action_Tubelet_Detector_ICCV_2017_paper.pdf,0,0,0
1282519,Lcr-net: Localization-classification-regression for human pose,2017,Gregory Rogez and Philippe Weinzaepfel and Cordelia Schmid,,,,3433-3441,,We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals per image. which allows us to predict 2D and 3D pose of multiple people simultaneously. Hence. our approach does not require an approximate localization of the humans for initialization. Our architecture. named LCR-Net. contains 3 main components: 1) the pose proposal generator that suggests potential poses at different locations in the image; 2) a classifier that scores the different pose proposals; and 3) a regressor that refines pose proposals both in 2D and 3D. All three stages share the convolutional feature layers and are trained jointly. The final pose estimation is obtained by integrating over neighboring pose hypotheses. which is shown to improve over a standard non maximum suppression algorithm. Our approach significantly outperforms the state of the art in 3D pose estimation on Human3. 6M. a controlled environment. Moreover. it shows promising results on real images for both single and multi-person subsets of the MPII 2D pose benchmark.,True,LSxIJ5cAAAAJ:Y0pCki6q_DkC,194,http://openaccess.thecvf.com/content_cvpr_2017/html/Rogez_LCR-Net_Localization-Classification-Regression_for_CVPR_2017_paper.html,5882225221066441347,/scholar?cites=5882225221066441347,,,http://openaccess.thecvf.com/content_cvpr_2017/papers/Rogez_LCR-Net_Localization-Classification-Regression_for_CVPR_2017_paper.pdf,0,0,0
1282520,Potion: Pose motion representation for action recognition,2018,Vasileios Choutas and Philippe Weinzaepfel and Jérôme Revaud and Cordelia Schmid,,,,7024-7033,,Most state-of-the-art methods for action recognition rely on a two-stream architecture that processes appearance and motion independently. In this paper. we claim that considering them jointly offers rich information for action recognition. We introduce a novel representation that gracefully encodes the movement of some semantic keypoints. We use the human joints as these keypoints and term our Pose moTion representation PoTion. Specifically. we first run a state-of-the-art human pose estimator and extract heatmaps for the human joints in each frame. We obtain our PoTion representation by temporally aggregating these probability maps. This is achieved by colorizing each of them depending on the relative time of the frames in the video clip and summing them. This fixed-size representation for an entire video clip is suitable to classify actions using a shallow convolutional neural network. Our experimental evaluation shows that PoTion outperforms other state-of-the-art pose representations. Furthermore. it is complementary to standard appearance and motion streams. When combining PoTion with the recent two-stream I3D approach [5]. we obtain state-of-the-art performance on the JHMDB. HMDB and UCF101 datasets.,True,LSxIJ5cAAAAJ:_FxGoFyzp5QC,141,http://openaccess.thecvf.com/content_cvpr_2018/html/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.html,1534091363610275817,/scholar?cites=1534091363610275817,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.pdf,0,0,0
1282521,Lcr-net++: Multi-person 2d and 3d pose detection in natural images,2019,Gregory Rogez and Philippe Weinzaepfel and Cordelia Schmid,42,IEEE transactions on pattern analysis and machine intelligence,5,1146-1161,IEEE,We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals per image. which allows us to predict 2D and 3D poses of multiple people simultaneously. Hence. our approach does not require an approximate localization of the humans for initialization. Our Localization-Classification-Regression architecture. named LCR-Net. contains 3 main components: 1) the pose proposal generator that suggests candidate poses at different locations in the image; 2) a classifier that scores the different pose proposals; and 3) a regressor that refines pose proposals both in 2D and 3D. All three stages share the convolutional feature layers and are trained jointly. The final pose estimation is obtained by integrating over neighboring pose hypotheses. which is shown to improve over a standard non maximum …,True,LSxIJ5cAAAAJ:ufrVoPGSRksC,139,https://ieeexplore.ieee.org/abstract/document/8611390/,15578529813228582847,/scholar?cites=15578529813228582847,,,https://arxiv.org/pdf/1803.00455,0,0,0
1282522,Reconstructing an image from its local descriptors,2011,Philippe Weinzaepfel and Hervé Jégou and Patrick Pérez,,,,337-344,IEEE,This paper shows that an image can be approximately reconstructed based on the output of a blackbox local description software such as those classically used for image indexing. Our approach consists first in using an off-the-shelf image database to find patches that are visually similar to each region of interest of the unknown input image. according to associated local descriptors. These patches are then warped into input image domain according to interest region geometry and seamlessly stitched together. Final completion of still missing texture-free regions is obtained by smooth interpolation. As demonstrated in our experiments. visually meaningful reconstructions are obtained just based on image local descriptors like SIFT. provided the geometry of regions of interest is known. The reconstruction most often allows the clear interpretation of the semantic image content. As a result. this work raises critical issues …,True,LSxIJ5cAAAAJ:u5HHmVD_uO8C,139,https://ieeexplore.ieee.org/abstract/document/5995616/,11441311833201210253,/scholar?cites=11441311833201210253,,,https://hal.inria.fr/inria-00566718/file/weinzaepfel_cvpr11.pdf,0,0,0
1282523,MARS: Motion-Augmented RGB Stream for Action Recognition,2019,Nieves Crasto and Philippe Weinzaepfel and Karteek Alahari and Cordelia Schmid,,,,,,Most state-of-the-art methods for action recognition consist of a two-stream architecture with 3D convolutions: an appearance stream for RGB frames and a motion stream for optical flow frames. Although combining flow with RGB improves the performance. the cost of computing accurate optical flow is high. and increases action recognition latency. This limits the usage of two-stream approaches in real-world applications requiring low latency. In this paper. we introduce two learning approaches to train a standard 3D CNN. operating on RGB frames. that mimics the motion stream. and as a result avoids flow computation at test time. First. by minimizing a feature-based loss compared to the Flow stream. we show that the network reproduces the motion stream with high fidelity. Second. to leverage both appearance and motion information effectively. we train with a linear combination of the feature-based loss and the standard cross-entropy loss for action recognition. We denote the stream trained using this combined loss as Motion-Augmented RGB Stream (MARS). As a single stream. MARS performs better than RGB or Flow alone. for instance with 72.7% accuracy on Kinetics compared to 72.0% and 65.6% with RGB and Flow streams respectively.,True,LSxIJ5cAAAAJ:roLk4NBRz8UC,102,http://openaccess.thecvf.com/content_CVPR_2019/html/Crasto_MARS_Motion-Augmented_RGB_Stream_for_Action_Recognition_CVPR_2019_paper.html,8853005918203548305,/scholar?cites=8853005918203548305,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Crasto_MARS_Motion-Augmented_RGB_Stream_for_Action_Recognition_CVPR_2019_paper.pdf,0,0,0
1282524,R2D2: repeatable and reliable detector and descriptor,2019,Jerome Revaud and Philippe Weinzaepfel and César De Souza and Noe Pion and Gabriela Csurka and Yohann Cabon and Martin Humenberger,,arXiv preprint arXiv:1906.06195,,,,Interest point detection and local feature description are fundamental steps in many computer vision applications. Classical methods for these tasks are based on a detect-then-describe paradigm where separate handcrafted methods are used to first identify repeatable keypoints and then represent them with a local descriptor. Neural networks trained with metric learning losses have recently caught up with these techniques. focusing on learning repeatable saliency maps for keypoint detection and learning descriptors at the detected keypoint locations. In this work. we argue that salient regions are not necessarily discriminative. and therefore can harm the performance of the description. Furthermore. we claim that descriptors should be learned only in regions for which matching can be performed with high confidence. We thus propose to jointly learn keypoint detection and description together with a predictor of the local descriptor discriminativeness. This allows us to avoid ambiguous areas and leads to reliable keypoint detections and descriptions. Our detection-and-description approach. trained with self-supervision. can simultaneously output sparse. repeatable and reliable keypoints that outperforms state-of-the-art detectors and descriptors on the HPatches dataset. It also establishes a record on the recently released Aachen Day-Night localization dataset.,True,LSxIJ5cAAAAJ:Se3iqnhoufwC,87,https://arxiv.org/abs/1906.06195,2247293624809694088,/scholar?cites=2247293624809694088,,,https://arxiv.org/pdf/1906.06195,0,0,0
1282525,Conditional Random Fields as Recurrent Neural Networks,2015,Shuai Zheng and Sadeep Jayasumana and Bernardino Romera-Paredes and Vibhav Vineet and Zhizhong Su and Dalong Du and Chang Huang and Philip Torr,,,,,,Pixel-level labelling tasks. such as semantic segmentation. play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem. we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end. we formulate Conditional Random Fields with Gaussian pairwise potentials and mean-field approximate inference as Recurrent Neural Networks. This network. called CRF-RNN. is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly. our system fully integrates CRF modelling with CNNs. making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm. avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation. obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark.,True,qYLOPxoAAAAJ:Tyk-4Ss8FVUC,2422,https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zheng_Conditional_Random_Fields_ICCV_2015_paper.html,4680896688857314530,/scholar?cites=4680896688857314530,,,https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf,0,0,0
1282526,Kernel Methods on the Riemannian Manifold of Symmetric Positive Definite Matrices,2013,Sadeep Jayasumana and Richard Hartley and Mathieu Salzmann and Hongdong Li and Mehrtash Harandi,,,,73-80,IEEE,Symmetric Positive Definite (SPD) matrices have become popular to encode image information. Accounting for the geometry of the Riemannian manifold of SPD matrices has proven key to the success of many algorithms. However. most existing methods only approximate the true shape of the manifold locally by its tangent plane. In this paper. inspired by kernel methods. we propose to map SPD matrices to a high dimensional Hilbert space where Euclidean geometry applies. To encode the geometry of the manifold in the mapping. we introduce a family of provably positive definite kernels on the Riemannian manifold of SPD matrices. These kernels are derived from the Gaussian kernel. but exploit different metrics on the manifold. This lets us extend kernel-based algorithms developed for Euclidean spaces. such as SVM and kernel PCA. to the Riemannian manifold of SPD matrices. We demonstrate the benefits of our approach on the problems of pedestrian detection. object categorization. texture analysis. 2D motion segmentation and Diffusion Tensor Imaging (DTI) segmentation.,True,qYLOPxoAAAAJ:u5HHmVD_uO8C,281,https://www.cv-foundation.org/openaccess/content_cvpr_2013/html/Jayasumana_Kernel_Methods_on_2013_CVPR_paper.html,8164421377622751873,/scholar?cites=8164421377622751873,,,https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Jayasumana_Kernel_Methods_on_2013_CVPR_paper.pdf,0,0,0
1282527,Higher order conditional random fields in deep neural networks,2016,Anurag Arnab and Sadeep Jayasumana and Shuai Zheng and Philip HS Torr,,,,524-540,Springer. Cham,We address the problem of semantic segmentation using deep learning. Most segmentation systems include a Conditional Random Field (CRF) to produce a structured output that is consistent with the image’s visual features. Recent deep learning approaches have incorporated CRFs into Convolutional Neural Networks (CNNs). with some even training the CRF end-to-end with the rest of the network. However. these approaches have not employed higher order potentials. which have previously been shown to significantly improve segmentation performance. In this paper. we demonstrate that two types of higher order potential. based on object detections and superpixels. can be included in a CRF embedded within a deep network. We design these higher order potentials to allow inference with the differentiable mean field algorithm. As a result. all the parameters of our richer CRF model can be learned …,True,qYLOPxoAAAAJ:WF5omc3nYNoC,211,https://link.springer.com/chapter/10.1007/978-3-319-46475-6_33,17919025335598312597,/scholar?cites=17919025335598312597,,,https://arxiv.org/pdf/1511.08119,0,0,0
1282528,Kernel Methods on Riemannian Manifolds with Gaussian RBF Kernels,2015,Sadeep Jayasumana and Richard Hartley and Mathieu Salzmann and Hongdong Li and Mehrtash Harandi,,IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),,,,In this paper. we develop an approach to exploiting kernel methods with manifold-valued data. In many computer vision problems. the data can be naturally represented as points on a Riemannian manifold. Due to the non-Euclidean geometry of Riemannian manifolds. usual Euclidean computer vision and machine learning algorithms yield inferior results on such data. In this paper. we define Gaussian radial basis function (RBF)-based positive definite kernels on manifolds that permit us to embed a given manifold with a corresponding metric in a high dimensional reproducing kernel Hilbert space. These kernels make it possible to utilize algorithms developed for linear spaces on nonlinear manifold-valued data. Since the Gaussian RBF defined with any given metric is not always positive definite. we present a unified framework for analyzing the positive definiteness of the Gaussian RBF on a generic metric space …,True,qYLOPxoAAAAJ:zYLM7Y9cAGgC,155,https://ieeexplore.ieee.org/abstract/document/7063231/,6474221604263905099,/scholar?cites=6474221604263905099,,,https://arxiv.org/pdf/1412.0265,0,0,0
1282529,Conditional random fields meet deep neural networks for semantic segmentation: Combining probabilistic graphical models with deep learning for structured prediction,2018,Anurag Arnab and Shuai Zheng and Sadeep Jayasumana and Bernardino Romera-Paredes and Måns Larsson and Alexander Kirillov and Bogdan Savchynskyy and Carsten Rother and Fredrik Kahl and Philip HS Torr,35,IEEE Signal Processing Magazine,1,37-52,IEEE,Semantic segmentation is the task of labeling every pixel in an image with a predefined object category. It has numerous applications in scenarios where the detailed understanding of an image is required. such as in autonomous vehicles and medical diagnosis. This problem has traditionally been solved with probabilistic models known as conditional random fields (CRFs) due to their ability to model the relationships between the pixels being predicted. However. deep neural networks (DNNs) recently have been shown to excel at a wide range of computer vision problems due to their ability to automatically learn rich feature representations from data. as opposed to traditional handcrafted features. The idea of combining CRFs and DNNs have achieved state-of-the-art results in a number of domains. We review the literature on combining the modeling power of CRFs with the representation-learning ability of DNNs …,True,qYLOPxoAAAAJ:_FxGoFyzp5QC,84,https://ieeexplore.ieee.org/abstract/document/8254255/,7654470686828724217,/scholar?cites=7654470686828724217,,,https://ora.ox.ac.uk/objects/uuid:0ff47a2f-c43e-4067-b56f-51fb1b7cc1d7/download_file?safe_filename=CRFMeetCNN4SemanticSegmentation.pdf&file_format=application%2Fpdf&type_of_work=Journal+article,0,0,0
1282530,Expanding the family of grassmannian kernels: An embedding perspective,2014,Mehrtash T Harandi and Mathieu Salzmann and Sadeep Jayasumana and Richard Hartley and Hongdong Li,,,,408-423,Springer. Cham,Modeling videos and image-sets as linear subspaces has proven beneficial for many visual recognition tasks. However. it also incurs challenges arising from the fact that linear subspaces do not obey Euclidean geometry. but lie on a special type of Riemannian manifolds known as Grassmannian. To leverage the techniques developed for Euclidean spaces (e.g.. support vector machines) with subspaces. several recent studies have proposed to embed the Grassmannian into a Hilbert space by making use of a positive definite kernel. Unfortunately. only two Grassmannian kernels are known. none of which -as we will show- is universal. which limits their ability to approximate a target function arbitrarily well. Here. we introduce several positive definite Grassmannian kernels. including universal ones. and demonstrate their superiority over previously-known kernels in various tasks. such as classification …,True,qYLOPxoAAAAJ:2osOgNQ5qMEC,81,https://link.springer.com/chapter/10.1007/978-3-319-10584-0_27,15141696963531307994,/scholar?cites=15141696963531307994,,,https://link.springer.com/content/pdf/10.1007/978-3-319-10584-0_27.pdf,0,0,0
1282531,A framework for shape analysis via hilbert space embedding,2013,Sadeep Jayasumana and Mathieu Salzmann and Hongdong Li and Mehrtash Harandi,,,,1249-1256,,We propose a framework for 2D shape analysis using positive definite kernels defined on Kendall's shape manifold. Different representations of 2D shapes are known to generate different nonlinear spaces. Due to the nonlinearity of these spaces. most existing shape classification algorithms resort to nearest neighbor methods and to learning distances on shape spaces. Here. we propose to map shapes on Kendall's shape manifold to a high dimensional Hilbert space where Euclidean geometry applies. To this end. we introduce a kernel on this manifold that permits such a mapping. and prove its positive definiteness. This kernel lets us extend kernel-based algorithms developed for Euclidean spaces. such as SVM. MKL and kernel PCA. to the shape manifold. We demonstrate the benefits of our approach over the state-of-the-art methods on shape classification. clustering and retrieval.,True,qYLOPxoAAAAJ:d1gkVwhDpl0C,35,https://www.cv-foundation.org/openaccess/content_iccv_2013/html/Jayasumana_A_Framework_for_2013_ICCV_paper.html,400751823956105245,/scholar?cites=400751823956105245,,,https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Jayasumana_A_Framework_for_2013_ICCV_paper.pdf,0,0,0
1282532,Optimizing Over Radial Kernels on Compact Manifolds,2014,Sadeep Jayasumana and Richard Hartley and Mathieu Salzmann and Hongdong Li and Mehrtash Harandi,,"Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on",,,IEEE,We tackle the problem of optimizing over all possible positive definite radial kernels on Riemannian manifolds for classification. Kernel methods on Riemannian manifolds have recently become increasingly popular in computer vision. However. the number of known positive definite kernels on manifolds remain very limited. Furthermore. most kernels typically depend on at least one parameter that needs to be tuned for the problem at hand. A poor choice of kernel. or of parameter value. may yield significant performance drop-off. Here. we show that positive definite radial kernels on the unit -sphere. the Grassmann manifold and Kendall's shape manifold can be expressed in a simple form whose parameters can be automatically optimized within a support vector machine framework. We demonstrate the benefits of our kernel learning algorithm on object. face. action and shape recognition.,True,qYLOPxoAAAAJ:u-x6o8ySG0sC,28,https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Jayasumana_Optimizing_Over_Radial_2014_CVPR_paper.html,8779924915563324195,/scholar?cites=8779924915563324195,,,https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Jayasumana_Optimizing_Over_Radial_2014_CVPR_paper.pdf,0,0,0
1282533,Prototypical Priors: From Improving Classification to Zero-Shot Learning,2015,Saumya Jetley and Bernardino Romera-Paredes and Sadeep Jayasumana and Philip Torr,,,,,,Recent works on zero-shot learning make use of side information such as visual attributes or natural language semantics to define the relations between output visual classes and then use these relationships to draw inference on new unseen classes at test time. In a novel extension to this idea. we propose the use of visual prototypical concepts as side information. For most real-world visual object categories. it may be difficult to establish a unique prototype. However. in cases such as traffic signs. brand logos. flags. and even natural language characters. these prototypical templates are available and can be leveraged for an improved recognition performance. The present work proposes a way to incorporate this prototypical information in a deep learning framework. Using prototypes as prior information. the deepnet pipeline learns the input image projections into the prototypical embedding space subject to minimization of the final classification loss. Based on our experiments with two different datasets of traffic signs and brand logos. prototypical embeddings incorporated in a conventional convolutional neural network improve the recognition performance. Recognition accuracy on the Belga logo dataset is especially noteworthy and establishes a new state-of-the-art. In zero-shot learning scenarios. the same system can be directly deployed to draw inference on unseen classes by simply adding the prototypical information for these new classes at test time. Thus. unlike earlier approaches. testing on seen and unseen classes is handled using the same pipeline. and the system can be tuned for a trade-off of seen and unseen class performance as …,True,qYLOPxoAAAAJ:Y0pCki6q_DkC,25,https://arxiv.org/abs/1512.01192,13791491603762175292,/scholar?cites=13791491603762175292,,,https://arxiv.org/pdf/1512.01192,0,0,0
1282534,Higher order potentials in end-to-end trainable conditional random fields,2015,Anurag Arnab and Sadeep Jayasumana and Shuai Zheng and Philip HS Torr,2,arXiv preprint arXiv:1511.08119,,,,We tackle the problem of semantic segmentation using deep learning techniques. Most semantic segmentation systems include a Conditional Random Field (CRF) model to produce a structured output that is consistent with visual features of the image. With recent advances in deep learning. it is becoming increasingly common to perform CRF inference within a deep neural network to facilitate joint learning of the CRF with a pixel-wise Convolutional Neural Network (CNN) classifier. While basic CRFs use only unary and pairwise potentials. it has been shown that the addition of higher order potentials defined on cliques with more than two nodes can result in a better segmentation outcome. In this paper. we show that two types of higher order potential. namely. object detection based potentials and superpixel based potentials. can be included in a CRF embedded within a deep network. We design these higher order potentials to allow inference with the efficient and differentiable mean field algorithm. making it possible to implement our CRF model as a stack of layers in a deep network. As a result. all parameters of our richer CRF model can be jointly learned with a CNN classifier during the end-to-end training of the entire network. We find significant improvement in the results with the introduction of these trainable higher order potentials.,True,qYLOPxoAAAAJ:YsMSGLbcyi4C,24,https://www.researchgate.net/profile/Sadeep_Jayasumana2/publication/284787687_Higher_Order_Potentials_in_End-to-End_Trainable_Conditional_Random_Fields/links/56601b7c08ae1ef92985731d.pdf,16008409746292904560,/scholar?cites=16008409746292904560,,,https://www.researchgate.net/profile/Sadeep_Jayasumana2/publication/284787687_Higher_Order_Potentials_in_End-to-End_Trainable_Conditional_Random_Fields/links/56601b7c08ae1ef92985731d.pdf,0,0,0
1282535,Combining multiple manifold-valued descriptors for improved object recognition,2013,Sadeep Jayasumana and Richard Hartley and Mathieu Salzmann and Hongdong Li and Mehrtash Harandi,,,,1-6,IEEE,We present a learning method for classification using multiple manifold-valued features. Manifold techniques are becoming increasingly popular in computer vision since Riemannian geometry often comes up as a natural model for many descriptors encountered in different branches of computer vision. We propose a feature combination and selection method that optimally combines descriptors lying on different manifolds while respecting the Riemannian geometry of each underlying manifold. We use our method to improve object recognition by combining HOG~\cite{Dalal05Hog} and Region Covariance~\cite{Tuzel06} descriptors that reside on two different manifolds. To this end. we propose a kernel on the -dimensional unit sphere and prove its positive definiteness. Our experimental evaluation shows that combining these two powerful descriptors using our method results in significant improvements in …,True,qYLOPxoAAAAJ:9yKSN-GCB0IC,22,https://ieeexplore.ieee.org/abstract/document/6691493/,4917464621437118574,/scholar?cites=4917464621437118574,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.712.5309&rep=rep1&type=pdf,0,0,0
1282536,Genome-wide association study of advanced age-related macular degeneration identifies a role of the hepatic lipase gene (LIPC),2010,Benjamin M Neale and Jesen Fagerness and Robyn Reynolds and Lucia Sobrin and Margaret Parker and Soumya Raychaudhuri and Perciliz L Tan and Edwin C Oh and Joanna E Merriam and Eric Souied and Paul S Bernstein and Binxing Li and Jeanne M Frederick and Kang Zhang and Milam A Brantley and Aaron Y Lee and Donald J Zack and Betsy Campochiaro and Peter Campochiaro and Stephan Ripke and R Theodore Smith and Gaetano R Barile and Nicholas Katsanis and Rando Allikmets and Mark J Daly and Johanna M Seddon,107,Proceedings of the National Academy of Sciences,16,7395-7400,National Academy of Sciences,Advanced age-related macular degeneration (AMD) is the leading cause of late onset blindness. We present results of a genome-wide association study of 979 advanced AMD cases and 1.709 controls using the Affymetrix 6.0 platform with replication in seven additional cohorts (totaling 5.789 unrelated cases and 4.234 unrelated controls). We also present a comprehensive analysis of copy-number variations and polymorphisms for AMD. Our discovery data implicated the association between AMD and a variant in the hepatic lipase gene (LIPC) in the high-density lipoprotein cholesterol (HDL) pathway (discovery P = 4.53e-05 for rs493258). Our LIPC association was strongest for a functional promoter variant. rs10468017. (P = 1.34e-08). that influences LIPC expression and serum HDL levels with a protective effect of the minor T allele (HDL increasing) for advanced wet and dry AMD. The association we found with …,True,E84LrtYAAAAJ:u5HHmVD_uO8C,426,https://www.pnas.org/content/107/16/7395.short,775976121663827443,/scholar?cites=775976121663827443,,,https://www.pnas.org/content/pnas/107/16/7395.full.pdf,0,0,0
1282537,Artificial intelligence and deep learning in ophthalmology,2019,Daniel Shu Wei Ting and Louis R Pasquale and Lily Peng and John Peter Campbell and Aaron Y Lee and Rajiv Raman and Gavin Siew Wei Tan and Leopold Schmetterer and Pearse A Keane and Tien Yin Wong,103,British Journal of Ophthalmology,2,167-175,BMJ Publishing Group Ltd,Artificial intelligence (AI) based on deep learning (DL) has sparked tremendous global interest in recent years. DL has been widely adopted in image recognition. speech recognition and natural language processing. but is only beginning to impact on healthcare. In ophthalmology. DL has been applied to fundus photographs. optical coherence tomography and visual fields. achieving robust classification performance in the detection of diabetic retinopathy and retinopathy of prematurity. the glaucoma-like disc. macular oedema and age-related macular degeneration. DL in ocular imaging may be used in conjunction with telemedicine as a possible solution to screen. diagnose and monitor major eye diseases for patients in primary care and community settings. Nonetheless. there are also potential challenges with DL application in ophthalmology. including clinical and technical challenges. explainability of the …,True,E84LrtYAAAAJ:nb7KW1ujOQ8C,265,https://bjo.bmj.com/content/103/2/167.abstract,751448864163124448,/scholar?cites=751448864163124448,,,https://bjo.bmj.com/content/bjophthalmol/103/2/167.full.pdf,0,0,0
1282538,Common variants near FRK/COL10A1 and VEGFA are associated with advanced age-related macular degeneration,2011,Yi Yu and Tushar R Bhangale and Jesen Fagerness and Stephan Ripke and Gudmar Thorleifsson and Perciliz L Tan and Eric H Souied and Andrea J Richardson and Joanna E Merriam and Gabriëlle HS Buitendijk and Robyn Reynolds and Soumya Raychaudhuri and Kimberly A Chin and Lucia Sobrin and Evangelos Evangelou and Phil H Lee and Aaron Y Lee and Nicolas Leveziel and Donald J Zack and Betsy Campochiaro and Peter Campochiaro and R Theodore Smith and Gaetano R Barile and Robyn H Guymer and Ruth Hogg and Usha Chakravarthy and Luba D Robman and Omar Gustafsson and Haraldur Sigurdsson and Ward Ortmann and Timothy W Behrens and Kari Stefansson and André G Uitterlinden and Cornelia M van Duijn and Johannes R Vingerling and Caroline CW Klaver and Rando Allikmets and Milam A Brantley and Paul N Baird and Nicholas Katsanis and Unnur Thorsteinsdottir and John Ioannidis and Mark J Daly and Robert R Graham and Johanna M Seddon,20,Human molecular genetics,18,3699-3709,Oxford University Press,Despite significant progress in the identification of genetic loci for age-related macular degeneration (AMD). not all of the heritability has been explained. To identify variants which contribute to the remaining genetic susceptibility. we performed the largest meta-analysis of genome-wide association studies to date for advanced AMD. We imputed 6 036 699 single-nucleotide polymorphisms with the 1000 Genomes Project reference genotypes on 2594 cases and 4134 controls with follow-up replication of top signals in 5640 cases and 52 174 controls. We identified two new common susceptibility alleles. rs1999930 on 6q21-q22.3 near FRK/COL10A1 [odds ratio (OR) 0.87; P = 1.1 × 10−8] and rs4711751 on 6p12 near VEGFA (OR 1.15; P = 8.7 × 10−9). In addition to the two novel loci. 10 previously reported loci in ARMS2/HTRA1 (rs10490924). CFH (rs1061170. and rs1410996). CFB (rs641153). C3 (rs2230199 …,True,E84LrtYAAAAJ:u-x6o8ySG0sC,255,https://academic.oup.com/hmg/article-abstract/20/18/3699/554994,12709168215985980525,/scholar?cites=12709168215985980525,,,https://academic.oup.com/hmg/article/20/18/3699/554994,0,0,0
1282539,Deep Learning Is Effective for Classifying Normal versus Age-Related Macular Degeneration OCT Images,2017,Cecilia S Lee and Doug M Baughman and Aaron Y Lee,1,Ophthalmology Retina,4,322-327,Elsevier,The advent of electronic medical records (EMRs) with large electronic imaging databases along with advances in deep neural networks with machine learning has provided a unique opportunity to achieve milestones in automated image analysis. Optical coherence tomography is the most common imaging modality in ophthalmology and represents a dense and rich data set when combined with labels derived from the EMR. We sought to determine whether deep learning could be utilized to distinguish normal OCT images from images from patients with age-related macular degeneration (AMD).EMR and OCT database study.Normal and AMD patients who underwent macular OCT.Automated extraction of an OCT database was performed and linked to clinical end points from the EMR. Optical coherence tomography scans of the macula were obtained by Heidelberg Spectralis. and …,True,E84LrtYAAAAJ:hMod-77fHWUC,245,https://www.sciencedirect.com/science/article/pii/S2468653016301749,9291283528874967637,/scholar?cites=9291283528874967637,,,https://www.sciencedirect.com/science/article/pii/S2468653016301749,0,0,0
1282540,Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration,2017,Cecilia S Lee and Doug M Baughman and Aaron Y Lee,1,Ophthalmology. Retina,4,322,NIH Public Access,,True,E84LrtYAAAAJ:dhFuZR0502QC,245,,9291283528874967637,/scholar?cites=9291283528874967637,,,,0,0,0
1282541,HLA-B27 and human β2-microglobulin affect the gut microbiota of transgenic rats,2014,Phoebe Lin and Mary Bach and Mark Asquith and Aaron Y Lee and Lakshmi Akileswaran and Patrick Stauffer and Sean Davin and Yuzhen Pan and Eric D Cambronne and Martha Dorris and Justine W Debelius and Christian L Lauber and Gail Ackermann and Yoshiki V Baeza and Tejpal Gill and Rob Knight and Robert A Colbert and Joel D Taurog and Russell N Van Gelder and James T Rosenbaum,9,PloS one,8,e105684,Public Library of Science,The HLA-B27 gene is a major risk factor for clinical diseases including ankylosing spondylitis. acute anterior uveitis. reactive arthritis. and psoriatic arthritis. but its mechanism of risk enhancement is not completely understood. The gut microbiome has recently been shown to influence several HLA-linked diseases. However. the role of HLA-B27 in shaping the gut microbiome has not been previously investigated. In this study. we characterize the differences in the gut microbiota mediated by the presence of the HLA-B27 gene. We identified differences in the cecal microbiota of Lewis rats transgenic for HLA-B27 and human β2-microglobulin (hβ2m). compared with wild-type Lewis rats. using biome representational in situ karyotyping (BRISK) and 16S rRNA gene sequencing. 16S sequencing revealed significant differences between transgenic animals and wild type animals by principal coordinates analysis. Further analysis of the data set revealed an increase in Prevotella spp. and a decrease in Rikenellaceae relative abundance in the transgenic animals compared to the wild type animals. By BRISK analysis. species-specific differences included an increase in Bacteroides vulgatus abundance in HLA-B27/hβ2m and hβ2m compared to wild type rats. The finding that HLA-B27 is associated with altered cecal microbiota has not been shown before and can potentially provide a better understanding of the clinical diseases associated with this gene.,True,E84LrtYAAAAJ:2osOgNQ5qMEC,212,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0105684,9955955319767363440,/scholar?cites=9955955319767363440,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0105684,0,0,0
1282542,Pharmacogenetics of complement factor H (Y402H) and treatment of exudative age-related macular degeneration with ranibizumab,2009,Aaron Y Lee and Amanda K Raya and Steven M Kymes and Alan Shiels and Milam A Brantley,93,British Journal of Ophthalmology,5,610-613,BMJ Publishing Group Ltd.,To determine whether complement factor H (CFH) genotypes have a pharmacogenetic effect on the treatment of exudative age-related macular degeneration (AMD) with ranibizumab.A retrospective study of 156 patients with exudative AMD treated with intravitreal ranibizumab monotherapy was conducted. AMD phenotypes were characterised by clinical examination. visual acuity. fundus photography. fluorescein angiography and injection timing. Patients received intravitreal ranibizumab injections as part of routine ophthalmological care and were followed for a minimum of 9 months. Each patient was genotyped for the single nucleotide polymorphism rs1061170 (Y402H) in the CFH gene.Baseline lesion size and angiographic type. as well as mean visual acuities at baseline. 6 months. and 9 months were similar among the three CFH genotypes. Over 9 months. patients with both risk …,True,E84LrtYAAAAJ:d1gkVwhDpl0C,188,https://bjo.bmj.com/content/93/5/610.short,11016730155065718514,/scholar?cites=11016730155065718514,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3490485/,0,0,0
1282543,Deep-learning based. automated segmentation of macular edema in optical coherence tomography,2017,Cecilia S Lee and Ariel J Tyring and Nicolaas P Deruyter and Yue Wu and Ariel Rokem and Aaron Y Lee,8,Biomedical optics express,7,3440-3448,Optical Society of America,Evaluation of clinical images is essential for diagnosis in many specialties. Therefore the development of computer vision algorithms to help analyze biomedical images will be important. In ophthalmology. optical coherence tomography (OCT) is critical for managing retinal conditions. We developed a convolutional neural network (CNN) that detects intraretinal fluid (IRF) on OCT in a manner indistinguishable from clinicians. Using 1.289 OCT images. the CNN segmented images with a 0.911 cross-validated Dice coefficient. compared with segmentations by experts. Additionally. the agreement between experts and between experts and CNN were similar. Our results reveal that CNN can be trained to perform automated segmentations of clinically relevant image features.,True,E84LrtYAAAAJ:RGFaLdJalmkC,162,https://www.osapublishing.org/abstract.cfm?uri=boe-8-7-3440,15245206082034159791,/scholar?cites=15245206082034159791,,,https://www.osapublishing.org/viewmedia.cfm?seq=0&uri=boe-8-7-3440,0,0,0
1282544,Automated diabetic retinopathy image assessment software: diagnostic accuracy and cost-effectiveness compared with human graders,2017,Adnan Tufail and Caroline Rudisill and Catherine Egan and Venediktos V Kapetanakis and Sebastian Salas-Vega and Christopher G Owen and Aaron Lee and Vern Louw and John Anderson and Gerald Liew and Louis Bolter and Sowmya Srinivas and Muneeswar Nittala and SriniVas Sadda and Paul Taylor and Alicja R Rudnicka,124,Ophthalmology,3,343-351,Elsevier,With the increasing prevalence of diabetes. annual screening for diabetic retinopathy (DR) by expert human grading of retinal images is challenging. Automated DR image assessment systems (ARIAS) may provide clinically effective and cost-effective detection of retinopathy. We aimed to determine whether ARIAS can be safely introduced into DR screening pathways to replace human graders.Observational measurement comparison study of human graders following a national screening program for DR versus ARIAS.Retinal images from 20 258 consecutive patients attending routine annual diabetic eye screening between June 1. 2012. and November 4. 2013.Retinal images were manually graded following a standard national protocol for DR screening and were processed by 3 ARIAS: iGradingM. Retmarker. and EyeArt. Discrepancies between manual grades and ARIAS …,True,E84LrtYAAAAJ:4JMBOYKVnBMC,115,https://www.sciencedirect.com/science/article/pii/S0161642016320188,7931355331212052404,/scholar?cites=7931355331212052404,,,https://www.sciencedirect.com/science/article/pii/S0161642016320188,0,0,0
1282545,Automated diabetic retinopathy image assessment software: diagnostic accuracy and cost-effectiveness compared with human graders,2017,Adnan Tufail and Caroline Rudisill and Catherine Egan and Venediktos V Kapetanakis and Sebastian Salas-Vega and Christopher G Owen and Aaron Lee and Vern Louw and John Anderson and Gerald Liew and Louis Bolter and Sowmya Srinivas and Muneeswar Nittala and SriniVas Sadda and Paul Taylor and Alicja R Rudnicka,124,Ophthalmology,3,343-351,Elsevier,With the increasing prevalence of diabetes. annual screening for diabetic retinopathy (DR) by expert human grading of retinal images is challenging. Automated DR image assessment systems (ARIAS) may provide clinically effective and cost-effective detection of retinopathy. We aimed to determine whether ARIAS can be safely introduced into DR screening pathways to replace human graders.Observational measurement comparison study of human graders following a national screening program for DR versus ARIAS.Retinal images from 20 258 consecutive patients attending routine annual diabetic eye screening between June 1. 2012. and November 4. 2013.Retinal images were manually graded following a standard national protocol for DR screening and were processed by 3 ARIAS: iGradingM. Retmarker. and EyeArt. Discrepancies between manual grades and ARIAS …,True,E84LrtYAAAAJ:NMxIlDl6LWMC,115,https://www.sciencedirect.com/science/article/pii/S0161642016320188,7931355331212052404,/scholar?cites=7931355331212052404,,,https://www.sciencedirect.com/science/article/pii/S0161642016320188,0,0,0
1282546,Real-world outcomes in patients with neovascular age-related macular degeneration treated with intravitreal vascular endothelial growth factor inhibitors,2018,Hemal Mehta and Adnan Tufail and Vincent Daien and Aaron Y Lee and Vuong Nguyen and Mehmet Ozturk and Daniel Barthelmes and Mark C Gillies,65,,,127-146,Pergamon,Clinical trials identified intravitreal vascular endothelial growth factor inhibitors (anti-VEGF agents) have the potential to stabilise or even improve visual acuity outcomes in neovascular age-related macular degeneration (AMD). a sight-threatening disease. Real-world evidence allows us to assess whether results from randomised controlled trials can be applied to the general population. We describe the development of global registries. in particular the Fight Retinal Blindness! registry that originated in Australia. the United Kingdom AMD Electronic Medical Records User Group and the IRIS registry in the USA. Real-world observations relating to efficacy. safety and resource utilisation of intravitreal anti-VEGF therapy for neovascular AMD are then summarised. Novel observations that would have been challenging to identify in a clinical trial setting are then highlighted. including the risk of late disease reactivation …,True,E84LrtYAAAAJ:zA6iFVUQeVQC,102,https://www.sciencedirect.com/science/article/pii/S1350946217301052,10078919247337396220,/scholar?cites=10078919247337396220,,,https://www.sciencedirect.com/science/article/pii/S1350946217301052,0,0,0
1282547,cudnn: Efficient primitives for deep learning,2014,Sharan Chetlur and Cliff Woolley and Philippe Vandermersch and Jonathan Cohen and John Tran and Bryan Catanzaro and Evan Shelhamer,,arXiv preprint arXiv:1410.0759,,,,We present a library of efficient implementations of deep learning primitives. Deep learning workloads are computationally intensive. and optimizing their kernels is difficult and time-consuming. As parallel architectures evolve. kernels must be reoptimized. which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS). However. there is no analogous library for deep learning. Without such a library. researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels. and this work must be repeated as new parallel processors emerge. To address this problem. we have created a library similar in intent to BLAS. with optimized routines for deep learning workloads. Our implementation contains routines for GPUs. although similarly to the BLAS library. these routines could be implemented for other platforms. The library is easy to integrate into existing frameworks. and provides optimized performance and memory usage. For example. integrating cuDNN into Caffe. a popular framework for convolutional networks. improves performance by 36% on a standard model while also reducing memory consumption.,True,Rio0D9wAAAAJ:70eg2SAEIzsC,1378,https://arxiv.org/abs/1410.0759,5899211555470942760,/scholar?cites=5899211555470942760,,,https://arxiv.org/pdf/1410.0759,0,0,0
1282548,Fast tridiagonal solvers on the GPU,2010,Yao Zhang and Jonathan Cohen and John D Owens,45,ACM Sigplan Notices,5,127-136,ACM,We study the performance of three parallel algorithms and their hybrid variants for solving tridiagonal linear systems on a GPU: cyclic reduction (CR). parallel cyclic reduction (PCR) and recursive doubling (RD). We develop an approach to measure. analyze. and optimize the performance of GPU programs in terms of memory access. computation. and control overhead. We find that CR enjoys linear algorithm complexity but suffers from more algorithmic steps and bank conflicts. while PCR and RD have fewer algorithmic steps but do more work each step. To combine the benefits of the basic algorithms. we propose hybrid CR+PCR and CR+RD algorithms. which improve the performance of PCR. RD and CR by 21%. 31% and 61% respectively. Our GPU solvers achieve up to a 28x speedup over a sequential LAPACK solver. and a 12x speedup over a multi-threaded CPU solver.,True,Rio0D9wAAAAJ:qjMakFHDy7sC,296,https://dl.acm.org/doi/abs/10.1145/1837853.1693472,16150424155743228872,/scholar?cites=16150424155743228872,,,https://escholarship.org/content/qt7b441610/qt7b441610.pdf,0,0,0
1282549,An interface for sketching 3D curves,1999,Jonathan M Cohen and Lee Markosian and Robert C Zeleznik and John F Hughes and Ronen Barzel,,,,17-21,,The technique we present is an extension of the idea used in [ll. 201 that a point in 3D can be determined from its image-space projection together with that of its “shadow.”(The “shadow” is just the vertical projection of the point onto some horizontal surface.) We apply this idea to a connected set of 3D points to define a curve. With this approach. the user sketches a curve directly into a scene in two strokes: Iirst drawing the curve as it appears from the current viewpoint. and then sketching its approximate “shadow.” The effect is to redefine the 3D shape of the curve while leaving its appearance unchanged. The user can then refine portions of the curve by over-sketching either its projected image or that of its shadow. Although this technique is less precise than existing ones. it lets the user quickly sketch a reasonably correct shape that may be further refined with more conventional methods.,True,Rio0D9wAAAAJ:u5HHmVD_uO8C,161,https://dl.acm.org/doi/pdf/10.1145/300523.300655,13637206490273621716,/scholar?cites=13637206490273621716,,,ftp://128.148.32.111/pub/papers/graphics/research/cohen-i3d99.pdf,0,0,0
1282550,A fast double precision CFD code using CUDA,2009,J Cohen and M Jeroen Molemaker,,Parallel Computational Fluid Dynamics: Recent Advances and Future Directions,,414-429,,We describe a second order double precision finite volume Boussinesq code designed to run on the CUDA architecture. We perform detailed validation of the code on a variety of Rayleigh-Benard convection problems and show second order convergence. We obtain matching results with a Fortran code running on an eightcore CPU. The CUDA-accelerated code performs approximately eight times faster than the Fortran code on identical problems. As a result. we are able to run a simulation with a grid of size 3842× 192 at 1.6 seconds per time step on a machine with a single GPU.,True,Rio0D9wAAAAJ:UeHWp8X0CEIC,156,http://books.google.com/books?hl=en&lr=&id=dSsbAhavxloC&oi=fnd&pg=PA414&dq=info:SeMBx5ektP8J:scholar.google.com&ots=M0kbFRES9v&sig=4giW-HHeqa-0Qx-k6PmN9geZjEc,18425532947265348425,/scholar?cites=18425532947265348425,,,http://people.atmos.ucla.edu/nmolem/papers/Cohen2009.pdf,0,0,0
1282551,Harold: A world made of drawings,2000,Jonathan M Cohen and John F Hughes and Robert C Zeleznik,,,,83-90,,The problem of interactively creating 3D scenes from 2D input is a compelling one. and recent progress has been exciting. We present our system. Harold. which combines ideas from existing techniques and introduces new concepts to make an interactive system for creating 3D worlds. The interface paradigm in Harold is drawing: all objects are created simply by drawing them with a 2D input device. Most of the 3D objects in Harold are collections of planar strokes that are reoriented in a view-dependent way as the camera moves through the world. Virtual worlds created in Harold are rendered with a stroke-based system so that a world will maintain a hand-drawn appearance as the user navigates through it. Harold is not suitable for representing certain classes of 3D objects. especially geometrically regular or extremely asymmetric objects. However. Harold supports a large enough class of objects that a user can …,True,Rio0D9wAAAAJ:d1gkVwhDpl0C,149,https://dl.acm.org/doi/pdf/10.1145/340916.340927,6256375362352288063,/scholar?cites=6256375362352288063,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.5246&rep=rep1&type=pdf,0,0,0
1282552,A photometric approach to digitizing cultural artifacts,2001,Tim Hawkins and Jonathan Cohen and Paul Debevec,,,,333-342,,In this paper we present a photometry-based approach to the digital documentation of cultural artifacts. Rather than representing an artifact as a geometric model with spatially varying reflectance properties. we instead propose directly representing the artifact in terms of its reflectance field---the manner in which it transforms light into images. The principal device employed in our technique is a computer-controlled lighting apparatus which quickly illuminates an artifact from an exhaustive set of incident illumination directions and a set of digital video cameras which record the artifact's appearance under these forms of illumination. From this database of recorded images. we compute linear combinations of the captured images to synthetically illuminate the object under arbitrary forms of complex incident illumination. correctly capturing the effects of specular reflection. subsurface scattering. self-shadowing. mutual …,True,Rio0D9wAAAAJ:2osOgNQ5qMEC,122,https://dl.acm.org/doi/abs/10.1145/584993.585053,15368991015054332899,/scholar?cites=15368991015054332899,,,https://www.academia.edu/download/30756800/Hawkins_Photometric_2001.pdf,0,0,0
1282553,Skin: a constructive approach to modeling free-form shapes,1999,Lee Markosian and Jonathan M Cohen and Thomas Crulli and John Hughes,,,,393-400,,We present a new particle-based surface representation with which a user can interactively sculpt free-form surfaces. The particles maintain mesh connectivity and operate under rules that lead them to form triangulations with properties that make them suitable for use in subdivision. A user interactively guides the particles. which we call skin. to grow over a given collection of polyhedral elements (or skeletons). yielding a smooth surface (through subdivision) that approximates the underlying skeletal shapes. Skin resembles blobby modeling in the constructive approach to modeling it supports. but allows a richer vocabulary of skeleton shapes. supports sharp creases where desired. and provides a convenient mechanism for adding multiresolution surface detail.,True,Rio0D9wAAAAJ:u-x6o8ySG0sC,121,https://dl.acm.org/doi/pdf/10.1145/311535.311595,15376161894463308912,/scholar?cites=15376161894463308912,,,http://128.148.32.110/people/jhughes/papers/Markosian-SAC-1999/paper.pdf,0,0,0
1282554,Low Viscosity Flow Simulations for Animation.,2008,Jeroen Molemaker and Jonathan M Cohen and Sanjit Patel and Jonyong Noh,2008,Symposium on Computer Animation,,,,We present a combination of techniques to simulate turbulent fluid flows in 3D. Flow in a complex domain is modeled using a regular rectilinear grid with a finite-difference solution to the incompressible Navier-Stokes equations. We propose the use of the QUICK advection algorithm over a globally high resolution grid. To calculate pressure over the grid. we introduce the Iterated Orthogonal Projection (IOP) framework. In IOP a series of orthogonal projections ensures that multiple conditions such as non-divergence and boundary conditions arising through complex domains shapes or moving objects will be satisfied simultaneously to specified accuracy. This framework allows us to use a simple and highly efficient multigrid method to enforce non-divergence in combination with complex domain boundary conditions. IOP is amenable to GPU implementation. resulting in over an order of magnitude improvement over a CPU-based solver. We analyze the impact of these algorithms on the turbulent energy cascade in simulated fluid flows and the resulting visual quality.,True,Rio0D9wAAAAJ:IjCSPb-OGe4C,109,https://research.nvidia.com/sites/default/files/pubs/2008-07_Low-Viscosity-Flow/Molemaker_Low_2008.pdf,9081940511554939466,/scholar?cites=9081940511554939466,,,https://research.nvidia.com/sites/default/files/pubs/2008-07_Low-Viscosity-Flow/Molemaker_Low_2008.pdf,0,0,0
1282555,Real-Time high dynamic range texture mapping,2001,Jonathan Cohen and Chris Tchou and Tim Hawkins and Paul Debevec,,,,313-320,Springer. Vienna,This paper presents a technique for representing and displaying high dynamic-range texture maps (HDRTMs) using current graphics hardware. Dynamic range in real-world environments often far exceeds the range representable in 8-bit per-channel texture maps. The increased realism afforded by a high-dynamic range representation provides improved fidelity and expressiveness for interactive visualization of image-based models. Our technique allows for realtime rendering of scenes with arbitrary dynamic range. limited only by available texture memory.In our technique. high-dynamic range textures are decomposed into sets of 8-bit textures. These 8-bit textures are dynamically reassembled by the graphics hardware’s programmable multitexturing system or using multipass techniques and framebuffer image processing. These operations allow the exposure level of the texture to be adjusted …,True,Rio0D9wAAAAJ:9yKSN-GCB0IC,103,https://link.springer.com/chapter/10.1007/978-3-7091-6242-2_29,9499307409529284138,/scholar?cites=9499307409529284138,,,https://apps.dtic.mil/sti/pdfs/ADA459538.pdf,0,0,0
1282556,Scalable fluid simulation using anisotropic turbulence particles,2010,Tobias Pfaff and Nils Thuerey and Jonathan Cohen and Sarah Tariq and Markus Gross,,,,1-8,,It is usually difficult to resolve the fine details of turbulent flows. especially when targeting real-time applications. We present a novel. scalable turbulence method that uses a realistic energy model and an efficient particle representation that allows for the accurate and robust simulation of small-scale detail. We compute transport of turbulent energy using a complete two-equation k-ε model with accurate production terms that allows us to capture anisotropic turbulence effects. which integrate smoothly into the base flow. We only require a very low grid resolution to resolve the underlying base flow. As we offload complexity from the fluid solver to the particle system. we can control the detail of the simulation easily by adjusting the number of particles. without changing the large scale behavior. In addition. no computations are wasted on areas that are not visible. We demonstrate that due to the design of our algorithm it is …,True,Rio0D9wAAAAJ:ufrVoPGSRksC,96,https://dl.acm.org/doi/abs/10.1145/1866158.1866196,1231989545002818561,/scholar?cites=1231989545002818561,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.943.1709&rep=rep1&type=pdf,0,0,0
1282557,Jasper: An end-to-end convolutional neural acoustic model,2019,Jason Li and Vitaly Lavrukhin and Boris Ginsburg and Ryan Leary and Oleksii Kuchaiev and Jonathan M Cohen and Huyen Nguyen and Ravi Teja Gadde,,arXiv preprint arXiv:1904.03288,,,,In this paper. we report state-of-the-art results on LibriSpeech among end-to-end speech recognition models without any external training data. Our model. Jasper. uses only 1D convolutions. batch normalization. ReLU. dropout. and residual connections. To improve training. we further introduce a new layer-wise optimizer called NovoGrad. Through experiments. we demonstrate that the proposed deep architecture performs as well or better than more complex choices. Our deepest Jasper variant uses 54 convolutional layers. With this architecture. we achieve 2.95% WER using a beam-search decoder with an external neural language model and 3.86% WER with a greedy decoder on LibriSpeech test-clean. We also report competitive results on the Wall Street Journal and the Hub5'00 conversational evaluation datasets.,True,Rio0D9wAAAAJ:t7zJ5fGR-2UC,94,https://arxiv.org/abs/1904.03288,17783694528257490731,/scholar?cites=17783694528257490731,,,https://arxiv.org/pdf/1904.03288,0,0,0
1282558,Deep speech 2: End-to-end speech recognition in english and mandarin,2016,Dario Amodei and Sundaram Ananthanarayanan and Rishita Anubhai and Jingliang Bai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Qiang Cheng and Guoliang Chen and Jie Chen and Jingdong Chen and Zhijie Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Ke Ding and Niandong Du and Erich Elsen and Jesse Engel and Weiwei Fang and Linxi Fan and Christopher Fougner and Liang Gao and Caixia Gong and Awni Hannun and Tony Han and Lappi Johannes and Bing Jiang and Cai Ju and Billy Jun and Patrick LeGresley and Libby Lin and Junjie Liu and Yang Liu and Weigao Li and Xiangang Li and Dongpeng Ma and Sharan Narang and Andrew Ng and Sherjil Ozair and Yiping Peng and Ryan Prenger and Sheng Qian and Zongfeng Quan and Jonathan Raiman and Vinay Rao and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Kavya Srinet and Anuroop Sriram and Haiyuan Tang and Liliang Tang and Chong Wang and Jidong Wang and Kaifu Wang and Yi Wang and Zhijian Wang and Zhiqian Wang and Shuang Wu and Likai Wei and Bo Xiao and Wen Xie and Yan Xie and Dani Yogatama and Bin Yuan and Jun Zhan and Zhenyao Zhu,,,,173-182,PMLR,We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks. end-to-end learning allows us to handle a diverse variety of speech including noisy environments. accents and different languages. Key to our approach is our application of HPC techniques. enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result. in several cases. our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally. using a technique called Batch Dispatch with GPUs in the data center. we show that our system can be inexpensively deployed in an online setting. delivering low latency when serving users at scale.,True,xQAoHP0AAAAJ:WF5omc3nYNoC,2028,http://proceedings.mlr.press/v48/amodei16.html,16030706496972570658,/scholar?cites=16030706496972570658,,,http://proceedings.mlr.press/v48/amodei16.html,0,0,0
1282559,Deep voice: Real-time neural text-to-speech,2017,Sercan Ö Arık and Mike Chrzanowski and Adam Coates and Gregory Diamos and Andrew Gibiansky and Yongguo Kang and Xian Li and John Miller and Andrew Ng and Jonathan Raiman and Shubho Sengupta and Mohammad Shoeybi,,,,195-204,PMLR,We present Deep Voice. a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries. a grapheme-to-phoneme conversion model. a phoneme duration prediction model. a fundamental frequency prediction model. and an audio synthesis model. For the segmentation model. we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model. we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component. our system is simpler and more flexible than traditional text-to-speech systems. where each component requires laborious feature engineering and extensive domain expertise. Finally. we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations.,True,xQAoHP0AAAAJ:Tyk-4Ss8FVUC,387,http://proceedings.mlr.press/v70/arik17a.html,18296399576126585694,/scholar?cites=18296399576126585694,,,http://proceedings.mlr.press/v70/arik17a/arik17a.pdf,0,0,0
1282560,Dota 2 with large scale deep reinforcement learning,2019,Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemysław Dębiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Pondé de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang,,arXiv preprint arXiv:1912.06680,,,,On April 13th. 2019. OpenAI Five became the first AI system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons. imperfect information. and complex. continuous state-action spaces. all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques. scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG). OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.,True,xQAoHP0AAAAJ:MXK_kJrjxJIC,248,https://arxiv.org/abs/1912.06680,13702817620040192625,/scholar?cites=13702817620040192625,,,https://arxiv.org/pdf/1912.06680,0,0,0
1282561,Deep voice 3: Scaling text-to-speech with convolutional sequence learning,2017,Wei Ping and Kainan Peng and Andrew Gibiansky and Sercan O Arik and Ajay Kannan and Sharan Narang and Jonathan Raiman and John Miller,,arXiv preprint arXiv:1710.07654,,,,We present Deep Voice 3. a fully-convolutional attention-based neural text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS. training on more than eight hundred hours of audio from over two thousand speakers. In addition. we identify common error modes of attention-based speech synthesis networks. demonstrate how to mitigate them. and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server.,True,xQAoHP0AAAAJ:9yKSN-GCB0IC,226,https://arxiv.org/abs/1710.07654,1828409622662260131,/scholar?cites=1828409622662260131,,,https://arxiv.org/pdf/1710.07654,0,0,0
1282562,Deep voice 3: 2000-speaker neural text-to-speech,2018,Wei Ping and Kainan Peng and Andrew Gibiansky and Sercan O Arik and Ajay Kannan and Sharan Narang and Jonathan Raiman and John Miller,,Proc. ICLR,,214-217,,We present Deep Voice 3. a fully-convolutional attention-based neural textto-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training an order of magnitude faster. We scale Deep Voice 3 to dataset sizes unprecedented for TTS. training on more than eight hundred hours of audio from over two thousand speakers. In addition. we identify common error modes of attention-based speech synthesis networks. demonstrate how to mitigate them. and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on a single GPU server.,True,xQAoHP0AAAAJ:YsMSGLbcyi4C,154,https://openreview.net/references/pdf?id=SyD5g8sPM,14771797392645709146,/scholar?cites=14771797392645709146,,,https://openreview.net/references/pdf?id=SyD5g8sPM,0,0,0
1282563,Deep voice 2: Multi-speaker neural text-to-speech,2017,Sercan Arik and Gregory Diamos and Andrew Gibiansky and John Miller and Kainan Peng and Wei Ping and Jonathan Raiman and Yanqi Zhou,,arXiv preprint arXiv:1705.08947,,,,We introduce a technique for augmenting neural text-to-speech (TTS) with lowdimensional trainable speaker embeddings to generate different voices from a single model. As a starting point. we show improvements over the two state-ofthe-art approaches for single-speaker neural TTS: Deep Voice 1 and Tacotron. We introduce Deep Voice 2. which is based on a similar pipeline with Deep Voice 1. but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over Deep Voice 1. We improve Tacotron by introducing a post-processing neural vocoder. and demonstrate a significant audio quality improvement. We then demonstrate our technique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron on two multi-speaker TTS datasets. We show that a single neural TTS system can learn hundreds of unique voices from less than half an hour of data per speaker. while achieving high audio quality synthesis and preserving the speaker identities almost perfectly.,True,xQAoHP0AAAAJ:M3ejUd6NZC8C,152,https://arxiv.org/abs/1705.08947,13044712636720181335,/scholar?cites=13044712636720181335,,,https://arxiv.org/pdf/1705.08947,0,0,0
1282564,Deep Voice 2: Multi-Speaker Neural Text-to-Speech.,2017,Andrew Gibiansky and Sercan Ömer Arik and Gregory Frederick Diamos and John Miller and Kainan Peng and Wei Ping and Jonathan Raiman and Yanqi Zhou,,,,,,We introduce a technique for augmenting neural text-to-speech (TTS) with low-dimensional trainable speaker embeddings to generate different voices from a single model. As a starting point. we show improvements over the two state-of-the-art approaches for single-speaker neural TTS: Deep Voice 1 and Tacotron. We introduce Deep Voice 2. which is based on a similar pipeline with Deep Voice 1. but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over Deep Voice 1. We improve Tacotron by introducing a post-processing neural vocoder. and demonstrate a significant audio quality improvement. We then demonstrate our technique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron on two multi-speaker TTS datasets. We show that a single neural TTS system can learn hundreds of unique voices from less than half an hour of data …,True,xQAoHP0AAAAJ:d1gkVwhDpl0C,147,https://openreview.net/forum?id=VlCBpLUSPTz,188402189689268087,/scholar?cites=188402189689268087,,,,0,0,0
1282565,Deeptype: multilingual entity linking by neural type system evolution,2018,Jonathan Raiman and Olivier Raiman,32,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,The wealth of structured (eg Wikidata) and unstructured data about the world available today presents an incredible opportunity for tomorrow's Artificial Intelligence. So far. integration of these two different modalities is a difficult process. involving many decisions concerning how best to represent the information so that it will be captured or useful. and hand-labeling large amounts of data. DeepType overcomes this challenge by explicitly integrating symbolic information into the reasoning process of a neural network with a type system. First we construct a type system. and second. we use it to constrain the outputs of a neural network to respect the symbolic structure. We achieve this by reformulating the design problem into a mixed integer problem: create a type system and subsequently train a neural network with it. In this reformulation discrete variables select which parent-child relations from an ontology are types within the type system. while continuous variables control a classifier fit to the type system. The original problem cannot be solved exactly. so we propose a 2-step algorithm: 1) heuristic search or stochastic optimization over discrete variables that define a type system informed by an Oracle and a Learnability heuristic. 2) gradient descent to fit classifier parameters. We apply DeepType to the problem of Entity Linking on three standard datasets (ie WikiDisamb30. CoNLL (YAGO). TAC KBP 2010) and find that it outperforms all existing solutions by a wide margin. including approaches that rely on a human-designed type system or recent deep learning-based entity embeddings. while explicitly using symbolic information lets it integrate new …,True,xQAoHP0AAAAJ:ufrVoPGSRksC,100,https://ojs.aaai.org/index.php/AAAI/article/view/12008,16583887833961895306,/scholar?cites=16583887833961895306,,,https://ojs.aaai.org/index.php/AAAI/article/view/12008/11867,0,0,0
1282566,Globally Normalized Reader,2017,Jonathan Raiman and John Miller,,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,,1059--1069,Association for Computational Linguistics,Rapid progress has been made towards question answering (QA) systems that can extract answers from text. Existing neural approaches make use of expensive bi-directional attention mechanisms or score all possible answer spans. limiting scalability. We propose instead to cast extractive QA as an iterative search problem: select the answer's sentence. start word. and end word. This representation reduces the space of each search step and allows computation to be conditionally allocated to promising search paths. We show that globally normalizing the decision process and back-propagating through beam search makes this representation viable and learning efficient. We empirically demonstrate the benefits of this approach using our model. Globally Normalized Reader (GNR). which achieves the second highest single model performance on the Stanford Question Answering Dataset (68.4 EM. 76.21 F1 dev) and is 24.7 x faster than bi-attention-flow. We also introduce a data-augmentation method to produce semantically valid examples by aligning named entities to a knowledge base and swapping them with new entities of the same type. This method improves the performance of all models considered in this work and is of independent interest for a variety of NLP tasks.,True,xQAoHP0AAAAJ:hqOjcs7Dif8C,18,https://arxiv.org/abs/1709.02828,20025758500129072,/scholar?cites=20025758500129072,,,https://arxiv.org/pdf/1709.02828,0,0,0
1282567,End to end speech recognition in English and Mandarin,2016,Dario Amodei and Rishita Anubhai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Jingdong Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Erich Elsen and Jesse Engel and Linxi Fan and Christopher Fougner and Tony Han and Awni Hannun and Billy Jun and Patrick LeGresley and Libby Lin and Sharan Narang and Andrew Ng and Sherjil Ozair and Ryan Prenger and Jonathan Raiman and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Yi Wang and Zhiqian Wang and Chong Wang and Bo Xiao and Dani Yogatama and Jun Zhan and Zhenyao Zhu,,,,,,We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks. end-to-end learning allows us to handle a diverse variety of speech including noisy environments. accents and different languages. Key to our approach is our application of HPC techniques. enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result. in several cases. our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally. using a technique called Batch Dispatch with GPUs in the data center. we show that our system can be inexpensively deployed in an online setting. delivering low latency when serving users at scale.,True,xQAoHP0AAAAJ:2osOgNQ5qMEC,16,https://openreview.net/pdf/XL9vPjMAjuXB8D1RUG6L.pdf,4043401544031822907,/scholar?cites=4043401544031822907,,,https://openreview.net/pdf/XL9vPjMAjuXB8D1RUG6L.pdf,0,0,0
1282568,Openai five. 2018,2018,Jakub Pachocki and Greg Brockman and Jonathan Raiman and Susan Zhang and Henrique Pondé and Jie Tang and Filip Wolski and Christy Dennison and Rafal Jozefowicz and Przemyslaw Debiak and Brooke Chan and Szymon Sidor and David Farhi and David Petrov,,URL https://blog. openai. com/openai-five,,,,,True,xQAoHP0AAAAJ:4TOpqqG69KYC,14,http://scholar.google.com/scholar?cluster=18417296086356745980&hl=en&oi=scholarr,18417296086356745980,/scholar?cites=18417296086356745980,,,,0,0,0
1282569,Detailed real-time urban 3d reconstruction from video,2008,Marc Pollefeys and David Nistér and J-M Frahm and Amir Akbarzadeh and Philippos Mordohai and Brian Clipp and Chris Engels and David Gallup and S-J Kim and Paul Merrell and Christina Salmi and Sudipta Sinha and Brad Talton and Liang Wang and Qingxiong Yang and Henrik Stewénius and Ruigang Yang and Greg Welch and Herman Towles,78,International Journal of Computer Vision,2,143-167,Springer US, The paper presents a system for automatic. geo-registered. real-time 3D reconstruction from video of urban scenes. The system collects video streams. as well as GPS and inertia measurements in order to place the reconstructed models in geo-registered coordinates. It is designed using current state of the art real-time modules for all processing steps. It employs commodity graphics hardware and standard CPU’s to achieve real-time performance. We present the main considerations in designing the system and the steps of the processing pipeline. Our system extends existing algorithms to meet the robustness and variability necessary to operate out of the lab. To account for the large dynamic range of outdoor videos the processing pipeline estimates global camera gain changes in the feature tracking stage and efficiently compensates for these in stereo estimation without impacting the real-time …,True,1F2czKYAAAAJ:u5HHmVD_uO8C,913,https://link.springer.com/article/10.1007%252Fs11263-007-0086-4,12939195738550888198,/scholar?cites=12939195738550888198,,,http://cvg-pub.inf.ethz.ch/WebBIB/papers/1900/002_fulltext.pdf,0,0,0
1282570,Robust radiometric calibration and vignetting correction,2008,Seon Joo Kim and Marc Pollefeys,30,IEEE transactions on pattern analysis and machine intelligence,4,562-576,IEEE,In many computer vision systems. it is assumed that the image brightness of a point directly reflects the scene radiance of the point. However. the assumption does not hold in most cases due to nonlinear camera response function. exposure changes. and vignetting. The effects of these factors are most visible in image mosaics and textures of 3D models where colors look inconsistent and notable boundaries exist. In this paper. we propose a full radiometric calibration algorithm that includes robust estimation of the radiometric response function. exposures. and vignetting. By decoupling the effect of vignetting from the response function estimation. we approach each process in a manner that is robust to noise and outliers. We verify our algorithm with both synthetic and real data. which shows significant improvement compared to existing methods. We apply our estimation results to radiometrically align images for …,True,1F2czKYAAAAJ:d1gkVwhDpl0C,263,https://ieeexplore.ieee.org/abstract/document/4359347/,6547822885598377633,/scholar?cites=6547822885598377633,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.361.6140&rep=rep1&type=pdf,0,0,0
1282571,Constructing image panoramas using dual-homography warping,2011,Junhong Gao and Seon Joo Kim and Michael S Brown,,,,49-56,IEEE,This paper describes a method to construct seamless image mosaics of a panoramic scene containing two predominate planes: a distant back plane and a ground plane that sweeps out from the camera's location. While this type of panorama can be stitched when the camera is carefully rotated about its optical center. such ideal scene capture is hard to perform correctly. Existing techniques use a single homography per image to perform alignment followed by seam cutting or image blending to hide inevitable alignments artifacts. In this paper. we demonstrate how to use two homographies per image to produce a more seamless image. Specifically. our approach blends the homographies in the alignment procedure to perform a nonlinear warping. Once the images are geometrically stitched. they are further processed to blend seams and reduce curvilinear visual artifacts due to the nonlinear warping. As …,True,1F2czKYAAAAJ:W7OEmFMy1HYC,227,https://ieeexplore.ieee.org/abstract/document/5995433/,12130654627336847023,/scholar?cites=12130654627336847023,,,http://www.cse.yorku.ca/~mbrown/pdf/cvpr_dualhomography2011.pdf,0,0,0
1282572,Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation,2018,Younghyun Jo and Seoung Wug Oh and Jaeyeon Kang and Seon Joo Kim,,,,3224-3232,,Video super-resolution (VSR) has become even more important recently to provide high resolution (HR) contents for ultra high definition displays. While many deep learning based VSR methods have been proposed. most of them rely heavily on the accuracy of motion estimation and compensation. We introduce a fundamentally different framework for VSR in this paper. We propose a novel end-to-end deep neural network that generates dynamic upsampling filters and a residual image. which are computed depending on the local spatio-temporal neighborhood of each pixel to avoid explicit motion compensation. With our approach. an HR image is reconstructed directly from the input image using the dynamic upsampling filters. and the fine details are added through the computed residual. Our network with the help of a new data augmentation technique can generate much sharper HR videos with temporal consistency. compared with the previous methods. We also provide analysis of our network through extensive experiments to show how the network deals with motions implicitly.,True,1F2czKYAAAAJ:u9iWguZQMMsC,187,http://openaccess.thecvf.com/content_cvpr_2018/html/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.html,14547343431451944570,/scholar?cites=14547343431451944570,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf,0,0,0
1282573,Fast Video Object Segmentation by Reference-Guided Mask Propagation,2018,Seoung Wug Oh and Joon-Young Lee and Kalyan Sunkavalli and Seon Joo Kim,,,,7376-7385,,We present an efficient method for the semi-supervised video object segmentation. Our method achieves accuracy competitive with state-of-the-art methods while running in a fraction of time compared to others. To this end. we propose a deep Siamese encoder-decoder network that is designed to take advantage of mask propagation and object detection while avoiding the weaknesses of both approaches. Our network. learned through a two-stage training process that exploits both synthetic and real data. works robustly without any online learning or post-processing. We validate our method on four benchmark sets that cover single and multiple object segmentation. On all the benchmark sets. our method shows comparable accuracy while having the order of magnitude faster runtime. We also provide extensive ablation and add-on studies to analyze and evaluate our framework.,True,1F2czKYAAAAJ:p2g8aNsByqUC,166,http://openaccess.thecvf.com/content_cvpr_2018/html/Oh_Fast_Video_Object_CVPR_2018_paper.html,9213245007933084222,/scholar?cites=9213245007933084222,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Oh_Fast_Video_Object_CVPR_2018_paper.pdf,0,0,0
1282574,A New In-Camera Imaging Model for Color Computer Vision and its Application,2012,SJ Kim and H Lin and Zheng Lu and Sabine Susstrunk and Stephen Lin and M Brown,,"Pattern Analysis and Machine Intelligence, IEEE Transactions on",99,1-1,IEEE,We present a study of in-camera image processing through an extensive analysis of more than 10.000 images from over 30 cameras. The goal of this work is to investigate if image values can be transformed to physically meaningful values. and if so. when and how this can be done. From our analysis. we found a major limitation of the imaging model employed in conventional radiometric calibration methods and propose a new in-camera imaging model that fits well with today's cameras. With the new model. we present associated calibration procedures that allow us to convert sRGB images back to their original CCD RAW responses in a manner that is significantly more accurate than any existing methods. Additionally. we show how this new imaging model can be used to build an image correction application that converts an sRGB input image captured with the wrong camera settings to an sRGB output image that …,True,1F2czKYAAAAJ:roLk4NBRz8UC,140,https://ieeexplore.ieee.org/abstract/document/6158647/,15903963369777119673,/scholar?cites=15903963369777119673,,,https://infoscience.epfl.ch/record/175950/files/Kim2012.pdf,0,0,0
1282575,Video Object Segmentation using Space-Time Memory Networks,2019,Seoung Wug Oh and Joon-Young Lee and Ning Xu and Seon Joo Kim,,,,9226-9235,,We propose a novel solution for semi-supervised video object segmentation. By the nature of the problem. available cues (eg video frame (s) with object masks) become richer with the intermediate predictions. However. the existing methods are unable to fully exploit this rich source of information. We resolve the issue by leveraging memory networks and learn to read relevant information from all available sources. In our framework. the past frames with object masks form an external memory. and the current frame as the query is segmented using the mask information in the memory. Specifically. the query and the memory are densely matched in the feature space. covering all the space-time pixel locations in a feed-forward fashion. Contrast to the previous approaches. the abundant use of the guidance information allows us to better handle the challenges such as appearance changes and occlussions. We validate our method on the latest benchmark sets and achieved the state-of-the-art performance (overall score of 79.4 on Youtube-VOS val set. J of 88.7 and 79.2 on DAVIS 2016/2017 val set respectively) while having a fast runtime (0.16 second/frame on DAVIS 2016 val set).,True,1F2czKYAAAAJ:fQNAKQ3IYiAC,113,http://openaccess.thecvf.com/content_ICCV_2019/html/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.html,4811785222141175494,/scholar?cites=4811785222141175494,,,https://openaccess.thecvf.com/content_ICCV_2019/papers/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.pdf,0,0,0
1282576,Visual enhancement of old documents with hyperspectral imaging,2011,Seon Joo Kim and Fanbo Deng and Michael S Brown,,Pattern Recognition,,,Pergamon,Hyperspectral imaging (HSI) of historical documents is becoming more common at national libraries and archives. HSI is useful for many tasks related to document conservation and management as it provides detailed quantitative measurements of the spectral reflectance of the document that is not limited to the visible spectrum. In this paper. we focus on how to use the invisible spectra. most notably near-infrared (NIR) bands. to assist in visually enhancing old documents. Specifically. we demonstrate how to use the invisible bands to improve the visual quality of text-based documents corrupted with undesired artifacts such as ink-bleed. ink-corrosion. and foxing. For documents of line drawings that suffer from low contrast. we use details found in the invisible bands to enhance legibility. The key components of our framework involve detecting regions in the document that can be enhanced by the NIR spectra …,True,1F2czKYAAAAJ:WF5omc3nYNoC,111,https://www.sciencedirect.com/science/article/pii/S0031320311000045,4184474816324452491,/scholar?cites=4184474816324452491,,,,0,0,0
1282577,A holistic approach to cross-channel image noise modeling and its application to image denoising,2016,Seonghyeon Nam and Youngbae Hwang and Yasuyuki Matsushita and Seon Joo Kim,,,,1683-1691,,Modelling and analyzing noise in images is a fundamental task in many computer vision systems. Traditionally. noise has been modelled per color channel assuming that the color channels are independent. Although the color channels can be considered as mutually independent in camera RAW images. signals from different color channels get mixed during the imaging process inside the camera due to gamut mapping. tone-mapping. and compression. We show the influence of the in-camera imaging pipeline on noise and propose a new noise model in the 3D RGB space to accounts for the color channel mix-ups. A data-driven approach for determining the parameters of the new noise model is introduced as well as its application to image denoising. The experiments show that our noise model represents the noise in regular JPEG images more accurately compared to the previous models and is advantageous in image denoising.,True,1F2czKYAAAAJ:pyW8ca7W8N0C,105,http://openaccess.thecvf.com/content_cvpr_2016/html/Nam_A_Holistic_Approach_CVPR_2016_paper.html,4334936717689802868,/scholar?cites=4334936717689802868,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Nam_A_Holistic_Approach_CVPR_2016_paper.pdf,0,0,0
1282578,Color transfer using probabilistic moving least squares,2014,Youngbae Hwang and Joon-Young Lee and In So Kweon and Seon Joo Kim,,,,3342-3349,,This paper introduces a new color transfer method which is a process of transferring color of an image to match the color of another image of the same scene. The color of a scene may vary from image to image because the photographs are taken at different times. with different cameras. and under different camera settings. To solve for a full nonlinear and nonparametric color mapping in the 3D RGB color space. we propose a scattered point interpolation scheme using moving least squares and strengthen it with a probabilistic modeling of the color transfer in the 3D color space to deal with mis-alignments and noise. Experiments show the effectiveness of our method over previous color transfer methods both quantitatively and qualitatively. In addition. our framework can be applied for various instances of color transfer such as transferring color between different camera models. camera settings. and illumination conditions. as well as for video color transfers.,True,1F2czKYAAAAJ:yD5IFk8b50cC,95,http://openaccess.thecvf.com/content_cvpr_2014/html/Hwang_Color_Transfer_Using_2014_CVPR_paper.html,6135796440460266003,/scholar?cites=6135796440460266003,,,https://openaccess.thecvf.com/content_cvpr_2014/papers/Hwang_Color_Transfer_Using_2014_CVPR_paper.pdf,0,0,0
1282579,Epinet: A fully-convolutional neural network using epipolar geometry for depth from light field images,2018,Changha Shin and Hae-Gon Jeon and Youngjin Yoon and In So Kweon and Seon Joo Kim,,,,4748-4757,,Light field cameras capture both the spatial and the angular properties of light rays in space. Due to its property. one can compute the depth from light fields in uncontrolled lighting environments. which is a big advantage over active sensing devices. Depth computed from light fields can be used for many applications including 3D modelling and refocusing. However. light field images from hand-held cameras have very narrow baselines with noise. making the depth estimation difficult. Many approaches have been proposed to overcome these limitations for the light field depth estimation. but there is a clear trade-off between the accuracy and the speed in these methods. In this paper. we introduce a fast and accurate light field depth estimation method based on a fully-convolutional neural network. Our network is designed by considering the light field geometry and we also overcome the lack of training data by proposing light field specific data augmentation methods. We achieved the top rank in the HCI 4D Light Field Benchmark on most metrics. and we also demonstrate the effectiveness of the proposed method on real-world light-field images.,True,1F2czKYAAAAJ:XiSMed-E-HIC,90,http://openaccess.thecvf.com/content_cvpr_2018/html/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.html,3895981395102311254,/scholar?cites=3895981395102311254,,,https://openaccess.thecvf.com/content_cvpr_2018/papers/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.pdf,0,0,0
1282580,Phaselift: Exact and stable signal recovery from magnitude measurements via convex programming,2013,Emmanuel J Candes and Thomas Strohmer and Vladislav Voroninski,66,Communications on Pure and Applied Mathematics,8,1241-1274,Wiley Subscription Services. Inc.. A Wiley Company,Suppose we wish to recover a signal\input amssym \font\abc=cmmib10\def\bi#1\abc#1\bix∈\BbbC^n from m intensity measurements of the form \font\abc=cmmib10\def\bi#1\abc#1|⟨\bix.\biz_i⟩|^2. i=1.2.....m; that is. from data in which phase information is missing. We prove that if the vectors \font\abc=cmmib10\def\bi#1\abc#1\biz_i are sampled independently and uniformly at random on the unit sphere. then the signal x can be recovered exactly (up to a global phase factor) by solving a convenient semidefinite program–‐a trace‐norm minimization problem; this holds with large probability provided that m is on the order of n\logn. and without any assumption about the signal whatsoever. This novel result demonstrates that in some instances. the combinatorial phase retrieval problem can be solved by convex programming techniques. Finally. we also prove that our methodology is robust vis‐à‐vis additive noise.© …,True,P8NRbbYAAAAJ:u5HHmVD_uO8C,1095,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21432,7493782083937418092,/scholar?cites=7493782083937418092,,,https://arxiv.org/pdf/1109.4499,0,0,0
1282581,Phase retrieval via matrix completion,2015,Emmanuel J Candes and Yonina C Eldar and Thomas Strohmer and Vladislav Voroninski,57,SIAM review,2,225-251,Society for Industrial and Applied Mathematics,This paper develops a novel framework for phase retrieval. a problem which arises in X-ray crystallography. diffraction imaging. astronomical imaging. and many other applications. Our approach. called PhaseLift. combines multiple structured illuminations together with ideas from convex programming to recover the phase from intensity measurements. typically from the modulus of the diffracted wave.  We demonstrate empirically that a complex-valued object can be recovered from the knowledge of the magnitude of just a few diffracted patterns by solving a simple convex optimization problem inspired by the recent literature on matrix completion. More importantly. we also demonstrate that our noise-aware algorithms are stable in the sense that the reconstruction degrades gracefully as the signal-to-noise ratio decreases. Finally. we introduce some theory showing that one can design very simple structured …,True,P8NRbbYAAAAJ:u-x6o8ySG0sC,946,https://epubs.siam.org/doi/abs/10.1137/151005099,9530517717718244556,/scholar?cites=9530517717718244556,,,https://arxiv.org/pdf/1109.0573,0,0,0
1282582,Sparse signal recovery from quadratic measurements via convex programming,2013,Xiaodong Li and Vladislav Voroninski,45,SIAM Journal on Mathematical Analysis,5,3019-3033,Society for Industrial and Applied Mathematics,In this paper we consider a system of quadratic equations $|\langle \bm{z_j}. \bm{x}\rangle|^2=b_j. j=1.\ldots.m$. where $\bm{x} \in \mathbb{R}^n$ is unknown while normal random vectors $\bm{z_j} \in \mathbb{R}^n$ and quadratic measurements $b_j \in \mathbb{R}$ are known. The system is assumed to be underdetermined. i.e.. $m<n$. We prove that if there exists a sparse solution $\bm{x}$. i.e.. at most $k$ components of $\bm{x}$ are nonzero. then by solving a convex optimization program. we can solve for $\bm{x}$ up to a multiplicative constant with high probability. provided that $k\leq O(\sqrt{m\over{\log n}})$. On the other hand. we prove that $k \leq O(\log n\sqrt{m})$ is necessary for a class of natural convex relaxations to be exact.,True,P8NRbbYAAAAJ:d1gkVwhDpl0C,235,https://epubs.siam.org/doi/abs/10.1137/120893707,11210462214101692386,/scholar?cites=11210462214101692386,,,https://arxiv.org/pdf/1209.4785,0,0,0
1282583,The non-convex Burer-Monteiro approach works on smooth semidefinite programs,2016,Nicolas Boumal and Vladislav Voroninski and Afonso S Bandeira,,arXiv preprint arXiv:1606.04970,,,,Semidefinite programs (SDPs) can be solved in polynomial time by interior point methods. but scalability can be an issue. To address this shortcoming. over a decade ago. Burer and Monteiro proposed to solve SDPs with few equality constraints via rank-restricted. non-convex surrogates. Remarkably. for some applications. local optimization methods seem to converge to global optima of these non-convex surrogates reliably. Although some theory supports this empirical success. a complete explanation of it remains an open question. In this paper. we consider a class of SDPs which includes applications such as max-cut. community detection in the stochastic block model. robust PCA. phase retrieval and synchronization of rotations. We show that the low-rank Burer--Monteiro formulation of SDPs in that class almost never has any spurious local optima.,True,P8NRbbYAAAAJ:roLk4NBRz8UC,178,https://arxiv.org/abs/1606.04970,16032063470049481750,/scholar?cites=16032063470049481750,,,https://arxiv.org/pdf/1606.04970,0,0,0
1282584,A survey of structure from motion,2017,Onur Ozyesil and Vladislav Voroninski and Ronen Basri and Amit Singer,,arXiv preprint arXiv:1701.08493,,,,The structure from motion (SfM) problem in computer vision is the problem of recovering the three-dimensional ( D) structure of a stationary scene from a set of projective measurements. represented as a collection of two-dimensional ( D) images. via estimation of motion of the cameras corresponding to these images. In essence. SfM involves the three main stages of (1) extraction of features in images (eg. points of interest. lines. etc.) and matching these features between images.(2) camera motion estimation (eg. using relative pairwise camera positions estimated from the extracted features). and (3) recovery of the  D structure using the estimated motion and features (eg. by minimizing the so-called reprojection error). This survey mainly focuses on relatively recent developments in the literature pertaining to stages (2) and (3). More specifically. after touching upon the early factorization-based techniques for motion and structure estimation. we provide a detailed account of some of the recent camera location estimation methods in the literature. followed by discussion of notable techniques for  D structure recovery. We also cover the basics of the simultaneous localization and mapping (SLAM) problem. which can be viewed as a specific case of the SfM problem. Further. our survey includes a review of the fundamentals of feature extraction and matching (ie. stage (1) above). various recent methods for handling ambiguities in  D scenes. SfM techniques involving relatively uncommon camera models and image features. and popular sources of data and SfM software.,True,P8NRbbYAAAAJ:KlAtU1dfN6UC,159,https://arxiv.org/abs/1701.08493,3018079256250381376,/scholar?cites=3018079256250381376,,,https://arxiv.org/pdf/1701.08493,0,0,0
1282585,On the low-rank approach for semidefinite programs arising in synchronization and community detection,2016,Afonso S Bandeira and Nicolas Boumal and Vladislav Voroninski,,,,361-382,PMLR,To address difficult optimization problems. convex relaxations based on semidefinite programming are now common place in many fields. Although solvable in polynomial time. large semidefinite programs tend to be computationally challenging. Over a decade ago. exploiting the fact that in many applications of interest the desired solutions are low rank. Burer and Monteiro proposed a heuristic to solve such semidefinite programs by restricting the search space to low-rank matrices. The accompanying theory does not explain the extent of the empirical success. We focus on Synchronization and Community Detection problems and provide theoretical guarantees shedding light on the remarkable efficiency of this heuristic.,True,P8NRbbYAAAAJ:LkGwnXOMwfcC,125,http://proceedings.mlr.press/v49/bandeira16.html,2971443224711329978,/scholar?cites=2971443224711329978,,,http://proceedings.mlr.press/v49/bandeira16.pdf,0,0,0
1282586,Global guarantees for enforcing deep generative priors by empirical risk,2018,Paul Hand and Vladislav Voroninski,,,,970-978,PMLR,We examine the theoretical properties of enforcing priors provided by generative deep neural networks via empirical risk minimization. In particular we consider two models. one in which the task is to invert a generative neural network given access to its last layer and another in which the task is to invert a generative neural network given only compressive linear observations of its last layer. We establish that in both cases. in suitable regimes of network layer sizes and a randomness assumption on the network weights. that the non-convex objective function given by empirical risk minimization does not have any spurious stationary points. That is. we establish that with high probability. at any point away from small neighborhoods around two scalar multiples of the desired solution. there is a descent direction. Hence. there are no local minima. saddle points. or other stationary points outside these neighborhoods. These results constitute the first theoretical guarantees which establish the favorable global geometry of these non-convex optimization problems. and they bridge the gap between the empirical success of enforcing deep generative priors and a rigorous understanding of non-linear inverse problems.,True,P8NRbbYAAAAJ:aqlVkmm33-oC,103,http://proceedings.mlr.press/v75/hand18a.html,13543035107030106805,/scholar?cites=13543035107030106805,,,http://proceedings.mlr.press/v75/hand18a/hand18a.pdf,0,0,0
1282587,Phase retrieval under a generative prior,2018,Paul Hand and Oscar Leong and Vladislav Voroninski,,arXiv preprint arXiv:1807.04261,,,,The phase retrieval problem asks to recover a natural signal  from  quadratic observations. where  is to be minimized. As is common in many imaging problems. natural signals are considered sparse with respect to a known basis. and the generic sparsity prior is enforced via  regularization. While successful in the realm of linear inverse problems. such  methods have encountered possibly fundamental limitations. as no computationally efficient algorithm for phase retrieval of a -sparse signal has been proven to succeed with fewer than  generic measurements. exceeding the theoretical optimum of . In this paper. we propose a novel framework for phase retrieval by 1) modeling natural signals as being in the range of a deep generative neural network  and 2) enforcing this prior directly by optimizing an empirical risk objective over the domain of the generator. Our formulation has provably favorable global geometry for gradient methods. as soon as . where  is the depth of the network. Specifically. when suitable deterministic conditions on the generator and measurement matrix are met. we construct a descent direction for any point outside of a small neighborhood around the unique global minimizer and its negative multiple. and show that such conditions hold with high probability under Gaussian ensembles of multilayer fully-connected generator networks and measurement matrices. This formulation for structured phase retrieval thus has two advantages over sparsity based methods: 1) deep generative priors can more tightly represent natural signals and 2) information theoretically optimal …,True,P8NRbbYAAAAJ:mVmsd5A6BfQC,81,https://arxiv.org/abs/1807.04261,6936219906560546279,/scholar?cites=6936219906560546279,,,https://arxiv.org/pdf/1807.04261,0,0,0
1282588,An elementary proof of convex phase retrieval in the natural parameter space via the linear program phasemax,2016,Paul Hand and Vladislav Voroninski,,arXiv preprint arXiv:1611.03935,,,,The phase retrieval problem has garnered significant attention since the development of the PhaseLift algorithm. which is a convex program that operates in a lifted space of matrices. Because of the substantial computational cost due to lifting. many approaches to phase retrieval have been developed. including non-convex optimization algorithms which operate in the natural parameter space. such as Wirtinger Flow. Very recently. a convex formulation called PhaseMax has been discovered. and it has been proven to achieve phase retrieval via linear programming in the natural parameter space under optimal sample complexity. The current proofs of PhaseMax rely on statistical learning theory or geometric probability theory. Here. we present a short and elementary proof that PhaseMax exactly recovers real-valued vectors from random measurements under optimal sample complexity. Our proof only relies on standard probabilistic concentration and covering arguments. yielding a simpler and more direct proof than those that require statistical learning theory. geometric probability or the highly technical arguments for Wirtinger Flow-like approaches.,True,P8NRbbYAAAAJ:MXK_kJrjxJIC,54,https://arxiv.org/abs/1611.03935,12864139600374469126,/scholar?cites=12864139600374469126,,,https://arxiv.org/pdf/1611.03935,0,0,0
1282589,Deterministic Guarantees for Burer‐Monteiro Factorizations of Smooth Semidefinite Programs,2020,Nicolas Boumal and Vladislav Voroninski and Afonso S Bandeira,73,Communications on Pure and Applied Mathematics,3,581-608,,We consider semidefinite programs (SDPs) with equality constraints. The variable to be optimized is a positive semidefinite matrix X of size n. Following the Burer‐Monteiro approach. we optimize a factor Y of size n × p instead. such that X = YYT. This ensures positive semidefiniteness at no cost and can reduce the dimension of the problem if p is small. but results in a nonconvex optimization problem with a quadratic cost function and quadratic equality constraints in Y. In this paper. we show that if the set of constraints on Y regularly defines a smooth manifold. then. despite nonconvexity. first‐ and second‐order necessary optimality conditions are also sufficient. provided p is large enough. For smaller values of p. we show a similar result holds for almost all (linear) cost functions. Under those conditions. a global optimum Y maps to a global optimum X = YYT of the SDP. We deduce old and new consequences …,True,P8NRbbYAAAAJ:4DMP91E08xMC,50,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21830,14588149837149789103,/scholar?cites=14588149837149789103,,,https://arxiv.org/pdf/1804.02008,0,0,0
1282590,A strong restricted isometry property. with an application to phaseless compressed sensing,2016,Vladislav Voroninski and Zhiqiang Xu,40,Applied and computational harmonic analysis,2,386-395,Academic Press,The many variants of the restricted isometry property (RIP) have proven to be crucial theoretical tools in the fields of compressed sensing and matrix completion. The study of extending compressed sensing to accommodate phaseless measurements naturally motivates a strong notion of restricted isometry property (SRIP). which we develop in this paper. We show that if A∈ R m× n satisfies SRIP and phaseless measurements| A x 0|= b are observed about a k-sparse signal x 0∈ R n. then minimizing the ℓ 1 norm subject to| A x|= b recovers x 0 up to multiplication by a global sign. Moreover. we establish that the SRIP holds for the random Gaussian matrices typically used for standard compressed sensing. implying that phaseless compressed sensing is possible from O (k log⁡(e n/k)) measurements with these matrices via ℓ 1 minimization over| A x|= b. Our analysis also yields an erasure robust version of the Johnson …,True,P8NRbbYAAAAJ:UeHWp8X0CEIC,37,https://www.sciencedirect.com/science/article/pii/S1063520315000901,14628299048431630746,/scholar?cites=14628299048431630746,,,https://www.sciencedirect.com/science/article/pii/S1063520315000901,0,0,0
1282591,On large-batch training for deep learning: Generalization gap and sharp minima,2016,Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang,,arXiv preprint arXiv:1609.04836,,,,The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data. say - data points. is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model. as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions-and as is well known. sharp minima lead to poorer generalization. In contrast. small-batch methods consistently converge to flat minimizers. and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.,True,CJ-_cEEAAAAJ:qjMakFHDy7sC,1395,https://arxiv.org/abs/1609.04836,2526562489715623205,/scholar?cites=2526562489715623205,,,"https://arxiv.org/pdf/1609.04836.pdf,",0,0,0
1282592,Regularizing and optimizing LSTM language models,2017,Stephen Merity and Nitish Shirish Keskar and Richard Socher,,arXiv preprint arXiv:1708.02182,,,,Recurrent neural networks (RNNs). such as long short-term memory networks (LSTMs). serve as a fundamental building block for many sequence learning tasks. including machine translation. language modeling. and question answering. In this paper. we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization. Further. we introduce NT-ASGD. a variant of the averaged stochastic gradient method. wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Using these and other regularization strategies. we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model. we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2.,True,CJ-_cEEAAAAJ:Y0pCki6q_DkC,742,https://arxiv.org/abs/1708.02182,10613038919449342432,/scholar?cites=10613038919449342432,,,https://arxiv.org/pdf/1708.02182,0,0,0
1282593,The natural language decathlon: Multitask learning as question answering,2018,Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher,,arXiv preprint arXiv:1806.08730,,,,Deep learning has improved performance on many natural language processing (NLP) tasks individually. However. general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric. dataset. and task. We introduce the Natural Language Decathlon (decaNLP). a challenge that spans ten tasks: question answering. machine translation. summarization. natural language inference. sentiment analysis. semantic role labeling. zero-shot relation extraction. goal-oriented dialogue. semantic parsing. and commonsense pronoun resolution. We cast all tasks as question answering over a context. Furthermore. we present a new Multitask Question Answering Network (MQAN) jointly learns all tasks in decaNLP without any task-specific modules or parameters in the multitask setting. MQAN shows improvements in transfer learning for machine translation and named entity recognition. domain adaptation for sentiment analysis and natural language inference. and zero-shot capabilities for text classification. We demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and performance further improves with an anti-curriculum training strategy. Though designed for decaNLP. MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. We also release code for procuring and processing data. training and evaluating models. and reproducing all experiments for decaNLP.,True,CJ-_cEEAAAAJ:roLk4NBRz8UC,242,https://arxiv.org/abs/1806.08730,11150838077444944380,/scholar?cites=11150838077444944380,,,https://arxiv.org/pdf/1806.08730.pdf?source=post_page---------------------------,0,0,0
1282594,Improving generalization performance by switching from adam to sgd,2017,Nitish Shirish Keskar and Richard Socher,,arXiv preprint arXiv:1712.07628,,,,Despite superior training outcomes. adaptive optimization methods such as Adam. Adagrad or RMSprop have been found to generalize poorly compared to Stochastic gradient descent (SGD). These methods tend to perform well in the initial portion of training but are outperformed by SGD at later stages of training. We investigate a hybrid strategy that begins training with an adaptive method and switches to SGD when appropriate. Concretely. we propose SWATS. a simple strategy which switches from Adam to SGD when a triggering condition is satisfied. The condition we propose relates to the projection of Adam steps on the gradient subspace. By design. the monitoring process for this condition adds very little overhead and does not increase the number of hyperparameters in the optimizer. We report experiments on several standard benchmarks such as: ResNet. SENet. DenseNet and PyramidNet for the CIFAR-10 and CIFAR-100 data sets. ResNet on the tiny-ImageNet data set and language modeling with recurrent networks on the PTB and WT2 data sets. The results show that our strategy is capable of closing the generalization gap between SGD and Adam on a majority of the tasks.,True,CJ-_cEEAAAAJ:eQOLeE2rZwMC,235,https://arxiv.org/abs/1712.07628,7257539054768070066,/scholar?cites=7257539054768070066,,,https://arxiv.org/pdf/1712.07628,0,0,0
1282595,Ctrl: A conditional transformer language model for controllable generation,2019,Nitish Shirish Keskar and Bryan McCann and Lav R Varshney and Caiming Xiong and Richard Socher,,arXiv preprint arXiv:1909.05858,,,,Large-scale language models show promising text generation capabilities. but users cannot easily control particular aspects of the generated text. We release CTRL. a 1.63 billion-parameter conditional transformer language model. trained to condition on control codes that govern style. content. and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text. preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow CTRL to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized. pretrained versions of CTRL at this https URL.,True,CJ-_cEEAAAAJ:YOwf2qJgpHMC,219,https://arxiv.org/abs/1909.05858,5569573650994079534,/scholar?cites=5569573650994079534,,,https://arxiv.org/pdf/1909.05858.pdf?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8XhOQEHHbFcUlDSEzaxbFz6uez6M5L6sbf6r5JlGOr8YkFfKQAaMWutRg8Inn1pwKBeJzr3EYkQP0EQHG-A7_6y-t7fw,0,0,0
1282596,An analysis of neural language modeling at multiple scales,2018,Stephen Merity and Nitish Shirish Keskar and Richard Socher,,arXiv preprint arXiv:1803.08240,,,,Many of the leading approaches in language modeling introduce novel. complex and specialized architectures. We take existing state-of-the-art word level language models based on LSTMs and QRNNs and extend them to both larger vocabularies as well as character-level granularity. When properly tuned. LSTMs and QRNNs achieve state-of-the-art results on character-level (Penn Treebank. enwik8) and word-level (WikiText-103) datasets. respectively. Results are obtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single modern GPU.,True,CJ-_cEEAAAAJ:ufrVoPGSRksC,138,https://arxiv.org/abs/1803.08240,10951389027720687053,/scholar?cites=10951389027720687053,,,https://arxiv.org/pdf/1803.08240.pdf).,0,0,0
1282597,Neural text summarization: A critical evaluation,2019,Wojciech Kryściński and Nitish Shirish Keskar and Bryan McCann and Caiming Xiong and Richard Socher,,arXiv preprint arXiv:1908.08960,,,,Text summarization aims at compressing long documents into a shorter form that conveys the most important parts of the original document. Despite increased interest in the community and notable research effort. progress on benchmark datasets has stagnated. We critically evaluate key ingredients of the current research setup: datasets. evaluation metrics. and models. and highlight three primary shortcomings: 1) automatically collected datasets leave the task underconstrained and may contain noise detrimental to training and evaluation. 2) current evaluation protocol is weakly correlated with human judgment and does not account for important characteristics such as factual correctness. 3) models overfit to layout biases of current datasets and offer limited diversity in their outputs.,True,CJ-_cEEAAAAJ:Zph67rFs4hoC,79,https://arxiv.org/abs/1908.08960,2865083581262945588,/scholar?cites=2865083581262945588,,,https://arxiv.org/pdf/1908.08960,0,0,0
1282598,Weighted transformer network for machine translation,2017,Karim Ahmed and Nitish Shirish Keskar and Richard Socher,,arXiv preprint arXiv:1711.02132,,,,State-of-the-art results on neural machine translation often use attentional sequence-to-sequence models with some form of convolution or recursion. Vaswani et al.(2017) propose a new architecture that avoids recurrence and convolution completely. Instead. it uses only self-attention and feed-forward layers. While the proposed architecture achieves state-of-the-art results on several machine translation tasks. it requires a large number of parameters and training iterations to converge. We propose Weighted Transformer. a Transformer with modified attention layers. that not only outperforms the baseline network in BLEU score but also converges 15-40% faster. Specifically. we replace the multi-head attention by multiple self-attention branches that the model learns to combine during the training process. Our model improves the state-of-the-art performance by 0.5 BLEU points on the WMT 2014 English-to-German translation task and by 0.4 on the English-to-French translation task.,True,CJ-_cEEAAAAJ:YsMSGLbcyi4C,79,https://arxiv.org/abs/1711.02132,13807743807630368021,/scholar?cites=13807743807630368021,,,https://arxiv.org/pdf/1711.02132,0,0,0
1282599,A closer look at deep learning heuristics: Learning rate restarts. warmup and distillation,2018,Akhilesh Gotmare and Nitish Shirish Keskar and Caiming Xiong and Richard Socher,,arXiv preprint arXiv:1810.13243,,,,The convergence rate and final performance of common deep learning models have significantly benefited from heuristics such as learning rate schedules. knowledge distillation. skip connections. and normalization layers. In the absence of theoretical underpinnings. controlled experiments aimed at explaining these strategies can aid our understanding of deep learning landscapes and the training dynamics. Existing approaches for empirical analysis rely on tools of linear interpolation and visualizations with dimensionality reduction. each with their limitations. Instead. we revisit such analysis of heuristics through the lens of recently proposed methods for loss surface and representation analysis. viz.. mode connectivity and canonical correlation analysis (CCA). and hypothesize reasons for the success of the heuristics. In particular. we explore knowledge distillation and learning rate heuristics of (cosine) restarts and warmup using mode connectivity and CCA. Our empirical analysis suggests that:(a) the reasons often quoted for the success of cosine annealing are not evidenced in practice;(b) that the effect of learning rate warmup is to prevent the deeper layers from creating training instability; and (c) that the latent knowledge shared by the teacher is primarily disbursed to the deeper layers.,True,CJ-_cEEAAAAJ:UebtZRa9Y70C,61,https://arxiv.org/abs/1810.13243,8375178060138487801,/scholar?cites=8375178060138487801,,,https://arxiv.org/pdf/1810.13243,0,0,0
1282600,Balancing communication and computation in distributed optimization,2018,Albert S Berahas and Raghu Bollapragada and Nitish Shirish Keskar and Ermin Wei,64,IEEE Transactions on Automatic Control,8,3141-3155,IEEE,Methods for distributed optimization have received significant attention in recent years owing to their wide applicability in various domains including machine learning. robotics. and sensor networks. A distributed optimization method typically consists of two key components: communication and computation. More specifically. at every iteration (or every several iterations) of a distributed algorithm. each node in the network requires some form of information exchange with its neighboring nodes (communication) and the computation step related to a (sub)-gradient (computation). The standard way of judging an algorithm via only the number of iterations overlooks the complexity associated with each iteration. Moreover. various applications deploying distributed methods may prefer a different composition of communication and computation. Motivated by this discrepancy. in this paper. we propose an adaptive cost …,True,CJ-_cEEAAAAJ:W7OEmFMy1HYC,47,https://ieeexplore.ieee.org/abstract/document/8528465/,1955204046345656148,/scholar?cites=1955204046345656148,,,https://arxiv.org/pdf/1709.02999,0,0,0
1282601,Coarse-grain fine-grain coattention network for multi-evidence question answering,2019,Victor Zhong and Caiming Xiong and Nitish Shirish Keskar and Richard Socher,,arXiv preprint arXiv:1901.00603,,,,End-to-end neural models have made significant progress in question answering. however recent studies show that these models implicitly assume that the answer and evidence appear close together in a single document. In this work. we propose the Coarse-grain Fine-grain Coattention Network (CFC). a new question answering model that combines information from evidence across multiple documents. The CFC consists of a coarse-grain module that interprets documents with respect to the query then finds a relevant answer. and a fine-grain module which scores each candidate answer by comparing its occurrences across all of the documents with the query. We design these modules using hierarchies of coattention and self-attention. which learn to emphasize different parts of the input. On the Qangaroo WikiHop multi-evidence question answering task. the CFC obtains a new state-of-the-art result of 70.6% on the blind test set. outperforming the previous best by 3% accuracy despite not using pretrained contextual encoders.,True,CJ-_cEEAAAAJ:0EnyYjriUFMC,35,https://arxiv.org/abs/1901.00603,6052706847759570603,/scholar?cites=6052706847759570603,,,https://arxiv.org/pdf/1901.00603,0,0,0
1282602,Residual dense network for image super-resolution,2018,Yulun Zhang and Yapeng Tian and Yu Kong and Bineng Zhong and Yun Fu,,,,2472-2481,,In this paper. we propose dense feature fusion (DFF) for image super-resolution (SR). As the same content in different natural images often have various scales and angles of view. jointly leaning hierarchical features is essential for image SR. On the other hand. very deep convolutional neural network (CNN) has recently achieved great success for image SR and offered hierarchical features as well. However. most of deep CNN based SR models neglect to jointly make full use of the hierarchical features. In addition. dense connected layers would allow the network to be deeper. efficient to train. and more powerful. To embrace these observations. in our proposed DFF model. we fully exploit all the meaningful convolutional features in local and global manners. Specifically. we use dense connected convolutional layers to extract abundant local features. We use local feature fusion to adaptively learn more efficient features from preceding and current local features. After fully obtaining dense local features. we use global feature fusion to jointly and adaptively learn global hierarchical features in a holistic way. Extensive experiments on benchmark datasets show that our DFF achieves favorable performance against state-of-the-art methods quantitatively and visually.,True,ORmLjWoAAAAJ:eQOLeE2rZwMC,1183,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Residual_Dense_Network_CVPR_2018_paper.html,10362327168909609533,/scholar?cites=10362327168909609533,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Residual_Dense_Network_CVPR_2018_paper.pdf,0,0,0
1282603,Image super-resolution using very deep residual channel attention networks,2018,Yulun Zhang and Kunpeng Li and Kai Li and Lichen Wang and Bineng Zhong and Yun Fu,,,,286-301,,Convolutional neural network (CNN) depth is of crucial importance for image super-resolution (SR). However. we observe that deeper networks for image SR are more difficult to train. The low-resolution (LR) inputs and features contain abundant low-frequency information. which is treated equally across channels. hence hindering the representational ability of CNNs. To solve these problems. we propose the very deep residual channel attention networks (RCAN). Specifically. we propose residual in residual (RIR) structure to form very deep network. which consists of several residual groups with long skip connections. Each residual group contains some residual blocks with short skip connections. Meanwhile. RIR allows abundant low-frequency information to be bypassed through multiple skip connections. making the main network focus on learning high-frequency information. Furthermore. we propose channel attention mechanism to adaptively rescale channel-wise features by considering interdependencies among channels. Extensive experiments show that our RCAN achieves better accuracy and visual improvements against state-of-the-art methods.,True,ORmLjWoAAAAJ:8k81kl-MbHgC,1068,http://openaccess.thecvf.com/content_ECCV_2018/html/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.html,3748973811121591896,/scholar?cites=3748973811121591896,,,https://openaccess.thecvf.com/content_ECCV_2018/papers/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.pdf,0,0,0
1282604,Ntire 2017 challenge on single image super-resolution: Methods and results,2017,Radu Timofte and Eirikur Agustsson and Luc Van Gool and Ming-Hsuan Yang and Lei Zhang,,,,114-125,,This paper reviews the first challenge on single image super-resolution (restoration of rich details in an low resolution image) with focus on proposed solutions and results. A new DIVerse 2K resolution image dataset (DIV2K) was employed. The challenge had 6 competitions divided into 2 tracks with 3 magnification factors each. Track 1 employed the standard bicubic downscaling setup. while Track 2 had unknown downscaling operators (blur kernel and decimation) but learnable through low and high res train images. Each competition had 100 registered participants and 20 teams competed in the final testing phase. They gauge the state-of-the-art in single image super-resolution.,True,ORmLjWoAAAAJ:Y0pCki6q_DkC,660,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/html/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.html,7685867950273076567,/scholar?cites=7685867950273076567,,,http://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Timofte_NTIRE_2017_Challenge_CVPR_2017_paper.pdf,0,0,0
1282605,Residual Non-local Attention Networks for Image Restoration,2019,Yulun Zhang and Kunpeng Li and Kai Li and Bineng Zhong and Yun Fu,,,,,,In this paper. we propose a residual non-local attention network for high-quality image restoration. Without considering the uneven distribution of information in the corrupted images. previous methods are restricted by local convolutional operation and equal treatment of spatial-and channel-wise features. To address this issue. we design local and non-local attention blocks to extract features that capture the long-range dependencies between pixels and pay more attention to the challenging parts. Specifically. we design trunk branch and (non-) local mask branch in each (non-) local attention block. The trunk branch is used to extract hierarchical features. Local and non-local mask branches aim to adaptively rescale these hierarchical features with mixed attentions. The local mask branch concentrates on more local structures with convolutional operations. while non-local attention considers more about long-range dependencies in the whole feature map. Furthermore. we propose residual local and non-local attention learning to train the very deep network. which further enhance the representation ability of the network. Our proposed method can be generalized for various image restoration applications. such as image denoising. demosaicing. compression artifacts reduction. and super-resolution. Experiments demonstrate that our method obtains comparable or better results compared with recently leading methods quantitatively and visually.,True,ORmLjWoAAAAJ:YOwf2qJgpHMC,154,https://arxiv.org/abs/1903.10082,5425381515618577679,/scholar?cites=5425381515618577679,,,https://arxiv.org/pdf/1903.10082,0,0,0
1282606,Residual dense network for image restoration,2020,Yulun Zhang and Yapeng Tian and Yu Kong and Bineng Zhong and Yun Fu,,IEEE Transactions on Pattern Analysis and Machine Intelligence,,,IEEE,Recently. deep convolutional neural network (CNN) has achieved great success for image restoration (IR) and provided hierarchical features at the same time. However. most deep CNN based IR models do not make full use of the hierarchical features from the original low-quality images. thereby resulting in relatively-low performance. In this work. we propose a novel and efficient residual dense network (RDN) to address this problem in IR. by making a better tradeoff between efficiency and effectiveness in exploiting the hierarchical features from all the convolutional layers. Specifically. we propose residual dense block (RDB) to extract abundant local features via densely connected convolutional layers. RDB further allows direct connections from the state of preceding RDB to all the layers of current RDB. leading to a contiguous memory mechanism. To adaptively learn more effective features from preceding and …,True,ORmLjWoAAAAJ:ULOm3_A8WrAC,132,https://ieeexplore.ieee.org/abstract/document/8964437/,1661094772141262709,/scholar?cites=1661094772141262709,,,https://arxiv.org/pdf/1812.10477,0,0,0
1282607,Tdan: Temporally-deformable alignment network for video super-resolution,2020,Yapeng Tian and Yulun Zhang and Yun Fu and Chenliang Xu,,,,3360-3369,,Video super-resolution (VSR) aims to restore a photo-realistic high-resolution (HR) video frame from both its corresponding low-resolution (LR) frame (reference frame) and multiple neighboring frames (supporting frames). Due to varying motion of cameras or objects. the reference frame and each support frame are not aligned. Therefore. temporal alignment is a challenging yet important problem for VSR. Previous VSR methods usually utilize optical flow between the reference frame and each supporting frame to warp the supporting frame for temporal alignment. However. both inaccurate flow and the image-level warping strategy will lead to artifacts in the warped supporting frames. To overcome the limitation. we propose a temporally-deformable alignment network (TDAN) to adaptively align the reference frame and each supporting frame at the feature level without computing optical flow. The TDAN uses features from both the reference frame and each supporting frame to dynamically predict offsets of sampling convolution kernels. By using the corresponding kernels. TDAN transforms supporting frames to align with the reference frame. To predict the HR video frame. a reconstruction network taking aligned frames and the reference frame is utilized. Experimental results demonstrate that the TDAN is capable of alleviating occlusions and artifacts for temporal alignment and the TDAN-based VSR model outperforms several recent state-of-the-art VSR networks with a comparable or even much smaller model size. The source code and pre-trained models are released in https://github. com/YapengTian/TDAN-VSR.,True,ORmLjWoAAAAJ:5nxA0vEk-isC,83,http://openaccess.thecvf.com/content_CVPR_2020/html/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.html,9134144164731399402,/scholar?cites=9134144164731399402,,,http://openaccess.thecvf.com/content_CVPR_2020/papers/Tian_TDAN_Temporally-Deformable_Alignment_Network_for_Video_Super-Resolution_CVPR_2020_paper.pdf,0,0,0
1282608,Visual semantic reasoning for image-text matching,2019,Kunpeng Li and Yulun Zhang and Kai Li and Yuanyuan Li and Yun Fu,,,,4654-4662,,Image-text matching has been a hot research topic bridging the vision and language areas. It remains challenging because the current representation of image usually lacks global semantic concepts as in its corresponding text caption. To address this issue. we propose a simple and interpretable reasoning model to generate visual representation that captures key objects and semantic concepts of a scene. Specifically. we first build up connections between image regions and perform reasoning with Graph Convolutional Networks to generate features with semantic relationships. Then. we propose to use the gate and memory mechanism to perform global semantic reasoning on these relationship-enhanced features. select the discriminative information and gradually generate the representation for the whole scene. Experiments validate that our method achieves a new state-of-the-art for the image-text matching on MS-COCO and Flickr30K datasets. It outperforms the current best method by 6.8% relatively for image retrieval and 4.8% relatively for caption retrieval on MS-COCO (Recall@ 1 using 1K test set). On Flickr30K. our model improves image retrieval by 12.6% relatively and caption retrieval by 5.8% relatively (Recall@ 1).,True,ORmLjWoAAAAJ:M3ejUd6NZC8C,69,http://openaccess.thecvf.com/content_ICCV_2019/html/Li_Visual_Semantic_Reasoning_for_Image-Text_Matching_ICCV_2019_paper.html,12074804324429937170,/scholar?cites=12074804324429937170,,,https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Visual_Semantic_Reasoning_for_Image-Text_Matching_ICCV_2019_paper.pdf,0,0,0
1282609,CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution,2016,Yongbing Zhang and Yulun Zhang and Jian Zhang and Qionghai Dai,18,IEEE Transactions on Multimedia,3,405-417,IEEE,Clustering and collaborative representation (CCR) have recently been used in fast single image super-resolution (SR). In this paper. we propose an effective and fast single image super-resolution (SR) algorithm by combining clustering and collaborative representation. In particular. we first cluster the feature space of low-resolution (LR) images into multiple LR feature subspaces and group the corresponding high-resolution (HR) feature subspaces. The local geometry property learned from the clustering process is used to collect numerous neighbor LR and HR feature subsets from the whole feature spaces for each cluster center. Multiple projection matrices are then computed via collaborative representation to map LR feature subspaces to HR subspaces. For an arbitrary input LR feature. the desired HR output can be estimated according to the projection matrix. whose corresponding LR cluster center is nearest …,True,ORmLjWoAAAAJ:2osOgNQ5qMEC,56,https://ieeexplore.ieee.org/abstract/document/7364261/,16913593086537153873,/scholar?cites=16913593086537153873,,,,0,0,0
1282610,Hierarchical Tracking by Reinforcement Learning based Searching and Coarse-to-fine Verifying,2019,Bineng Zhong and Bing Bai and Jun Li and Yulun Zhang and Yun Fu,,IEEE Transactions on Image Processing,,,,A class-agnostic tracker typically consists of three key components. i.e.. its motion model. its target appearance model. and its updating strategy. However. most recent top-performing trackers mainly focus on constructing complicated appearance models and updating strategies. while using comparatively simple and heuristic motion models that may result in an inefficient search and degrade the tracking performance. To address this issue. we propose a hierarchical tracker that learns to move and track based on the combination of data-driven search at the coarse level and coarse-to-fine verification at the fine level. At the coarse level. a data-driven motion model learned from deep recurrent reinforcement learning provides our tracker with coarse localization of an object. By formulating motion search as an action-decision problem in reinforcement learning. our tracker utilizes a recurrent convolutional neural network …,True,ORmLjWoAAAAJ:0EnyYjriUFMC,47,https://ieeexplore.ieee.org/abstract/document/8561254/,17918721806370051010,/scholar?cites=17918721806370051010,,,https://par.nsf.gov/servlets/purl/10113622,0,0,0
1282611,Deep Alignment Network Based Multi-person Tracking with Occlusion and Motion Reasoning,2019,Qinqin Zhou and Bineng Zhong and Yulun Zhang and Jun Li and Yun Fu,,IEEE Transactions on Multimedia,,,,Tracking-by-detection is one of the typical paradigms for multi-person tracking. due to the availability of automatic pedestrian detectors. However. existing multi-person trackers are greatly challenged by misalignment in the pedestrian detectors (i.e.. excessive background and part missing) and occlusion. To effectively handle these problems. we propose a deep alignment network-based multi-person tracking method with occlusion and motion reasoning. Specifically. the inaccurate detections are first corrected via a deep alignment network. in which an alignment estimation module is used to automatically learn the spatial transformation of these detections. As a result. the deep features from our alignment network will have better representation power and. thus. lead to more consistent tracks. Then. a coarse-to-fine schema is designed for construing a discriminative association cost matrix with spatial. motion. and …,True,ORmLjWoAAAAJ:hqOjcs7Dif8C,42,https://ieeexplore.ieee.org/abstract/document/8488599/,4958201595264434987,/scholar?cites=4958201595264434987,,,,0,0,0
1282612,Channel splitting network for single MR image super-resolution,2019,Xiaole Zhao and Yulun Zhang and Tao Zhang and Xueming Zou,28,IEEE Transactions on Image Processing,11,5649-5662,IEEE,High resolution magnetic resonance (MR) imaging is desirable in many clinical applications due to its contribution to more accurate subsequent analyses and early clinical diagnoses. Single image super-resolution (SISR) is an effective and cost efficient alternative technique to improve the spatial resolution of MR images. In the past few years. SISR methods based on deep learning techniques. especially convolutional neural networks (CNNs). have achieved the state-of-the-art performance on natural images. However. the information is gradually weakened and training becomes increasingly difficult as the network deepens. The problem is more serious for medical images because lacking high quality and effective training samples makes deep models prone to underfitting or overfitting. Nevertheless. many current models treat the hierarchical features on different channels equivalently. which is not helpful for the …,True,ORmLjWoAAAAJ:LkGwnXOMwfcC,34,https://ieeexplore.ieee.org/abstract/document/8736987/,4006112297509588515,/scholar?cites=4006112297509588515,,,https://arxiv.org/pdf/1810.06453,0,0,0
1282613,Quantitative optical coherence tomography angiography of vascular abnormalities in the living human eye,2015,Yali Jia and Steven T Bailey and Thomas S Hwang and Scott M McClintic and Simon S Gao and Mark E Pennesi and Christina J Flaxel and Andreas K Lauer and David J Wilson and Joachim Hornegger and James G Fujimoto and David Huang,112,Proceedings of the National Academy of Sciences,18,E2395-E2402,National Acad Sciences,Retinal vascular diseases are important causes of vision loss. A detailed evaluation of the vascular abnormalities facilitates diagnosis and treatment in these diseases. Optical coherence tomography (OCT) angiography using the highly efficient split-spectrum amplitude decorrelation angiography algorithm offers an alternative to conventional dye-based retinal angiography. OCT angiography has several advantages. including 3D visualization of retinal and choroidal circulations (including the choriocapillaris) and avoidance of dye injection-related complications. Results from six illustrative cases are reported. In diabetic retinopathy. OCT angiography can detect neovascularization and quantify ischemia. In age-related macular degeneration. choroidal neovascularization can be observed without the obscuration of details caused by dye leakage in conventional angiography. Choriocapillaris dysfunction can be …,True,AUmSiGsAAAAJ:tkaPQYYpVKoC,531,https://www.pnas.org/content/112/18/E2395.short,7202570659185343782,/scholar?cites=7202570659185343782,,,https://www.pnas.org/content/pnas/112/18/E2395.full.pdf,0,0,0
1282614,Automated quantification of capillary nonperfusion using optical coherence tomography angiography in diabetic retinopathy,2016,Thomas S Hwang and Simon S Gao and Liang Liu and Andreas K Lauer and Steven T Bailey and Christina J Flaxel and David J Wilson and David Huang and Yali Jia,134,JAMA ophthalmology,4,367-373,American Medical Association,Macular ischemia is a key feature of diabetic retinopathy (DR). Quantification of macular ischemia has potential as a biomarker for DR.To assess the feasibility of automated quantification of capillary nonperfusion as a potential sign of macular ischemia using optical coherence tomography (OCT) angiography.An observational study conducted in a tertiary. subspecialty. academic practice evaluated macular nonperfusion with 6 × 6-mm OCT angiography obtained with commercially available 70-kHz OCT and fluorescein angiography (FA). The study was conducted from January 22 to September 18. 2014. Data analysis was performed from October 1. 2014. to April 7. 2015. Participants included 12 individuals with normal vision serving as controls and 12 patients with various levels of DR.Preplanned primary measures were …,True,AUmSiGsAAAAJ:SdhP9T11ey4C,288,https://jamanetwork.com/journals/jamaophthalmology/article-abstract/2481141,13589958901562754614,/scholar?cites=13589958901562754614,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4978127/,0,0,0
1282615,Optical coherence tomography angiography features of diabetic retinopathy,2015,Thomas S Hwang and Yali Jia and Simon S Gao and Steven T Bailey and Andreas K Lauer and Christina J Flaxel and David J Wilson and David Huang,35,"Retina (Philadelphia, Pa.)",11,2371,NIH Public Access,MethodsUsing a 70kHz OCT and the split-spectrum amplitude decorrelation angiography (SSADA) algorithm. 6× 6 mm 3-dimensional angiograms of the macula of 4 patients with diabetic retinopathy were obtained and compared with fluorescein angiography (FA) for features catalogued by the Early Treatment of Diabetic Retinopathy Study.ResultsOCT angiography detected enlargement and distortion of the foveal avascular zone. retinal capillary dropout. and pruning of arteriolar branches. Areas of capillary loss obscured by fluorescein leakage on FA were more clearly defined on OCT angiography. Some areas of focal leakage on FA that were thought to be microaneurysms were found to be small tufts of neovascularization that extended above the inner limiting membrane.ConclusionOCT angiography does not show leakage. but can better delineate areas of capillary dropout and detect early retinal …,True,AUmSiGsAAAAJ:JoZmwDi-zQgC,284,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4623938/,14005216342849618558,/scholar?cites=14005216342849618558,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4623938/,0,0,0
1282616,Optical Coherence Tomography Angiography,2016,Simon S Gao and Yali Jia and Miao Zhang and Johnny P Su and Gangjun Liu and Thomas S Hwang and Steven T Bailey and David Huang,57,Investigative Ophthalmology & Visual Science,9,OCT27-OCT36,The Association for Research in Vision and Ophthalmology,Optical coherence tomography angiography (OCTA) is a noninvasive approach that can visualize blood vessels down to the capillary level. With the advent of high-speed OCT and efficient algorithms. practical OCTA of ocular circulation is now available to ophthalmologists. Clinical investigations that used OCTA have increased exponentially in the past few years. This review will cover the history of OCTA and survey its most important clinical applications. The salient problems in the interpretation and analysis of OCTA are described. and recent advances are highlighted.,True,AUmSiGsAAAAJ:ye4kPcJQO24C,251,https://iovs.arvojournals.org/article.aspx?articleid=2535944,3448468746564451934,/scholar?cites=3448468746564451934,,,https://iovs.arvojournals.org/article.aspx?articleid=2535944,0,0,0
1282617,Projection-resolved optical coherence tomography angiography of macular retinal circulation in glaucoma,2017,Hana L Takusagawa and Liang Liu and Kelly N Ma and Yali Jia and Simon S Gao and Miao Zhang and Beth Edmunds and Mansi Parikh and Shandiz Tehrani and John C Morrison and David Huang,124,Ophthalmology,11,1589-1599,Elsevier,To detect macular perfusion defects in glaucoma using projection-resolved optical coherence tomography (OCT) angiography.Prospective observation study.A total of 30 perimetric glaucoma and 30 age-matched normal participants were included.One eye of each participant was imaged using 6×6–mm macular OCT angiography (OCTA) scan pattern by 70-kHz 840-nm spectral-domain OCT. Flow signal was calculated by the split-spectrum amplitude-decorrelation angiography algorithm. A projection-resolved OCTA (PR-OCTA) algorithm was used to remove flow projection artifacts. Four en face OCTA slabs were analyzed: the superficial vascular complex (SVC). intermediate capillary plexus (ICP). deep capillary plexus (DCP). and all-plexus retina (SVC + ICP + DCP). The vessel density (VD). defined as the percentage area occupied by flow pixels. was calculated from en face …,True,AUmSiGsAAAAJ:kzcrU_BdoSEC,148,https://www.sciencedirect.com/science/article/pii/S0161642016323855,319006285579092730,/scholar?cites=319006285579092730,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc5651191/,0,0,0
1282618,Detection of non-exudative choroidal neovascularization in age-related macular degeneration with optical coherence tomography angiography,2015,Neal V Palejwala and Yali Jia and Simon S Gao and Liang Liu and Christina J Flaxel and Thomas S Hwang and Andreas K Lauer and David J Wilson and David Huang and Steven T Bailey,35,"Retina (Philadelphia, Pa.)",11,2204,NIH Public Access,Age-related macular degeneration (AMD) is the leading cause of irreversible vision loss in the United States in the 65 and older age group. Neovascular AMD accounts for approximately 15% of AMD cases and makes up the majority of cases with vision loss. 1 Choroidal neovascularization (CNV) in the fellow eye is an established risk factor for the development of neovascularization with an annual incidence ranging between 4–19%. 2–4 With advancements in diagnostic imaging. screening this population for early detection of CNV is becoming increasingly important as it may have both therapeutic and prognostic implications.Structural optical coherence tomography (OCT) is used routinely to detect and monitor exudative changes in neovascular AMD. 5 En face spectral-domain (SD) OCT has demonstrated vascular structure within pigment epithelial detachment (PED). 6 However. the ability to discriminate …,True,AUmSiGsAAAAJ:9vf0nzSNQJEC,143,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4623999/,14476947849871798974,/scholar?cites=14476947849871798974,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4623999/,0,0,0
1282619,Optical Coherence Tomography Angiography ofPeripapillary Retinal Blood Flow Response to Hyperoxia,2015,Alex D Pechauer and Yali Jia and Liang Liu and Simon S Gao and Chunhui Jiang and David Huang,56,Investigative ophthalmology & visual science,5,3287-3291,The Association for Research in Vision and Ophthalmology,Purpose.: To measure the change in peripapillary retinal blood flow in response to hyperoxia by using optical coherence tomography (OCT) angiography.Methods.: One eye of each healthy human participants (six) was scanned with a commercial high-speed (70 kHz) spectral OCT. Scans were captured twice after 10-minute exposures to normal breathing (baseline) and hyperoxia. Blood flow was detected by the split-spectrum amplitude-decorrelation angiography (SSADA) algorithm. Peripapillary retinal blood flow index and vessel density were calculated from en face maximum projections of the retinal layers. The experiment was performed on 2 separate days for each participant. Coefficient of variation (CV) was used to measure within-day repeatability and between-day reproducibility. Paired t-tests were used to compare means of baseline and hyperoxic peripapillary retinal blood flow.Results.: A decrease of 8.87%±3.09%(mean±standard deviation) in flow index and 2.61%±1.50% in vessel density was observed under hyperoxia. The within-day repeatability CV of baseline measurements was 5.75% for flow index and 1.67% for vessel density. The between-day reproducibility CV for baseline flow index and vessel density was 11.1% and 1.14%. respectively. The between-day reproducibility of the hyperoxic response was 3.71% and 1.67% for flow index and vessel density. respectively.Conclusions.: Optical coherence tomography angiography with SSADA was able to detect a decrease in peripapillary retinal blood flow in response to hyperoxia. The response was larger than the variability of baseline measurements. The magnitude of an …,True,AUmSiGsAAAAJ:PELIpwtuRlgC,126,https://iovs.arvojournals.org/article.aspx?articleid=2299614,17423726295333874898,/scholar?cites=17423726295333874898,,,https://iovs.arvojournals.org/article.aspx?articleid=2299614,0,0,0
1282620,Advanced image processing for optical coherence tomographic angiography of macular diseases,2015,Miao Zhang and Jie Wang and Alex D Pechauer and Thomas S Hwang and Simon S Gao and Liang Liu and Li Liu and Steven T Bailey and David J Wilson and David Huang and Yali Jia,6,Biomedical optics express,12,4661-4675,Optical Society of America,This article provides an overview of advanced image processing for three dimensional (3D) optical coherence tomographic (OCT) angiography of macular diseases. including age-related macular degeneration (AMD) and diabetic retinopathy (DR). A fast automated retinal layers segmentation algorithm using directional graph search was introduced to separates 3D flow data into different layers in the presence of pathologies. Intelligent manual correction methods are also systematically addressed which can be done rapidly on a single frame and then automatically propagated to full 3D volume with accuracy better than 1 pixel. Methods to visualize and analyze the abnormalities including retinal and choroidal neovascularization. retinal ischemia. and macular edema were presented to facilitate the clinical use of OCT angiography.,True,AUmSiGsAAAAJ:5awf1xo2G04C,114,https://www.osapublishing.org/viewmedia.cfm?uri=boe-6-12-4661&html=true,1274778311669850227,/scholar?cites=1274778311669850227,,,https://www.osapublishing.org/viewmedia.cfm?uri=boe-6-12-4661&html=true,0,0,0
1282621,Optimization of the split-spectrum amplitude-decorrelation angiography algorithm on a spectral optical coherence tomography system,2015,Simon S Gao and Gangjun Liu and David Huang and Yali Jia,40,Optics letters,10,2305-2308,Optical Society of America,The split-spectrum amplitude-decorrelation angiography algorithm was optimized on a spectral optical coherence tomography system using a flow phantom. The number of times the spectrum was split and the bandwidth of each split were adjusted to maximize the flow phantom decorrelation signal-to-noise ratio. The improvement in flow detection was then demonstrated with en face retinal angiograms. The optimized algorithm increased the detectable retinal microvascular flow and decreased the variability of the quantified vessel density in OCT retinal angiograms of healthy human subjects.,True,AUmSiGsAAAAJ:_B80troHkn4C,108,https://www.osapublishing.org/abstract.cfm?uri=ol-40-10-2305,1081484984001678620,/scholar?cites=1081484984001678620,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4581446/,0,0,0
1282622,Mechanisms of hearing loss after blast injury to the ear,2013,Sung-Il Cho and Simon S Gao and Anping Xia and Rosalie Wang and Felipe T Salles and Patrick D Raphael and Homer Abaya and Jacqueline Wachtel and Jongmin Baek and David Jacobs and Matthew N Rasband and John S Oghalai,8,PloS one,7,e67618,Public Library of Science,Given the frequent use of improvised explosive devices (IEDs) around the world. the study of traumatic blast injuries is of increasing interest. The ear is the most common organ affected by blast injury because it is the body’s most sensitive pressure transducer. We fabricated a blast chamber to re-create blast profiles similar to that of IEDs and used it to develop a reproducible mouse model to study blast-induced hearing loss. The tympanic membrane was perforated in all mice after blast exposure and found to heal spontaneously. Micro-computed tomography demonstrated no evidence for middle ear or otic capsule injuries; however. the healed tympanic membrane was thickened. Auditory brainstem response and distortion product otoacoustic emission threshold shifts were found to be correlated with blast intensity. As well. these threshold shifts were larger than those found in control mice that underwent surgical perforation of their tympanic membranes. indicating cochlear trauma. Histological studies one week and three months after the blast demonstrated no disruption or damage to the intra-cochlear membranes. However. there was loss of outer hair cells (OHCs) within the basal turn of the cochlea and decreased spiral ganglion neurons (SGNs) and afferent nerve synapses. Using our mouse model that recapitulates human IED exposure. our results identify that the mechanisms underlying blast-induced hearing loss does not include gross membranous rupture as is commonly believed. Instead. there is both OHC and SGN loss that produce auditory dysfunction.,True,AUmSiGsAAAAJ:VOx2b1Wkg3QC,106,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0067618,13256819796249770878,/scholar?cites=13256819796249770878,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0067618,0,0,0
1282623,Optical coherence tomography angiography using the optovue device,2016,David Huang and Yali Jia and Simon S Gao and Bruno Lumbroso and Marco Rispoli,56,,,6-12,Karger Publishers,Optovue AngioVue system technology for optical coherence tomography (OCT) angiography is based on the AngioVue Imaging System (Optovue. Inc.. Freemont. CA). using split-spectrum amplitude-decorrelation angiography (SSADA) algorithm. This algorithm was developed to minimize scanning time. It detects motion in blood vessel lumen by measuring the variation in reflected OCT signal amplitude between consecutive cross-sectional scans. The novelty of SSADA lies in how the OCT signal is processed to enhance flow detection and reject axial bulk motion noise. Specifically. the algorithm splits the OCT image into different spectral bands. thus increasing the number of usable image frames. Each new frame has a lower axial resolution that is less susceptible to axial eye motion caused by blood pulsation. Optovue AngioVue system technology allows quantitative analysis. It provides numerical data about flow …,True,AUmSiGsAAAAJ:2KloaMYe4IUC,100,https://www.karger.com/Article/Abstract/442770,10856502111687180509,/scholar?cites=10856502111687180509,,,,0,0,0
1282624,Flownet 2.0: Evolution of optical flow estimation with deep networks,2017,Eddy Ilg and Nikolaus Mayer and Tonmoy Saikia and Margret Keuper and Alexey Dosovitskiy and Thomas Brox,,,,2462-2470,,The FlowNet demonstrated that optical flow estimation can be cast as a learning problem. However. the state of the art with regard to the quality of the flow has still been defined by traditional methods. Particularly on small displacements and real-world data. FlowNet cannot compete with variational methods. In this paper. we advance the concept of end-to-end learning of optical flow and make it work really well. The large improvements in quality and speed are caused by three major contributions: first. we focus on the training data and show that the schedule of presenting data during training is very important. Second. we develop a stacked architecture that includes warping of the second image with intermediate optical flow. Third. we elaborate on small displacements by introducing a subnetwork specializing on small motions. FlowNet 2.0 is only marginally slower than the original FlowNet but decreases the estimation error by more than 50%. It performs on par with state-of-the-art methods. while running at interactive frame rates. Moreover. we present faster variants that allow optical flow computation at up to 140fps with accuracy matching the original FlowNet.,True,Is8Zxz8AAAAJ:2osOgNQ5qMEC,1693,http://openaccess.thecvf.com/content_cvpr_2017/html/Ilg_FlowNet_2.0_Evolution_CVPR_2017_paper.html,10327949235117821487,/scholar?cites=10327949235117821487,,,https://openaccess.thecvf.com/content_cvpr_2017/papers/Ilg_FlowNet_2.0_Evolution_CVPR_2017_paper.pdf,0,0,0
1282625,A large dataset to train convolutional networks for disparity. optical flow. and scene flow estimation,2016,Nikolaus Mayer and Eddy Ilg and Philip Hausser and Philipp Fischer and Daniel Cremers and Alexey Dosovitskiy and Thomas Brox,,,,4040-4048,,Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation. To this end. we propose three synthetic stereo video datasets with sufficient realism. variation. and size to successfully train large networks. Our datasets are the first large-scale datasets to enable training and evaluation of scene flow methods. Besides the datasets. we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a flow and disparity estimation network and training it jointly. we demonstrate the first scene flow estimation with a convolutional network.,True,Is8Zxz8AAAAJ:d1gkVwhDpl0C,1243,http://openaccess.thecvf.com/content_cvpr_2016/html/Mayer_A_Large_Dataset_CVPR_2016_paper.html,5567272789746439114,/scholar?cites=5567272789746439114,,,https://openaccess.thecvf.com/content_cvpr_2016/papers/Mayer_A_Large_Dataset_CVPR_2016_paper.pdf,0,0,0
1282626,Demon: Depth and motion network for learning monocular stereo,2017,Benjamin Ummenhofer and Huizhong Zhou and Jonas Uhrig and Nikolaus Mayer and Eddy Ilg and Alexey Dosovitskiy and Thomas Brox,,,,5038-5047,,In this paper we formulate structure from motion as a learning problem. We train a convolutional network end-to-end to compute depth and camera motion from successive. unconstrained image pairs. The architecture is composed of multiple stacked encoder-decoder networks. the core part being an iterative network that is able to improve its own predictions. The network estimates not only depth and motion. but additionally surface normals. optical flow between the images and confidence of the matching. A crucial component of the approach is a training loss based on spatial relative differences. Compared to traditional two-frame structure from motion methods. results are more accurate and more robust. In contrast to the popular depth-from-single-image networks. DeMoN learns the concept of matching and. thus. better generalizes to structures not seen during training.,True,Is8Zxz8AAAAJ:UeHWp8X0CEIC,442,http://openaccess.thecvf.com/content_cvpr_2017/html/Ummenhofer_DeMoN_Depth_and_CVPR_2017_paper.html,17697059828222209959,/scholar?cites=17697059828222209959,,,https://openaccess.thecvf.com/content_cvpr_2017/papers/Ummenhofer_DeMoN_Depth_and_CVPR_2017_paper.pdf,0,0,0
1282627,What makes good synthetic training data for learning disparity and optical flow estimation?,2018,Nikolaus Mayer and Eddy Ilg and Philipp Fischer and Caner Hazirbas and Daniel Cremers and Alexey Dosovitskiy and Thomas Brox,126,International Journal of Computer Vision,9,942-960,Springer US,The finding that very large networks can be trained efficiently and reliably has led to a paradigm shift in computer vision from engineered solutions to learning formulations. As a result. the research challenge shifts from devising algorithms to creating suitable and abundant training data for supervised learning. How to efficiently create such training data? The dominant data acquisition method in visual recognition is based on web data and manual annotation. Yet. for many computer vision problems. such as stereo or optical flow estimation. this approach is not feasible because humans cannot manually enter a pixel-accurate flow field. In this paper. we promote the use of synthetically generated data for the purpose of training deep networks on such tasks. We suggest multiple ways to generate such data and evaluate the influence of dataset properties on the performance and generalization properties of the …,True,Is8Zxz8AAAAJ:9yKSN-GCB0IC,112,https://link.springer.com/article/10.1007/s11263-018-1082-6,7751152421004443982,/scholar?cites=7751152421004443982,,,https://arxiv.org/pdf/1801.06397,0,0,0
1282628,Diskmask: Focusing Object Features for Accurate Instance Segmentation of Elongated or Overlapping Objects,2020,Anton Böhm and Nikolaus Mayer and Thomas Brox,,,,230-234,IEEE,Deep learning has enabled automated segmentation in a large variety of cases. Instance segmentation of touching and overlapping objects remains an open challenge. We present an end-to-end approach that focuses object detections and features to local regions in an encoder stage and derives accurate instance masks in a decoder. We avoid heavy pre- or postprocessing. such as lifting or non-maximum suppression. The approach compares favorably to the current state-of-the-art on three challenging biological datasets.,True,Is8Zxz8AAAAJ:u5HHmVD_uO8C,2,https://ieeexplore.ieee.org/abstract/document/9098435/,3384361180032834213,/scholar?cites=3384361180032834213,,,https://lmb.informatik.uni-freiburg.de/Publications/2020/BMB20/paper-ISBI20_DiskMask_finalSubmission_IEEE_CR.pdf,0,0,0
1282629,Automated Boxwood Topiary Trimming with a Robotic Arm and Integrated Stereo Vision*.,2019,Dejan Kaljaca and Nikolaus Mayer and Bastiaan A Vroegindeweij and Angelo Mencarelli and Eldert J van Henten and Thomas Brox,,,,5542-5549,,This paper presents an integrated hardwaresoftware solution to perform fully automated robotic bush trimming to user-specified shapes. In contrast to specialized solutions that can trim only bushes of a certain shape. the approach ensures flexibility via a vision-based shape fitting module that allows fitting an arbitrary mesh into a bush at hand. A trimming planning method considers the available degrees of freedom of the robot arm to achieve effective cutting motions. The performance of the mesh fitting module is assessed in multiple experiments involving both artificial and real plants with a variety of shapes. The trimming accuracy of the overall approach is quantitatively evaluated by inspecting the bush pointcloud before and after robotic trimming. and measuring the change in the deviation from the originally computed target mesh.,True,Is8Zxz8AAAAJ:IjCSPb-OGe4C,2,https://lmb.informatik.uni-freiburg.de/Publications/2019/MB19/paper-MB19.pdf,18333090700541312243,/scholar?cites=18333090700541312243,,,https://lmb.informatik.uni-freiburg.de/Publications/2019/MB19/paper-MB19.pdf,0,0,0
1282630,Coupling ICP and Whole Image Alignment for Real-time Camera Tracking,2014,Nikolaus Mayer,,,,,,Tracking a camera’s movement through space while compiling a map of the observed environment. commonly called Simultaneous Localization And Mapping (SLAM). is a central task in robotics and computer vision. Many variants of this task exist. depending on the available sensor data. whether it has to run at interactive rates or with offline data. and the desired properties of the resulting scene map. A particularly challenging form of SLAM. in which the only available data source is a video stream from a single-lens RGB camera that has to be tracked live. is called monocular SLAM or realtime Structure from Motion. It combines the difficulties of unknown camera pose. unknown structure of the observed scene. and tight bounds on computation time. While being hard. monocular SLAM is also especially interesting. as RGB cameras are ubiquitously available and allow for virtually limitless applications.This work combines two approaches for accurate tracking in a monocular SLAM setting: First. the physical camera is tracked in realtime using a semi-dense frameto-keyframe scheme. By using keyframe depth maps which are dense only where the corresponding input color image exhibits significant visual structure. this scheme minimizes the time spent on data that does not contribute useful tracking information. Areas displaying little or no structure are ignored. Second. newly constructed depth maps are aligned to the existing collection of depth maps using a variant of ICP that is robust with respect to incomplete overlap between data sets. which helps reduce camera drift left by frame-to-keyframe tracking. The tracked input frames are used in …,True,Is8Zxz8AAAAJ:qjMakFHDy7sC,1,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1852&rep=rep1&type=pdf,15451416913020324509,/scholar?cites=15451416913020324509,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1852&rep=rep1&type=pdf,0,0,0
1282631,Synthetic Training Data for Deep Neural Networks on Visual Correspondence Tasks,2020,Nikolaus Mayer,,,,,,In the realm of deep learning for computer vision tasks. the best performing models tend to be trained with supervision. ie with a training dataset that contains ground-truth annotations which the model is expected to match. Visual tasks are particularly interesting because humans rely mostly on their eyes for almost everything they do; we attribute great importance to our visual perception of the world. and we have developed methods to produce visually realistic simulations of this world for purposes of entertainment. communication. and research. These same methods enable the creation of synthetic training data: rendered views of virtual worlds with annotations that are more extensive and accurate than anything a human could label with justifiable time and effort.,True,Is8Zxz8AAAAJ:u-x6o8ySG0sC,0,https://lmb.informatik.uni-freiburg.de/Publications/2020/May20/,,,,,,0,0,0
1282632,Mining educational data to analyze students' performance,2012,Brijesh Kumar Baradwaj and Saurabh Pal,,arXiv preprint arXiv:1201.3417,,,,The main objective of higher education institutions is to provide quality education to its students. One way to achieve highest level of quality in higher education system is by discovering knowledge for prediction regarding enrolment of students in a particular course. alienation of traditional classroom teaching model. detection of unfair means used in online examination. detection of abnormal values in the result sheets of the students. prediction about students' performance and so on. The knowledge is hidden among the educational data set and it is extractable through data mining techniques. Present paper is designed to justify the capabilities of data mining techniques in context of higher education by offering a data mining model for higher education system in the university. In this research. the classification task is used to evaluate student's performance and as there are many approaches that are used for data classification. the decision tree method is used here. By this task we extract knowledge that describes students' performance in end semester examination. It helps earlier in identifying the dropouts and students who need special attention and allow the teacher to provide appropriate advising/counseling. Keywords-Educational Data Mining (EDM); Classification; Knowledge Discovery in Database (KDD); ID3 Algorithm.,True,BdMXgHYAAAAJ:wvYxNZNCP7wC,816,https://arxiv.org/abs/1201.3417,11948874423346679741,/scholar?cites=11948874423346679741,,,https://arxiv.org/pdf/1201.3417,0,0,0
1282633,Data Mining: A prediction for performance improvement using classification,2012,Brijesh Kumar Bhardwaj and Saurabh Pal,,arXiv preprint arXiv:1201.3418,,,,Now-a-days the amount of data stored in educational database increasing rapidly. These databases contain hidden information for improvement of students' performance. The performance in higher education in India is a turning point in the academics for all students. This academic performance is influenced by many factors. therefore it is essential to develop predictive data mining model for students' performance so as to identify the difference between high learners and slow learners student. In the present investigation. an experimental methodology was adopted to generate a database. The raw data was preprocessed in terms of filling up missing values. transforming values in one form into another and relevant attribute/variable selection. As a result. we had 300 student records. which were used for by Byes classification prediction model construction. Keywords-Data Mining. Educational Data Mining. Predictive Model. Classification.,True,BdMXgHYAAAAJ:jSAVyFp_754C,372,https://arxiv.org/abs/1201.3418,12916873224777731359,/scholar?cites=12916873224777731359,,,https://arxiv.org/pdf/1201.3418,0,0,0
1282634,Data mining: A prediction for performance improvement of engineering students using classification,2012,Surjeet Kumar Yadav and Saurabh Pal,,arXiv preprint arXiv:1203.3832,,,,Now-a-days the amount of data stored in educational database increasing rapidly. These databases contain hidden information for improvement of students' performance. Educational data mining is used to study the data available in the educational field and bring out the hidden knowledge from it. Classification methods like decision trees. Bayesian network etc can be applied on the educational data for predicting the student's performance in examination. This prediction will help to identify the weak students and help them to score better marks. The C4. 5. ID3 and CART decision tree algorithms are applied on engineering student's data to predict their performance in the final exam. The outcome of the decision tree predicted the number of students who are likely to pass. fail or promoted to next year. The results provide steps to improve the performance of the students who were predicted to fail or promoted. After the declaration of the results in the final examination the marks obtained by the students are fed into the system and the results were analyzed for the next session. The comparative analysis of the results states that the prediction has helped the weaker students to improve and brought out betterment in the result.,True,BdMXgHYAAAAJ:2l5NCbZemmgC,231,https://arxiv.org/abs/1203.3832,5859349011888227801,/scholar?cites=5859349011888227801,,,https://arxiv.org/pdf/1203.3832,0,0,0
1282635,Data mining applications: A comparative study for predicting student's performance,2012,Surjeet Kumar Yadav and Brijesh Bharadwaj and Saurabh Pal,,arXiv preprint arXiv:1202.4815,,,,Knowledge Discovery and Data Mining (KDD) is a multidisciplinary area focusing upon methodologies for extracting useful knowledge from data and there are several useful KDD tools to extracting the knowledge. This knowledge can be used to increase the quality of education. But educational institution does not use any knowledge discovery process approach on these data. Data mining can be used for decision making in educational system. A decision tree classifier is one of the most widely used supervised learning methods used for data exploration based on divide & conquer technique. This paper discusses use of decision trees in educational data mining. Decision tree algorithms are applied on students' past performance data to generate the model and this model can be used to predict the students' performance. It helps earlier in identifying the dropouts and students who need special attention and allow the teacher to provide appropriate advising/counseling.,True,BdMXgHYAAAAJ:oi2SiIJ9l4AC,206,https://arxiv.org/abs/1202.4815,3779966620011635668,/scholar?cites=3779966620011635668,,,https://arxiv.org/pdf/1202.4815,0,0,0
1282636,Early prediction of heart diseases using data mining techniques,2013,Vikas Chaurasia and Saurabh Pal,1,Caribbean Journal of Science and Technology,,208-217,,Largest-ever study of deaths shows heart diseases have emerged as the number one killer in world. About 25 per cent of deaths in the age group of 25-69 years occur because of heart diseases. If all age groups are included. heart diseases account for about 19 per cent of all deaths. It is the leading cause of death among males as well as females. It is also the leading cause of death in all regions though the numbers vary. The proportion of deaths caused by heart disease is the highest in south India (25 per cent) and lowest-12 per cent-in the central region of India. The prediction of heart disease survivability has been a challenging research problem for many researchers. Since the early dates of the related research. much advancement has been recorded in several related fields. Therefore. the main objective of this manuscript is to report on a research project where we took advantage of those available technological advancements to develop prediction models for heart disease survivability.,True,BdMXgHYAAAAJ:mUJArPsKIAAC,194,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2991237,4013148062945320195,/scholar?cites=4013148062945320195,,,https://www.researchgate.net/profile/Vikas_Chaurasia/publication/259474824_Early_Prediction_of_Heart_Diseases_Using_Data_Mining_Techniques/links/0c96052bfd32153b24000000/Early-Prediction-of-Heart-Diseases-Using-Data-Mining-Techniques.pdf,0,0,0
1282637,Data Mining: A prediction of performer or underperformer using classification,2011,Umesh Kumar Pandey and Saurabh Pal,,arXiv preprint arXiv:1104.4163,,,,Now a day's students have a large set of data having precious information hidden. Data mining technique can help to find this hidden information. In this paper. data mining techniques name Byes classification method is used on these data to help an institution. Institutions can find those students who are consistently perform well. This study will help to institution reduce the drop put ratio to a significant level and improve the performance level of the institution.,True,BdMXgHYAAAAJ:1DsIQWDZLl8C,179,https://arxiv.org/abs/1104.4163,858724198457584941,/scholar?cites=858724198457584941,,,https://arxiv.org/pdf/1104.4163,0,0,0
1282638,Data mining techniques: To predict and resolve breast cancer survivability,2014,Vikas Chaurasia and Saurabh Pal,3,International Journal of Computer Science and Mobile Computing IJCSMC,1,10-22,,Breast cancer is one of the deadliest disease. is the most common of all cancers and is the leading cause of cancer deaths in women worldwide. accounting for> 1.6% of deaths and case fatality rates are highest in low-resource countries. The breast cancer risks are broadly classified into modifiable and non–modifiable factors. The non modifiable risk factors are age. gender. number of first degree relatives suffering from breast cancer. menstrual history. age at menarche and age at menopause. While the modifiable risk factors are BMI. age at first child birth. number of children. duration of breast feeding. alcohol. diet and number of abortions. This paper presents a diagnosis system for detecting breast cancer based on RepTree. RBF Network and Simple Logistic. In test stage. 10-fold cross validation method was applied to the University Medical Centre. Institute of Oncology. Ljubljana. Yugoslavia database to evaluate the proposed system performances. The correct classification rate of proposed system is 74.5%. This research demonstrated that the Simple Logistic can be used for reducing the dimension of feature space and proposed Rep Tree and RBF Network model can be used to obtain fast automatic diagnostic systems for other diseases.,True,BdMXgHYAAAAJ:69ZgNCALVd0C,155,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2994925,9989527661677621408,/scholar?cites=9989527661677621408,,,https://www.researchgate.net/profile/Vikas_Chaurasia/publication/259591152_Data_Mining_Techniques_To_Predict_and_Resolve_Breast_Cancer_Survivability/links/5f97a2e092851c14bceab926/Data-Mining-Techniques-To-Predict-and-Resolve-Breast-Cancer-Survivability.pdf,0,0,0
1282639,A novel approach for breast cancer detection using data mining techniques,2014,Vikas Chaurasia and Saurabh Pal,2,International Journal of Innovative Research in Computer and Communication Engineering (An ISO 3297: 2007 Certified Organization) Vol,,,,Breast cancer is one of the leading cancers for women when compared to all other cancers. It is the second most common cause of cancer death in women. Breast cancer risk in India revealed that 1 in 28 women develop breast cancer during her lifetime. This is higher in urban areas being 1 in 22 in a lifetime compared to rural areas where this risk is relatively much lower being 1 in 60 women developing breast cancer in their lifetime. In India the average age of the high risk group is 43-46 years unlike in the west where women aged 53-57 years are more prone to breast cancer.,True,BdMXgHYAAAAJ:An6A6Jpfc1oC,147,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2994932,5572838240958566383,/scholar?cites=5572838240958566383,,,https://www.academia.edu/download/32919308/9_A_Novel.pdf,0,0,0
1282640,Data mining approach to detect heart diseases,2014,Vikas Chaurasia and Saurabh Pal,2,International Journal of Advanced Computer Science and Information Technology (IJACSIT) Vol,,56-66,,Globally. heart diseases are the number one cause of death. About 80% of deaths occurred in low-and middle income countries. If current trends are allowed to continue. by 2030 an estimated 23.6 million people will die from cardiovascular disease (mainly from heart attacks and strokes).,True,BdMXgHYAAAAJ:YsrPvlHIBpEC,130,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2376653,4740992294346905020,/scholar?cites=4740992294346905020,,,https://www.academia.edu/download/32271805/IJACSIT-24031.pdf,0,0,0
1282641,Prediction of benign and malignant breast cancer using data mining techniques,2018,Vikas Chaurasia and Saurabh Pal and BB Tiwari,12,Journal of Algorithms & Computational Technology,2,119-126,SAGE Publications,Breast cancer is the second most leading cancer occurring in women compared to all other cancers. Around 1.1 million cases were recorded in 2004. Observed rates of this cancer increase with industrialization and urbanization and also with facilities for early detection. It remains much more common in high-income countries but is now increasing rapidly in middle- and low-income countries including within Africa. much of Asia. and Latin America. Breast cancer is fatal in under half of all cases and is the leading cause of death from cancer in women. accounting for 16% of all cancer deaths worldwide. The objective of this research paper is to present a report on breast cancer where we took advantage of those available technological advancements to develop prediction models for breast cancer survivability. We used three popular data mining algorithms (Naïve Bayes. RBF Network. J48) to develop the prediction …,True,BdMXgHYAAAAJ:VN7nJs4JPk0C,116,https://journals.sagepub.com/doi/abs/10.1177/1748301818756225,1920680775187161120,/scholar?cites=1920680775187161120,,,https://journals.sagepub.com/doi/pdf/10.1177/1748301818756225,0,0,0
1282642,Mining Education data to predict student's retention: a comparative study,2012,Surjeet Kumar Yadav and Brijesh Bharadwaj and Saurabh Pal,,arXiv preprint arXiv:1203.2987,,,,The main objective of higher education is to provide quality education to students. One way to achieve highest level of quality in higher education system is by discovering knowledge for prediction regarding enrolment of students in a course. This paper presents a data mining project to generate predictive models for student retention management. Given new records of incoming students. these predictive models can produce short accurate prediction lists identifying students who tend to need the support from the student retention program most. This paper examines the quality of the predictive models generated by the machine learning algorithms. The results show that some of the machines learning algorithms are able to establish effective predictive models from the existing student retention data.,True,BdMXgHYAAAAJ:Hck25ST_3aIC,97,https://arxiv.org/abs/1203.2987,14157657160367992509,/scholar?cites=14157657160367992509,,,https://arxiv.org/pdf/1203.2987,0,0,0
1282643,Adaptive motion-vector resampling for compressed video downscaling,1999,Bo Shen and Ishwar K Sethi and Bhaskaran Vasudev,9,IEEE Transactions on Circuits and Systems for Video Technology,6,929-936,IEEE,Digital video is becoming widely available in compressed form. such as a motion JPEG or MPEG coded bitstream. In applications such as video browsing or picture-in-picture. or in transcoding for a lower bit rate. there is a need to downscale the video prior to its transmission. In such instances. the conventional approach to generating a downscaled video bitstream at the video server would be to first decompress the video. perform the downscaling operation in the pixel domain. and then recompress it as. say. an MPEG. bitstream for efficient delivery. This process is computationally expensive due to the motion-estimation process needed during the recompression phase. We propose an alternative compressed domain-based approach that computes motion vectors for the downscaled (N/2xN/2) video sequence directly from the original motion vectors for the N/spl times/N video sequence. We further discover that the …,True,aAo9PNMAAAAJ:_Qo2XoVZTnwC,294,https://ieeexplore.ieee.org/abstract/document/785730/,9292778030313729803,/scholar?cites=9292778030313729803,,,https://www.academia.edu/download/31085257/shen-csvt-99.pdf,0,0,0
1282644,Direct feature extraction from compressed images,1996,Bo Shen and Ishwar K Sethi,2670,,,404-414,International Society for Optics and Photonics,This paper examines the issue of direct extraction of low level features from compressed images. Specifically. we consider the detection of areas of interest and edges in images compressed using the discrete cosine transform (DCT). For interest areas. we show how a measure based on certain DCT coefficients of a block can provide an indication of underlying activity. For edges. we show using an ideal edge model how the relative values of different DCT coefficients of a block can be used to estimate the strength and orientation of an edge. Our experimental results indicate that coarse edge information from compressed images can be extracted up to 20 times faster than conventional edge detectors.,True,aAo9PNMAAAAJ:LkGwnXOMwfcC,251,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2670/0000/Direct-feature-extraction-from-compressed-images/10.1117/12.234779.short,2239464714380592829,/scholar?cites=2239464714380592829,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.329.5774&rep=rep1&type=pdf,0,0,0
1282645,Caching strategies in transcoding-enabled proxy systems for streaming media distribution networks,2004,Bo Shen and Sung-Ju Lee and Sujoy Basu,6,IEEE Transactions on Multimedia,2,375-386,IEEE,With the wide availability of high-speed network access. we are experiencing high quality streaming media delivery over the Internet. The emergence of ubiquitous computing enables mobile users to access the Internet with their laptops. PDAs. or even cell phones. When nomadic users connect to the network via wireless links or phone lines. high quality video transfer can be problematic due to long delay or size mismatch between the application display and the screen. Our proposed solution to this problem is to enable network proxies with the transcoding capability. and hence provide different. appropriate video quality to different network environment. The proxies in our transcoding-enabled caching (TeC) system perform transcoding as well as caching for efficient rich media delivery to heterogeneous network users. This design choice allows us to perform content adaptation at the network edges. We propose …,True,aAo9PNMAAAAJ:qUcmZB5y_30C,178,https://ieeexplore.ieee.org/abstract/document/1275467/,7907192096284708880,/scholar?cites=7907192096284708880,,,https://www.researchgate.net/profile/Bo_Shen8/publication/3424189_Caching_Strategies_in_Transcoding-Enabled_Proxy_Systems_for_Streaming_Media_Distribution_Networks/links/0f31753c4109b3db10000000/Caching-Strategies-in-Transcoding-Enabled-Proxy-Systems-for-Streaming-Media-Distribution-Networks.pdf,0,0,0
1282646,Method for managing a streaming media service,2005,Michael Harville and Michele Covell and Susie Wee and John Ankcorn and Sumit Roy and Bo Shen,,,,,,One embodiment of the invention includes a method for managing a streaming media service. The method includes receiving a request for a streaming media service from a client. The streaming media service includes a plurality of media services components. Additionally. the method includes determining which media service component of the plurality of media services components to assign to a service node of a plurality of service nodes of a network. The method also includes informing each service node assigned to perform a media service component of the plurality of media services components enabling the streaming media service to be performed on a streaming media.,True,aAo9PNMAAAAJ:cFHS6HbyZ2cC,169,https://patents.google.com/patent/US20050005025A1/en,16538652039225714943,/scholar?cites=16538652039225714943,,,https://patentimages.storage.googleapis.com/f0/9f/97/3d508591cc6b12/US20050005025A1.pdf,0,0,0
1282647,Adaptive and lazy segmentation based proxy caching for streaming media delivery,2003,Songqing Chen and Bo Shen and Susie Wee and Xiaodong Zhang,,,,22-31,ACM,Streaming media objects are often cached in segments. Previous segment-based caching strategies cache segments with constant or exponentially increasing lengths and typically favor caching the beginning segments of media objects. However. these strategies typically do not consider the fact that most accesses are targeted toward a few popular objects. In this paper. we argue that neither the use of a predefined segment length nor the favorable caching of the beginning segments is the best caching strategy for reducing network traffic. We propose an adaptive and lazy segmentation based caching mechanism by delaying the segmentation as late as possible and determining the segment length based on the client access behaviors in real time. In addition. the admission and eviction of segments are carried out adaptively based on an accurate utility function. The proposed method is evaluated by simulations …,True,aAo9PNMAAAAJ:ns9cj8rnVeAC,161,https://dl.acm.org/doi/abs/10.1145/776322.776328,12544216174918962915,/scholar?cites=12544216174918962915,,,https://cs.gmu.edu/~sqchen/publications/nossdav03.pdf,0,0,0
1282648,Segment-based proxy caching for internet streaming media delivery,2005,Songqing Chen and Haining Wang and Xiaodong Zhang and Bo Shen and Susie Wee,12,IEEE multimedia,3,59-67,IEEE,The proliferation of multimedia content on the Internet poses challenges to existing content delivery networks. While proxy caching can successfully deliver traditional text-based static objects. it faces difficulty delivering streaming media objects because of the objects' sizes as well as clients' rigorous continuous delivery demands. We present two techniques supporting segment based proxy caching of streaming media. We evaluated these techniques in simulations and real systems.,True,aAo9PNMAAAAJ:9ZlFYXVOiuMC,105,https://ieeexplore.ieee.org/abstract/document/1490497/,7066415382441422704,/scholar?cites=7066415382441422704,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5296&rep=rep1&type=pdf,0,0,0
1282649,Segment-based streaming media proxy: modeling and optimization,2006,Songqing Chen and Bo Shen and Susie Wee and Xiaodong Zhang,8,IEEE Transactions on Multimedia,2,243-256,IEEE,Researchers often use segment-based proxy caching strategies to deliver streaming media by partially caching media objects. The existing strategies mainly consider increasing the byte hit ratio and/or reducing the client perceived startup latency (denoted by the metric delayed startup ratio). However. these efforts do not guarantee continuous media delivery because the to-be-viewed object segments may not be cached in the proxy when they are demanded. The potential consequence is playback jitter at the client side due to proxy delay in fetching the uncached segments. which we call proxy jitter. Thus. for the best interests of clients. a correct model for streaming proxy system design should aim to minimize proxy jitter subject to reducing the delayed startup ratio and increasing the byte hit ratio. However. we have observed two major pairs of conflicting interests inherent in this model: (1) one between improving …,True,aAo9PNMAAAAJ:Se3iqnhoufwC,97,https://ieeexplore.ieee.org/abstract/document/1608106/,2856427864583313336,/scholar?cites=2856427864583313336,,,http://web.cse.ohio-state.edu/hpcs/WWW/HTML/publications/papers/TR-06-4.pdf,0,0,0
1282650,Method for assigning a streaming media session to a server in fixed and mobile streaming media systems,2005,John G Apostolopoulos and Sujoy Basu and Gene Cheung and Rajendra Kumar and Sumit Roy and Wai-Tan Tan and Susie J Wee and Tina Wong and Bo Shen,,,,,,A method for assigning servers to provide multiple description bitstreams to a mobile client (in a mobile client environment) or to a fixed client (in a fixed client environment). In one embodiment. the present invention. upon receiving a request from a mobile client to have media data streamed thereto. analyzes a plurality of servers to determine a first candidate server for providing a first multiple description bitstream to the base station along a first path. The present method also determines a second candidate server for providing a second multiple description bitstream to the base station along a second path. The present method then sends a request to the first candidate server to provide the first multiple description bitstream to a mobile client through a base station along the first path. and also sends a request to the second candidate server to provide the second multiple description bitstream to the mobile client …,True,aAo9PNMAAAAJ:b0M2c_1WBrUC,96,https://patents.google.com/patent/US6941378B2/en,17555902371185901363,/scholar?cites=17555902371185901363,,,https://patentimages.storage.googleapis.com/eb/fe/ef/202ee7f101a383/US6941378.pdf,0,0,0
1282651,Method for assigning a streaming media session to a server in fixed and mobile streaming media systems,2005,John G Apostolopoulos and Sujoy Basu and Gene Cheung and Rajendra Kumar and Sumit Roy and Wai-Tan Tan and Susie J Wee and Tina Wong and Bo Shen,,,,,,A method for assigning servers to provide multiple description bitstreams to a mobile client (in a mobile client environment) or to a fixed client (in a fixed client environment). In one embodiment. the present invention. upon receiving a request from a mobile client to have media data streamed thereto. analyzes a plurality of servers to determine a first candidate server for providing a first multiple description bitstream to the base station along a first path. The present method also determines a second candidate server for providing a second multiple description bitstream to the base station along a second path. The present method then sends a request to the first candidate server to provide the first multiple description bitstream to a mobile client through a base station along the first path. and also sends a request to the second candidate server to provide the second multiple description bitstream to the mobile client …,True,aAo9PNMAAAAJ:aqlVkmm33-oC,96,https://patents.google.com/patent/US6941378B2/en,17555902371185901363,/scholar?cites=17555902371185901363,,,https://patentimages.storage.googleapis.com/eb/fe/ef/202ee7f101a383/US6941378.pdf,0,0,0
1282652,Shared running-buffer-based caching system,2005,Bo Shen and Songqing Chen and Yong Yan and Sujoy Basu,,,,,,A server-proxy-client network delivers web content objects from servers to clients from cache content at a proxy server in between. Multiple. moving-window buffers are used to service content requests of the server by various independent clients. A first request for content is delivered by the server through the proxy to the requesting client. The content is simultaneously duplicated to a first circulating buffer. Once the buffer fills. the earlier parts are automatically deleted. The buffer therefore holds a most-recently delivered window of content. If a second request for the same content comes in. a check is made to see if the start of the content is still in the first buffer. If it is. the content is delivered from the first buffer. Otherwise. a second buffer is opened and both buffers are used to deliver what they can simultaneously. Such process can open up third and fourth buffers depending on the size of the content. the size of the …,True,aAo9PNMAAAAJ:e5wmG9Sq2KIC,89,https://patents.google.com/patent/US20050086386A1/en,9134323205601460357,/scholar?cites=9134323205601460357,,,https://patentimages.storage.googleapis.com/0e/a7/fa/278d60d92ec3a2/US20050086386A1.pdf,0,0,0
1282653,Content services network: the architecture and protocols,2001,Wei-Ying Ma and Bo Shen and Jack Brassil,,Proceedings of 6th International Workshop on Web Caching and Content Distribution (IWCW6),,,,Content delivery networks (CDNs) can be viewed as application-specific overlay networks that make web caching an infrastructure service accessible to any content provider. As the Internet continues to evolve with increasing diversity and heterogeneity. we see a growing demand for extending the capabilities of network intermediaries to provide additional services such as content adaptation. personalization. watermarking and location-aware data insertion.A content services network (CSN) is proposed in this paper to make content transformation and processing an infrastructure service accessible to its subscribers. One can think of CSN as another layer of network infrastructure built around CDNs. This layer interacts collaboratively with user-agents. content servers. and other network intermediaries including ISPs’ caching proxies and CDNs’ surrogates in the content delivery process to provide value-added services. Furthermore. a CSN provides network resources that are used as a “service” distribution channel for value-added services providers to make their applications an infrastructure service.,True,aAo9PNMAAAAJ:ufrVoPGSRksC,82,https://www.researchgate.net/profile/Bo_Shen8/publication/2532080_Content_Services_Network_The_Architecture_and_Protocols/links/0f31753c4109cd1f4d000000/Content-Services-Network-The-Architecture-and-Protocols.pdf,2024974480095370700,/scholar?cites=2024974480095370700,,,https://www.researchgate.net/profile/Bo_Shen8/publication/2532080_Content_Services_Network_The_Architecture_and_Protocols/links/0f31753c4109cd1f4d000000/Content-Services-Network-The-Architecture-and-Protocols.pdf,0,0,0
1282654,BING: Binarized normed gradients for objectness estimation at 300fps,2014,Ming-Ming Cheng and Ziming Zhang and Wen-Yan Lin and Philip Torr,,,,3286-3293,,Training a generic objectness measure to produce a small set of candidate object windows. has been shown to speed up the classical sliding window object detection paradigm. We observe that generic objects with well-defined closed boundary can be discriminated by looking at the norm of gradients. with a suitable resizing of their corresponding image windows in to a small fixed size. Based on this observation and computational reasons. we propose to resize the window to 8× 8 and use the norm of the gradients as a simple 64D feature to describe it. for explicitly training a generic objectness measure. We further show how the binarized version of this feature. namely binarized normed gradients (BING). can be used for efficient objectness estimation. which requires only a few atomic operations (eg ADD. BITWISE SHIFT. etc.). Experiments on the challenging PASCAL VOC 2007 dataset show that our method efficiently (300fps on a single laptop CPU) generates a small set of category-independent. high quality object windows. yielding 96.2% object detection rate (DR) with 1.000 proposals. Increasing the numbers of proposals and color spaces for computing BING features. our performance can be further improved to 99.5% DR.,True,2yqx3oIAAAAJ:B3FOqHPlNUQC,1211,http://openaccess.thecvf.com/content_cvpr_2014/html/Cheng_BING_Binarized_Normed_2014_CVPR_paper.html,3954510416846951864,/scholar?cites=3954510416846951864,,,https://openaccess.thecvf.com/content_cvpr_2014/papers/Cheng_BING_Binarized_Normed_2014_CVPR_paper.pdf,0,0,0
1282655,Zero-Shot Learning via Semantic Similarity Embedding,2015,Ziming Zhang and Venkatesh Saligrama,,,,,,In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided. The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information (eg attributes) for unseen classes. Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class. This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured. We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation. Our test results are compelling. leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition.,True,2yqx3oIAAAAJ:LPZeul_q3PIC,496,https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhang_Zero-Shot_Learning_via_ICCV_2015_paper.html,3847883737916740072,/scholar?cites=3847883737916740072,,,https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zhang_Zero-Shot_Learning_via_ICCV_2015_paper.pdf,0,0,0
1282656,Zero-shot learning via joint latent similarity embedding,2016,Ziming Zhang and Venkatesh Saligrama,,,,6034-6042,,Zero-shot recognition (ZSR) deals with the problem of predicting class labels for target domain instances based on source domain side information (eg attributes) of unseen classes. We formulate ZSR as a binary prediction problem. Our resulting classifier is class-independent. It takes an arbitrary pair of source and target domain instances as input and predicts whether or not they come from the same class. ie whether there is a match. We model the posterior probability of a match since it is a sufficient statistic and propose a latent probabilistic model in this context. We develop a joint discriminative learning framework based on dictionary learning to jointly learn the parameters of our model for both domains. which ultimately leads to our class-independent classifier. Many of the existing embedding methods can be viewed as special cases of our probabilistic model. On ZSR our method shows 4.90% improvement over the state-of-the-art in accuracy averaged across four benchmark datasets. We also adapt ZSR method for zero-shot retrieval and show 22.45% improvement accordingly in mean average precision (mAP).,True,2yqx3oIAAAAJ:1yQoGdGgb4wC,324,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Zhang_Zero-Shot_Learning_via_CVPR_2016_paper.html,11042220739614162925,/scholar?cites=11042220739614162925,,,https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhang_Zero-Shot_Learning_via_CVPR_2016_paper.pdf,0,0,0
1282657,Attention-based multimodal fusion for video description,2017,Chiori Hori and Takaaki Hori and Teng-Yok Lee and Ziming Zhang and Bret Harsham and John R. Hershey and Tim K. Marks and Kazuhiro Sumi,,,,,,Current methods for video description are based on encoder-decoder sentence generation using recurrent neural networks (RNNs). Recent work has demonstrated the advantages of integrating temporal attention mechanisms into these models. in which the decoder network predicts each word in the description by selectively giving more weight to encoded features from specific time frames. Such methods typically use two different types of features: image features (from an object classification model). and motion features (from an action recognition model). combined by naive concatenation in the model input. Because different feature modalities may carry task-relevant information at different times. fusing them by naive concatenation may limit the model's ability to dynamically determine the relevance of each type of feature to different parts of the description. In this paper. we incorporate audio features in addition to the image and motion features. To fuse these three modalities. we introduce a multimodal attention model that can selectively utilize features from different modalities for each word in the output description. Combining our new multimodal attention model with standard temporal attention outperforms state-of-the-art methods on two standard datasets: YouTube2Text and MSR-VTT.,True,2yqx3oIAAAAJ:NJ774b8OgUMC,207,http://openaccess.thecvf.com/content_iccv_2017/html/Hori_Attention-Based_Multimodal_Fusion_ICCV_2017_paper.html,9584037578258422077,/scholar?cites=9584037578258422077,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Hori_Attention-Based_Multimodal_Fusion_ICCV_2017_paper.pdf,0,0,0
1282658,Motion context: A new representation for human action recognition,2008,Ziming Zhang and Yiqun Hu and Syin Chan and Liang-Tien Chia,,,,817-829,Springer. Berlin. Heidelberg,One of the key challenges in human action recognition from video sequences is how to model an action sufficiently. Therefore. in this paper we propose a novel motion-based representation called Motion Context (MC). which is insensitive to the scale and direction of an action. by employing image representation techniques. A MC captures the distribution of the motion words (MWs) over relative locations in a local region of the motion image (MI) around a reference point and thus summarizes the local motion information in a rich 3D MC descriptor. In this way. any human action can be represented as a 3D descriptor by summing up all the MC descriptors of this action. For action recognition. we propose 4 different recognition configurations: MW+pLSA. MW+SVM. MC+w 3-pLSA (a new direct graphical model by extending pLSA). and MC+SVM. We test our approach on two human action video …,True,2yqx3oIAAAAJ:ULOm3_A8WrAC,199,https://link.springer.com/chapter/10.1007/978-3-540-88693-8_60,2090407601193397444,/scholar?cites=2090407601193397444,,,https://link.springer.com/content/pdf/10.1007/978-3-540-88693-8_60.pdf,0,0,0
1282659,Efficient training of very deep neural networks for supervised hashing,2016,Ziming Zhang and Yuting Chen and Venkatesh Saligrama,,,,1487-1495,,"In this paper. we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively"" shallow"" networks limited by the issues arising in back propagation (eg vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-the-art on several benchmark datasets.",True,2yqx3oIAAAAJ:PR6Y55bgFSsC,118,http://openaccess.thecvf.com/content_cvpr_2016/html/Zhang_Efficient_Training_of_CVPR_2016_paper.html,5218623187270418652,/scholar?cites=5218623187270418652,,,http://openaccess.thecvf.com/content_cvpr_2016/papers/Zhang_Efficient_Training_of_CVPR_2016_paper.pdf,0,0,0
1282660,Proposal generation for object detection using cascaded ranking svms,2011,Ziming Zhang and Jonathan Warrell and Philip HS Torr,,,,1497-1504,IEEE,Object recognition has made great strides recently. However. the best methods. such as those based on kernel-SVMs are highly computationally intensive. The problem of how to accelerate the evaluation process without decreasing accuracy is thus of current interest. In this paper. we deal with this problem by using the idea of ranking. We propose a cascaded architecture which using the ranking SVM generates an ordered set of proposals for windows containing object instances. The top ranking windows may then be fed to a more complex detector. Our experiments demonstrate that our approach is robust. achieving higher overlap-recall values using fewer output proposals than the state-of-the-art. Our use of simple gradient features and linear convolution indicates that our method is also faster than the state-of-the-art.,True,2yqx3oIAAAAJ:qxL8FJ1GzNcC,117,https://ieeexplore.ieee.org/abstract/document/5995411/,10158828421613216730,/scholar?cites=10158828421613216730,,,https://www.academia.edu/download/50128354/Proposal_generation_for_object_detection20161105-23785-1s1lk4f.pdf,0,0,0
1282661,Zero-shot recognition via structured prediction,2016,Ziming Zhang and Venkatesh Saligrama,,,,533-548,Springer. Cham,We develop a novel method for zero shot learning (ZSL) based on test-time adaptation of similarity functions learned using training data. Existing methods exclusively employ source-domain side information for recognizing unseen classes during test time. We show that for batch-mode applications. accuracy can be significantly improved by adapting these predictors to the observed test-time target-domain ensemble. We develop a novel structured prediction method for maximum a posteriori (MAP) estimation. where parameters account for test-time domain shift from what is predicted primarily using source domain information. We propose a Gaussian parameterization for the MAP problem and derive an efficient structure prediction algorithm. Empirically we test our method on four popular benchmark image datasets for ZSL. and show significant improvement over the state-of-the-art. on average. by 11.50 …,True,2yqx3oIAAAAJ:UHK10RUVsp4C,93,https://link.springer.com/chapter/10.1007/978-3-319-46478-7_33,2524828315960568724,/scholar?cites=2524828315960568724,,,https://www.researchgate.net/profile/Venkatesh_Saligrama/publication/308189175_Zero-Shot_Recognition_via_Structured_Prediction/links/59fdb7510f7e9b9968c2cda4/Zero-Shot-Recognition-via-Structured-Prediction.pdf,0,0,0
1282662,A Novel Visual Word Co-occurrence Model for Person Re-identification,2014,Ziming Zhang and Yuting Chen and Venkatesh Saligrama,,,,,,Person re-identification aims to maintain the identity of an individual in diverse locations through different non-overlapping camera views. The problem is fundamentally challenging due to appearance variations resulting from differing poses. illumination and configurations of camera views. To deal with these difficulties. we propose a novel visual word co-occurrence model. We first map each pixel of an image to a visual word using a codebook. which is learned in an unsupervised manner. The appearance transformation between camera views is encoded by a co-occurrence matrix of visual word joint distributions in probe and gallery images. Our appearance model naturally accounts for spatial similarities and variations caused by pose. illumination & configuration change across camera views. Linear SVMs are then trained as classifiers using these co-occurrence descriptors. On the VIPeR [1] and CUHK …,True,2yqx3oIAAAAJ:sSrBHYA8nusC,65,https://link.springer.com/chapter/10.1007/978-3-319-16199-0_9,13014224940922346974,/scholar?cites=13014224940922346974,,,https://link.springer.com/content/pdf/10.1007/978-3-319-16199-0_9.pdf,0,0,0
1282663,Exploiting the anisotropy of correlation filter learning for visual tracking,2019,Yao Sui and Ziming Zhang and Guanghui Wang and Yafei Tang and Li Zhang,127,International Journal of Computer Vision,8,1084-1105,Springer US,Correlation filtering based tracking model has received significant attention and achieved great success in terms of both tracking accuracy and computational complexity. However. due to the limitation of the loss function. current correlation filtering paradigm could not reliably respond to the abrupt appearance changes of the target object. This study focuses on improving the robustness of the correlation filter learning. An anisotropy of the filter response is observed and analyzed for the correlation filtering based tracking model. through which the overfitting issue of previous methods is alleviated. Three sparsity related loss functions are proposed to exploit the anisotropy. leading to three implementations of visual trackers. correspondingly resulting in improved overall tracking performance. A large number of experiments are conducted and these experimental results demonstrate that the proposed approach …,True,2yqx3oIAAAAJ:epqYDVWIO7EC,59,https://link.springer.com/article/10.1007/s11263-019-01156-6,7561429577680240067,/scholar?cites=7561429577680240067,,,,0,0,0
1282664,Sequential Optimization for Efficient High-Quality Object Proposal Generation,2017,Ziming Zhang and Yun Liu and Xi Chen and Yanjun Zhu and Ming-Ming Cheng and Venkatesh Saligrama and Philip H.S. Torr,,PAMI,,,,We are motivated by the need for a generic object proposal generation algorithm which achieves good balance between object detection recall. proposal localization quality and computational efficiency. We propose a novel object proposal algorithm. BING ++. which inherits the virtue of good computational efficiency of BING [1] but significantly improves its proposal localization quality. At high level we formulate the problem of object proposal generation from a novel probabilistic perspective. based on which our BING++ manages to improve the localization quality by employing edges and segments to estimate object boundaries and update the proposals sequentially. We propose learning the parameters efficiently by searching for approximate solutions in a quantized parameter space for complexity reduction. We demonstrate the generalization of BING++ with the same fixed parameters across different object …,True,2yqx3oIAAAAJ:WqliGbK-hY8C,49,https://ieeexplore.ieee.org/abstract/document/7932893/,16362871080065443571,/scholar?cites=16362871080065443571,,,https://arxiv.org/pdf/1511.04511,0,0,0
1282665,Deep learning for computational biology,2016,Christof Angermueller and Tanel Pärnamaa and Leopold Parts and Oliver Stegle,12,,7,878,,Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods. such as deep learning. promise to leverage very large data sets for finding hidden structure within them. and for making accurate predictions. In this review. we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is. and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use. we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new …,True,OXZC0mQAAAAJ:wbdj-CoPYUoC,877,https://www.embopress.org/doi/abs/10.15252/msb.20156651,4376082732262141203,/scholar?cites=4376082732262141203,,,https://www.embopress.org/doi/pdf/10.15252/msb.20156651,0,0,0
1282666,Single-cell genome-wide bisulfite sequencing for assessing epigenetic heterogeneity,2014,Sébastien A Smallwood and Heather J Lee and Christof Angermueller and Felix Krueger and Heba Saadeh and Julian Peat and Simon R Andrews and Oliver Stegle and Wolf Reik and Gavin Kelsey,11,Nature methods,8,817-820,Nature Publishing Group,We report a single-cell bisulfite sequencing (scBS-seq) method that can be used to accurately measure DNA methylation at up to 48.4% of CpG sites. Embryonic stem cells grown in serum or in 2i medium displayed epigenetic heterogeneity. with'2i-like'cells present in serum culture. Integration of 12 individual mouse oocyte datasets largely recapitulated the whole DNA methylome. which makes scBS-seq a versatile tool to explore DNA methylation in rare cells and heterogeneous populations.,True,OXZC0mQAAAAJ:XiSMed-E-HIC,699,https://www.nature.com/articles/nmeth.3035,11786932185569474087,/scholar?cites=11786932185569474087,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4117646/,0,0,0
1282667,Theano: A Python framework for fast computation of mathematical expressions,2016,Rami Al-Rfou and Guillaume Alain and Amjad Almahairi and Christof Angermueller and Dzmitry Bahdanau and Nicolas Ballas and Frédéric Bastien and Justin Bayer and Anatoly Belikov and Alexander Belopolsky and Yoshua Bengio and Arnaud Bergeron and James Bergstra and Valentin Bisson and Josh Bleecher Snyder and Nicolas Bouchard and Nicolas Boulanger-Lewandowski and Xavier Bouthillier and Alexandre de Brébisson and Olivier Breuleux and Pierre-Luc Carrier and Kyunghyun Cho and Jan Chorowski and Paul Christiano and Tim Cooijmans and Marc-Alexandre Côté and Myriam Côté and Aaron Courville and Yann N Dauphin and Olivier Delalleau and Julien Demouth and Guillaume Desjardins and Sander Dieleman and Laurent Dinh and Melanie Ducoffe and Vincent Dumoulin and Samira Ebrahimi Kahou and Dumitru Erhan and Ziye Fan and Orhan Firat and Mathieu Germain and Xavier Glorot and Ian Goodfellow and Matt Graham and Caglar Gulcehre and Philippe Hamel and Iban Harlouchet and Jean-Philippe Heng and Balázs Hidasi and Sina Honari and Arjun Jain and Sébastien Jean and Kai Jia and Mikhail Korobov and Vivek Kulkarni and Alex Lamb and Pascal Lamblin and Eric Larsen and César Laurent and Sean Lee and Simon Lefrançois and Simon Lemieux and Nicholas Léonard and Zhouhan Lin and Jesse A Livezey and Cory Lorenz and Jeremiah Lowin and Qianli Ma and Pierre-Antoine Manzagol and Olivier Mastropietro and Robert T McGibbon and Roland Memisevic and Bart van Merriënboer and Vincent Michalski and Mehdi Mirza and Alberto Orlandi and Christopher Pal and Razvan Pascanu and Mohammad Pezeshki and Colin Raffel and Daniel Renshaw and Matthew Rocklin and Adriana Romero and Markus Roth and Peter Sadowski and John Salvatier and François Savard and Jan Schlüter and John Schulman and Gabriel Schwartz and Iulian Vlad Serban and Dmitriy Serdyuk and Samira Shabanian and Étienne Simon and Sigurd Spieckermann and S Ramana Subramanyam and Jakub Sygnowski and Jérémie Tanguay and Gijs van Tulder and Joseph Turian and Sebastian Urban and Pascal Vincent and Francesco Visin and Harm de Vries and David Warde-Farley and Dustin J Webb and Matthew Willson and Kelvin Xu and Lijun Xue and Li Yao and Saizheng Zhang and Ying Zhang,,arXiv e-prints,,arXiv: 1605.02688,,Theano is a Python library that allows to define. optimize. and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction. it has been one of the most used CPU and GPU mathematical compilers-especially in the machine learning community-and has shown steady performance improvements. Theano is being actively and continuously developed since 2008. multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them. and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and …,True,OXZC0mQAAAAJ:eMMeJKvmdy0C,628,https://ui.adsabs.harvard.edu/abs/2016arXiv160502688T/abstract,3168617625725328375,/scholar?cites=3168617625725328375,,,https://www.researchgate.net/profile/Dumitru-Erhan/publication/302569301_Theano_A_Python_framework_for_fast_computation_of_mathematical_expressions/links/57335bc808ae298602dce993/Theano-A-Python-framework-for-fast-computation-of-mathematical-expressions.pdf,0,0,0
1282668,Parallel single-cell sequencing links transcriptional and epigenetic heterogeneity,2016,Christof Angermueller and Stephen J Clark and Heather J Lee and Iain C Macaulay and Mabel J Teng and Tim Xiaoming Hu and Felix Krueger and Sébastien A Smallwood and Chris P Ponting and Thierry Voet and Gavin Kelsey and Oliver Stegle and Wolf Reik,13,Nature methods,3,229-232,Nature Publishing Group,We report scM&T-seq. a method for parallel single-cell genome-wide methylome and transcriptome sequencing that allows for the discovery of associations between transcriptional and epigenetic variation. Profiling of 61 mouse embryonic stem cells confirmed known links between DNA methylation and transcription. Notably. the method revealed previously unrecognized associations between heterogeneously methylated distal regulatory elements and transcription of key pluripotency genes.,True,OXZC0mQAAAAJ:eflP2zaiRacC,406,https://www.nature.com/articles/nmeth.3728,4598729258923625454,/scholar?cites=4598729258923625454,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4770512/,0,0,0
1282669,DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning,2017,Christof Angermueller and Heather J Lee and Wolf Reik and Oliver Stegle,18,Genome biology,1,1-13,BioMed Central,Recent technological advances have enabled DNA methylation to be assayed at single-cell resolution. However. current protocols are limited by incomplete CpG coverage and hence methods to predict missing methylation states are critical to enable genome-wide analyses. We report DeepCpG. a computational approach based on deep neural networks to predict methylation states in single cells. We evaluate DeepCpG on single-cell methylation data from five cell types generated using alternative sequencing protocols. DeepCpG yields substantially more accurate predictions than previous methods. Additionally. we show that the model parameters can be interpreted. thereby providing insights into how sequence composition affects methylation variability.,True,OXZC0mQAAAAJ:5ugPr518TE4C,275,https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1189-z,6182152825771296083,/scholar?cites=6182152825771296083,,,https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1189-z,0,0,0
1282670,The Mre11: Rad50 structure shows an ATP-dependent molecular clamp in DNA double-strand break repair,2011,Katja Lammens and Derk J Bemeleit and Carolin Möckel and Emanuel Clausing and Alexandra Schele and Sophia Hartung and Christian B Schiller and Maria Lucas and Christof Angermüller and Johannes Söding and Katja Sträßer and Karl-Peter Hopfner,145,Cell,1,54-66,Cell Press,The MR (Mre11 nuclease and Rad50 ABC ATPase) complex is an evolutionarily conserved sensor for DNA double-strand breaks. highly genotoxic lesions linked to cancer development. MR can recognize and process DNA ends even if they are blocked and misfolded. To reveal its mechanism. we determined the crystal structure of the catalytic head of Thermotoga maritima MR and analyzed ATP-dependent conformational changes. MR adopts an open form with a central Mre11 nuclease dimer and two peripheral Rad50 molecules. a form suited for sensing obstructed breaks. The Mre11 C-terminal helix-loop-helix domain binds Rad50 and attaches flexibly to the nuclease domain. enabling large conformational changes. ATP binding to the two Rad50 subunits induces a rotation of the Mre11 helix-loop-helix and Rad50 coiled-coil domains. creating a clamp conformation with increased DNA-binding activity. The …,True,OXZC0mQAAAAJ:u5HHmVD_uO8C,190,https://www.sciencedirect.com/science/article/pii/S0092867411001905,17350107404639617764,/scholar?cites=17350107404639617764,,,https://www.sciencedirect.com/science/article/pii/S0092867411001905,0,0,0
1282671,Feature ranking of type 1 diabetes susceptibility genes improves prediction of type 1 diabetes,2014,Christiane Winkler and Jan Krumsiek and Florian Buettner and Christof Angermüller and Eleni Z Giannopoulou and Fabian J Theis and Anette-Gabriele Ziegler and Ezio Bonifacio,57,Diabetologia,12,2521-2529,Springer Berlin Heidelberg,More than 40 regions of the human genome confer susceptibility for type 1 diabetes and could be used to establish population screening strategies. The aim of our study was to identify weighted sets of SNP combinations for type 1 diabetes prediction.We applied multivariable logistic regression and Bayesian feature selection to the Type 1 Diabetes Genetics Consortium (T1DGC) dataset with genotyping of HLA plus 40 SNPs within other type 1 diabetes-associated gene regions in 4.574 cases and 1.207 controls. We tested the weighted models in an independent validation set (765 cases. 423 controls). and assessed their performance in 1.772 prospectively followed children.The inclusion of 40 non-HLA gene SNPs significantly improved the prediction of type 1 diabetes over that …,True,OXZC0mQAAAAJ:Tiz5es2fbqcC,101,https://link.springer.com/article/10.1007/s00125-014-3362-1,15312429674944710804,/scholar?cites=15312429674944710804,,,https://link.springer.com/article/10.1007/s00125-014-3362-1,0,0,0
1282672,Deep learning for predicting refractive error from retinal fundus images,2018,Avinash V Varadarajan and Ryan Poplin and Katy Blumer and Christof Angermueller and Joe Ledsam and Reena Chopra and Pearse A Keane and Greg S Corrado and Lily Peng and Dale R Webster,59,Investigative ophthalmology & visual science,7,2861-2868,The Association for Research in Vision and Ophthalmology,Purpose: We evaluate how deep learning can be applied to extract novel information such as refractive error from retinal fundus imaging.Methods: Retinal fundus images used in this study were 45-and 30-degree field of view images from the UK Biobank and Age-Related Eye Disease Study (AREDS) clinical trials. respectively. Refractive error was measured by autorefraction in UK Biobank and subjective refraction in AREDS. We trained a deep learning algorithm to predict refractive error from a total of 226.870 images and validated it on 24.007 UK Biobank and 15.750 AREDS images. Our model used the “attention” method to identify features that are correlated with refractive error.Results: The resulting algorithm had a mean absolute error (MAE) of 0.56 diopters (95% confidence interval [CI]: 0.55–0.56) for estimating spherical equivalent on the UK Biobank data set and 0.91 diopters (95% CI: 0.89–0.93) for the AREDS data set. The baseline expected MAE (obtained by simply predicting the mean of this population) was 1.81 diopters (95% CI: 1.79–1.84) for UK Biobank and 1.63 (95% CI: 1.60–1.67) for AREDS. Attention maps suggested that the foveal region was one of the most important areas used by the algorithm to make this prediction. though other regions also contribute to the prediction.Conclusions: To our knowledge. the ability to estimate refractive error with high accuracy from retinal fundus photos has not been previously known and demonstrates that deep learning can be applied to make novel predictions from medical images.,True,OXZC0mQAAAAJ:tkaPQYYpVKoC,57,https://iovs.arvojournals.org/article.aspx?articleid=2683803,8181111095088533981,/scholar?cites=8181111095088533981,,,https://iovs.arvojournals.org/article.aspx?articleid=2683803,0,0,0
1282673,Discriminative modelling of context-specific amino acid substitution probabilities,2012,Christof Angermüller and Andreas Biegert and Johannes Söding,28,Bioinformatics,24,3240-3247,Oxford University Press, Motivation: Protein sequence searching and alignment are fundamental tools of modern biology. Alignments are assessed using their similarity scores. essentially the sum of substitution matrix scores over all pairs of aligned amino acids. We previously proposed a generative probabilistic method that yields scores that take the sequence context around each aligned residue into account. This method showed drastically improved sensitivity and alignment quality compared with standard substitution matrix-based alignment. Results: Here. we develop an alternative discriminative approach to predict sequence context-specific substitution scores. We applied our approach to compute context-specific sequence profiles for Basic Local Alignment Search Tool (BLAST) and compared the new tool (CS-BLASTdis) to BLAST and the previous context-specific version (CS-BLASTgen). On a dataset filtered …,True,OXZC0mQAAAAJ:u-x6o8ySG0sC,52,https://academic.oup.com/bioinformatics/article-abstract/28/24/3240/247865,14314581394569778672,/scholar?cites=14314581394569778672,,,https://academic.oup.com/bioinformatics/article/28/24/3240/247865,0,0,0
1282674,Genome-scale oscillations in DNA methylation during exit from pluripotency,2018,Steffen Rulands and Heather J Lee and Stephen J Clark and Christof Angermueller and Sébastien A Smallwood and Felix Krueger and Hisham Mohammed and Wendy Dean and Jennifer Nichols and Peter Rugg-Gunn and Gavin Kelsey and Oliver Stegle and Benjamin D Simons and Wolf Reik,7,Cell systems,1,63-76. e12,Cell Press,Pluripotency is accompanied by the erasure of parental epigenetic memory. with naïve pluripotent cells exhibiting global DNA hypomethylation both in vitro and in vivo. Exit from pluripotency and priming for differentiation into somatic lineages is associated with genome-wide de novo DNA methylation. We show that during this phase. co-expression of enzymes required for DNA methylation turnover. DNMT3s and TETs. promotes cell-to-cell variability in this epigenetic mark. Using a combination of single-cell sequencing and quantitative biophysical modeling. we show that this variability is associated with coherent. genome-scale oscillations in DNA methylation with an amplitude dependent on CpG density. Analysis of parallel single-cell transcriptional and epigenetic profiling provides evidence for oscillatory dynamics both in vitro and in vivo. These observations provide insights into the emergence of epigenetic …,True,OXZC0mQAAAAJ:AXPGKjj_ei8C,45,https://www.sciencedirect.com/science/article/pii/S2405471218302795,2582355374835173131,/scholar?cites=2582355374835173131,,,https://www.sciencedirect.com/science/article/pii/S2405471218302795,0,0,0
1282675,Cloud prediction of protein structure and function with PredictProtein for Debian,2013,László Kaján and Guy Yachdav and Esmeralda Vicedo and Martin Steinegger and Milot Mirdita and Christof Angermüller and Ariane Böhm and Simon Domke and Julia Ertl and Christian Mertes and Eva Reisinger and Cedric Staniewski and Burkhard Rost,2013,BioMed Research International,,,Hindawi,We report the release of PredictProtein for the Debian operating system and derivatives. such as Ubuntu. Bio-Linux. and Cloud BioLinux. The PredictProtein suite is available as a standard set of open source Debian packages. The release covers the most popular prediction methods from the Rost Lab. including methods for the prediction of secondary structure and solvent accessibility (profphd). nuclear localization signals (predictnls). and intrinsically disordered regions (norsnet). We also present two case studies that successfully utilize PredictProtein packages for high performance computing in the cloud: the first analyzes protein disorder for whole organisms. and the second analyzes the effect of all possible single sequence variants in protein coding regions of the human genome.,True,OXZC0mQAAAAJ:d1gkVwhDpl0C,23,https://www.hindawi.com/journals/bmri/2013/398968/abs/,8128782985148483687,/scholar?cites=8128782985148483687,,,https://www.hindawi.com/journals/bmri/2013/398968/abs/,0,0,0
1282676,Long short term memory networks for anomaly detection in time series,2015,Pankaj Malhotra and Lovekesh Vig and Gautam Shroff and Puneet Agarwal,89,Proceedings,,89-94,Presses universitaires de Louvain,Long Short Term Memory (LSTM) networks have been demonstrated to be particularly useful for learning sequences containing longer term patterns of unknown length. due to their ability to maintain long term memory. Stacking recurrent hidden layers in such networks also enables the learning of higher level temporal features. for faster learning with sparser representations. In this paper. we use stacked LSTM networks for anomaly/fault detection in time series. A network is trained on non-anomalous data and used as a predictor over a number of time steps. The resulting prediction errors are modeled as a multivariate Gaussian distribution. which is used to assess the likelihood of anomalous behavior. The efficacy of this approach is demonstrated on four datasets: ECG. space shuttle. power demand. and multi-sensor engine dataset.,True,f70Rc2wAAAAJ:SnGPuo6Feq8C,801,http://books.google.com/books?hl=en&lr=&id=USGLCgAAQBAJ&oi=fnd&pg=PA89&dq=info:b84tChj_s-AJ:scholar.google.com&ots=Fte8fqHXPK&sig=cBnriyKbqwU32G9msO1Q2CP5-n0,16191565564042137199,/scholar?cites=16191565564042137199,,,https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf,0,0,0
1282677,LSTM-based encoder-decoder for multi-sensor anomaly detection,2016,Pankaj Malhotra and Anusha Ramakrishnan and Gaurangi Anand and Lovekesh Vig and Puneet Agarwal and Gautam Shroff,,arXiv preprint arXiv:1607.00148,,,,Mechanical devices such as engines. vehicles. aircrafts. etc.. are typically instrumented with numerous sensors to capture the behavior and health of the machine. However. there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance. manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity. or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct'normal'time-series behavior. and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand. space shuttle. and ECG. and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable. unpredictable. periodic. aperiodic. and quasi-periodic time-series. Further. we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).,True,f70Rc2wAAAAJ:sA9dB-pw3HoC,381,https://arxiv.org/abs/1607.00148,17745057306182411306,/scholar?cites=17745057306182411306,,,https://arxiv.org/pdf/1607.00148,0,0,0
1282678,Stabilization of unstable procedures: the recursive projection method,1993,Gautam M Shroff and Herbert B Keller,30,SIAM Journal on numerical analysis,4,1099-1120,Society for Industrial and Applied Mathematics,Fixed-point iterative procedures for solving nonlinear parameter dependent problems can converge for some interval of parameter values and diverge as the parameter changes. The Recursive Projection Method (RPM). which stabilizes such procedures by computing a projection onto the unstable subspace is presented. On this subspace a Newton or special Newton iteration is performed. and the fixed-point iteration is used on the complement. As continuation in the parameter proceeds. the projection is efficiently updated. possibly increasing or decreasing the dimension of the unstable subspace. The method is extremely effective when the dimension of the unstable subspace is small compared to the dimension of the system. Convergence proofs are given and pseudo-arclength continuation on the unstable subspace is introduced to allow continuation past folds. Examples are presented for an important …,True,f70Rc2wAAAAJ:u5HHmVD_uO8C,306,https://epubs.siam.org/doi/abs/10.1137/0730057,4567869693925437696,/scholar?cites=4567869693925437696,,,https://authors.library.caltech.edu/29630/1/SHROsiamjna93.pdf,0,0,0
1282679,On updating signal subspaces,1992,Christian H Bischof and Gautam M Shroff,40,IEEE Transactions on Signal Processing,1,96-105,IEEE,The authors develop an algorithm for adaptively estimating the noise subspace of a data matrix. as is required in signal processing applications employing the 'signal subspace' approach. The noise subspace is estimated using a rank-revealing QR factorization instead of the more expensive singular value or eigenvalue decompositions. Using incremental condition estimation to monitor the smallest singular values of triangular matrices. the authors can update the rank-revealing triangular factorization inexpensively when new rows are added and old rows are deleted. Experiments demonstrate that the new approach usually requires O(n/sup 2/) work to update an n*n matrix. and that it accurately tracks the noise subspace.< >,True,f70Rc2wAAAAJ:u-x6o8ySG0sC,141,https://ieeexplore.ieee.org/abstract/document/157185/,9087785190093704573,/scholar?cites=9087785190093704573,,,,0,0,0
1282680,Enterprise cloud computing: technology. architecture. applications,2010,Gautam Shroff,,,,,Cambridge university press,Cloud computing promises to revolutionize IT and business by making computing available as a utility over the internet. This book is intended primarily for practising software architects who need to assess the impact of such a transformation. It explains the evolution of the internet into a cloud computing platform. describes emerging development paradigms and technologies. and discusses how these will change the way enterprise applications should be architected for cloud deployment. Gautam Shroff provides a technical description of cloud computing technologies. covering cloud infrastructure and platform services. programming paradigms such as MapReduce. as well as' do-it-yourself'hosted development tools. He also describes emerging technologies critical to cloud computing. The book also covers the fundamentals of enterprise computing. including a technical introduction to enterprise architecture. so it will interest programmers aspiring to become software architects and serve as a reference for a graduate-level course in software architecture or software engineering.,True,f70Rc2wAAAAJ:8k81kl-MbHgC,134,http://books.google.com/books?hl=en&lr=&id=18gi4bXZ044C&oi=fnd&pg=PR5&dq=info:QeNqt9KYuWkJ:scholar.google.com&ots=5-roluNpIZ&sig=iHISwWnuBHYQHRD2u5oEdo1bQQE,7618288275461694273,/scholar?cites=7618288275461694273,,,,0,0,0
1282681,Multi-sensor prognostics using an unsupervised health index based on LSTM encoder-decoder,2016,Pankaj Malhotra and Vishnu TV and Anusha Ramakrishnan and Gaurangi Anand and Lovekesh Vig and Puneet Agarwal and Gautam Shroff,,arXiv preprint arXiv:1608.06154,,,,Many approaches for estimation of Remaining Useful Life (RUL) of a machine. using its operational sensor data. make assumptions about how a system degrades or a fault evolves. eg. exponential degradation. However. in many domains degradation may not follow a pattern. We propose a Long Short Term Memory based Encoder-Decoder (LSTM-ED) scheme to obtain an unsupervised health index (HI) for a system using multi-sensor time-series data. LSTM-ED is trained to reconstruct the time-series corresponding to healthy state of a system. The reconstruction error is used to compute HI which is then used for RUL estimation. We evaluate our approach on publicly available Turbofan Engine and Milling Machine datasets. We also present results on a real-world industry dataset from a pulverizer mill where we find significant correlation between LSTM-ED based HI and maintenance costs.,True,f70Rc2wAAAAJ:CYCckWUYoCcC,122,https://arxiv.org/abs/1608.06154,17912227605024151891,/scholar?cites=17912227605024151891,,,https://arxiv.org/pdf/1608.06154,0,0,0
1282682,Acquiring competitive intelligence from social media,2011,Lipika Dey and Sk Mirajul Haque and Arpit Khurdiya and Gautam Shroff,,,,1-9,,Competitive intelligence is the art of defining. gathering and analyzing intelligence about competitor's products. promotions. sales etc. from external sources. The Web comes across as an important source for gathering competitive intelligence. News. blogs. as well as social media not only provide competitors information but also provide direct comparison of customer behaviors with respect to different verticals among competing organizations. This paper discusses methodologies to obtain competitive intelligence from different types of web resources including social media using a wide array of text mining techniques. It provides some results from case-studies to show how the gathered information can be integrated with structured data and used to explain business facts and thereby adopted for future decision making.,True,f70Rc2wAAAAJ:Zph67rFs4hoC,90,https://dl.acm.org/doi/abs/10.1145/2034617.2034621,6598976538557889715,/scholar?cites=6598976538557889715,,,https://www.researchgate.net/profile/Lipika_Dey2/publication/254007149_Acquiring_competitive_intelligence_from_social_media/links/56ebde5108ae24f050990895.pdf,0,0,0
1282683,Predicting remaining useful life using time series embeddings based on recurrent neural networks,2017,Narendhar Gugulothu and Vishnu Tv and Pankaj Malhotra and Lovekesh Vig and Puneet Agarwal and Gautam Shroff,,arXiv preprint arXiv:1709.01073,,,,We consider the problem of estimating the remaining useful life (RUL) of a system or a machine from sensor data. Many approaches for RUL estimation based on sensor data make assumptions about how machines degrade. Additionally. sensor data from machines is noisy and often suffers from missing values in many practical settings. We propose Embed-RUL: a novel approach for RUL estimation from sensor data that does not rely on any degradation-trend assumptions. is robust to noise. and handles missing values. Embed-RUL utilizes a sequence-to-sequence model based on Recurrent Neural Networks (RNNs) to generate embeddings for multivariate time series subsequences. The embeddings for normal and degraded machines tend to be different. and are therefore found to be useful for RUL estimation. We show that the embeddings capture the overall pattern in the time series while filtering out the noise. so that the embeddings of two machines with similar operational behavior are close to each other. even when their sensor readings have significant and varying levels of noise content. We perform experiments on publicly available turbofan engine dataset and a proprietary real-world dataset. and demonstrate that Embed-RUL outperforms the previously reported state-of-the-art on several metrics.,True,f70Rc2wAAAAJ:AYInfyleIOsC,81,https://arxiv.org/abs/1709.01073,15296157550289521003,/scholar?cites=15296157550289521003,,,https://arxiv.org/pdf/1709.01073,0,0,0
1282684,Catching the long-tail: Extracting local news events from twitter,2012,Puneet Agarwal and Rajgopal Vaithiyanathan and Saurabh Sharma and Gautam Shroff,6,Proceedings of The International AAAI Conference on Web and Social Media,1,,,Twitter. used in 200 countries with over 250 milliontweets a day. is a rich source of local news from aroundthe world. Many events of local importance are first reportedon Twitter. including many that never reach newschannels. Further. there are often only a few tweetsreporting each such event. in contrast with the largervolumes that follow events of wider significance. Eventhough such events may be primarily of local importance. they can also be of critical interest to some specificbut possibly far flung entities: For example. a firein a supplier’s factory half-way around the world maybe of interest even from afar. In this paper we describehow this ‘long tail’of events can be detected in spite oftheir sparsity. We then extract and correlate informationfrom multiple tweets describing the same event. Ourgeneric architecture for converting a tweet-stream intoevent-objects uses locality sensitive hashing. classification. boosting. information extraction and clustering. Our results. based on millions of tweets monitored overmany months. appear to validate our approach and architecture: We achieved success-rates in the 80% rangefor event detection and 76% on event-correlation; we also reduced tweet-comparisons by 80% using LSH.,True,f70Rc2wAAAAJ:mVmsd5A6BfQC,76,https://ojs.aaai.org/index.php/ICWSM/article/view/14317,10051640691240818273,/scholar?cites=10051640691240818273,,,https://ojs.aaai.org/index.php/ICWSM/article/download/14317/14166,0,0,0
1282685,TimeNet: Pre-trained deep recurrent neural network for time series classification,2017,Pankaj Malhotra and Vishnu TV and Lovekesh Vig and Puneet Agarwal and Gautam Shroff,,arXiv preprint arXiv:1706.08838,,,,Inspired by the tremendous success of deep Convolutional Neural Networks as generic feature extractors for images. we propose TimeNet: a deep recurrent neural network (RNN) trained on diverse time series in an unsupervised manner using sequence to sequence (seq2seq) models to extract features from time series. Rather than relying on data from the problem domain. TimeNet attempts to generalize time series representation across domains by ingesting time series from several domains simultaneously. Once trained. TimeNet can be used as a generic off-the-shelf feature extractor for time series. The representations or embeddings given by a pre-trained TimeNet are found to be useful for time series classification (TSC). For several publicly available datasets from UCR TSC Archive and an industrial telematics sensor data from vehicles. we observe that a classifier learned over the TimeNet embeddings yields significantly better performance compared to (i) a classifier learned over the embeddings given by a domain-specific RNN. as well as (ii) a nearest neighbor classifier based on Dynamic Time Warping.,True,f70Rc2wAAAAJ:2ywjKiB__4kC,71,https://arxiv.org/abs/1706.08838,14760911145081953,/scholar?cites=14760911145081953,,,https://arxiv.org/pdf/1706.08838,0,0,0
1282686,On the convergence of the cyclic Jacobi method for parallel block orderings,1989,Gautam Shroff and Robert Schreiber,10,SIAM journal on matrix analysis and applications,3,326-346,Society for Industrial and Applied Mathematics,Convergence of the cyclic Jacobi method for diagonalizing a symmetric matrix has never been  conclusively settled. Forsythe and Henrici [Trans. Amer. Math. Soc.. 94(1960). pp. 1–23] proved convergence for a cyclic by rows ordering. Here orderings are investigated that can be obtained from the cyclic by rows ordering through convergence preserving combinatorial transformations. First the class of “cyclic wavefront” orderings is introduced and it is shown that the class consists of exactly those orderings that are “equivalent” to the cyclic by rows ordering. It is also shown that certain block Jacobi methods are cyclic wavefront orderings when viewed as cyclic Jacobi methods. While discussing convergence proofs for parallel implementations of Jacobi methods and block Jacobi methods. the notions of “weak equivalence” and “P-equivalence” of Jacobi orderings is developed. Next the class of “P-wavefront” orderings …,True,f70Rc2wAAAAJ:d1gkVwhDpl0C,71,https://epubs.siam.org/doi/abs/10.1137/0610025,9031190087961226999,/scholar?cites=9031190087961226999,,,https://www.researchgate.net/profile/Robert_Schreiber2/publication/247033016_On_the_Convergence_of_the_Cyclic_Jacobi_Method_for_Parallel_Block_Orderings/links/57069abd08aea3d28021194b.pdf,0,0,0
1282687,Pose primitive based human action recognition in videos or still images,2008,Christian Thurau and Václav Hlavác,,,,1-8,IEEE,This paper presents a method for recognizing human actions based on pose primitives. In learning mode. the parameters representing poses and activities are estimated from videos. In run mode. the method can be used both for videos or still images. For recognizing pose primitives. we extend a Histogram of Oriented Gradient (HOG) based descriptor to better cope with articulated poses and cluttered background. Action classes are represented by histograms of poses primitives. For sequences. we incorporate the local temporal context by means of n-gram expressions. Action recognition is based on a simple histogram comparison. Unlike the mainstream video surveillance approaches. the proposed method does not rely on background subtraction or dynamic features and thus allows for action recognition in still images.,True,WDHoQtYAAAAJ:u5HHmVD_uO8C,380,https://ieeexplore.ieee.org/abstract/document/4587721/,9076771539816362730,/scholar?cites=9076771539816362730,,,ftp://147.32.84.2/pub/cmp/articles/hlavac/Thurau-HlavacPosePrimitivesCVPR2008.pdf,0,0,0
1282688,"The"" something something"" video database for learning and evaluating visual common sense",2017,Raghav Goyal and Samira Ebrahimi Kahou and Vincent Michalski and Joanna Materzynska and Susanne Westphal and Heuna Kim and Valentin Haenel and Ingo Fruend and Peter Yianilos and Moritz Mueller-Freitag and Florian Hoppe and Christian Thurau and Ingo Bax and Roland Memisevic,,,,5842-5850,,"Neural networks trained on datasets such as ImageNet have led to major advances in visual object classification. One obstacle that prevents networks from reasoning more deeply about complex scenes and situations. and from integrating visual knowledge with natural language. like humans do. is their lack of common sense knowledge about the physical world. Videos. unlike still images. contain a wealth of detailed information about the physical world. However. most labelled video datasets represent high-level concepts rather than detailed physical aspects about actions and scenes. In this work. we describe our ongoing collection of the"" something-something"" database of video prediction tasks whose solutions require a common sense understanding of the depicted situation. The database currently contains more than 100.000 videos across 174 classes. which are defined as caption-templates. We also describe the challenges in crowd-sourcing this data at scale.",True,WDHoQtYAAAAJ:NMxIlDl6LWMC,314,http://openaccess.thecvf.com/content_iccv_2017/html/Goyal_The_Something_Something_ICCV_2017_paper.html,7727520095601508370,/scholar?cites=7727520095601508370,,,http://openaccess.thecvf.com/content_ICCV_2017/papers/Goyal_The_Something_Something_ICCV_2017_paper.pdf,0,0,0
1282689,Guns. swords and data: Clustering of player behavior in computer games in the wild,2012,Anders Drachen and Rafet Sifa and Christian Bauckhage and Christian Thurau,,,,163-170,IEEE,Behavioral data from computer games can be exceptionally high-dimensional. of massive scale and cover a temporal segment reaching years of real-time and a varying population of users. Clustering of user behavior provides a way to discover behavioral patterns that are actionable for game developers. Interpretability and reliability of clustering results is vital. as decisions based on them affect game design and thus ultimately revenue. Here case studies are presented focusing on clustering analysis applied to high-dimensionality player behavior telemetry. covering a combined total of 260.000 characters from two major commercial game titles: the Massively Multiplayer Online Role-Playing Game Tera and the multi-player strategy war game Battlefield 2: Bad Company 2. K-means and Simplex Volume Maximization clustering were applied to the two datasets. combined with considerations of the design of the …,True,WDHoQtYAAAAJ:UebtZRa9Y70C,180,https://ieeexplore.ieee.org/abstract/document/6374152/,4553111023536909489,/scholar?cites=4553111023536909489,,,http://geneura.ugr.es/cig2012/papers/paper87.pdf,0,0,0
1282690,Predicting player churn in the wild,2014,Fabian Hadiji and Rafet Sifa and Anders Drachen and Christian Thurau and Kristian Kersting and Christian Bauckhage,,,,1-8,Ieee,Free-to-Play or “freemium” games represent a fundamental shift in the business models of the game industry. facilitated by the increasing use of online distribution platforms and the introduction of increasingly powerful mobile platforms. The ability of a game development company to analyze and derive insights from behavioral telemetry is crucial to the success of these games which rely on in-game purchases and in-game advertising to generate revenue. and for the company to remain competitive in a global marketplace. The ability to model. understand and predict future player behavior has a crucial value. allowing developers to obtain data-driven insights to inform design. development and marketing strategies. One of the key challenges is modeling and predicting player churn. This paper presents the first cross-game study of churn prediction in Free-to-Play games. Churn in games is discussed and thoroughly …,True,WDHoQtYAAAAJ:r0BpntZqJG4C,153,https://ieeexplore.ieee.org/abstract/document/6932876/,9587491428263191762,/scholar?cites=9587491428263191762,,,http://storage.kghost.de/cig_proc/full/paper_46.pdf,0,0,0
1282691,Early drought stress detection in cereals: simplex volume maximisation for hyperspectral image analysis,2012,Christoph Römer and Mirwaes Wahabzada and Agim Ballvora and Francisco Pinto and Micol Rossini and Cinzia Panigada and Jan Behmann and Jens Léon and Christian Thurau and Christian Bauckhage and Kristian Kersting and Uwe Rascher and Lutz Plümer,39,Functional Plant Biology,11,878-890,CSIRO PUBLISHING,Early water stress recognition is of great relevance in precision plant breeding and production. Hyperspectral imaging sensors can be a valuable tool for early stress detection with high spatio-temporal resolution. They gather large. high dimensional data cubes posing a significant challenge to data analysis. Classical supervised learning algorithms often fail in applied plant sciences due to their need of labelled datasets. which are difficult to obtain. Therefore. new approaches for unsupervised learning of relevant patterns are needed. We apply for the first time a recent matrix factorisation technique. simplex volume maximisation (SiVM). to hyperspectral data. It is an unsupervised classification approach. optimised for fast computation of massive datasets. It allows calculation of how similar each spectrum is to observed typical spectra. This provides the means to express how likely it is that one plant is suffering from …,True,WDHoQtYAAAAJ:_kc_bZDykSQC,129,http://www.publish.csiro.au/fp/FP12060,11253662640599241780,/scholar?cites=11253662640599241780,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.6157&rep=rep1&type=pdf,0,0,0
1282692,Learning human-like movement behavior for computer games,2004,Christian Thurau and Christian Bauckhage and Gerhard Sagerer,,Proc. Int. Conf. on the Simulation of Adaptive Behavior,,315-323,,Modern Computer Game AI still relies on rulebased approaches. so far failing to develop a convincing. human-like opponent. Towards the development of more human-like computer game agents. we propose an approach for learning strategies by observation of human players. principally viewing the design of a computer game agent as a problem of pattern recognition. First we introduce a Neural Gas based grid learning of an internal representation of the 3D game-world. Then we discuss the use of a learn-ing potential fields approach. establishing a mapping from world state vectors to corresponding potential field forces for agent guidance. The training data being used is acquired by observation of human players acting in the 3D game environment of a commercial computer game. Finally. some experiments are presented. research directions in Game Al. Nevertheless. up to now there has been little effort in applying techniques from pattern recognition or machine learning. While learning movement primitives for humanoid robots (Schaal et al.. 2004) or implementations of autonomous behavior for simulated worlds,True,WDHoQtYAAAAJ:u-x6o8ySG0sC,125,http://books.google.com/books?hl=en&lr=&id=KtH3hF1-ZtEC&oi=fnd&pg=PA315&dq=info:fH0Hu1oWeUcJ:scholar.google.com&ots=4uc_5Efv6n&sig=UDTD0OK9Hl9ce9VxlAFzdvJZ0xc,5150172227815570812,/scholar?cites=5150172227815570812,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.551.2301&rep=rep1&type=pdf,0,0,0
1282693,Action recognition by learning discriminative key poses,2011,Shahzad Cheema and Abdalrahman Eweiwi and Christian Thurau and Christian Bauckhage,,,,1302-1309,IEEE,This paper proposes a novel approach to pose-based human action recognition. Given a set of training images. we first extract a scale invariant contour-based pose feature from silhouettes. Then. we cluster the features in order to build a set of prototypical key poses. Based on their relative discriminative power for action recognition. we learn weights that favor distinctive key poses. Finally. classification of a novel action sequence is based on a simple and efficient weighted voting scheme that augments results with a confidence value which indicates recognition uncertainty. Our approach does not require temporal information and is applicable for action recognition from videos or still images. It is efficient and delivers real-time performance. In experimental evaluations for single-view action recognition and the multi-view MuHAVi data set. it shows high recognition accuracy.,True,WDHoQtYAAAAJ:hqOjcs7Dif8C,98,https://ieeexplore.ieee.org/abstract/document/6130402/,9658238742915250435,/scholar?cites=9658238742915250435,,,https://www.researchgate.net/profile/Muhammad_Shahzad_Cheema/publication/221429876_Action_recognition_by_learning_discriminative_key_poses/links/0deec51e9ce68cb074000000/Action-recognition-by-learning-discriminative-key-poses.pdf,0,0,0
1282694,How players lose interest in playing a game: An empirical study based on distributions of total playing times,2012,Christian Bauckhage and Kristian Kersting and Rafet Sifa and Christian Thurau and Anders Drachen and Alessandro Canossa,,,,139-146,IEEE,Analyzing telemetry data of player behavior in computer games is a topic of increasing interest for industry and research. alike. When applied to game telemetry data. pattern recognition and statistical analysis provide valuable business intelligence tools for game development. An important problem in this area is to characterize how player engagement in a game evolves over time. Reliable models are of pivotal interest since they allow for assessing the long-term success of game products and can provide estimates of how long players may be expected to keep actively playing a game. In this paper. we introduce methods from random process theory into game data mining in order to draw inferences about player engagement. Given large samples (over 250.000 players) of behavioral telemetry data from five different action-adventure and shooter games. we extract information as to how long individual players have …,True,WDHoQtYAAAAJ:Se3iqnhoufwC,97,https://ieeexplore.ieee.org/abstract/document/6374148/,12573378769701269376,/scholar?cites=12573378769701269376,,,http://geneura.ugr.es/cig2012/papers/paper17.pdf,0,0,0
1282695,Non-negative matrix factorization in multimodality data for segmentation and label prediction,2011,Zeynep Akata and Christian Thurau and Christian Bauckhage,,,,,,With the increasing availability of annotated multimedia data on the Internet. techniques are in demand that allow for a principled joint processing of different types of data. Multiview learning and multiview clustering attempt to identify latent components in different features spaces in a simultaneous manner. The resulting basis vectors or centroids faithfully represent the different views on the data but are implicitly coupled and they were jointly estimated. This opens new avenues to problems such as label prediction. image retrieval. or semantic grouping. In this paper. we present a new model for multiview clustering that extends traditional non-negative matrix factorization to the joint factorization of different data matrices. Accordingly. the technique provides a new approach to the joint treatment of image parts and attributes. First experiments in image segmentation and multiview clustering of image features and image labels show promising results and indicate that the proposed method offers a common framework for image analysis on different levels of abstraction.,True,WDHoQtYAAAAJ:kNdYIx-mwKoC,91,https://hal.inria.fr/hal-00652879/,4175753356681312182,/scholar?cites=4175753356681312182,,,https://hal.inria.fr/docs/00/65/28/79/PDF/CVWW.pdf,0,0,0
1282696,Game data mining,2013,Anders Drachen and Christian Thurau and Julian Togelius and Georgios N Yannakakis and Christian Bauckhage,,,,205-253,Springer. London,During the years of the Information Age. technological advances in the computers. satellites. data transfer. optics. and digital storage has led to the collection of an immense mass of data on everything from business to astronomy. counting on the power of digital computing to sort through the amalgam of information and generate meaning from the data. Initially. in the 1970s and 1980s of the previous century. data were stored on disparate structures and very rapidly became overwhelming. The initial chaos led to the creation of structured databases and database management systems to assist with the management of large corpuses of data. and notably. the effective and efficient retrieval of information from databases. The rise of the database management system increased the already rapid pace of information gathering.,True,WDHoQtYAAAAJ:mVmsd5A6BfQC,90,https://link.springer.com/chapter/10.1007/978-1-4471-4769-5_12,3687334472224816337,/scholar?cites=3687334472224816337,,,https://www.um.edu.mt/library/oar/bitstream/123456789/29690/1/Game_data_mining.pdf,0,0,0
1282697,Making archetypal analysis practical,2009,Christian Bauckhage and Christian Thurau,,,,272-281,Springer. Berlin. Heidelberg,Archetypal analysis represents the members of a set of multivariate data as a convex combination of extremal points of the data. It allows for dimensionality reduction and clustering and is particularly useful whenever the data are superpositions of basic entities. However. since its computation costs grow quadratically with the number of data points. the original algorithm hardly applies to modern pattern recognition or data mining settings. In this paper. we introduce ways of notably accelerating archetypal analysis. Our experiments are the first successful application of the technique to large scale data analysis problems.,True,WDHoQtYAAAAJ:ufrVoPGSRksC,88,https://link.springer.com/chapter/10.1007/978-3-642-03798-6_28,9580331063995909444,/scholar?cites=9580331063995909444,,,https://www.researchgate.net/profile/Christian_Bauckhage/publication/221115052_Making_Archetypal_Analysis_Practical/links/02e7e5272ae59e72c0000000/Making-Archetypal-Analysis-Practical.pdf,0,0,0
1282698,Learning to reweight examples for robust deep learning,2018,Mengye Ren and Wenyuan Zeng and Bin Yang and Raquel Urtasun,,,,,,Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However. they can also easily overfit to training set biases and label noises. In addition to various regularizers. example reweighting algorithms are popular solutions to these problems. but they require careful tuning of additional hyperparameters. such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods. which typically consist of functions of the cost value of each example. in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights. our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network. does not require any additional hyperparameter tuning. and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.,True,DSKXnkkAAAAJ:roLk4NBRz8UC,437,http://proceedings.mlr.press/v80/ren18a.html,17871432661582272860,/scholar?cites=17871432661582272860,,,http://proceedings.mlr.press/v80/ren18a/ren18a.pdf,0,0,0
1282699,Pixor: Real-time 3d object detection from point clouds,2018,Bin Yang and Wenjie Luo and Raquel Urtasun,,,,7652-7660,,We address the problem of real-time 3D object detection from point clouds in the context of autonomous driving. Speed is critical as detection is a necessary component for safety. Existing approaches are. however. expensive in computation due to high dimensionality of point clouds. We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV). and propose PIXOR. a proposal-free. single-stage detector that outputs oriented 3D object estimates decoded from pixel-wise neural network predictions. The input representation. network architecture. and model optimization are specially designed to balance high accuracy and real-time efficiency. We validate PIXOR on two datasets: the KITTI BEV object detection benchmark. and a large-scale 3D vehicle detection benchmark. In both datasets we show that the proposed detector surpasses other state-of-the-art methods notably in terms of Average Precision (AP). while still runs at 10 FPS.,True,DSKXnkkAAAAJ:hqOjcs7Dif8C,427,http://openaccess.thecvf.com/content_cvpr_2018/html/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.html,10655145744484957995,/scholar?cites=10655145744484957995,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.pdf,0,0,0
1282700,Convolutional channel features,2015,Bin Yang and Junjie Yan and Zhen Lei and Stan Z Li,,,,82-90,,Deep learning methods are powerful tools but often suffer from expensive computation and limited flexibility. An alternative is to combine light-weight models with deep representations. As successful cases exist in several visual problems. a unified framework is absent. In this paper. we revisit two widely used approaches in computer vision. namely filtered channel features and Convolutional Neural Networks (CNN). and absorb merits from both by proposing an integrated method called Convolutional Channel Features (CCF). CCF transfers low-level features from pre-trained CNN models to feed the boosting forest model. With the combination of CNN features and boosting forest. CCF benefits from the richer capacity in feature representation compared with channel features. as well as lower cost in computation and storage compared with end-to-end CNN methods. We show that CCF serves as a good way of tailoring pre-trained CNN models to diverse tasks without fine-tuning the whole network to each task by achieving state-of-the-art performances in pedestrian detection. face detection. edge detection and object proposal generation.,True,DSKXnkkAAAAJ:d1gkVwhDpl0C,311,https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Yang_Convolutional_Channel_Features_ICCV_2015_paper.html,15348182900133754024,/scholar?cites=15348182900133754024,,,https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_Convolutional_Channel_Features_ICCV_2015_paper.pdf,0,0,0
1282701,Deep Continuous Fusion for Multi-Sensor 3D Object Detection,2018,Ming Liang and Bin Yang and Shenlong Wang and Raquel Urtasun,,,,641-656,,In this paper. we propose a novel 3D object detector that can exploit both LIDAR as well as cameras to perform very accurate localization. Towards this goal. we design an end-to-end learnable architecture that exploits continuous convolutions to fuse image and LIDAR feature maps at different levels of resolution. Our proposed continuous fusion layer encode both discrete-state image features as well as continuous geometric information. This enables us to design a novel. reliable and efficient end-to-end learnable 3D object detector based on multiple sensors. Our experimental evaluation on both KITTI as well as a large scale 3D object detection benchmark shows significant improvements over the state of the art.,True,DSKXnkkAAAAJ:5nxA0vEk-isC,304,http://openaccess.thecvf.com/content_ECCV_2018/html/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.html,15523011476685408326,/scholar?cites=15523011476685408326,,,http://openaccess.thecvf.com/content_ECCV_2018/papers/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.pdf,0,0,0
1282702,Aggregate channel features for multi-view face detection,2014,Bin Yang and Junjie Yan and Zhen Lei and Stan Z Li,,,,1-8,,Face detection has drawn much attention in recent decades since the seminal work by Viola and Jones. While many subsequences have improved the work with more powerful learning algorithms. the feature representation used for face detection still can't meet the demand for effectively and efficiently handling faces with large appearance variance in the wild. To solve this bottleneck. we borrow the concept of channel features to the face detection domain. which extends the image channel to diverse types like gradient magnitude and oriented gradient histograms and therefore encodes rich information in a simple form. We adopt a novel variant called aggregate channel features. make a full exploration of feature design. and discover a multi-scale version of features with better performance. To deal with poses of faces in the wild. we propose a multi-view detection approach featuring score re-ranking and detection …,True,DSKXnkkAAAAJ:u5HHmVD_uO8C,301,https://ieeexplore.ieee.org/abstract/document/6996284/,11225825311962158642,/scholar?cites=11225825311962158642,,,https://arxiv.org/pdf/1407.4023,0,0,0
1282703,Fast and furious: Real time end-to-end 3d detection. tracking and motion forecasting with a single convolutional net,2018,Wenjie Luo and Bin Yang and Raquel Urtasun,,,,3569-3577,,In this paper we propose a novel deep neural network that is able to jointly reason about 3D detection. tracking and motion forecasting given data captured by a 3D sensor. By jointly reasoning about these tasks. our holistic approach is more robust to occlusion as well as sparse data at range. Our approach performs 3D convolutions across space and time over a bird's eye view representation of the 3D world. which is very efficient in terms of both memory and computation. Our experiments on a new very large scale dataset captured in several north american cities. show that we can outperform the state-of-the-art by a large margin. Importantly. by sharing computation we can perform all tasks in as little as 30 ms.,True,DSKXnkkAAAAJ:Se3iqnhoufwC,288,http://openaccess.thecvf.com/content_cvpr_2018/html/Luo_Fast_and_Furious_CVPR_2018_paper.html,5385005746237696409,/scholar?cites=5385005746237696409,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Luo_Fast_and_Furious_CVPR_2018_paper.pdf,0,0,0
1282704,T-cnn: Tubelets with convolutional neural networks for object detection from videos,2017,Kai Kang and Hongsheng Li and Junjie Yan and Xingyu Zeng and Bin Yang and Tong Xiao and Cong Zhang and Zhe Wang and Ruohui Wang and Xiaogang Wang and Wanli Ouyang,28,IEEE Transactions on Circuits and Systems for Video Technology,10,2896-2907,IEEE,The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks. such as GoogleNet and VGG. novel object detection frameworks. such as R-CNN and its successors. Fast R-CNN. and Faster R-CNN. play an essential role in improving the state of the art. Despite their effectiveness on still images. those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this paper. we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos. which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN. i.e.. tubelets with convolutional neural networks. The proposed …,True,DSKXnkkAAAAJ:IjCSPb-OGe4C,276,https://ieeexplore.ieee.org/abstract/document/8003302/,392731400711624845,/scholar?cites=392731400711624845,,,https://arxiv.org/pdf/1604.02532,0,0,0
1282705,Multi-task multi-sensor fusion for 3d object detection,2019,Ming Liang and Bin Yang and Yun Chen and Rui Hu and Raquel Urtasun,,,,7345-7353,,In this paper we propose to exploit multiple related tasks for accurate multi-sensor 3D object detection. Towards this goal we present an end-to-end learnable architecture that reasons about 2D and 3D object detection as well as ground estimation and depth completion. Our experiments show that all these tasks are complementary and help the network learn better representations by fusing information at various levels. Importantly. our approach leads the KITTI benchmark on 2D. 3D and bird's eye view object detection. while being real-time.,True,DSKXnkkAAAAJ:Zph67rFs4hoC,201,http://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Multi-Task_Multi-Sensor_Fusion_for_3D_Object_Detection_CVPR_2019_paper.html,14501124345135130835,/scholar?cites=14501124345135130835,,,http://openaccess.thecvf.com/content_CVPR_2019/papers/Liang_Multi-Task_Multi-Sensor_Fusion_for_3D_Object_Detection_CVPR_2019_paper.pdf,0,0,0
1282706,Hdnet: Exploiting hd maps for 3d object detection,2018,Bin Yang and Ming Liang and Raquel Urtasun,,,,146-155,PMLR,In this paper we show that High-Definition (HD) maps provide strong priors that can boost the performance and robustness of modern 3D object detectors. Towards this goal. we design a single stage detector that extracts geometric and semantic features from the HD maps. As maps might not be available everywhere. we also propose a map prediction module that estimates the map on the fly from raw LiDAR data. We conduct extensive experiments on KITTI [1] as well as a large-scale 3D detection benchmark containing 1 million frames. and show that the proposed map-aware detector consistently outperforms the state-of-the-art in both mapped and un-mapped scenarios. Importantly the whole framework runs at 20 frames per second.,True,DSKXnkkAAAAJ:8k81kl-MbHgC,137,http://proceedings.mlr.press/v87/yang18b.html,15176797729115193086,/scholar?cites=15176797729115193086,,,http://proceedings.mlr.press/v87/yang18b/yang18b.pdf,0,0,0
1282707,Torontocity: Seeing the world with a million eyes,2017,Shenlong Wang and Min Bai and Gellert Mattyus and Hang Chu and Wenjie Luo and Bin Yang and Justin Liang and Joel Cheverie and Sanja Fidler and Raquel Urtasun,,,,3009-3017,,In this paper we introduce the TorontoCity benchmark. which covers the full greater Toronto area (GTA) with 712.5 of land. 8439 of road and around 400.000 buildings. Our benchmark provides different perspectives of the world captured from airplanes. drones and cars driving around the city. Manually labeling such a large scale dataset is infeasible. Instead. we propose to utilize different sources of high-precision maps to create our ground truth. Towards this goal. we develop algorithms that allow us to align all data sources with the maps while requiring minimal human supervision. We have designed a wide variety of tasks including building height estimation (reconstruction). road centerline and curb extraction. building instance segmentation. building contour extraction (reorganization). semantic labeling and scene type classification (recognition). Our pilot study shows that most of these tasks are still difficult for modern convolutional neural networks.,True,DSKXnkkAAAAJ:0EnyYjriUFMC,130,https://arxiv.org/abs/1612.00423,12969034788027848806,/scholar?cites=12969034788027848806,,,https://arxiv.org/pdf/1612.00423.pdf?utm_campaign=Marketing%20Blog%20-%20Daily%20Emails&utm_campaign=Marketing%20Blog%20-%20Daily%20Emails&utm_content=61642942&utm_content=61642942&utm_medium=email&utm_medium=email&utm_source=hs_email&utm_source=hs_email,0,0,0
1282708,Crafting gbd-net for object detection,2018,Xingyu Zeng and Wanli Ouyang and Junjie Yan and Hongsheng Li and Tong Xiao and Kun Wang and Yu Liu and Yucong Zhou and Bin Yang and Zhe Wang and Hui Zhou and Xiaogang Wang,40,IEEE Transactions on Pattern Analysis and Machine Intelligence,9,2109-2123,IEEE,The visual cues from multiple support regions of different sizes and resolutions are complementary in classifying a candidate box in object detection. Effective integration of local and contextual visual cues from these regions has become a fundamental problem in object detection. In this paper. we propose a gated bi-directional CNN (GBD-Net) to pass messages among features from different support regions during both feature learning and feature extraction. Such message passing can be implemented through convolution between neighboring support regions in two directions and can be conducted in various layers. Therefore. local and contextual visual patterns can validate the existence of each other by learning their nonlinear relationships and their close interactions are modeled in a more complex way. It is also shown that message passing is not always helpful but dependent on individual samples. Gated …,True,DSKXnkkAAAAJ:Tyk-4Ss8FVUC,112,https://ieeexplore.ieee.org/abstract/document/8017422/,1968573158878984666,/scholar?cites=1968573158878984666,,,https://arxiv.org/pdf/1610.02579,0,0,0
1282709,What can we learn privately?,2011,Shiva Prasad Kasiviswanathan and Homin K Lee and Kobbi Nissim and Sofya Raskhodnikova and Adam Smith,40,SIAM Journal on Computing,3,793-826,Society for Industrial and Applied Mathematics,Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask. What concept classes can be learned privately. namely. by an algorithm whose output does not depend too heavily on any one input or specific training example? More precisely. we investigate learning algorithms that satisfy differential privacy. a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals. Our goal is a broad understanding of the resources required for private learning in terms of samples. computation time. and interaction. We demonstrate that. ignoring computational constraints. it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept …,True,XnHdkZUAAAAJ:u5HHmVD_uO8C,725,https://epubs.siam.org/doi/abs/10.1137/090756090,12154067552343221864,/scholar?cites=12154067552343221864,,,https://arxiv.org/pdf/0803.0924,0,0,0
1282710,Composition attacks and auxiliary information in data privacy,2008,Srivatsava Ranjit Ganta and Shiva Prasad Kasiviswanathan and Adam Smith,,,,265-273,,Privacy is an increasingly important aspect of data publishing. Reasoning about privacy. however. is fraught with pitfalls. One of the most significant is the auxiliary information (also called external knowledge. background knowledge. or side information) that an adversary gleans from other channels such as the web. public records. or domain knowledge. This paper explores how one can reason about privacy in the face of rich. realistic sources of auxiliary information. Specifically. we investigate the effectiveness of current anonymization schemes in preserving privacy when multiple organizations independently release anonymized data about overlapping populations.,True,XnHdkZUAAAAJ:u-x6o8ySG0sC,401,https://dl.acm.org/doi/abs/10.1145/1401890.1401926,7149627066805094758,/scholar?cites=7149627066805094758,,,https://arxiv.org/pdf/0803.0032,0,0,0
1282711,Analyzing graphs with node differential privacy,2013,Shiva Prasad Kasiviswanathan and Kobbi Nissim and Sofya Raskhodnikova and Adam Smith,,,,457-476,Springer. Berlin. Heidelberg,We develop algorithms for the private analysis of network data that provide accurate analysis of realistic networks while satisfying stronger privacy guarantees than those of previous work. We present several techniques for designing node differentially private algorithms. that is. algorithms whose output distribution does not change significantly when a node and all its adjacent edges are added to a graph. We also develop methodology for analyzing the accuracy of such algorithms on realistic networks.The main idea behind our techniques is to “project” (in one of several senses) the input graph onto the set of graphs with maximum degree below a certain threshold. We design projection operators. tailored to specific statistics that have low sensitivity and preserve information about the original statistic. These operators can be viewed as giving a fractional (low-degree) graph that is a solution to an …,True,XnHdkZUAAAAJ:9ZlFYXVOiuMC,221,https://link.springer.com/chapter/10.1007/978-3-642-36594-2_26,15180953378909560304,/scholar?cites=15180953378909560304,,,https://link.springer.com/content/pdf/10.1007/978-3-642-36594-2_26.pdf,0,0,0
1282712,Emerging topic detection using dictionary learning,2011,Shiva Prasad Kasiviswanathan and Prem Melville and Arindam Banerjee and Vikas Sindhwani,,,,745-754,,Streaming user-generated content in the form of blogs. microblogs. forums. and multimedia sharing sites. provides a rich source of data from which invaluable information and insights maybe gleaned. Given the vast volume of such social media data being continually generated. one of the challenges is to automatically tease apart the emerging topics of discussion from the constant background chatter. Such emerging topics can be identified by the appearance of multiple posts on a unique subject matter. which is distinct from previous online discourse. We address the problem of identifying emerging topics through the use of dictionary learning. We propose a two stage approach respectively based on detection and clustering of novel user-generated content. We derive a scalable approach by using the alternating directions method to solve the resulting optimization problems. Empirical results show that our …,True,XnHdkZUAAAAJ:Zph67rFs4hoC,159,https://dl.acm.org/doi/abs/10.1145/2063576.2063686,14969450402366953753,/scholar?cites=14969450402366953753,,,https://prem-melville.com/publications/emerging-topics-cikm2011.pdf,0,0,0
1282713,Simple black-box adversarial perturbations for deep networks,2016,Nina Narodytska and Shiva Prasad Kasiviswanathan,,arXiv preprint arXiv:1612.06299,,,,Deep neural networks are powerful and popular learning models that achieve state-of-the-art pattern recognition performance on many computer vision. speech. and language processing tasks. However. these networks have also been shown susceptible to carefully crafted adversarial perturbations which force misclassification of the inputs. Adversarial examples enable adversaries to subvert the expected system behavior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world.In this work. we focus on deep convolutional neural networks and demonstrate that adversaries can easily craft adversarial examples even without any internal knowledge of the target network. Our attacks treat the network as an oracle (black-box) and only assume that the output of the network can be observed on the probed inputs. Our first attack is based on a simple idea of adding perturbation to a randomly selected single pixel or a small set of them. We then improve the effectiveness of this attack by carefully constructing a small set of pixels to perturb by using the idea of greedy local-search. Our proposed attacks also naturally extend to a stronger notion of misclassification. Our extensive experimental results illustrate that even these elementary attacks can reveal a deep neural network's vulnerabilities. The simplicity and effectiveness of our proposed schemes mean that they could serve as a litmus test for designing robust networks.,True,XnHdkZUAAAAJ:k_IJM867U9cC,145,https://arxiv.org/abs/1612.06299,10878822896053833036,/scholar?cites=10878822896053833036,,,https://arxiv.org/pdf/1612.06299,0,0,0
1282714,Simple Black-Box Adversarial Attacks on Deep Neural Networks.,2017,Nina Narodytska and Shiva Prasad Kasiviswanathan,2,CVPR Workshops,,,,Deep neural networks are powerful and popular learning models that achieve state-of-the-art pattern recognition performance on many computer vision. speech. and language processing tasks. However. these networks have also been shown susceptible to crafted adversarial perturbations which force misclassification of the inputs. Adversarial examples enable adversaries to subvert the expected system behavior leading to undesired consequences and could pose a security risk when these systems are deployed in the real world. In this work. we focus on deep convolutional neural networks and demonstrate that adversaries can easily craft adversarial examples even without any internal knowledge of the target network. Our attacks treat the network as an oracle (black-box) and only assume that the output of the network can be observed on the probed inputs. Our attacks utilize a novel local-search based technique to construct numerical approximation to the network gradient. which is then carefully used to construct a small set of pixels in an image to perturb. We demonstrate how this underlying idea can be adapted to achieve several strong notions of misclassification. The simplicity and effectiveness of our proposed schemes mean that they could serve as a litmus test for designing robust networks.,True,XnHdkZUAAAAJ:maZDTaKrznsC,144,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w16/papers/Kasiviswanathan_Simple_Black-Box_Adversarial_CVPR_2017_paper.pdf,13362724871658147388,/scholar?cites=13362724871658147388,,,https://openaccess.thecvf.com/content_cvpr_2017_workshops/w16/papers/Kasiviswanathan_Simple_Black-Box_Adversarial_CVPR_2017_paper.pdf,0,0,0
1282715,Verifying properties of binarized deep neural networks,2018,Nina Narodytska and Shiva Kasiviswanathan and Leonid Ryzhyk and Mooly Sagiv and Toby Walsh,32,Proceedings of the AAAI Conference on Artificial Intelligence,1,,,Understanding properties of deep neural networks is an important challenge in deep learning. In this paper. we take a step in this direction by proposing a rigorous way of verifying properties of a popular class of neural networks. Binarized Neural Networks. using the well-developed means of Boolean satisfiability. Our main contribution is a construction that creates a representation of a binarized neural network as a Boolean formula. Our encoding is the first exact Boolean representation of a deep neural network. Using this encoding. we leverage the power of modern SAT solvers along with a proposed counterexample-guided search procedure to verify various properties of these networks. A particular focus will be on the critical property of robustness to adversarial perturbations. For this property. our experimental results demonstrate that our approach scales to medium-size deep neural networks used in image classification tasks. To the best of our knowledge. this is the first work on verifying properties of deep neural networks using an exact Boolean encoding of the network.,True,XnHdkZUAAAAJ:JV2RwH3_ST0C,113,https://ojs.aaai.org/index.php/AAAI/article/view/12206,12383597175909645624,/scholar?cites=12383597175909645624,,,https://ojs.aaai.org/index.php/AAAI/article/view/12206/12065,0,0,0
1282716,The price of privately releasing contingency tables and the spectra of random matrices with correlated rows,2010,Shiva Prasad Kasiviswanathan and Mark Rudelson and Adam Smith and Jonathan Ullman,,,,775-784,,Marginal (contingency) tables are the method of choice for government agencies releasing statistical summaries of categorical data. In this paper. we derive lower bounds on how much distortion (noise) is necessary in these tables to ensure the privacy of sensitive data. We extend a line of recent work on impossibility results for private data analysis [9. 12. 13. 15] to a natural and important class of functionalities. Consider a database consisting of n rows (one per individual). each row comprising d binary attributes. For any subset of T attributes of size| T|= k. the marginal table for T has 2 k entries; each entry counts how many times in the database a particular setting of these attributes occurs. We provide lower bounds for releasing all dk k-attribute marginal tables under several different notions of privacy.(1) We give efficient polynomial time attacks which allow an adversary to reconstruct sensitive information given …,True,XnHdkZUAAAAJ:9yKSN-GCB0IC,105,https://dl.acm.org/doi/abs/10.1145/1806689.1806795,12985834043142063353,/scholar?cites=12985834043142063353,,,https://www.osti.gov/servlets/purl/990798,0,0,0
1282717,On the'semantics' of differential privacy: A bayesian formulation,2014,Shiva P Kasiviswanathan and Adam Smith,6,Journal of Privacy and Confidentiality,1,,,Differential privacy is a definition of privacy for algorithms that analyze and publish information about statistical databases. It is often claimed that differential privacy provides guarantees against adversaries with arbitrary side information. In this paper. we provide a precise formulation of these guarantees in terms of the inferences drawn by a Bayesian adversary. We show that this formulation is satisfied by both epsilon-differential privacy as well as a relaxation known as (epsilon. delta)-differential privacy. Our formulation follows the ideas originally due to Dwork and McSherry. This paper is. to our knowledge. the first place such a formulation appears explicitly. The analysis of the relaxed definition is new to this paper. and provides some guidance for setting the delta parameter when using (epsilon. delta)-differential privacy.,True,XnHdkZUAAAAJ:YFjsv_pBGBYC,94,https://journalprivacyconfidentiality.org/index.php/jpc/article/view/634,8385696806198295841,/scholar?cites=8385696806198295841,,,https://journalprivacyconfidentiality.org/index.php/jpc/article/download/634/617,0,0,0
1282718,Bounds on the sample complexity for private learning and private data release,2010,Amos Beimel and Shiva Prasad Kasiviswanathan and Kobbi Nissim,,,,437-454,Springer. Berlin. Heidelberg,Learning is a task that generalizes many of the analyses that are applied to collections of data. and in particular. collections of sensitive individual information. Hence. it is natural to ask what can be learned while preserving individual privacy. [Kasiviswanathan. Lee. Nissim. Raskhodnikova. and Smith; FOCS 2008] initiated such a discussion. They formalized the notion of private learning. as a combination of PAC learning and differential privacy. and investigated what concept classes can be learned privately. Somewhat surprisingly. they showed that. ignoring time complexity. every PAC learning task could be performed privately with polynomially many samples. and in many natural cases this could even be done in polynomial time.While these results seem to equate non-private and private learning. there is still a significant gap: the sample complexity of (non-private) PAC learning is crisply …,True,XnHdkZUAAAAJ:bEWYMUwI8FkC,91,https://link.springer.com/chapter/10.1007/978-3-642-11799-2_26,1691709622419716203,/scholar?cites=1691709622419716203,,,https://link.springer.com/content/pdf/10.1007/978-3-642-11799-2_26.pdf,0,0,0
1282719,Subsampled Rényi differential privacy and analytical moments accountant,2019,Yu-Xiang Wang and Borja Balle and Shiva Prasad Kasiviswanathan,,,,1226-1235,PMLR,We study the problem of subsampling in differential privacy (DP). a question that is the centerpiece behind many successful differentially private machine learning algorithms. Specifically. we provide a tight upper bound on the Renyi Differential Privacy (RDP)[Mironov 2017] parameters for algorithms that:(1) subsample the dataset. and then (2) applies a randomized mechanism M to the subsample. in terms of the RDP parameters of M and the subsampling probability parameter. Our results generalize the moments accounting technique. developed by [Abadi et al. 2016] for the Gaussian mechanism. to any subsampled RDP mechanism.,True,XnHdkZUAAAAJ:RYcK_YlVTxYC,88,http://proceedings.mlr.press/v89/wang19b.html,399341455977454227,/scholar?cites=399341455977454227,,,http://proceedings.mlr.press/v89/wang19b/wang19b.pdf,0,0,0
1282720,Planning chemical syntheses with deep neural networks and symbolic AI,2018,Marwin HS Segler and Mike Preuss and Mark P Waller,555,Nature,7698,604-610,Nature Publishing Group,To plan the syntheses of small organic molecules. chemists use retrosynthesis. a problem-solving technique in which target molecules are recursively transformed into increasingly simpler precursors. Computer-aided retrosynthesis would be a valuable tool but at present it is slow and provides results of unsatisfactory quality. Here we use Monte Carlo tree search and symbolic artificial intelligence (AI) to discover retrosynthetic routes. We combined Monte Carlo tree search with an expansion policy network that guides the search. and a filter network to pre-select the most promising retrosynthetic steps. These deep neural networks were trained on essentially all reactions ever published in organic chemistry. Our system solves for almost twice as many molecules. thirty times faster than the traditional computer-aided search method. which is based on extracted rules and hand-designed heuristics. In a double-blind AB …,True,Qr-m-iwAAAAJ:TFP_iSt0sucC,662,https://www.nature.com/articles/nature25978,14474788541355041386,/scholar?cites=14474788541355041386,,,https://www.gwern.net/docs/rl/2018-segler.pdf,0,0,0
1282721,Generating focused molecule libraries for drug discovery with recurrent neural networks,2018,Marwin HS Segler and Thierry Kogej and Christian Tyrchan and Mark P Waller,4,ACS central science,1,120-131,American Chemical Society,In de novo drug design. computational strategies are used to generate novel molecules with good affinity to the desired biological target. In this work. we show that recurrent neural networks can be trained as generative models for molecular structures. similar to statistical language models in natural language processing. We demonstrate that the properties of the generated molecules correlate very well with the properties of the molecules used to train the model. In order to enrich libraries with molecules active toward a given biological target. we propose to fine-tune the model with small sets of molecules. which are known to be active against that target. Against Staphylococcus aureus. the model reproduced 14% of 6051 hold-out test molecules that medicinal chemists designed. whereas against Plasmodium falciparum (Malaria). it reproduced 28% of 1240 test molecules. When coupled with a scoring function. our …,True,Qr-m-iwAAAAJ:hFOr9nPyWt4C,541,https://pubs.acs.org/doi/abs/10.1021/acscentsci.7b00512,704960625136257570,/scholar?cites=704960625136257570,,,https://pubs.acs.org/doi/full/10.1021%2Facscentsci.7b00512,0,0,0
1282722,Hybrid density functional theory for π‐stacking interactions: Application to benzenes. pyridines. and DNA bases,2006,Mark P Waller and Arturo Robertazzi and James A Platts and David E Hibbs and Peter A Williams,27,Journal of computational chemistry,4,491-504,Wiley Subscription Services. Inc.. A Wiley Company,The suitability of a hybrid density functional to qualitatively reproduce geometric and energetic details of parallel π‐stacked aromatic complexes is presented. The hybrid functional includes an ad hoc mixture of half the exact (HF) exchange with half of the uniform electron gas exchange. plus Lee. Yang. and Parr's expression for correlation energy. This functional. in combination with polarized. diffuse basis sets. gives a binding energy for the parallel‐displaced benzene dimer in good agreement with the best available high‐level calculations reported in the literature. and qualitatively reproduces the local MP2 potential energy surface of the parallel‐displaced benzene dimer. This method was further critically compared to high‐level calculations recently reported in the literature for a range of π‐stacked complexes. including monosubstituted benzene–benzene dimers. along with DNA and RNA bases. and generally …,True,Qr-m-iwAAAAJ:u5HHmVD_uO8C,262,https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.20363,12125754548010089627,/scholar?cites=12125754548010089627,,,https://www.academia.edu/download/43956735/Hybrid_density_functional_theory_for_-st20160321-29197-1ytjxtd.pdf,0,0,0
1282723,Neural‐symbolic machine learning for retrosynthesis and reaction prediction,2017,Marwin HS Segler and Mark P Waller,23,Chemistry–A European Journal,25,5966-5971,,Reaction prediction and retrosynthesis are the cornerstones of organic chemistry. Rule‐based expert systems have been the most widespread approach to computationally solve these two related challenges to date. However. reaction rules often fail because they ignore the molecular context. which leads to reactivity conflicts. Herein. we report that deep neural networks can learn to resolve reactivity conflicts and to prioritize the most suitable transformation rules. We show that by training our model on 3.5 million reactions taken from the collective published knowledge of the entire discipline of chemistry. our model exhibits a top10‐accuracy of 95 % in retrosynthesis and 97 % for reaction prediction on a validation set of almost 1 million reactions.,True,Qr-m-iwAAAAJ:HDshCWvjkbEC,241,https://onlinelibrary.wiley.com/doi/abs/10.1002/chem.201605499,11066709388422310372,/scholar?cites=11066709388422310372,,,,0,0,0
1282724,Geometries of second-row transition-metal complexes from density-functional theory,2007,Mark P Waller and Heiko Braun and Nils Hojdis and Michael Bühl,3,Journal of chemical theory and computation,6,2234-2242,American Chemical Society,A data set of 19 second-row transition-metal complexes has been collated from sufficiently precise gas-phase electron-diffraction experiments and used for evaluating errors in DFT optimized geometries. Equilibrium geometries have been computed using 15 different combinations of exchange-correlation functionals in conjunction with up to three different effective core potentials. Most DFT levels beyond the local density approximation can reproduce the 29 metal−ligand bond distances selected in this set with reasonable accuracy and precision. as assessed by the mean and standard deviations of optimized vs experimentally observed bond lengths. The pure GGAs tested in this study all have larger standard deviations than their corresponding hybrid variants. In contrast to previous findings for first-row transition-metal complexes. the TPSSh hybrid meta-GGA is slightly inferior to the best hybrid GGAs. The ranking …,True,Qr-m-iwAAAAJ:d1gkVwhDpl0C,155,https://pubs.acs.org/doi/abs/10.1021/ct700178y,2983665042896571843,/scholar?cites=2983665042896571843,,,,0,0,0
1282725,Cholesterol effect on the dipole potential of lipid membranes,2006,Thomas Starke-Peterkovic and Nigel Turner and Mark F Vitha and Mark P Waller and David E Hibbs and Ronald J Clarke,90,Biophysical journal,11,4060-4070,Cell Press,The effect of cholesterol removal by methyl-β-cyclodextrin on the dipole potential. ψd. of membrane vesicles composed of natural membrane lipids extracted from the kidney and brain of eight vertebrate species was investigated using the voltage-sensitive fluorescent probe di-8-ANEPPS. Cyclodextrin treatment reduced cholesterol levels by on average 80% and this was associated with an average reduction in ψd of 50 mV. Measurements of the effect of a range of cholesterol derivatives on the ψd of DMPC lipid vesicles showed that the magnitude of the effect correlated with the component of the sterol’s dipole moment perpendicular to the membrane surface. The changes in ψd observed could not be accounted for solely by the electric field originating from the sterols’ dipole moments. Additional factors must arise from sterol-induced changes in lipid packing. which changes the density of dipoles in the membrane …,True,Qr-m-iwAAAAJ:9yKSN-GCB0IC,145,https://www.sciencedirect.com/science/article/pii/S0006349506725863,1627375048071162857,/scholar?cites=1627375048071162857,,,https://www.sciencedirect.com/science/article/pii/S0006349506725863,0,0,0
1282726,Modelling chemical reasoning to predict and invent reactions,2017,Marwin HS Segler and Mark P Waller,23,Chemistry–A European Journal,25,6118-6128,,The ability to reason beyond established knowledge allows organic chemists to solve synthetic problems and invent novel transformations. Herein. we propose a model that mimics chemical reasoning. and formalises reaction prediction as finding missing links in a knowledge graph. We have constructed a knowledge graph containing 14.4 million molecules and 8.2 million binary reactions. which represents the bulk of all chemical reactions ever published in the scientific literature. Our model outperforms a rule‐based expert system in the reaction prediction task for 180 000 randomly selected binary reactions. The data‐driven model generalises even beyond known reaction types. and is thus capable of effectively (re‐)discovering novel transformations (even including transition metal‐catalysed reactions). Our model enables computers to infer hypotheses about reactivity and reactions by only considering the …,True,Qr-m-iwAAAAJ:ZeXyd9-uunAC,122,https://onlinelibrary.wiley.com/doi/abs/10.1002/chem.201604556,1437686757783728427,/scholar?cites=1437686757783728427,,,https://arxiv.org/pdf/1608.07117,0,0,0
1282727,51V NMR Chemical Shifts Calculated from QM/MM Models of Vanadium Chloroperoxidase,2007,Mark P Waller and Michael Bühl and K emsp14R Geethalakshmi and Dongqi Wang and Walter Thiel,13,Chemistry–A European Journal,17,4723-4732,WILEY‐VCH Verlag,51V NMR chemical shifts calculated from QM/MM‐optimized (QM=quantum mechanical; MM=molecular mechanical) models of vanadium‐dependent chloroperoxidase (VCPO) are presented. An extensive number of protonation states for the vanadium cofactor (active site of the protein) and a number of probable positional isomers for each of the protonation states are considered. The size of the QM region is increased incrementally to observe the convergence behavior of the 51V NMR chemical shifts. A total of 40 models are assessed by comparison to experimental solid‐state 51V NMR results recently reported in the literature. Isotropic chemical shifts are found to be a poor indicator of the protonation state; however. anisotropic chemical shifts and the nuclear quadrupole tensors appear to be sensitive to changes in the proton environment of the vanadium nuclei. This detailed investigation of the 51V NMR …,True,Qr-m-iwAAAAJ:u-x6o8ySG0sC,97,https://chemistry-europe.onlinelibrary.wiley.com/doi/abs/10.1002/chem.200700295,5577793607604502639,/scholar?cites=5577793607604502639,,,,0,0,0
1282728,pH‐Switchable ampholytic supramolecular copolymers,2013,Hendrik Frisch and Jan Patrick Unsleber and David Lüdeker and Martin Peterlechner and Gunther Brunklaus and Mark Waller and Pol Besenius,52,Angewandte Chemie International Edition,38,10097-10101,WILEY‐VCH Verlag,β‐sheet‐encoded anionic and cationic dendritic peptide amphiphiles form supramolecular copolymers when self‐assembled in a 1: 1 feed ratio of the monomers. These ampholytic materials have been designed for on‐off polymerization in response to pH triggers. The cooperative supramolecular self‐assembly process is switched on at a physiologically relevant pH value and can be switched off by increasing or decreasing the pH value.,True,Qr-m-iwAAAAJ:4TOpqqG69KYC,92,https://onlinelibrary.wiley.com/doi/abs/10.1002/anie.201303810,14785073679688617838,/scholar?cites=14785073679688617838,,,,0,0,0
1282729,Pattern‐Based Peptide Recognition,2007,Byron E Collins and Eric V Anslyn,13,Chemistry–A European Journal,17,4700-4708,WILEY‐VCH Verlag,Nature's use of sensor arrays in the mammalian olfactory and gustatory systems has encouraged supramolecular chemists to take a new approach to molecular recognition. Pattern‐based recognition involves the use of sensor arrays to create fingerprints for analytes. The use of sensing arrays has paved the way for systems capable of identifying biological analytes that would have been difficult targets using the traditional “lock‐and‐key” approach to sensor design.,True,Qr-m-iwAAAAJ:ns9cj8rnVeAC,73,https://onlinelibrary.wiley.com/doi/abs/10.1002/chem.200700153,9802903730366846984,/scholar?cites=9802903730366846984,,,,0,0,0
1282730,Investigating inclusion complexes using quantum chemical methods,2012,Mark P Waller and Holger Kruse and Christian Mück-Lichtenfeld and Stefan Grimme,41,,8,3119-3128,Royal Society of Chemistry,Quantum chemistry has firmly established itself as a reliable method for investigating present-day problems in biological and materials chemistry. Understanding inclusion complexes represents one of the cutting edges of simulation sciences. In this tutorial review. we focus on the role and composition of non-covalent interactions. which are essential when studying inclusion complexes. A selected set of recently developed pragmatic methods used to study inclusion complexes are then surveyed including e.g. dispersion corrected DFT. double-hybrid functionals and spin-component scaled MP2. Finally. three case studies are outlined: (a) endohedral fullerene complexes. (b) buckyball catcher and (c) resorcinarene capsule. These case studies were carefully chosen to help illustrate how one may accurately investigate inclusion complexes. at a modest computational cost. using state-of-the-art quantum chemical …,True,Qr-m-iwAAAAJ:Y0pCki6q_DkC,62,https://pubs.rsc.org/lv/content/articlehtml/2012/cs/c2cs15244d,5999648245392579748,/scholar?cites=5999648245392579748,,,,0,0,0
1282731,Expressive expression mapping with ratio images,2001,Zicheng Liu and Ying Shan and Zhengyou Zhang,,,,271-276,,Facial expressions exhibit not only facial feature motions. but also subtle changes in illumination and appearance (eg. facial creases and wrinkles). These details are important visual cues. but they are difficult to synthesize. Traditional expression mapping techniques consider feature motions while the details in illumination changes are ignored. In this paper. we present a novel technique for facial expression mapping. We capture the illumination change of one person's expression in what we call an expression ratio image (ERI). Together with geometric warping. we map an ERI to any other person's face image to generate more expressive facial expressions.,True,4oXBp9UAAAAJ:u5HHmVD_uO8C,317,https://dl.acm.org/doi/abs/10.1145/383259.383289,11428871215430186596,/scholar?cites=11428871215430186596,,,https://www.academia.edu/download/30584114/expression_mapping.pdf,0,0,0
1282732,Deep crossing: Web-scale modeling without manually crafted combinatorial features,2016,Ying Shan and T Ryan Hoens and Jian Jiao and Haijing Wang and Dong Yu and JC Mao,,,,255-262,,"Manually crafted combinatorial features have been the"" secret sauce"" behind many successful models. For web-scale applications. however. the variety and volume of features make these manually crafted features expensive to create. maintain. and deploy. This paper proposes the Deep Crossing model which is a deep neural network that automatically combines features to produce superior models. The input of Deep Crossing is a set of individual features that can be either dense or sparse. The important crossing features are discovered implicitly by the networks. which are comprised of an embedding and stacking layer. as well as a cascade of Residual Units. Deep Crossing is implemented with a modeling tool called the Computational Network Tool Kit (CNTK). powered by a multi-GPU platform. It was able to build. from scratch. two web-scale models for a major paid search engine. and achieve superior results …",True,4oXBp9UAAAAJ:URolC5Kub84C,196,https://dl.acm.org/doi/abs/10.1145/2939672.2939704,5456494982618377535,/scholar?cites=5456494982618377535,,,https://www.kdd.org/kdd2016/papers/files/adf0975-shanA.pdf,0,0,0
1282733,Model-based bundle adjustment with application to face modeling,2001,Ying Shan and Zicheng Liu and Zhengyou Zhang,2,,,644-651,IEEE,We present a new model-based bundle adjustment algorithm to recover the 3D model of a scene/object from a sequence of images with unknown motions. Instead of representing scene/object by a collection of isolated 3D features (usually points). our algorithm uses a surface controlled by a small set of parameters. Compared with previous model-based approaches. our approach has the following advantages. First instead of using the model space as a regularizer we directly use it as our search space. thus resulting in a more elegant formulation with fewer unknowns and fewer equations. Second. our algorithm automatically associates tracked points with their correct locations on the surfaces. thereby eliminating the need for a prior 2D-to-3D association. Third. regarding face modeling. we use a very small set of face metrics (meaningful deformations) to parameterize the face geometry. resulting in a smaller search …,True,4oXBp9UAAAAJ:u-x6o8ySG0sC,190,https://ieeexplore.ieee.org/abstract/document/937687/,597414912424239712,/scholar?cites=597414912424239712,,,https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/Model-Based-Bundle-Adjustment-with-Application-to-Face-Modeling.pdf,0,0,0
1282734,Visual panel: virtual mouse. keyboard and 3D controller with an ordinary piece of paper,2001,Zhengyou Zhang and Ying Wu and Ying Shan and Steven Shafer,,,,1-8,,This paper presents a vision-based interface system. VISUAL PANEL. which employs an arbitrary quadrangle-shaped panel (eg. an ordinary piece of paper) and a tip pointer (eg. fingertip) as an intuitive. wireless and mobile input device. The system can accurately and reliably track the panel and the tip pointer. The panel tracking continuously determines the projective mapping between the panel at the current position and the display. which in turn maps the tip position to the corresponding position on the display. By detecting the clicking and dragging actions. the system can fulfill many tasks such as controlling a remote large display. and simulating a physical keyboard. Users can naturally use their fingers or other tip pointers to issue commands and type texts. Furthermore. by tracking the 3D position and orientation of the visual panel. the system can also provide 3D information. serving as a virtual joystick. to …,True,4oXBp9UAAAAJ:d1gkVwhDpl0C,174,https://dl.acm.org/doi/abs/10.1145/971478.971522,4807095461234830304,/scholar?cites=4807095461234830304,,,https://www.microsoft.com/en-us/research/uploads/prod/2016/12/Virtual-Mouse-Keyboard-and-3D-Controller-with-an-Ordinary-Piece-of-Paper.pdf,0,0,0
1282735,System and method for providing a mobile input device,2003,Zhengyou Zhang and Ying Shan and Steven AN Shafer and Ying Wu,,,,,,(57) ABSTRACT A vision-based gesture interface System. which employs an arbitrary quadrangle-shaped panel and a pointer tip like a fingertip as an intuitive input device. Taking advantage of the panel. the System can fulfill many tasks Such as control ling a remote and large display. and Simulating a physical keyboard. Users can naturally use their fingers and other pointer tips to issue commands and type texts. The System is facilitated by accurately and reliably tracking the panel and the pointer tip and detecting clicking and dragging actions.,True,4oXBp9UAAAAJ:IjCSPb-OGe4C,143,https://patents.google.com/patent/US6594616B2/en,3155964882828495538,/scholar?cites=3155964882828495538,,,https://patentimages.storage.googleapis.com/aa/3c/80/f6edbdf63940ad/US6594616.pdf,0,0,0
1282736,Robust and rapid generation of animated faces from video images: A model-based modeling approach,2004,Zhengyou Zhang and Zicheng Liu and Dennis Adler and Michael F Cohen and Erik Hanson and Ying Shan,58,International journal of computer vision,2,93-119,Kluwer Academic Publishers,We have developed an easy-to-use and cost-effective system to construct textured 3D animated face models from videos with minimal user interaction. This is a particularly challenging task for faces due to a lack of prominent textures. We develop a robust system by following a model-based approach: we make full use of generic knowledge of faces in head motion determination. head tracking. model fitting. and multiple-view bundle adjustment. Our system first takes. with an ordinary video camera. images of a face of a person sitting in front of the camera turning their head from one side to the other. After five manual clicks on two images to indicate the position of the eye corners. nose tip and mouth corners. the system automatically generates a realistic looking 3D human head model that can be animated immediately (different poses. facial expressions and talking). A user. with a PC and a video camera. can …,True,4oXBp9UAAAAJ:9yKSN-GCB0IC,134,https://link.springer.com/article/10.1023/B:VISI.0000015915.50080.85,16203562822576481425,/scholar?cites=16203562822576481425,,,https://www.researchgate.net/profile/Michael_Cohen12/publication/220659369_Robust_and_Rapid_Generation_of_Animated_Faces_from_Video_Images_A_Model-Based_Modeling_Approach/links/00b49520a6f144c3b4000000.pdf,0,0,0
1282737,A two-stage approach to people and vehicle detection with HOG-based SVM,2006,Feng Han and Ying Shan and Ryan Cekander and Harpreet S Sawhney and Rakesh Kumar,,Performance Metrics for Intelligent Systems 2006 Workshop,,133-140,,In this paper. we present a two-stage approach to robustly detect people and vehicles in static images using extended histogram of oriented gradient (HOG) and SVM for classification. The first stage is focus of attention generation. in which possible people and vehicle locations are hypothesized. This step uses stereo cue and generates potential target locations using some prior knowledge about what people and vehicle may look like in the depth map of the whole scene. The second stage is hypothesis verification. In this stage. all the hypothesis are verified by a strong classifier using extended HOG feature and SVM. which is robust to the wide range of variations of poses and viewpoints within people and vehicles. By adaptively combining the two stages. the final system achieves both speeding up and performance improvement. The system has been tested on some challenging datasets and illustrates good performance.,True,4oXBp9UAAAAJ:eQOLeE2rZwMC,129,https://www.nist.gov/system/files/documents/el/isd/ks/Final_PerMIS_2006_Proceedings.pdf#page=135,4908113086816570010,/scholar?cites=4908113086816570010,,,https://www.nist.gov/system/files/documents/el/isd/ks/Final_PerMIS_2006_Proceedings.pdf#page=135,0,0,0
1282738,Incremental motion estimation through modified bundle adjustment,2003,Zhengyou Zhang and Ying Shan,2,,,II-343,IEEE,An incremental motion estimation scheme for long image sequence analysis is introduced. It applies to a sliding window of triplet images and maintains local motion consistency without resort to post-concatenation. This is possible thanks to our newly developed local process called three-view partial bundle adjustment. Unlike previous approaches that rely only on point matches across three or more views. our local process also takes into account all available two-view matches. leading to more accurate motion estimation. For sparse image sequences. two-view matches are very reliable and it becomes even more important to use them since the number of matches across more views decreases quickly. In this case. our incremental method can produce results very close to those obtained with a global bundle adjustment but in a fraction of time. Experiments with both synthetic and real data have been conducted to …,True,4oXBp9UAAAAJ:WF5omc3nYNoC,128,https://ieeexplore.ieee.org/abstract/document/1246687/,15666682968175323138,/scholar?cites=15666682968175323138,,,,0,0,0
1282739,Rapid object indexing using locality sensitive hashing and joint 3D-signature space estimation,2006,Bogdan Matei and Ying Shan and Harpreet S Sawhney and Yi Tan and Rakesh Kumar and Daniel Huber and Martial Hebert,28,IEEE Transactions on Pattern Analysis and Machine Intelligence,7,1111-1126,IEEE,We propose a new method for rapid 3D object indexing that combines feature-based methods with coarse alignment-based matching techniques. Our approach achieves a sublinear complexity on the number of models. maintaining at the same time a high degree of performance for real 3D sensed data that is acquired in largely uncontrolled settings. The key component of our method is to first index surface descriptors computed at salient locations from the scene into the whole model database using the locality sensitive hashing (LSH). a probabilistic approximate nearest neighbor method. Progressively complex geometric constraints are subsequently enforced to further prune the initial candidates and eliminate false correspondences due to inaccuracies in the surface descriptors and the errors of the LSH algorithm. The indexed models are selected based on the MAP rule using posterior probability of the models …,True,4oXBp9UAAAAJ:qjMakFHDy7sC,124,https://ieeexplore.ieee.org/abstract/document/1634342/,7776088227165371480,/scholar?cites=7776088227165371480,,,,0,0,0
1282740,Unsupervised learning of discriminative edge measures for vehicle matching between nonoverlapping cameras,2008,Ying Shan and Harpreet S Sawhney and Rakesh Kumar,30,IEEE transactions on pattern analysis and machine intelligence,4,700-711,IEEE,This paper proposes a novel unsupervised algorithm learning discriminative features in the context of matching road vehicles between two nonoverlapping cameras. The matching problem is formulated as a same-different classification problem; which aims to compute the probability of vehicle images from two distinct cameras being from the same vehicle or different vehicle(s). We employ a novel measurement vector that consists of three independent edge-based measures and their associated robust measures computed from a pair of aligned vehicle edge maps. The weight of each measure is determined by an unsupervised learning algorithm that optimally separates the same-different classes in the combined measurement space. This is achieved with a weak classification algorithm that automatically collects representative samples from same-different classes. followed by a more discriminative classifier based …,True,4oXBp9UAAAAJ:Se3iqnhoufwC,96,https://ieeexplore.ieee.org/abstract/document/4359343/,16227014282234296880,/scholar?cites=16227014282234296880,,,,0,0,0
1282741,System and method for transforming an ordinary computer monitor into a touch screen,2008,Zhengyou Zhang and Ying Shan,,,,,,A system and method for turning a regular computer monitor screen into a touch screen using an ordinary camera. It includes an image-screen mapping procedure to correct for the non-flatness of the computer screen. It also includes a segmentation method to distinguish the foreground. for example an indicator such as a finger. from the background of a computer screen. Additionally. this system and method includes a robust technique of finding the tip point location of the indicator (such as the finger tip). The screen coordinates of the tip point are then used to control the position of the system indicator.,True,4oXBp9UAAAAJ:QIV2ME_5wuYC,94,https://patents.google.com/patent/US7342572B2/en,3706368373967380170,/scholar?cites=3706368373967380170,,,https://patentimages.storage.googleapis.com/83/c3/9d/9955b85a7aac06/US7342572.pdf,0,0,0
1282742,View invariant human action recognition using histograms of 3d joints,2012,Lu Xia and Chia-Chih Chen and Jake K Aggarwal,,,,20-27,IEEE,In this paper. we present a novel approach for human action recognition with histograms of 3D joint locations (HOJ3D) as a compact representation of postures. We extract the 3D skeletal joint locations from Kinect depth maps using Shotton et al.'s method [6]. The HOJ3D computed from the action depth sequences are reprojected using LDA and then clustered into k posture visual words. which represent the prototypical poses of actions. The temporal evolutions of those visual words are modeled by discrete hidden Markov models (HMMs). In addition. due to the design of our spherical coordinate system and the robust 3D skeleton estimation from Kinect. our method demonstrates significant view invariance on our 3D action dataset. Our dataset is composed of 200 3D sequences of 10 indoor activities performed by 10 individuals in varied views. Our method is real-time and achieves superior results on the …,True,0Hr1SOUAAAAJ:aqlVkmm33-oC,1373,https://ieeexplore.ieee.org/abstract/document/6239233/,2262400623113147225,/scholar?cites=2262400623113147225,,,https://groups.io/g/miners/attachment/38/0/view_inv_hoj.pdf,0,0,0
1282743,Human detection using depth information by kinect,2011,Lu Xia and Chia-Chih Chen and Jake K Aggarwal,,,,15-22,IEEE,Conventional human detection is mostly done in images taken by visible-light cameras. These methods imitate the detection process that human use. They use features based on gradients. such as histograms of oriented gradients (HOG). or extract interest points in the image. such as scale-invariant feature transform (SIFT). etc. In this paper. we present a novel human detection method using depth information taken by the Kinect for Xbox 360. We propose a model based approach. which detects humans using a 2-D head contour model and a 3-D head surface model. We propose a segmentation scheme to segment the human from his/her surroundings and extract the whole contours of the figure based on our detection point. We also explore the tracking algorithm based on our detection result. The methods are tested on our database taken by the Kinect in our lab and present superior results.,True,0Hr1SOUAAAAJ:IjCSPb-OGe4C,700,https://ieeexplore.ieee.org/abstract/document/5981811/,18162130644134749386,/scholar?cites=18162130644134749386,,,https://isl2-dev.cp.eng.chula.ac.th/sites/default/files/Human%20Detection%20Using%20Depth%20Information%20by%20Kinect.pdf,0,0,0
1282744,A large-scale benchmark dataset for event recognition in surveillance video,2011,Sangmin Oh and Anthony Hoogs and Amitha Perera and Naresh Cuntoor and Chia-Chih Chen and Jong Taek Lee and Saurajit Mukherjee and JK Aggarwal and Hyungtae Lee and Larry Davis and Eran Swears and Xioyang Wang and Qiang Ji and Kishore Reddy and Mubarak Shah and Carl Vondrick and Hamed Pirsiavash and Deva Ramanan and Jenny Yuen and Antonio Torralba and Bi Song and Anesco Fong and Amit Roy-Chowdhury and Mita Desai,,,,3153-3160,IEEE,We introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (CVER) in outdoor areas with wide coverage. Previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15. 8]. Datasets have been developed for movies [11] and sports [12]. but. these actions and scene conditions do not apply effectively to surveillance videos. Our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. The dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. This data is accompanied by detailed annotations which include both moving object tracks and event examples. which will provide …,True,0Hr1SOUAAAAJ:2osOgNQ5qMEC,632,https://ieeexplore.ieee.org/abstract/document/5995586/,7107034697157985163,/scholar?cites=7107034697157985163,,,https://apps.dtic.mil/sti/pdfs/ADA554181.pdf,0,0,0
1282745,An overview of contest on semantic description of human activities (SDHA) 2010,2010,M Ryoo and Chia-Chih Chen and J Aggarwal and Amit Roy-Chowdhury,,"Recognizing Patterns in Signals, Speech, Images and Videos",,270-285,Springer Berlin/Heidelberg,This paper summarizes results of the 1st Contest on Semantic Description of Human Activities (SDHA). in conjunction with ICPR 2010. SDHA 2010 consists of three types of challenges. High-level Human Interaction Recognition Challenge. Aerial View Activity Classification Challenge. and Wide-Area Activity Search and Recognition Challenge. The challenges are designed to encourage participants to test existing methodologies and develop new approaches for complex human activity recognition scenarios in realistic environments. We introduce three new public datasets through these challenges. and discuss results of the state-of-the-art activity recognition systems designed and implemented by the contestants. A methodology using a spatio-temporal voting [19] successfully classified segmented videos in the UT-Interaction datasets. but had a difficulty correctly localizing activities from continuous videos …,True,0Hr1SOUAAAAJ:u-x6o8ySG0sC,130,https://link.springer.com/chapter/10.1007/978-3-642-17711-8_28,3674908482703363953,/scholar?cites=3674908482703363953,,,https://core.ac.uk/download/pdf/205222697.pdf,0,0,0
1282746,Detection of abandoned objects in crowded environments,2007,Medha Bhargava and Chia-Chih Chen and Michael S Ryoo and Jake K Aggarwal,,,,271-276,IEEE,With concerns about terrorism and global security on the rise. it has become vital to have in place efficient threat detection systems that can detect and recognize potentially dangerous situations. and alert the authorities to take appropriate action. Of particular significance is the case of unattended objects in mass transit areas. This paper describes a general framework that recognizes the event of someone leaving a piece of baggage unattended in forbidden areas. Our approach involves the recognition of four sub-events that characterize the activity of interest. When an unaccompanied bag is detected. the system analyzes its history to determine its most likely owner(s). where the owner is defined as the person who brought the bag into the scene before leaving it unattended. Through subsequent frames. the system keeps a lookout for the owner. whose presence in or disappearance from the scene defines the …,True,0Hr1SOUAAAAJ:u5HHmVD_uO8C,74,https://ieeexplore.ieee.org/abstract/document/4425322/,1647127460258874450,/scholar?cites=1647127460258874450,,,https://repositories.lib.utexas.edu/bitstream/handle/2152/41563/txu-oclc-163829990.pdf?sequence=2,0,0,0
1282747,Recognizing human action from a far field of view,2009,Chia-Chih Chen and JK Aggarwal,,,,1-7,IEEE,In this paper. we present a novel descriptor to characterize human action when it is being observed from a far field of view. Visual cues are usually sparse and vague under this scenario. An action sequence is divided into overlapped spatial-temporal volumes to make reliable and comprehensive use of the observed features. Within each volume. we represent successive poses by time series of Histogram of Oriented Gradients (HOG) and movements by time series of Histogram of Oriented Optical Flow (HOOF). Supervised Principle Component Analysis (SPCA) is applied to seek a subset of discriminantly informative principle components (PCs) to reduce the dimension of histogram vectors without loss of accuracy. The final action descriptor is formed by concatenating sequences of SPCA projected HOG and HOOF features. A Support Vector Machines (SVM) classifier is trained to perform action classification. We …,True,0Hr1SOUAAAAJ:d1gkVwhDpl0C,72,https://ieeexplore.ieee.org/abstract/document/5399231/,6785785740652511818,/scholar?cites=6785785740652511818,,,http://cvrc.ece.utexas.edu/Publications/Chen_WMVC09.pdf,0,0,0
1282748,Human shadow removal with unknown light source,2010,Chia-Chih Chen and Jake K Aggarwal,,,,2407-2410,IEEE,In this paper. we present a shadow removal technique which effectively eliminates a human shadow cast from an unknown direction of light source. A multi-cue shadow descriptor is proposed to characterize the distinctive properties of shadows. We employ a 3-stage process to detect then remove shadows. Our algorithm improves the shadow detection accuracy by imposing the spatial constraint between the foreground subregions of human and shadow. We collect a dataset containing 81 human-shadow images for evaluation. Both descriptor ROC curves and qualitative results demonstrate the superior performance of our method.,True,0Hr1SOUAAAAJ:UeHWp8X0CEIC,56,https://ieeexplore.ieee.org/abstract/document/5595737/,14503289594091534355,/scholar?cites=14503289594091534355,,,https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2010/data/4109c407.pdf,0,0,0
1282749,Detection of object abandonment using temporal logic,2009,Medha Bhargava and Chia-Chih Chen and Michael S Ryoo and Jake K Aggarwal,20,Machine Vision and Applications,5,271-281,Springer-Verlag,This paper describes a novel framework for a smart threat detection system that uses computer vision to capture. exploit and interpret the temporal flow of events related to the abandonment of an object. Our approach uses contextual information along with an analysis of the causal progression of events to decide whether or not an alarm should be raised. When an unattended object is detected. the system traces it back in time to determine and record who its most likely owner(s) may be. Through subsequent frames. the system searches the scene for the owner and issues an alert if no match is found for the owner over a given period of time. Our algorithm has been successfully tested on two benchmark datasets (PETS 2006 Benchmark Data. 2006; i-LIDS Dataset for AVSS. 2007). and yielded results that are substantially more accurate than similar systems developed by other academic and industrial …,True,0Hr1SOUAAAAJ:9yKSN-GCB0IC,48,https://link.springer.com/article/10.1007/s00138-008-0181-8,2741717808597345483,/scholar?cites=2741717808597345483,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.415.1314&rep=rep1&type=pdf,0,0,0
1282750,Modeling human activities as speech,2011,Chia-Chih Chen and JK Aggarwal,,,,3425-3432,IEEE,Human activity recognition and speech recognition appear to be two loosely related research areas. However. on a careful thought. there are several analogies between activity and speech signals with regard to the way they are generated. propagated. and perceived. In this paper. we propose a novel action representation. the action spectrogram. which is inspired by a common spectrographic representation of speech. Different from sound spectrogram. an action spectrogram is a space-time-frequency representation which characterizes the short-time spectral properties of body parts' movements. While the essence of the speech signal is the variation of air pressure in time. our method models activities as the likelihood time series of action associated local interest patterns. This low-level process is realized by learning boosted window classifiers from spatially quantized spatio-temporal interest features. We have …,True,0Hr1SOUAAAAJ:Y0pCki6q_DkC,44,https://ieeexplore.ieee.org/abstract/document/5995555/,5498897628399525684,/scholar?cites=5498897628399525684,,,https://core.ac.uk/download/pdf/192951692.pdf,0,0,0
1282751,UT-Tower dataset: aerial view activity classification challenge,2010,Chia-Chih Chen and MS Ryoo and JK Aggarwal,,,,,Online,,True,0Hr1SOUAAAAJ:LkGwnXOMwfcC,35,http://scholar.google.com/scholar?cluster=3740797896967735694&hl=en&oi=scholarr,3740797896967735694,/scholar?cites=3740797896967735694,,,,0,0,0
1282752,An adaptive background model initialization algorithm with objects moving at different depths,2008,Chia-Chih Chen and JK Aggarwal,,,,2664-2667,IEEE,Background subtraction is an essential element in most object tracking and video surveillance systems. The success of this low-level processing step is highly dependent on the quality of the background model maintained. Gutchess et al. [4] proposed a novel background initialization algorithm that utilizes local optical flow information to locate the stable interval (of intensity values) which is most likely to display background. However. it is found that the accuracy of the computed background is rather sensitive to the parameters used. In addition. their algorithm is not able to handle the scenario where objects are moving at different depths. In this paper. we propose an algorithm which is adaptive to the input sequence and is able to equalize the uneven effect caused by different object depths. Our algorithm is successfully tested on complex indoor and outdoor scenes with promising results.,True,0Hr1SOUAAAAJ:zYLM7Y9cAGgC,31,https://ieeexplore.ieee.org/abstract/document/4712342/,17102535221684919388,/scholar?cites=17102535221684919388,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.415.1224&rep=rep1&type=pdf,0,0,0
1282753,Why is real-world visual object recognition hard?,2008,Nicolas Pinto and David D Cox and James J DiCarlo,4,PLoS computational biology,1,e27,Public Library of Science,Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology. but ultimately match its performance on visual tasks. In recent years. “natural” images have become popular in the study of vision and have been used to show apparently impressive progress in building such models. Here. we challenge the use of uncontrolled “natural” images in guiding that progress. In particular. we show that a simple V1-like model—a neuroscientist's “null” model. which should perform poorly at real-world visual object recognition tasks—outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard. ostensibly natural image recognition test. As a counterpoint. we designed a “simpler” recognition test to better span the real-world variation in object pose. position. and scale. and we show that this test correctly exposes the inadequacy of the V1-like model. Taken together. these results demonstrate that tests based on uncontrolled natural images can be seriously misleading. potentially guiding progress in the wrong direction. Instead. we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition—real-world image variation.,True,eMwEEXUAAAAJ:u5HHmVD_uO8C,677,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0040027,1671911754162022090,/scholar?cites=1671911754162022090,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0040027,0,0,0
1282754,PyCUDA and PyOpenCL: A Scripting-Based Approach to GPU Run-Time Code Generation,2011,Andreas Klöckner and Nicolas Pinto and Yunsup Lee and Bryan Catanzaro and Paul Ivanov and Ahmed Fasih,,Parallel Computing,,,North-Holland,High-performance computing has recently seen a surge of interest in heterogeneous systems. with an emphasis on modern Graphics Processing Units (GPUs). These devices offer tremendous potential for performance and efficiency in important large-scale applications of computational science. However. exploiting this potential can be challenging. as one must adapt to the specialized and rapidly evolving computing environment currently exhibited by GPUs. One way of addressing this challenge is to embrace better techniques and develop tools tailored to their needs. This article presents one simple technique. GPU run-time code generation (RTCG). along with PyCUDA and PyOpenCL. two open-source toolkits that supports this technique.In introducing PyCUDA and PyOpenCL. this article proposes the combination of a dynamic. high-level scripting language with the massive performance of a GPU as a …,True,eMwEEXUAAAAJ:IjCSPb-OGe4C,642,https://www.sciencedirect.com/science/article/pii/S0167819111001281,13017018517442672444,/scholar?cites=13017018517442672444,,,https://arxiv.org/pdf/0911.3456,0,0,0
1282755,Deep neural networks rival the representation of primate IT cortex for core visual object recognition,2014,Charles F Cadieu and Ha Hong and Daniel LK Yamins and Nicolas Pinto and Diego Ardila and Ethan A Solomon and Najib J Majaj and James J DiCarlo,10,PLoS Comput Biol,12,e1003963,Public Library of Science,The primate visual system achieves remarkable visual object recognition performance even in brief presentations. and under changes to object exemplar. geometric transformations. and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel. recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear. however. whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison. a major difficulty has been a unifying metric that accounts for experimental limitations. such as the amount of noise. the number of neural recording sites. and the number of trials. and computational limitations. such as the complexity of the decoding classifier and the number of classifier training examples. In this work. we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology. we propose an extension of “kernel analysis” that measures the generalization accuracy as a function of representational complexity. Our evaluations show that. unlike previous bio-inspired models. the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore. we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT. and on measures of predicting individual IT multi-unit responses. Whether these …,True,eMwEEXUAAAAJ:4DMP91E08xMC,502,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003963,2934398626011762419,/scholar?cites=2934398626011762419,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003963,0,0,0
1282756,A high-throughput screening approach to discovering good forms of biologically inspired visual representation,2009,Nicolas Pinto and David Doukhan and James J DiCarlo and David D Cox,5,PLoS computational biology,11,e1000579,Public Library of Science,While many models of biological object recognition share a common set of “broad-stroke” properties. the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model—e.g.. the number of units per layer. the size of pooling kernels. exponents in normalization operations. etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high. the space of possible model instantiations goes largely unexplored. Thus. when a model fails to approach the abilities of biological visual systems. we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct “parts” have not been tuned correctly. assembled at sufficient scale. or provided with enough training. Here. we present a high-throughput approach to the exploration of such parameter sets. leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3's IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics. we explored thousands of potential network architectures and parameter instantiations. screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant. reproducible gains in performance across an array of basic object recognition tasks. consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand. we argue that this approach …,True,eMwEEXUAAAAJ:9yKSN-GCB0IC,326,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000579,17769708116539239591,/scholar?cites=17769708116539239591,,,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000579,0,0,0
1282757,Beyond simple features: A large-scale feature search approach to unconstrained face recognition,2011,Nicolas Pinto and David D Cox,25,IEEE Automated Face and Gesture Recognition (FG),,26-27,,,True,eMwEEXUAAAAJ:qjMakFHDy7sC,262,,3043405991756296652,/scholar?cites=3043405991756296652,,,,0,0,0
1282758,How far can you get with a modern face recognition test set using only simple features?,2009,Nicolas Pinto and James J DiCarlo and David D Cox,,,,2591-2598,IEEE,In recent years. large databases of natural images have become increasingly popular in the evaluation of face and object recognition algorithms. However. Pinto et al. previously illustrated an inherent danger in using such sets. showing that an extremely basic recognition system. built on a trivial feature set. was able to take advantage of low-level regularities in popular object and face recognition sets. performing on par with many state-of-the-art systems. Recently. several groups have raised the performance “bar” for these sets. using more advanced classification tools. However. it is difficult to know whether these improvements are due to progress towards solving the core computational problem. or are due to further improvements in the exploitation of low-level regularities. Here. we show that even modest optimization of the simple model introduced by Pinto et al. using modern multiple kernel learning (MKL …,True,eMwEEXUAAAAJ:u-x6o8ySG0sC,255,https://ieeexplore.ieee.org/abstract/document/5206605/,15600169663743233851,/scholar?cites=15600169663743233851,,,https://dspace.mit.edu/bitstream/handle/1721.1/59976/Pinto-2009-How%20far%20can%20you%20get%20with%20a%20modern%20face%20recognition%20test%20set%20using%20only%20simple%20features.pdf?sequence=2&isAllowed=y,0,0,0
1282759,Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook,2011,Nicolas Pinto and Zak Stone and Todd Zickler and David Cox,,,,35-42,IEEE,Biological visual systems are currently unrivaled by artificial systems in their ability to recognize faces and objects in highly variable and cluttered real-world environments. Biologically-inspired computer vision systems seek to capture key aspects of the computational architecture of the brain. and such approaches have proven successful across a range of standard object and face recognition tasks (e.g. [23. 8. 9. 18]). Here. we explore the effectiveness of these algorithms on a large-scale unconstrained real-world face recognition problem based on images taken from the Face-book social networking website. In particular. we use a family of biologically-inspired models derived from a high-throughput feature search paradigm [19. 15] to tackle a face identification task with up to one hundred individuals (a number that approaches the reasonable size of real-world social networks). We show that these models yield high …,True,eMwEEXUAAAAJ:eQOLeE2rZwMC,115,https://ieeexplore.ieee.org/abstract/document/5981788/,5296389389041196491,/scholar?cites=5296389389041196491,,,https://projects.iq.harvard.edu/files/zickler/files/scalingfacerec_wbcv2011_0.pdf,0,0,0
1282760,Machine learning for predictive auto-tuning with boosted regression trees,2012,James Bergstra and Nicolas Pinto and David Cox,,,,1-9,IEEE,The rapidly evolving landscape of multicore architectures makes the construction of efficient libraries a daunting task. A family of methods known collectively as “auto-tuning” has emerged to address this challenge. Two major approaches to auto-tuning are empirical and model-based: empirical autotuning is a generic but slow approach that works by measuring runtimes of candidate implementations. model-based auto-tuning predicts those runtimes using simplified abstractions designed by hand. We show that machine learning methods for non-linear regression can be used to estimate timing models from data. capturing the best of both approaches. A statistically-derived model offers the speed of a model-based approach. with the generality and simplicity of empirical auto-tuning. We validate our approach using the filterbank correlation kernel described in Pinto and Cox [2012]. where we find that 0.1 seconds of …,True,eMwEEXUAAAAJ:0EnyYjriUFMC,81,https://ieeexplore.ieee.org/abstract/document/6339587/,16170797004929305485,/scholar?cites=16170797004929305485,,,http://www.rowland.org/rjf/cox/pdfs/inpar2012.pdf,0,0,0
1282761,Comparing state-of-the-art visual features on invariant object recognition tasks,2011,Nicolas Pinto and Youssef Barhomi and David D Cox and James J DiCarlo,,,,463-470,IEEE,Tolerance (“invariance”) to identity-preserving image variation (e.g. variation in position. scale. pose. illumination) is a fundamental problem that any visual object recognition system. biological or engineered. must solve. While standard natural image database benchmarks are useful for guiding progress in computer vision. they can fail to probe the ability of a recognition system to solve the invariance problem. Thus. to understand which computational approaches are making progress on solving the invariance problem. we compared and contrasted a variety of state-of-the-art visual representations using synthetic recognition tasks designed to systematically probe invariance. We successfully re-implemented a variety of state-of-the-art visual representations and confirmed their published performance on a natural image benchmark. We here report that most of these representations perform poorly on invariant …,True,eMwEEXUAAAAJ:Tyk-4Ss8FVUC,77,https://ieeexplore.ieee.org/abstract/document/5711540/,2191474779843187363,/scholar?cites=2191474779843187363,,,https://dspace.mit.edu/bitstream/handle/1721.1/72169/Pinto%20et%20al_IEEE2011_WACV.pdf?sequence=1,0,0,0
1282762,Establishing good benchmarks and baselines for face recognition,2008,Nicolas Pinto and James J DiCarlo and David D Cox,,,,,,"Progress in face recognition relies critically on the creation of test sets against which the performance of various approaches can be evaluated. A good set must capture the essential elements of what makes the problem hard. while conforming to practical scale limitations. However. these goals are often deceptively difficult to achieve. In the related area of object recognition. Pinto et al. [2] demonstrated the potential dangers of using a large. uncontrolled natural image set. showing that an extremely rudimentary vision system (inspired by the early stages of visual processing in the brain) was able to perform on par with many state-of-the-art vision systems on the popular Caltech101 object set [3]. At the same time. this same rudimentary system was easily defeated by an ostensibly ""simpler"" synthetic recognition test designed to better span the range of real world variation in object pose. position. scale. etc. These results suggested that image sets that look ""natural"" to human observers may nonetheless fail to properly embody the problem of interest. and that care must be taken to establish baselines against which performance can be judged. Here. we repeat this approach for the ""Labeled Faces in the Wild"" (LFW) dataset [1]. and for a collection of standard face recognition tests. The goal of the present work is not to compete in the LFW challenge. per se. but to provide a baseline against which the performance of other systems can be judged. In particular. we found that our rudimentary ""baseline"" vision system was able to achieve ~68% correct performance on the LFW challenge. substantially higher than a pure ""chance"" baseline. We argue that this …",True,eMwEEXUAAAAJ:2osOgNQ5qMEC,58,https://hal.inria.fr/inria-00326732/,2434177734474304525,/scholar?cites=2434177734474304525,,,https://hal.inria.fr/docs/00/32/67/32/PDF/pinto-dicarlo-cox-eccv-2008-lfw_final.pdf,0,0,0
1282763,Experience grounds language,2020,Yonatan Bisk and Ari Holtzman and Jesse Thomason and Jacob Andreas and Yoshua Bengio and Joyce Chai and Mirella Lapata and Angeliki Lazaridou and Jonathan May and Aleksandr Nisnevich and Nicolas Pinto and Joseph Turian,,arXiv preprint arXiv:2004.10151,,,,Successful linguistic communication relies on a shared experience of the world. and it is this shared experience that makes utterances meaningful. Despite the incredible effectiveness of language processing models trained on text alone. today's best systems still make mistakes that arise from a failure to relate language to the physical world it describes and to the social interactions it facilitates.Natural Language Processing is a diverse field. and progress throughout its development has come from new representational theories. modeling techniques. data collection paradigms. and tasks. We posit that the present success of representation learning approaches trained on large text corpora can be deeply enriched from the parallel tradition of research on the contextual and social nature of language.,True,eMwEEXUAAAAJ:TQgYirikUcIC,54,https://arxiv.org/abs/2004.10151,3734668471751920487,/scholar?cites=3734668471751920487,,,https://arxiv.org/pdf/2004.10151.pdf%22,0,0,0
1282764,DARTS: Differentiable architecture search,2018,Hanxiao Liu and Karen Simonyan and Yiming Yang,,"International Conference on Learning Representations, ICLR 2019",,,,This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space. our method is based on the continuous relaxation of the architecture representation. allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10. ImageNet. Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling. while being orders of magnitude faster than state-of-the-art non-differentiable techniques. Our implementation has been made publicly available to facilitate further research on efficient architecture search algorithms.,True,IMkVH_8AAAAJ:HDshCWvjkbEC,1411,https://arxiv.org/abs/1806.09055,895422516420751823,/scholar?cites=895422516420751823,,,https://arxiv.org/pdf/1806.09055,0,0,0
1282765,Hierarchical representations for efficient architecture search,2017,Hanxiao Liu and Karen Simonyan and Oriol Vinyals and Chrisantha Fernando and Koray Kavukcuoglu,,"International Conference on Learning Representations, ICLR 2018",,,,We explore efficient neural architecture search methods and show that a simple yet powerful evolutionary algorithm can discover new architectures with excellent performance. Our approach combines a novel hierarchical genetic representation scheme that imitates the modularized design pattern commonly adopted by human experts. and an expressive search space that supports complex topologies. Our algorithm efficiently discovers architectures that outperform a large number of manually designed models for image classification. obtaining top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet. which is competitive with the best existing neural architecture search approaches. We also present results using random search. achieving 0.3% less top-1 accuracy on CIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36 hours down to 1 hour.,True,IMkVH_8AAAAJ:qUcmZB5y_30C,525,https://arxiv.org/abs/1711.00436,8727964422666186494,/scholar?cites=8727964422666186494,,,https://arxiv.org/pdf/1711.00436,0,0,0
1282766,RACE: Large-scale reading comprehension dataset from examinations,2017,Guokun Lai and Qizhe Xie and Hanxiao Liu and Yiming Yang and Eduard Hovy,,,,,,We present RACE. a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18. RACE consists of near 28.000 passages and near 100.000 questions generated by human experts (English instructors). and covers a variety of topics which are carefully designed for evaluating the students' ability in understanding and reasoning. In particular. the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension. and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at this http URL and the code is available at this https URL.,True,IMkVH_8AAAAJ:dhFuZR0502QC,442,https://arxiv.org/abs/1704.04683,16999749681986953093,/scholar?cites=16999749681986953093,,,https://arxiv.org/pdf/1704.04683,0,0,0
1282767,Gated-attention readers for text comprehension,2016,Bhuwan Dhingra* and Hanxiao Liu* and Zhilin Yang and William W Cohen and Ruslan Salakhutdinov,,,,,,In this paper we study the problem of answering cloze-style questions over documents. Our model. the Gated-Attention (GA) Reader. integrates a multi-hop architecture with a novel attention mechanism. which is based on multiplicative interactions between the query embedding and the intermediate states of a recurrent neural network document reader. This enables the reader to build query-specific representations of tokens in the document for accurate answer selection. The GA Reader obtains state-of-the-art results on three benchmarks for this task--the CNN\& Daily Mail news stories and the Who Did What dataset. The effectiveness of multiplicative interaction is demonstrated by an ablation study. and by comparing to alternative compositional operators for implementing the gated-attention. The code is available at this https URL.,True,IMkVH_8AAAAJ:4TOpqqG69KYC,335,https://arxiv.org/abs/1606.01549,3290403078094631843,/scholar?cites=3290403078094631843,,,https://arxiv.org/pdf/1606.01549,0,0,0
1282768,Modeling long- and short-term temporal patterns with deep neural networks,2017,Guokun Lai and Wei-Cheng Chang and Yiming Yang and Hanxiao Liu,,"International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018",,,,Multivariate time series forecasting is an important machine learning problem across many domains. including predictions of solar plant energy output. electricity consumption. and traffic jam situation. Temporal data arise in these real-world applications often involves a mixture of long-term and short-term patterns. for which traditional approaches such as Autoregressive models and Gaussian Process may fail. In this paper. we proposed a novel deep learning framework. namely Long-and Short-term Time-series network (LSTNet). to address this open challenge. LSTNet uses the Convolution Neural Network (CNN) and the Recurrent Neural Network (RNN) to extract short-term local dependency patterns among variables and to discover long-term patterns for time series trends. Furthermore. we leverage traditional autoregressive model to tackle the scale insensitive problem of the neural network model. In our …,True,IMkVH_8AAAAJ:QIV2ME_5wuYC,289,https://dl.acm.org/doi/abs/10.1145/3209978.3210006,33118695529112396,/scholar?cites=33118695529112396,,,https://arxiv.org/pdf/1703.07015,0,0,0
1282769,Analogical inference for multi-relational embeddings,2017,Hanxiao Liu and Yuexin Wu and Yiming Yang,,,,,,Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the analogical properties of the embedded entities and relations. By formulating the objective function in a differentiable fashion. our model enjoys both its theoretical power and computational scalability. and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore. the model offers an elegant unification of several well-known methods in multi-relational embedding. which can be proven to be special instantiations of our framework.,True,IMkVH_8AAAAJ:L8Ckcad2t8MC,187,http://proceedings.mlr.press/v70/liu17d.html,4290007913375024637,/scholar?cites=4290007913375024637,,,http://proceedings.mlr.press/v70/liu17d/liu17d.pdf,0,0,0
1282770,Rethinking pre-training and self-training,2020,Barret Zoph and Golnaz Ghiasi and Tsung-Yi Lin and Yin Cui and Hanxiao Liu and Ekin Dogus Cubuk and Quoc Le,,Advances in Neural Information Processing Systems (NeurIPS),,,,Pre-training is a dominant paradigm in computer vision. For example. supervised ImageNet pre-training is commonly used to initialize the backbones of object detection and segmentation models. He et al.. however. show a surprising result that ImageNet pre-training has limited impact on COCO object detection. Here we investigate self-training as another method to utilize additional data on the same setup and contrast it against ImageNet pre-training. Our study reveals the generality and flexibility of self-training with three additional insights: 1) stronger data augmentation and more labeled data further diminish the value of pre-training. 2) unlike pre-training. self-training is always helpful when using stronger data augmentation. in both low-data and high-data regimes. and 3) in the case that pre-training is helpful. self-training improves upon pre-training. For example. on the COCO object detection dataset. pre-training benefits when we use one fifth of the labeled data. and hurts accuracy when we use all labeled data. Self-training. on the other hand. shows positive improvements from+ 1.3 to+ 3.4 AP across all dataset sizes. In other words. self-training works well exactly on the same setup that pre-training does not work (using ImageNet to help COCO). On the PASCAL segmentation dataset. which is a much smaller dataset than COCO. though pre-training does help significantly. self-training improves upon the pre-trained model. On COCO object detection. we achieve 54.3 AP. an improvement of+ 1.5 AP over the strongest SpineNet model. On PASCAL segmentation. we achieve 90.5 mIOU. an improvement of+ 1.5% mIOU over the previous state-of …,True,IMkVH_8AAAAJ:M3NEmzRMIkIC,65,https://arxiv.org/abs/2006.06882,14309100461064079035,/scholar?cites=14309100461064079035,,,https://arxiv.org/pdf/2006.06882,0,0,0
1282771,Concept graph learning from educational data,2015,Yiming Yang and Hanxiao Liu and Jaime Carbonell and Wanli Ma,,,,,ACM,This paper addresses an open challenge in educational data mining. ie. the problem of using observed prerequisite relations among courses to learn a directed universal concept graph. and using the induced graph to predict unobserved prerequisite relations among a broader range of courses. This is particularly useful to induce prerequisite relations among courses from different providers (universities. MOOCs. etc.). We propose a new framework for inference within and across two graphs---at the course level and at the induced concept level---which we call Concept Graph Learning (CGL). In the training phase. our system projects the course-level links onto the concept space to induce directed concept links; in the testing phase. the concept links are used to predict (unobserved) prerequisite links for test-set courses within the same institution or across institutions. The dual mappings enable our system to perform …,True,IMkVH_8AAAAJ:Zph67rFs4hoC,57,https://dl.acm.org/doi/abs/10.1145/2684822.2685292,4221142366336022548,/scholar?cites=4221142366336022548,,,https://pdfs.semanticscholar.org/a710/59c42397c17582cf2ebb1b2b6a878f5aa572.pdf,0,0,0
1282772,BigNAS: Scaling up neural architecture search with big single-stage models,2020,Jiahui Yu and Pengchong Jin and Hanxiao Liu and Gabriel Bender and Pieter-Jan Kindermans and Mingxing Tan and Thomas Huang and Xiaodan Song and Ruoming Pang and Quoc Le,,European Conference on Computer Vision (ECCV),,,,Neural architecture search (NAS) has shown promising results discovering models that are both accurate and fast. For NAS. training a one-shot model has become a popular strategy to rank the relative quality of different architectures (child models) using a single set of shared weights. However. while one-shot model weights can effectively rank different network architectures. the absolute accuracies from these shared weights are typically far below those obtained from stand-alone training. To compensate. existing methods assume that the weights must be retrained. finetuned. or otherwise post-processed after the search is completed. These steps significantly increase the compute requirements and complexity of the architecture search and model deployment. In this work. we propose BigNAS. an approach that challenges the conventional wisdom that post-processing of the weights is necessary to get good …,True,IMkVH_8AAAAJ:iH-uZ7U-co4C,38,https://link.springer.com/chapter/10.1007/978-3-030-58571-6_41,14713025129873223206,/scholar?cites=14713025129873223206,,,https://arxiv.org/pdf/2003.11142,0,0,0
1282773,Learning concept graphs from online educational data,2016,Hanxiao Liu and Wanli Ma and Yiming Yang and Jaime Carbonell,55,Journal of Artificial Intelligence Research (JAIR),,1059-1090,,This paper addresses an open challenge in educational data mining. i.e.. the problem of automatically mapping online courses from different providers (universities. MOOCs. etc.) onto a universal space of concepts. and predicting latent prerequisite dependencies (directed links) among both concepts and courses. We propose a novel approach for inference within and across course-level and concept-level directed graphs. In the training phase. our system projects partially observed course-level prerequisite links onto directed concept-level links; in the testing phase. the induced concept-level links are used to infer the unknown course-level prerequisite links. Whereas courses may be specific to one institution. concepts are shared across different providers. The bi-directional mappings enable our system to perform interlingua-style transfer learning. e.g. treating the concept graph as the interlingua and transferring the prerequisite relations across universities via the interlingua. Experiments on our newly collected datasets of courses from MIT. Caltech. Princeton and CMU show promising results.,True,IMkVH_8AAAAJ:_kc_bZDykSQC,36,https://www.jair.org/index.php/jair/article/view/11000,1327650130949410384,/scholar?cites=1327650130949410384,,,https://www.jair.org/index.php/jair/article/view/11000/26159,0,0,0
1282774,Adaptive smoothed online multi-task learning,2016,Keerthiram Murugesan* and Hanxiao Liu* and Jaime Carbonell and Yiming Yang,,,,,,This paper addresses the challenge of jointly learning both the per-task model parameters and the inter-task relationships in a multi-task online learning setting. The proposed algorithm features probabilistic interpretation. efficient updating rules and flexible modulation on whether learners focus on their specific task or on jointly address all tasks. The paper also proves a sub-linear regret bound as compared to the best linear predictor in hindsight. Experiments over three multitask learning benchmark datasets show advantageous performance of the proposed approach over several state-of-the-art online multi-task learning baselines.,True,IMkVH_8AAAAJ:Wp0gIr-vW9MC,32,https://www.cs.cmu.edu/~jgc/publication/smoothedlearning.pdf,11434297261770086687,/scholar?cites=11434297261770086687,,,https://www.cs.cmu.edu/~jgc/publication/smoothedlearning.pdf,0,0,0
1282775,Practical image and video processing using MATLAB,2011,Oge Marques,,,,,John Wiley & Sons,UP-TO-DATE. TECHNICALLY ACCURATE COVERAGE OF ESSENTIAL TOPICS IN IMAGE AND VIDEO PROCESSING This is the first book to combine image and video processing with a practical MATLAB®-oriented approach in order to demonstrate the most important image and video techniques and algorithms. Utilizing minimal math. the contents are presented in a clear. objective manner. emphasizing and encouraging experimentation. The book has been organized into two parts. Part I: Image Processing begins with an overview of the field. then introduces the fundamental concepts. notation. and terminology associated with image representation and basic image processing operations. Next. it discusses MATLAB® and its Image Processing Toolbox with the start of a series of chapters with hands-on activities and step-by-step tutorials. These chapters cover image acquisition and digitization; arithmetic. logic. and geometric operations; point-based. histogram-based. and neighborhood-based image enhancement techniques; the Fourier Transform and relevant frequency-domain image filtering techniques; image restoration; mathematical morphology; edge detection techniques; image segmentation; image compression and coding; and feature extraction and representation. Part II: Video Processing presents the main concepts and terminology associated with analog video signals and systems. as well as digital video formats and standards. It then describes the technically involved problem of standards conversion. discusses motion estimation and compensation techniques. shows how video sequences can be filtered. and concludes with an …,True,ZgWULzYAAAAJ:9ZlFYXVOiuMC,390,http://books.google.com/books?hl=en&lr=&id=xzD25QEo8qYC&oi=fnd&pg=PR21&dq=info:537t8rYEMMcJ:scholar.google.com&ots=45M95IViv9&sig=tmWeJNuAuHtcxgXwx_ZoUAnMwNk,14352977196235980519,/scholar?cites=14352977196235980519,,,https://cds.cern.ch/record/1481034/files/9780470048153_TOC.pdf,0,0,0
1282776,Processamento digital de imagens,1999,Ogê Marques Filho and Hugo Vieira Neto,,,,,Brasport,1.2 Um sistema de processamento de imagens e seus componentes 2 1.3 O sistema visual humano 5,True,ZgWULzYAAAAJ:u5HHmVD_uO8C,360,http://projetoaprendizagemgrupo4.pbworks.com/w/file/fetch/96395952/Processamento%20Digital%20de%20Imagens.pdf,5123244330772027243,/scholar?cites=5123244330772027243,,,http://projetoaprendizagemgrupo4.pbworks.com/w/file/fetch/96395952/Processamento%20Digital%20de%20Imagens.pdf,0,0,0
1282777,Neural network approach to background modeling for video object segmentation,2007,Dubravko Culibrk and Oge Marques and Daniel Socek and Hari Kalva and Borko Furht,18,IEEE Transactions on Neural Networks,6,1614-1627,IEEE,This paper presents a novel background modeling and subtraction approach for video object segmentation. A neural network (NN) architecture is proposed to form an unsupervised Bayesian classifier for this application domain. The constructed classifier efficiently handles the segmentation in natural-scene sequences with complex background motion and changes in illumination. The weights of the proposed NN serve as a model of the background and are temporally updated to reflect the observed statistics of background. The segmentation performance of the proposed NN is qualitatively and quantitatively examined and compared to two extant probabilistic object segmentation algorithms. based on a previously published test pool containing diverse surveillance-related sequences. The proposed algorithm is parallelized on a subpixel level and designed to enable efficient hardware implementation.,True,ZgWULzYAAAAJ:9yKSN-GCB0IC,222,https://ieeexplore.ieee.org/abstract/document/4359175/,5781192406508848124,/scholar?cites=5781192406508848124,,,http://cronus.uwindsor.ca/units/isplab/ISPLab.nsf/54ef3e94e5fe816e85256d6e0063d208/6312a4c084f9b8a4852576d20061edbd/$FILE/Neural%20network%20approach%20to%20background%20modeling%20for%20video%20object%20segmentation_TNN%20Nov07.pdf,0,0,0
1282778,Skin lesion classification from dermoscopic images using deep learning techniques,2017,Adria Romero Lopez and Xavier Giro-i-Nieto and Jack Burdick and Oge Marques,,,,49-54,IEEE,The recent emergence of deep learning methods for medical image analysis has enabled the development of intelligent medical imaging-based diagnosis systems that can assist the human expert in making better decisions about a patients health. In this paper we focus on the problem of skin lesion classification. particularly early melanoma detection. and present a deep-learning based approach to solve the problem of classifying a dermoscopic image containing a skin lesion as malignant or benign. The proposed solution is built around the VGGNet convolutional neural network architecture and uses the transfer learning paradigm. Experimental results are encouraging: on the ISIC Archive dataset. the proposed method achieves a sensitivity value of 78.66%. which is significantly higher than the current state of the art on that dataset.,True,ZgWULzYAAAAJ:EkHepimYqZsC,162,https://ieeexplore.ieee.org/abstract/document/7893267/,13965900339869794360,/scholar?cites=13965900339869794360,,,https://upcommons.upc.edu/bitstream/handle/2117/103386/biomed-2017-paper.pdf,0,0,0
1282779,Content-based image and video retrieval,2002,Oge Marques and Borko Furht,21,,,,Springer Science & Business Media,The amount of audiovisual information available in digital format has grown exponentially in recent years. Gigabytes of new images. audio and video clips are generated and stored everyday. Most audiovisual content can be accessed through the Internet. which is a very large. unstructured. distributed information database. Searching and retrieving multimedia information from the Web has been limited to the use of keywords. Over the past decade. many researchers. mostly from the Image Processing and Computer Vision community. have started to investigate possible ways of retrieving visual information based solely on its contents. Instead of being manually annotated using keywords. images and video clips would be indexed by their own visual content. such as color. texture. objects' shape and movement. among others. Research in the field of content-based image and video retrieval (CBIVR) is very active. Many research groups in leading universities. research institutes. and companies are actively working in this field. Their ultimate goal is to enable users to retrieve the desired image or video clip among massive amounts of visual data in a fast. efficient. semantically meaningful. friendly. and location-independent manner. Applications of CBIVR systems include digital libraries. video-on-demand systems. geographic information systems. astronomical research. satellite observation systems. and criminal investigation systems. among many others. Content-Based Image And Video Retrieval addresses the basic concepts and techniques for designing content-based image and video retrieval systems. It also discusses a variety of design choices …,True,ZgWULzYAAAAJ:d1gkVwhDpl0C,150,http://books.google.com/books?hl=en&lr=&id=ds6xRLdlmJgC&oi=fnd&pg=PA1&dq=info:LjgAv1UAinEJ:scholar.google.com&ots=jyhRdMcj0c&sig=KtiHB47Aej51Vm2jMW0Wk9KLlJ4,8181352041348610094,/scholar?cites=8181352041348610094,,,,0,0,0
1282780,Video browsing interfaces and applications: a review,2010,Klaus Schoeffmann and Frank Hopfgartner and Oge Marques and Laszlo Boeszoermenyi and Joemon M Jose,1,,1,018004,International Society for Optics and Photonics,We present a comprehensive review of the state of the art in video browsing and retrieval systems. with special emphasis on interfaces and applications. There has been a significant increase in activity (e.g.. storage. retrieval. and sharing) employing video data in the past decade. both for personal and professional use. The ever-growing amount of video content available for human consumption and the inherent characteristics of video data-which. if presented in its raw format. is rather unwieldy and costly-have become driving forces for the development of more effective solutions to present video contents and allow rich user interaction. As a result. there are many contemporary research efforts toward developing better video browsing solutions. which we summarize. We review more than 40 different video browsing and retrieval interfaces and classify them into three groups: applications that use video-player-like …,True,ZgWULzYAAAAJ:LkGwnXOMwfcC,90,https://www.spiedigitallibrary.org/journals/SPIE-Reviews/volume-1/issue-1/018004/Video-browsing-interfaces-and-applications-a-review/10.1117/6.0000005.short,16240610479951437381,/scholar?cites=16240610479951437381,,,https://www.spiedigitallibrary.org/journalArticle/Download?fullDOI=10.1117/6.0000005,0,0,0
1282781,Handbook of video databases: design and applications,2003,Borko Furht and Oge Marques,,,,,CRC press,Technology has spurred the growth of huge image and video libraries. many growing into the hundreds of terabytes. As a result there is a great demand among organizations for the design of databases that can effectively support the storage. search. retrieval. and transmission of video data. Engineers and researchers in the field demand a comprehensi,True,ZgWULzYAAAAJ:u-x6o8ySG0sC,81,http://books.google.com/books?hl=en&lr=&id=w55BzND_8icC&oi=fnd&pg=PP1&dq=info:iYe0lm-UV_AJ:scholar.google.com&ots=NFBxSBmQ1T&sig=c26PVQv4NRYnFeCD71FDuCMmrUs,17318474099067225993,/scholar?cites=17318474099067225993,,,,0,0,0
1282782,How To Design a Virtual Classroom: 10 Easy Steps To Follow!.,1999,Sam Hsu and Oge Marques and M Khalid Hamza and Bassem Alhalabi,,,,,,Despite the ever-increasing number of higher education institutions offering online courses. there are still a lot of controversial debates and a strong sense of confusion about how well the concept of Web-based distance learning is being implemented. This paper summarizes the 10 primary steps toward the assessment. planning. design. implementation. and maintenance of a successful virtual classroom. Benefits and drawbacks of a Web-based classroom are first outlined. followed by these 10 steps:(1) Assess the needs and the necessary conditions to satisfy them;(2) Estimate the development cost. effort. and implications;(3) Plan the virtual classroom;(4) Design the virtual classroom;(5) Prepare and distribute contents;(6) Enable communication;(7) Implement online student assessment methods;(8) Implement class management procedures;(9) Set up the system; and (10) Maintain and update the virtual classroom.(AEF),True,ZgWULzYAAAAJ:2osOgNQ5qMEC,72,https://eric.ed.gov/?id=ED437027,874961181646496441,/scholar?cites=874961181646496441,,,https://files.eric.ed.gov/fulltext/ED437027.pdf,0,0,0
1282783,Visual information retrieval using java and lire,2013,Mathias Lux and Oge Marques,5,"Synthesis Lectures on Information Concepts, Retrieval, and Services",1,1-112,Morgan & Claypool Publishers,Visual information retrieval (VIR) is an active and vibrant research area. which attempts at providing means for organizing. indexing. annotating. and retrieving visual information (images and videos) from large. unstructured repositories.  The goal of VIR is to retrieve matches ranked by their relevance to a given query. which is often expressed as an example image and/or a series of keywords.  During its early years (1995-2000). the research efforts were dominated by content-based approaches contributed primarily by the image and video processing community.  During the past decade. it was widely recognized that the challenges imposed by the lack of coincidence between an image's visual contents and its semantic interpretation. also known as semantic gap. required a clever use of textual metadata (in addition to information extracted from the image's pixel contents) to make image and video retrieval solutions …,True,ZgWULzYAAAAJ:WbkHhVStYXYC,65,https://www.morganclaypool.com/doi/abs/10.2200/s00468ed1v01y201301icr025,18058997960685396197,/scholar?cites=18058997960685396197,,,,0,0,0
1282784,Semi-automatic semantic annotation of images using machine learning techniques,2003,Oge Marques and Nitish Barman,,,,550-565,Springer. Berlin. Heidelberg,The success of the Semantic Web hinges on being able to produce semantic markups on Web pages and their components. in a way that is cost-effective and consistent with adopted schemas and ontologies. Since images are an essential component of the Web. this work focuses on an intelligent approach to semantic annotation of images. We propose a three-layer architecture. in which the bottom layer organizes visual information extracted from the raw image contents. which are mapped to semantically meaningful keywords in the middle layer. which are then connected to schemas and ontologies on the top layer. Our key contribution is the use of machine learning algorithms for user-assisted. semi-automatic image annotation. in such a way that the knowledge of previously annotated images – both at metadata and visual levels – is used to speed up the annotation of subsequent images within the same …,True,ZgWULzYAAAAJ:qjMakFHDy7sC,55,https://link.springer.com/chapter/10.1007/978-3-540-39718-2_35,12741416293539555153,/scholar?cites=12741416293539555153,,,https://link.springer.com/content/pdf/10.1007/978-3-540-39718-2_35.pdf,0,0,0
1282785,Stereo depth with a unified architecture GPU,2008,Joel Gibson and Oge Marques,,,,1-6,IEEE,This paper describes how the calculation of depth from stereo images was accelerated using a GPU. The Compute Unified Device Architecture (CUDA) from NVIDIA was employed in novel ways to compute depth using BT cost matching and the semi-global matching algorithm. The challenges of mapping a sequential algorithm to a massively parallel thread environment and performance optimization techniques are considered.,True,ZgWULzYAAAAJ:UeHWp8X0CEIC,54,https://ieeexplore.ieee.org/abstract/document/4563092/,15830098283225488587,/scholar?cites=15830098283225488587,,,https://www.researchgate.net/profile/Oge_Marques/publication/4350681_Stereo_depth_with_a_Unified_Architecture_GPU/links/0fcfd50b4087d74222000000.pdf,0,0,0
1282786,Non-Local Deep Features for Salient Object Detection,2017,Pierre-Marc Jodoin Zhiming Luo and Akshaya Mishra and Andrew Achkar and Justin Eichel and Shaozi Li1,,CVPR,,,,,True,s2JWeL8AAAAJ:BqipwSGYUEgC,324,,16428186249695992880,/scholar?cites=16428186249695992880,,,,0,0,0
1282787,Intra-retinal layer segmentation in optical coherence tomography images,2009,Akshaya Mishra and Alexander Wong and Kostadinka Bizheva and David A Clausi,17,Optics express,26,23719-23728,Optical Society of America,Retinal layer thickness. evaluated as a function of spatial position from optical coherence tomography (OCT) images is an important diagnostics marker for many retinal diseases. However. due to factors such as speckle noise. low image contrast. irregularly shaped morphological features such as retinal detachments. macular holes. and drusen. accurate segmentation of individual retinal layers is difficult. To address this issue. a computer method for retinal layer segmentation from OCT images is presented. An efficient two-step kernel-based optimization scheme is employed to first identify the approximate locations of the individual layers. which are then refined to obtain accurate segmentation results for the individual layers. The performance of the algorithm was tested on a set of retinal images acquired in-vivo from healthy and diseased rodent models with a high speed. high resolution OCT system. Experimental …,True,s2JWeL8AAAAJ:u5HHmVD_uO8C,234,https://www.osapublishing.org/abstract.cfm?uri=oe-17-26-23719,3101569107408611590,/scholar?cites=3101569107408611590,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-17-26-23719&seq=0,0,0,0
1282788,Selective management of mobile device data in an enterprise environment,2014,Suresh Kumar Batchu and Ajay Kumar Mishra and Ojas Udayan Rege,,,,,,In various embodiments. a method is described that includes registering a mobile device with an enterprise by storing registration data for the mobile device in a device management database; designating one or more group designations for the mobile device; storing the one or more group designations in the device management database; determining one or more policies for the mobile device based at least in part on the one or more group designations; and selectively taking action on selected data from the mobile device in the device management database based on the one or more policies.,True,s2JWeL8AAAAJ:geHnlv5EZngC,232,https://patents.google.com/patent/US8695058B2/en,11424998146146704795,/scholar?cites=11424998146146704795,,,https://patentimages.storage.googleapis.com/19/47/5c/076be49780d1ae/US8695058.pdf,0,0,0
1282789,Selective Management of Mobile Devices in an Enterprise Environment,2010,Suresh Kumar Batchu and Ajay Kumar Mishra,,,,,,In various embodiments. a method is described that includes registering a mobile device with an enterprise by storing registration data for the mobile device in a device management database; designating one or more group designations for the mobile device; storing the one or more group designations in the device management database; determining one or more policies for the mobile device based at least in part on the one or more group designations; and selectively taking action on selected data from the mobile device in the device management database based on the one or more policies.,True,s2JWeL8AAAAJ:4fKUyHm3Qg0C,195,https://patents.google.com/patent/US20100299152A1/en,2215795661188028174,/scholar?cites=2215795661188028174,,,https://patentimages.storage.googleapis.com/d9/89/78/9061aaf83334a4/US20100299152A1.pdf,0,0,0
1282790,General Bayesian estimation for speckle noise reduction in optical coherence tomography retinal imagery,2010,Alexander Wong and Akshaya Mishra and Kostadinka Bizheva and David A Clausi,18,Optics express,8,8338-8352,Optical Society of America,An important image post-processing step for optical coherence tomography (OCT) images is speckle noise reduction. Noise in OCT images is multiplicative in nature and is difficult to suppress due to the fact that in addition the noise component. OCT speckle also carries structural information about the imaged object. To address this issue. a novel speckle noise reduction algorithm was developed. The algorithm projects the imaging data into the logarithmic space and a general Bayesian least squares estimate of the noise-free data is found using a conditional posterior sampling approach. The proposed algorithm was tested on a number of rodent (rat) retina images acquired in-vivo with an ultrahigh resolution OCT system. The performance of the algorithm was compared to that of the state-of-the-art algorithms currently available for speckle denoising. such as the adaptive median. maximum a posteriori (MAP …,True,s2JWeL8AAAAJ:u-x6o8ySG0sC,163,https://www.osapublishing.org/abstract.cfm?uri=oe-18-8-8338,7009677963016925884,/scholar?cites=7009677963016925884,,,https://www.osapublishing.org/viewmedia.cfm?uri=oe-18-8-8338&seq=0,0,0,0
1282791,Decoupled active contour (DAC) for boundary detection,2010,Akshaya K Mishra and Paul W Fieguth and David A Clausi,33,IEEE Transactions on Pattern Analysis and Machine Intelligence,2,310-324,IEEE,The accurate detection of object boundaries via active contours is an ongoing research topic in computer vision. Most active contours converge toward some desired contour by minimizing a sum of internal (prior) and external (image measurement) energy terms. Such an approach is elegant. but suffers from a slow convergence rate and frequently misconverges in the presence of noise or complex contours. To address these limitations. a decoupled active contour (DAC) is developed which applies the two energy terms separately. Essentially. the DAC consists of a measurement update step. employing a Hidden Markov Model (HMM) and Viterbi search. and then a separate prior step. which modifies the updated curve based on the relative strengths of the measurement uncertainty and the nonstationary prior. By separating the measurement and prior steps. the algorithm is less likely to misconverge; furthermore. the …,True,s2JWeL8AAAAJ:d1gkVwhDpl0C,117,https://ieeexplore.ieee.org/abstract/document/5439007/,7842198366401669286,/scholar?cites=7842198366401669286,,,,0,0,0
1282792,Management of mobile applications,2014,Jesse Wagner Lindeman and Thomas Edward Wagner and Suresh Kumar Batchu and Ojas Udayan Rege and Ajay Kumar Mishra and Robert Bates Tinker,,,,,,In particular implementations. a mobile device management system allows network administrators to control the distribution and publication of applications to mobile device users in an enterprise network.,True,s2JWeL8AAAAJ:fQNAKQ3IYiAC,115,https://patents.google.com/patent/US8731529B2/en,12064640560934423633,/scholar?cites=12064640560934423633,,,https://patentimages.storage.googleapis.com/8e/31/2e/744465ad911b10/US8731529.pdf,0,0,0
1282793,Selective discount for supplier–buyer coordination using common replenishment epochs,2004,Ajay K Mishra,153,European Journal of Operational Research,3,751-756,North-Holland,A supplier may reduce its order costs by providing an incentive in the form of price discounts to buyers to restrict their replenishment intervals to multiples of a common replenishment epoch (CRE). This coordination mechanism was studied by Viswanathan and Piplani who suggested that the supplier offer a discount that is the maximum of the discount required by all buyers. We generalize their model to allow for a selective discount policy that. if beneficial. excludes some buyers to minimize the supplier’s total cost. Using a computational study. we observe that offering discounts to buyers selectively. if necessary. by segmenting them and offering multiple CRE. reduces the supplier’s cost in many scenarios.,True,s2JWeL8AAAAJ:pyW8ca7W8N0C,102,https://www.sciencedirect.com/science/article/pii/S0377221702008111,16614494088232713805,/scholar?cites=16614494088232713805,,,,0,0,0
1282794,Computational investigations of maximum flow algorithms,1997,Ravindra K Ahuja and Murali Kodialam and Ajay K Mishra and James B Orlin,97,European Journal of Operational Research,3,509-542,North-Holland,The maximum flow algorithm is distinguished by the long line of successive contributions researchers have made in obtaining algorithms with incrementally better worst-case complexity. Some. but not all. of these theoretical improvements have produced improvements in practice. The purpose of this paper is to test some of the major algorithmic ideas developed in the recent years and to assess their utility on the empirical front. However. our study differs from previous studies in several ways. Whereas previous studies focus primarily on CPU time analysis. our analysis goes further and provides detailed insight into algorithmic behavior. It not only observes how algorithms behave but also tries to explain why algorithms behave that way. We have limited our study to the best previous maximum flow algorithms and some of the recent algorithms that are likely to be efficient in practice. Our study encompasses ten …,True,s2JWeL8AAAAJ:a0OBvERweLwC,102,https://www.sciencedirect.com/science/article/pii/S037722179600269X,10649524410795779560,/scholar?cites=10649524410795779560,,,https://dspace.mit.edu/bitstream/handle/1721.1/2573/SWP-3811-32867587.pdf?sequence=1,0,0,0
1282795,Epidemiology of bacterial colonization at intensive care unit admission with emphasis on extended-spectrum β-lactamase-and metallo-β-lactamase-producing Gram-negative bacteria …,2010,Afzal Azim and Mayank Dwivedi and P Bhaskar Rao and AK Baronia and RK Singh and KN Prasad and Banani Poddar and Anshuman Mishra and Mohan Gurjar and TN Dhole,59,Journal of medical microbiology,8,955-960,Microbiology Society,An important risk factor for nosocomial infection in an intensive care unit (ICU) is prior colonization. This study was undertaken to determine the spectrum of bacterial colonization and predisposing risk factors in patients being admitted to an ICU in India. with special emphasis on extended-spectrum β-lactamase (ESBL)- and metallo-β-lactamase (MBL)-producing Gram-negative bacteria. Nasal. oral and rectal swab samples were collected and processed for isolation of ESBL-producing Gram-negative bacteria and MBL-producing Pseudomonas aeruginosa and Acinetobacter species. Bacterial colonization (of one or more sites) on admission was detected in 51 out of 96 patients included in the study. Non-fermenters. i.e. P. aeruginosa and Acinetobacter baumannii. were the most common colonizers. present in 37 patients. with simultaneous colonization in 12 patients. A total of 16 patients were colonized with MBL …,True,s2JWeL8AAAAJ:LjlpjdlvIbIC,91,https://www.microbiologyresearch.org/content/journal/jmm/10.1099/jmm.0.018085-0?crawler=true,582148098670138672,/scholar?cites=582148098670138672,,,https://www.researchgate.net/profile/Afzal_Azim/publication/240256754_Epidemiology_of_bacterial_colonization_at_intensive_care_unit_admission_with_emphasis_on_extended-spectrum_b-lactamase-_and_metallo-b-_lactamase-producing_Gram-negative_bacteria_-_An_Indian_experience/links/565c142b08aeafc2aac6f98c.pdf,0,0,0
1282796,Antibacterial activity of ethanol extract of Andrographis paniculata,2009,US Mishra and A Mishra and R Kumari and PN Murthy and BS Naik,71,Indian Journal of Pharmaceutical Sciences,4,436,Wolters Kluwer--Medknow Publications,In the present study the ethanol extract of the aerial part of Andrographis paniculata was prepared and evaluated for antimicrobial activity against eleven bacterial strains by determining minimum inhibitory concentration and zone of inhibition. Minimum inhibitory concentration values were compared with control and zone of inhibition values were compared with standard ciprofloxacin in concentration 100 and 200 μg/ml. The results revealed that. the ethanol extract is potent in inhibiting bacterial growth of both Gram-negative and Gram positive bacteria.,True,s2JWeL8AAAAJ:lSLTfruPkqcC,85,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2865817/,8663112369154019486,/scholar?cites=8663112369154019486,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2865817/,0,0,0
1282797,Anomalous video event detection using spatiotemporal context,2011,Fan Jiang and Junsong Yuan and Sotirios A Tsaftaris and Aggelos K Katsaggelos,115,Computer Vision and Image Understanding,3,323-333,Academic Press,Compared to other anomalous video event detection approaches that analyze object trajectories only. we propose a context-aware method to detect anomalies. By tracking all moving objects in the video. three different levels of spatiotemporal contexts are considered. i.e.. point anomaly of a video object. sequential anomaly of an object trajectory. and co-occurrence anomaly of multiple video objects. A hierarchical data mining approach is proposed. At each level. frequency-based analysis is performed to automatically discover regular rules of normal events. Events deviating from these rules are identified as anomalies. The proposed method is computationally efficient and can infer complex rules. Experiments on real traffic video validate that the detected video anomalies are hazardous or illegal according to traffic regulations.,True,jC1uFnYAAAAJ:YsMSGLbcyi4C,215,https://www.sciencedirect.com/science/article/pii/S1077314210002390,6130738709542364563,/scholar?cites=6130738709542364563,,,http://www.eecs.northwestern.edu/~fji295/publications/CVIU11.pdf,0,0,0
1282798,Leaf segmentation in plant phenotyping: a collation study,2016,Hanno Scharr and Massimo Minervini and Andrew P French and Christian Klukas and David M Kramer and Xiaoming Liu and Imanol Luengo and Jean-Michel Pape and Gerrit Polder and Danijela Vukadinovic and Xi Yin and Sotirios A Tsaftaris,27,Machine vision and applications,4,585-606,Springer Berlin Heidelberg,Image-based plant phenotyping is a growing application area of computer vision in agriculture. A key task is the segmentation of all individual leaves in images. Here we focus on the most common rosette model plants. Arabidopsis and young tobacco. Although leaves do share appearance and shape characteristics. the presence of occlusions and variability in leaf shape and pose. as well as imaging conditions. render this problem challenging. The aim of this paper is to compare several leaf segmentation solutions on a unique and first-of-its-kind dataset containing images from typical phenotyping experiments. In particular. we report and discuss methods and findings of a collection of submissions for the first Leaf Segmentation Challenge of the Computer Vision Problems in Plant Phenotyping workshop in 2014. Four methods are presented: three segment leaves by processing the distance transform in an …,True,jC1uFnYAAAAJ:eJXPG6dFmWUC,174,https://link.springer.com/content/pdf/10.1007/s00138-015-0737-3.pdf,12611179262798701573,/scholar?cites=12611179262798701573,,,https://core.ac.uk/download/pdf/43717239.pdf,0,0,0
1282799,Finely-grained annotated datasets for image-based plant phenotyping,2016,Massimo Minervini and Andreas Fischbach and Hanno Scharr and Sotirios A Tsaftaris,81,Pattern recognition letters,,80-89,North-Holland,Image-based approaches to plant phenotyping are gaining momentum providing fertile ground for several interesting vision tasks where fine-grained categorization is necessary. such as leaf segmentation among a variety of cultivars. and cultivar (or mutant) identification. However. benchmark data focusing on typical imaging situations and vision tasks are still lacking. making it difficult to compare existing methodologies. This paper describes a collection of benchmark datasets of raw and annotated top-view color images of rosette plants. We briefly describe plant material. imaging setup and procedures for different experiments: one with various cultivars of Arabidopsis and one with tobacco undergoing different treatments. We proceed to define a set of computer vision and classification tasks and provide accompanying datasets and annotations based on our raw data. We describe the annotation process performed …,True,jC1uFnYAAAAJ:LPZeul_q3PIC,155,https://www.sciencedirect.com/science/article/pii/S0167865515003645,6111548251600026145,/scholar?cites=6111548251600026145,,,http://eprints.imtlucca.it/3541/1/Minervini_et_al_PRL2016.pdf,0,0,0
1282800,Image analysis: the new bottleneck in plant phenotyping [applications corner],2015,Massimo Minervini and Hanno Scharr and Sotirios A Tsaftaris,32,IEEE signal processing magazine,4,126-131,IEEE,Plant phenotyping is the identification of effects on the phenotype (i.e.. the plant appearance and performance) as a result of genotype differences (i.e.. differences in the genetic code) and the environmental conditions to which a plant has been exposed [1]?[3]. According to the Food and Agriculture Organization of the United Nations. large-scale experiments in plant phenotyping are a key factor in meeting the agricultural needs of the future to feed the world and provide biomass for energy. while using less water. land. and fertilizer under a constantly evolving environment due to climate change. Working on model plants (such as Arabidopsis). combined with remarkable advances in genotyping. has revolutionized our understanding of biology but has accelerated the need for precision and automation in phenotyping. favoring approaches that provide quantifiable phenotypic information that could be better used to …,True,jC1uFnYAAAAJ:p2g8aNsByqUC,146,https://ieeexplore.ieee.org/abstract/document/7123050/,10668884386155821847,/scholar?cites=10668884386155821847,,,http://www.research.ed.ac.uk/portal/files/22078988/Image_Analysis_The_New_Bottleneck_in_Plant_Phenotyping.pdf,0,0,0
1282801,Multimodal MR synthesis via modality-invariant latent representation,2017,Agisilaos Chartsias and Thomas Joyce and Mario Valerio Giuffrida and Sotirios A Tsaftaris,37,IEEE transactions on medical imaging,3,803-814,IEEE,We propose a multi-input multi-output fully convolutional neural network model for MRI synthesis. The model is robust to missing data. as it benefits from. but does not require. additional input modalities. The model is trained end-to-end. and learns to embed all input modalities into a shared modality-invariant latent space. These latent representations are then combined into a single fused representation. which is transformed into the target output modality with a learnt decoder. We avoid the need for curriculum learning by exploiting the fact that the various input modalities are highly correlated. We also show that by incorporating information from segmentation masks the model can both decrease its error and generate data with synthetic lesions. We evaluate our model on the ISLES and BRATS data sets and demonstrate statistically significant improvements over state-of-the-art methods for single input tasks. This …,True,jC1uFnYAAAAJ:1yQoGdGgb4wC,117,https://ieeexplore.ieee.org/abstract/document/8071026/,13784980018576454592,/scholar?cites=13784980018576454592,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc5904017/,0,0,0
1282802,Image-based plant phenotyping with incremental learning and active contours,2014,Massimo Minervini and Mohammed M Abdelsamea and Sotirios A Tsaftaris,23,Ecological Informatics,,35-48,Elsevier,Plant phenotyping investigates how a plant's genome. interacting with the environment. affects the observable traits of a plant (phenome). It is becoming increasingly important in our quest towards efficient and sustainable agriculture. While sequencing the genome is becoming increasingly efficient. acquiring phenotype information has remained largely of low throughput. Current solutions for automated image-based plant phenotyping. rely either on semi-automated or manual analysis of the imaging data. or on expensive and proprietary software which accompanies costly hardware infrastructure. While some attempts have been made to create software applications that enable the analysis of such images in an automated fashion. most solutions are tailored to particular acquisition scenarios and restrictions on experimental design. In this paper we propose and test. a method for the segmentation and the automated …,True,jC1uFnYAAAAJ:M05iB0D1s5AC,113,https://www.sciencedirect.com/science/article/pii/S1574954113000691,12258529608175497910,/scholar?cites=12258529608175497910,,,http://tsaftaris.com/preprints/Minervini_etal_EcoInf_2013.pdf,0,0,0
1282803,Dominant β-catenin mutations cause intellectual disability with recognizable syndromic features,2014,Valter Tucci and Tjitske Kleefstra and Andrea Hardy and Ines Heise and Silvia Maggi and Marjolein H Willemsen and Helen Hilton and Chris Esapa and Michelle Simon and Maria-Teresa Buenavista and Liam J McGuffin and Lucie Vizor and Luca Dodero and Sotirios Tsaftaris and Rosario Romero and Willy N Nillesen and Lisenka ELM Vissers and Marlies J Kempers and Anneke T Vulto-van Silfhout and Zafar Iqbal and Marta Orlando and Alessandro Maccione and Glenda Lassi and Pasqualina Farisello and Andrea Contestabile and Federico Tinarelli and Thierry Nieus and Andrea Raimondi and Barbara Greco and Daniela Cantatore and Laura Gasparini and Luca Berdondini and Angelo Bifone and Alessandro Gozzi and Sara Wells and Patrick M Nolan,124,The Journal of clinical investigation,4,1468-1482,American Society for Clinical Investigation,The recent identification of multiple dominant mutations in the gene encoding β-catenin in both humans and mice has enabled exploration of the molecular and cellular basis of β-catenin function in cognitive impairment. In humans. β-catenin mutations that cause a spectrum of neurodevelopmental disorders have been identified. We identified de novo β-catenin mutations in patients with intellectual disability. carefully characterized their phenotypes. and were able to define a recognizable intellectual disability syndrome. In parallel. characterization of a chemically mutagenized mouse line that displays features similar to those of human patients with β-catenin mutations enabled us to investigate the consequences of β-catenin dysfunction through development and into adulthood. The mouse mutant. designated batface (Bfc). carries a Thr653Lys substitution in the C-terminal armadillo repeat of β-catenin and displayed …,True,jC1uFnYAAAAJ:bFI3QPDXJZMC,99,https://www.jci.org/articles/view/70372,3391303792343335060,/scholar?cites=3391303792343335060,,,https://www.jci.org/articles/view/70372,0,0,0
1282804,Adversarial image synthesis for unpaired multi-modal cardiac data,2017,Agisilaos Chartsias and Thomas Joyce and Rohan Dharmakumar and Sotirios A Tsaftaris,,,,3-13,Springer. Cham,This paper demonstrates the potential for synthesis of medical images in one modality (e.g. MR) from images in another (e.g. CT) using a CycleGAN [24] architecture. The synthesis can be learned from unpaired images. and applied directly to expand the quantity of available training data for a given task. We demonstrate the application of this approach in synthesising cardiac MR images from CT images. using a dataset of MR and CT images coming from different patients. Since there can be no direct evaluation of the synthetic images. as no ground truth images exist. we demonstrate their utility by leveraging our synthetic data to achieve improved results in segmentation. Specifically. we show that training on both real and synthetic data increases accuracy by 15% compared to real data. Additionally. our synthetic data is of sufficient quality to be used alone to train a segmentation neural network. that …,True,jC1uFnYAAAAJ:N5tVd3kTz84C,97,https://link.springer.com/chapter/10.1007/978-3-319-68127-6_1,14467636317615256601,/scholar?cites=14467636317615256601,,,http://tsaftaris.com/preprints/SASHIMI_2017_Chartsias.pdf,0,0,0
1282805,Neuroimaging evidence of major morpho-anatomical and functional abnormalities in the BTBR T+ TF/J mouse model of autism,2013,Luca Dodero and Mario Damiano and Alberto Galbusera and Angelo Bifone and Sotirios A Tsaftsaris and Maria Luisa Scattoni and Alessandro Gozzi,8,PloS one,10,e76655,Public Library of Science,BTBR T+tf/J (BTBR) mice display prominent behavioural deficits analogous to the defining symptoms of autism. a feature that has prompted a widespread use of the model in preclinical autism research. Because neuro-behavioural traits are described with respect to reference populations. multiple investigators have examined and described the behaviour of BTBR mice against that exhibited by C57BL/6J (B6). a mouse line characterised by high sociability and low self-grooming. In an attempt to probe the translational relevance of this comparison for autism research. we used Magnetic Resonance Imaging (MRI) to map in both strain multiple morpho-anatomical and functional neuroimaging readouts that have been extensively used in patient populations. Diffusion tensor tractography confirmed previous reports of callosal agenesis and lack of hippocampal commissure in BTBR mice. and revealed a concomitant rostro-caudal reorganisation of major cortical white matter bundles. Intact inter-hemispheric tracts were found in the anterior commissure. ventro-medial thalamus. and in a strain-specific white matter formation located above the third ventricle. BTBR also exhibited decreased fronto-cortical. occipital and thalamic gray matter volume and widespread reductions in cortical thickness with respect to control B6 mice. Foci of increased gray matter volume and thickness were observed in the medial prefrontal and insular cortex. Mapping of resting-state brain activity using cerebral blood volume weighted fMRI revealed reduced cortico-thalamic function together with foci of increased activity in the hypothalamus and dorsal hippocampus of BTBR mice …,True,jC1uFnYAAAAJ:SeFeTyx0c_EC,93,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076655,6945362410444134441,/scholar?cites=6945362410444134441,,,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076655,0,0,0
1282806,Accuracy of electrocardiographic criteria for atrial enlargement: validation with cardiovascular magnetic resonance,2008,Connie W Tsao and Mark E Josephson and Thomas H Hauser and T David O'Halloran and Anupam Agarwal and Warren J Manning and Susan B Yeon,10,Journal of Cardiovascular Magnetic Resonance,1,1-7,BioMed Central,Anatomic atrial enlargement is associated with significant morbidity and mortality. However. atrial enlargement may not correlate with clinical measures such as electrocardiographic (ECG) criteria. Past studies correlating ECG criteria with anatomic measures mainly used inferior M-mode or two-dimensional echocardiographic data. We sought to determine the accuracy of the ECG to predict anatomic atrial enlargement as determined by volumetric cardiovascular magnetic resonance (CMR). ECG criteria for left (LAE) and right atrial enlargement (RAE) were compared to CMR atrial volume index measurements for 275 consecutive subjects referred for CMR (67% males. 51 ± 14 years). ECG criteria for LAE and RAE were assessed by an expert observer blinded to CMR data. Atrial volume index was computed using the biplane area-length method. The prevalence of CMR LAE and RAE was 28% and 11 …,True,jC1uFnYAAAAJ:8k81kl-MbHgC,89,https://link.springer.com/article/10.1186/1532-429X-10-7,13068688370330493838,/scholar?cites=13068688370330493838,,,https://link.springer.com/article/10.1186/1532-429X-10-7,0,0,0
1282807,Learning to count leaves in rosette plants,2016,Mario Valerio Giuffrida and Massimo Minervini and Sotirios A Tsaftaris,,,,1.1-1.13,BMVA press,Counting the number of leaves in plants is important for plant phenotyping. since it can be used to assess plant growth stages. We propose a learning-based approach for counting leaves in rosette (model) plants. We relate image-based descriptors learned in an unsupervised fashion to leaf counts using a supervised regression model. To take advantage of the circular and coplanar arrangement of leaves and also to introduce scale and rotation invariance. we learn features in a log-polar representation. Image patches extracted in this log-polar domain are provided to K-means. which builds a codebook in a unsupervised manner. Feature codes are obtained by projecting patches on the codebook using the triangle encoding. introducing both sparsity and specifically designed representation. A global. per-plant image descriptor is obtained by pooling local features in specific regions of the image. Finally. we provide the global descriptors to a support vector regression framework to estimate the number of leaves in a plant. We evaluate our method on datasets of the \textit{Leaf Counting Challenge} (LCC). containing images of Arabidopsis and tobacco plants. Experimental results show that on average we reduce absolute counting error by 40% w.r.t. the winner of the 2014 edition of the challenge -a counting via segmentation method. When compared to state-of-the-art density-based approaches to counting. on Arabidopsis image data ~75% less counting errors are observed. Our findings suggest that it is possible to treat leaf counting as a regression problem. requiring as input only the total leaf count per training image.,True,jC1uFnYAAAAJ:tOudhMTPpwUC,82,http://eprints.imtlucca.it/2744/,2160999413909783567,/scholar?cites=2160999413909783567,,,http://eprints.imtlucca.it/2744/1/paper001.pdf,0,0,0
