,title,pub_year,author,volume,journal,number,pages,publisher,abstract,filled,author_pub_id,num_citations,pub_url,cites_id,citedby_url,gsrank,author_id,eprint_url,got_citations,got_author_ids,author_ids
1276117,Integrative analysis of complex cancer genomics and clinical profiles using the cBioPortal,2013,Jianjiong Gao and Bülent Arman Aksoy and Ugur Dogrusoz and Gideon Dresdner and Benjamin Gross and S Onur Sumer and Yichao Sun and Anders Jacobsen and Rileen Sinha and Erik Larsson and Ethan Cerami and Chris Sander and Nikolaus Schultz,6,Science signaling,269,pl1-pl1,American Association for the Advancement of Science,The cBioPortal for Cancer Genomics (http://cbioportal.org) provides a Web resource for exploring. visualizing. and analyzing multidimensional cancer genomics data. The portal reduces molecular profiling data from cancer tissues and cell lines into readily understandable genetic. epigenetic. gene expression. and proteomic events. The query interface combined with customized data storage enables researchers to interactively explore genetic alterations across samples. genes. and pathways and. when available in the underlying data. to link these to clinical outcomes. The portal provides graphical summaries of gene-level data from multiple platforms. network visualization and analysis. survival analysis. patient-centric queries. and software programmatic access. The intuitive Web interface of the portal makes complex cancer genomics profiles accessible to researchers and clinicians without requiring …,True,zCsVb4IAAAAJ:u5HHmVD_uO8C,7709,https://stke.sciencemag.org/content/6/269/pl1.short,825652708373249998,/scholar?cites=825652708373249998,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc4160307/,0,0,0
1276118,Integrated genomic characterization of endometrial carcinoma,2013,Douglas A Levine,497,Nature,7447,67-73,Nature Publishing Group,We performed an integrated genomic. transcriptomic and proteomic characterization of 373 endometrial carcinomas using array-and sequencing-based technologies. Uterine serous tumours and∼ 25% of high-grade endometrioid tumours had extensive copy number alterations. few DNA methylation changes. low oestrogen receptor/progesterone receptor levels. and frequent TP53 mutations. Most endometrioid tumours had few copy number alterations or TP53 mutations. but frequent mutations in PTEN. CTNNB1. PIK3CA. ARID1A and KRAS and novel mutations in the SWI/SNF chromatin remodelling complex gene ARID5B. A subset of endometrioid tumours that we identified had a markedly increased transversion mutation frequency and newly identified hotspot mutations in POLE. Our results classified endometrial cancers into four categories: POLE ultramutated. microsatellite instability hypermutated. copy …,True,zCsVb4IAAAAJ:d1gkVwhDpl0C,2808,https://www.nature.com/articles/nature12113,11384515426975270944,/scholar?cites=11384515426975270944,,,https://www.nature.com/articles/nature12113,0,0,0
1276119,Comprehensive molecular characterization of urothelial bladder carcinoma,2014,Cancer Genome Atlas Research Network,507,Nature,7492,315,NIH Public Access,Urothelial carcinoma of the bladder is a common malignancy that causes approximately 150.000 deaths per year worldwide. To date. no molecularly targeted agents have been approved for the disease. As part of The Cancer Genome Atlas project. we report here an integrated analysis of 131 urothelial carcinomas to provide a comprehensive landscape of molecular alterations. There were statistically significant recurrent mutations in 32 genes. including multiple genes involved in cell cycle regulation. chromatin regulation. and kinase signaling pathways. as well as 9 genes not previously reported as significantly mutated in any cancer. RNA sequencing revealed four expression subtypes. two of which (papillary-like and basal/squamous-like) were also evident in miRNA sequencing and protein data. Whole-genome and RNA sequencing identified recurrent in-frame activating FGFR3-TACC3 fusions and expression …,True,zCsVb4IAAAAJ:IjCSPb-OGe4C,1800,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3962515/,6693677122521287203,/scholar?cites=6693677122521287203,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc3962515/,0,0,0
1276120,Integrated genomic characterization of papillary thyroid carcinoma,2014,Nishant Agrawal and Rehan Akbani and B Arman Aksoy and Adrian Ally and Harindra Arachchi and Sylvia L Asa and J Todd Auman and Miruna Balasundaram and Saianand Balu and Stephen B Baylin and Madhusmita Behera and Brady Bernard and Rameen Beroukhim and Justin A Bishop and Aaron D Black and Tom Bodenheimer and Lori Boice and Moiz S Bootwalla and Jay Bowen and Reanne Bowlby and Christopher A Bristow and Robin Brookens and Denise Brooks and Robert Bryant and Elizabeth Buda and Yaron SN Butterfield and Tobias Carling and Rebecca Carlsen and Scott L Carter and Sally E Carty and Timothy A Chan and Amy Y Chen and Andrew D Cherniack and Dorothy Cheung and Lynda Chin and Juok Cho and Andy Chu and Eric Chuah and Kristian Cibulskis and Giovanni Ciriello and Amanda Clarke and Gary L Clayman and Leslie Cope and John A Copland and Kyle Covington and Ludmila Danilova and Tanja Davidsen and John A Demchok and Daniel DiCara and Noreen Dhalla and Rajiv Dhir and Sheliann S Dookran and Gideon Dresdner and Jonathan Eldridge and Greg Eley and Adel K El-Naggar and Stephanie Eng and James A Fagin and Timothy Fennell and Robert L Ferris and Sheila Fisher and Scott Frazer and Jessica Frick and Stacey B Gabriel and Ian Ganly and Jianjiong Gao and Levi A Garraway and Julie M Gastier-Foster and Gad Getz and Nils Gehlenborg and Ronald Ghossein and Richard A Gibbs and Thomas J Giordano and Karen Gomez-Hernandez and Jonna Grimsby and Benjamin Gross and Ranabir Guin and Angela Hadjipanayis and Hollie A Harper and D Neil Hayes and David I Heiman and James G Herman and Katherine A Hoadley and Matan Hofree and Robert A Holt and Alan P Hoyle and Franklin W Huang and Mei Huang and Carolyn M Hutter and Trey Ideker and Lisa Iype and Anders Jacobsen and Stuart R Jefferys and Corbin D Jones and Steven JM Jones and Katayoon Kasaian and Electron Kebebew and Fadlo R Khuri and Jaegil Kim and Roger Kramer and Richard Kreisberg and Raju Kucherlapati and David J Kwiatkowski and Marc Ladanyi and Phillip H Lai and Peter W Laird and Eric Lander and Michael S Lawrence and Darlene Lee and Eunjung Lee and Semin Lee and William Lee and Kristen M Leraas and Tara M Lichtenberg and Lee Lichtenstein and Pei Lin and Shiyun Ling and Jinze Liu and Wenbin Liu and Yingchun Liu and Virginia A LiVolsi and Yiling Lu and Yussanne Ma and Harshad S Mahadeshwar and Marco A Marra and Michael Mayo and David G McFadden and Shaowu Meng and Matthew Meyerson and Piotr A Mieczkowski and Michael Miller and Gordon Mills and Richard A Moore and Lisle E Mose and Andrew J Mungall and Bradley A Murray and Yuri E Nikiforov and Michael S Noble and Akinyemi I Ojesina and Taofeek K Owonikoko and Bradley A Ozenberger and Angeliki Pantazi and Michael Parfenov and Peter J Park and Joel S Parker and Evan O Paull and Chandra Sekhar Pedamallu and Charles M Perou and Jan F Prins and Alexei Protopopov,159,Cell,3,676-690,Cell Press,Papillary thyroid carcinoma (PTC) is the most common type of thyroid cancer. Here. we describe the genomic landscape of 496 PTCs. We observed a low frequency of somatic alterations (relative to other carcinomas) and extended the set of known PTC driver alterations to include EIF1AX. PPM1D. and CHEK2 and diverse gene fusions. These discoveries reduced the fraction of PTC cases with unknown oncogenic driver from 25% to 3.5%. Combined analyses of genomic variants. gene expression. and methylation demonstrated that different driver groups lead to different pathologies with distinct signaling and differentiation characteristics. Similarly. we identified distinct molecular subgroups of BRAF-mutant tumors. and multidimensional analyses highlighted a potential involvement of oncomiRs in less-differentiated subgroups. Our results propose a reclassification of thyroid cancers into molecular subtypes that …,True,zCsVb4IAAAAJ:UeHWp8X0CEIC,1426,https://www.sciencedirect.com/science/article/pii/S0092867414012380,1300577726801350223,/scholar?cites=1300577726801350223,,,https://www.sciencedirect.com/science/article/pii/S0092867414012380,0,0,0
1276121,Characterization of HPV and host genome interactions in primary head and neck cancers,2014,Michael Parfenov and Chandra Sekhar Pedamallu and Nils Gehlenborg and Samuel S Freeman and Ludmila Danilova and Christopher A Bristow and Semin Lee and Angela G Hadjipanayis and Elena V Ivanova and Matthew D Wilkerson and Alexei Protopopov and Lixing Yang and Sahil Seth and Xingzhi Song and Jiabin Tang and Xiaojia Ren and Jianhua Zhang and Angeliki Pantazi and Netty Santoso and Andrew W Xu and Harshad Mahadeshwar and David A Wheeler and Robert I Haddad and Joonil Jung and Akinyemi I Ojesina and Natalia Issaeva and Wendell G Yarbrough and D Neil Hayes and Jennifer R Grandis and Adel K El-Naggar and Matthew Meyerson and Peter J Park and Lynda Chin and JG Seidman and Peter S Hammerman and Raju Kucherlapati and Cancer Genome Atlas Network,111,Proceedings of the National Academy of Sciences,43,15544-15549,National Academy of Sciences,Previous studies have established that a subset of head and neck tumors contains human papillomavirus (HPV) sequences and that HPV-driven head and neck cancers display distinct biological and clinical features. HPV is known to drive cancer by the actions of the E6 and E7 oncoproteins. but the molecular architecture of HPV infection and its interaction with the host genome in head and neck cancers have not been comprehensively described. We profiled a cohort of 279 head and neck cancers with next generation RNA and DNA sequencing and show that 35 (12.5%) tumors displayed evidence of high-risk HPV types 16. 33. or 35. Twenty-five cases had integration of the viral genome into one or more locations in the human genome with statistical enrichment for genic regions. Integrations had a marked impact on the human genome and were associated with alterations in DNA copy number. mRNA transcript …,True,zCsVb4IAAAAJ:Tyk-4Ss8FVUC,265,https://www.pnas.org/content/111/43/15544.short,7611388731983909317,/scholar?cites=7611388731983909317,,,https://www.pnas.org/content/pnas/111/43/15544.full.pdf,0,0,0
1276122,Boosting Black Box Variational Inference,2018,Francesco* Locatello and Gideon* Dresdner and Rajiv Khanna and Isabel Valera and Gunnar Rätsch,,,,3405-3415,,Approximating a probability density in a tractable manner is a central task in Bayesian statistics. Variational Inference (VI) is a popular technique that achieves tractability by choosing a relatively simple variational family. Borrowing ideas from the classic boosting framework. recent approaches attempt to\emph {boost} VI by replacing the selection of a single density with a greedily constructed mixture of densities. In order to guarantee convergence. previous works impose stringent assumptions that require significant effort for practitioners. Specifically. they require a custom implementation of the greedy step (called the LMO) for every probabilistic model with respect to an unnatural variational family of truncated distributions. Our work fixes these issues with novel theoretical and algorithmic insights. On the theoretical side. we show that boosting VI satisfies a relaxed smoothness assumption which is sufficient for the convergence of the functional Frank-Wolfe (FW) algorithm. Furthermore. we rephrase the LMO problem and propose to maximize the Residual ELBO (RELBO) which replaces the standard ELBO optimization in VI. These theoretical enhancements allow for black box implementation of the boosting subroutine. Finally. we present a stopping criterion drawn from the duality gap in the classic FW analyses and exhaustive experiments to illustrate the usefulness of our theoretical and algorithmic contributions.,True,zCsVb4IAAAAJ:ufrVoPGSRksC,19,https://arxiv.org/abs/1806.02185,493456481295082921,/scholar?cites=493456481295082921,,,https://arxiv.org/pdf/1806.02185,0,0,0
1276123,PiHelper: an open source framework for drug-target and antibody-target data,2013,Bülent Arman Aksoy and Jianjiong Gao and Gideon Dresdner and Weiqing Wang and Alex Root and Xiaohong Jing and Ethan Cerami and Chris Sander,29,Bioinformatics,16,2071-2072,Oxford University Press, Motivation: The interaction between drugs and their targets. often proteins. and between antibodies and their targets. is important for planning and analyzing investigational and therapeutic interventions in many biological systems. Although drug-target and antibody-target datasets are available in separate databases. they are not publicly available in an integrated bioinformatics resource. As medical therapeutics. especially in cancer. increasingly uses targeted drugs and measures their effects on biomolecular profiles. there is an unmet need for a user-friendly toolset that allows researchers to comprehensively and conveniently access and query information about drugs. antibodies and their targets. Summary: The PiHelper framework integrates human drug-target and antibody-target associations from publicly available resources to help meet the needs of researchers in systems pharmacology …,True,zCsVb4IAAAAJ:u-x6o8ySG0sC,18,https://academic.oup.com/bioinformatics/article-abstract/29/16/2071/204715,9156077462434808835,/scholar?cites=9156077462434808835,,,https://academic.oup.com/bioinformatics/article/29/16/2071/204715,0,0,0
1276124,Scalable gaussian processes on discrete domains,2018,Vincent Fortuin and Gideon Dresdner and Heiko Strathmann and Gunnar Rätsch,,arXiv preprint arXiv:1810.10368,,,,Kernel methods on discrete domains have shown great promise for many challenging data types. for instance. biological sequence data and molecular structure data. Scalable kernel methods like Support Vector Machines may offer good predictive performances but do not intrinsically provide uncertainty estimates. In contrast. probabilistic kernel methods like Gaussian Processes offer uncertainty estimates in addition to good predictive performance but fall short in terms of scalability. We present the first sparse Gaussian Process approximation framework on discrete input domains. Our framework achieves good predictive performance as well as uncertainty estimates using discrete optimization techniques. We present competitive results comparing our framework to baseline methods such as Support Vector Machines and full Gaussian Processes on synthetic data as well as on challenging real-world DNA sequence data.,True,zCsVb4IAAAAJ:_FxGoFyzp5QC,7,https://arxiv.org/abs/1810.10368,3487819691170697416,/scholar?cites=3487819691170697416,,,https://arxiv.org/pdf/1810.10368,0,0,0
1276125,Stochastic Frank-Wolfe for constrained finite-sum minimization,2020,Geoffrey Négiar and Gideon Dresdner and Alicia Tsai and Laurent El Ghaoui and Francesco Locatello and Robert Freund and Fabian Pedregosa,,,,7253-7262,PMLR,We propose a novel Stochastic Frank-Wolfe (aka conditional gradient) algorithm for constrained smooth finite-sum minimization with a generalized linear prediction/structure. This class of problems includes empirical risk minimization with sparse. low-rank. or other structured constraints. The proposed method is simple to implement. does not require step-size tuning. and has a constant per-iteration cost that is independent of the dataset size. Furthermore. as a byproduct of the method we obtain a stochastic estimator of the Frank-Wolfe gap that can be used as a stopping criterion. Depending on the setting. the proposed method matches or improves on the best computational guarantees for Stochastic Frank-Wolfe algorithms. Benchmarks on several datasets highlight different regimes in which the proposed method exhibits a faster empirical convergence than related methods. Finally. we provide an implementation of all considered methods in an open-source package.,True,zCsVb4IAAAAJ:LkGwnXOMwfcC,6,http://proceedings.mlr.press/v119/negiar20a.html,611899428047262705,/scholar?cites=611899428047262705,,,http://proceedings.mlr.press/v119/negiar20a/negiar20a.pdf,0,0,0
1276126,The cbioportal for cancer genomics as a clinical decision support tool,2014,JianJiong Gao and B Arman Aksoy and Benjamin Gross and Gideon Dresdner and Yichao Sun and S Onur Sumer and Chris Sander and Nikolaus Schultz,74,,19 Supplement,4271-4271,American Association for Cancer Research,As sequencing of tumor samples is entering clinical practice. there is an urgent need for new tools that facilitate the interpretation of sequence data so that they can effectively inform treatment decisions. To this end. we are evolving the cBioPortal for Cancer Genomics into a clinical decision support tool. The cBioPortal is a web-based visualization and analysis engine that makes complex cancer genomics data accessible to a wide range of cancer researchers and clinicians.To transition the cBioPortal towards use in clinical practice. we have recently developed the following new functions:1. Filtering of oncogenic mutations: By using information about the known or likely oncogenic effects of specific mutations. the portal can now filter out passenger events and highlight known and potentially druggable drivers.2. Clinical timelines: Compact and interactive visualization of a patient9s clinical and treatment history3 …,True,zCsVb4IAAAAJ:2osOgNQ5qMEC,4,https://cancerres.aacrjournals.org/content/74/19_Supplement/4271.short,12849838594593000122,/scholar?cites=12849838594593000122,,,,0,0,0
1276127,Individual patient cancer profiles in the cBio Cancer Genomic Portal.,2013,Jianjiong Gao and Selcuk Onur Sumer and Gideon Dresdner and Bülent Arman Aksoy and Chris Sander and Nikolaus Schultz,73,,8 Supplement,5140-5140,American Association for Cancer Research,The most prominent or most interesting genomic alteration events from an individual tumor sample can now be browsed and analyzed in the cBio Cancer Genomics Portal. With the rapid accumulation of detailed and comprehensive genomic maps of thousands of tumors in The Cancer Genome Atlas and other projects it has now become feasible to nominate the functionally most significant events affecting a tumor from an individual patient.The cBio Cancer Genomics Portal (http://cbioportal.org) allows interactive exploration of multidimensional cancer genomics data sets. currently for more than 6.000 tumor samples from 20 cancer genomics studies. including all TCGA projects. This information gateway significantly lowers the barrier between complex genomic data and their efficient use by cancer researchers for the development of biologic insights and clinical applications.In addition to gene-by-gene alteration …,True,zCsVb4IAAAAJ:9yKSN-GCB0IC,0,https://cancerres.aacrjournals.org/content/73/8_Supplement/5140.short,,,,,,0,0,0
1276128,Choline acetyltransferase: the structure. distribution and pathologic changes in the central nervous system,1999,Yoshio Oda,49,,11,921-937,Blackwell Science Pty,Choline acetyltransferase (ChAT). the enzyme responsible for the biosynthesis of acetylcholine. is presently the most specific indicator for monitoring the functional state of cholinergic neurones in the central and peripheral nervous systems. ChAT is a single‐strand globular protein. The enzyme is synthesized in the perikaryon of cholinergic neurones and transported to the nerve terminals probably by both slow and rapid axoplasmic flows. ChAT exists in at least two forms in cholinergic nerve terminals: (i) soluble; and (ii) non‐ionically membrane‐bound forms. Multiple mRNA species of ChAT (R‐. N‐and M‐types) are transcribed from different promoter regions and produced by different splicing in the mouse. rat. and human. All transcripts encode the same ChAT protein in rodents. while in human M‐type mRNA has the capability to generate both large and small forms of ChAT proteins and R‐and N‐types ChAT …,True,831HmKMAAAAJ:RVqaWcrwK10C,429,https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1440-1827.1999.00977.x,15543835590300992964,/scholar?cites=15543835590300992964,,,,0,0,0
1276129,Adsorption of Pb and Cd onto metal oxides and organic material in natural surface coatings as determined by selective extractions: new evidence for the importance of Mn and Fe …,2000,Deming Dong and Yarrow M Nelson and Leonard W Lion and Michael L Shuler and William C Ghiorse,34,Water Research,2,427-436,Pergamon,Surface coatings (biofilms and associated minerals) were collected on glass slides in the oxic surface waters of Cayuga Lake (New York State. U.S.A.) and were used to evaluate the relative contributions of Fe. Mn and Al oxides and organic material to total observed Pb and Cd adsorption by the surface coating materials. Several alternative selective extraction techniques were evaluated with respect to both selectivity and alteration of the residual unextracted material. Pb and Cd adsorption was measured under controlled laboratory conditions (mineral salts solution with defined metal speciation. ionic strength 0.05 M. 25°C and pH 6.0) before and after extractions to determine by difference the adsorptive properties of the extracted component(s). Hydroxylamine hydrochloride (0.01 M NH2OH·HCl+0.01 M HNO3) was used to selectively remove Mn oxides. sodium dithionite (0.3 M Na2S2O4) was used to remove Mn …,True,831HmKMAAAAJ:VBDT71xRUdcC,422,https://www.sciencedirect.com/science/article/pii/S0043135499001852,14498528214721476857,/scholar?cites=14498528214721476857,,,https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1102&context=cenv_fac,0,0,0
1276130,Farm size and productivity: Understanding the strengths of smallholders and improving their livelihoods,2011,Ramesh Chand and PA Lakshmi Prasanna and Aruna Singh,,Economic and Political Weekly,,5-11,Sameeksha Trust,During the 1960s and 1970s there was an intense debate on the observed inverse relationship between farm size and per hectare agricultural productivity in India. It was subsequently argued that the higher productivity of smallholdings would disappear with the adoption of superior technology. modernisation and growth in general. However. close to half a century later. National Sample Survey data from the initial years of the 21st century show that smallholdings in Indian agriculture still exhibit a higher productivity than large holdings. These smallholdings however show lower per capita productivity and the incidence of poverty is widespread. Strategies for Indian agriculture and smallholding households should include reducing the inequality in land distribution and promoting off-farm work in the rural areas itself. The strategy of improving the crop land-man ratio by facilitating migration from rural India has not …,True,831HmKMAAAAJ:tfDI-GPdlUQC,286,https://www.jstor.org/stable/23018813,17068311579785729399,/scholar?cites=17068311579785729399,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.363.4414&rep=rep1&type=pdf,0,0,0
1276131,Molecular mechanisms of potassium and sodium uptake in plants,2002,Pascal Mäser and Markus Gierth and Julian I Schroeder,,,,43-54,Springer. Dordrecht,Potassium (K+) is an essential nutrient and the most abundant cation in plants. whereas the closely related ion sodium (Na+) is toxic to most plants at high millimolar concentrations. K+ deficiency and Na+ toxicity are both major constraints to crop production worldwide. K+ counteracts Na+ stress. while Na+. in turn. can to a certain degree alleviate K+ deficiency. Elucidation of the molecular mechanisms of K+ and Na+ transport is pivotal to the understanding — and eventually engineering — of plant K+ nutrition and Na+ sensitivity. Here we provide an overview on plant K+ transporters with particular emphasis on root K+ and Na+ uptake. Plant K+-permeable cation transporters comprise seven families. Shaker-type K+ channels. ‘two-pore’ K+ channels. cyclic-nucleotidegated channels. putative K+/H+ antiporters. KUP/HAK/KT transporters. HKT transporters. and LCT1. Candidate genes for Na+ transport are …,True,831HmKMAAAAJ:VL0QpB8kHFEC,268,https://link.springer.com/chapter/10.1007/978-94-017-2789-1_3,2711245971647650921,/scholar?cites=2711245971647650921,,,https://www.academia.edu/download/50298005/a_3A102115913072920161114-16422-tch920.pdf,0,0,0
1276132,Hepatoprotective activity of Apium graveolens and Hygrophila auriculata against paracetamol and thioacetamide intoxication in rats,1995,Anubha Singh and SS Handa,49,Journal of ethnopharmacology,3,119-126,Elsevier,Seeds of Apium graveolens L. (Apiaceae) and Hygrophila auriculata (K. Schum.) Heine (Syn. Astercantha auriculata Nees. Acanthaceae) are used in Indian systems of medicine for the treatment of liver ailments. The antihepatotoxic effect of methanolic extracts of the seeds of these two plants was studied on rat liver damage induced by a single dose of paracetamol (3 g/kg p.o.) or thioacetamide (100 mg/kg. s.c.) by monitoring several liver function tests. viz. serum transaminases (SGOT and SGPT). alkaline phosphatase. sorbitol dehydrogenase. glutamate dehydrogenase and bilirubin in serum. Furthermore. hepatic tissues were processed for assay of triglycerides and histopathological alterations simultaneously. A significant hepatoprotective activity of the methanolic extract of the seeds of both the plants was reported.,True,831HmKMAAAAJ:F1b5ZUV5XREC,244,https://www.sciencedirect.com/science/article/pii/0378874195012915,1120984494460755313,/scholar?cites=1120984494460755313,,,,0,0,0
1276133,Influence of sulphur and nitrogen on seed yield and quality of low glucosinolate oilseed rape (Brassica napus L),1993,Fangjie Zhao and Eric J Evans and Paul E Bilsborrow and J Keith Syers,63,Journal of the Science of Food and Agriculture,1,29-37,John Wiley & Sons. Ltd,Influence of S and N application on seed yield and quality of a double low (low erucic acid and glucosinolate content) variety of winter oilseed rape (Brassica napus L) was examined in field experiments at both S‐sufficient and S‐deficient sites. At the S‐sufficient site. application of S had no significant influences on seed yield. yield components. seed protein and oil contents. and resulted in only a marginal increase in seed glucosinolate content. Application of N increased seed yield and protein content. but decreased oil content concurrently. A significant increase in seed glucosinolate content in response to the increasing N rate was obtained at this site. which was more noticeable in those treatments with applied S than without. In contrast. at the S‐deficient site. there were significant interactions between S and N on seed yield. protein and glucosinolate contents. Increasing the N rate beyond 150 kg ha−1 did not …,True,831HmKMAAAAJ:LnJLeQ70pnUC,205,https://onlinelibrary.wiley.com/doi/abs/10.1002/jsfa.2740630106,8614877557384946408,/scholar?cites=8614877557384946408,,,,0,0,0
1276134,Litterfall. litter decomposition and nutrient dynamics in a subtropical natural oak forest and managed plantation in northeastern India,2007,RR Pandey and G Sharma and SK Tripathi and AK Singh,240,Forest Ecology and Management,1-3,96-104,Elsevier,In northeastern India. subtropical forests are over-exploited for timber. fuel wood and common agricultural practice like shifting cultivation. which are responsible for the degradation of natural forest. In degraded areas. large-scale plantations of different species of Quercus have been raised since 1980 for the production of economic Tasar silk. Conversion of natural forest into plantation affects the process of nutrient cycling due to management practices. Thus. it would be of importance to study the litterfall. litter decomposition process and the factors regulating the rate of litter decay in these ecosystems to improve recommendations for their management and conservation. We recorded litterfall by using litter traps and decomposition of leaf litter by nylon net bag technique to understand the amount of organic matter and nutrient return and their release in soils of forest and plantation in Manipur. northeast India. Total …,True,831HmKMAAAAJ:gQbQcM3rmFsC,204,https://www.sciencedirect.com/science/article/pii/S0378112706011480,4440634345133470870,/scholar?cites=4440634345133470870,,,https://www.researchgate.net/profile/Shri_Tripathi/publication/222299121_Litterfall_litter_decomposition_and_nutrient_dynamics_in_a_subtropical_natural_oak_forest_and_managed_plantation_in_northeastern_India/links/5a5f1f38aca272d4a3e0cf5f/Litterfall-litter-decomposition-and-nutrient-dynamics-in-a-subtropical-natural-oak-forest-and-managed-plantation-in-northeastern-India.pdf,0,0,0
1276135,Evaluation of functional properties of composite flours and sensorial attributes of composite flour biscuits,2015,Suresh Chandra and Samsher Singh and Durvesh Kumari,52,Journal of food science and technology,6,3681-3688,Springer India,The present study was undertaken to develop biscuits from the composite flours. Composite flours were prepared by blending wheat flour with rice flour. green gram flour and potato flour in ratios of 100:0:0:0 (W100). 85:5:5:5 (W85). 70:10:10:10 (W70) and 55:15:15:15 (W55). respectively. The functional properties of composite flours such as swelling capacity. water absorption capacity. oil absorption capacity. emulsion activity. emulsion stability. foam capacity. foam stability. gelatinization temperature. least gelation concentration and bulk density were increased with increase in the incorporation of other flours with wheat flour. Overall acceptability for composite flour biscuits was awarded highest score for W55 followed by W70 and W85 as compared to control biscuits. All biscuits coincided in the range of ‘like moderately’ to ‘like very much’ for composite flours biscuits while ‘like slightly’ to like moderately’ for …,True,831HmKMAAAAJ:kGbpvR7Ecy8C,193,https://link.springer.com/article/10.1007/s13197-014-1427-2,5307446106377070717,/scholar?cites=5307446106377070717,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4444897/,0,0,0
1276136,β-Catenin expression is altered in human colonic aberrant crypt foci,2001,Xing Pei Hao and Thomas G Pretlow and J Sunil Rao and Theresa P Pretlow,61,Cancer research,22,8085-8088,American Association for Cancer Research,The aberrant expression of β-catenin in colon tumors and the discovery of β-catenin mutations in small adenomas suggest that alterations of β-catenin are early events in human colorectal carcinogenesis. Here. we describe the expression of β-catenin in human aberrant crypt foci (ACF). the earliest identified neoplastic lesions in the colon. Paraffin-embedded sections of 94 ACF. 12 adenomas. and 10 carcinomas were evaluated for β-catenin expression by immunohistochemistry. Normal colonic epithelial cells adjacent to these lesions showed strong membranous expression of β-catenin and lacked cytoplasmic and nuclear expression. Cytoplasmic expression of β-catenin was seen in 25 of 46 ACF with dysplasia and in 2 of 48 ACF with atypia. In ACF with dysplasia. reduced membranous expression of β-catenin was associated with increased nuclear (P = 0.0013) and cytoplasmic (P = 0.0247) expression. The …,True,831HmKMAAAAJ:4e5Qn2KL_jwC,193,https://cancerres.aacrjournals.org/content/61/22/8085.short,17483192817389329876,/scholar?cites=17483192817389329876,,,https://cancerres.aacrjournals.org/content/canres/61/22/8085.full.pdf,0,0,0
1276137,One-way cross-talk between p38MAPK and p42/44MAPK: inhibition of p38MAPK induces low density lipoprotein receptor expression through activation of the p42/44MAPK cascade,1999,Rajesh P Singh and Punita Dhawan and Carmen Golden and Gurpreet S Kapoor and Kamal D Mehta,274,Journal of Biological Chemistry,28,19593-19600,Elsevier,In this paper. we report that SB202190 alone. a specific inhibitor of p38MAPK. induces low density lipoprotein (LDL) receptor expression (6–8-fold) in a sterol-sensitive manner in HepG2 cells. Consistent with this finding. selective activation of the p38MAPK signaling pathway by expression of MKK6b(E). a constitutive activator of p38MAPK. significantly reduced LDL receptor promoter activity. Expression of the p38MAPK α-isoform had a similar effect. whereas expression of the p38MAPK βII-isoform had no significant effect on LDL receptor promoter activity. SB202190-dependent increase in LDL receptor expression was accompanied by induction of p42/44MAPK. and inhibition of this pathway completely prevented SB202190-induced LDL receptor expression. suggesting that p38MAPK negatively regulates the p42/44MAPK cascade and the responses mediated by this kinase. Cross-talk between these kinases …,True,831HmKMAAAAJ:qmyJBmpVKbYC,183,https://www.sciencedirect.com/science/article/pii/S0021925819870692,8042999685831323025,/scholar?cites=8042999685831323025,,,https://www.sciencedirect.com/science/article/pii/S0021925819870692,0,0,0
1276138,Determination of thermal conductivity. specific heat and thermal diffusivity of borage seeds,2002,W Yang and S Sokhansanj and J Tang and P Winter,82,Biosystems engineering,,169-176,ACADEMIC PRESS,Borage is a speciality oilseed with a high content of crude oil (33%) and crude protein (28%). It is especially high in gamma linolenic acid which is currently in great demand for pharmaceutical and health-care applications. Thermal conductivity. thermal diffusivity and specific heat capacity are three important engineering properties of a material related to heat transfer characteristics. These parameters are essential in studying heating. drying and cooling processes for borage seeds. Thermal properties of many agricultural and food products have been reported in the literature. and most of these data are compiled by Polley et al.(1980) and ASAE (2001) for engineering research and design purposes. The thermal property data of many novelty crops are not. however. available in the literature. For borage seeds. no other thermal property data than the specific heat capacity as reported by Yang et al.(1997) can be found in the literature. Thermal conductivity. thermal diffusivity and specific heat capacity each can be measured by several well-established methods (Mohsenin. 1980; Dickerson. 1965). but measuring any two of them would lead to the third through the relationship a ¼ k rcp ð1Þ where a is the thermal diffusivity. k is the thermal conductivity. r is the bulk density and cp is the specific heat.Methods for measuring thermal conductivity can be classified into two broad categories: steady-and transient-state heat transfer methods (Mohsenin. 1980). The tests using steady-state methods often require a long time to complete and moisture migration may introduce significant measurement errors (Mohsenin. 1980; Kazarian & Hall. 1965; Dutta et al.. 1988 …,True,831HmKMAAAAJ:cNepPnSnVCgC,167,http://sites.bsyse.wsu.edu/tang/main/publications/pdfdocs/Thermal/tang67.pdf,17699409291793068520,/scholar?cites=17699409291793068520,,,http://sites.bsyse.wsu.edu/tang/main/publications/pdfdocs/Thermal/tang67.pdf,0,0,0
1276139,Software Product Lines,2013,Sven Apel and Don Batory and Christian Kästner and Gunter Saake,,,,3-15,Springer. Berlin. Heidelberg,Software product lines aim at empowering software vendors to tailor software products to the requirements of individual customers. In this sense. software product lines follow a development that emerged in industrial manufacturing over the last 200 years. Starting with handcrafting of individual goods. the advent of mass production scaled the production process to large quantities. but neglected individualism. as all products were the same. With mass customization. individualism got back into the focus of attention. Manufacturers systematically planned and designed product lines to cover a whole spectrum of possible products and variations thereof. serving the individual needs and wishes of many customers. Software product lines take the same line and reconcile mass production and mass customization in software engineering.,True,_4ssMloAAAAJ:-_dYPAW6P2MC,854,https://link.springer.com/chapter/10.1007/978-3-642-37521-7_1,11556922539506340605,/scholar?cites=11556922539506340605,,,,0,0,0
1276140,Granularity in software product lines,2008,Christian Kästner and Sven Apel and Martin Kuhlemann,,,,311-320,ACM,Building software product lines (SPLs) with features is a challenging task. Many SPL implementations support features with coarse granularity - e.g.. the ability to add and wrap entire methods. However. fine-grained extensions. like adding a statement in the middle of a method. either require intricate workarounds or obfuscate the base code with annotations. Though many SPLs can and have been implemented with the coarse granularity of existing approaches. fine-grained extensions are essential when extracting features from legacy applications. Furthermore. also some existing SPLs could benefit from fine-grained extensions to reduce code replication or improve readability. In this paper. we analyze the effects of feature granularity in SPLs and present a tool. called Colored IDE (CIDE). that allows features to implement coarse-grained and fine-grained extensions in a concise way. In two case studies. we show …,True,_4ssMloAAAAJ:u5HHmVD_uO8C,603,https://ieeexplore.ieee.org/abstract/document/4814142/,5702325035670758983,/scholar?cites=5702325035670758983,,,https://www.academia.edu/download/33668232/ICSE2008.pdf,0,0,0
1276141,An overview of feature-oriented software development,2009,Sven Apel and Christian Kästner,8,Journal of Object Technology (JOT),5,49-84,,Feature-oriented software development (FOSD) is a paradigm for the construction. customization. and synthesis of large-scale software systems. In this survey. we give an overview and a personal perspective on the roots of FOSD. connections to other software development paradigms. and recent developments in this field. Our aim is to point to connections between different lines of research and to identify open issues.,True,_4ssMloAAAAJ:IjCSPb-OGe4C,543,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/JOT09_OverviewFOSD.pdf,10388835983436080272,/scholar?cites=10388835983436080272,,,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/JOT09_OverviewFOSD.pdf,0,0,0
1276142,A classification and survey of analysis strategies for software product lines,2014,Thomas Thüm and Sven Apel and Christian Kästner and Ina Schaefer and Gunter Saake,47,,1,1-45,ACM,Software-product-line engineering has gained considerable momentum in recent years. both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques. such as type checking. model checking. and theorem proving. in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible. due to the potentially exponential number of valid feature combinations. Recently. researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account. for example. by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse. so it is difficult for researchers and …,True,_4ssMloAAAAJ:kkSDTGFLcmwC,415,https://dl.acm.org/doi/abs/10.1145/2580950,9534498399631107234,/scholar?cites=9534498399631107234,,,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/CSUR14.pdf,0,0,0
1276143,An analysis of the variability in forty preprocessor-based software product lines,2010,Jorg Liebig and Sven Apel and Christian Lengauer and Christian Kästner and Michael Schulze,1,,,105-114,IEEE,Over 30 years ago. the preprocessor cpp was developed to extend the programming language C by lightweight metaprogramming capabilities. Despite its error-proneness and low abstraction level. the preprocessor is still widely used in present-day software projects to implement variable software. However. not much is known about how cpp is employed to implement variability. To address this issue. we have analyzed forty open-source software projects written in C. Specifically. we answer the following questions: How does program size influence variability? How complex are extensions made via cpp's variability mechanisms? At which level of granularity are extensions applied? Which types of extension occur? These questions revive earlier discussions on program comprehension and refactoring in the context of the preprocessor. To provide answers. we introduce several metrics measuring the variability …,True,_4ssMloAAAAJ:5nxA0vEk-isC,347,https://dl.acm.org/doi/abs/10.1145/1806799.1806819,3589439399277352227,/scholar?cites=3589439399277352227,,,https://www.se.cs.uni-saarland.de/publications/docs/ICSE2010.pdf,0,0,0
1276144,FeatureHouse: Language-independent. automated software composition,2009,Sven Apel and Christian Kastner and Christian Lengauer,,,,221-231,IEEE,Superimposition is a composition technique that has been applied successfully in many areas of software development. Although superimposition is a general-purpose concept. it has been (re)invented and implemented individually for various kinds of software artifacts. We unify languages and tools that rely on superimposition by using the language-independent model of feature structure trees (FSTs). On the basis of the FST model. we propose a general approach to the composition of software artifacts written in different languages. Furthermore. we offer a supporting framework and tool chain. called FEATUREHOUSE. We use attribute grammars to automate the integration of additional languages. in particular. we have integrated Java. C#. C. Haskell. JavaCC. and XML. Several case studies demonstrate the practicality and scalability of our approach and reveal insights into the properties a language must have in …,True,_4ssMloAAAAJ:zYLM7Y9cAGgC,297,https://ieeexplore.ieee.org/abstract/document/5070523/,12512114506268037307,/scholar?cites=12512114506268037307,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.444.9414&rep=rep1&type=pdf,0,0,0
1276145,A case study implementing features using AspectJ,2007,Christian Kastner and Sven Apel and Don Batory,,,,223-232,IEEE,Software product lines aim to create highly configurable programs from a set of features. Common belief and recent studies suggest that aspects are well-suited for implementing features. We evaluate the suitability of AspectJ with respect to this task by a case study that refactors the embedded database system Berkeley DB into 38 features. Contrary to our initial expectations. the results were not encouraging. As the number of aspects in a feature grows. there is a noticeable decrease in code readability and maintainability. Most of the unique and powerful features of AspectJ were not needed. We document where AspectJ is unsuitable for implementing features of refactored legacy applications and explain why.,True,_4ssMloAAAAJ:d1gkVwhDpl0C,277,https://ieeexplore.ieee.org/abstract/document/4339271/,5229620999429606357,/scholar?cites=5229620999429606357,,,http://www.cs.cmu.edu/~ckaestne/pdf/splc07.pdf,0,0,0
1276146,FeatureIDE: A tool framework for feature-oriented software development,2009,Christian Kastner and Thomas Thum and Gunter Saake and Janet Feigenspan and Thomas Leich and Fabian Wielgorz and Sven Apel,,,,611-614,IEEE,Tools support is crucial for the acceptance of a new programming language. However. providing such tool support is a huge investment that can usually not be provided for a research language. With FeatureIDE. we have built an IDE for AHEAD that integrates all phases of feature-oriented software development. To reuse this investment for other tools and languages. we refactored FeatureIDE into an open source framework that encapsulates the common ideas of feature-oriented software development and that can be reused and extended beyond AHEAD. Among others. we implemented extensions for FeatureC++ and FeatureHouse. but in general. FeatureIDE is open for everybody to showcase new research results and make them usable to a wide audience of students. researchers. and practitioners.,True,_4ssMloAAAAJ:_FxGoFyzp5QC,264,https://ieeexplore.ieee.org/abstract/document/5070568/,506901375479050691,/scholar?cites=506901375479050691,,,https://www.researchgate.net/profile/Thomas_Thuem/publication/216168407_FeatureIDE_Tool_Framework_for_Feature-Oriented_Software_Development/links/0912f509d05260ab78000000.pdf,0,0,0
1276147,FeatureC++: On the symbiosis of feature-oriented and aspect-oriented programming,2005,Sven Apel and Thomas Leich and Marko Rosenmüller and Gunter Saake,,Generative Programming and Component Engineering,,125-140,Springer Berlin/Heidelberg,This paper presents FeatureC++. a novel language extension to C++ that supports Feature-Oriented Programming (FOP) and Aspect-Oriented Programming (AOP). Besides well-known concepts of FOP languages. FeatureC++ contributes several novel FOP language features. in particular multiple inheritance and templates for generic programming. Furthermore. FeatureC++ solves several problems regarding incremental software development by adopting AOP concepts. Starting our considerations on solving these problems. we give a summary of drawbacks and weaknesses of current FOP languages in expressing incremental refinements. Specifically. we outline five key problems and present three approaches to solve them: Multi Mixins. Aspectual Mixin Layers. and Aspectual Mixins that adopt AOP concepts in different ways. We use FeatureC++ as a representative FOP language to explain these three …,True,_4ssMloAAAAJ:9yKSN-GCB0IC,259,https://link.springer.com/chapter/10.1007/11561347_10,8841629278688244813,/scholar?cites=8841629278688244813,,,https://www.infosun.fim.uni-passau.de/publications/docs/GPCE2005.pdf,0,0,0
1276148,Predicting performance via automated feature-interaction detection,2012,Norbert Siegmund and Sergiy S Kolesnikov and Christian Kästner and Sven Apel and Don Batory and Marko Rosenmüller and Gunter Saake,,,,167-177,IEEE,Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However. when features interact. accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end. we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g.. databases. encoding libraries. and web servers …,True,_4ssMloAAAAJ:q3oQSFYPqjQC,233,https://ieeexplore.ieee.org/abstract/document/6227196/,6583761672055665857,/scholar?cites=6583761672055665857,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1071.6705&rep=rep1&type=pdf,0,0,0
1276149,Aspectual feature modules,2008,Sven Apel and Thomas Leich and Gunter Saake,34,"Software Engineering, IEEE Transactions on",2,162-180,IEEE,Two programming paradigms are gaining attention in the overlapping fields of software product lines (SPLs) and incremental software development (ISD). Feature-oriented programming (FOP) aims at large-scale compositional programming and feature modularity in SPLs using ISD. Aspect-oriented programming (AOP) focuses on the modularization of crosscutting concerns in complex software. Although feature modules. the main abstraction mechanisms of FOP. perform well in implementing large-scale software building blocks. they are incapable of modularizing certain kinds of crosscutting concerns. This weakness is exactly the strength of aspects. the main abstraction mechanisms of AOP. We contribute a systematic evaluation and comparison of FOP and AOP. It reveals that aspects and feature modules are complementary techniques. Consequently. we propose the symbiosis of FOP and AOP and aspectual …,True,_4ssMloAAAAJ:2osOgNQ5qMEC,209,https://ieeexplore.ieee.org/abstract/document/4407729/,2073638256591570496,/scholar?cites=2073638256591570496,,,https://drive.google.com/file/u/0/d/1rC2tN3lbREkqFgkCPPIcBiNulFZ3-cqu/view,0,0,0
1276150,The large area telescope on the Fermi gamma-ray space telescope mission,2009,WB Atwood and Aous A Abdo and Markus Ackermann and W Althouse and B Anderson and M Axelsson and Luca Baldini and J Ballet and DL Band and Guido Barbiellini and J Bartelt and D Bastieri and BM Baughman and K Bechtol and D Bédérède and F Bellardi and R Bellazzini and B Berenji and GF Bignami and D Bisello and Elisabetta Bissaldi and RD Blandford and ED Bloom and JR Bogart and E Bonamente and J Bonnell and AW Borgland and A Bouvier and J Bregeon and A Brez and M Brigida and P Bruel and TH Burnett and G Busetto and GA Caliandro and RA Cameron and PA Caraveo and Staffan Carius and P Carlson and JM Casandjian and E Cavazzuti and M Ceccanti and C Cecchi and E Charles and A Chekhtman and CC Cheung and J Chiang and R Chipaux and AN Cillis and S Ciprini and R Claus and J Cohen-Tanugi and S Condamoor and J Conrad and R Corbet and L Corucci and L Costamante and S Cutini and DS Davis and D Decotigny and M DeKlotz and CD Dermer and A De Angelis and SW Digel and E do Couto e Silva and PS Drell and R Dubois and D Dumora and Y Edmonds and D Fabiani and C Farnier and C Favuzzi and DL Flath and P Fleury and WB Focke and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and F-X Gentit and S Germani and B Giebels and N Giglietto and P Giommi and F Giordano and T Glanzman and G Godfrey and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and G Haller and AK Harding and PA Hart and E Hays and SE Healey and M Hirayama and L Hjalmarsdotter and R Horn and RE Hughes and G Jóhannesson and G Johansson and AS Johnson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and A Kavelaars and N Kawai and H Kelly and M Kerr and W Klamra and J Knödlseder and ML Kocian and N Komin and F Kuehn and M Kuss and D Landriu and L Latronico and B Lee and S-H Lee and M Lemoine-Goumard and AM Lionetto and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and A Makeev and B Marangelli and Marco Maria Massai and MN Mazziotta and JE McEnery and N Menon and C Meurer and PF Michelson and M Minuti and N Mirizzi and W Mitthumsiri and T Mizuno and AA Moiseev and C Monte and ME Monzani and E Moretti and A Morselli,697,,2,1071,IOP Publishing,A revolution is underway in our understanding of the highenergy sky. The early SAS 2 (Fichtel et al. 1975) and COS B,True,sFHXR6sAAAAJ:qxL8FJ1GzNcC,4153,https://iopscience.iop.org/article/10.1088/0004-637X/697/2/1071/meta,15337853610723244392,/scholar?cites=15337853610723244392,,,https://iopscience.iop.org/article/10.1088/0004-637X/697/2/1071/pdf,0,0,0
1276151,Fermi large area telescope third source catalog,2015,Fabio Acero and Markus Ackermann and M Ajello and A Albert and WB Atwood and Magnus Axelsson and Luca Baldini and J Ballet and Guido Barbiellini and D Bastieri and A Belfiore and R Bellazzini and E Bissaldi and RD Blandford and ED Bloom and JR Bogart and Raffaella Bonino and E Bottacini and J Bregeon and RJ Britto and P Bruel and R Buehler and TH Burnett and S Buson and GA Caliandro and RA Cameron and R Caputo and M Caragiulo and PA Caraveo and JM Casandjian and E Cavazzuti and E Charles and RCG Chaves and A Chekhtman and CC Cheung and J Chiang and G Chiaro and S Ciprini and R Claus and J Cohen-Tanugi and LR Cominsky and Jan Conrad and S Cutini and F D’ammando and A de Angelis and M DeKlotz and F de Palma and R Desiante and SW Digel and L Di Venere and PS Drell and R Dubois and D Dumora and C Favuzzi and SJ Fegan and EC Ferrara and J Finke and A Franckowiak and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and B Giebels and N Giglietto and P Giommi and F Giordano and M Giroletti and T Glanzman and G Godfrey and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and D Hadasch and AK Harding and E Hays and JW Hewitt and AB Hill and D Horan and G Iafrate and T Jogler and G Jóhannesson and RP Johnson and AS Johnson and TJ Johnson and WN Johnson and T Kamae and J Kataoka and J Katsuta and M Kuss and G La Mura and D Landriu and Stefan Larsson and L Latronico and M Lemoine-Goumard and J Li and L Li and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and Francesco Massaro and M Mayer and MN Mazziotta and JE McEnery and PF Michelson and N Mirabal and T Mizuno and AA Moiseev and M Mongelli and ME Monzani and A Morselli and IV Moskalenko and S Murgia and E Nuss and M Ohno and T Ohsugi and N Omodei and M Orienti and E Orlando and JF Ormes and D Paneque and JH Panetta and JS Perkins and M Pesce-Rollins and F Piron and Giovanna Pivato and TA Porter and JL Racusin and R Rando and Massimiliano Razzano and S Razzaque and A Reimer and O Reimer and T Reposeur and LS Rochester and RW Romani and D Salvetti and M Sánchez-Conde and PM Saz Parkinson and A Schulz and EJ Siskind and DA Smith and F Spada and G Spandre and P Spinelli,218,The Astrophysical Journal Supplement Series,2,23,IOP Publishing,We present the third Fermi Large Area Telescope (LAT) source catalog (3FGL) of sources in the 100 MeV–300 GeV range. Based on the first 4 yr of science data from the Fermi Gamma-ray Space Telescope mission. it is the deepest yet in this energy range. Relative to the Second Fermi LAT catalog. the 3FGL catalog incorporates twice as much data. as well as a number of analysis improvements. including improved calibrations at the event reconstruction level. an updated model for Galactic diffuse γ-ray emission. a refined procedure for source detection. and improved methods for associating LAT sources with potential counterparts at other wavelengths. The 3FGL catalog includes 3033 sources above  significance. with source location regions. spectral properties. and monthly light curves for each. Of these. 78 are flagged as potentially being due to imperfections in the model for Galactic diffuse emission. Twenty …,True,sFHXR6sAAAAJ:5nxA0vEk-isC,1653,https://iopscience.iop.org/article/10.1088/0067-0049/218/2/23/meta,11711056510126736734,/scholar?cites=11711056510126736734,,,https://iopscience.iop.org/article/10.1088/0067-0049/218/2/23/pdf,0,0,0
1276152,Fermi large area telescope second source catalog,2012,Patrick L Nolan and AA Abdo and Markus Ackermann and Marco Ajello and A Allafort and E Antolini and WB Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and Guido Barbiellini and D Bastieri and K Bechtol and A Belfiore and R Bellazzini and B Berenji and GF Bignami and RD Blandford and ED Bloom and E Bonamente and J Bonnell and AW Borgland and E Bottacini and A Bouvier and TJ Brandt and J Bregeon and M Brigida and Pascal Bruel and R Buehler and TH Burnett and S Buson and GA Caliandro and RA Cameron and R Campana and B Cañadas and A Cannon and PA Caraveo and JM Casandjian and E Cavazzuti and M Ceccanti and C Cecchi and Ö Çelik and E Charles and A Chekhtman and CC Cheung and J Chiang and R Chipaux and S Ciprini and R Claus and J Cohen-Tanugi and LR Cominsky and Jan Conrad and R Corbet and S Cutini and F D'Ammando and DS Davis and A de Angelis and ME DeCesar and M DeKlotz and A De Luca and PR den Hartog and F de Palma and CD Dermer and SW Digel and E do Couto e Silva and PS Drell and A Drlica-Wagner and R Dubois and D Dumora and T Enoto and L Escande and D Fabiani and L Falletti and C Favuzzi and SJ Fegan and EC Ferrara and WB Focke and P Fortin and M Frailis and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and S Germani and B Giebels and N Giglietto and P Giommi and F Giordano and M Giroletti and T Glanzman and G Godfrey and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and M Gustafsson and D Hadasch and Y Hanabata and AK Harding and M Hayashida and E Hays and AB Hill and D Horan and X Hou and RE Hughes and G Iafrate and R Itoh and G Jóhannesson and RP Johnson and TE Johnson and AS Johnson and TJ Johnson and T Kamae and H Katagiri and J Kataoka and J Katsuta and N Kawai and M Kerr and J Knödlseder and D Kocevski and M Kuss and J Lande and D Landriu and L Latronico and M Lemoine-Goumard and AM Lionetto and M Llena Garde and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and M Marelli and E Massaro and MN Mazziotta and W McConville and JE McEnery and J Mehault and PF Michelson and M Minuti and W Mitthumsiri and T Mizuno and AA Moiseev and M Mongelli and C Monte and ME Monzani,199,The Astrophysical Journal Supplement Series,2,31,IOP Publishing,This paper presents a catalog of high-energy γ-ray sources detected in the first two years of the Fermi Gamma-ray Space Telescope mission by the Large Area Telescope (LAT). It is the successor to the LAT Bright Source List (Abdo et al. 2009d) and the first Fermi-LAT (1FGL; Abdo et al. 2010f) catalog. which were based on 3 months and 11 months of flight data. respectively. The new catalog represents the deepest-ever catalog in the 100 MeV–100 GeV energy range and includes a number of analysis refinements. Some important improvements compared to the 1FGL catalog are the following.,True,sFHXR6sAAAAJ:_kc_bZDykSQC,1522,https://iopscience.iop.org/article/10.1088/0067-0049/199/2/31/meta,14200394053579205515,/scholar?cites=14200394053579205515,,,https://iopscience.iop.org/article/10.1088/0067-0049/199/2/31/pdf,0,0,0
1276153,Fermi large area telescope first source catalog,2010,AA ea Abdo and Markus Ackermann and Marco Ajello and A Allafort and E Antolini and WB Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and Guido Barbiellini and D Bastieri and BM Baughman and K Bechtol and R Bellazzini and F Belli and B Berenji and D Bisello and RD Blandford and ED Bloom and E Bonamente and J Bonnell and AW Borgland and A Bouvier and J Bregeon and A Brez and M Brigida and Pascal Bruel and TH Burnett and G Busetto and S Buson and GA Caliandro and RA Cameron and R Campana and B Canadas and PA Caraveo and S Carrigan and JM Casandjian and E Cavazzuti and M Ceccanti and C Cecchi and Ö Çelik and E Charles and A Chekhtman and CC Cheung and J Chiang and AN Cillis and S Ciprini and R Claus and J Cohen-Tanugi and J Conrad and R Corbet and DS Davis and M DeKlotz and PR Den Hartog and CD Dermer and A De Angelis and A De Luca and F De Palma and SW Digel and M Dormody and E do Couto e Silva and PS Drell and R Dubois and D Dumora and D Fabiani and C Farnier and C Favuzzi and SJ Fegan and EC Ferrara and WB Focke and P Fortin and M Frailis and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and S Germani and G Giavitto and B Giebels and N Giglietto and P Giommi and F Giordano and M Giroletti and T Glanzman and G Godfrey and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and M Gustafsson and D Hadasch and Y Hanabata and AK Harding and M Hayashida and E Hays and SE Healey and AB Hill and D Horan and RE Hughes and G Iafrate and G Johannesson and AS Johnson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and N Kawai and M Kerr and J Knödlseder and D Kocevski and M Kuss and J Lande and D Landriu and L Latronico and S-H Lee and M Lemoine-Goumard and AM Lionetto and M Llena Garde and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and A Makeev and B Marangelli and M Marelli and E Massaro and MN Mazziotta and W McConville and JE McEnery and PF Michelson and M Minuti and W Mitthumsiri and T Mizuno and AA Moiseev and M Mongelli and C Monte and ME Monzani and Elena Moretti and A Morselli and IV Moskalenko and S Murgia and H Nakajima and T Nakamori,188,The Astrophysical Journal Supplement Series,2,405,IOP Publishing,We present a catalog of high-energy gamma-ray sources detected by the Large Area Telescope (LAT). the primary science instrument on the Fermi Gamma-ray Space Telescope (Fermi). during the first 11 months of the science phase of the mission. which began on 2008 August 4. The First Fermi-LAT catalog (1FGL) contains 1451 sources detected and characterized in the 100 MeV to 100 GeV range. Source detection was based on the average flux over the 11 month period. and the threshold likelihood Test Statistic is 25. corresponding to a significance of just over 4σ. The 1FGL catalog includes source location regions. defined in terms of elliptical fits to the 95% confidence regions and power-law spectral fits as well as flux measurements in five energy bands for each source. In addition. monthly light curves are provided. Using a protocol defined before launch we have tested for several populations of gamma-ray …,True,sFHXR6sAAAAJ:M3ejUd6NZC8C,1325,https://iopscience.iop.org/article/10.1088/0067-0049/188/2/405/meta,15236665364345628976,/scholar?cites=15236665364345628976,,,https://iopscience.iop.org/article/10.1088/0067-0049/188/2/405/pdf,0,0,0
1276154,Measurement of the Cosmic Ray  Spectrum from 20 GeV to 1 TeV with the Fermi Large Area Telescope,2009,Aous A Abdo and Markus Ackermann and Marco Ajello and WB Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and Guido Barbiellini and Denis Bastieri and Milan Battelino and BM Baughman and K Bechtol and R Bellazzini and B Berenji and RD Blandford and Elliott D Bloom and G Bogaert and E Bonamente and AW Borgland and J Bregeon and A Brez and M Brigida and Pascal Bruel and TH Burnett and GA Caliandro and RA Cameron and PA Caraveo and P Carlson and JM Casandjian and C Cecchi and E Charles and A Chekhtman and CC Cheung and J Chiang and S Ciprini and R Claus and J Cohen-Tanugi and LR Cominsky and J Conrad and S Cutini and CD Dermer and A De Angelis and F De Palma and SW Digel and G Di Bernardo and E do Couto e Silva and PS Drell and R Dubois and D Dumora and Y Edmonds and C Farnier and C Favuzzi and WB Focke and M Frailis and Y Fukazawa and S Funk and P Fusco and D Gaggero and F Gargano and D Gasparrini and N Gehrels and S Germani and B Giebels and N Giglietto and F Giordano and T Glanzman and G Godfrey and D Grasso and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and Y Hanabata and AK Harding and RC Hartman and M Hayashida and E Hays and RE Hughes and G Jóhannesson and AS Johnson and RP Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and N Kawai and M Kerr and J Knödlseder and D Kocevski and F Kuehn and M Kuss and J Lande and L Latronico and M Lemoine-Goumard and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and A Makeev and MM Massai and MN Mazziotta and W McConville and JE McEnery and C Meurer and PF Michelson and W Mitthumsiri and T Mizuno and AA Moiseev and C Monte and ME Monzani and E Moretti and A Morselli and IV Moskalenko and S Murgia and PL Nolan and JP Norris and E Nuss and T Ohsugi and N Omodei and E Orlando and JF Ormes and M Ozaki and D Paneque and JH Panetta and D Parent and V Pelassa and M Pepe and M Pesce-Rollins and F Piron and M Pohl and TA Porter and S Profumo and S Raino and R Rando and M Razzano and A Reimer and O Reimer and T Reposeur and S Ritz and LS Rochester and AY Rodriguez and RW Romani and M Roth and F Ryde and HF-W Sadrozinski and D Sanchez and A Sander,102,Physical Review Letters,18,181101,American Physical Society,Designed as a high-sensitivity gamma-ray observatory. the Fermi Large Area Telescope is also an electron detector with a large acceptance exceeding 2 m 2 sr at 300 GeV. Building on the gamma-ray analysis. we have developed an efficient electron detection strategy which provides sufficient background rejection for measurement of the steeply falling electron spectrum up to 1 TeV. Our high precision data show that the electron spectrum falls with energy as E− 3.0 and does not exhibit prominent spectral features. Interpretations in terms of a conventional diffusive model as well as a potential local extra component are briefly discussed.,True,sFHXR6sAAAAJ:roLk4NBRz8UC,1257,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.102.181101,8881552529538659931,/scholar?cites=8881552529538659931,,,https://www.osti.gov/pages/servlets/purl/1357449,0,0,0
1276155,Fermi observations of high-energy gamma-ray emission from GRB 080916C,2009,Aous A Abdo and Markus Ackermann and M Arimoto and K Asano and William B Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and DL Band and Guido Barbiellini and Matthew G Baring and Denis Bastieri and M Battelino and BM Baughman and K Bechtol and F Bellardi and R Bellazzini and B Berenji and PN Bhat and Elisabetta Bissaldi and RD Blandford and ED Bloom and G Bogaert and JR Bogart and E Bonamente and J Bonnell and AW Borgland and A Bouvier and J Bregeon and A Brez and MS Briggs and M Brigida and Pascal Bruel and TH Burnett and D Burrows and G Busetto and GA Caliandro and RA Cameron and PA Caraveo and JM Casandjian and M Ceccanti and C Cecchi and A Celotti and E Charles and A Chekhtman and CC Cheung and J Chiang and S Ciprini and R Claus and J Cohen-Tanugi and LR Cominsky and V Connaughton and J Conrad and L Costamante and S Cutini and M DeKlotz and CD Dermer and A De Angelis and F De Palma and SW Digel and BL Dingus and E do Couto e Silva and PS Drell and R Dubois and D Dumora and Y Edmonds and PA Evans and D Fabiani and C Farnier and C Favuzzi and J Finke and G Fishman and WB Focke and M Frailis and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and S Germani and B Giebels and N Giglietto and P Giommi and F Giordano and T Glanzman and G Godfrey and A Goldstein and J Granot and J Greiner and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and G Haller and Y Hanabata and AK Harding and M Hayashida and E Hays and JA Hernando Morata and A Hoover and RE Hughes and G Jóhannesson and AS Johnson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and A Kavelaars and N Kawai and H Kelly and J Kennea and M Kerr and RM Kippen and J Knödlseder and D Kocevski and ML Kocian and N Komin and C Kouveliotou and F Kuehn and M Kuss and J Lande and D Landriu and S Larsson and L Latronico and C Lavalley and B Lee and S-H Lee and M Lemoine-Goumard and GG Lichti and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and A Makeev and B Marangelli and MN Mazziotta and S McBreen and JE McEnery and S McGlynn and C Meegan and P Mészáros and C Meurer and PF Michelson and M Minuti,,Science,,,American Association for the Advancement of Science,Downloaded from/www. sciencexpress. org/19 February 2009/Page 2/10.1126/science. 1169101 (a. b. c. d. e) delineated by the vertical lines (Fig. 1). The GRB lightcurve at low energy has two bright peaks. one between 0 and 3.6 s after the trigger (intervala'). and one between 3.6 and 7.7 s (intervalb'). The two peaks are distinct in the BGO lightcurve. but less so in the NaI. In the LAT detector the first peak is not significant though the lightcurve shows evidence of activity in time interval (a). mostly in events below 100 MeV. Above 100 MeV. peak (b) is prominent in the LAT lightcurve. Interval (c) coincides with the tail of the main pulse. and the last two intervals reflect temporal structure in the NaI lightcurve and have been chosen to provide enough statistics in the LAT energy band for spectral analysis. The highest energy photon was observed during interval (d): Eh= 13.22+ 0.70− 1.54 GeV. Most of the emission in peak …,True,sFHXR6sAAAAJ:Zph67rFs4hoC,746,https://science.sciencemag.org/content/sci/early/2009/02/19/science.1169101.full.pdf,13170949725607574204,/scholar?cites=13170949725607574204,,,https://www.osti.gov/pages/servlets/purl/1357451,0,0,0
1276156,Fermi/large area telescope bright gamma-ray source list,2009,Aous A Abdo and Markus Ackermann and Marco Ajello and WB Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and DL Band and Guido Barbiellini and Denis Bastieri and M Battelino and BM Baughman and K Bechtol and R Bellazzini and B Berenji and GF Bignami and RD Blandford and ED Bloom and E Bonamente and AW Borgland and A Bouvier and J Bregeon and A Brez and M Brigida and P Bruel and TH Burnett and GA Caliandro and RA Cameron and PA Caraveo and JM Casandjian and E Cavazzuti and C Cecchi and E Charles and A Chekhtman and CC Cheung and J Chiang and S Ciprini and R Claus and J Cohen-Tanugi and LR Cominsky and J Conrad and R Corbet and L Costamante and S Cutini and DS Davis and CD Dermer and A de Angelis and A De Luca and F de Palma and SW Digel and M Dormody and E do Couto e Silva and PS Drell and R Dubois and D Dumora and C Farnier and C Favuzzi and SJ Fegan and EC Ferrara and WB Focke and M Frailis and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and S Germani and B Giebels and N Giglietto and P Giommi and F Giordano and T Glanzman and G Godfrey and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and Y Hanabata and AK Harding and RC Hartman and M Hayashida and E Hays and SE Healey and D Horan and RE Hughes and G Jóhannesson and AS Johnson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and N Kawai and M Kerr and J Knödlseder and D Kocevski and ML Kocian and N Komin and F Kuehn and M Kuss and J Lande and L Latronico and S-H Lee and M Lemoine-Goumard and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and GM Madejski and A Makeev and M Marelli and MN Mazziotta and W McConville and JE McEnery and S McGlynn and C Meurer and PF Michelson and W Mitthumsiri and T Mizuno and AA Moiseev and C Monte and ME Monzani and E Moretti and A Morselli and IV Moskalenko and S Murgia and T Nakamori and PL Nolan and JP Norris and E Nuss and M Ohno and T Ohsugi and N Omodei and E Orlando and JF Ormes and M Ozaki and D Paneque and JH Panetta and D Parent and V Pelassa and M Pepe and M Pesce-Rollins and F Piron and TA Porter and L Poupard and S Raino,183,The Astrophysical Journal Supplement Series,1,46,IOP Publishing,Following its launch in 2008 June. the Fermi Gamma-ray Space Telescope (Fermi) began a sky survey in August. The Large Area Telescope (LAT) on Fermi in three months produced a deeper and better resolved map of the γ-ray sky than any previous space mission. We present here initial results for energies above 100 MeV for the 205 most significant (statistical significance greater than∼ 10σ) γ-ray sources in these data. These are the best characterized and best localized point-like (ie. spatially unresolved) γ-ray sources in the early mission data.,True,sFHXR6sAAAAJ:qjMakFHDy7sC,655,https://iopscience.iop.org/article/10.1088/0067-0049/183/1/46/meta,1977933971059691579,/scholar?cites=1977933971059691579,,,https://iopscience.iop.org/article/10.1088/0067-0049/183/1/46/pdf,0,0,0
1276157,The Fermi large area telescope on orbit: event classification. instrument response functions. and calibration,2012,Markus Ackermann and Marco Ajello and A Albert and A Allafort and WB Atwood and Magnus Axelsson and Luca Baldini and Jean Ballet and Guido Barbiellini and D Bastieri and K Bechtol and R Bellazzini and Elisabetta Bissaldi and RD Blandford and ED Bloom and JR Bogart and E Bonamente and AW Borgland and E Bottacini and A Bouvier and TJ Brandt and J Bregeon and M Brigida and Pascal Bruel and R Buehler and TH Burnett and S Buson and GA Caliandro and RA Cameron and PA Caraveo and JM Casandjian and E Cavazzuti and C Cecchi and Ö Çelik and E Charles and RCG Chaves and A Chekhtman and CC Cheung and J Chiang and S Ciprini and R Claus and J Cohen-Tanugi and Jan Conrad and R Corbet and S Cutini and F D’Ammando and DS Davis and A De Angelis and M DeKlotz and F De Palma and CD Dermer and SW Digel and E do Couto e Silva and PS Drell and A Drlica-Wagner and R Dubois and C Favuzzi and SJ Fegan and EC Ferrara and WB Focke and P Fortin and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and B Giebels and N Giglietto and F Giordano and M Giroletti and T Glanzman and G Godfrey and IA Grenier and JE Grove and S Guiriec and D Hadasch and M Hayashida and E Hays and D Horan and X Hou and RE Hughes and Miranda S Jackson and T Jogler and G Jóhannesson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and M Kerr and J Knödlseder and M Kuss and J Lande and Stefan Larsson and L Latronico and C Lavalley and M Lemoine-Goumard and F Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and MN Mazziotta and W McConville and JE McEnery and J Mehault and PF Michelson and W Mitthumsiri and T Mizuno and AA Moiseev and C Monte and ME Monzani and A Morselli and IV Moskalenko and S Murgia and M Naumann-Godo and R Nemmen and S Nishino and JP Norris and E Nuss and M Ohno and T Ohsugi and A Okumura and N Omodei and M Orienti and E Orlando and JF Ormes and D Paneque and JH Panetta and JS Perkins and M Pesce-Rollins and M Pierbattista and F Piron and G Pivato and TA Porter and JL Racusin and S Rainò and R Rando and M Razzano and S Razzaque and A Reimer and O Reimer and T Reposeur and LC Reyes and S Ritz and LS Rochester and C Romoli and M Roth,203,The Astrophysical Journal Supplement Series,1,4,IOP Publishing,The Fermi Large Area Telescope (Fermi-LAT. hereafter LAT). the primary instrument on the Fermi Gamma-ray Space Telescope (Fermi) mission. is an imaging. wide field-of-view. high-energy γ-ray telescope. covering the energy range from 20 MeV to more than 300 GeV. During the first years of the mission. the LAT team has gained considerable insight into the in-flight performance of the instrument. Accordingly. we have updated the analysis used to reduce LAT data for public release as well as the instrument response functions (IRFs). the description of the instrument performance provided for data analysis. In this paper. we describe the effects that motivated these updates. Furthermore. we discuss how we originally derived IRFs from Monte Carlo simulations and later corrected those IRFs for discrepancies observed between flight and simulated data. We also give details of the validations performed using flight …,True,sFHXR6sAAAAJ:WF5omc3nYNoC,604,https://iopscience.iop.org/article/10.1088/0067-0049/203/1/4/meta,6239761302209355355,/scholar?cites=6239761302209355355,,,https://iopscience.iop.org/article/10.1088/0067-0049/203/1/4/pdf,0,0,0
1276158,Fermi LAT observations of cosmic-ray electrons from 7 GeV to 1 TeV,2010,Markus Ackermann and Marco Ajello and WB Atwood and Luca Baldini and Jean Ballet and Guido Barbiellini and D Bastieri and BM Baughman and K Bechtol and F Bellardi and R Bellazzini and F Belli and B Berenji and RD Blandford and ED Bloom and JR Bogart and E Bonamente and AW Borgland and TJ Brandt and J Bregeon and A Brez and M Brigida and Pascal Bruel and R Buehler and TH Burnett and G Busetto and S Buson and GA Caliandro and RA Cameron and PA Caraveo and Per Carlson and S Carrigan and JM Casandjian and M Ceccanti and C Cecchi and Ö Çelik and E Charles and A Chekhtman and CC Cheung and J Chiang and AN Cillis and S Ciprini and R Claus and J Cohen-Tanugi and Jan Conrad and R Corbet and M Deklotz and CD Dermer and A De Angelis and F De Palma and SW Digel and G Di Bernardo and E do Couto e Silva and PS Drell and A Drlica-Wagner and R Dubois and D Fabiani and C Favuzzi and SJ Fegan and P Fortin and Y Fukazawa and S Funk and P Fusco and D Gaggero and F Gargano and D Gasparrini and N Gehrels and S Germani and N Giglietto and P Giommi and F Giordano and M Giroletti and T Glanzman and G Godfrey and D Grasso and IA Grenier and M-H Grondin and JE Grove and S Guiriec and M Gustafsson and D Hadasch and AK Harding and M Hayashida and E Hays and D Horan and RE Hughes and G Jóhannesson and AS Johnson and RP Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and M Kerr and J Knödlseder and M Kuss and J Lande and L Latronico and M Lemoine-Goumard and M Llena Garde and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and A Makeev and MN Mazziotta and JE McEnery and J Mehault and PF Michelson and M Minuti and W Mitthumsiri and T Mizuno and AA Moiseev and C Monte and ME Monzani and Elena Moretti and A Morselli and IV Moskalenko and S Murgia and T Nakamori and M Naumann-Godo and PL Nolan and JP Norris and E Nuss and T Ohsugi and A Okumura and N Omodei and E Orlando and JF Ormes and M Ozaki and D Paneque and JH Panetta and D Parent and V Pelassa and M Pepe and M Pesce-Rollins and V Petrosian and M Pinchera and F Piron and TA Porter and S Profumo and S Rainò and R Rando and E Rapposelli and Massimiliano Razzano and A Reimer and O Reimer and T Reposeur and Joachim Ripken,82,Physical Review D,9,092004,American Physical Society,We present the results of our analysis of cosmic-ray electrons using about 8× 10 6 electron candidates detected in the first 12 months on-orbit by the Fermi Large Area Telescope. This work extends our previously published cosmic-ray electron spectrum down to 7 GeV. giving a spectral range of approximately 2.5 decades up to 1 TeV. We describe in detail the analysis and its validation using beam-test and on-orbit data. In addition. we describe the spectrum measured via a subset of events selected for the best energy resolution as a cross-check on the measurement using the full event sample. Our electron spectrum can be described with a power law∝ E− 3.08±0.05 with no prominent spectral features within systematic uncertainties. Within the limits of our uncertainties. we can accommodate a slight spectral hardening at around 100 GeV and a slight softening above 500 GeV.,True,sFHXR6sAAAAJ:zYLM7Y9cAGgC,471,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.82.092004,4034404181899865638,/scholar?cites=4034404181899865638,,,https://arxiv.org/pdf/1008.3999,0,0,0
1276159,On possible interpretations of the high energy electron–positron spectrum measured by the Fermi Large Area Telescope,2009,D Grasso and S Profumo and AW Strong and Luca Baldini and R Bellazzini and ED Bloom and J Bregeon and G Di Bernardo and D Gaggero and N Giglietto and T Kamae and L Latronico and Francesco Longo and MN Mazziotta and AA Moiseev and A Morselli and JF Ormes and M Pesce-Rollins and M Pohl and Massimiliano Razzano and C Sgro and G Spandre and TE Stephens,32,Astroparticle Physics,2,140-151,North-Holland,The Fermi-LAT experiment recently reported high precision measurements of the spectrum of cosmic-ray electrons-plus-positrons (CRE) between 20 GeV and 1 TeV. The spectrum shows no prominent spectral features. and is significantly harder than that inferred from several previous experiments. Here we discuss several interpretations of the Fermi results based either on a single large scale Galactic CRE component or by invoking additional electron–positron primary sources. e.g. nearby pulsars or particle dark matter annihilation. We show that while the reported Fermi-LAT data alone can be interpreted in terms of a single component scenario. when combined with other complementary experimental results. specifically the CRE spectrum measured by H.E.S.S. and especially the positron fraction reported by PAMELA between 1 and 100 GeV. that class of models fails to provide a consistent interpretation. Rather …,True,sFHXR6sAAAAJ:kNdYIx-mwKoC,364,https://www.sciencedirect.com/science/article/pii/S0927650509001078,12521096061065860090,/scholar?cites=12521096061065860090,,,https://arxiv.org/pdf/0905.0636,0,0,0
1276160,The on-orbit calibration of the Fermi Large Area Telescope,2009,Aous A Abdo and Markus Ackermann and Marco Ajello and J Ampe and B Anderson and WB Atwood and Magnus Axelsson and R Bagagli and Luca Baldini and Jean Ballet and Guido Barbiellini and J Bartelt and Denis Bastieri and BM Baughman and K Bechtol and D Bédérède and F Bellardi and R Bellazzini and F Belli and B Berenji and D Bisello and Elisabetta Bissaldi and ED Bloom and G Bogaert and JR Bogart and E Bonamente and AW Borgland and P Bourgeois and A Bouvier and J Bregeon and A Brez and M Brigida and Pascal Bruel and TH Burnett and G Busetto and GA Caliandro and RA Cameron and M Campell and PA Caraveo and Staffan Carius and P Carlson and JM Casandjian and E Cavazzuti and M Ceccanti and C Cecchi and E Charles and A Chekhtman and CC Cheung and J Chiang and R Chipaux and AN Cillis and S Ciprini and R Claus and J Cohen-Tanugi and S Condamoor and J Conrad and R Corbet and S Cutini and DS Davis and M DeKlotz and CD Dermer and A De Angelis and F De Palma and SW Digel and P Dizon and M Dormody and E do Couto e Silva and PS Drell and R Dubois and D Dumora and Y Edmonds and D Fabiani and C Farnier and C Favuzzi and EC Ferrara and O Ferreira and Z Fewtrell and DL Flath and P Fleury and WB Focke and K Fouts and M Frailis and D Freytag and Y Fukazawa and S Funk and P Fusco and F Gargano and D Gasparrini and N Gehrels and S Germani and B Giebels and N Giglietto and F Giordano and T Glanzman and G Godfrey and J Goodman and IA Grenier and M-H Grondin and JE Grove and L Guillemot and S Guiriec and M Hakimi and G Haller and Y Hanabata and PA Hart and P Hascall and E Hays and M Huffer and RE Hughes and G Johannesson and AS Johnson and RP Johnson and TJ Johnson and WN Johnson and T Kamae and H Katagiri and J Kataoka and A Kavelaars and H Kelly and M Kerr and W Klamra and J Knödlseder and ML Kocian and F Kuehn and M Kuss and L Latronico and C Lavalley and B Leas and B Lee and S-H Lee and M Lemoine-Goumard and Francesco Longo and F Loparco and B Lott and MN Lovellette and P Lubrano and DK Lung and GM Madejski and A Makeev and B Marangelli and M Marchetti and Marco Maria Massai and D May and G Mazzenga and MN Mazziotta and JE McEnery and S McGlynn and C Meurer and PF Michelson and M Minuti,32,Astroparticle Physics,3-4,193-219,North-Holland,The Large Area Telescope (LAT) on-board the Fermi Gamma-ray Space Telescope began its on-orbit operations on June 23. 2008. Calibrations. defined in a generic sense. correspond to synchronization of trigger signals. optimization of delays for latching data. determination of detector thresholds. gains and responses. evaluation of the perimeter of the South Atlantic Anomaly (SAA). measurements of live time. of absolute time. and internal and spacecraft boresight alignments. Here we describe on-orbit calibration results obtained using known astrophysical sources. galactic cosmic rays. and charge injection into the front-end electronics of each detector. Instrument response functions will be described in a separate publication. This paper demonstrates the stability of calibrations and describes minor changes observed since launch. These results have been used to calibrate the LAT datasets to be publicly released …,True,sFHXR6sAAAAJ:4TOpqqG69KYC,215,https://www.sciencedirect.com/science/article/pii/S0927650509001352,14445830907811308243,/scholar?cites=14445830907811308243,,,https://www.osti.gov/servlets/purl/1357429,0,0,0
1276161,Systematic literature reviews in software engineering–a systematic literature review,2009,Barbara Kitchenham and O Pearl Brereton and David Budgen and Mark Turner and John Bailey and Stephen Linkman,51,,1,7-15,Elsevier,In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference.This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence.We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings.Of 20 relevant studies. eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4.Currently. the topic areas covered by SLRs are limited. European researchers. particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence …,True,pBN51isAAAAJ:4fKUyHm3Qg0C,2675,https://www.sciencedirect.com/science/article/pii/S0950584908001390,14563517766994888844,/scholar?cites=14563517766994888844,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.9182&rep=rep1&type=pdf,0,0,0
1276162,Lessons from applying the systematic literature review process within the software engineering domain,2007,Pearl Brereton and Barbara A Kitchenham and David Budgen and Mark Turner and Mohamed Khalil,80,,4,571-583,Elsevier,A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach. the practice of systematic literature review. to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised. a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted.The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights …,True,pBN51isAAAAJ:u5HHmVD_uO8C,1940,https://www.sciencedirect.com/science/article/pii/S016412120600197X,3247557312333793226,/scholar?cites=3247557312333793226,,,https://www.sciencedirect.com/science/article/pii/S016412120600197X,0,0,0
1276163,Does the technology acceptance model predict actual use? A systematic literature review,2010,Mark Turner and Barbara Kitchenham and Pearl Brereton and Stuart Charters and David Budgen,52,,5,463-479,Elsevier,The technology acceptance model (TAM) was proposed in 1989 as a means of predicting technology usage. However. it is usually validated by using a measure of behavioural intention to use (BI) rather than actual usage.This review examines the evidence that the TAM predicts actual usage using both subjective and objective measures of actual usage.We performed a systematic literature review based on a search of six digital libraries. along with vote-counting meta-analysis to analyse the overall results.The search identified 79 relevant empirical studies in 73 articles. The results show that BI is likely to be correlated with actual usage. However. the TAM variables perceived ease of use (PEU) and perceived usefulness (PU) are less likely to be correlated with actual usage.Care should be taken using the TAM outside the context in which it has been validated.,True,pBN51isAAAAJ:d1gkVwhDpl0C,817,https://www.sciencedirect.com/science/article/pii/S0950584909002055,5564301797652352464,/scholar?cites=5564301797652352464,,,https://www.academia.edu/download/50268701/Does_the_technology_acceptance_model_pre20161112-26606-16jrjzj.pdf,0,0,0
1276164,Turning software into a service,2003,Mark Turner and David Budgen and Pearl Brereton,36,Computer,10,38-44,IEEE,The software as a service model composes services dynamically. as needed. by binding several lower-level services-thus overcoming many limitations that constrain traditional software use. deployment. and evolution.,True,pBN51isAAAAJ:u-x6o8ySG0sC,806,https://ieeexplore.ieee.org/abstract/document/1236470/,9340963101078923796,/scholar?cites=9340963101078923796,,,https://dro.dur.ac.uk/624/1/624.pdf,0,0,0
1276165,Systematic literature reviews in software engineering–a tertiary study,2010,Barbara Kitchenham and Rialette Pretorius and David Budgen and O Pearl Brereton and Mark Turner and Mahmood Niazi and Stephen Linkman,52,,8,792-805,Elsevier,In a previous study. we reported on a systematic literature review (SLR). based on a manual search of 13 journals and conferences undertaken in the period 1st January 2004 to 30th June 2007.The aim of this on-going research is to provide an annotated catalogue of SLRs available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search.We performed a broad automated search to find SLRs published in the time period 1st January 2004 to 30th June 2008. We contrast the number. quality and source of these SLRs with SLRs found in the original study.Our broad search found an additional 35 SLRs corresponding to 33 unique studies. Of these papers. 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of SLRs being published is …,True,pBN51isAAAAJ:B3FOqHPlNUQC,780,https://www.sciencedirect.com/science/article/pii/S0950584910000467,8543740193074692352,/scholar?cites=8543740193074692352,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1048.8963&rep=rep1&type=pdf,0,0,0
1276166,Using mapping studies as the basis for further research–a participant-observer case study,2011,Barbara A Kitchenham and David Budgen and O Pearl Brereton,53,,6,638-651,Elsevier,We are strong advocates of evidence-based software engineering (EBSE) in general and systematic literature reviews (SLRs) in particular. We believe it is essential that the SLR methodology is used constructively to support software engineering research.This study aims to assess the value of mapping studies which are a form of SLR that aims to identify and categorise the available research on a broad software engineering topic.We used a multi-case. participant-observer case study using five examples of studies that were based on preceding mapping studies. We also validated our results by contacting two other researchers who had undertaken studies based on preceding mapping studies and by assessing review comments related to our follow-on studies.Our original case study identified 11 unique benefits that can accrue from basing research on a preceding mapping study of …,True,pBN51isAAAAJ:sSrBHYA8nusC,554,https://www.sciencedirect.com/science/article/pii/S0950584910002272,785208108783246535,/scholar?cites=785208108783246535,,,https://eprints.keele.ac.uk/2685/3/kitchenham-2011-IST.pdf,0,0,0
1276167,A systematic review of systematic review process research in software engineering,2013,Barbara Kitchenham and Pearl Brereton,55,,12,2049-2075,Elsevier,Many researchers adopting systematic reviews (SRs) have also published papers discussing problems with the SR methodology and suggestions for improving it. Since guidelines for SRs in software engineering (SE) were last updated in 2007. we believe it is time to investigate whether the guidelines need to be amended in the light of recent research.To identify. evaluate and synthesize research published by software engineering researchers concerning their experiences of performing SRs and their proposals for improving the SR process.We undertook a systematic review of papers reporting experiences of undertaking SRs and/or discussing techniques that could be used to improve the SR process. Studies were classified with respect to the stage in the SR process they addressed. whether they related to education or problems faced by novices and whether they proposed the use of …,True,pBN51isAAAAJ:UeHWp8X0CEIC,535,https://www.sciencedirect.com/science/article/pii/S0950584913001560,1736668098199170402,/scholar?cites=1736668098199170402,,,https://eprints.keele.ac.uk/2683/1/B%20Kitchenham%20-%20A%20systematic%20review%20of%20systematic%20review%20process%20research%20in%20software%20engineering.pdf,0,0,0
1276168,Using Mapping Studies in Software Engineering.,2008,David Budgen and Mark Turner and Pearl Brereton and Barbara A Kitchenham,8,Ppig,,195-204,,Background: A mapping study provides a systematic and objective procedure for identifying the nature and extent of the empirical study data that is available to answer a particular research question. Such studies can also form a useful preliminary step for PhD study.Aim: We set out to assess how effective such studies have been when used for software engineering topics. and to identify the specific challenges that they present.Method: We have conducted an informal review of a number of mapping studies in software engineering. describing their main characteristics and the forms of analysis employed. Results: We examine the experiences and outcomes from six mapping studies. of which four are published. From these we note a recurring theme about the problems of classification and a preponderance of ‘gaps’ in the set of empirical studies.Conclusions: We identify our challenges as improving classification guidelines. encouraging better reporting of primary studies. and argue for identifying some’empirical grand challenges’ for software engineering as a focus for the community1.,True,pBN51isAAAAJ:2osOgNQ5qMEC,377,http://ramus.se.uni-hannover.de/glosebase/images/b/b3/Using_Mapping_Studies_in_Software_Engineering-anno.pdf,952955619788685144,/scholar?cites=952955619788685144,,,http://ramus.se.uni-hannover.de/glosebase/images/b/b3/Using_Mapping_Studies_in_Software_Engineering-anno.pdf,0,0,0
1276169,Evidence-based software engineering and systematic reviews,2015,Barbara Ann Kitchenham and David Budgen and Pearl Brereton,4,,,,CRC press,In the decade since the idea of adapting the evidence-based paradigm for software engineering was first proposed. it has become a major tool of empirical software engineering. Evidence-Based Software Engineering and Systematic Reviews provides a clear introduction to the use of an evidence-based model for software engineering research and practice.,True,pBN51isAAAAJ:qxL8FJ1GzNcC,354,http://books.google.com/books?hl=en&lr=&id=bGfdCgAAQBAJ&oi=fnd&pg=PP1&dq=info:9KhybjJivGQJ:scholar.google.com&ots=VMF1SaKNWA&sig=WgpPG4hJ7Fufce3qsuaIIauFeeQ,7258784668155291892,/scholar?cites=7258784668155291892,,,,0,0,0
1276170,Performing systematic literature reviews in software engineering,2006,David Budgen and Pearl Brereton,,,,1051-1052,,Context: Making best use of the growing number of empirical studies in Software Engineering. for making decisions and formulating research questions. requires the ability to construct an objective summary of available research evidence. Adopting a systematic approach to assessing and aggregating the outcomes from a set of empirical studies is also particularly important in Software Engineering. given that such studies may employ very different experimental forms and be undertaken in very different experimental contexts. Objectives: To provide an introduction to the role. form and processes involved in performing Systematic Literature Reviews. After the tutorial. participants should be able to read and use such reviews. and have gained the knowledge needed to conduct systematic reviews of their own. Method: We will use a blend of information presentation (including some experiences of the problems that can …,True,pBN51isAAAAJ:YsMSGLbcyi4C,334,https://dl.acm.org/doi/abs/10.1145/1134285.1134500,8200424800277817283,/scholar?cites=8200424800277817283,,,https://www.irisa.fr/lande/lande/icse-proceedings/icse/p1051.pdf,0,0,0
1276171,Service-based software: the future for flexible software,2000,Keith Bennett and Paul Layzell and David Budgen and Pearl Brereton and Linda Macaulay and Malcolm Munro,,,,214-221,IEEE,For the past 40 years. the techniques. processes and methods of software development have been dominated by supply-side issues. giving rise to a software industry oriented towards developers rather than users. To achieve the levels of functionality. flexibility and time-to-market required by users. a radical shift is required in the development of software. with a more demand-centric view. leading to software which will be delivered as a service within the framework of an open marketplace. Already. there are some signs that this approach is being adopted by industry. but in a very limited way. We summarise research and a research method which has resulted in a long-term strategic view of software engineering innovation. Based on this foundation. we describe more recent work. which has resulted in an innovative demand-side model for the future of software. We propose a service architecture in which …,True,pBN51isAAAAJ:9yKSN-GCB0IC,319,https://ieeexplore.ieee.org/abstract/document/896702/,8321169541364721820,/scholar?cites=8321169541364721820,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3674&rep=rep1&type=pdf,0,0,0
1276172,Requirements engineering: a roadmap,2000,Bashar Nuseibeh and Steve Easterbrook,,,,35-46,,This paper presents an overview of the field of software systems requirements engineering (RE). It describes the main areas of RE practice. and highlights some key open research issues for the future.,True,bD8DWiEAAAAJ:u5HHmVD_uO8C,2906,https://dl.acm.org/doi/abs/10.1145/336512.336523,17583760794092376146,/scholar?cites=17583760794092376146,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.4288&rep=rep1&type=pdf,0,0,0
1276173,Selecting empirical methods for software engineering research,2008,Steve Easterbrook and Janice Singer and Margaret-Anne Storey and Daniela Damian,,,,285-311,Springer. London,Selecting a research method for empirical software engineering research is problematic because the benefits and challenges to using each method are not yet well catalogued. Therefore. this chapter describes a number of empirical methods available. It examines the goals of each and analyzes the types of questions each best addresses. Theoretical stances behind the methods. practical considerations in the application of the methods and data collection are also briefly reviewed. Taken together. this information provides a suitable basis for both understanding and selecting from the variety of methods applicable to empirical software engineering.,True,bD8DWiEAAAAJ:Tyk-4Ss8FVUC,1342,https://link.springer.com/chapter/10.1007/978-1-84800-044-5_11,9728078615205123012,/scholar?cites=9728078615205123012,,,http://maveric0.uwaterloo.ca/~migod/846/papers/easterbrookChapter.pdf,0,0,0
1276174,Matching and merging of statecharts specifications,2007,Shiva Nejati and Mehrdad Sabetzadeh and Marsha Chechik and Steve Easterbrook and Pamela Zave,,,,54-64,IEEE,Model Management addresses the problem of managing an evolving collection of models. by capturing the relationships between models and providing well-defined operators to manipulate them. In this paper. we describe two such operators for manipulating hierarchical Statecharts: Match. for finding correspondences between models. and Merge. for combining models with respect to known correspondences between them. Our Match operator is heuristic. making use of both static and behavioural properties of the models to improve the accuracy of matching. Our Merge operator preserves the hierarchical structure of the input models. and handles differences in behaviour through parameterization. In this way. we automatically construct merges that preserve the semantics of Statecharts models. We illustrate and evaluate our work by applying our operators to AT&T telecommunication features.,True,bD8DWiEAAAAJ:u-x6o8ySG0sC,359,https://ieeexplore.ieee.org/abstract/document/4222568/,18152811669205881054,/scholar?cites=18152811669205881054,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.4261&rep=rep1&type=pdf,0,0,0
1276175,Using benchmarking to advance research: A challenge to software engineering,2003,Susan Elliott Sim and Steve Easterbrook and Richard C Holt,,,,74-83,IEEE,Benchmarks have been used in computer science to compare the performance of computer systems. information retrieval algorithms. databases. and many other technologies. The creation and widespread use of a benchmark within a research area is frequently accompanied by rapid technical progress and community building. These observations have led us to formulate a theory of benchmarking within scientific disciplines. Based on this theory. we challenge software engineering research to become more scientific and cohesive by working as a community to define benchmarks. In support of this challenge. we present a case study of the reverse engineering community. where we have successfully used benchmarks to advance the state of research.,True,bD8DWiEAAAAJ:IjCSPb-OGe4C,328,https://ieeexplore.ieee.org/abstract/document/1201189/,15791227937774649306,/scholar?cites=15791227937774649306,,,http://www.cs.toronto.edu/~sme/papers/2003/icse03-challenge.pdf,0,0,0
1276176,Using viewpoints for inconsistency management,1996,Steve Easterbrook and Bashar Nuseibeh,11,Software Engineering Journal,1,31-43,IET,Large-scale software development is an evolutionary process. In an evolving specification. multiple development participants often hold multiple inconsistent views on the system being developed. and considerable effort is spent handling recurrent inconsistencies. Detecting and resolving inconsistencies is only part of the problem; a resolved inconsistency might not stay resolved as a specification evolves. Frameworks in which inconsistency is tolerated help by allowing resolution to be delayed. However. the evolution of a specification may affect both resolved and unresolved inconsistencies. A framework is presented and elaborated in which software development knowledge is partitioned into multiple views called ViewPoints. Inconsistencies between ViewPoints are managed by explicitly representing relationships between them. and recording both resolved and unresolved inconsistencies. It is assumed that …,True,bD8DWiEAAAAJ:yB1At4FlUx8C,284,https://digital-library.theiet.org/content/journals/10.1049/sej.1996.0004,16371022820936117325,/scholar?cites=16371022820936117325,,,http://www.panda.sys.t.u-tokyo.ac.jp/kushiro/ReferencePaper/Requirements%20Elicitation/00487321.pdf,0,0,0
1276177,Leveraging inconsistency in software development,2000,Bashar Nuseibeh and Steve Easterbrook and Alessandra Russo,33,Computer,4,24-29,IEEE,Software engineers make use of many descriptions. including analysis models. specifications. designs. program code. user guides. test plans. change requests. style guides. schedules. and process models. But since different developers construct and update these descriptions at various times during development. maintaining consistency among descriptions presents several problems. Descriptions tend to vary considerably. Individual descriptions can be ill-formed or self-contradictory and frequently evolve throughout the life cycle at different rates. Also. checking the consistency of a large. arbitrary set of descriptions is computationally expensive. The authors assert that maintaining consistency at all times is counterproductive. In many cases. it may be desirable to tolerate or even encourage inconsistency to facilitate distributed team-work and prevent premature commitment to design decisions. They advocate …,True,bD8DWiEAAAAJ:d1gkVwhDpl0C,250,https://ieeexplore.ieee.org/abstract/document/839317/,15974383725032531370,/scholar?cites=15974383725032531370,,,https://www.researchgate.net/profile/Alessandra_Russo4/publication/2955246_Leveraging_Inconsistency_in_Software_Development/links/02e7e52f0af9042f6f000000/Leveraging-Inconsistency-in-Software-Development.pdf,0,0,0
1276178,Multi-valued symbolic model-checking,2003,Marsha Chechik and Benet Devereux and Steve Easterbrook and Arie Gurfinkel,12,ACM Transactions on Software Engineering and Methodology (TOSEM),4,371-408,ACM,This article introduces the concept of multi-valued model-checking and describes a multi-valued symbolic model-checker. ΧChek. Multi-valued model-checking is a generalization of classical model-checking. useful for analyzing models that contain uncertainty (lack of essential information) or inconsistency (contradictory information. often occurring when information is gathered from multiple sources). Multi-valued logics support the explicit modeling of uncertainty and disagreement by providing additional truth values in the logic.This article provides a theoretical basis for multi-valued model-checking and discusses some of its applications. A companion article [Chechik et al. 2002b] describes implementation issues in detail. The model-checker works for any member of a large class of multi-valued logics. Our modeling language is based on a generalization of Kripke structures. where both atomic propositions and …,True,bD8DWiEAAAAJ:zYLM7Y9cAGgC,248,https://dl.acm.org/doi/abs/10.1145/990010.990011,17829438605757514901,/scholar?cites=17829438605757514901,,,https://www.researchgate.net/profile/Marsha_Chechik/publication/220403865_Multi-valued_symbolic_model-checking/links/09e41510c2bdda0427000000.pdf,0,0,0
1276179,Communication problems in requirements engineering: a field study,1996,Amer Al-Rawas and Steven Michael Easterbrook,,,,47-60,National Aeronautics and Space Administration,The requirements engineering phase of software development projects is characterised by the intensity and importance of communication activities. During this phase. the various stakeholders must be able to communicate their requirements to the analysts. and the analysts need to be able to communicate the specifications they generate back to the stakeholders for validation. This paper describes a field investigation into the problems of communication between disparate communities involved in the requirements specification activities. The results of this study are discussed in terms of their relation to three major communication barriers: 1) ineffectiveness of the current communication channels; 2) restrictions on expressiveness imposed by notations; and 3) social and organisational barriers. The results confirm that organisational and social issues have great influence on the effectiveness of communication. They also show that in general. endusers find the notations used by software practitioners to model their requirements difficult to understand and validate.,True,bD8DWiEAAAAJ:Y0pCki6q_DkC,236,http://www.cs.toronto.edu/~sme/papers/1996/NASA-IVV-96-002.pdf,5388512591388864323,/scholar?cites=5388512591388864323,,,http://www.cs.toronto.edu/~sme/papers/1996/NASA-IVV-96-002.pdf,0,0,0
1276180,Experiences using lightweight formal methods for requirements modeling,1998,Steve Easterbrook and Robyn Lutz and Richard Covington and John Kelly and Yoko Ampo and David Hamilton,24,IEEE Transactions on Software Engineering,1,4-14,IEEE,The paper describes three case studies in the lightweight application of formal methods to requirements modeling for spacecraft fault protection systems. The case studies differ from previously reported applications of formal methods in that formal methods were applied very early in the requirements engineering process to validate the evolving requirements. The results were fed back into the projects to improve the informal specifications. For each case study. we describe what methods were applied. how they were applied. how much effort was involved. and what the findings were. In all three cases. formal methods enhanced the existing verification and validation processes by testing key properties of the evolving requirements and helping to identify weaknesses. We conclude that the benefits gained from early modeling of unstable requirements more than outweigh the effort needed to maintain multiple …,True,bD8DWiEAAAAJ:qjMakFHDy7sC,230,https://ieeexplore.ieee.org/abstract/document/663994/,11991566101110081119,/scholar?cites=11991566101110081119,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.3960&rep=rep1&type=pdf,0,0,0
1276181,Making inconsistency respectable in software development,2001,Bashar Nuseibeh and Steve Easterbrook and Alessandra Russo,58,Journal of systems and software,2,171-180,Elsevier,The development of software systems inevitably involves the detection and handling of inconsistencies. These inconsistencies can arise in system requirements. design specifications and. quite often. in the descriptions that form the final implemented software product. A large proportion of software engineering research has been devoted to consistency maintenance. or geared towards eradicating inconsistencies as soon as they are detected. Software practitioners. on the other hand. live with inconsistency as a matter of course. Depending on the nature of an inconsistency. its causes and its impact. they sometimes choose to tolerate its presence. rather than resolve it immediately. if at all. This paper argues for “making inconsistency respectable” [A phrase first used by D. Gabbay and A. Hunter (in: Proceedings of Fundamentals of Artificial Intelligence Research'91. Springer. Berlin. p. 19; in: Symbolic and …,True,bD8DWiEAAAAJ:W7OEmFMy1HYC,220,https://www.sciencedirect.com/science/article/pii/S016412120100036X,8824470845020155952,/scholar?cites=8824470845020155952,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.3300&rep=rep1&type=pdf,0,0,0
1276182,Research issues in the study of computer supported collaborative writing,1993,Mike Sharples and James S Goodlet and Eevi E Beck and Charles C Wood and Steve M Easterbrook and Lydia Plowman,,,,9-28,Springer. London,In this chapter we set out issues central to the investigation of computer support for collaborative writing. extending previous work to develop cognitive support systems for single writers (Sharples and O’Malley 1988; Sharples et al. 1989). The most successful computer tools to support complex tasks such as writing are those that fit in with the user’s normal patterns of work (Norman 1986). All writers have strategies of working that suit the context of the task and that have been acquired over many years. through apprenticeship and trial and error. It is difficult to uncover and analyse these strategies. and more difficult still to design computer systems that will support them. Our method for single-person writing was to develop a task model that drew on research in the writing process and to extend it through empirical studies of those aspects of writing (for example. the writer’s use of external representations such as …,True,bD8DWiEAAAAJ:maZDTaKrznsC,220,https://link.springer.com/chapter/10.1007/978-1-4471-2007-0_2,5817867047840279569,/scholar?cites=5817867047840279569,,,,0,0,0
1276183,Prioritized Intervention In E-Commerce Applications Using Logical OCL Software Agents (PIE),2020,Gaurav Kant Shikha Singh and Dr. Manuj Darbari,15,Journal of Mechanics of Continua and Mathematical Sciences,6,104-117,Mechanics of Continua and Mathematical Sciences,,True,g-rMC5sAAAAJ:4ZjPyBmb-CUC,0,,,,,,,0,0,0
1276184,An Analysis on OCL/UML Constraints in E-commerce Application,2020,Dr. Manuj Darbari Shikha Singh,121,,,401-413,,,True,g-rMC5sAAAAJ:7DTIKO_nxaIC,0,,,,,,,0,0,0
1276185,Ontological Representation of the UML/OCL Models and Their Verifications,2020,Dr. Manuj Darbari Shikha Singh,13,"International Journal of Future Generation Communication and Networking (IJFGCN),",1,940-951,SERSC,,True,g-rMC5sAAAAJ:4I90hQsHr_gC,0,,,,,,,0,0,0
1276186,Logical Intervention in the Form of Work Breakdown Strategy using Object Constraint Language for e-Commerce Application,2020,Dr. Manuj Darbari Shikha Singh,11,International Journal of Advanced Computer Science and Applications(IJACSA),03,266-271,The Science and Information (SAI) Organization,,True,g-rMC5sAAAAJ:Xs1h1I_UytMC,0,,,,,,,0,0,0
1276187,Impact of Internet of Things on Societal Applications,2019,Shikha Singh Tanya Srivastava,989,,,pp 579-587,,,True,g-rMC5sAAAAJ:NYu48kWxaQAC,0,,,,,,,0,0,0
1276188,Object-Oriented Metrics in Practice - Using Software Metrics to Characterize. Evaluate. and Improve the Design of Object-Oriented Systems,2006,Michele Lanza and Radu Marinescu,,,,,Springer,"Metrics are paramount in every engineering discipline. Software engineering. however. is not considered a classical engineering activity for several reasons. In general. if a software system is seen to deliver the required functionality. only few people if any care about the internals. Moreover. defining. understanding and applying software metrics often looks like an overly complex activity. recommended only to'trained professionals'. Lanza and Marinescu demystify the design metrics used to assess the size. quality and complexity of object-oriented software systems. Based on statistical information from many industrial projects and generally accepted semantics they deduce many single and combined threshold values. They show in detail how to identify collaboration and classification disharmony patterns in code. how to visualize their results using the freely available CodeCrawler visualization tool. and how to devise possible remedies. The combination of theoretically sound results and practically tested procedures and solution paths makes this book an ideal companion for professional software architects. developers and quality engineers. The pattern-oriented description of disharmonies offers easy access to detecting shortcomings and applying solution strategies."" This well-written book is an important piece of work that takes the seemingly forgotten art of object-oriented metrics to the next level in terms of relevance and usefulness."" Richard C. Gronback. Chief Scientist. Borland Software Corporation.",True,hKMBth8AAAAJ:u-x6o8ySG0sC,1221,http://books.google.com/books?hl=en&lr=&id=gdLbgnaMaa0C&oi=fnd&pg=PA1&dq=info:53JH4i8I75AJ:scholar.google.com&ots=s1pUCPKrxN&sig=hIuu4DZVydkc19eUyvUhIO5fIkA,10443575062648287975,/scholar?cites=10443575062648287975,,,,0,0,0
1276189,An Extensive Comparison of Bug Prediction Approaches,2010,Marco D'Ambros and Michele Lanza and Romain Robbes,,,,31-41,IEEE,Reliably predicting software defects is one of software engineering's holy grails. Researchers have devised and implemented a plethora of bug prediction approaches varying in terms of accuracy. complexity and the input data they require. However. the absence of an established benchmark makes it hard. if not impossible. to compare approaches. We present a benchmark for defect prediction. in the form of a publicly available data set consisting of several software systems. and provide an extensive comparison of the explanative and predictive power of well-known bug prediction approaches. together with novel approaches we devised. Based on the results. we discuss the performance and stability of the approaches with respect to our benchmark and deduce a number of insights on bug prediction models.,True,hKMBth8AAAAJ:-f6ydRqryjwC,585,https://ieeexplore.ieee.org/abstract/document/5463279/,5189630131832627593,/scholar?cites=5189630131832627593,,,https://flosshub.org/sites/flosshub.org/files/31dambrosLanzaRobbes31.pdf,0,0,0
1276190,Polymetric Views - A Lightweight Visual Approach to Reverse Engineering,2003,Michele Lanza and Stéphane Ducasse,29,IEEE Transactions on Software Engineering,9,782-795,IEEE,Reverse engineering software systems has become a major concern in software industry because of their sheer size and complexity. This problem needs to be tackled since the systems in question are of considerable worth to their owners and maintainers. In this article. we present the concept of a polymetric view. a lightweight software visualization technique enriched with software metrics information. Polymetric views help to understand the structure and detect problems of a software system in the initial phases of a reverse engineering process. We discuss the benefits and limits of several predefined polymetric views we have implemented in our tool CodeCrawler. Moreover. based on clusters of different polymetric views. we have developed a methodology which supports and guides a software engineer in the first phases of a reverse engineering of a large software system. We have refined this methodology by …,True,hKMBth8AAAAJ:u5HHmVD_uO8C,542,https://ieeexplore.ieee.org/abstract/document/1232284/,11605022175567291953,/scholar?cites=11605022175567291953,,,https://rmod.inria.fr/archives/papers/Lanz03d-TSE-PolymetricViews.pdf,0,0,0
1276191,Evaluating Defect Prediction Approaches: A Benchmark and an Extensive Comparison,2012,Marco D’Ambros and Michele Lanza and Romain Robbes,17,Empirical Software Engineering,4-5,531-577,Springer,Reliably predicting software defects is one of the holy grails of software engineering. Researchers have devised and implemented a plethora of defect/bug prediction approaches varying in terms of accuracy. complexity and the input data they require. However. the absence of an established benchmark makes it hard. if not impossible. to compare approaches. We present a benchmark for defect prediction. in the form of a publicly available dataset consisting of several software systems. and provide an extensive comparison of well-known bug prediction approaches. together with novel approaches we devised. We evaluate the performance of the approaches using different performance indicators: classification of entities as defect-prone or not. ranking of the entities. with and without taking into account the effort to review an entity. We performed three sets of experiments aimed at (1) comparing the …,True,hKMBth8AAAAJ:08ZZubdj9fEC,484,https://link.springer.com/article/10.1007/s10664-011-9173-9,3671701388662869428,/scholar?cites=3671701388662869428,,,https://doc.rero.ch/record/317717/files/10664_2011_Article_9173.pdf,0,0,0
1276192,Visualizing Software Systems as Cities,2007,Richard Wettel and Michele Lanza,,,,92-99,IEEE,This paper presents a 3D visualization approach which gravitates around the city metaphor. i.e.. an object-oriented software system is represented as a city that can be traversed and interacted with: the goal is to give the viewer a sense of locality to ease program comprehension. The key point in conceiving a realistic software city is to map the information about the source code in meaningful ways in order to take the approach beyond beautiful pictures. We investigated several concepts that contribute to the urban feeling. such as appropriate layouts. topology. and facilities to ease navigation and interaction. We experimented our approach on a number of systems. and present our findings.,True,hKMBth8AAAAJ:eQOLeE2rZwMC,302,https://ieeexplore.ieee.org/abstract/document/4290706/,14280799956203569136,/scholar?cites=14280799956203569136,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.142.3858&rep=rep1&type=pdf,0,0,0
1276193,The Evolution Matrix: Recovering Software Evolution using Software Visualization Techniques,2001,Michele Lanza,,,,37-42,ACM,One of the major problems in software evolution is coping with the complexity which stems from the huge amount of data that must be considered. The current approaches to deal with that problem all aim at a reduction of complexity and a filtering of the relevant information. In this paper we propose an approach based on a combination of software visualization and software metrics which we have already successfully applied in the field of software reverse engineering. Using this approach we discuss a simple and effective way to visualize the evolution of software systems which helps to recover the evolution of object oriented software systems.,True,hKMBth8AAAAJ:d1gkVwhDpl0C,290,https://dl.acm.org/doi/abs/10.1145/602461.602467,7612129297134528419,/scholar?cites=7612129297134528419,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.502.7134&rep=rep1&type=pdf,0,0,0
1276194,Software Systems as Cities: A Controlled Experiment,2011,Richard Wettel and Michele Lanza and Romain Robbes,,,,551-560,IEEE,Software visualization is a popular program comprehension technique used in the context of software maintenance. reverse engineering. and software evolution analysis. While there is a broad range of software visualization approaches. only few have been empirically evaluated. This is detrimental to the acceptance of software visualization in both the academic and the industrial world.,True,hKMBth8AAAAJ:lSLTfruPkqcC,271,https://dl.acm.org/doi/abs/10.1145/1985793.1985868,5529217241083962213,/scholar?cites=5529217241083962213,,,https://users.dcc.uchile.cl/~rrobbes/p/ICSE2011-codecity.pdf,0,0,0
1276195,Mining StackOverflow to Turn the IDE into a Self-confident Programming Prompter,2014,Luca Ponzanelli and Gabriele Bavota and Massimiliano Di Penta and Rocco Oliveto and Michele Lanza,,,,102-111,ACM,Developers often require knowledge beyond the one they possess. which often boils down to consulting sources of information like Application Programming Interfaces (API) documentation. forums. Q&A websites. etc. Knowing what to search for and how is non-trivial. and developers spend time and energy to formulate their problems as queries and to peruse and process the results. We propose a novel approach that. given a context in the IDE. automatically retrieves pertinent discussions from Stack Overflow. evaluates their relevance. and. if a given confidence threshold is surpassed. notifies the developer about the available help. We have implemented our approach in Prompter. an Eclipse plug-in. Prompter has been evaluated through two studies. The first was aimed at evaluating the devised ranking model. while the second was conducted to evaluate the usefulness of Prompter.,True,hKMBth8AAAAJ:_axFR9aDTf0C,227,https://dl.acm.org/doi/abs/10.1145/2597073.2597077,6016967981264310966,/scholar?cites=6016967981264310966,,,https://people.lu.usi.ch/bavotg/papers/msr2014_Prompter.pdf,0,0,0
1276196,Visualizing Multiple Evolution Metrics,2005,Martin Pinzger and Harald Gall and Michael Fischer and Michele Lanza,,,,67-75,ACM,Observing the evolution of very large software systems needs the analysis of large complex data models and visualization of condensed views on the system. For visualization software metrics have been used to compute such condensed views. However. current techniques concentrate on visualizing data of one particular release providing only insufficient support for visualizing data of several releases. In this paper we present the RelVis visualization approach that concentrates on providing integrated condensed graphical views on source code and release history data of up to n releases. Measures of metrics of source code entities and relationships are composed in Kiviat diagrams as annual rings. Diagrams highlight the good and bad times of an entity and facilitate the identification of entities and relationships with critical trends. They represent potential refactoring candidates that should be addressed first …,True,hKMBth8AAAAJ:2osOgNQ5qMEC,195,https://dl.acm.org/doi/abs/10.1145/1056018.1056027,6056358905916224863,/scholar?cites=6056358905916224863,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.6330&rep=rep1&type=pdf,0,0,0
1276197,Linking E-Mails and Source Code Artifacts,2010,Alberto Bacchelli and Michele Lanza and Romain Robbes,,,,375-384,ACM,E-mails concerning the development issues of a system constitute an important source of information about high-level design decisions. low-level implementation concerns. and the social structure of developers.,True,hKMBth8AAAAJ:_Qo2XoVZTnwC,188,https://dl.acm.org/doi/abs/10.1145/1806799.1806855,5130492066000626879,/scholar?cites=5130492066000626879,,,https://www.inf.usi.ch/faculty/lanza/Downloads/Bacc2010b.pdf,0,0,0
1276198,Yesterday's Weather: Guiding Early Reverse Engineering Efforts by Summarizing the Evolution of Changes,2004,Tudor Girba and Stéphane Ducasse and Michele Lanza,,,,40-49,IEEE,Knowing where to start reverse engineering a large software system. when no information other than the system's source code itself is available. is a daunting task. Having the history of the code (i.e.. the versions) could be of help if this would not imply analyzing a huge amount of data. We present an approach for identifying candidate classes for reverse engineering and reengineering efforts. Our solution is based on summarizing the changes in the evolution of object-oriented software systems by defining history measurements. Our approach. named Yesterday's Weather. is an analysis based on the retrospective empirical observation that classes which changed the most in the recent past also suffer important changes in the near future. We apply this approach on two case studies and show how we can obtain an overview of the evolution of a system and pinpoint its classes that might change in the next versions.,True,hKMBth8AAAAJ:UeHWp8X0CEIC,181,https://ieeexplore.ieee.org/abstract/document/1357788/,17209129542361155094,/scholar?cites=17209129542361155094,,,https://www.academia.edu/download/30662936/10.1.1.9.6996.pdf,0,0,0
1276199,Software Product Lines,2013,Sven Apel and Don Batory and Christian Kästner and Gunter Saake,,,,3-15,Springer. Berlin. Heidelberg,Software product lines aim at empowering software vendors to tailor software products to the requirements of individual customers. In this sense. software product lines follow a development that emerged in industrial manufacturing over the last 200 years. Starting with handcrafting of individual goods. the advent of mass production scaled the production process to large quantities. but neglected individualism. as all products were the same. With mass customization. individualism got back into the focus of attention. Manufacturers systematically planned and designed product lines to cover a whole spectrum of possible products and variations thereof. serving the individual needs and wishes of many customers. Software product lines take the same line and reconcile mass production and mass customization in software engineering.,True,PR-ZnJUAAAAJ:WA5NYHcadZ8C,854,https://link.springer.com/chapter/10.1007/978-3-642-37521-7_1,11556922539506340605,/scholar?cites=11556922539506340605,,,,0,0,0
1276200,Granularity in software product lines,2008,Christian Kästner and Sven Apel and Martin Kuhlemann,,,,311-320,IEEE,Building software product lines (SPLs) with features is a challenging task. Many SPL implementations support features with coarse granularity - e.g.. the ability to add and wrap entire methods. However. fine-grained extensions. like adding a statement in the middle of a method. either require intricate workarounds or obfuscate the base code with annotations. Though many SPLs can and have been implemented with the coarse granularity of existing approaches. fine-grained extensions are essential when extracting features from legacy applications. Furthermore. also some existing SPLs could benefit from fine-grained extensions to reduce code replication or improve readability. In this paper. we analyze the effects of feature granularity in SPLs and present a tool. called Colored IDE (CIDE). that allows features to implement coarse-grained and fine-grained extensions in a concise way. In two case studies. we show …,True,PR-ZnJUAAAAJ:u5HHmVD_uO8C,603,https://ieeexplore.ieee.org/abstract/document/4814142/,5702325035670758983,/scholar?cites=5702325035670758983,,,https://www.academia.edu/download/33668232/ICSE2008.pdf,0,0,0
1276201,An overview of feature-oriented software development.,2009,Sven Apel and Christian Kästner,8,J. Object Technol.,5,49-84,,Feature-oriented software development (FOSD) is a paradigm for the construction. customization. and synthesis of large-scale software systems. In this survey. we give an overview and a personal perspective on the roots of FOSD. connections to other software development paradigms. and recent developments in this field. Our aim is to point to connections between different lines of research and to identify open issues.,True,PR-ZnJUAAAAJ:u-x6o8ySG0sC,543,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/JOT09_OverviewFOSD.pdf,10388835983436080272,/scholar?cites=10388835983436080272,,,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/JOT09_OverviewFOSD.pdf,0,0,0
1276202,FeatureIDE: An extensible framework for feature-oriented software development,2014,Thomas Thüm and Christian Kästner and Fabian Benduhn and Jens Meinicke and Gunter Saake and Thomas Leich,79,Science of Computer Programming,,70-85,Elsevier,FeatureIDE is an open-source framework for feature-oriented software development (FOSD) based on Eclipse. FOSD is a paradigm for the construction. customization. and synthesis of software systems. Code artifacts are mapped to features. and a customized software system can be generated given a selection of features. The set of software systems that can be generated is called a software product line (SPL). FeatureIDE supports several FOSD implementation techniques such as feature-oriented programming. aspect-oriented programming. delta-oriented programming. and preprocessors. All phases of FOSD are supported in FeatureIDE. namely domain analysis. requirements analysis. domain implementation. and software generation.,True,PR-ZnJUAAAAJ:mvPsJ3kp5DgC,493,https://www.sciencedirect.com/science/article/pii/S0167642312001128,4929993044769814427,/scholar?cites=4929993044769814427,,,https://www.sciencedirect.com/science/article/pii/S0167642312001128/pdf?md5=1246a4221ea11fc8d2290d2855eb6bd4&pid=1-s2.0-S0167642312001128-main.pdf,0,0,0
1276203,Reasoning about edits to feature models,2009,Thomas Thüm and Don Batory and Christian Kästner,,,,254-264,IEEE,Features express the variabilities and commonalities among programs in a software product line (SPL). A feature model defines the valid combinations of features. where each combination corresponds to a program in an SPL. SPLs and their feature models evolve over time. We classify the evolution of a feature model via modifications as refactorings. specializations. generalizations. or arbitrary edits. We present an algorithm to reason about feature model edits to help designers determine how the program membership of an SPL has changed. Our algorithm takes two feature models as input (before and after edit versions). where the set of features in both models are not necessarily the same. and it automatically computes the change classification. Our algorithm is able to give examples of added or deleted products and efficiently classifies edits to even large models that have thousands of features.,True,PR-ZnJUAAAAJ:70eg2SAEIzsC,419,https://ieeexplore.ieee.org/abstract/document/5070526/,6798064718975022067,/scholar?cites=6798064718975022067,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.435.4349&rep=rep1&type=pdf,0,0,0
1276204,A classification and survey of analysis strategies for software product lines,2014,Thomas Thüm and Sven Apel and Christian Kästner and Ina Schaefer and Gunter Saake,47,,1,1-45,ACM,Software-product-line engineering has gained considerable momentum in recent years. both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques. such as type checking. model checking. and theorem proving. in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible. due to the potentially exponential number of valid feature combinations. Recently. researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account. for example. by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse. so it is difficult for researchers and …,True,PR-ZnJUAAAAJ:N5tVd3kTz84C,415,https://dl.acm.org/doi/abs/10.1145/2580950,9534498399631107234,/scholar?cites=9534498399631107234,,,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/CSUR14.pdf,0,0,0
1276205,An analysis of the variability in forty preprocessor-based software product lines,2010,Jörg Liebig and Sven Apel and Christian Lengauer and Christian Kästner and Michael Schulze,,,,105-114,,Over 30 years ago. the preprocessor cpp was developed to extend the programming language C by lightweight metaprogramming capabilities. Despite its error-proneness and low abstraction level. the preprocessor is still widely used in present-day software projects to implement variable software. However. not much is known about how cpp is employed to implement variability. To address this issue. we have analyzed forty open-source software projects written in C. Specifically. we answer the following questions: How does program size influence variability? How complex are extensions made via cpp's variability mechanisms? At which level of granularity are extensions applied? Which types of extension occur? These questions revive earlier discussions on program comprehension and refactoring in the context of the preprocessor. To provide answers. we introduce several metrics measuring the variability …,True,PR-ZnJUAAAAJ:Tyk-4Ss8FVUC,347,https://dl.acm.org/doi/abs/10.1145/1806799.1806819,3589439399277352227,/scholar?cites=3589439399277352227,,,https://www.se.cs.uni-saarland.de/publications/docs/ICSE2010.pdf,0,0,0
1276206,FEATUREHOUSE: Language-independent. automated software composition,2009,Sven Apel and Christian Kästner and Christian Lengauer,,,,221-231,IEEE,Superimposition is a composition technique that has been applied successfully in many areas of software development. Although superimposition is a general-purpose concept. it has been (re)invented and implemented individually for various kinds of software artifacts. We unify languages and tools that rely on superimposition by using the language-independent model of feature structure trees (FSTs). On the basis of the FST model. we propose a general approach to the composition of software artifacts written in different languages. Furthermore. we offer a supporting framework and tool chain. called FEATUREHOUSE. We use attribute grammars to automate the integration of additional languages. in particular. we have integrated Java. C#. C. Haskell. JavaCC. and XML. Several case studies demonstrate the practicality and scalability of our approach and reveal insights into the properties a language must have in …,True,PR-ZnJUAAAAJ:35N4QoGY0k4C,297,https://ieeexplore.ieee.org/abstract/document/5070523/,12512114506268037307,/scholar?cites=12512114506268037307,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.444.9414&rep=rep1&type=pdf,0,0,0
1276207,Variability-aware parsing in the presence of lexical macros and conditional compilation,2011,Christian Kästner and Paolo G Giarrusso and Tillmann Rendel and Sebastian Erdweg and Klaus Ostermann and Thorsten Berger,,,,805-824,,In many projects. lexical preprocessors are used to manage different variants of the project (using conditional compilation) and to define compile-time code transformations (using macros). Unfortunately. while being a simple way to implement variability. conditional compilation and lexical macros hinder automatic analysis. even though such analysis is urgently needed to combat variability-induced complexity. To analyze code with its variability. we need to parse it without preprocessing it. However. current parsing solutions use unsound heuristics. support only a subset of the language. or suffer from exponential explosion. As part of the TypeChef project. we contribute a novel variability-aware parser that can parse almost all unpreprocessed code without heuristics in practicable time. Beyond the obvious task of detecting syntax errors. our parser paves the road for further analysis. such as variability-aware type …,True,PR-ZnJUAAAAJ:hC7cP41nSMkC,279,https://dl.acm.org/doi/abs/10.1145/2048066.2048128,8090108763694885566,/scholar?cites=8090108763694885566,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.232.4186&rep=rep1&type=pdf,0,0,0
1276208,A case study implementing features using AspectJ,2007,Christian Kästner and Sven Apel and Don Batory,,,,223-232,IEEE,Software product lines aim to create highly configurable programs from a set of features. Common belief and recent studies suggest that aspects are well-suited for implementing features. We evaluate the suitability of AspectJ with respect to this task by a case study that refactors the embedded database system Berkeley DB into 38 features. Contrary to our initial expectations. the results were not encouraging. As the number of aspects in a feature grows. there is a noticeable decrease in code readability and maintainability. Most of the unique and powerful features of AspectJ were not needed. We document where AspectJ is unsuitable for implementing features of refactored legacy applications and explain why.,True,PR-ZnJUAAAAJ:lSLTfruPkqcC,277,https://ieeexplore.ieee.org/abstract/document/4339271/,5229620999429606357,/scholar?cites=5229620999429606357,,,http://www.cs.cmu.edu/~ckaestne/pdf/splc07.pdf,0,0,0
1276209,FeatureIDE: A tool framework for feature-oriented software development,2009,Christian Kästner and Thomas Thum and Gunter Saake and Janet Feigenspan and Thomas Leich and Fabian Wielgorz and Sven Apel,,,,611-614,IEEE,Tools support is crucial for the acceptance of a new programming language. However. providing such tool support is a huge investment that can usually not be provided for a research language. With FeatureIDE. we have built an IDE for AHEAD that integrates all phases of feature-oriented software development. To reuse this investment for other tools and languages. we refactored FeatureIDE into an open source framework that encapsulates the common ideas of feature-oriented software development and that can be reused and extended beyond AHEAD. Among others. we implemented extensions for FeatureC++ and FeatureHouse. but in general. FeatureIDE is open for everybody to showcase new research results and make them usable to a wide audience of students. researchers. and practitioners.,True,PR-ZnJUAAAAJ:2P1L_qKh6hAC,264,https://ieeexplore.ieee.org/abstract/document/5070568/,506901375479050691,/scholar?cites=506901375479050691,,,https://www.researchgate.net/profile/Thomas_Thuem/publication/216168407_FeatureIDE_Tool_Framework_for_Feature-Oriented_Software_Development/links/0912f509d05260ab78000000.pdf,0,0,0
1276210,Proof-carrying code,1997,George C Necula,,,,106-119,,This paper describes proof-carrying code (PCC). a mechanism by which a host system can determine with certainty that it is safe to execute a program supplied (possibly in binary form) by an untrusted source. For this to be possible. the untrusted code producer must supply with the code a safety proof that attests to the code's adherence to a previously defined safety policy. The host can then easily and quickly validate the proof without using cryptography and without consulting any external agents. In order to gain preliminary experience with PCC. we have performed several case studies. We show in this paper how proof-carrying code might be used to develop safe assembly-language extensions of ML programs. In the context of this case study. we present and prove the adequacy of concrete representations for the safety policy. the safety proofs. and the proof validation. Finally. we briefly discuss how we use proof …,True,_fiHvDAAAAAJ:JoZmwDi-zQgC,2638,https://dl.acm.org/doi/abs/10.1145/263699.263712,3353077750931142976,/scholar?cites=3353077750931142976,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.977&rep=rep1&type=pdf,0,0,0
1276211,CIL: Intermediate language and tools for analysis and transformation of C programs,2002,George C Necula and Scott McPeak and Shree P Rahul and Westley Weimer,,,,213-228,Springer. Berlin. Heidelberg,This paper describes the C Intermediate Language: a highlevel representation along with a set of tools that permit easy analysis and source-to-source transformation of C programs.Compared to C. CIL has fewer constructs. It breaks down certain complicated constructs of C into simpler ones. and thus it works at a lower level than abstract-syntax trees. But CIL is also more high-level than typical intermediate languages (e.g.. three-address code) designed for compilation. As a result. what we have is a representation that makes it easy to analyze and manipulate C programs. and emit them in a form that resembles the original source. Moreover. it comes with a front-end that translates to CIL not only ANSI C programs but also those using Microsoft C or GNU C extensions.We describe the structure of CIL with a focus on how it disambiguates those features of C that we found to be most confusing …,True,_fiHvDAAAAAJ:u-x6o8ySG0sC,1276,https://link.springer.com/chapter/10.1007/3-540-45937-5_16,2618699998908611709,/scholar?cites=2618699998908611709,,,https://link.springer.com/content/pdf/10.1007/3-540-45937-5_16.pdf,0,0,0
1276212,CCured: Type-safe retrofitting of legacy code,2002,George C Necula and Scott McPeak and Westley Weimer,,,,128-139,,In this paper we propose a scheme that combines type inference and run-time checking to make existing C programs type safe. We describe the CCured type system. which extends that of C by separating pointer types according to their usage. This type system allows both pointers whose usage can be verified statically to be type safe. and pointers whose safety must be checked at run time. We prove a type soundness result and then we present a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs. Our experience with the CCured system shows that the inference is very effective for many C programs. as it is able to infer that most or all of the pointers are statically verifiable to be type safe. The remaining pointers are instrumented with efficient run-time checks to ensure that they are used safely. The resulting performance loss due to run-time checks is 0 …,True,_fiHvDAAAAAJ:9yKSN-GCB0IC,862,https://dl.acm.org/doi/abs/10.1145/503272.503286,10099420917673607401,/scholar?cites=10099420917673607401,,,https://web.eecs.umich.edu/~weimerw/p/p128-necula.pdf,0,0,0
1276213,Safe kernel extensions without run-time checking,1996,George C Necula and Peter Lee,96,OSDI,16,229-243,,This paper describes a mechanism by which an operating system kernel can determine with certainty that it is safe to execute a binary supplied by an untrusted source. The kernel rst de nes a safety policy and makes it public. Then. using this policy. an application can provide binaries in a special form called proof-carrying code. or simply PCC. Each PCC binary contains. in addition to the native code. a formal proof that the code obeys the safety policy. The kernel can easily validate the proof without using cryptography and without consulting any external trusted entities. If the validation succeeds. the code is guaranteed to respect the safety policy without relying on run-time checks. The main practical di culty of PCC is in generating the safety proofs. In order to gain some preliminary experience with this. we have written several network packet lters in hand-tuned DEC Alpha assembly language. and then generated PCC binaries for them using a special prototype assembler. The PCC binaries can be executed with no run-time overhead. beyond a one-time cost of 1 to 3 milliseconds for validating the enclosed proofs. The net result is that our packet lters are formally guaranteed to be safe and are faster than packet lters created using Berkeley Packet Filters. Software Fault Isolation. or safe languages such as Modula-3.,True,_fiHvDAAAAAJ:d1gkVwhDpl0C,778,https://www.usenix.org/publications/library/proceedings/osdi96/full_papers/necula/necula.ps,1459124347061483749,/scholar?cites=1459124347061483749,,,https://www.usenix.org/publications/library/proceedings/osdi96/full_papers/necula/necula.ps,0,0,0
1276214,Translation validation for an optimizing compiler,2000,George C Necula,,,,83-94,,We describe a translation validation infrastructure for the GNU C compiler. During the compilation the infrastructure compares the intermediate form of the program before and after each compiler pass and verifies the preservation of semantics. We discuss a general framework that the optimizer can use to communicate to the validator what transformations were performed. Our implementation however does not rely on help from the optimizer and it is quite successful by using instead a few heuristics to detect the transformations that take place.,True,_fiHvDAAAAAJ:qjMakFHDy7sC,567,https://dl.acm.org/doi/abs/10.1145/349299.349314,4805962795133105699,/scholar?cites=4805962795133105699,,,http://www.cs.tufts.edu/~nr/cs257/archive/george-necula/tv_pldi00.pdf,0,0,0
1276215,XFI: Software guards for system address spaces,2006,Ulfar Erlingsson and Martín Abadi and Michael Vrable and Mihai Budiu and George C Necula,,,,75-88,,XFI is a comprehensive protection system that offers both flexible access control and fundamental integrity guarantees. at any privilege level and even for legacy code in commodity systems. For this purpose. XFI combines static analysis with inline software guards and a two-stack execution model. We have implemented XFI for Windows on the x86 architecture using binary rewriting and a simple. stand-alone verifier; the implementation’s correctness depends on the verifier. but not on the rewriter. We have applied XFI to software such as device drivers and multimedia codecs. The resulting modules function safely within both kernel and user-mode address spaces. with only modest enforcement overheads.,True,_fiHvDAAAAAJ:W7OEmFMy1HYC,495,https://www.usenix.org/legacy/event/osdi06/tech/full_papers/erlingsson/erlingsson.pdf,1669141386692678377,/scholar?cites=1669141386692678377,,,https://www.usenix.org/legacy/event/osdi06/tech/full_papers/erlingsson/erlingsson.pdf,0,0,0
1276216,The design and implementation of a certifying compiler,1998,George C Necula and Peter Lee,33,ACM SIGPLAN Notices,5,333-344,ACM,This paper presents the design and implementation of a compiler that translates programs written in a type-safe subset of the C programming language into highly optimized DEC Alpha assembly language programs. and a certifier that automatically checks the type safety and memory safety of any assembly language program produced by the compiler. The result of the certifier is either a formal proof of type safety or a counterexample pointing to a potential violation of the type system by the target program. The ensemble of the compiler and the certifier is called a certifying compiler.Several advantages of certifying compilation over previous approaches can be claimed. The notion of a certifying compiler is significantly easier to employ than a formal compiler verification. in part because it is generally easier to verify the correctness of the result of a computation than to prove the correctness of the computation itself …,True,_fiHvDAAAAAJ:2osOgNQ5qMEC,458,https://dl.acm.org/doi/abs/10.1145/277652.277752,17045742566941622911,/scholar?cites=17045742566941622911,,,http://vglab.cse.iitd.ac.in/~sbansal/csl862-soft/readings/necula_certifying_compiler_full.pdf,0,0,0
1276217,CCured: Type-safe retrofitting of legacy software,2005,George C Necula and Jeremy Condit and Matthew Harren and Scott McPeak and Westley Weimer,27,ACM Transactions on Programming Languages and Systems (TOPLAS),3,477-526,ACM,This article describes CCured. a program transformation system that adds type safety guarantees to existing C programs. CCured attempts to verify statically that memory errors cannot occur. and it inserts run-time checks where static verification is insufficient.CCured extends C's type system by separating pointer types according to their usage. and it uses a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs. CCured uses physical subtyping to recognize and verify a large number of type casts at compile time. Additional type casts are verified using run-time type information. CCured uses two instrumentation schemes. one that is optimized for performance and one in which metadata is stored in a separate data structure whose shape mirrors that of the original user data. This latter scheme allows instrumented programs to invoke external functions …,True,_fiHvDAAAAAJ:Y0pCki6q_DkC,423,https://dl.acm.org/doi/abs/10.1145/1065887.1065892,17931437880584031120,/scholar?cites=17931437880584031120,,,https://people.eecs.berkeley.edu/~necula/Papers/ccured_toplas.pdf,0,0,0
1276218,Guided gui testing of android apps with minimal restart and approximate learning,2013,Wontae Choi and George Necula and Koushik Sen,48,Acm Sigplan Notices,10,623-640,ACM,Smartphones and tablets with rich graphical user interfaces (GUI) are becoming increasingly popular. Hundreds of thousands of specialized applications. called apps. are available for such mobile platforms. Manual testing is the most popular technique for testing graphical user interfaces of such apps. Manual testing is often tedious and error-prone. In this paper. we propose an automated technique. called Swift-Hand. for generating sequences of test inputs for Android apps. The technique uses machine learning to learn a model of the app during testing. uses the learned model to generate user inputs that visit unexplored states of the app. and uses the execution of the app on the generated inputs to refine the model. A key feature of the testing algorithm is that it avoids restarting the app. which is a significantly more expensive operation than executing the app on a sequence of inputs. An important insight behind …,True,_fiHvDAAAAAJ:NhqRSupF_l8C,394,https://dl.acm.org/doi/abs/10.1145/2544173.2509552,3359478678921689786,/scholar?cites=3359478678921689786,,,https://digitalassets.lib.berkeley.edu/etd/ucb/text/Choi_berkeley_0028E_17447.pdf,0,0,0
1276219,Capriccio: scalable threads for internet services,2003,Rob Von Behren and Jeremy Condit and Feng Zhou and George C Necula and Eric Brewer,37,ACM SIGOPS Operating Systems Review,5,268-281,ACM,This paper presents Capriccio. a scalable thread package for use with high-concurrency servers. While recent work has advocated event-based systems. we believe that thread-based systems can provide a simpler programming model that achieves equivalent or superior performance.By implementing Capriccio as a user-level thread package. we have decoupled the thread package implementation from the underlying operating system. As a result. we can take advantage of cooperative threading. new asynchronous I/O mechanisms. and compiler support. Using this approach. we are able to provide three key features: (1) scalability to 100.000 threads. (2) efficient stack management. and (3) resource-aware scheduling.We introduce linked stack management. which minimizes the amount of wasted stack space by providing safe. small. and non-contiguous stacks that can grow or shrink at run time. A compiler …,True,_fiHvDAAAAAJ:zYLM7Y9cAGgC,388,https://dl.acm.org/doi/abs/10.1145/1165389.945471,9189169158557819622,/scholar?cites=9189169158557819622,,,http://pages.cs.wisc.edu/~remzi/Classes/739/Fall2018/Papers/capriccio-sosp-2003.pdf,0,0,0
1276220,Safe. untrusted agents using proof-carrying code,1998,George C Necula and Peter Lee,,,,61-91,Springer. Berlin. Heidelberg,Proof-Carrying Code (PCC) enables a computer system to determine. automatically and with certainty. that program code provided by another system is safe to install and execute without requiring interpretation or run-time checking. PCC has applications in any computing system in which the safe. efficient. and dynamic installation of code is needed. The key idea is to attach to the code an easily-checkable proof that its execution does not violate the safety policy of the receiving system. This paper describes the design and a typical implementation of Proof-Carrying Code. where the language used for specifying the safety properties is first-order predicate logic. Examples of safety properties described in this paper are memory safety and compliance with data access policies. resource usage bounds. and data abstraction boundaries.,True,_fiHvDAAAAAJ:UeHWp8X0CEIC,340,https://link.springer.com/chapter/10.1007/3-540-68671-1_5,14710524678556577767,/scholar?cites=14710524678556577767,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/Mobile%20Agents%20and%20Security(LNCS1419,%20Springer,%201998)(ISBN%203540647929)(268s).pdf#page=72",0,0,0
1276221,Software metrics: a rigorous and practical approach,2014,Norman Fenton and James Bieman,,,,,CRC press,A Framework for Managing. Measuring. and Predicting Attributes of Software Development Products and ProcessesReflecting the immense progress in the development and use of software metrics in the past decades. Software Metrics: A Rigorous and Practical Approach. Third Edition provides an up-to-date. accessible. and comprehensive introduction to soft,True,PbQ8dzsAAAAJ:xtoqd-5pKcoC,6530,http://books.google.com/books?hl=en&lr=&id=lx_OBQAAQBAJ&oi=fnd&pg=PP1&dq=info:AJiZdPCO3q4J:scholar.google.com&ots=_Vh_VmVS-y&sig=pgLXb4NzCSOajjbYBbVufyNIWbU,12600665970828744704,/scholar?cites=12600665970828744704,,,,0,0,0
1276222,Cohesion and reuse in an object-oriented system,1995,James M Bieman and Byung-Kyoo Kang,20,,SI,259-262,ACM,We define and apply two new measures of object-oriented class cohesion to a reasonably large C++ system. We find that most of the classes are quite cohesive. but that the classes that are reused more frequently via inheritance exhibit clearly lower cohesion.,True,PbQ8dzsAAAAJ:u5HHmVD_uO8C,655,https://dl.acm.org/doi/abs/10.1145/223427.211856,3022493825891608857,/scholar?cites=3022493825891608857,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.2683&rep=rep1&type=pdf,0,0,0
1276223,Measuring functional cohesion,1994,James M Bieman and Linda M Ott,20,IEEE transactions on Software Engineering,8,644-657,IEEE,"We examine the functional cohesion of procedures using a data slice abstraction. Our analysis identifies the data tokens that lie on more than one slice as the ""glue"" that binds separate components together. Cohesion is measured in terms of the relative number of glue tokens. tokens that lie on more than one data slice. and super-glue tokens. tokens that lie on all data slices in a procedure. and the adhesiveness of the tokens. The intuition and measurement scale factors are demonstrated through a set of abstract transformations.< >",True,PbQ8dzsAAAAJ:u-x6o8ySG0sC,379,https://ieeexplore.ieee.org/abstract/document/310673/,2142657067842341761,/scholar?cites=2142657067842341761,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.4338&rep=rep1&type=pdf,0,0,0
1276224,Software reliability growth with test coverage,2002,Yashwant K Malaiya and Michael Naixin Li and James M Bieman and Rick Karcich,51,IEEE Transactions on Reliability,4,420-426,IEEE,"""Software test-coverage measures"" quantify the degree of thoroughness of testing. Tools are now available that measure test-coverage in terms of blocks. branches. computation-uses. predicate-uses. etc. that are covered. This paper models the relations among testing time. coverage. and reliability. An LE (logarithmic-exponential) model is presented that relates testing effort to test coverage (block. branch. computation-use. or predicate-use). The model is based on the hypothesis that the enumerable elements (like branches or blocks) for any coverage measure have various probabilities of being exercised; just like defects have various probabilities of being encountered. This model allows relating a test-coverage measure directly with defect-coverage. The model is fitted to 4 data-sets for programs with real defects. In the model. defect coverage can predict the time to next failure. The LE model can eliminate …",True,PbQ8dzsAAAAJ:UeHWp8X0CEIC,253,https://ieeexplore.ieee.org/abstract/document/1044339/,17998046731000821458,/scholar?cites=17998046731000821458,,,ftp://mail.im.tku.edu.tw/Prof_Shyur/Software%20Reliability/%B4%C1%A5%BD%B3%F8%A7i/P10.pdf,0,0,0
1276225,Rapid prototyping: lessons learned,1995,V Scott Gordon and James M.  Bieman,12,IEEE software,1,85-95,IEEE,Opinions on rapid prototyping as a practical development tool vary widely. with conventional wisdom seeing it more as a research topic than a workable method. The authors counter this notion with results from 39 case studies. most of which have used this approach successfully.< >,True,PbQ8dzsAAAAJ:9yKSN-GCB0IC,229,https://ieeexplore.ieee.org/abstract/document/363162/,13704313315955959402,/scholar?cites=13704313315955959402,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.6796&rep=rep1&type=pdf,0,0,0
1276226,Towards the systematic testing of aspect-oriented programs,2004,Roger T Alexander and James M Bieman and Anneliese A Andrews,,,,,Technical Report CS-4-105. Department of Computer Science. Colorado State University. Fort Collins. Colorado,The code that provides solutions to key software requirements. such as security and fault-tolerance. tends to be spread throughout (or cross-cut) the program modules that implement the “primary functionality” of a software system. Aspect-oriented programming is an emerging programming paradigm that supports implementing such cross-cutting requirements into named program units called “aspects”. To construct a system as an aspect-oriented program (AOP). one develops code for primary functionality in traditional modules and code for cross-cutting functionality in aspect modules. Compiling and running an AOP requires that the aspect code be “woven” into the code. Although aspect-oriented programming supports the separation of concerns into named program units. explicit and implicit dependencies of both aspects and traditional modules will result in systems with new testing challenges. which include new sources for program faults. This paper introduces a candidate fault model. along with associated testing criteria. for AOPs based on interactions that are unique to AOPs. The paper also identifies key issues relevant to the systematic testing of AOPs.,True,PbQ8dzsAAAAJ:2osOgNQ5qMEC,214,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.2547&rep=rep1&type=pdf,11936661826106708271,/scholar?cites=11936661826106708271,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.2547&rep=rep1&type=pdf,0,0,0
1276227,Directives for composing aspect-oriented design class models,2006,Y Raghu Reddy and Sudipto Ghosh and Robert B France and Greg Straw and James M Bieman and Nathan McEachen and Eunjee Song and Geri Georg,,,,75-105,Springer. Berlin. Heidelberg,An aspect-oriented design model consists of a set of aspect models and a primary model. Each aspect model describes a feature that crosscuts elements in the primary model. Aspect and primary models are composed to obtain an integrated design view. In this paper we describe a composition approach that utilizes a merging algorithm and composition directives. Composition directives are used when the default merging algorithm is known or expected to yield incorrect models. Our prototype tool supports default class diagram composition.,True,PbQ8dzsAAAAJ:qjMakFHDy7sC,195,https://link.springer.com/chapter/10.1007/11687061_3,17658035968089129247,/scholar?cites=17658035968089129247,,,http://www.cs.colostate.edu/~france/publications/TAOSD05-draft.pdf,0,0,0
1276228,The FreeBSD project: a replication case study of open source development,2005,Trung T Ding-Trong and James M. Bieman,31,IEEE Transactions on Software Engineering,6,481-494,,Case studies can help to validate claims that open source software development produces higher quality software at lower cost than traditional commercial development. One problem inherent in case studies are external validity - we do not know whether or not results from one case study apply to another development project. We gain or lose confidence in case study results when similar case studies are conducted on other projects. This case study of the FreeBSD project. a long-lived open source project. provides further understanding of open source development. The paper details a method for mining repositories and querying project participants to retrieve key process information. The FreeBSD development process is fairly well-defined with proscribed methods for determining developer responsibilities. dealing with enhancements and defects. and managing releases. Compared to the Apache project …,True,PbQ8dzsAAAAJ:LjlpjdlvIbIC,192,https://ieeexplore.ieee.org/abstract/document/1463231/,1233812399793273056,/scholar?cites=1233812399793273056,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.94.5926&rep=rep1&type=pdf,0,0,0
1276229,Measuring Design–level Cohesion,1998,JM Bieman and BK Kang,20,IEEE Transactions on Software Engineering,2,111-124,,Cohesion was first introduced as a software attribute that. when measured. could be used to predict properties of implementations that would be created from a given design. Unfortunately. cohesion. as originally defined. could not be objectively assessed. while more recently developed objective cohesion measures depend on code-level information. We show that association-based and slice-based approaches can be used to measure cohesion using only design-level information. An analytical and empirical analysis shows that the design-level measures correspond closely with code-level cohesion measures. They can be used as predictors of or surrogates for the code-level measures. The design-level cohesion measures are formally defined. have been implemented. and can support software design. maintenance and restructuring.,True,PbQ8dzsAAAAJ:SdhP9T11ey4C,176,https://ieeexplore.ieee.org/abstract/document/666825/,15423374075952429018,/scholar?cites=15423374075952429018,,,,0,0,0
1276230,Design patterns and change proneness: An examination of five evolving systems,2004,James M Bieman and Greg Straw and Huxia Wang and P Willard Munger and Roger T Alexander,,,,40-49,IEEE,Design patterns are recognized. named solutions to common design problems. The use of the most commonly referenced design patterns should promote adaptable and reusable program code. When a system evolves. changes to code involving a design pattern should. in theory. consist of creating new concrete classes that are extensions or subclasses of previously existing classes. Changes should not. in theory. involve direct modifications to the classes in prior versions that play roles in a design patterns. We studied five systems. three proprietary systems and two open source systems. to identify the observable effects of the use of design patterns in early versions on changes that occur as the systems evolve. In four of the five systems. pattern classes are more rather than less change prone. Pattern classes in one of the systems were less change prone. These results held up after normalizing for the effect of …,True,PbQ8dzsAAAAJ:W7OEmFMy1HYC,168,https://ieeexplore.ieee.org/abstract/document/1232454/,7830131904103863859,/scholar?cites=7830131904103863859,,,http://www.ptidej.net/teaching/ift6251/fall06/presentations/060927/01232454.pdf,0,0,0
1276231,Competencies of exceptional and nonexceptional software engineers,1995,Richard T Turley and James M Bieman,28,Journal of Systems and Software,1,19-38,Elsevier,The attributes of individual software engineers are perhaps the most important factors determining the success of software development. Our goal is to identify the professional competencies that are most essential. In particular. we seek to identify the attributes that differentiate exceptional and nonexceptional software engineers. Phase 1 of our research is a qualitative study designed to identify competencies to be used in the quantitative analysis performed in phase 2. In phase 1. we conduct an in-depth review of 10 exceptional and 10 nonexceptional software engineers working for a major computing firm. We use biographical data and Myers-Briggs Type Indicator test results to characterize our sample. We conduct Critical Incident Interviews focusing on the subjects' experience in software and identify 38 essential competencies of software engineers. Phase 2 of this study is a survey of 129 software engineers …,True,PbQ8dzsAAAAJ:YsMSGLbcyi4C,166,https://www.sciencedirect.com/science/article/pii/0164121294000782,13652289482393691999,/scholar?cites=13652289482393691999,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.8463&rep=rep1&type=pdf,0,0,0
1276232,Feature-Oriented Software Product Lines: Concepts and Implementation,2013,Sven Apel and Don Batory and Christian Kästner and Gunter Saake,,,,,Springer Publishing Company. Incorporated,,True,Tggnh5oAAAAJ:ymY9cBF3mdcC,852,,11556922539506340605,/scholar?cites=11556922539506340605,,,,0,0,0
1276233,FeatureIDE: An extensible framework for feature-oriented software development,2014,Thomas Thüm and Christian Kästner and Fabian Benduhn and Jens Meinicke and Gunter Saake and Thomas Leich,,Science of Computer Programming,,,Elsevier,FeatureIDE is an open-source framework for feature-oriented software development (FOSD) based on Eclipse. FOSD is a paradigm for the construction. customization. and synthesis of software systems. Code artifacts are mapped to features. and a customized software system can be generated given a selection of features. The set of software systems that can be generated is called a software product line (SPL). FeatureIDE supports several FOSD implementation techniques such as feature-oriented programming. aspect-oriented programming. delta-oriented programming. and preprocessors. All phases of FOSD are supported in FeatureIDE. namely domain analysis. requirements analysis. domain implementation. and software generation.,True,Tggnh5oAAAAJ:LPtt_HFRSbwC,493,https://www.sciencedirect.com/science/article/pii/S0167642312001128,4929993044769814427,/scholar?cites=4929993044769814427,,,https://www.sciencedirect.com/science/article/pii/S0167642312001128/pdf?md5=1246a4221ea11fc8d2290d2855eb6bd4&pid=1-s2.0-S0167642312001128-main.pdf,0,0,0
1276234,A classification and survey of analysis strategies for software product lines,2014,Thomas Thüm and Sven Apel and Christian Kästner and Ina Schaefer and Gunter Saake,,ACM Computing Surveys,,,,Software-product-line engineering has gained considerable momentum in recent years. both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques. such as type checking. model checking. and theorem proving. in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible. due to the potentially exponential number of valid feature combinations. Recently. researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account. for example. by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse. so it is difficult for researchers and …,True,Tggnh5oAAAAJ:X4-KO54GjGYC,415,https://dl.acm.org/doi/abs/10.1145/2580950,9534498399631107234,/scholar?cites=9534498399631107234,,,https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ckaestne/pdf/CSUR14.pdf,0,0,0
1276235,Datenbanken. Konzepte und Sprachen,1995,Andreas Heuer and Gunter Saake,,,,,,Das Gebiet der Datenbanksysteme gehört zu den klassischen Ausbildungsgebieten der Informatikstudiengänge. Datenbanksysteme kommen immer dann zum Einsatz. wenn an die Datenhaltung besondere Anforderungen hinsichtlich der Zuverlässigkeit. des zu speichernden Volumens. der Ausfallsicherheit. des Mehrbenutzerzugriffs. der Komplexität der Datenbeschreibung oder der Datenqualität gestellt werden. Zu Beginn des Informationszeitalters ist es daher nicht verwunderlich. dass der Umgang mit Datenbanksystemen für viele Absolventinnen und Absolventen der Informatikstudiengänge zum Berufsalltag gehört.,True,Tggnh5oAAAAJ:t-hv7AR41mYC,307,https://www.mitp.de/out/media/9783958457799_Leseprobe.pdf,11117246799826975407,/scholar?cites=11117246799826975407,,,https://www.mitp.de/out/media/9783958457799_Leseprobe.pdf,0,0,0
1276236,FeatureIDE: A tool framework for feature-oriented software development,2009,Christian Kästner and Thomas Thüm and Gunter Saake and Janet Feigenspan and Thomas Leich and Fabian Wielgorz and Sven Apel,,,,611-614,IEEE,Tools support is crucial for the acceptance of a new programming language. However. providing such tool support is a huge investment that can usually not be provided for a research language. With FeatureIDE. we have built an IDE for AHEAD that integrates all phases of feature-oriented software development. To reuse this investment for other tools and languages. we refactored FeatureIDE into an open source framework that encapsulates the common ideas of feature-oriented software development and that can be reused and extended beyond AHEAD. Among others. we implemented extensions for FeatureC++ and FeatureHouse. but in general. FeatureIDE is open for everybody to showcase new research results and make them usable to a wide audience of students. researchers. and practitioners.,True,Tggnh5oAAAAJ:MXK_kJrjxJIC,264,https://ieeexplore.ieee.org/abstract/document/5070568/,506901375479050691,/scholar?cites=506901375479050691,,,https://www.researchgate.net/profile/Thomas_Thuem/publication/216168407_FeatureIDE_Tool_Framework_for_Feature-Oriented_Software_Development/links/0912f509d05260ab78000000.pdf,0,0,0
1276237,FeatureC++: On the symbiosis of feature-oriented and aspect-oriented programming,2005,Sven Apel and Thomas Leich and Marko Rosenmüller and Gunter Saake,,,,125-140,Springer. Berlin. Heidelberg,This paper presents FeatureC++. a novel language extension to C++ that supports Feature-Oriented Programming (FOP) and Aspect-Oriented Programming (AOP). Besides well-known concepts of FOP languages. FeatureC++ contributes several novel FOP language features. in particular multiple inheritance and templates for generic programming. Furthermore. FeatureC++ solves several problems regarding incremental software development by adopting AOP concepts. Starting our considerations on solving these problems. we give a summary of drawbacks and weaknesses of current FOP languages in expressing incremental refinements. Specifically. we outline five key problems and present three approaches to solve them: Multi Mixins. Aspectual Mixin Layers. and Aspectual Mixins that adopt AOP concepts in different ways. We use FeatureC++ as a representative FOP language to explain these three …,True,Tggnh5oAAAAJ:UeHWp8X0CEIC,259,https://link.springer.com/chapter/10.1007/11561347_10,8841629278688244813,/scholar?cites=8841629278688244813,,,https://www.infosun.fim.uni-passau.de/publications/docs/GPCE2005.pdf,0,0,0
1276238,Predicting Performance via Automated Feature-Interaction Detection,2012,Norbert Siegmund and Sergiy S Kolesnikov and Christian Kästner and Sven Apel and Don Batory and Marko Rosenmüller and Gunter Saake,,,,,,Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However. when features interact. accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end. we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g.. databases. encoding libraries. and web servers …,True,Tggnh5oAAAAJ:MpfHP-DdYjUC,233,https://ieeexplore.ieee.org/abstract/document/6227196/,6583761672055665857,/scholar?cites=6583761672055665857,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1071.6705&rep=rep1&type=pdf,0,0,0
1276239,Aspectual feature modules,2008,Sven Apel and Thomas Leich and Gunter Saake,34,,2,162-180,IEEE,Two programming paradigms are gaining attention in the overlapping fields of software product lines (SPLs) and incremental software development (ISD). Feature-oriented programming (FOP) aims at large-scale compositional programming and feature modularity in SPLs using ISD. Aspect-oriented programming (AOP) focuses on the modularization of crosscutting concerns in complex software. Although feature modules. the main abstraction mechanisms of FOP. perform well in implementing large-scale software building blocks. they are incapable of modularizing certain kinds of crosscutting concerns. This weakness is exactly the strength of aspects. the main abstraction mechanisms of AOP. We contribute a systematic evaluation and comparison of FOP and AOP. It reveals that aspects and feature modules are complementary techniques. Consequently. we propose the symbiosis of FOP and AOP and aspectual …,True,Tggnh5oAAAAJ:IjCSPb-OGe4C,209,https://ieeexplore.ieee.org/abstract/document/4407729/,2073638256591570496,/scholar?cites=2073638256591570496,,,https://drive.google.com/file/d/1rC2tN3lbREkqFgkCPPIcBiNulFZ3-cqu/view,0,0,0
1276240,Conceptual modelling of database applications using an extended ER model,1992,Gregor Engels and Martin Gogolla and Uwe Hohenstein and Klaus Hülsmann and Perdita Löhr-Richter and Gunter Saake and Hans-Dieter Ehrich,9,Data & Knowledge Engineering,2,157-204,North-Holland,In this paper. we motivate and present a data model for conceptual design of structural and behavioural aspects of databases. We follow an object centered design paradigm in the spirit of semantic data models. The specification of structural aspects is divided into modelling of object structures and modelling of data types used for describing object properties. The specification of object structures is based on an E xtended E ntity-R elationship (EER) model. The specification of behavioural aspects is divided into the modelling of admissible database state evolutions by means of temporal integrity constraints and the formulation of database (trans) actions. The central link for integrating these design components is a descriptive logic-based query language for the EER model. The logic part of this language is the basis for static constraints and descriptive action specifications by means of pre-and postconditions. A …,True,Tggnh5oAAAAJ:u-x6o8ySG0sC,195,https://www.sciencedirect.com/science/article/pii/0169023X9290008Y,10773788605355144926,/scholar?cites=10773788605355144926,,,,0,0,0
1276241,Understanding Understanding Source Code with Functional Magnetic Resonance Imaging,2014,Janet Siegmund and Christian Kästner and Sven Apel and Chris Parnin and Anja Bethmann and Thomas Leich and Gunter Saake and André Brechmann,,,,,,Program comprehension is an important cognitive process that inherently eludes direct measurement. Thus. researchers are struggling with providing suitable programming languages. tools. or coding conventions to support developers in their everyday work. In this paper. we explore whether functional magnetic resonance imaging (fMRI). which is well established in cognitive neuroscience. is feasible to soundly measure program comprehension. In a controlled experiment. we observed 17 participants inside an fMRI scanner while they were comprehending short source-code snippets. which we contrasted with locating syntax errors. We found a clear. distinct activation pattern of five brain regions. which are related to working memory. attention. and language processing---all processes that fit well to our understanding of program comprehension. Our results encourage us and. hopefully. other researchers to use …,True,Tggnh5oAAAAJ:EBV337fEn3EC,188,https://dl.acm.org/doi/abs/10.1145/2568225.2568252,10881870177978183236,/scholar?cites=10881870177978183236,,,https://kilthub.cmu.edu/articles/Understanding_Understanding_Source_Code_with_Functional_Magnetic_Resonance_Imaging/6626357/files/12123905.pdf,0,0,0
1276242,Troll: A language for object-oriented specification of information systems,1996,Ralf Jungclaus and Gunter Saake and Thorsten Hartmann and Cristina Sernadas,14,ACM Transactions on Information Systems (TOIS),2,175-211,ACM,TROLL is a language particularly suited for the early stages of information system development. when the universe of discourse must be described. In TROLL the descriptions of the static and dynamic aspects of entities are integrated into object descriptions. Sublanguages for data terms. for first-order and temporal assertions. and for processes. are used to describe respectively the static properties. the behavior. and the evolution over time of objects. TROLL organizes system design through object-orientation and the support of abstractions such as classification. specialization. roles. and aggregation. Language features for state interactions and dependencies among components support the composition of the system from smaller modules. as does the facility of defining interfaces on top of object descriptions.,True,Tggnh5oAAAAJ:d1gkVwhDpl0C,182,https://dl.acm.org/doi/abs/10.1145/226163.226166,7481778018242160895,/scholar?cites=7481778018242160895,,,https://www.researchgate.net/profile/Gunter_Saake/publication/2518875_Object-Oriented_Specification_of_Information_Systems_The_TROLL_Language/links/02bfe50ca4c20bfb7d000000.pdf,0,0,0
1276243,Mop: an efficient and generic runtime verification framework,2007,Feng Chen and Grigore Roşu,,,,569-588,,Monitoring-Oriented Programming (MOP1)[21. 18. 22. 19] is a formal framework for software development and analysis. in which the developer specifies desired properties using definable specification formalisms. along with code to execute when properties are violated or validated. The MOP framework automatically generates monitors from the specified properties and then integrates them together with the user-defined code into the original system.,True,yxpqbdQAAAAJ:4fGpz3EwCPoC,475,https://dl.acm.org/doi/abs/10.1145/1297027.1297069,6690799026034586185,/scholar?cites=6690799026034586185,,,https://www.ideals.illinois.edu/bitstream/handle/2142/11306/MOP%20An%20Efficient%20and%20Generic%20Runtime%20Verification%20Framework.pdf?sequence=2&isAllowed=y,0,0,0
1276244,An overview of the K semantic framework,2010,Grigore Roșu and Traian Florin Șerbănută,79,,6,397-434,North-Holland,K is an executable semantic framework in which programming languages. calculi. as well as type systems or formal analysis tools can be defined. making use of configurations. computations and rules. Configurations organize the system/program state in units called cells. which are labeled and can be nested. Computations carry “computational meaning” as special nested list structures sequentializing computational tasks. such as fragments of program; in particular. computations extend the original language or calculus syntax. K (rewrite) rules generalize conventional rewrite rules by making explicit which parts of the term they read. write. or do not care about. This distinction makes K a suitable framework for defining truly concurrent languages or calculi. even in the presence of sharing. Since computations can be handled like any other terms in a rewriting environment. that is. they can be matched. moved from one …,True,yxpqbdQAAAAJ:kVjdVfd2voEC,421,https://www.sciencedirect.com/science/article/pii/S1567832610000160,17103805417234224914,/scholar?cites=17103805417234224914,,,https://www.sciencedirect.com/science/article/pii/S1567832610000160/pdf?md5=691f3bec3256f182f2d9a3de4f99f067&pid=1-s2.0-S1567832610000160-main.pdf&_valck=1,0,0,0
1276245,Synthesizing monitors for safety properties,2002,Klaus Havelund and Grigore Roşu,,,,342-356,Springer. Berlin. Heidelberg,The problem of testing a linear temporal logic (LTL) formula on a finite execution trace of events. generated by an executing program. occurs naturally in runtime analysis of software. An algorithm which takes a past time LTL formula and generates an efficient dynamic programming algorithm is presented. The generated algorithm tests whether the formula is satisfied by a finite trace of events given as input and runs in linear time. its constant depending on the size of the LTL formula. The memory needed is constant. also depending on the size of the formula. Further optimizations of the algorithm are suggested. Past time operators suitable for writing succinct specifications are introduced and shown definitionally equivalent to the standard operators. This work is part of the PathExplorer project. the objective of which it is to construct a flexible framework for monitoring and analyzing program executions.,True,yxpqbdQAAAAJ:9pM33mqn1YgC,415,https://link.springer.com/chapter/10.1007/3-540-46002-0_24,15795214406081288086,/scholar?cites=15795214406081288086,,,https://link.springer.com/content/pdf/10.1007/3-540-46002-0_24.pdf,0,0,0
1276246,Monitoring java programs with java pathexplorer,2001,Klaus Havelund and Grigore Roşu,55,Electronic Notes in Theoretical Computer Science,2,200-217,Elsevier,We present recent work on the development of Java PathExplorer (JPaX). a tool for monitoring the execution of Java programs. JPaX can be used during program testing to gain increased information about program executions. and can potentially furthermore be applied during operation to survey safety critical systems. The tool facilitates automated instrumentation of a program's byte code. which will then emit events to an observer during its execution. The observer checks the events against user provided high level requirement specifications. for example temporal logic formulae. and against lower level error detection procedures. usually concurrency related such as deadlock and data race algorithms. High level requirement specifications together with their underlying logics are defined in rewriting logic using Maude. and then can either be directly checked using Maude rewriting engine. or be first translated to …,True,yxpqbdQAAAAJ:bz8QjSJIRt4C,376,https://www.sciencedirect.com/science/article/pii/S1571066104002531,5504294604504136463,/scholar?cites=5504294604504136463,,,https://www.sciencedirect.com/science/article/pii/S1571066104002531/pdf?md5=859ced9bf5c1dbf119f64c7789442fba&pid=1-s2.0-S1571066104002531-main.pdf&_valck=1,0,0,0
1276247,An executable formal semantics of C with applications,2012,Chucky Ellison and Grigore Rosu,,,,533-544,ACM,"This paper describes an executable formal semantics of C. Being executable. the semantics has been thoroughly tested against the GCC torture test suite and successfully passes 99.2% of 776 test programs. It is the most complete and thoroughly tested formal definition of C to date. The semantics yields an interpreter. debugger. state space search tool. and model checker ""for free"". The semantics is shown capable of automatically finding program errors. both statically and at runtime. It is also used to enumerate nondeterministic behavior.",True,yxpqbdQAAAAJ:j3f4tGmQtD8C,272,https://dl.acm.org/doi/abs/10.1145/2103621.2103719,4560368032922563724,/scholar?cites=4560368032922563724,,,https://pdfs.semanticscholar.org/5d7f/3d162650ad051da01b0a54a6dc9b767abf13.pdf,0,0,0
1276248,An overview of the runtime verification tool Java PathExplorer,2004,Klaus Havelund and Grigore Roşu,24,Formal methods in system design,2,189-215,Springer Netherlands,We present an overview of the Java PathExplorer runtime verification tool. in short referred to as JPAX. JPAX can monitor the execution of a Java program and check that it conforms with a set of user provided properties formulated in temporal logic. JPAX can in addition analyze the program for concurrency errors such as deadlocks and data races. The concurrency analysis requires no user provided specification. The tool facilitates automated instrumentation of a program's bytecode. which when executed will emit an event stream. the execution trace. to an observer. The observer dispatches the incoming event stream to a set of observer processes. each performing a specialized analysis. such as the temporal logic verification. the deadlock analysis and the data race analysis. Temporal logic specifications can be formulated by the user in the Maude rewriting logic. where Maude is a high-speed rewriting …,True,yxpqbdQAAAAJ:_FM0Bhl9EiAC,262,https://link.springer.com/article/10.1023/B:FORM.0000017721.39909.4b,14787303799458976232,/scholar?cites=14787303799458976232,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.7740&rep=rep1&type=pdf,0,0,0
1276249,An overview of the MOP runtime verification framework,2012,Patrick O’Neil Meredith and Dongyun Jin and Dennis Griffith and Feng Chen and Grigore Roşu,14,,3,249-289,Springer-Verlag,This article gives an overview of the. monitoring oriented programming framework (MOP). In MOP. runtime monitoring is supported and encouraged as a fundamental principle for building reliable systems. Monitors are automatically synthesized from specified properties and are used in conjunction with the original system to check its dynamic behaviors. When a specification is violated or validated at runtime. user-defined actions will be triggered. which can be any code. such as information logging or runtime recovery. Two instances of MOP are presented: JavaMOP (for Java programs) and BusMOP (for monitoring PCI bus traffic). The architecture of MOP is discussed. and an explanation of parametric trace monitoring and its implementation is given. A comprehensive evaluation of JavaMOP attests to its efficiency. especially in comparison with similar systems. The implementation of BusMOP is discussed in …,True,yxpqbdQAAAAJ:mlAyqtXpCwEC,260,https://link.springer.com/article/10.1007/s10009-011-0198-6,12318521750649659126,/scholar?cites=12318521750649659126,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.360.5593&rep=rep1&type=pdf,0,0,0
1276250,Institution morphisms,2002,Joseph Goguen and Grigore Roşu,13,Formal aspects of computing,3,274-307,Springer-Verlag, Institutions formalise the intuitive notion of logical system. including syntax. semantics. and the relation of satisfaction between them. Our exposition emphasises the natural way that institutions can support deduction on sentences. and inclusions of signatures. theories. etc.; it also introduces terminology to clearly distinguish several levels of generality of the institution concept. A surprising number of different notions of morphism have been suggested for forming categories with institutions as objects. and an amazing variety of names have been proposed for them. One goal of this paper is to suggest a terminology that is uniform and informative to replace the current chaotic nomenclature; another goal is to investigate the properties and interrelations of these notions in a systematic way. Following brief expositions of indexed categories. diagram categories. twisted relations and Kan extensions. we …,True,yxpqbdQAAAAJ:GtLg2Ama23sC,255,https://link.springer.com/article/10.1007/s001650200013,910732328975936218,/scholar?cites=910732328975936218,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.7.3729&rep=rep1&type=pdf,0,0,0
1276251,Monitoring programs using rewriting,2001,Klaus Havelund and Grigore Rosu,,,,135-143,IEEE,We present a rewriting algorithm for efficiently testing future time Linear Temporal Logic (LTL) formulae on finite execution traces. The standard models of LTL are infinite traces. reflecting the behavior of reactive and concurrent systems which conceptually may be continuously alive. In most past applications of LTL. theorem provers and model checkers have been used to formally prove that down-scaled models satisfy such LTL specifications. Our goal is instead to use LTL for up-scaled testing of real software applications. corresponding to analyzing the conformance of finite traces against LTL formulae. We first describe what it means for a finite trace to satisfy an LTL formula and then suggest an optimized algorithm based on transforming LTL formulae. We use the Maude rewriting logic. which turns out to be a good notation and being supported by an efficient rewriting engine for performing these experiments. The …,True,yxpqbdQAAAAJ:u-x6o8ySG0sC,255,https://ieeexplore.ieee.org/abstract/document/989799/,7377666545686710009,/scholar?cites=7377666545686710009,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.8.836&rep=rep1&type=pdf,0,0,0
1276252,Java-MOP: A monitoring oriented programming environment for Java,2005,Feng Chen and Grigore Roşu,,,,546-550,Springer. Berlin. Heidelberg,A Java-based tool-supported software development and analysis framework is presented. where monitoring is a foundational principle. Expressive requirements specification formalisms can be included into the framework via logic plug-ins. allowing one to refer not only to the current state. but also to both past and future states.,True,yxpqbdQAAAAJ:LO7wyVUgiFcC,239,https://link.springer.com/chapter/10.1007/978-3-540-31980-1_36,10568474978709789422,/scholar?cites=10568474978709789422,,,https://link.springer.com/content/pdf/10.1007/978-3-540-31980-1_36.pdf,0,0,0
1276253,Efficient monitoring of safety properties,2004,Klaus Havelund and Grigore Roşu,6,International Journal on Software Tools for Technology Transfer,2,158-173,Springer Berlin Heidelberg,The problem of testing whether a finite execution trace of events generated by an executing program violates a linear temporal logic (LTL) formula occurs naturally in runtime analysis of software. Two efficient algorithms for this problem are presented in this paper. both for checking safety formulae of the form “always P”. where P is a past-time LTL formula. The first algorithm is implemented by rewriting. and the second synthesizes efficient code from formulae. Further optimizations of the second algorithm are suggested. reducing space and time consumption. Special operators suitable for writing succinct specifications are discussed and shown to be equivalent to the standard past-time operators. This work is part of NASA’s PathExplorer project. the objective of which is to construct a flexible framework for efficient monitoring and analysis of program executions. ,True,yxpqbdQAAAAJ:anf4URPfarAC,216,https://link.springer.com/article/10.1007/s10009-003-0117-6,9392581715029060738,/scholar?cites=9392581715029060738,,,http://www.havelund.com/Publications/sttt-tacas02.pdf,0,0,0
1276254,Software engineering for self-adaptive systems,2009,R de Lemos and H Giese and HA Müller and M Shaw and J Andersson and L Baresi and B Becker,10431,Dagstuhl Seminar,,,,,True,qABYFOIAAAAJ:4vMrXwiscB8C,2027,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276255,08031--Software engineering for self-adaptive systems: A research road map,2008,Betty HC Cheng and Holger Giese and Paola Inverardi and Jeff Magee and Rogério de Lemos and Jesper Andersson and Basil Becker and Nelly Bencomo and Yuriy Brun and Bojan Cukic and Giovanna Di Marzo Serugendo and Schahram Dustdar and Anthony Finkelstein and Cristina Gacek and Kurt Geihs and Vincenzo Grassi and Gabor Karsai and Holger Kienle and Jeff Kramer and Marin Litoiu and Sam Malek and Raffaela Mirandola and Hausi Müller and Sooyong Park and Mary Shaw and Matthias Tichy and Massimo Tivoli and Danny Weyns and Jon Whittle,,,,,Schloss Dagstuhl-Leibniz-Zentrum für Informatik,,True,qABYFOIAAAAJ:QbuKDewGlxwC,1999,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276256,Software engineering for self-adaptive systems: A research roadmap,2009,Betty HC Cheng and RogÚrio de Lemos and Holger Giese and Paola Inverardi and Jeff Magee and Jesper Andersson and Basil Becker and Nelly Bencomo and Yuriy Brun and Bojan Cukic and Giovanna Di Marzo Serugendo and Schahram Dustdar and Anthony Finkelstein and Cristina Gacek and Kurt Geihs and Vincenzo Grassi and Gabor Karsai and Holger M Kienle and Jeff Kramer and Marin Litoiu and Sam Malek and Raffaela Mirandola and Hausi A MŘller and Sooyong Park and Mary Shaw and Matthias Tichy and Massimo Tivoli and Danny Weyns and Jon Whittle,,,,1-26,Springer. Berlin. Heidelberg,,True,qABYFOIAAAAJ:bO_hriczGZwC,1995,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276257,Software engineering for self-adaptive systems: A research roadmap,2009,,,Software Engineering for Self-Adaptive Systems,,1-26,Springer Berlin/Heidelberg,,True,qABYFOIAAAAJ:Uo5fLKClJkAC,1995,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276258,Software Engineering for Self-Adaptive Systems: A Research Road Map (Draft Version),2008,Betty HC Cheng and Rogério de Lemos and Holger Giese and Paola Inverardi and Jeff Magee and Raffaela Mirandola Malek and Hausi Müller and Sooyong Park and Mary Shaw and Matthias Tichy and Massimo Tivoli and Danny Weyns and Jon Whittle,,Dagstuhl Seminar Proc. 08031,,,,,True,qABYFOIAAAAJ:_kc_bZDykSQC,1995,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276259,Composing adaptive software,2004,P.K. McKinley and S.M. Sadjadi and E.P. Kasten and BHC Cheng,,,,,,Interest in adaptive computing systems has increased dramatically in the past few years. and a variety of techniques now allow software to adapt dynamically to its environment. Compositional adaptation enables software to modify its structure and behavior dynamically in response to change in its execution environment. A review of current technology compares how. when. and where recomposition occurs.,True,qABYFOIAAAAJ:Tiz5es2fbqcC,896,https://ieeexplore.ieee.org/abstract/document/1310241/,2720715807615092249,/scholar?cites=2720715807615092249,,,https://www.academia.edu/download/46612967/Composing_adaptive_software20160619-5636-fzhwgu.pdf,0,0,0
1276260,Research directions in requirements engineering,2007,Betty HC Cheng and Joanne M Atlee,,,,285-303,IEEE,"In this paper. we review current requirements engineering (RE) research and identify future research directions suggested by emerging software needs. First. we overview the state of the art in RE research. The research is considered with respect to technologies developed to address specific requirements tasks. such as elicitation. modeling. and analysis. Such a review enables us to identify mature areas of research. as well as areas that warrant further investigation. Next. we review several strategies for performing and extending RE research results. to help delineate the scope of future research directions. Finally. we highlight what we consider to be the ""hot"" current and future research topics. which aim to address RE needs for emerging systems of the future.",True,qABYFOIAAAAJ:WbkHhVStYXYC,876,https://ieeexplore.ieee.org/abstract/document/4221627/,777466033969324854,/scholar?cites=777466033969324854,,,https://cs.uwaterloo.ca/~jmatlee/Papers/ICSE07c.pdf,0,0,0
1276261,Model-based development of dynamically adaptive software,2006,Ji Zhang and Betty HC Cheng,,,,371-380,ACM,Increasingly. software should dynamically adapt its behavior at run-time in response to changing conditions in the supporting computing and communication infrastructure. and in the surrounding physical environment. In order for an adaptive program to be trusted. it is important to have mechanisms to ensure that the program functions correctly during and after adaptations. Adaptive programs are generally more difficult to specify. verify. and validate due to their high complexity. Particularly. when involving multi-threaded adaptations. the program behavior is the result of the collaborative behavior of multiple threads and software components. This paper introduces an approach to create formal models for the behavior of adaptive programs. Our approach separates the adaptation behavior and non-adaptive behavior specifications of adaptive programs. making the models easier to specify and more amenable to …,True,qABYFOIAAAAJ:l7t_Zn2s7bgC,535,https://dl.acm.org/doi/abs/10.1145/1134285.1134337,1336431861597398859,/scholar?cites=1336431861597398859,,,https://www.researchgate.net/profile/Betty_Cheng3/publication/221553932_Model-based_development_of_dynamically_adaptive_software/links/0046351f6c3222b69a000000/Model-based-development-of-dynamically-adaptive-software.pdf,0,0,0
1276262,Real-time specification patterns,2005,Sascha Konrad and Betty HC Cheng,,,,372-381,ACM,Embedded systems are pervasive and frequently used for critical systems with time-dependent functionality. Dwyer et al have developed qualitative specification patterns to facilitate the specification of critical properties. such as those that must be satisfied by embedded systems. Thus far. no analogous repository has been compiled for real-time specification patterns. This paper makes two main contributions: First. based on an analysis of timing-based requirements of several industrial embedded system applications. we created real-time specification patterns in terms of three commonly used real-time temporal logics. Second. as a means to further facilitate the understanding of the meaning of a specification. we offer a structured English grammar that includes support for real-time properties. We illustrate the use of the real-time specification patterns in the context of property specifications of a real-world automotive …,True,qABYFOIAAAAJ:08ZZubdj9fEC,375,https://dl.acm.org/doi/abs/10.1145/1062455.1062526,12926886400104316216,/scholar?cites=12926886400104316216,,,https://www.researchgate.net/profile/Betty_Cheng3/publication/4200522_Real-time_specification_patterns/links/0912f50aa1299d7c66000000.pdf,0,0,0
1276263,A formal semantics for object model diagrams,1995,Robert H Bourdeau and Betty HC Cheng,21,IEEE Transactions on software engineering,10,799-821,IEEE,Informal software development techniques. such as the object modeling technique (OMT). provide the user with easy to understand graphical notations for expressing a wide variety of concepts central to the presentation of software requirements. OMT combines three complementary diagramming notations for documenting requirements: object models. dynamic models. and functional models. OMT is a useful organizational tool in the requirements analysis and system design processes. Currently. the lack of formality in OMT prevents the evaluation of completeness. consistency. and content in requirements and design specifications. A formal method is a mathematical approach to software development that begins with the construction of a formal specification describing the system under development. However. constructing a formal specification directly from a prose description of requirements can be challenging …,True,qABYFOIAAAAJ:738O_yMBCRsC,310,https://ieeexplore.ieee.org/abstract/document/469459/,7948775859693901478,/scholar?cites=7948775859693901478,,,,0,0,0
1276264,Relax: Incorporating uncertainty into the specification of self-adaptive systems,2009,Jon Whittle and Pete Sawyer and Nelly Bencomo and Betty HC Cheng and Jean-Michel Bruel,,,,79-88,IEEE,Self-adaptive systems have the capability to autonomously modify their behaviour at run-time in response to changes in their environment. Self-adaptation is particularly necessary for applications that must run continuously. even under adverse conditions and changing requirements; sample domains include automotive systems. telecommunications. and environmental monitoring systems. While a few techniques have been developed to support the monitoring and analysis of requirements for adaptive systems. limited attention has been paid to the actual creation and specification of requirements of self-adaptive systems. As a result. self-adaptivity is often constructed in an ad-hoc manner. In this paper. we argue that a more rigorous treatment of requirements explicitly relating to self-adaptivity is needed and that. in particular. requirements languages for self-adaptive systems should include explicit constructs for …,True,qABYFOIAAAAJ:mvPsJ3kp5DgC,307,https://ieeexplore.ieee.org/abstract/document/5328591/,12374767763743734825,/scholar?cites=12374767763743734825,,,https://publications.aston.ac.uk/id/eprint/19658/1/RELAX_incorporating_uncertainty.pdf,0,0,0
1276265,Making components contract aware,1999,Antoine Beugnard and J-M Jézéquel and Noël Plouzeau and Damien Watkins,32,Computer,7,38-45,IEEE,Components have long promised to encapsulate data and programs into a box that operates predictably without requiring that users know the specifics of how it does so. Many advocates have predicted that components will bring about widespread software reuse. spawning a market for components usable with such mainstream software buses as the Common Object Request Broker Architecture (CORBA) and the Distributed Component Object Model (DCOM). In the Windows world. at least. this prediction is becoming a reality. Yet recent reports indicate mixed results when using and reusing components in mission-critical settings. Such results raise disturbing questions. How can you trust a component? What if the component behaves unexpectedly. either because it is faulty or simply because you misused it? Before we can trust a component in mission-critical applications. we must be able to determine. reliably …,True,DZ5_Gw4AAAAJ:u5HHmVD_uO8C,892,https://ieeexplore.ieee.org/abstract/document/774917/,15442822453224632512,/scholar?cites=15442822453224632512,,,https://core.ac.uk/download/pdf/227333443.pdf,0,0,0
1276266,Weaving executability into object-oriented meta-languages,2005,Pierre-Alain Muller and Franck Fleurey and Jean-Marc Jézéquel,,,,264-278,Springer. Berlin. Heidelberg,Nowadays. object-oriented meta-languages such as MOF (Meta-Object Facility) are increasingly used to specify domain-specific languages in the model-driven engineering community. However. these meta-languages focus on structural specifications and have no built-in support for specifications of operational semantics. In this paper we explore the idea of using aspect-oriented modeling to add precise action specifications with static type checking and genericity at the meta level. and examine related issues and possible solutions. We believe that such a combination would bring significant benefits to the community. such as the specification. simulation and testing of operational semantics of metamodels. We present requirements for such statically-typed meta-languages and rationales for the aforementioned benefits.,True,DZ5_Gw4AAAAJ:u-x6o8ySG0sC,667,https://link.springer.com/chapter/10.1007/11557432_19,9423625165708141912,/scholar?cites=9423625165708141912,,,https://hal.inria.fr/hal-00795095/document,0,0,0
1276267,Models@ run. time to support dynamic adaptation,2009,Brice Morin and Olivier Barais and Jean-Marc Jézéquel and Franck Fleurey and Arnor Solberg,42,Computer,10,44-51,IEEE,Today's society increasingly depends on software systems deployed in large companies. banks. airports. and so on. These systems must be available 24/7 and continuously adapt to varying environmental conditions and requirements. Such dynamically adaptive systems exhibit degrees of variability that depend on user needs and runtime fluctuations in their contexts. The paper presents an approach for specifying and executing dynamically adaptive software systems that combines model-driven and aspect-oriented techniques to help engineers tame the complexity of such systems while offering a high degree of automation and validation.,True,DZ5_Gw4AAAAJ:LkGwnXOMwfcC,489,https://ieeexplore.ieee.org/abstract/document/5280651/,15766243700441114043,/scholar?cites=15766243700441114043,,,https://hal.inria.fr/inria-00477529/document,0,0,0
1276268,Refactoring UML models,2001,Gerson Sunyé and Damien Pollet and Yves Le Traon and Jean-Marc Jézéquel,,,,134-148,Springer. Berlin. Heidelberg,Software developers spend most of their time modifying and maintaining existing products. This is because systems. and consequently their design. are in perpetual evolution before they die. Nevertheless. dealing with this evolution is a complex task. Before evolving a system. structural modifications are often required. The goal of this kind of modification is to make certain elements more extensible. permitting the addition of new features. However. designers are seldom able to evaluate the impact. on the whole model. of a single modification. That is. they cannot precisely verify if a change modifies the behavior of the modeled system. A possible solution for this problem is to provide designers with a set of basic transformations. which can ensure behavior preservation. These transformations. also known as refactorings. can then be used. step by step. to improve the design of the system. In this paper we …,True,DZ5_Gw4AAAAJ:d1gkVwhDpl0C,394,https://link.springer.com/chapter/10.1007/3-540-45441-1_11,17382783106844086392,/scholar?cites=17382783106844086392,,,https://hal.inria.fr/hal-00794510/file/Sunye01b.pdf,0,0,0
1276269,Automatic test generation: A use case driven approach,2006,Clementine Nebut and Franck Fleurey and Yves Le Traon and J-M Jezequel,32,IEEE Transactions on Software Engineering,3,140-155,IEEE,Use cases are believed to be a good basis for system testing. Yet. to automate the test generation process. there is a large gap to bridge between high-level use cases and concrete test cases. We propose a new approach for automating the generation of system test scenarios in the context of object-oriented embedded software. taking into account traceability problems between high-level views and concrete test case execution. Starting from a formalization of the requirements based on use cases extended with contracts. we automatically build a transition system from which we synthesize test cases. Our objective is to cover the system in terms of statement coverage with those generated tests: an empirical evaluation of our approach is given based on this objective and several case studies. We briefly discuss the experimental deployment of our approach in the field at Thales Airborne Systems.,True,DZ5_Gw4AAAAJ:2osOgNQ5qMEC,389,https://ieeexplore.ieee.org/abstract/document/1610607/,13993453186457639715,/scholar?cites=13993453186457639715,,,https://hal-lirmm.ccsd.cnrs.fr/lirmm-00102747/file/D647.PDF,0,0,0
1276270,Design by contract: The lessons of Ariane,1997,J-M Jazequel and Bertrand Meyer,30,Computer,1,129-130,IEEE,Design by contract is the principle that the interfaces between modules of a software system-especially a mission-critical one-should be governed by precise specifications. The contracts cover mutual obligations (pre-conditions). benefits (post-conditions). and consistency constraints (invariants). Together. these properties are known as assertions. and are directly supported in some design and programming languages. A recent $500 million software error provides a sobering reminder that this principle is not just a pleasant academic ideal. On June 4. 1996. the maiden flight of the European Ariane 5 launcher crashed. about 40 seconds after takeoff. The rocket was uninsured. The French space agency. CNES (Centre National d'Etudes Spatiales). and the European Space Agency (ESA) immediately appointed an international inquiry board. The board makes several recommendations with respect to software …,True,DZ5_Gw4AAAAJ:q3CdL3IzO_QC,380,https://ieeexplore.ieee.org/abstract/document/562936/,6517968218667332078,/scholar?cites=6517968218667332078,,,http://se.inf.ethz.ch/~meyer/publications/computer/ariane.pdf,0,0,0
1276271,Taming dynamically adaptive systems using models and aspects,2009,Brice Morin and Olivier Barais and Gregory Nain and Jean-Marc Jézéquel,,,,122-132,IEEE,Since software systems need to be continuously available under varying conditions. their ability to evolve at runtime is increasingly seen as one key issue. Modern programming frameworks already provide support for dynamic adaptations. However the high-variability of features in Dynamic Adaptive Systems (DAS) introduces an explosion of possible runtime system configurations (often called modes) and mode transitions. Designing these configurations and their transitions is tedious and error-prone. making the system feature evolution difficult. While Aspect-Oriented Modeling (AOM) was introduced to improve the modularity of software. this paper presents how an AOM approach can be used to tame the combinatorial explosion of DAS modes. Using AOM techniques. we derive a wide range of modes by weaving aspects into an explicit model reflecting the runtime system. We use these generated modes to …,True,DZ5_Gw4AAAAJ:_FxGoFyzp5QC,291,https://ieeexplore.ieee.org/abstract/document/5070514/,10099634254243446735,/scholar?cites=10099634254243446735,,,https://hal.inria.fr/inria-00468516/file/Morin09a.pdf,0,0,0
1276272,Towards a UML profile for software product lines,2003,Tewfik Ziadi and Loïc Hélouët and Jean-Marc Jézéquel,,,,129-139,Springer. Berlin. Heidelberg,This paper proposes a UML profile for software product lines. This profile includes stereotypes. tagged values. and structural constraints and it makes possible to define PL models with variabilities. Product derivation consists in generating product models from PL models. The derivation should preserve and ensure a set of constraints which are specified using the OCL.,True,DZ5_Gw4AAAAJ:Tyk-4Ss8FVUC,240,https://link.springer.com/chapter/10.1007/978-3-540-24667-1_10,15479132651278337060,/scholar?cites=15479132651278337060,,,https://hal.inria.fr/hal-00794817/file/Ziadi03c.pdf,0,0,0
1276273,Efficient object-oriented integration and regression testing,2000,Yves Le Traon and Thierry Jéron and J-M Jézéquel and Pierre Morel,49,IEEE Transactions on Reliability,1,12-25,IEEE,This paper presents a model. a strategy and a methodology for planning integration and regression testing from an object-oriented model. It shows how to produce a model of structural system test dependencies which evolves with the refinement process of the object-oriented design. The model (test dependency graph) serves as a basis for ordering classes and methods to be tested for regression and integration purposes (minimization of test stubs). The mapping from unified modeling language to the defined model is detailed as well as the test methodology. While the complexity of optimal stub minimization is exponential with the size of the model. an algorithm is given that: computes a strategy for integration testing with a quadratic complexity in the worst case; and provides an efficient testing order for minimizing the number of stubs. Various integration strategies are compared with the optimized algorithm (a real …,True,DZ5_Gw4AAAAJ:IjCSPb-OGe4C,179,https://ieeexplore.ieee.org/abstract/document/855533/,8891317785901027577,/scholar?cites=8891317785901027577,,,https://www.academia.edu/download/39231297/79e4150ca5001512d8.pdf,0,0,0
1276274,On model typing,2007,Jim Steel and Jean-Marc Jézéquel,6,Software & Systems Modeling,4,401-413,Springer-Verlag,Where object-oriented languages deal with objects as described by classes. model-driven development uses models. as graphs of interconnected objects. described by metamodels. A number of new languages have been and continue to be developed for this model-based paradigm. both for model transformation and for general programming using models. Many of these use single-object approaches to typing. derived from solutions found in object-oriented systems. while others use metamodels as model types. but without a clear notion of polymorphism. Both of these approaches lead to brittle and overly restrictive reuse characteristics. In this paper we propose a simple extension to object-oriented typing to better cater for a model-oriented context. including a simple strategy for typing models as a collection of interconnected objects. We suggest extensions to existing type system formalisms to support …,True,DZ5_Gw4AAAAJ:UebtZRa9Y70C,174,https://link.springer.com/content/pdf/10.1007/s10270-006-0036-6.pdf,18237604728606888,/scholar?cites=18237604728606888,,,https://tel.archives-ouvertes.fr/tel-00538274/file/Steel07b.pdf,0,0,0
1276275,UMLAUT: an extendible UML transformation framework,1999,Wai Ming Ho and J-M Jézéquel and Alain Le Guennec and François Pennaneac'h,,,,275-278,IEEE,Advanced users often find themselves restricted by the limited facilities of most UML CASE tools when they want to do complex manipulations of UML models. e.g.. apply design patterns. generate code for simulation and validation etc. We describe UMLAUT. a freely available UML transformation framework for manipulating UML models. These manipulations are expressed as algebraic compositions of reified elementary transformations. They are thus open to extensions through inheritance and aggregation. To illustrate the interest of our approach. we show how the model of a UML distributed application can be automatically transformed into a labeled transition system validated using advanced protocol validation technology.,True,DZ5_Gw4AAAAJ:9yKSN-GCB0IC,169,https://ieeexplore.ieee.org/abstract/document/802320/,14091066268363085659,/scholar?cites=14091066268363085659,,,https://hal.inria.fr/docs/00/07/28/86/PDF/RR-3775.pdf,0,0,0
1276276,Adalimumab induces and maintains mucosal healing in patients with Crohn's disease: data from the EXTEND trial,2012,Paul Rutgeerts and Gert Van Assche and William J Sandborn and Douglas C Wolf and Karel Geboes and Jean–Frédéric Colombel and Walter Reinisch and Ashish Kumar and Andreas Lazar and Anne Camez and Kathleen G Lomax and Paul F Pollack and Geert D'Haens and EXTEND Investigators,142,Gastroenterology,5,1102-1111. e2,WB Saunders,We investigated the efficacy of adalimumab for inducing and maintaining mucosal healing in patients with Crohn's disease (CD).A randomized. double-blind. placebo-controlled trial (extend the safety and efficacy of adalimumab through endoscopic healing [EXTEND]) evaluated adalimumab for induction and maintenance of mucosal healing in 135 adults with moderate to severe ileocolonic CD. The baseline degree of mucosal ulceration was documented by ileocolonoscopy. All patients received induction therapy (subcutaneous adalimumab 160/80 mg at weeks 0/2). At week 4. patients were randomly assigned to groups given 40 mg adalimumab or placebo every other week through week 52. Open-label adalimumab was given to patients with flares or no response. starting at week 8. Mucosal healing was reassessed by ileocolonoscopy at weeks 12 and 52.Twenty-seven …,True,_JxZ_VwAAAAJ:5Y7y0xowK3MC,517,https://www.sciencedirect.com/science/article/pii/S001650851200159X,11325213355711295239,/scholar?cites=11325213355711295239,,,https://www.gastrojournal.org/article/S0016-5085(12)00159-X/fulltext,0,0,0
1276277,Immediate early and early lytic cycle proteins are frequent targets of the Epstein-Barr virus–induced cytotoxic T cell response,1997,NM Steven and NE Annels and A Kumar and AM Leese and MG Kurilla and AB Rickinson,185,The Journal of experimental medicine,9,1605-1618,The Rockefeller University Press,Epstein-Barr virus (EBV). a human γ-herpesvirus. can establish both nonproductive (latent) and productive (lytic) infections. Although the CD8+ cytotoxic T lymphocyte (CTL) response to latently infected cells is well characterized. very little is known about T cell controls over lytic infection; this imbalance in our understanding belies the importance of virus-replicative lesions in several aspects of EBV disease pathogenesis. The present work shows that the primary CD8+ CTL response to EBV in infectious mononucleosis patients contains multiple lytic antigen-specific reactivities at levels at least as high as those seen against latent antigens; similar reactivities are also detectable in CTL memory. Clonal analysis revealed individual responses to the two immediate early proteins BZLF1 and BRLF1. and to three (BMLF1. BMRF1. and BALF2) of the six early proteins tested. In several cases. the peptide epitope and HLA …,True,_JxZ_VwAAAAJ:RgMnzfD6kpIC,377,https://rupress.org/jem/article-abstract/185/9/1605/25443,6074017887358646662,/scholar?cites=6074017887358646662,,,https://rupress.org/jem/article/185/9/1605/25443,0,0,0
1276278,A role for CREB binding protein and p300 transcriptional coactivators in Ets-1 transactivation functions,1998,Cheng Yang and Linda H Shapiro and Morris Rivera and Alok Kumar and Paul K Brindle,18,Molecular and cellular biology,4,2218-2229,American Society for Microbiology Journals,The Ets-1 transcription factor plays a critical role in cell growth and development. but the means by which it activates transcription are still unclear (J. C. Bories. D. M. Willerford. D. Grevin. L. Davidson. A. Camus. P. Martin. D. Stehelin. F. W. Alt. and J. C. Borles. Nature 377:635–638. 1995; N. Muthusamy. K. Barton. and J. M. Leiden. Nature 377:639–642. 1995). Here we show that Ets-1 binds the transcriptional coactivators CREB binding protein (CBP) and the related p300 protein (together referred to as CBP/p300) and that this interaction is required for specific Ets-1 transactivation functions. The Ets-1- and c-Myb-dependent aminopeptidase N (CD13/APN) promoter and an Ets-1-dependent artificial promoter were repressed by adenovirus E1A. a CBP/p300-specific inhibitor. Furthermore. Ets-1 activity was potentiated by CBP and p300 overexpression. The transactivation function of Ets-1 correlated with its ability to …,True,_JxZ_VwAAAAJ:10ZmGoIvuzkC,234,https://mcb.asm.org/content/18/4/2218.short,8364819662512998795,/scholar?cites=8364819662512998795,,,https://mcb.asm.org/content/mcb/18/4/2218.full.pdf,0,0,0
1276279,Effect of A. lanata leaf extract and Vediuppu chunnam on the urinary risk factors of calcium oxalate urolithiasis during experimental hyperoxaluria,2001,R Selvam and P Kalaiselvi and A Govindaraj and V Bala Murugan and AS Sathish Kumar,43,Pharmacological Research,1,89-93,Academic Press,Urolithiasis is one of the third most common afflictions found in humans. The efficacy of the two Siddha drugs. Aerva lanata and Vediuppu chunnam as antilithic agents using a urolithic rat model were tested in this study. Hyperoxaluria was induced in rats using 0.75% ethylene glycol in drinking water. Aerva lanata(3.0 mg kg−1body weight) and Vediuppu chunnam (3.5 mg kg−1body weight) were given orally for 28 days. Urinary risk factors of urolithiasis were monitored at the end of 7th. 14th. 21st and 28th days. Urinary volume was increased in hyperoxaluric as well as drug-treated rats. Increased urinary excretion of calcium. oxalate. uric acid. phosphorus and protein in hyperoxaluric rats was brought down significantly by the administration of A. lanata or Vediuppu chunnam. Decreased magnesium excretion in hyperoxaluric rats was normalized by drug treatment. The drug increases the urine volume. thereby …,True,_JxZ_VwAAAAJ:9fRKRCJz75UC,216,https://www.sciencedirect.com/science/article/pii/S104366180090745X,3905037017209482680,/scholar?cites=3905037017209482680,,,,0,0,0
1276280,Are eddies nature's trigger to enhance biological productivity in the Bay of Bengal?,2004,S Prasanna Kumar and M Nuncio and Jayu Narvekar and Ajoy Kumar and de Souza Sardesai and SN De Souza and Mangesh Gauns and N Ramaiah and M Madhupratap,31,Geophysical Research Letters,7,,,The Bay of Bengal is traditionally considered to be a less productive basin compared to the Arabian Sea. Despite the contrasting chlorophyll and primary productivity pattern. sediment trap data shows that annual fluxes of organic carbon reach comparable rates in both the basins. The traditional mechanisms of nutrient supply to the upper ocean waters cannot account for this. We propose eddy pumping as a possible mechanism of vertical transfer of nutrients across the halocline to the oligotrophic euphotic zone during summer monsoon when upper ocean is highly stratified. This would induce rapid biological uptake and in turn significantly increase biological production. In the northern Bay. riverine input acts as an additional source of nutrients and augments the subsurface nutrient injection to the euphotic zone by eddy pumping. Notwithstanding this. the lower than expected primary production in the north suggests …,True,_JxZ_VwAAAAJ:K0fIQ6b0NmsC,203,https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2003GL019274,18241897094746092052,/scholar?cites=18241897094746092052,,,https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2003GL019274,0,0,0
1276281,Impact of distributed generations with energy storage devices on the electric grid,2012,Anurag K Srivastava and Aarti Asok Kumar and Noel N Schulz,6,IEEE Systems Journal,1,110-117,IEEE,The commonly used distributed generations (DG) technologies include wind generators. photovoltaics. and biomass generators with their sizes varying between several kW to a few MW. Energy storage devices are generally used to smooth variations in DG's MW output due to inherent unpredictability and to minimize exchange of power from grid. Connecting the storage and DGs to the grid have both technical and economic impacts. This paper aims at analyzing the technical and economic impacts of distributed generators along with energy storage devices on the distribution system. The technical analysis includes analyzing the transient stability of a system with DGs and energy storage devices. such as a battery and ultracapacitor. The DGs are represented by small synchronous and induction generators. Different types and locations of faults and different penetration levels of the DGs are considered in the …,True,_JxZ_VwAAAAJ:6sy8ByAbWgIC,199,https://ieeexplore.ieee.org/abstract/document/6140538/,1275718397762852471,/scholar?cites=1275718397762852471,,,http://krex.k-state.edu/dspace/bitstream/handle/2097/15273/Schulz?sequence=1,0,0,0
1276282,Human papillomavirus oncoprotein E6 inactivates the transcriptional coactivator human ADA3,2002,Ajay Kumar and Yongtong Zhao and Gaoyuan Meng and Musheng Zeng and Seetha Srinivasan and Laurie M Delmolino and Qingshen Gao and Goberdhan Dimri and Georg F Weber and David E Wazer and Hamid Band and Vimla Band,22,Molecular and cellular biology,16,5801-5812,American Society for Microbiology Journals,High-risk human papillomaviruses (HPVs) are associated with carcinomas of the cervix and other genital tumors. The HPV oncoprotein E6 is essential for oncogenic transformation. We identify here hADA3. human homologue of the yeast transcriptional coactivator yADA3. as a novel E6-interacting protein and a target of E6-induced degradation. hADA3 binds selectively to the high-risk HPV E6 proteins and only to immortalization-competent E6 mutants. hADA3 functions as a coactivator for p53-mediated transactivation by stabilizing p53 protein. Notably. three immortalizing E6 mutants that do not induce direct p53 degradation but do interact with hADA3 induced the abrogation of p53-mediated transactivation and G1 cell cycle arrest after DNA damage. comparable to wild-type E6. These findings reveal a novel strategy of HPV E6-induced loss of p53 function that is independent of direct p53 degradation. Given the …,True,_JxZ_VwAAAAJ:1zNUifcpCKoC,194,https://mcb.asm.org/content/22/16/5801.short,8680936007954856177,/scholar?cites=8680936007954856177,,,https://mcb.asm.org/content/mcb/22/16/5801.full.pdf,0,0,0
1276283,IL-10 production is enhanced in human T cells by IL-12 and IL-6 and in monocytes by tumor necrosis factor-alpha.,1996,Pirouz M Daftarian and Ashok Kumar and Marko Kryworuchko and Francisco Diaz-Mitoma,157,The Journal of Immunology,1,12-20,American Association of Immunologists,IL-10. an immunoregulatory cytokine produced by T cells and monocytes. inhibits the expression of inflammatory and hemopoietic cytokines as well as its own expression. To evaluate the regulation of IL-10 production by T cells and monocytes. we measured IL-10 levels by ELISA in supernatants of PHA-stimulated PBMC following depletion of either T cells or monocytes. IL-10 production was significantly down-regulated in both T cell- and monocyte-depleted PBMC compared with undepleted PBMC. and IL-10 production could be restored by the addition of monocyte-conditioned medium (supernatant of PHA-stimulated. T cell-depleted PBMC). suggesting that IL-10 production by T cells is regulated by a monokine(s) produced by activated monocytes. To further clarify the monokine(s) responsible for IL-10 induction. we stimulated monocyte-depleted PBMC. purified CD4+. and CD8+ T cells with PHA and measured …,True,_JxZ_VwAAAAJ:UBSsHvkqiq4C,190,https://www.jimmunol.org/content/157/1/12.short,3578355750512256235,/scholar?cites=3578355750512256235,,,,0,0,0
1276284,The phenylalanine ammonia-lyase gene family in raspberry. Structure. expression. and evolution,2001,Amrita Kumar and Brian E Ellis,127,Plant Physiology,1,230-239,American Society of Plant Biologists,In raspberry (Rubus idaeus). development of fruit color and flavor are critically dependent on products of the phenylpropanoid pathway. To determine how these metabolic functions are integrated with the fruit ripening program. we are examining the properties and expression of key genes in the pathway. Here. we report that l- phenylalanine ammonia-lyase (PAL) is encoded in raspberry by a family of two genes (RiPAL1 andRiPAL2). RiPAL1 shares 88% amino acid sequence similarity to RiPAL2. but phylogenetic analysis places RiPAL1 and RiPAL2 in different clusters within the plant PAL gene family. The spatial and temporal expression patterns of the two genes were investigated in various vegetative and floral tissues using the reverse transcriptase competitor polymerase chain reaction assay. Although expression of both genes was detected in all tissues examined. RiPAL1 was associated with early fruit …,True,_JxZ_VwAAAAJ:IWHjjKOFINEC,182,http://www.plantphysiol.org/content/127/1/230.short,4180234994721215919,/scholar?cites=4180234994721215919,,,http://www.plantphysiol.org/content/plantphysiol/127/1/230.full.pdf,0,0,0
1276285,Measuring arthropod biodiversity in the tropical forest canopy.,1995,Terry L Erwin,,Forest canopies.,,109-127,Academic Press,A historical review of what has been achieved with arthropod diversity sampling sampling Subject Category: Techniques. Methodologies and Equipment,True,_JxZ_VwAAAAJ:as11RrW_MxEC,156,https://www.cabdirect.org/cabdirect/abstract/19960603745,11090231147645294103,/scholar?cites=11090231147645294103,,,,0,0,0
1276286,Role of secondary structure in discrimination between constitutive and inducible activators,1999,David Parker and Morris Rivera and Tsaffir Zor and Alexandra Henrion-Caude and Ishwar Radhakrishnan and Alok Kumar and Linda H Shapiro and Peter E Wright and Marc Montminy and Paul K Brindle,19,Molecular and cellular biology,8,5601-5607,American Society for Microbiology Journals,We have examined structural differences between the proto-oncogene c-Myb and the cyclic AMP-responsive factor CREB that underlie their constitutive or signal-dependent activation properties. Both proteins stimulate gene expression via activating regions that articulate with a shallow hydrophobic groove in the KIX domain of the coactivator CREB-binding protein (CBP). Three hydrophobic residues in c-Myb that are conserved in CREB function importantly in cellular gene activation and in complex formation with KIX. These hydrophobic residues are assembled on one face of an amphipathic helix in both proteins. and mutations that disrupt c-Myb or CREB helicity in this region block interaction of either factor with KIX. Binding of the helical c-Myb domain to KIX is accompanied by a substantial increase in entropy that compensates for the comparatively low enthalpy of complex formation. By contrast. binding of …,True,_JxZ_VwAAAAJ:ktX0m338QuYC,149,https://mcb.asm.org/content/19/8/5601.short,9716016996817734793,/scholar?cites=9716016996817734793,,,https://mcb.asm.org/content/mcb/19/8/5601.full.pdf,0,0,0
1276287,Handbook of graph grammars and computing by graph transformation,1997,Grzegorz Rozenberg,1,,,,World scientific,Graph grammars originated in the late 60s. motivated by considerations about pattern recognition and compiler construction. Since then the list of areas which have interacted with the development of graph grammars has grown quite impressively. Besides the aforementioned areas it includes software specification and development. VLSI layout schemes. database design. modeling of concurrent systems. massively parallel computer architectures. logic programming. computer animation. developmental biology. music composition. visual languages. and many others. The area of graph grammars and graph transformations generalizes formal language theory based on strings and the theory of term rewriting based on trees. As a matter of fact within the area of graph grammars. graph transformation is considered a fundamental programming paradigm where computation includes specification. programming. and implementation.,True,3AV1TsAAAAAJ:LhH-TYMQEocC,2168,http://books.google.com/books?hl=en&lr=&id=P3r82gfRf8MC&oi=fnd&pg=PA1&dq=info:2wYWGEfUprUJ:scholar.google.com&ots=S9x3NRmr1U&sig=kqG7P35SXWKIdujQ-A6rmfymhhw,13089382768810788571,/scholar?cites=13089382768810788571,,,https://www.academia.edu/download/51344554/52752569.pdf,0,0,0
1276288,Software engineering for self-adaptive systems: A second research roadmap,2013,Rogério De Lemos and Holger Giese and Hausi A Müller and Mary Shaw and Jesper Andersson and Marin Litoiu and Bradley Schmerl and Gabriel Tamura and Norha M Villegas and Thomas Vogel and Danny Weyns and Luciano Baresi and Basil Becker and Nelly Bencomo and Yuriy Brun and Bojan Cukic and Ron Desmarais and Schahram Dustdar and Gregor Engels and Kurt Geihs and Karl M Göschka and Alessandra Gorla and Vincenzo Grassi and Paola Inverardi and Gabor Karsai and Jeff Kramer and Antónia Lopes and Jeff Magee and Sam Malek and Serge Mankovskii and Raffaela Mirandola and John Mylopoulos and Oscar Nierstrasz and Mauro Pezzè and Christian Prehofer and Wilhelm Schäfer and Rick Schlichting and Dennis B Smith and Joao Pedro Sousa and Ladan Tahvildari and Kenny Wong and Jochen Wuttke,,,,1-32,Springer. Berlin. Heidelberg,The goal of this roadmap paper is to summarize the state-of-the-art and identify research challenges when developing. deploying and managing self-adaptive software systems. Instead of dealing with a wide range of topics associated with the field. we focus on four essential topics of self-adaptation: design space for self-adaptive solutions. software engineering processes for self-adaptive systems. from centralized to decentralized control. and practical run-time verification & validation for self-adaptive systems. For each topic. we present an overview. suggest future directions. and focus on selected challenges. This paper complements and extends a previous roadmap on software engineering for self-adaptive systems published in 2009 covering a different set of topics. and reflecting in part on the previous paper. This roadmap is one of the many results of the Dagstuhl Seminar 10431 on Software …,True,3AV1TsAAAAAJ:R3hNpaxXUhUC,2010,https://link.springer.com/chapter/10.1007/978-3-642-35813-5_1,6326161709606373965,/scholar?cites=6326161709606373965,,,https://drops.dagstuhl.de/opus/volltexte/2011/3156/pdf/report10431_3156.pdf,0,0,0
1276289,Handbook of graph grammars and computing by graph transformation,1999,Hartmut Ehrig and Grzegorz Rozenberg and Hans-J rg Kreowski,3,,,,world Scientific,Graph grammars originated in the late 60s. motivated by considerations about pattern recognition and compiler construction. Since then. the list of areas which have interacted with the development of graph grammars has grown quite impressively. Besides the aforementioned areas. it includes software specification and development. VLSI layout schemes. database design. modeling of concurrent systems. massively parallel computer architectures. logic programming. computer animation. developmental biology. music composition. visual languages. and many others. The area of graph grammars and graph transformations generalizes formal language theory based on strings and the theory of term rewriting based on trees. As a matter of fact. within the area of graph grammars. graph transformation is considered as a fundamental computation paradigm where computation includes specification. programming. and implementation. Over the last three decades. graph grammars have developed at a steady pace into a theoretically attractive and important-for-applications research field. Volume 3 of the indispensable Handbook of Graph Grammars and Computing by Graph Transformations presents the research on concurrency. parallelism. and distribution? important paradigms of modern computer science. The topics considered include semantics for concurrent systems. modeling of concurrency. mobile and coordinated systems. algebraic specifications. Petri nets. visual design of distributed systems. and distributed algorithms. The contributions have been written in a tutorial/survey style by the top experts.,True,3AV1TsAAAAAJ:u5HHmVD_uO8C,1060,http://books.google.com/books?hl=en&lr=&id=nwD_oRtfJKkC&oi=fnd&pg=PA2&dq=info:aZVErnwfW64J:scholar.google.com&ots=zxgYwQna9x&sig=osbFAipkvkIeUuG8Go0uP2C0maQ,12563670205840266601,/scholar?cites=12563670205840266601,,,,0,0,0
1276290,Graph transformation for specification and programming,1999,Marc Andries and Gregor Engels and Annegret Habel and Berthold Hoffmann and Hans-Jörg Kreowski and Sabine Kuske and Detlef Plump and Andy Schürr and Gabriele Taentzer,34,,1,1-54,Elsevier,The framework of graph transformation combines the potentials and advantages of both. graphs and rules. to a single computational paradigm. In this paper we present some recent developments in applying graph transformation as a rule-based framework for the specification and development of systems. languages. and tools. After reviewing the basic features of graph transformation. we discuss a selection of applications. including the evaluation of functional expressions. the specification of an interactive graphical tool. an example specification for abstract data types. and the definition of a visual database query language. The case studies indicate the need for suitable structuring principles which are independent of a particular graph transformation approach. To this end. we present the concept of a transformation unit. which allows systematic and structured specification and programming based on graph …,True,3AV1TsAAAAAJ:u-x6o8ySG0sC,278,https://www.sciencedirect.com/science/article/pii/S0167642398000239,11783141817981966835,/scholar?cites=11783141817981966835,,,https://www.sciencedirect.com/science/article/pii/S0167642398000239/pdf?md5=46f6a461f53ea30758ea7da6c44b4dee&pid=1-s2.0-S0167642398000239-main.pdf&_valck=1,0,0,0
1276291,Dynamic meta modeling: A graphical approach to the operational semantics of behavioral diagrams in UML,2000,Gregor Engels and Jan Hendrik Hausmann and Reiko Heckel and Stefan Sauer,,,,323-337,Springer. Berlin. Heidelberg,In this paper. dynamic meta modeling is proposed as a new approach to the operational semantics of behavioral UML diagrams. The dynamic meta model extends the well-known static meta model by a speci.cation of the system’s dynamics by means of collaboration diagrams. In this way. it is possible to de.ne the behavior of UML diagrams within UML.The conceptual idea is inherited from Plotkin’s structured operational semantics (SOS) paradigm. a style of semantics speci.cation for concurrent programming languages and process calculi: Collaboration diagrams are used as deduction rules to specify a goal-oriented interpreter for the language. The approach is exemplified using a fragment of UML statechart and object diagrams.Formally. collaboration diagrams are interpreted as graph transformation rules. In this way. dynamic UML semantics can be both mathematically rigorous so as to …,True,3AV1TsAAAAAJ:9yKSN-GCB0IC,248,https://link.springer.com/chapter/10.1007/3-540-40011-7_23,16967575648872014273,/scholar?cites=16967575648872014273,,,https://www.researchgate.net/profile/Reiko_Heckel/publication/220868291_Dynamic_Meta_Modeling_A_Graphical_Approach_to_the_Operational_Semantics_of_Behavioral_Diagrams_in_UML/links/02bfe50f693ec90b71000000.pdf,0,0,0
1276292,A methodology for specifying and analyzing consistency of object-oriented behavioral models,2001,Gregor Engels and Jochem M Küster and Reiko Heckel and Luuk Groenewegen,26,ACM SIGSOFT software engineering notes,5,186-195,ACM,Object-oriented modeling favors the modeling of object behavior from different viewpoints and the successive refinement of behavioral models in the development process. This gives rise to consistency problems of behavioral models. The absence of a formal semantics for UML models and the numerous possibilities of employing behavioral models within the development process lead to the rise of a number of different consistency notions. In this paper. we discuss the issue of consistency of behavioral models in the UML and present a general methodology how consistency problems can be dealt with. According to the methodology. those aspects of the models relevant to the consistency are mapped to a semantic domain in which precise consistency tests can be formulated. The choice of the semantic domain and the definition of consistency conditions can be used to construct different consistency notions. We …,True,3AV1TsAAAAAJ:2osOgNQ5qMEC,225,https://dl.acm.org/doi/abs/10.1145/503271.503235,2318611541232667985,/scholar?cites=2318611541232667985,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.7670&rep=rep1&type=pdf,0,0,0
1276293,Conceptual modelling of database applications using an extended ER model,1992,Gregor Engels and Martin Gogolla and Uwe Hohenstein and Klaus Hülsmann and Perdita Löhr-Richter and Gunter Saake and Hans-Dieter Ehrich,9,Data & Knowledge Engineering,2,157-204,North-Holland,In this paper. we motivate and present a data model for conceptual design of structural and behavioural aspects of databases. We follow an object centered design paradigm in the spirit of semantic data models. The specification of structural aspects is divided into modelling of object structures and modelling of data types used for describing object properties. The specification of object structures is based on an E xtended E ntity-R elationship (EER) model. The specification of behavioural aspects is divided into the modelling of admissible database state evolutions by means of temporal integrity constraints and the formulation of database (trans) actions. The central link for integrating these design components is a descriptive logic-based query language for the EER model. The logic part of this language is the basis for static constraints and descriptive action specifications by means of pre-and postconditions. A …,True,3AV1TsAAAAAJ:d1gkVwhDpl0C,195,https://www.sciencedirect.com/science/article/pii/0169023X9290008Y,10773788605355144926,/scholar?cites=10773788605355144926,,,,0,0,0
1276294,Detecting and resolving process model differences in the absence of a change log,2008,Jochen M Küster and Christian Gerth and Alexander Förster and Gregor Engels,,,,244-260,Springer. Berlin. Heidelberg,Business-driven development favors the construction of process models at different abstraction levels and by different people. As a consequence. there is a demand for consolidating different versions of process models by detecting and resolving differences. Existing approaches rely on the existence of a change log which logs the changes when changing a process model. However. in several scenarios such a change log does not exist and differences must be identified by comparing process models before and after changes have been made. In this paper. we present our approach to detecting and resolving differences between process models. in the absence of a change log. It is based on computing differences and deriving change operations for resolving differences. thereby providing a foundation for variant and version management in these cases.,True,3AV1TsAAAAAJ:Y0pCki6q_DkC,190,https://link.springer.com/chapter/10.1007/978-3-540-85758-7_19,2719703029975469570,/scholar?cites=2719703029975469570,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.678.1053&rep=rep1&type=pdf,0,0,0
1276295,Rule-based specification of behavioral consistency based on the UML meta-model,2001,Gregor Engels and Reiko Heckel and Jochen Malte Küster,,,,272-286,Springer. Berlin. Heidelberg,Object-oriented modeling favors the modeling of object behavior from different viewpoints and at different levels of abstraction. This gives rise to consistency problems between overlapping or semantically related submodels. The absence of a formal semantics for the UML and the numerous ways of employing the language within the development process lead to a number of different consistency notions. Therefore. general meta-level techniques are required for specifying. analyzing. and communicating consistency constraints. In this paper. we discuss the issue of consistency of behavioral models in the UML and present techniques for specifying and analyzing consistency. Using meta-model rules we transform elements of UML models into a semantic domain. Then. consistency constraints can by specified and validated using the language and the tools of the semantic domain. This general methodology …,True,3AV1TsAAAAAJ:qjMakFHDy7sC,165,https://link.springer.com/chapter/10.1007/3-540-45441-1_21,964567085106974288,/scholar?cites=964567085106974288,,,https://www.researchgate.net/profile/Reiko_Heckel/publication/220868224_Rule-Based_Specification_of_Behavioral_Consistency_Based_on_the_UML_Meta-model/links/02bfe50f693ecbdafd000000/Rule-Based-Specification-of-Behavioral-Consistency-Based-on-the-UML-Meta-model.pdf,0,0,0
1276296,ClassSheets: automatic generation of spreadsheet applications from object-oriented specifications,2005,Gregor Engels and Martin Erwig,,,,124-133,,Spreadsheets are widely used in all kinds of business applications. Numerous studies have shown that they contain many errors that sometimes have dramatic impacts. One reason for this situation is the low-level. cell-oriented development process of spreadsheets. We improve this process by introducing and formalizing a higher-level object-oriented model termed ClassSheet. While still following the tabular look-and feel of spreadsheets. ClassSheets allow the developer to express explicitly business object structures within a spreadsheet. which is achieved by integrating concepts from the UML (Unified Modeling Language). A stepwise automatic transformation process generates a spreadsheet application that is consistent with the ClassSheet model. Thus. by deploying the formal underpinning of ClassSheets. a large variety of errors can be prevented that occur in many existing spreadsheet applications today …,True,3AV1TsAAAAAJ:LkGwnXOMwfcC,136,https://dl.acm.org/doi/abs/10.1145/1101908.1101929,1176067244677315179,/scholar?cites=1176067244677315179,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.2193&rep=rep1&type=pdf,0,0,0
1276297,Building integrated software development environments. Part I: tool specification,1992,Gregor Engels and Claus Lewerentz and Manfred Nagl and Wilhelm Schäfer and Andy Schürr,1,ACM Transactions on Software Engineering and Methodology (TOSEM),2,135-167,ACM,The conceptual modeling approach of the IPSEN (Integrated Project Support Environment) project for building highly integrated environments is based on using attributed graphs to model and implement arbitrary object structures. in particular all kinds of software documents and their relationships. A language based on graph grammars. called PROGRESS (PROgrammed Graph REwriting SyStems). and a suitable method for the application of this language. called graph grammar engineering. have been developed over the last ten years.  This language and method are being extensively used for specifying the complex graph structures of internal document representations as well as for specifying the functionality of all tools (editors. browsers. analyzers. debuggers) working on these internal  rpresentations. This paper explains the language and the method for applying the language based on a pragmatic nontrivial …,True,3AV1TsAAAAAJ:UeHWp8X0CEIC,132,https://dl.acm.org/doi/abs/10.1145/128894.128895,17767960434221526082,/scholar?cites=17767960434221526082,,,,0,0,0
1276298,Systematic literature reviews in software engineering–a systematic literature review,2009,Barbara Kitchenham and O Pearl Brereton and David Budgen and Mark Turner and John Bailey and Stephen Linkman,51,,1,7-15,Elsevier,In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference.This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence.We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings.Of 20 relevant studies. eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4.Currently. the topic areas covered by SLRs are limited. European researchers. particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence …,True,CTtHu1UAAAAJ:Zph67rFs4hoC,2675,https://www.sciencedirect.com/science/article/pii/S0950584908001390,14563517766994888844,/scholar?cites=14563517766994888844,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.9182&rep=rep1&type=pdf,0,0,0
1276299,Lessons from applying the systematic literature review process within the software engineering domain,2007,Pearl Brereton and Barbara A Kitchenham and David Budgen and Mark Turner and Mohamed Khalil,80,,4,571-583,Elsevier,A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach. the practice of systematic literature review. to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised. a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted.The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights …,True,CTtHu1UAAAAJ:kNdYIx-mwKoC,1940,https://www.sciencedirect.com/science/article/pii/S016412120600197X,3247557312333793226,/scholar?cites=3247557312333793226,,,https://www.sciencedirect.com/science/article/pii/S016412120600197X,0,0,0
1276300,Does the technology acceptance model predict actual use? A systematic literature review,2010,Mark Turner and Barbara Kitchenham and Pearl Brereton and Stuart Charters and David Budgen,52,,5,463-479,Elsevier,The technology acceptance model (TAM) was proposed in 1989 as a means of predicting technology usage. However. it is usually validated by using a measure of behavioural intention to use (BI) rather than actual usage.This review examines the evidence that the TAM predicts actual usage using both subjective and objective measures of actual usage.We performed a systematic literature review based on a search of six digital libraries. along with vote-counting meta-analysis to analyse the overall results.The search identified 79 relevant empirical studies in 73 articles. The results show that BI is likely to be correlated with actual usage. However. the TAM variables perceived ease of use (PEU) and perceived usefulness (PU) are less likely to be correlated with actual usage.Care should be taken using the TAM outside the context in which it has been validated.,True,CTtHu1UAAAAJ:4TOpqqG69KYC,817,https://www.sciencedirect.com/science/article/pii/S0950584909002055,5564301797652352464,/scholar?cites=5564301797652352464,,,https://www.academia.edu/download/50268701/Does_the_technology_acceptance_model_pre20161112-26606-16jrjzj.pdf,0,0,0
1276301,Turning software into a service,2003,Mark Turner and David Budgen and Pearl Brereton,36,Computer,10,38-44,IEEE,The software as a service model composes services dynamically. as needed. by binding several lower-level services-thus overcoming many limitations that constrain traditional software use. deployment. and evolution.,True,CTtHu1UAAAAJ:8k81kl-MbHgC,806,https://ieeexplore.ieee.org/abstract/document/1236470/,9340963101078923796,/scholar?cites=9340963101078923796,,,https://dro.dur.ac.uk/624/1/624.pdf,0,0,0
1276302,Systematic literature reviews in software engineering–a tertiary study,2010,Barbara Kitchenham and Rialette Pretorius and David Budgen and O Pearl Brereton and Mark Turner and Mahmood Niazi and Stephen Linkman,52,,8,792-805,Elsevier,In a previous study. we reported on a systematic literature review (SLR). based on a manual search of 13 journals and conferences undertaken in the period 1st January 2004 to 30th June 2007.The aim of this on-going research is to provide an annotated catalogue of SLRs available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search.We performed a broad automated search to find SLRs published in the time period 1st January 2004 to 30th June 2008. We contrast the number. quality and source of these SLRs with SLRs found in the original study.Our broad search found an additional 35 SLRs corresponding to 33 unique studies. Of these papers. 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of SLRs being published is …,True,CTtHu1UAAAAJ:4DMP91E08xMC,780,https://www.sciencedirect.com/science/article/pii/S0950584910000467,8543740193074692352,/scholar?cites=8543740193074692352,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1048.8963&rep=rep1&type=pdf,0,0,0
1276303,Using mapping studies as the basis for further research–a participant-observer case study,2011,Barbara A Kitchenham and David Budgen and O Pearl Brereton,53,,6,638-651,Elsevier,We are strong advocates of evidence-based software engineering (EBSE) in general and systematic literature reviews (SLRs) in particular. We believe it is essential that the SLR methodology is used constructively to support software engineering research.This study aims to assess the value of mapping studies which are a form of SLR that aims to identify and categorise the available research on a broad software engineering topic.We used a multi-case. participant-observer case study using five examples of studies that were based on preceding mapping studies. We also validated our results by contacting two other researchers who had undertaken studies based on preceding mapping studies and by assessing review comments related to our follow-on studies.Our original case study identified 11 unique benefits that can accrue from basing research on a preceding mapping study of …,True,CTtHu1UAAAAJ:g5m5HwL7SMYC,554,https://www.sciencedirect.com/science/article/pii/S0950584910002272,785208108783246535,/scholar?cites=785208108783246535,,,https://eprints.keele.ac.uk/2685/3/kitchenham-2011-IST.pdf,0,0,0
1276304,Software design,2003,David Budgen,,,,,Pearson Education,Software Design provides a balanced view of the many and varied software design methodologies most widely used by practitioners. By being aware of the strengths and limitations of each method. a student is better able to judge which to adopt when working in the field. The book is also valuable for software engineers and project managers who need an objective guide to the state of the art in this area. The text provides a general overview of software design within the context of software development and also of more general thinking about design issues. It examines the nature of design activities. as well as their applications within software development.,True,CTtHu1UAAAAJ:t6usbXjVLHcC,419,http://books.google.com/books?hl=en&lr=&id=bnY3vb606bAC&oi=fnd&pg=PR9&dq=info:zv93L2XjR9MJ:scholar.google.com&ots=QFus6o82rh&sig=Ttvjtm3E-HWaDj5GCwiRaEOuE1w,15224387089076846542,/scholar?cites=15224387089076846542,,,http://dim.uchile.cl/~juaperez/beto/otro.bueno.pdf,0,0,0
1276305,Using Mapping Studies in Software Engineering.,2008,David Budgen and Mark Turner and Pearl Brereton and Barbara A Kitchenham,8,Ppig,,195-204,,Background: A mapping study provides a systematic and objective procedure for identifying the nature and extent of the empirical study data that is available to answer a particular research question. Such studies can also form a useful preliminary step for PhD study.Aim: We set out to assess how effective such studies have been when used for software engineering topics. and to identify the specific challenges that they present.Method: We have conducted an informal review of a number of mapping studies in software engineering. describing their main characteristics and the forms of analysis employed. Results: We examine the experiences and outcomes from six mapping studies. of which four are published. From these we note a recurring theme about the problems of classification and a preponderance of ‘gaps’ in the set of empirical studies.Conclusions: We identify our challenges as improving classification guidelines. encouraging better reporting of primary studies. and argue for identifying some’empirical grand challenges’ for software engineering as a focus for the community1.,True,CTtHu1UAAAAJ:aqlVkmm33-oC,377,http://ramus.se.uni-hannover.de/glosebase/images/b/b3/Using_Mapping_Studies_in_Software_Engineering-anno.pdf,952955619788685144,/scholar?cites=952955619788685144,,,http://ramus.se.uni-hannover.de/glosebase/images/b/b3/Using_Mapping_Studies_in_Software_Engineering-anno.pdf,0,0,0
1276306,Evidence-based software engineering and systematic reviews,2015,Barbara Ann Kitchenham and David Budgen and Pearl Brereton,4,,,,CRC press,In the decade since the idea of adapting the evidence-based paradigm for software engineering was first proposed. it has become a major tool of empirical software engineering. Evidence-Based Software Engineering and Systematic Reviews provides a clear introduction to the use of an evidence-based model for software engineering research and practice.,True,CTtHu1UAAAAJ:BUYA1_V_uYcC,354,http://books.google.com/books?hl=en&lr=&id=bGfdCgAAQBAJ&oi=fnd&pg=PP1&dq=info:9KhybjJivGQJ:scholar.google.com&ots=VMF1SaLIUy&sig=GAV2k_cp9uhcMfs41E5b0ROAmkE,7258784668155291892,/scholar?cites=7258784668155291892,,,,0,0,0
1276307,Service-based software: the future for flexible software,2000,Keith Bennett and Paul Layzell and David Budgen and Pearl Brereton and Linda Macaulay and Malcolm Munro,,,,214-221,IEEE,For the past 40 years. the techniques. processes and methods of software development have been dominated by supply-side issues. giving rise to a software industry oriented towards developers rather than users. To achieve the levels of functionality. flexibility and time-to-market required by users. a radical shift is required in the development of software. with a more demand-centric view. leading to software which will be delivered as a service within the framework of an open marketplace. Already. there are some signs that this approach is being adopted by industry. but in a very limited way. We summarise research and a research method which has resulted in a long-term strategic view of software engineering innovation. Based on this foundation. we describe more recent work. which has resulted in an innovative demand-side model for the future of software. We propose a service architecture in which …,True,CTtHu1UAAAAJ:3fE2CSJIrl8C,319,https://ieeexplore.ieee.org/abstract/document/896702/,8321169541364721820,/scholar?cites=8321169541364721820,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.23.3674&rep=rep1&type=pdf,0,0,0
1276308,Component-based systems: A classification of issues,2000,Pearl Brereton and David Budgen,33,Computer,11,54-62,IEEE,Developing and using various component forms as building blocks can significantly enhance software-based system development and use. which is why both the academic and commercial sectors have shown interest in component-based software development. Indeed. much effort has been devoted to defining and describing the terms and concepts involved. Briefly. we describe software components as units of independent production. acquisition. and deployment that interact to form a functional system. We identify a set of issues organized within an overall framework that software developers must address for component-based systems (CBS) to achieve their full potential.,True,CTtHu1UAAAAJ:KlAtU1dfN6UC,213,https://ieeexplore.ieee.org/abstract/document/881695/,983005697126699951,/scholar?cites=983005697126699951,,,,0,0,0
1276309,A classification of SQL-injection attacks and countermeasures,2006,William G Halfond and Jeremy Viegas and Alessandro Orso,1,Proceedings of the IEEE international symposium on secure software engineering,,13-15,IEEE,SQL injection attacks pose a serious security threat to Web applications: they allow attackers to obtain unrestricted access to the databases underlying the applications and to the potentially sensitive information these databases contain. Although researchers and practitioners have proposed various methods to address the SQL injection problem. current approaches either fail to address the full scope of the problem or have limitations that prevent their use and adoption. Many researchers and practitioners are familiar with only a subset of the wide range of techniques available to attackers who are trying to take advantage of SQL injection vulnerabilities. As a consequence. many solutions proposed in the literature address only some of the issues related to SQL injection. To address this problem. we present an extensive review of the different types of SQL injection attacks known to date. For each type of attack. we provide descriptions and examples of how attacks of that type could be performed. We also present and analyze existing detection and prevention techniques against SQL injection attacks. For each technique. we discuss its strengths and weaknesses in addressing the entire range of SQL injection attacks.,True,wCfYkMkAAAAJ:qjMakFHDy7sC,807,http://www.cc.gatech.edu/fac/Alex.Orso/papers/halfond.viegas.orso.ISSSE06.pdf,2968924591244262450,/scholar?cites=2968924591244262450,,,http://www.cc.gatech.edu/fac/Alex.Orso/papers/halfond.viegas.orso.ISSSE06.pdf,0,0,0
1276310,AMNESIA: analysis and monitoring for neutralizing SQL-injection attacks,2005,William GJ Halfond and Alessandro Orso,,,,174-183,,The use of web applications has become increasingly popular in our routine activities. such as reading the news. paying bills. and shopping on-line. As the availability of these services grows. we are witnessing an increase in the number and sophistication of attacks that target them. In particular. SQL injection. a class of code-injection attacks in which specially crafted input strings result in illegal queries to a database. has become one of the most serious threats to web applications. In this paper we present and evaluate a new technique for detecting and preventing SQL injection attacks. Our technique uses a model-based approach to detect illegal queries before they are executed on the database. In its static part. the technique uses program analysis to automatically build a model of the legitimate queries that could be generated by the application. In its dynamic part. the technique uses runtime monitoring to …,True,wCfYkMkAAAAJ:u5HHmVD_uO8C,759,https://dl.acm.org/doi/abs/10.1145/1101908.1101935,12210141221485037810,/scholar?cites=12210141221485037810,,,http://www.cc.gatech.edu/fac/Alex.Orso/papers/halfond.orso.ASE05.pdf,0,0,0
1276311,Dytan: a generic dynamic taint analysis framework,2007,James Clause and Wanchun Li and Alessandro Orso,,,,196-206,,Dynamic taint analysis is gaining momentum. Techniques based on dynamic tainting have been successfully used in the context of application security. and now their use is also being explored in different areas. such as program understanding. software testing. and debugging. Unfortunately. most existing approaches for dynamic tainting are defined in an ad-hoc manner. which makes it difficult to extend them. experiment with them. and adapt them to new contexts. Moreover. most existing approaches are focused on data-flow based tainting only and do not consider tainting due to control flow. which limits their applicability outside the security domain. To address these limitations and foster experimentation with dynamic tainting techniques. we defined and developed a general framework for dynamic tainting that (1) is highly flexible and customizable.(2) allows for performing both data-flow and control-flow based …,True,wCfYkMkAAAAJ:9yKSN-GCB0IC,632,https://dl.acm.org/doi/abs/10.1145/1273463.1273490,15762588155593323901,/scholar?cites=15762588155593323901,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.1353&rep=rep1&type=pdf,0,0,0
1276312,Are automated debugging techniques actually helping programmers?,2011,Chris Parnin and Alessandro Orso,,,,199-209,,Debugging is notoriously difficult and extremely time consuming. Researchers have therefore invested a considerable amount of effort in developing automated techniques and tools for supporting various debugging tasks. Although potentially useful. most of these techniques have yet to demonstrate their practical effectiveness. One common limitation of existing approaches. for instance. is their reliance on a set of strong assumptions on how developers behave when debugging (eg. the fact that examining a faulty statement in isolation is enough for a developer to understand and fix the corresponding bug). In more general terms. most existing techniques just focus on selecting subsets of potentially faulty statements and ranking them according to some criterion. By doing so. they ignore the fact that understanding the root cause of a failure typically involves complex activities. such as navigating program …,True,wCfYkMkAAAAJ:NMxIlDl6LWMC,497,https://dl.acm.org/doi/abs/10.1145/2001420.2001445,17278179178396840794,/scholar?cites=17278179178396840794,,,http://www.cc.gatech.edu/~orso/papers/parnin.orso.ISSTA11.pdf,0,0,0
1276313,Regression test selection for Java software,2001,Mary Jean Harrold and James A Jones and Tongyu Li and Donglin Liang and Alessandro Orso and Maikel Pennings and Saurabh Sinha and S Alexander Spoon and Ashish Gujarathi,36,ACM Sigplan Notices,11,312-326,ACM,Regression testing is applied to modified software to provide confidence that the changed parts behave as intended and that the unchanged parts have not been adversely affected by the modifications. To reduce the cost of regression testing. test cases are selected from the test suite that was used to test the original version of the software---this process is called regression test selection. A safe regression-test-selection algorithm selects every test case in the test suite that may reveal a fault in the modified software. Safe regression-test-selection technique that. based on the use of a suitable representation. handles the features of the Java language. Unlike other safe regression test selection techniques. the presented technique also handles incomplete programs. The technique can thus be safely applied in the (very common) case of Java software that uses external libraries of components; the analysis of the …,True,wCfYkMkAAAAJ:u-x6o8ySG0sC,414,https://dl.acm.org/doi/abs/10.1145/504311.504305,6625237717433538285,/scholar?cites=6625237717433538285,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.481.3688&rep=rep1&type=pdf,0,0,0
1276314,Automated test input generation for android: Are we there yet?(e),2015,Shauvik Roy Choudhary and Alessandra Gorla and Alessandro Orso,,,,429-440,IEEE,"Like all software. mobile applications (""apps"") must be adequately tested to gain confidence that they behave correctly. Therefore. in recent years. researchers and practitioners alike have begun to investigate ways to automate apps testing. In particular. because of Android's open source nature and its large share of the market. a great deal of research has been performed on input generation techniques for apps that run on the Android operating systems. At this point in time. there are in fact a number of such techniques in the literature. which differ in the way they generate inputs. the strategy they use to explore the behavior of the app under test. and the specific heuristics they use. To better understand the strengths and weaknesses of these existing approaches. and get general insight on ways they could be made more effective. in this paper we perform a thorough comparison of the main existing test input …",True,wCfYkMkAAAAJ:t6usbXjVLHcC,405,https://ieeexplore.ieee.org/abstract/document/7372031/,6245939765991510688,/scholar?cites=6245939765991510688,,,https://arxiv.org/pdf/1503.07217,0,0,0
1276315,Statistical debugging: A hypothesis testing-based approach,2006,Chao Liu and Long Fei and Xifeng Yan and Jiawei Han and Samuel P Midkiff,32,IEEE Transactions on software engineering,10,831-848,IEEE,Manual debugging is tedious. as well as costly. The high cost has motivated the development of fault localization techniques. which help developers search for fault locations. In this paper. we propose a new statistical method. called SOBER. which automatically localizes software faults without any prior knowledge of the program semantics. Unlike existing statistical approaches that select predicates correlated with program failures. SOBER models the predicate evaluation in both correct and incorrect executions and regards a predicate as fault-relevant if its evaluation pattern in incorrect executions significantly diverges from that in correct ones. Featuring a rationale similar to that of hypothesis testing. SOBER quantifies the fault relevance of each predicate in a principled way. We systematically evaluate SOBER under the same setting as previous studies. The result clearly demonstrates the effectiveness: SOBER …,True,wCfYkMkAAAAJ:W5xh706n7nkC,369,https://ieeexplore.ieee.org/abstract/document/1717474/,13351091290986453671,/scholar?cites=13351091290986453671,,,,0,0,0
1276316,Leveraging field data for impact analysis and regression testing,2003,Alessandro Orso and Taweesup Apiwattanapong and Mary Jean Harrold,28,ACM SIGSOFT Software Engineering Notes,5,128-137,ACM,Software products are often released with missing functionality. errors. or incompatibilities that may result in failures. inferior performances. or user dissatisfaction. In previous work. we presented the Gamma approach. which facilitates remote analysis and measurement of deployed software and permits gathering of program-execution data from the field. In this paper. we investigate the use of the Gamma approach to support and improve two fundamental tasks performed by software engineers during maintenance: impact analysis and regression testing. We present a new approach that leverages field data to perform these two tasks. The approach is efficient in that the kind of field data that we consider require limited space and little instrumentation. We also present a set of empirical studies that we performed. on a real subject and on a real user population. to evaluate the approach. The results of the studies show …,True,wCfYkMkAAAAJ:2osOgNQ5qMEC,324,https://dl.acm.org/doi/abs/10.1145/949952.940089,9635238797910708273,/scholar?cites=9635238797910708273,,,http://www.cc.gatech.edu/people/home/orso/papers/orso.term.harrold.FSE03.pdf,0,0,0
1276317,Scaling regression testing to large software systems,2004,Alessandro Orso and Nanjuan Shi and Mary Jean Harrold,29,ACM SIGSOFT Software Engineering Notes,6,241-251,ACM,When software is modified. during development and maintenance. it is regression tested to provide confidence that the changes did not introduce unexpected errors and that new features behave as expected. One important problem in regression testing is how to select a subset of test cases. from the test suite used for the original version of the software. when testing a modified version of the software. Regression-test-selection techniques address this problem. Safe regression-test-selection techniques select every test case in the test suite that may behave differently in the original and modified versions of the software. Among existing safe regression testing techniques. efficient techniques are often too imprecise and achieve little savings in testing effort. whereas precise techniques are too expensive when used on large systems. This paper presents a new regression-test-selection technique for Java programs that …,True,wCfYkMkAAAAJ:Tyk-4Ss8FVUC,294,https://dl.acm.org/doi/abs/10.1145/1041685.1029928,16470989051720650538,/scholar?cites=16470989051720650538,,,https://www.cc.gatech.edu/~orso/papers/orso.shi.harrold.FSE04.pdf,0,0,0
1276318,Using positive tainting and syntax-aware evaluation to counter SQL injection attacks,2006,William GJ Halfond and Alessandro Orso and Panagiotis Manolios,,,,175-185,,SQL injection attacks pose a serious threat to the security of Web applications because they can give attackers unrestricted access to databases that contain sensitive information. In this paper. we propose a new. highly automated approach for protecting existing Web applications against SQL injection. Our approach has both conceptual and practical advantages over most existing techniques. From the conceptual standpoint. the approach is based on the novel idea of positive tainting and the concept of syntax-aware evaluation. From the practical standpoint. our technique is at the same time precise and efficient and has minimal deployment requirements. The paper also describes wasp. a tool that implements our technique. and a set of studies performed to evaluate our approach. In the studies. we used our tool to protect several Web applications and then subjected them to a large and varied set of attacks and …,True,wCfYkMkAAAAJ:Y0pCki6q_DkC,274,https://dl.acm.org/doi/abs/10.1145/1181775.1181797,4577994916185781606,/scholar?cites=4577994916185781606,,,https://www.cc.gatech.edu/~orso/papers/halfond.orso.manolios.FSE06.pdf,0,0,0
1276319,WASP: Protecting web applications using positive tainting and syntax-aware evaluation,2008,William Halfond and Alex Orso and Pete Manolios,34,IEEE transactions on Software Engineering,1,65-81,IEEE,Many software systems have evolved to include a Web-based component that makes them available to the public via the Internet and can expose them to a variety of Web-based attacks. One of these attacks is SQL injection. which can give attackers unrestricted access to the databases that underlie Web applications and has become increasingly frequent and serious. This paper presents a new highly automated approach for protecting Web applications against SQL injection that has both conceptual and practical advantages over most existing techniques. From a conceptual standpoint. the approach is based on the novel idea of positive tainting and on the concept of syntax-aware evaluation. From a practical standpoint. our technique is precise and efficient. has minimal deployment requirements. and incurs a negligible performance overhead in most cases. We have implemented our techniques in the Web …,True,wCfYkMkAAAAJ:l7t_Zn2s7bgC,250,https://ieeexplore.ieee.org/abstract/document/4359474/,7972467532082934259,/scholar?cites=7972467532082934259,,,,0,0,0
1276320,Hints on test data selection: Help for the practicing programmer,1978,Richard A DeMillo and Richard J Lipton and Frederick G Sayward,11,Computer,4,34-41,IEEE,In many cases tests of a program that uncover simple errors are also effective in uncovering much more complex errors. This so-called coupling effect can be used to save work during the testing process.,True,Pil9rEEAAAAJ:u5HHmVD_uO8C,2495,https://ieeexplore.ieee.org/abstract/document/1646911/,3164353600655378701,/scholar?cites=3164353600655378701,,,https://www.academia.edu/download/50164286/Hints_on_Test_Data.pdf,0,0,0
1276321,On the importance of checking cryptographic protocols for faults,1997,Dan Boneh and Richard A DeMillo and Richard J Lipton,,,,37-51,Springer. Berlin. Heidelberg,We present a theoretical model for breaking various cryptographic schemes by taking advantage of random hardware faults. We show how to attack certain implementations of RSA and Rabin signatures. We also show how various authentication protocols. such as Fiat-Shamir and Schnorr. can be broken using hardware faults.,True,Pil9rEEAAAAJ:u-x6o8ySG0sC,2130,https://link.springer.com/chapter/10.1007/3-540-69053-0_4,16670724884084567192,/scholar?cites=16670724884084567192,,,https://link.springer.com/content/pdf/10.1007/3-540-69053-0_4.pdf,0,0,0
1276322,Constraint-based automatic test data generation,1991,Richard A DeMillo and A Jefferson Offutt,17,IEEE Transactions on Software Engineering,9,900-910,,This paper presents a new technique for automatically generating test data. The technique is based on mutation analysis and creates test data that approximates relative-adequacy. The technique is a fault-based technique that uses algebraic constraints to describe test cases designed to find particular types of faults. A set of tools. collectively called Godzilla. has been implemented that automatically generates constraints and solves them to create test cases for unit and module testing. Godzilla has been integrated with the Mothra testing system and has been used as an effective way to generate test data that kills program mutants.,True,Pil9rEEAAAAJ:tS2w5q8j5-wC,1140,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.1702&rep=rep1&type=pdf,16251681100150663222,/scholar?cites=16251681100150663222,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.1702&rep=rep1&type=pdf,0,0,0
1276323,Social processes and proofs of theorems and programs,1993,Richard A DeMillo and Richard J Lipton and Alan J Perlis,,,,297-319,Kluwer Academic Publishers,Many people have argued that computer programming should strive to become more like mathematics. Maybe so. but not in the way they seem to think. The aim of program verification. an attempt to make programming more mathematics-like. is to increase dramatically one’s confidence in the correct functioning of a piece of software. and the device that verifiers use to achieve this goal is a long chain of formal. deductive logic. In mathematics. the aim is to increase one’s confidence in the correctness of a theorem. and it’s true that one of the devices mathematicians could in theory use to achieve this goal is a long chain of formal logic. But in fact they don’t. What they use is a proof. a very different animal. Nor does the proof settle the matter; contrary to what its name suggests. a proof is only one step in the direction of confidence. We believe that. in the end. it is a social process that determines whether …,True,Pil9rEEAAAAJ:ZfRJV9d4-WMC,820,https://link.springer.com/chapter/10.1007/978-94-011-1793-7_14,8133970149534323281,/scholar?cites=8133970149534323281,,,,0,0,0
1276324,Social Processes and Proofs of Theorems and Programs,1977,RA DeMillo and RJ Lipton and AJ Perlis,,,,245-262,Association for Computing Machinery,It is argued that formal verifications of programs. no matter how obtained. will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity. the inevitability of change. and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.,True,Pil9rEEAAAAJ:yB1At4FlUx8C,820,https://dl.acm.org/doi/abs/10.1145/359104.359106,8133970149534323281,/scholar?cites=8133970149534323281,,,https://www.ics.uci.edu/~pattis/misc/socialproofs.pdf,0,0,0
1276325,Social processes and proofs of theorems and programs,1979,Richard A De Millo and Richard J Lipton and Alan J Perlis,22,Communications of the ACM,5,271-280,ACM,It is argued that formal verifications of programs. no matter how obtained. will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity. the inevitability of change. and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.,True,Pil9rEEAAAAJ:uJ-U7cs_P_0C,814,https://dl.acm.org/doi/abs/10.1145/359104.359106,8133970149534323281,/scholar?cites=8133970149534323281,,,https://www.ics.uci.edu/~pattis/misc/socialproofs.pdf,0,0,0
1276326,Social processes and proofs of theorems and programs,1979,Richard A De Millo and Richard J Lipton and Alan J Perlis,22,Communications of the ACM,5,271-280,ACM,It is argued that formal verifications of programs. no matter how obtained. will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity. the inevitability of change. and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.,True,Pil9rEEAAAAJ:K3LRdlH-MEoC,814,https://dl.acm.org/doi/abs/10.1145/359104.359106,8133970149534323281,/scholar?cites=8133970149534323281,,,https://www.ics.uci.edu/~pattis/misc/socialproofs.pdf,0,0,0
1276327,On the importance of checking computations,1997,Dan Boneh and Richard A Demillo and Richard J Lipton,,,,,Springer-Verlag,We present a theoretical model for breaking various cryptographic schemes by taking advantage of random hardware faults. We show how to attack certain implementations of RSA and Rabin signatures. We also show how various authentication protocols. such as Fiat-Shamir and Schnorr. can be broken using hardware faults. 1 Introduction Direct attacks on the famous RSA cryptosystem seem to require that one factor the modulus. Therefore. it is interesting to ask whether there are attacks that avoid this. The answer is yes: the first was the recent attack based on timing [2]. It was observed that a few bits could be obtained from the time that operations took. This would allow one to break the system without factoring. We have a new type of attack that also avoids directly factoring the modulus. We essentially use the fact that from time to time the hardware performing the computations may introduce errors. There are several models that may enable a malicious adversary to collect and poss...,True,Pil9rEEAAAAJ:4DMP91E08xMC,607,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7211,4882650107678787667,/scholar?cites=4882650107678787667,,,,0,0,0
1276328,A Probabilistic Remark on Algebraic Program Testing.,1977,Richard A DeMillo and Richard J Lipton,,,,,GEORGIA INST OF TECH ATLANTA SCHOOL OF INFORMATION AND COMPUTER SCIENCE,A key step in Howdens method for algebraic program testing requires checking the algebraic identity of multinomials. Howdens solution requires evaluations in at least 2 to the mth power points for m-ary multinomials. This note presents a probabilistic solution which achieves small probability of error on 30 points.Descriptors:,True,Pil9rEEAAAAJ:IjCSPb-OGe4C,448,https://apps.dtic.mil/sti/citations/ADA050745,7846620573938221380,/scholar?cites=7846620573938221380,,,https://apps.dtic.mil/sti/pdfs/ADA050745.pdf,0,0,0
1276329,Debugging with dynamic slicing and backtracking,1993,Hiralal Agrawal and Richard A DeMillo and Eugene H Spafford,23,Software: Practice and Experience,6,589-616,John Wiley & Sons. Ltd.,Programmers spend considerable time debugging code. Symbolic debuggers provide some help but the task remains complex and difficult. Other than breakpoints and tracing. these tools provide little high‐level help. Programmers must perform many tasks manually that the tools could perform automatically. such as finding which statements in the program affect the value of an output variable for a given test case. and what was the value of a given variable when the control last reached a given program location. If debugging tools provided explicit support for these tasks. the debugging process could be automated to a significant extent.In this paper we present a debugging model. based on dynamic program slicing and execution backtracking techniques. that easily lends itself to automation. This model is based on experience with using these techniques to debug software. We also present a prototype debugging …,True,Pil9rEEAAAAJ:9yKSN-GCB0IC,433,https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380230603,8828109511545337900,/scholar?cites=8828109511545337900,,,https://www.academia.edu/download/50164307/Debugging_with_Dynamic_Slicing.pdf,0,0,0
1276330,An extended overview of the Mothra software testing environment,1988,Richard A DeMillo and Dany S Guindi and WM McCracken and A Jefferson Offutt and Kim N King,,,,"142,143,144,145,146,147,148,149,150,151-142,143,144,145,146,147,148,149,150,151",IEEE Computer Society,The authors give a brief introduction to mutation analysis. They they discuss Mothra. emphasizing how it interacts with the tester. The authors present some major problems with using mutation analysis and discuss possible solutions. They conclude with a solution to one of these problems-a method of automatically generating mutation-adequate data.<>,True,Pil9rEEAAAAJ:qjMakFHDy7sC,375,https://www.computer.org/csdl/proceedings-article/wst/1988/00005369/12OmNxX3uAC,9660438348854215635,/scholar?cites=9660438348854215635,,,,0,0,0
1276331,Quantifying aspects in middleware platforms,2003,Charles Zhang and Hans-Arno Jacobsen,,,,130-139,,Middleware technologies such as Web Services. CORBA and DCOM have been very successful in solving distributed computing problems for a large family of application domains. As middleware systems are getting widely adopted and more functionally mature. it is also increasingly difficult for the architecture of middleware to achieve a high level of adaptability and configurability. due to the limitations of traditional software decomposition methods. Aspect oriented programming has brought us new design perspectives because it permits the superimpositions of multiple abstraction models on top of one another. It is a very powerful technique in separating and simplifying design concerns. In this paper. we first show that. through the quantification of aspects in the legacy implementations. the modularity of middleware architecture is greatly hindered by the ubiquitous existence of tangled logic. We then go one step …,True,Zmppp9kAAAAJ:u-x6o8ySG0sC,164,https://dl.acm.org/doi/abs/10.1145/643603.643617,1829236140987327406,/scholar?cites=1829236140987327406,,,http://msrg.org/publications/pdf_files/2003/ZhJ03c-Quantifying_Aspects_in_Middleware_Plat.pdf,0,0,0
1276332,LEAP: Lightweight deterministic multi-processor replay of concurrent Java programs,2010,Jeff Huang and Peng Liu and Charles Zhang,,,,207-216,,The technique of deterministic record and replay aims at faithfully reenacting an earlier program execution. For concurrent programs. it is one of the most important techniques for program understanding and debugging. The state of the art deterministic replay techniques face challenging efficiency problems in supporting multi-processor executions due to the unoptimized treatment of shared memory accesses. We propose LEAP: a deterministic record and replay technique that uses a new type of local order wrt the shared memory locations and concurrent threads. Compared to the related work. our technique records much less information without losing the replay determinism. The correctness of our technique is underpinned by formal models and a replay theorem that we have developed in this work. Through our evaluation using both benchmarks and real world applications. we show that LEAP is more than 10x …,True,Zmppp9kAAAAJ:W7OEmFMy1HYC,130,https://dl.acm.org/doi/abs/10.1145/1882291.1882323,14565042724861120687,/scholar?cites=14565042724861120687,,,http://www.cs.ust.hk/~charlesz/academic/leap.pdf,0,0,0
1276333,Qsynth: A tool for qos-aware automatic service composition,2010,Wei Jiang and Charles Zhang and Zhenqiu Huang and Mingwen Chen and Songlin Hu and Zhiyong Liu,,,,42-49,IEEE,With the proliferation of Web services. service engineers demand good automatic service composition algorithms that not only synthesize the correct work plans from thousands of services but also satisfy the quality requirements of the users. Our observation is that conventional approaches suffer from serious limitations in scalability and accuracy when addressing both requirements simultaneously. We have designed and implemented a tool QSynth to use QoS objectives of service requests as the search directives. This approach effectively prunes the search space and significantly improves the accuracy of the search results. Evaluations show that. compared to the state of the art. QSynth achieves superior scalability and accuracy with respect to a large variety of composition scenarios. Our design of QSynth won the performance championship of Web Services Challenge 2009.,True,Zmppp9kAAAAJ:eQOLeE2rZwMC,130,https://ieeexplore.ieee.org/abstract/document/5552803/,16464785920318843475,/scholar?cites=16464785920318843475,,,https://www.researchgate.net/profile/Songlin_Hu2/publication/220268220_QSynth_A_Tool_for_QoS-aware_Automatic_Service_Composition/links/54f714470cf210398e914c0c/QSynth-A-Tool-for-QoS-aware-Automatic-Service-Composition.pdf,0,0,0
1276334,Resolving feature convolution in middleware systems,2004,Charles Zhang and Hans-Arno Jacobsen,,,,188-205,,Middleware provides simplicity and uniformity for the development of distributed applications. However. the modularity of the architecture of middleware is starting to disintegrate and to become complicated due to the interaction of too many orthogonal concerns imposed from a wide range of application requirements. This is not due to bad design but rather due to the limitations of the conventional architectural decomposition methodologies. We introduce the principles of horizontal decomposition (HD) which addresses this problem with a mixed-paradigm middleware architecture. HD provides guidance for the use of conventional decomposition methods to implement the core functionalities of middleware and the use of aspect orientation to address its orthogonal properties. Our evaluation of the horizontal decomposition principles focuses on refactoring major middleware functionalities into aspects in order to …,True,Zmppp9kAAAAJ:d1gkVwhDpl0C,129,https://dl.acm.org/doi/abs/10.1145/1028976.1028992,12538355531920452570,/scholar?cites=12538355531920452570,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.360.9383&rep=rep1&type=pdf,0,0,0
1276335,Clap: Recording local executions to reproduce concurrency failures,2013,Jeff Huang and Charles Zhang and Julian Dolby,48,Acm Sigplan Notices,6,141-152,ACM,We present CLAP. a new technique to reproduce concurrency bugs. CLAP has two key steps. First. it logs thread local execution paths at runtime. Second. offline. it computes memory dependencies that accord with the logged execution and are able to reproduce the observed bug. The second step works by combining constraints from the thread paths and constraints based on a memory model. and computing an execution with a constraint solver.CLAP has four major advantages. First. logging purely local execution of each thread is substantially cheaper than logging memory interactions. which enables CLAP to be efficient compared to previous approaches. Second. our logging does not require any synchronization and hence with no added memory barriers or fences; this minimizes perturbation and missed bugs due to extra synchronizations foreclosing certain racy behaviors. Third. since it uses no …,True,Zmppp9kAAAAJ:0EnyYjriUFMC,124,https://dl.acm.org/doi/abs/10.1145/2499370.2462167,2138665147356040147,/scholar?cites=2138665147356040147,,,https://people.engr.ncsu.edu/gjin2/Classes/591/Spring2018/concurrency-clap.pdf,0,0,0
1276336,Refactoring middleware with aspects,2003,Charles Zhang and H-A Jacobsen,14,IEEE Transactions on Parallel and Distributed Systems,11,1058-1073,IEEE,Middleware platforms. such as Web services. J2EE. CORBA. and DCOM. have become increasingly popular during the last decade. They have been very successful in solving distributed computing problems for a large family of application domains. The architecture of middleware systems have gone through many significant cycles of evolution. both in terms of the completeness of functionality and the range of adoptions for different types of platforms. However. at the same time. it is getting increasingly difficult to achieve and to maintain a high level of adaptability and configurability because the structure of the middleware architecture is becoming overly complicated and rigid. We attribute that problem to the limitations of traditional software decomposition methods. Aspect-oriented programming. on the contrary. has introduced new design perspectives that permit the superimpositions of different abstraction models …,True,Zmppp9kAAAAJ:9yKSN-GCB0IC,114,https://ieeexplore.ieee.org/abstract/document/1247668/,18005483658387787877,/scholar?cites=18005483658387787877,,,,0,0,0
1276337,Axis: Automatically fixing atomicity violations through solving control constraints,2012,Peng Liu and Charles Zhang,,,,299-309,IEEE,Atomicity. a general correctness criterion in concurrency programs. is often violated in real-world applications. The violations are difficult for developers to fix. making automatic bug fixing techniques attractive. The state of the art approach aims at automating the manual fixing process but cannot provide any theoretical reasoning and guarantees. We provide an automatic approach that applies well-studied discrete control theory to guarantee deadlocks are not introduced and maximal preservation of the concurrency of the original code. Under the hood. we reduce the problem of violation fixing to a constraint solving problem using the Petri net model. Our evaluation on 13 subjects shows that the slowdown incurred by our patches is only 40% of that of the state of the art. With the deadlock-free guarantee. our patches incur moderate overhead (around 10%). which is a worthwhile cost for safety.,True,Zmppp9kAAAAJ:qxL8FJ1GzNcC,93,https://ieeexplore.ieee.org/abstract/document/6227184/,1515473569618645349,/scholar?cites=1515473569618645349,,,https://www.cse.ust.hk/~charlesz/axis.pdf,0,0,0
1276338,Persuasive prediction of concurrency access anomalies,2011,Jeff Huang and Charles Zhang,,,,144-154,,"Predictive analysis is a powerful technique that exposes concurrency bugs in un-exercised program executions. However. current predictive analysis approaches lack the persuasiveness property as they offer little assistance in helping programmers fully understand the execution history that triggers the predicted bugs. We present a persuasive bug prediction technique as well as a prototype tool. PECAN. for detecting general access anomalies (AAs) in concurrent programs. The main characteristic of PECAN is that. in addition to predict AAs in a more general way. it generates"" bug hatching clips"" that deterministically instruct the input program to exercise the predicted AAs. The key ingredient of PECAN is an efficient offline schedule generation algorithm. with proof of the soundness. that guarantees to generate a feasible schedule for every real AA in programs that use locks in a nested way. We evaluate PECAN …",True,Zmppp9kAAAAJ:ULOm3_A8WrAC,86,https://dl.acm.org/doi/abs/10.1145/2001420.2001438,10862911174496407134,/scholar?cites=10862911174496407134,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.387.146&rep=rep1&type=pdf,0,0,0
1276339,Towards just-in-time middleware architectures,2005,Charles Zhang and Dapeng Gao and Hans-Arno Jacobsen,,,,63-74,,Middleware becomes increasingly important in building distributed applications. Today. conventional middleware systems are designed. implemented. and packaged prior to their applications. We argue that with this middleware construction paradigm it is often difficult to meet the challenges imposed by application specific customization requirements. We propose to reverse this paradigm by automatically synthesizing middleware structures as the result of reasoning about the distribution needs of the user application of middleware. We term this type of post-postulated middleware Just-in-time middleware (JiM). In this paper. we present our initial design and present an evaluation of the JiM paradigm through Abacus. a CORBA middleware implementation based on the aspect oriented refactoring of an industrial strength object request broker. In addition. we present Arachne. the Abacus synthesizer. which integrates …,True,Zmppp9kAAAAJ:2osOgNQ5qMEC,72,https://dl.acm.org/doi/abs/10.1145/1052898.1052904,4372224477870069401,/scholar?cites=4372224477870069401,,,https://www.cse.ust.hk/~charlesz/academic/jim_aosd05.pdf,0,0,0
1276340,Grail: Context-aware fixing of concurrency bugs,2014,Peng Liu and Omer Tripp and Charles Zhang,,,,318-329,,Writing efficient synchronization for multithreaded programs is notoriously hard. The resulting code often contains subtle concurrency bugs. Even worse. many bug fixes introduce new bugs. A classic example. seen widely in practice. is deadlocks resulting from fixing of an atomicity violation. These complexities have motivated the development of automated fixing techniques. Current techniques generate fixes that are typically conservative. giving up on available parallelism. Moreover. some of the techniques cannot guarantee the correctness of a fix. and may introduce deadlocks similarly to manual fix. whereas techniques that ensure correctness do so at the expense of even greater performance loss. We present Grail. a novel fixing algorithm that departs from previous techniques by simultaneously providing both correctness and optimality guarantees. Grail synthesizes bug-free yet optimal lock-based …,True,Zmppp9kAAAAJ:imad7qCvcD4C,52,https://dl.acm.org/doi/abs/10.1145/2635868.2635881,5793917430420375364,/scholar?cites=5793917430420375364,,,,0,0,0
1276341,Efficiently mining crosscutting concerns through random walks,2007,Charles Zhang and Hans-Arno Jacobsen,,,,226-238,,"Inspired by our past manual aspect mining experiences. this paper describes a random walk model to approximate how crosscutting concerns can be discovered in the absence of domain knowledge of the investigated application. Random walks are performed on the coupling graphs extracted from the program sources. The ideas underlying the popular page-rank algorithm are adapted and extended to generate ranks reflecting the degrees of"" popularity"" and"" significance"" for each of the program elements on the coupling graphs. Filtering techniques. exploiting both types of ranks. are applied to produce a final list of candidates representing crosscutting concerns. The resulting aspect mining algorithm is evaluated on numerous Java applications ranging from a small-scale drawing application. to a medium-sized middleware application. and to a largescale enterprise application server. In seconds. the aspect …",True,Zmppp9kAAAAJ:zYLM7Y9cAGgC,52,https://dl.acm.org/doi/abs/10.1145/1218563.1218588,14090229948268127733,/scholar?cites=14090229948268127733,,,http://www.msrg.org/publications/pdf_files/2007/ZhJ07-Efficiently_Mining_Crosscutting_Concern.pdf,0,0,0
1276342,The Concise Oxford Dictionary of Current English [computing terms],1990,Robert E Allen and et al.,,,,,Oxford University Press,,True,L-7d2uUAAAAJ:CS3DEtbQARgC,1342,,16146088746646195750,/scholar?cites=16146088746646195750,,,,0,0,0
1276343,Safety-critical systems. formal methods and standards,1993,Jonathan P Bowen and Victoria Stavridou,8,Software Engineering Journal,4,189-209,IEE/BCS,Standards concerned with the development of safety-critical systems. and the software in such systems in particular. abound today as the software crisis increasingly affects the world of embedded computer-based systems. The use of formal methods is often advocated as a way of increasing confidence in such systems. This paper examines the industrial use of these techniques. the recommendations concerning formal methods in a number of current and draft standards. and comments on the applicability and problems of using formal methods for the development of safety-critical systems on an industrial scale. Some possible future directions are suggested.,True,L-7d2uUAAAAJ:oNZyr7d5Mn4C,498,https://digital-library.theiet.org/content/journals/10.1049/sej.1993.0025,2164495428756616089,/scholar?cites=2164495428756616089,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.5195&rep=rep1&type=pdf,0,0,0
1276344,Seven more myths of formal methods,1995,Jonathan P Bowen and Michael G Hinchey,12,IEEE Software,4,34-41,IEEE,New myths about formal methods are gaining tacit acceptance both outside and inside the system-development community. The authors address and dispel these myths based on their observations of industrial projects. The myths include: formal methods delay the development process; they lack tools; they replace traditional engineering design methods; they only apply to software; are unnecessary; not supported; and formal methods people always use formal methods.< >,True,L-7d2uUAAAAJ:MB4u-SWKN0MC,492,https://ieeexplore.ieee.org/abstract/document/391826/,10061426416203135117,/scholar?cites=10061426416203135117,,,https://www.academia.edu/download/4890661/10.1.1.18.4068.pdf,0,0,0
1276345,Using formal specifications to support testing,2009,Robert M Hierons and Kirill Bogdanov and Jonathan P Bowen and Rance Cleaveland and John Derrick and Jeremy Dick and Marian Gheorghe and Mark Harman and Kalpesh Kapoor and Paul Krause and Gerald Lüttgen and Anthony JH Simons and Sergiy Vilkomir and Martin R Woodward and Hussein Zedan,41,ACM Computing Surveys (CSUR),2,1-76,Association for Computing Machinery,Formal methods and testing are two important approaches that assist in the development of high-quality software. While traditionally these approaches have been seen as rivals. in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.,True,L-7d2uUAAAAJ:ZeXyd9-uunAC,420,https://dl.acm.org/doi/abs/10.1145/1459352.1459354,8701672188994041348,/scholar?cites=8701672188994041348,,,http://eprints.whiterose.ac.uk/78801/7/WRRO_78801.pdf,0,0,0
1276346,Ten commandments of formal methods,1995,Jonathan P Bowen and Michael G Hinchey,28,Computer,4,56-63,IEEE Computer Society,Producing correct. reliable software in systems of ever increasing complexity is a problem with no immediate end in sight. The software industry suffers from a plague of bugs on a near-biblical scale. One promising technique in alleviating this problem is the application of formal methods that provide a rigorous mathematical basis to software development. When correctly applied. formal methods produce systems of the highest integrity and thus are especially recommended for security- and safety-critical systems. Unfortunately. although projects based on formal methods are proliferating. the use of these methods is still more the exception than the rule. which results from many misconceptions regarding their costs. difficulties. and payoffs. Surveys of formal methods applied to large problems in industry help dispel these misconceptions and show that formal methods projects can be completed on schedule and within …,True,L-7d2uUAAAAJ:VLnqNzywnoUC,388,https://ieeexplore.ieee.org/abstract/document/375178/,14134628646546791332,/scholar?cites=14134628646546791332,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.1817&rep=rep1&type=pdf,0,0,0
1276347,Applications of Formal Methods,1995,Michael G Hinchey and Jonathan P Bowen,,,,,Prentice Hall International Series in Computer Science,The main goal of the series has been to develop. illustrate and promulgate the scientific basis of computer programming. and its application in software engineering on an industrial scale. It is very encouraging to publish a record of success in this endeavour. Jonathan Bowen and Michael Hinchey have put together a varied collection of industrial case studies under the title Applications of Formal Methods. I hope they will be welcomed by the practitioner. removing some of the fear (but none of the challenge or benefit) of keeping to the forefront of the state of the art.,True,L-7d2uUAAAAJ:ufrVoPGSRksC,345,https://www.researchgate.net/profile/Jonathan_Bowen/publication/319015764_Applications_of_Formal_Methods/data/598b0d6e45851519f1102f37/Applications-of-Formal-Methods.pdf,17947481878883480406,/scholar?cites=17947481878883480406,,,https://www.researchgate.net/profile/Jonathan_Bowen/publication/319015764_Applications_of_Formal_Methods/data/598b0d6e45851519f1102f37/Applications-of-Formal-Methods.pdf,0,0,0
1276348,Digital Technologies and the Museum Experience: Handheld guides and other media,2008,Jonathan P Bowen and James Bradburne and Alexandra Burch and Lynn Dierking and John Falk and Silvia Filippini-Fantoni and Ben Gammon and Ellen Giusti and Halina Gottlieb and Sherry Hsi and Peter Lonsdale and Julia Meek and Ross Parry and Paul Rudman and Peter Samis and Mike Sharples and Jeffery K Smith and Pablo PL Tinio and Giasemi Vavoula,,,,,AltaMira Press,The biggest trend in museum exhibit design today is the creative incorporation of technology. Digital Technologies and the Museum Experience: Handheld Guides and Other Media explores the potential of mobile technologies (cell phones. digital cameras. MP3 players. PDAs) for visitor interaction and learning in museums. drawing on established practice to identify guidelines for future implementations.,True,L-7d2uUAAAAJ:9bzyojSiTPoC,342,http://books.google.com/books?hl=en&lr=&id=1dC-AAAAQBAJ&oi=fnd&pg=PR5&dq=info:NduRqBGfECcJ:scholar.google.com&ots=9zXGHZNhFY&sig=PfBnW4hB8jDLtAZQ4CetVP8eOTs,2814924665297951541,/scholar?cites=2814924665297951541,,,,0,0,0
1276349,Formal Specification and Documentation using Z: A case study approach,1996,Jonathan Peter Bowen,66,,,,International Thomson Computer Press,Formal methods are becoming more accepted in both academia and industry as one possible way in which to help improve the quality of both software and hardware systems. It should be remembered however that they are not a panacea. but rather one more weapon in the armoury against making design mistakes. To quote from Prof. Tony Hoare:Of course. there is no fool-proof methodology or magic formula that will ensure a good. efficient. or even feasible design. For that. the designer needs experience. insight. flair. judgement. invention. Formal methods can only stimulate. guide. and discipline our human inspiration. clarify design alternatives. assist in exploring their consequences. formalize and communicate design decisions. and help to ensure that they are correctly carried out.,True,L-7d2uUAAAAJ:2osOgNQ5qMEC,266,http://images4.wikia.nocookie.net/__cb20091031155410/formalmethods/images/4/4e/Zbook.pdf,3710860025657680199,/scholar?cites=3710860025657680199,,,http://images4.wikia.nocookie.net/__cb20091031155410/formalmethods/images/4/4e/Zbook.pdf,0,0,0
1276350,The Computer Science and Engineering Handbook [Formal methods],1997,Allen B Tucker Jr and et al.,,,,,CRC Press,,True,L-7d2uUAAAAJ:Ol96Buz8XVoC,230,,6896083620565686730,/scholar?cites=6896083620565686730,,,,0,0,0
1276351,The Oxford Companion to the History of Modern Science [Computer science],2003,John L Heilbron and et al.,,,,,Oxford University Press,Containing 609 encyclopedic articles written by more than 200 prominent scholars. The Oxford Companion to the History of Modern Science presents an unparalleled history of the field invaluable to anyone with an interest in the technology. ideas. discoveries. and learned institutions that have shaped our world over the past five centuries. Focusing on the period from the Renaissance to the early twenty-first century. the articles cover all disciplines (Biology. Alchemy. Behaviorism). historical periods (the Scientific Revolution. World War II. the Cold War). concepts (Hypothesis. Space and Time. Ether). and methodologies and philosophies (Observation and Experiment. Darwinism). Coverage is international. tracing the spread of science from its traditional centers and explaining how the prevailing knowledge of non-Western societies has modified or contributed to the dominant global science as it is currently understood. Revealing the interplay between science and the wider culture. the Companion includes entries on topics such as minority groups. art. religion. and science's practical applications. One hundred biographies of the most iconic historic figures. chosen for their contributions to science and the interest of their lives. are also included. Above all The Oxford Companion to the History of Modern Science is a companion to world history: modern in coverage. generous in breadth. and cosmopolitan in scope. The volume's utility is enhanced by a thematic outline of the entire contents. a thorough system of cross-referencing. and a detailed index that enables the reader to follow a specific line of inquiry along various threads from multiple starting …,True,L-7d2uUAAAAJ:tWiuw1KVSQEC,210,http://books.google.com/books?hl=en&lr=&id=abqjP-_KfzkC&oi=fnd&pg=PR5&dq=info:9erjK-fO3lYJ:scholar.google.com&ots=C1WX9VY-EP&sig=MIdLMsyqa7bp5PXcVL2GePrpUFw,6259668024360692469,/scholar?cites=6259668024360692469,,,,0,0,0
1276352,An invitation to formal methods,1996,Hossein Saiedian and Jonathan P Bowen and Ricky W Butler and David L Dill and Robert L Glass and David Gries and J. Anthony Hall and Michael G Hinchey and C Michael Holloway and Daniel Jackson and Cliff B Jones and Michael J Lutz and John Rushby and Jeannette Wing and Pamela Zave,29,Computer,4,16-30,IEEE Computer Society,"One of the most challenging tasks in software system design is to assure reliability. especially as these systems are increasingly used in sensitive and often life-critical environments such as medical systems. air traffic control. and space applications. Many claim that formal methods not only provide assurance of reliability but also have the potential to reduce costs. Although the literature contains many excellent examples of applications of formal methods for large. critical. or even business transaction systems. a large percentage of practitioners see formal methods as irrelevant to their daily work. Why? This roundtable brings together some preeminent experts in the field. asking them to address the question"" What is hindering the use of formal methods in industry?""",True,L-7d2uUAAAAJ:R3hNpaxXUhUC,203,https://www.computer.org/csdl/magazine/co/1996/04/r4016/13rRUzpzeFA,13996112848348636345,/scholar?cites=13996112848348636345,,,,0,0,0
1276353,Estimating software project effort using analogies,1997,Martin Shepperd and Chris Schofield,23,IEEE Transactions on software engineering,11,736-743,IEEE,Accurate project effort prediction is an important goal for the software engineering community. To date most work has focused upon building algorithmic models of effort. for example COCOMO. These can be calibrated to local environments. We describe an alternative approach to estimation based upon the use of analogies. The underlying principle is to characterize projects in terms of features (for example. the number of interfaces. the development method or the size of the functional requirements document). Completed projects are stored and then the problem becomes one of finding the most similar projects to the one for which a prediction is required. Similarity is defined as Euclidean distance in n-dimensional space where n is the number of project features. Each dimension is standardized so all dimensions have equal weight. The known effort values of the nearest neighbors to the new project are then used …,True,VqZsDvUAAAAJ:u5HHmVD_uO8C,1269,https://ieeexplore.ieee.org/abstract/document/637387/,11924185714050308013,/scholar?cites=11924185714050308013,,,https://bura.brunel.ac.uk/bitstream/2438/1101/3/Estimating%20Software%201997.pdf,0,0,0
1276354,A systematic review of software development cost estimation studies,2006,Magne Jorgensen and Martin Shepperd,33,,1,33-53,IEEE,This paper aims to provide a basis for the improvement of software-estimation research through a systematic review of previous work. The review identifies 304 software cost estimation papers in 76 journals and classifies the papers according to research topic. estimation approach. research approach. study context and data set. A Web-based library of these cost estimation papers is provided to ease the identification of relevant estimation research results. The review results combined with other knowledge provide support for recommendations for future software cost estimation research. including: 1) increase the breadth of the search for relevant studies. 2) search manually for relevant papers within a carefully selected set of journals when completeness is essential. 3) conduct more studies on estimation methods commonly used by the software industry. and 4) increase the awareness of how properties of the data …,True,VqZsDvUAAAAJ:u-x6o8ySG0sC,1110,https://ieeexplore.ieee.org/abstract/document/4027147/,10645674402785210672,/scholar?cites=10645674402785210672,,,https://bura.brunel.ac.uk/bitstream/2438/1076/3/04027147.pdf,0,0,0
1276355,What accuracy statistics really measure,2001,Barbara A Kitchenham and Lesley M Pickard and Stephen G.  MacDonell and Martin J.  Shepperd,148,IEE Proceedings-Software,3,81-85,IET Digital Library,The paper aims to provide the software estimation research community with a better understanding of the meaning of. and relationship between. two statistics that are often used to assess the accuracy of predictive models: the mean magnitude relative error. MMRE. and the number of predictions within 25% of the actuals. pred(25). It is demonstrated that MMRE and pred(25) are. respectively. measures of the spread and the kurtosis of the variable z where z=estimate/actual. Thus. z is considered to be a measure of accuracy. and statistics such as MMRE and pred(25) to be measures of properties of the distribution of z. It is suggested that measures of the central location and skewness of z. as well as measures of spread and kurtosis. are necessary. Furthermore. since the distribution of z is non-normal. non-parametric measures of these properties may be needed. For this reason. boxplots of z are useful alternatives to …,True,VqZsDvUAAAAJ:2osOgNQ5qMEC,514,https://digital-library.theiet.org/content/journals/10.1049/ip-sen_20010506,3041505261594631561,/scholar?cites=3041505261594631561,,,https://bura.brunel.ac.uk/bitstream/2438/1855/1/00942859.pdf,0,0,0
1276356,Reformulating software engineering as a search problem,2003,John Clarke and Jose Javier  Dolado and Mark Harman and Rob Hierons and Bryan Jones and Mary Lumkin and Brian Mitchell and Spiros Mancoridis and Kearton Rees and Marc Roper and Martin Shepperd,150,IEE Proceedings-software,3,161-175,IET Digital Library,Metaheuristic techniques such as genetic algorithms. simulated annealing and tabu search have found wide application in most areas of engineering. These techniques have also been applied in business. financial and economic modelling. Metaheuristics have been applied to three areas of software engineering: test data generation. module clustering and cost/effort prediction. yet there remain many software engineering problems which have yet to be tackled using metaheuristics. It is surprising that metaheuristics have not been more widely applied to software engineering; many problems in software engineering are characterised by precisely the features which make metaheuristics search applicable. In the paper it is argued that the features which make metaheuristics applicable for engineering and business applications outside software engineering also suggest that there is great potential for the exploitation …,True,VqZsDvUAAAAJ:9yKSN-GCB0IC,406,https://digital-library.theiet.org/content/journals/10.1049/ip-sen_20030559,13504433044590985239,/scholar?cites=13504433044590985239,,,https://bura.brunel.ac.uk/bitstream/2438/328/1/Reformulating%202003.pdf,0,0,0
1276357,Effort estimation using analogy,1996,Martin Shepperd and Chris Schofield and Barbara Kitchenham,,,,170-178,IEEE,The staff resources or effort required for a software project are notoriously difficult to estimate in advance. To date most work has focused upon algorithmic cost models such as COCOMO and Function Points. These can suffer from the disadvantage of the need to calibrate the model to each individual measurement environment coupled with very variable accuracy levels even after calibration. An alternative approach is to use analogy for estimation. We demonstrate that this method has considerable promise in that we show it to out perform traditional algorithmic methods for six different datasets. A disadvantage of estimation by analogy is that it requires a considerable amount of computation. The paper describes an automated environment known as ANGEL that supports the collection. storage and identification of the most analogous projects in order to estimate the effort for a new project. ANGEL is based upon the …,True,VqZsDvUAAAAJ:d1gkVwhDpl0C,400,https://ieeexplore.ieee.org/abstract/document/493413/,3363065236672844852,/scholar?cites=3363065236672844852,,,http://www.st.cs.uni-saarland.de/edu/empirical-se/2006/PDFs/shepperd96.pdf,0,0,0
1276358,Data quality: Some comments on the NASA software defect datasets,2013,Martin Shepperd and Qinbao Song and Zhongbin Sun and Carolyn Mair,39,IEEE Transactions on Software Engineering,9,1208-1215,IEEE,,True,VqZsDvUAAAAJ:dTyEYWd-f8wC,353,https://ieeexplore.ieee.org/abstract/document/6464273/,7381107125736512004,/scholar?cites=7381107125736512004,,,https://bura.brunel.ac.uk/bitstream/2438/7926/2/TSE_NASADataQualNote_V26.pdf,0,0,0
1276359,A general software defect-proneness prediction framework,2010,Qinbao Song and Zihan Jia and Martin Shepperd and Shi Ying and Jin Liu,37,IEEE transactions on software engineering,3,356-370,IEEE,,True,VqZsDvUAAAAJ:isC4tDSrTZIC,348,https://ieeexplore.ieee.org/abstract/document/5611551/,6107825787291478518,/scholar?cites=6107825787291478518,,,https://bura.brunel.ac.uk/bitstream/2438/8781/2/Fulltext.pdf,0,0,0
1276360,An empirical investigation of an object-oriented software system,2000,Michelle Cartwright and Martin Shepperd,26,IEEE Transactions on software engineering,8,786-796,IEEE,The paper describes an empirical investigation into an industrial object oriented (OO) system comprised of 133000 lines of C++. The system was a subsystem of a telecommunications product and was developed using the Shlaer-Mellor method (S. Shlaer and S.J. Mellor. 1988; 1992). From this study. we found that there was little use of OO constructs such as inheritance. and therefore polymorphism. It was also found that there was a significant difference in the defect densities between those classes that participated in inheritance structures and those that did not. with the former being approximately three times more defect-prone. We were able to construct useful prediction systems for size and number of defects based upon simple counts such as the number of states and events per class. Although these prediction systems are only likely to have local significance. there is a more general principle that software …,True,VqZsDvUAAAAJ:qjMakFHDy7sC,340,https://ieeexplore.ieee.org/abstract/document/879814/,11375702402723252923,/scholar?cites=11375702402723252923,,,https://bura.brunel.ac.uk/bitstream/2438/4805/1/Fulltext.pdf,0,0,0
1276361,Comparing software prediction techniques using simulation,2001,Martin Shepperd and Gada Kadoda,27,IEEE Transactions on Software Engineering,11,1014-1022,IEEE,The need for accurate software prediction systems increases as software becomes much larger and more complex. We believe that the underlying characteristics: size. number of features. type of distribution. etc.. of the data set influence the choice of the prediction system to be used. For this reason. we would like to control the characteristics of such data sets in order to systematically explore the relationship between accuracy. choice of prediction system. and data set characteristic. It would also be useful to have a large validation data set. Our solution is to simulate data allowing both control and the possibility of large (1000) validation cases. The authors compare four prediction techniques: regression. rule induction. nearest neighbor (a form of case-based reasoning). and neural nets. The results suggest that there are significant differences depending upon the characteristics of the data set. Consequently …,True,VqZsDvUAAAAJ:IjCSPb-OGe4C,313,https://ieeexplore.ieee.org/abstract/document/965341/,16195343269144930194,/scholar?cites=16195343269144930194,,,https://bura.brunel.ac.uk/bitstream/2438/1102/3/Comparing%20Software%20Prediction%202001.pdf,0,0,0
1276362,Reliability and validity in comparative studies of software prediction models,2005,Ingunn Myrtveit and Erik Stensrud and Martin Shepperd,31,IEEE Transactions on Software Engineering,5,380-391,IEEE,"Empirical studies on software prediction models do not converge with respect to the question ""which prediction model is best?"" The reason for this lack of convergence is poorly understood. In this simulation study. we have examined a frequently used research procedure comprising three main ingredients: a single data sample. an accuracy indicator. and cross validation. Typically. these empirical studies compare a machine learning model with a regression model. In our study. we use simulation and compare a machine learning and a regression model. The results suggest that it is the research procedure itself that is unreliable. This lack of reliability may strongly contribute to the lack of convergence. Our findings thus cast some doubt on the conclusions of any study of competing software prediction models that used this research procedure as a basis of model comparison. Thus. we need to develop more reliable …",True,VqZsDvUAAAAJ:Tyk-4Ss8FVUC,311,https://ieeexplore.ieee.org/abstract/document/1438374/,13663722695440436257,/scholar?cites=13663722695440436257,,,https://bura.brunel.ac.uk/bitstream/2438/1853/1/01438374.pdf,0,0,0
1276363,Evaluating prediction systems in software project estimation,2012,Martin Shepperd and Steve MacDonell,54,Information and Software Technology,8,820-827,Elsevier,Software engineering has a problem in that when we empirically evaluate competing prediction systems we obtain conflicting results.To reduce the inconsistency amongst validation study results and provide a more formal foundation to interpret results with a particular focus on continuous prediction systems.A new framework is proposed for evaluating competing prediction systems based upon (1) an unbiased statistic. Standardised Accuracy. (2) testing the result likelihood relative to the baseline technique of random ‘predictions’. that is guessing. and (3) calculation of effect sizes.Previously published empirical evaluations of prediction systems are re-examined and the original conclusions shown to be unsafe. Additionally. even the strongest results are shown to have no more than a medium effect size relative to random guessing.Biased accuracy statistics such as …,True,VqZsDvUAAAAJ:g5m5HwL7SMYC,304,https://www.sciencedirect.com/science/article/pii/S095058491200002X,1730979205044074335,/scholar?cites=1730979205044074335,,,https://arxiv.org/pdf/2101.05426,0,0,0
1276364,Agile software development methods: Review and analysis,2017,Pekka Abrahamsson and Outi Salo and Jussi Ronkainen and Juhani Warsta,,,,,,"Agile-denoting"" the quality of being agile. readiness for motion. nimbleness. activity. dexterity in motion""-software development methods are attempting to offer an answer to the eager business community asking for lighter weight along with faster and nimbler software development processes. This is especially the case with the rapidly growing and volatile Internet software industry as well as for the emerging mobile application environment. The new agile methods have evoked substantial amount of literature and debates. However. academic research on the subject is still scarce. as most of existing publications are written by practitioners or consultants. The aim of this publication is to begin filling this gap by systematically reviewing the existing literature on agile software development methodologies. This publication has three purposes. First. it proposes a definition and a classification of agile software development approaches. Second. it analyses ten software development methods that can be characterized as being"" agile"" against the defined criterion. Third. it compares these methods and highlights their similarities and differences. Based on this analysis. future research needs are identified and discussed.",True,A-CX3y4AAAAJ:u5HHmVD_uO8C,2236,https://arxiv.org/abs/1709.08439,3168580308161775457,/scholar?cites=3168580308161775457,,,https://arxiv.org/pdf/1709.08439,0,0,0
1276365,New directions on agile methods: a comparative analysis,2003,Pekka Abrahamsson and Juhani Warsta and Mikko T Siponen and Jussi Ronkainen,,,,244-254,Ieee,Agile software development methods have caught the attention of software engineers and researchers worldwide. Scientific research is yet scarce. This paper reports results from a study. which aims to organize. analyze and make sense out of the dispersed field of agile software development methods. The comparative analysis is performed using the method's life-cycle coverage. project management support. type of practical guidance. fitness-for-use and empirical evidence as the analytical lenses. The results show that agile software development methods. without rationalization. cover certain/different phases of the software development life-cycle and most of them do not offer adequate support for project management. Yet. many methods still attempt to strive for universal solutions (as opposed to situation appropriate) and the empirical evidence is still very limited. Based on the results. new directions are …,True,A-CX3y4AAAAJ:u-x6o8ySG0sC,1050,https://ieeexplore.ieee.org/abstract/document/1201204/,11952331949201023269,/scholar?cites=11952331949201023269,,,http://secure.com.sg/courses/ICT353/Session_Collateral/TOP_03_ART_06_ARTICLE_ABRAHAMSSON_New_Directions_Agile_Methods.pdf,0,0,0
1276366,The impact of agile practices on communication in software development,2008,Minna Pikkarainen and Jukka Haikara and Outi Salo and Pekka Abrahamsson and Jari Still,13,Empirical Software Engineering,3,303-337,Springer US,Agile software development practices such as eXtreme Programming (XP) and SCRUM have increasingly been adopted to respond to the challenges of volatile business environments. where the markets and technologies evolve rapidly and present the unexpected. In spite of the encouraging results so far. little is known about how agile practices affect communication. This article presents the results from a study which examined the impact of XP and SCRUM practices on communication within software development teams and within the focal organization. The research was carried out as a case study in F-Secure where two agile software development projects were compared from the communication perspective. The goal of the study is to increase the understanding of communication in the context of agile software development: internally among the developers and project leaders and in the interface …,True,A-CX3y4AAAAJ:d1gkVwhDpl0C,429,https://link.springer.com/article/10.1007/s10664-008-9065-9,8346757855337431534,/scholar?cites=8346757855337431534,,,https://www.academia.edu/download/49867753/s10664-008-9065-920161025-18106-19kvhxc.pdf,0,0,0
1276367,Software development in startup companies: A systematic mapping study,2014,Nicolò Paternoster and Carmine Giardino and Michael Unterkalmsteiner and Tony Gorschek and Pekka Abrahamsson,56,,10,1200-1218,Elsevier,Software startups are newly created companies with no operating history and fast in producing cutting-edge technologies. These companies develop software under highly uncertain conditions. tackling fast-growing markets under severe lack of resources. Therefore. software startups present a unique combination of characteristics which pose several challenges to software development activities.This study aims to structure and analyze the literature on software development in startup companies. determining thereby the potential for technology transfer and identifying software development work practices reported by practitioners and researchers.We conducted a systematic mapping study. developing a classification schema. ranking the selected primary studies according their rigor and relevance. and analyzing reported software development work practices in startups.A total of 43 …,True,A-CX3y4AAAAJ:XiVPGOgt02cC,360,https://www.sciencedirect.com/science/article/pii/S0950584914000950,18287134524021887105,/scholar?cites=18287134524021887105,,,https://www.diva-portal.org/smash/get/diva2:834117/FULLTEXT01.pdf,0,0,0
1276368,‘Lots done. more to do’: the current state of agile systems development research,2009,Pekka Abrahamsson and Kieran Conboy and Xiaofeng Wang,18,,4,281-284,Taylor & Francis,Agile systems development methods emerged as a response to the inability of previous plan-driven approaches to handle rapidly changing environments (Highsmith. 2002). Originating from the so-called ‘light-weight’methods and promoted through the publication of the Agile Manifesto (2001). the agile method family have become highly prevalent in recent years. Meantime. agile system development research has gained momentum. as is evident from the increasing number of dedicated journal special issues. conferences. conference tracks and workshops. However. practitioners and consultants have largely driven the creation and dissemination of these methods. Agile research has lagged behind practice. as is often the case with new and emerging phenomena in Information Systems Development (ISD).,True,A-CX3y4AAAAJ:qjMakFHDy7sC,318,https://orsociety.tandfonline.com/doi/full/10.1057/ejis.2009.27?src=recsys,17178846879634019250,/scholar?cites=17178846879634019250,,,https://orsociety.tandfonline.com/doi/full/10.1057/ejis.2009.27?src=recsys,0,0,0
1276369,Agile methods rapidly replacing traditional methods at Nokia: A survey of opinions on agile transformation,2011,Maarit Laanti and Outi Salo and Pekka Abrahamsson,53,Information and Software Technology,3,276-290,Elsevier,Many organizations have started to deploy agile methods. but so far there exist only a few studies on organization-wide transformations. Are agile methods here to stay? Some claim that agile software development methods are in the mainstream adoption phase in the software industry. while others hope that those are a passing fad. The assumption here is that if agile would not provide real improvement. adopters would be eager at first but turn pessimistic after putting it into practice.Despite the growing amount of anecdotal evidence on the success of agile methods across a wide range of different real-life development settings. scientific studies remain scarce. Even less is known about the perception of the impacts of agile transformation when it is deployed in a very large software development environment. and whether agile methods are here to stay. This study aims to fill that gap by providing …,True,A-CX3y4AAAAJ:YsMSGLbcyi4C,287,https://www.sciencedirect.com/science/article/pii/S0950584910002119,6103205263011018060,/scholar?cites=6103205263011018060,,,https://www.academia.edu/download/36438613/1_Agile_Methods_Nokia_INFSOF5071.pdf,0,0,0
1276370,Agile methods in European embedded software development organisations: a survey on the actual use and usefulness of Extreme Programming and Scrum,2008,Outi Salo and Pekka Abrahamsson,2,IET software,1,58-64,IET Digital Library,Press releases. scientific publications and anecdotal evidence demonstrate that organisations worldwide are adopting agile software development methods at increasing speed. Little is still known about the current usefulness of agile methods in the complex environment of the embedded software development industry. Embedded devices are already commonplace in regular households. The goal of this survey is to provide first-hand knowledge of the adoption and experience of two of the most known agile methods. namely Extreme Programming and Scrum. in a number of European organisations of embedded software known to be interested and active in experimenting with agile software development methods. The survey involved 13 industrial organisations in eight European countries and 35 individual software development projects. The focus of the questionnaire was to enquire into the level of use as well as …,True,A-CX3y4AAAAJ:2osOgNQ5qMEC,278,https://digital-library.theiet.org/content/journals/10.1049/iet-sen_20070038,17414350511214907682,/scholar?cites=17414350511214907682,,,http://agilesouthflorida.pbworks.com/f/Agile%2BMethods%2Bin%2BEuropean%2BEmbedded%2BSoftware%2BDevelopment.pdf,0,0,0
1276371,Mobile-D: an agile approach for mobile application development,2004,Pekka Abrahamsson and Antti Hanhineva and Hanna Hulkko and Tuomas Ihme and Juho Jäälinoja and Mikko Korkala and Juha Koskela and Pekka Kyllönen and Outi Salo,,,,174-175,,Mobile phones have been closed environments until recent years. The change brought by open platform technologies such as the Symbian operating system and Java technologies has opened up a significant business opportunity for anyone to develop application software such as games for mobile terminals. However. developing mobile applications is currently a challenging task due to the specific demands and technical constraints of mobile development. Furthermore. at the moment very little is known about the suitability of the different development processes for mobile application development. Due to these issues. we have developed an agile development approach called Mobile-D. The Mobile-D approach is briefly outlined here and the experiences gained from four case studies are discussed.,True,A-CX3y4AAAAJ:UeHWp8X0CEIC,270,https://dl.acm.org/doi/abs/10.1145/1028664.1028736,300883485122790963,/scholar?cites=300883485122790963,,,https://arxiv.org/pdf/1709.06820,0,0,0
1276372,Agility and architecture: Can they coexist?,2010,Pekka Abrahamsson and Muhammad Ali Babar and Philippe Kruchten,27,IEEE Software,2,16-22,IEEE,Agile development has significantly impacted industrial software development practices. However. despite its wide popularity. there's an increasing perplexity about software architecture's role and importance in agile approaches. Advocates of architecture's vital role in achieving quality goals for large software-intensive systems doubt the scalability of any development approach that doesn't pay sufficient attention to architecture. This article talks about software architecture being relevant to the basis of aspects such as communication among team members. inputs to subsequent design decisions. documenting design assumptions. and evaluating design alternatives. In a large software organization. implementing agile approaches isn't a straightforward adoption problem. Most likely. it will take several years to shorten the feedback cycles to benefit from the adaptability and earlier value-creation opportunities. Failure …,True,A-CX3y4AAAAJ:W7OEmFMy1HYC,215,https://ieeexplore.ieee.org/abstract/document/5420791/,7769816700659034209,/scholar?cites=7769816700659034209,,,https://ieeexplore.ieee.org/iel5/52/5420782/05420791.pdf,0,0,0
1276373,A multiple case study on the impact of pair programming on product quality,2005,Hanna Hulkko and Pekka Abrahamsson,,,,495-504,,Pair programming is a programming technique in which two programmers use one computer to work together on the same task. There is an ongoing debate over the value of pair programming in software development. The current body of knowledge in this area is scattered and unorganized. Review shows that most of the results have been obtained from experimental studies in university settings. Few. if any. empirical studies exist. where pair programming has been systematically under scrutiny in real software development projects. Thus. its proposed benefits remain currently without solid empirical evidence. This paper reports results from four software development projects where the impact of pair programming on software product quality was studied. Our empirical findings appear to offer contrasting results regarding some of the claimed benefits of pair programming. They indicate that pair programming may …,True,A-CX3y4AAAAJ:9yKSN-GCB0IC,199,https://dl.acm.org/doi/abs/10.1145/1062455.1062545,6190580556834723231,/scholar?cites=6190580556834723231,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.528.8188&rep=rep1&type=pdf,0,0,0
1276374,What do we know about software development in startups?,2014,Carmine Giardino and Michael Unterkalmsteiner and Nicolo Paternoster and Tony Gorschek and Pekka Abrahamsson,31,IEEE software,5,28-32,IEEE,An impressive number of new startups are launched every day as a result of growing new markets. accessible technologies. and venture capital. New ventures such as Facebook. Supercell. Linkedin. Spotify. WhatsApp. and Dropbox. to name a few. are good examples of startups that evolved into successful businesses. However. despite many successful stories. the great majority of them fail prematurely. Operating in a chaotic and rapidly evolving domain conveys new uncharted challenges for startuppers. In this study. the authors characterize their context and identify common software development startup practices.,True,A-CX3y4AAAAJ:PELIpwtuRlgC,195,https://ieeexplore.ieee.org/abstract/document/6898758/,10801533274390122474,/scholar?cites=10801533274390122474,,,https://www.diva-portal.org/smash/get/diva2:834141/FULLTEXT01.pdf,0,0,0
1276375,Deckard: Scalable and accurate tree-based detection of code clones,2007,Lingxiao Jiang and Ghassan Misherghi and Zhendong Su and Stephane Glondu,,,,96-105,IEEE,Detecting code clones has many software engineering applications. Existing approaches either do not scale to large code bases or are not robust against minor code modifications. In this paper. we present an efficient algorithm for identifying similar subtrees and apply it to tree representations of source code. Our algorithm is based on a novel characterization of subtrees with numerical vectors in the Euclidean space R n middot and an efficient algorithm to cluster these vectors w.r.t. the Euclidean distance metric. Subtrees with vectors in one cluster are considered similar. We have implemented our tree similarity algorithm as a clone detection tool called DECKARD and evaluated it on large code bases written in C and Java including the Linux kernel and JDK. Our experiments show that DECKARD is both scalable and accurate. It is also language independent. applicable to any language with a formally specified …,True,RivxoIcAAAAJ:IjCSPb-OGe4C,1048,https://ieeexplore.ieee.org/abstract/document/4222572/,10191962116768592876,/scholar?cites=10191962116768592876,,,http://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=2010&context=sis_research,0,0,0
1276376,The essence of command injection attacks in web applications,2006,Zhendong Su and Gary Wassermann,41,Acm Sigplan Notices,1,372-382,ACM,Web applications typically interact with a back-end database to retrieve persistent data and then present the data to the user as dynamically generated output. such as HTML web pages. However. this interaction is commonly done through a low-level API by dynamically constructing query strings within a general-purpose programming language. such as Java. This low-level interaction is ad hoc because it does not take into account the structure of the output language. Accordingly. user inputs are treated as isolated lexical entities which. if not properly sanitized. can cause the web application to generate unintended output. This is called a command injection attack. which poses a serious threat to web application security. This paper presents the first formal definition of command injection attacks in the context of web applications. and gives a sound and complete algorithm for preventing them based on context-free …,True,RivxoIcAAAAJ:u5HHmVD_uO8C,752,https://dl.acm.org/doi/abs/10.1145/1111320.1111070,17767513425868634189,/scholar?cites=17767513425868634189,,,https://cs.uwaterloo.ca/~brecht/courses/702/Possible-Readings/security/injection-attacks-web-apps-popl-2006.pdf,0,0,0
1276377,On the naturalness of software,2016,Abram Hindle and Earl T Barr and Mark Gabel and Zhendong Su and Premkumar Devanbu,59,Communications of the ACM,5,122-131,ACM,Natural languages like English are rich. complex. and powerful. The highly creative and graceful use of languages like English and Tamil. by masters like Shakespeare and Avvaiyar. can certainly delight and inspire. But in practice. given cognitive constraints and the exigencies of daily life. most human utterances are far simpler and much more repetitive and predictable. In fact. these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition. natural language translation. question-answering. and text mining and comprehension.We begin with the conjecture that most software is also natural. in the sense that it is created by humans at work. with all the attendant constraints and limitations---and thus. like natural language. it is also likely to be repetitive and predictable. We then proceed to ask whether (a) code …,True,RivxoIcAAAAJ:lSLTfruPkqcC,724,https://dl.acm.org/doi/abs/10.1145/2902362,14558049290902271347,/scholar?cites=14558049290902271347,,,https://discovery.ucl.ac.uk/id/eprint/1505799/1/Barr_On%20the%20Naturalness%20of%20Software%20-%20E%20Barr.pdf,0,0,0
1276378,FIREMAN: A toolkit for firewall modeling and analysis,2006,Lihua Yuan and Jianning Mai and Zhendong Su and Hao Chen and Chen-Nee Chuah and Prasant Mohapatra,,,,15 pp.-213,IEEE,Security concerns are becoming increasingly critical in networked systems. Firewalls provide important defense for network security. However. misconfigurations in firewalls are very common and significantly weaken the desired security. This paper introduces FIREMAN. a static analysis toolkit for firewall modeling and analysis. By treating firewall configurations as specialized programs. FIREMAN applies static analysis techniques to check misconfigurations. such as policy violations. inconsistencies. and inefficiencies. in individual firewalls as well as among distributed firewalls. FIREMAN performs symbolic model checking of the firewall configurations for all possible IP packets and along all possible data paths. It is both sound and complete because of the finite state nature of firewall configurations. FIREMAN is implemented by modeling firewall rules using binary decision diagrams (BDDs). which have been used …,True,RivxoIcAAAAJ:d1gkVwhDpl0C,584,https://ieeexplore.ieee.org/abstract/document/1624012/,10801929424375464398,/scholar?cites=10801929424375464398,,,https://www.ece.ucdavis.edu/~chuah/rubinet/paper/2006/sosp06-fireman.pdf,0,0,0
1276379,Sound and precise analysis of web applications for injection vulnerabilities,2007,Gary Wassermann and Zhendong Su,,,,32-41,,Web applications are popular targets of security attacks. One common type of such attacks is SQL injection. where an attacker exploits faulty application code to execute maliciously crafted database queries. Bothstatic and dynamic approaches have been proposed to detect or prevent SQL injections; while dynamic approaches provide protection for deployed software. static approaches can detect potential vulnerabilities before software deployment. Previous static approaches are mostly based on tainted information flow tracking and have at least some of the following limitations:(1) they do not model the precise semantics of input sanitization routines;(2) they require manually written specifications. either for each query or for bug patterns; or (3) they are not fully automated and may require user intervention at various points in the analysis. In this paper. we address these limitations by proposing a precise. sound …,True,RivxoIcAAAAJ:9yKSN-GCB0IC,506,https://dl.acm.org/doi/abs/10.1145/1250734.1250739,13402065734223110753,/scholar?cites=13402065734223110753,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.4964&rep=rep1&type=pdf,0,0,0
1276380,Static detection of cross-site scripting vulnerabilities,2008,Gary Wassermann and Zhendong Su,,,,171-180,IEEE,Web applications support many of our daily activities. but they often have security problems. and their accessibility makes them easy to exploit. In cross-site scripting (XSS). an attacker exploits the trust a Web client (browser) has for a trusted server and executes injected script on the browser with the server's privileges. In 2006. XSS constituted the largest class of newly reported vulnerabilities making it the most prevalent class of attacks today. Web applications have XSS vulnerabilities because the validation they perform on untrusted input does not suffice to prevent that input from invoking a browser's JavaScript interpreter. and this validation is particularly difficult to get right if it must admit some HTML mark-up. Most existing approaches to finding XSS vulnerabilities are taint-based and assume input validation functions to be adequate. so they either miss real vulnerabilities or report many false positives. This paper …,True,RivxoIcAAAAJ:zYLM7Y9cAGgC,486,https://ieeexplore.ieee.org/abstract/document/4814128/,16477007915604139653,/scholar?cites=16477007915604139653,,,https://www.academia.edu/download/6784478/20090204paperd.pdf,0,0,0
1276381,Scalable detection of semantic clones,2008,Mark Gabel and Lingxiao Jiang and Zhendong Su,,,,321-330,,Several techniques have been developed for identifying similar code fragments in programs. These similar fragments. referred to as code clones. can be used to identify redundant code. locate bugs. or gain insight into program design. Existing scalable approaches to clone detection are limited to finding program fragments that are similar only in their contiguous syntax. Other. semantics-based approaches are more resilient to differences in syntax. such as reordered statements. related statements interleaved with other unrelated statements. or the use of semantically equivalent control structures. However. none of these techniques have scaled to real world code bases. These approaches capture semantic information from Program Dependence Graphs (PDGs). program representations that encode data and control dependencies between statements and predicates. Our definition of a code clone is also based on …,True,RivxoIcAAAAJ:W7OEmFMy1HYC,399,https://dl.acm.org/doi/abs/10.1145/1368088.1368132,3968107146994403610,/scholar?cites=3968107146994403610,,,https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=1933&context=sis_research,0,0,0
1276382,Compiler validation via equivalence modulo inputs,2014,Vu Le and Mehrdad Afshari and Zhendong Su,49,ACM SIGPLAN Notices,6,216-226,ACM,We introduce equivalence modulo inputs (EMI). a simple. widely applicable methodology for validating optimizing compilers. Our key insight is to exploit the close interplay between (1) dynamically executing a program on some test inputs and (2) statically compiling the program to work on all possible inputs. Indeed. the test inputs induce a natural collection of the original program's EMI variants. which can help differentially test any compiler and specifically target the difficult-to-find miscompilations.To create a practical implementation of EMI for validating C compilers. we profile a program's test executions and stochastically prune its unexecuted code. Our extensive testing in eleven months has led to 147 confirmed. unique bug reports for GCC and LLVM alone. The majority of those bugs are miscompilations. and more than 100 have already been fixed.Beyond testing compilers. EMI can be adapted to validate …,True,RivxoIcAAAAJ:BrmTIyaxlBUC,279,https://dl.acm.org/doi/abs/10.1145/2666356.2594334,8307596962351297995,/scholar?cites=8307596962351297995,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.698.6361&rep=rep1&type=pdf,0,0,0
1276383,Partial online cycle elimination in inclusion constraint graphs,1998,Manuel Fähndrich and Jeffrey S Foster and Zhendong Su and Alexander Aiken,,,,85-96,,Many program analyses are naturally formulated and implemented using inclusion constraints. We present new results on the scalable implementation of such analyses based on two insights: first. that online elimination of cyclic constraints yields orders-of-magnitude improvements in analysis time for large problems; second. that the choice of constraint representation affects the quality and efficiency of online cycle elimination. We present an analytical model that explains our design choices and show that the model's predictions match well with results from a substantial experiment.,True,RivxoIcAAAAJ:u-x6o8ySG0sC,267,https://dl.acm.org/doi/abs/10.1145/277650.277667,14651964035644456478,/scholar?cites=14651964035644456478,,,https://www.researchgate.net/profile/Manuel_Faehndrich/publication/220752319_Partial_Online_Cycle_Elimination_in_Inclusion_Constraint_Graphs/links/0fcfd50ca6a59cd0c1000000/Partial-Online-Cycle-Elimination-in-Inclusion-Constraint-Graphs.pdf,0,0,0
1276384,Static checking of dynamically generated queries in database applications,2004,Carl Gould and Zhendong Su and Premkumar Devanbu,,,,645-654,IEEE,Many data-intensive applications dynamically construct queries in response to client requests and execute them. Java servlets. e.g.. can create string representations of SQL queries and then send the queries. using JDBC. to a database server for execution. The servlet programmer enjoys static checking via Java's strong type system. However. the Java type system does little to check for possible errors in the dynamically generated SQL query strings. Thus. a type error in a generated selection query (e.g.. comparing a string attribute with an integer) can result in an SQL runtime exception. Currently. such defects must be rooted out through careful testing. or (worse) might be found by customers at runtime. In this paper. we present a sound. static. program analysis technique to verify the correctness of dynamically generated query strings. We describe our analysis technique and provide soundness results for our static …,True,RivxoIcAAAAJ:UeHWp8X0CEIC,255,https://ieeexplore.ieee.org/abstract/document/1317486/,15949678099996963260,/scholar?cites=15949678099996963260,,,https://www.researchgate.net/profile/Premkumar_Devanbu/publication/220403873_Static_checking_of_dynamically_generated_queries_in_database_applications/links/00b4951de3ea93aa0f000000/Static-checking-of-dynamically-generated-queries-in-database-applications.pdf,0,0,0
1276385,On deriving unknown vulnerabilities from zero-day polymorphic and metamorphic worm exploits,2005,Jedidiah R Crandall and Zhendong Su and S Felix Wu and Frederic T Chong,,,,235-248,,Vulnerabilities that allow worms to hijack the control flow of each host that they spread to are typically discovered months before the worm outbreak. but are also typically discovered by third party researchers. A determined attacker could discover vulnerabilities as easily and create zero-day worms for vulnerabilities unknown to network defenses. It is important for an analysis tool to be able to generalize from a new exploit observed and derive protection for the vulnerability. Many researchers have observed that certain predicates of the exploit vector must be present for the exploit to work and that therefore these predicates place a limit on the amount of polymorphism and metamorphism available to the attacker. We formalize this idea and subject it to quantitative analysis with a symbolic execution tool called DACODA. Using DACODA we provide an empirical analysis of 14 exploits (seven of them actual worms or …,True,RivxoIcAAAAJ:2osOgNQ5qMEC,238,https://dl.acm.org/doi/abs/10.1145/1102120.1102152,7578842837095085498,/scholar?cites=7578842837095085498,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.5377&rep=rep1&type=pdf,0,0,0
1276386,The goal question metric approach,1994,Victor R Basili1 Gianluigi Caldiera and H Dieter Rombach,,Encyclopedia of software engineering,,528-532,,As with any engineering discipline. software development requires a measurement mechanism for feedback and evaluation. Measurement is a mechanism for creating a corporate memory and an aid in answering a variety of questions associated with the enactment of any software process. It helps support project planning (eg. How much will a new project cost?); it allows us to determine the strengths and weaknesses of the current processes and products (eg. What is the frequency of certain types of errors?); it provides a rationale for adopting/refining techniques (eg. What is the impact of the technique XX on the productivity of the projects?); it allows us to evaluate the quality of specific processes and products (eg. What is the defect density in a specific system after deployment?). Measurement also helps. during the course of a project. to assess its progress. to take corrective action based on this assessment. and to evaluate the impact of such action.,True,T_618nIAAAAJ:YFjsv_pBGBYC,2533,http://www.csri.utoronto.ca/~sme/CSC444F/handouts/GQM-paper.pdf,5480316701638503294,/scholar?cites=5480316701638503294,,,http://www.csri.utoronto.ca/~sme/CSC444F/handouts/GQM-paper.pdf,0,0,0
1276387,The TAME project: Towards improvement-oriented software environments,1988,Victor R Basili and H Dieter Rombach,14,IEEE Transactions on software engineering,6,758-773,IEEE,Experience from a dozen years of analyzing software engineering processes and products is summarized as a set of software engineering and measurement principles that argue for software engineering process models that integrate sound planning and analysis into the construction process. In the TAME (Tailoring A Measurement Environment) project at the University of Maryland. such an improvement-oriented software engineering process model was developed that uses the goal/question/metric paradigm to integrate the constructive and analytic aspects of software development. The model provides a mechanism for formalizing the characterization and planning tasks. controlling and improving projects based on quantitative analysis. learning in a deeper and more systematic way about the software process and product. and feeding the appropriate experience back into the current and future projects. The …,True,T_618nIAAAAJ:MLfJN-KU85MC,1936,https://ieeexplore.ieee.org/abstract/document/6156/,17193129876797270159,/scholar?cites=17193129876797270159,,,https://drum.lib.umd.edu/bitstream/handle/1903/7524/The%20TAME%20Project.pdf?sequence=1&isAllowed=y,0,0,0
1276388,Experience factory,2002,Victor R Basili and Gianluigi Caldiera and H Dieter Rombach,,Encyclopedia of software engineering,,,John Wiley & Sons. Inc.,Reuse of products. processes. and experience originating from the system life cycle is seen today as a feasible solution to the problem of developing higher quality systems at a lower cost. In fact. quality improvement is very often achieved by repeatedly reusing and modifying the same elements. learning about them by direct experience.This article presents an infrastructure. called the experience factory. aimed at capitalization and reuse of life‐cycle experience and products. The experience factory is a logical and physical organization. and its activities are independent from those of the development organization. The activities of the development organization and of the experience factory can be summarized as follows:  The development organization develops and delivers systems with the aid of analyzed. synthesized. and packaged experiences from the experience factory. It provides the experience factory with …The development organization develops and delivers systems with the aid of analyzed. synthesized. and packaged experiences from the experience factory. It provides the experience factory with …,True,T_618nIAAAAJ:i2xiXl-TujoC,1318,https://onlinelibrary.wiley.com/doi/abs/10.1002/0471028959.sof110,18048848868552178414,/scholar?cites=18048848868552178414,,,http://www.cs.umd.edu/projects/SoftEng/ESEG/papers/fact.pdf,0,0,0
1276389,A handbook of software and systems engineering: Empirical observations. laws. and theories,2003,Albert Endres and H Dieter Rombach,,,,,Pearson Education,Computers are the most pervasive tools of modern society. Their development relies on advanced methods of software and systems engineering. Based on repeated and consistent observations. key lessons of these fields can now be formulated into rules or even laws. providing initial building blocks towards a theoretical foundation that is essential for further research. for teaching and for the practice of software development. This book guides students toward the best practice to use when implementing software engineering techniques. It identifies and discusses the rules and laws of developing software. Largely independent of technologies. these rules and laws form the basis for principles underlying software and systems engineering. The book is structured around the software development life cycle. which begins with requirements definition and continues by covering maintenance and withdrawal. This is the first book in the Fraunhofer IESE series in Software Engineering.,True,T_618nIAAAAJ:dshw04ExmUIC,513,http://books.google.com/books?hl=en&lr=&id=QrsBoLfyD1IC&oi=fnd&pg=PR15&dq=info:9JYDNeADTnoJ:scholar.google.com&ots=6XZwwZK71Z&sig=pr0FeJhMla91iopzqYJIIHU0SWw,8812985782307624692,/scholar?cites=8812985782307624692,,,,0,0,0
1276390,Support for comprehensive reuse,1991,Victor R Basili and H Dieter Rombach,6,Software engineering journal,5,303-316,IET Digital Library,Reuse of products. processes and other knowledge will be the key to enable the software industry to achieve the dramatic improvement in productivity and quality required to satisfy anticipated growing demands. Although experience shows that certain kinds of reuse can be successful. general success has been elusive. A software life-cycle technology that allows comprehensive reuse of all kinds of software-related experience could provide the means of achieving the desired order-of-magnitude improvements. In this paper. we introduce a comprehensive framework of models. model-based characterisation schemes. and support mechanisms for better understanding. evaluating. planning and supporting all aspects of reuse.,True,T_618nIAAAAJ:-FonjvnnhkoC,329,https://digital-library.theiet.org/content/journals/10.1049/sej.1991.0032,17710082162798604867,/scholar?cites=17710082162798604867,,,https://drum.lib.umd.edu/bitstream/handle/1903/7512/Support.pdf?sequence=1&isAllowed=y,0,0,0
1276391,Goal question metric (gqm) approach,2002,Rini Van Solingen and Vic Basili and Gianluigi Caldiera and H Dieter Rombach,,Encyclopedia of software engineering,,,John Wiley & Sons. Inc.,As with any engineering discipline. software development requires a measurement mechanism for feedback and evaluation. Measurement supports creating a corporate memory and is an aid in answering a variety of questions associated with the enactment of any software process. Measurement also helps. during the course of a project. to assess its progress. to take corrective action based on this assessment. and to evaluate the impact of such action.According to many studies made on the application of metrics and models in industrial environments. measurement in order to be effective must be.  Focused on specific goals Applied to all life‐cycle products. processes. and resources Interpreted on the basis of characterization and understanding of the organizational context. environment. and goals   This means that measurement must be defined in a top‐down fashion. It must be focused. based on goals and …Focused on specific goalsApplied to all life‐cycle products. processes. and resourcesInterpreted on the basis of characterization and understanding of the organizational context. environment. and goals,True,T_618nIAAAAJ:yB1At4FlUx8C,307,https://onlinelibrary.wiley.com/doi/abs/10.1002/0471028959.sof142,15440383551017896803,/scholar?cites=15440383551017896803,,,,0,0,0
1276392,Practical guidelines for measurement‐based process improvement,1996,Lionel C Briand and Christiane M Differding and H Dieter Rombach,2,Software Process: Improvement and Practice,4,253-280,John Wiley & Sons. Ltd.,Despite significant progress in the last 15 years. implementing a successful measurement program for software development is still a challenging undertaking. Most problems are not of theoretical but of methodological or practical nature. In this article. we present lessons learned from experiences with goal‐oriented measurement. We structure them into practical guidelines for efficient and useful software measurement aimed at process improvement in industry. Issues related to setting measurement goals. defining explicit measurement models. and implementing data collection procedures are addressed from a practical perspective. In addition. guidelines for using measurement in the context of process improvement are provided. © 1996 by John Wiley & Sons. Ltd. and Gauthier‐Villars,True,T_618nIAAAAJ:vRqMK49ujn8C,304,https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1099-1670(199612)2:4%3C253::AID-SPIP53%3E3.0.CO;2-G,9729822167422481771,/scholar?cites=9729822167422481771,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.3110&rep=rep1&type=pdf,0,0,0
1276393,Tailoring the software process to project goals and environments,1986,Victor R Basili and H Dieter Rombach,,,,,,. This paper presents a methodology for improving the software process by tailoring it to the specific project goals and environment. This improvement process is aimed at the global software process model as well as at the methods and tools supporting that model. The basic idea is to use defect profiles to help characterize the environment and evalu-ate the project goals and the effectiveness of methods and tools in a quantitative way. The improvement process is implemented iteratively by setting project improvement goals. characterizing those goals and the environment. in part. via defect profiles in a quantitative way. choosing methods and tools fitting those characteristics. evaluating the actual behavior of the chosen set of methods and tools. and refining the project goals based on the evaluation results. All these activities require analysis of large amounts of data and. therefore. support by an …,True,T_618nIAAAAJ:L7CI7m0gUJcC,303,https://drum.lib.umd.edu/bitstream/handle/1903/7525/Tailoring.pdf?sequence=1,16568737638380067300,/scholar?cites=16568737638380067300,,,https://drum.lib.umd.edu/bitstream/handle/1903/7525/Tailoring.pdf?sequence=1,0,0,0
1276394,Linking software development and business strategy through measurement,2010,Victor R Basili and Mikael Lindvall and Myrna Regardie and Carolyn Seaman and Jens Heidrich and Jürgen Münch and Dieter Rombach and Adam Trendowicz,43,Computer,4,57-65,IEEE,The GQM+Strategies approach extends the goal/question/metric paradigm for measuring the success or failure of goals and strategies. adding enterprise-wide support for determining action on the basis of measurement results. An organization can thus integrate its measurement program across all levels.,True,T_618nIAAAAJ:bFI3QPDXJZMC,199,https://ieeexplore.ieee.org/abstract/document/5445168/,8027935919137885990,/scholar?cites=8027935919137885990,,,https://arxiv.org/pdf/1311.6224,0,0,0
1276395,Outsourcing in India [software development],2001,Werner Kobitzsch and Dieter Rombach and Raimund L Feldmann,18,IEEE Software,2,78-86,IEEE,Starting in the early 1990s and motivated initially by the desire to cut personnel costs. many companies have explored multisite. multi-country software development approaches. India and Eastern Europe. in particular. have drawn attention. Most companies today distribute their development primarily to access human resources and competencies not available at home and only secondarily to cut labor costs. After examining various possible outsourcing models. this article reports on the experiences of Tenovis GmbH and Co. KG. a German company in the private (in-house) telecommunication domain. and its software development partner in Bangalore. India.,True,T_618nIAAAAJ:uJ-U7cs_P_0C,189,https://ieeexplore.ieee.org/abstract/document/914751/,15102182207870413703,/scholar?cites=15102182207870413703,,,https://www.academia.edu/download/26383833/20021023-2.pdf,0,0,0
1276396,A controlled expeniment on the impact of software structure on maintainability,1987,H. Dieter  Rombach,,IEEE Transactions on Software Engineering,3,344-354,IEEE,This paper describes a study on the impact of software structure on maintainability aspects such as comprehensibility. locality. modifiability. and reusability in a distributed system environment. The study was part of a project at the University of Kaiserslautern. West Germany. to design and implement LADY. a LAnguage for Distributed systems. The study addressed the impact of software structure from two perspectives. The language designer's perspective was to evaluate the general impact of the set of structural concepts chosen for LADY on the maintainability of software systems implemented in LADY. The language user's perspective was to derive structural criteria (metrics). measurable from LADY systems. that allow the explanation or prediction of the software maintenance behavior. A controlled maintenance experiment was conducted involving twelve medium-size distributed software systems; six of these …,True,T_618nIAAAAJ:R3hNpaxXUhUC,177,https://ieeexplore.ieee.org/abstract/document/1702220/,3959457746835547844,/scholar?cites=3959457746835547844,,,,0,0,0
1276397,Stargan: Unified generative adversarial networks for multi-domain image-to-image translation,2018,Yunjey Choi and Minje Choi and Munyoung Kim and Jung-Woo Ha and Sunghun Kim and Jaegul Choo,,,,8789-8797,,Recent studies have shown remarkable success in image-to-image translation for two domains. However. existing approaches have limited scalability and robustness in handling more than two domains. since different models should be built independently for every pair of image domains. To address this limitation. we propose StarGAN. a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.,True,JE_m2UgAAAAJ:6syOTa9L3GQC,1584,http://openaccess.thecvf.com/content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.html,15940143923298105219,/scholar?cites=15940143923298105219,,,http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf,0,0,0
1276398,Classifying software changes: Clean or buggy?,2008,Sunghun Kim and E James Whitehead and Yi Zhang,34,IEEE Transactions on Software Engineering,2,181-196,IEEE,This paper introduces a new technique for predicting latent software bugs. called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner. change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean. with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file). 2) predictions do not require semantic information about the source code. 3) the technique works for a broad array of project …,True,JE_m2UgAAAAJ:2osOgNQ5qMEC,618,https://ieeexplore.ieee.org/abstract/document/4408585/,16015809695858654263,/scholar?cites=16015809695858654263,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.219.2942&rep=rep1&type=pdf,0,0,0
1276399,Predicting faults from cached history,2007,Sunghun Kim and Thomas Zimmermann and E James Whitehead Jr and Andreas Zeller,,,,489-498,IEEE,We analyze the version history of 7 software systems to predict the most fault prone entities and files. The basic assumption is that faults do not occur in isolation. but rather in bursts of several related faults. Therefore. we cache locations that are likely to have faults: starting from the location of a known (fixed) fault. we cache the location itself. any locations changed together with the fault. recently added locations. and recently changed locations. By consulting the cache at the moment a fault is fixed. a developer can detect likely fault-prone locations. This is useful for prioritizing verification and validation resources on the most fault prone files or entities. In our evaluation of seven open source projects with more than 200.000 revisions. the cache selects 10% of the source code files; these files account for 73%-95% of faults - a significant advance beyond the state of the art.,True,JE_m2UgAAAAJ:u5HHmVD_uO8C,595,https://ieeexplore.ieee.org/abstract/document/4222610/,338532016657424558,/scholar?cites=338532016657424558,,,https://home.cse.ust.hk/~hunkim/images/3/37/Papers_kim_2007_bugcache.pdf,0,0,0
1276400,Automatic patch generation learned from human-written patches,2013,Dongsun Kim and Jaechang Nam and Jaewoo Song and Sunghun Kim,,,,802-811,IEEE,Patch generation is an essential software maintenance task because most software systems inevitably have bugs that need to be fixed. Unfortunately. human resources are often insufficient to fix all reported and known bugs. To address this issue. several automated patch generation techniques have been proposed. In particular. a genetic-programming-based patch generation technique. GenProg. proposed by Weimer et al.. has shown promising results. However. these techniques can generate nonsensical patches due to the randomness of their mutation operations. To address this limitation. we propose a novel patch generation approach. Pattern-based Automatic program Repair (Par). using fix patterns learned from existing human-written patches. We manually inspected more than 60.000 human-written patches and found there are several common fix patterns. Our approach leverages these fix patterns to …,True,JE_m2UgAAAAJ:BqipwSGYUEgC,564,https://ieeexplore.ieee.org/abstract/document/6606626/,9364097885708520424,/scholar?cites=9364097885708520424,,,https://staff.fmi.uvt.ro/~daniela.zaharie/ma2018/projects/biblio/applications/AutomatedProgramRepair/PatternBasedPatchGeneration.pdf,0,0,0
1276401,Improving bug triage with bug tossing graphs,2009,Gaeul Jeong and Sunghun Kim and Thomas Zimmermann,,,,111-120,,"bug report is typically assigned to a single developer who is then responsible for fixing the bug. In Mozilla and Eclipse. between 37%-44% of bug reports are"" tossed""(reassigned) to other developers. for example because the bug has been assigned by accident or another developer with additional expertise is needed. In any case. tossing increases the time-to-correction for a bug.",True,JE_m2UgAAAAJ:Tyk-4Ss8FVUC,530,https://dl.acm.org/doi/abs/10.1145/1595696.1595715,11013625250506329957,/scholar?cites=11013625250506329957,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.491.2717&rep=rep1&type=pdf,0,0,0
1276402,Automatically patching errors in deployed software,2009,Jeff H Perkins and Sunghun Kim and Sam Larsen and Saman Amarasinghe and Jonathan Bachrach and Michael Carbin and Carlos Pacheco and Frank Sherwood and Stelios Sidiroglou and Greg Sullivan and Weng-Fai Wong and Yoav Zibin and Michael D Ernst and Martin Rinard,,,,87-102,,We present ClearView. a system for automatically patching errors in deployed software. ClearView works on stripped Windows x86 binaries without any need for source code. debugging information. or other external information. and without human intervention.,True,JE_m2UgAAAAJ:blknAaTinKkC,449,https://dl.acm.org/doi/abs/10.1145/1629575.1629585,10615365151037003723,/scholar?cites=10615365151037003723,,,http://hunkim.cse.ust.hk/images/9/92/Automatic-patching-sosp2009.pdf,0,0,0
1276403,Transfer defect learning,2013,Jaechang Nam and Sinno Jialin Pan and Sunghun Kim,,,,382-391,IEEE,Many software defect prediction approaches have been proposed and most are effective in within-project prediction settings. However. for new projects or projects with limited training data. it is desirable to learn a prediction model by using sufficient training data from existing source projects and then apply the model to some target projects (cross-project defect prediction). Unfortunately. the performance of cross-project defect prediction is generally poor. largely because of feature distribution differences between the source and target projects. In this paper. we apply a state-of-the-art transfer learning approach. TCA. to make feature distributions in source and target projects similar. In addition. we propose a novel transfer defect learning approach. TCA+. by extending TCA. Our experimental results for eight open-source projects show that TCA+ significantly improves cross-project prediction performance.,True,JE_m2UgAAAAJ:O3NaXMp0MMsC,399,https://ieeexplore.ieee.org/abstract/document/6606584/,9795579670329778442,/scholar?cites=9795579670329778442,,,http://www.cse.ust.hk/~hunkim/papers/nam-icse2013.pdf,0,0,0
1276404,Deep API learning,2016,Xiaodong Gu and Hongyu Zhang and Dongmei Zhang and Sunghun Kim,,,,631-642,,Developers often wonder how to implement a certain functionality (eg. how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query. existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bags-of-words and lack a deep understanding of the semantics of the query. We propose DeepAPI. a deep learning based approach to generate API usage sequences for a given natural language query. Instead of a bag-of-words assumption. it learns the sequence of words in a query and the sequence of associated APIs. DeepAPI adapts a neural language model named RNN Encoder-Decoder. It encodes a word sequence (user query) into a fixed-length context vector. and generates an API sequence based on the context vector. We also …,True,JE_m2UgAAAAJ:eH23hyXCXa4C,372,https://dl.acm.org/doi/abs/10.1145/2950290.2950334,10439969254066917534,/scholar?cites=10439969254066917534,,,https://arxiv.org/pdf/1605.08535,0,0,0
1276405,Duplicate bug reports considered harmful… really?,2008,Nicolas Bettenburg and Rahul Premraj and Thomas Zimmermann and Sunghun Kim,,,,337-345,IEEE,In a survey we found that most developers have experienced duplicated bug reports. however. only few considered them as a serious problem. This contradicts popular wisdom that considers bug duplicates as a serious problem for open source projects. In the survey. developers also pointed out that the additional information provided by duplicates helps to resolve bugs quicker. In this paper. we therefore propose to merge bug duplicates. rather than treating them separately. We quantify the amount of information that is added for developers and show that automatic triaging can be improved as well. In addition. we discuss the different reasons why users submit duplicate bug reports in the first place.,True,JE_m2UgAAAAJ:UeHWp8X0CEIC,335,https://ieeexplore.ieee.org/abstract/document/4658082/,6525126157425211011,/scholar?cites=6525126157425211011,,,https://www.researchgate.net/profile/R_Premraj/publication/224343297_Duplicate_Bug_Reports_Considered_Harmful_Really/links/0912f508e35bac4f3a000000/Duplicate-Bug-Reports-Considered-Harmful-Really.pdf,0,0,0
1276406,Relink: recovering links between bugs and changes,2011,Rongxin Wu and Hongyu Zhang and Sunghun Kim and Shing-Chi Cheung,,,,15-25,,Software defect information. including links between bugs and committed changes. plays an important role in software maintenance such as measuring quality and predicting defects. Usually. the links are automatically mined from change logs and bug reports using heuristics such as searching for specific keywords and bug IDs in change logs. However. the accuracy of these heuristics depends on the quality of change logs. Bird et al. found that there are many missing links due to the absence of bug references in change logs. They also found that the missing links lead to biased defect information. and it affects defect prediction performance. We manually inspected the explicit links. which have explicit bug IDs in change logs and observed that the links exhibit certain features. Based on our observation. we developed an automatic link recovery algorithm. ReLink. which automatically learns criteria of features from …,True,JE_m2UgAAAAJ:L8Ckcad2t8MC,328,https://dl.acm.org/doi/abs/10.1145/2025113.2025120,5053815138903195703,/scholar?cites=5053815138903195703,,,https://www.cse.ust.hk/~hunkim/images/b/b6/Relink_fse2011.pdf,0,0,0
1276407,Dealing with noise in defect prediction,2011,Sunghun Kim and Hongyu Zhang and Rongxin Wu and Liang Gong,,,,481-490,IEEE,Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises. This paper proposes approaches to deal with the noise in defect data. First. we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general. for large defect datasets. adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However. the prediction performance decreases significantly when the dataset …,True,JE_m2UgAAAAJ:4TOpqqG69KYC,325,https://ieeexplore.ieee.org/abstract/document/6032487/,4264256398111048184,/scholar?cites=4264256398111048184,,,https://www.researchgate.net/profile/Rongxin_Wu/publication/221556058_Dealing_with_noise_in_defect_prediction/links/0deec536ccea82528e000000.pdf,0,0,0
1276408,SDSS-III: Massive spectroscopic surveys of the distant universe. the Milky Way. and extra-solar planetary systems,2011,Daniel J Eisenstein and David H Weinberg and Eric Agol and Hiroaki Aihara and Carlos Allende Prieto and Scott F Anderson and James A Arns and Éric Aubourg and Stephen Bailey and Eduardo Balbinot and Robert Barkhouser and Timothy C Beers and Andreas A Berlind and Steven J Bickerton and Dmitry Bizyaev and Michael R Blanton and John J Bochanski and Adam S Bolton and Casey T Bosman and Jo Bovy and WN Brandt and Ben Breslauer and Howard J Brewington and Jon Brinkmann and Peter J Brown and Joel R Brownstein and Dan Burger and Heather Campbell and Phillip A Cargile and William C Carithers and Joleen K Carlberg and Michael A Carr and Liang Chang and Yanmei Chen and Cristina Chiappini and Johan Comparat and Natalia Connolly and Marina Cortes and Rupert AC Croft and Katia Cunha and Luiz N Da Costa and James RA Davenport and Kyle Dawson and Nathan De Lee and Gustavo F Porto De Mello and Fernando De Simoni and Janice Dean and Saurav Dhital and Anne Ealet and Garrett L Ebelke and Edward M Edmondson and Jacob M Eiting and Stephanie Escoffier and Massimiliano Esposito and Michael L Evans and Xiaohui Fan and Bruno Femenía Castellá and Leticia Dutra Ferreira and Greg Fitzgerald and Scott W Fleming and Andreu Font-Ribera and Eric B Ford and Peter M Frinchaboy and Ana Elia García Pérez and B Scott Gaudi and Jian Ge and Luan Ghezzi and Bruce A Gillespie and Gerry Gilmore and Léo Girardi and J Richard Gott and Andrew Gould and Eva K Grebel and James E Gunn and Jean-Christophe Hamilton and Paul Harding and David W Harris and Suzanne L Hawley and Frederick R Hearty and Joseph F Hennawi and Jonay I González Hernández and Shirley Ho and David W Hogg and Jon A Holtzman and Klaus Honscheid and Naohisa Inada and Inese I Ivans and Linhua Jiang and Peng Jiang and Jennifer A Johnson and Cathy Jordan and Wendell P Jordan and Guinevere Kauffmann and Eyal Kazin and David Kirkby and Mark A Klaene and GR Knapp and Jean-Paul Kneib and CS Kochanek and Lars Koesterke and Juna A Kollmeier and Richard G Kron and Hubert Lampeitl and Dustin Lang and James E Lawler and Jean-Marc Le Goff and Brian L Lee and Young Sun Lee and Jarron M Leisenring and Yen-Ting Lin and Jian Liu and Daniel C Long and Craig P Loomis and Sara Lucatello and Britt Lundgren and Robert H Lupton and Bo Ma and Zhibo Ma and Nicholas MacDonald and Claude Mack and Suvrath Mahadevan and Marcio AG Maia and Steven R Majewski and Martin Makler and Elena Malanushenko and Viktor Malanushenko and Rachel Mandelbaum and Claudia Maraston and Daniel Margala and Paul Maseman and Karen L Masters and Cameron K McBride and Patrick McDonald and Ian D McGreer and Richard G McMahon and Olga Mena Requejo and Brice Ménard and Jordi Miralda-Escudé and Heather L Morrison and Fergal Mullally and Demitri Muna and Hitoshi Murayama and Adam D Myers and Tracy Naugle and Angelo Fausti Neto and Duy Cuong Nguyen and Robert C Nichol and David L Nidever and Robert W O’Connell and Ricardo LC Ogando,142,The Astronomical Journal,3,72,IOP Publishing,Building on the legacy of the Sloan Digital Sky Survey (SDSS-I and II). SDSS-III is a program of four spectroscopic surveys on three scientific themes: dark energy and cosmological parameters. the history and structure of the Milky Way. and the population of giant planets around other stars. In keeping with SDSS tradition. SDSS-III will provide regular public releases of all its data. beginning with SDSS Data Release 8 (DR8). which was made public in 2011 January and includes SDSS-I and SDSS-II images and spectra reprocessed with the latest pipelines and calibrations produced for the SDSS-III investigations. This paper presents an overview of the four surveys that comprise SDSS-III. The Baryon Oscillation Spectroscopic Survey will measure redshifts of 1.5 million massive galaxies and Lyα forest spectra of 150.000 quasars. using the baryon acoustic oscillation feature of large-scale structure to obtain percent …,True,ieqpr_kAAAAJ:u-x6o8ySG0sC,1999,https://iopscience.iop.org/article/10.1088/0004-6256/142/3/72/meta,10262077413743067370,/scholar?cites=10262077413743067370,,,https://iopscience.iop.org/article/10.1088/0004-6256/142/3/72/pdf,0,0,0
1276409,The eighth data release of the Sloan Digital Sky Survey: first data from SDSS-III,2011,Hiroaki Aihara and Carlos Allende Prieto and Deokkeun An and Scott F Anderson and Éric Aubourg and Eduardo Balbinot and Timothy C Beers and Andreas A Berlind and Steven J Bickerton and Dmitry Bizyaev and Michael R Blanton and John J Bochanski and Adam S Bolton and Jo Bovy and William Nielsen Brandt and Jon Brinkmann and Peter J Brown and Joel R Brownstein and Heather Campbell and Michael A Carr and Yanmei Chen and Cristina Chiappini and Johan Comparat and Natalia Connolly and Marina Cortes and Rupert AC Croft and Antonio J Cuesta and Luiz N Da Costa and James RA Davenport and Kyle Dawson and Saurav Dhital and Anne Ealet and Garrett L Ebelke and Edward M Edmondson and Daniel J Eisenstein and Stephanie Escoffier and Massimiliano Esposito and Michael L Evans and Xiaohui Fan and Bruno Femenía Castellá and Andreu Font-Ribera and Peter M Frinchaboy and Jian Ge and Bruce A Gillespie and G Gilmore and Jonay I González Hernández and J Richard Gott and Andrew Gould and Eva K Grebel and James E Gunn and Jean-Christophe Hamilton and Paul Harding and David W Harris and Suzanne L Hawley and Frederick R Hearty and Shirley Ho and David W Hogg and Jon A Holtzman and Klaus Honscheid and Naohisa Inada and Inese I Ivans and Linhua Jiang and Jennifer A Johnson and Cathy Jordan and Wendell P Jordan and Eyal A Kazin and David Kirkby and Mark A Klaene and Gillian R Knapp and Jean-Paul Kneib and Christopher S Kochanek and Lars Koesterke and Juna A Kollmeier and Richard G Kron and Hubert Lampeitl and Dustin Lang and Jean-Marc Le Goff and Young Sun Lee and Yen-Ting Lin and Daniel C Long and Craig P Loomis and Sara Lucatello and Britt Lundgren and Robert H Lupton and Zhibo Ma and Nicholas MacDonald and Suvrath Mahadevan and Marcio AG Maia and Martin Makler and Elena Malanushenko and Viktor Malanushenko and Rachel Mandelbaum and Claudia Maraston and Daniel Margala and Karen L Masters and Cameron K McBride and Peregrine M McGehee and Ian D McGreer and Brice Ménard and Jordi Miralda-Escudé and Heather L Morrison and Fergal Mullally and Demitri Muna and Jeffrey A Munn and Hitoshi Murayama and Adam D Myers and Tracy Naugle and Angelo Fausti Neto and Duy Cuong Nguyen and Robert C Nichol and Robert W O'Connell and Ricardo LC Ogando and Matthew D Olmstead and Daniel J Oravetz and Nikhil Padmanabhan and Nathalie Palanque-Delabrouille and Kaike Pan and Parul Pandey and Isabelle Pâris and Will J Percival and Patrick Petitjean and Robert Pfaffenberger and Janine Pforr and Stefanie Phleps and Christophe Pichon and Matthew M Pieri and Francisco Prada and Adrian M Price-Whelan and M Jordan Raddick and Beatriz HF Ramos and Céline Reylé and James Rich and Gordon T Richards and Hans-Walter Rix and Annie C Robin and Helio J Rocha-Pinto and Constance M Rockosi and Natalie A Roe and Emmanuel Rollinde and Ashley J Ross and Nicholas P Ross and Bruno M Rossetto and Ariel G Sánchez and Conor Sayres and David J Schlegel and Katharine J Schlesinger and Sarah J Schmidt and Donald P Schneider and Erin Sheldon and Yiping Shu,193,The Astrophysical Journal Supplement Series,2,29,IOP Publishing,The Sloan Digital Sky Survey (SDSS) started a new phase in 2008 August. with new instrumentation and new surveys focused on Galactic structure and chemical evolution. measurements of the baryon oscillation feature in the clustering of galaxies and the quasar Lyα forest. and a radial velocity search for planets around~ 8000 stars. This paper describes the first data release of SDSS-III (and the eighth counting from the beginning of the SDSS). The release includes five-band imaging of roughly 5200 deg 2 in the southern Galactic cap. bringing the total footprint of the SDSS imaging to 14.555 deg 2. or over a third of the Celestial Sphere. All the imaging data have been reprocessed with an improved sky-subtraction algorithm and a final. self-consistent photometric recalibration and flat-field determination. This release also includes all data from the second phase of the Sloan Extension for Galactic Understanding …,True,ieqpr_kAAAAJ:u5HHmVD_uO8C,1444,https://iopscience.iop.org/article/10.1088/0067-0049/193/2/29/meta,583930629472618420,/scholar?cites=583930629472618420,,,https://iopscience.iop.org/article/10.1088/0067-0049/193/2/29/pdf,0,0,0
1276410,LSST: from science drivers to reference design and anticipated data products,2019,Željko Ivezić and Steven M Kahn and J Anthony Tyson and Bob Abel and Emily Acosta and Robyn Allsman and David Alonso and Yusra AlSayyad and Scott F Anderson and John Andrew and James Roger P Angel and George Z Angeli and Reza Ansari and Pierre Antilogus and Constanza Araujo and Robert Armstrong and Kirk T Arndt and Pierre Astier and Éric Aubourg and Nicole Auza and Tim S Axelrod and Deborah J Bard and Jeff D Barr and Aurelian Barrau and James G Bartlett and Amanda E Bauer and Brian J Bauman and Sylvain Baumont and Ellen Bechtol and Keith Bechtol and Andrew C Becker and Jacek Becla and Cristina Beldica and Steve Bellavia and Federica B Bianco and Rahul Biswas and Guillaume Blanc and Jonathan Blazek and Roger D Blandford and Josh S Bloom and Joanne Bogart and Tim W Bond and Michael T Booth and Anders W Borgland and Kirk Borne and James F Bosch and Dominique Boutigny and Craig A Brackett and Andrew Bradshaw and William Nielsen Brandt and Michael E Brown and James S Bullock and Patricia Burchat and David L Burke and Gianpietro Cagnoli and Daniel Calabrese and Shawn Callahan and Alice L Callen and Jeffrey L Carlin and Erin L Carlson and Srinivasan Chandrasekharan and Glenaver Charles-Emerson and Steve Chesley and Elliott C Cheu and Hsin-Fang Chiang and James Chiang and Carol Chirino and Derek Chow and David R Ciardi and Charles F Claver and Johann Cohen-Tanugi and Joseph J Cockrum and Rebecca Coles and Andrew J Connolly and Kem H Cook and Asantha Cooray and Kevin R Covey and Chris Cribbs and Wei Cui and Roc Cutri and Philip N Daly and Scott F Daniel and Felipe Daruich and Guillaume Daubard and Greg Daues and William Dawson and Francisco Delgado and Alfred Dellapenna and Robert De Peyster and Miguel de Val-Borro and Seth W Digel and Peter Doherty and Richard Dubois and Gregory P Dubois-Felsmann and Josef Durech and Frossie Economou and Tim Eifler and Michael Eracleous and Benjamin L Emmons and Angelo Fausti Neto and Henry Ferguson and Enrique Figueroa and Merlin Fisher-Levine and Warren Focke and Michael D Foss and James Frank and Michael D Freemon and Emmanuel Gangler and Eric Gawiser and John C Geary and Perry Gee and Marla Geha and Charles JB Gessner and Robert R Gibson and D Kirk Gilmore and Thomas Glanzman and William Glick and Tatiana Goldina and Daniel A Goldstein and Iain Goodenow and Melissa L Graham and William J Gressler and Philippe Gris and Leanne P Guy and Augustin Guyonnet and Gunther Haller and Ron Harris and Patrick A Hascall and Justine Haupt and Fabio Hernandez and Sven Herrmann and Edward Hileman and Joshua Hoblitt and John A Hodgson and Craig Hogan and James D Howard and Dajun Huang and Michael E Huffer and Patrick Ingraham and Walter R Innes and Suzanne H Jacoby and Bhuvnesh Jain and Fabrice Jammes and M James Jee and Tim Jenness and Garrett Jernigan and Darko Jevremović and Kenneth Johns and Anthony S Johnson and Margaret WG Johnson,873,The Astrophysical Journal,2,111,IOP Publishing,Major advances in our understanding of the universe have historically arisen from dramatic improvements in our ability to “see.” We have developed progressively larger telescopes over the past century. allowing us to peer further into space. and further back in time. With the development of advanced instrumentation—imagers. spectrographs. and polarimeters—we have been able to parse radiation detected from distant sources over the full electromagnetic spectrum in increasingly subtle ways. These data have provided the detailed information needed to construct physical models of planets. stars. galaxies. quasars. and larger structures and to probe the new physics of dark matter and dark energy.Until recently. most astronomical investigations have focused on small samples of cosmic sources or individual objects. This is because our largest telescope facilities typically had rather small fields of view. and those …,True,ieqpr_kAAAAJ:vRqMK49ujn8C,1360,https://iopscience.iop.org/article/10.3847/1538-4357/ab042c/meta,13548419934749715280,/scholar?cites=13548419934749715280,,,https://iopscience.iop.org/article/10.3847/1538-4357/ab042c/pdf,0,0,0
1276411,The statistics of Λ CDM halo concentrations,2007,Angelo F Neto and Liang Gao and Philip Bett and Shaun Cole and Julio F Navarro and Carlos S Frenk and Simon DM White and Volker Springel and Adrian Jenkins,381,Monthly Notices of the Royal Astronomical Society,4,1450-1462,Blackwell Publishing Ltd,We use the Millennium Simulation (MS) to study the statistics of Λ cold dark matter (ΛCDM) halo concentrations at z= 0. Our results confirm that the average halo concentration declines monotonically with mass; the concentration–mass relation is well fitted by a power law over three decades in mass. up to the most massive objects that form in a ΛCDM universe (∼ 1015 h−1 M⊙). This is in clear disagreement with the predictions of the model proposed by Bullock et al. for these rare objects. and agrees better with the original predictions of Navarro. Frenk & White. The large volume surveyed. together with the unprecedented numerical resolution of the MS. allows us to estimate with confidence the distribution of concentrations and. consequently. the abundance of systems with unusual properties. About one in a hundred cluster haloes (M200≳ 3 × 1014 h−1 M⊙) have concentrations exceeding c200= 7.5. a …,True,ieqpr_kAAAAJ:9yKSN-GCB0IC,770,https://academic.oup.com/mnras/article-abstract/381/4/1450/971806,18351295155434643641,/scholar?cites=18351295155434643641,,,https://academic.oup.com/mnras/article/381/4/1450/971806,0,0,0
1276412,The dark energy camera,2015,Brenna Flaugher and HT Diehl and K Honscheid and TMC Abbott and O Alvarez and R Angstadt and JT Annis and M Antonik and O Ballester and L Beaufore and GM Bernstein and RA Bernstein and B Bigelow and M Bonati and D Boprie and D Brooks and EJ Buckley-Geer and J Campa and L Cardiel-Sas and FJ Castander and J Castilla and H Cease and JM Cela-Ruiz and S Chappa and E Chi and C Cooper and LN Da Costa and E Dede and G Derylo and DL DePoy and J De Vicente and P Doel and A Drlica-Wagner and J Eiting and AE Elliott and J Emes and J Estrada and A Fausti Neto and DA Finley and R Flores and J Frieman and D Gerdes and MD Gladders and B Gregory and GR Gutierrez and J Hao and SE Holland and S Holm and D Huffman and C Jackson and DJ James and M Jonas and A Karcher and I Karliner and S Kent and R Kessler and M Kozlovsky and RG Kron and D Kubik and K Kuehn and S Kuhlmann and K Kuk and O Lahav and A Lathrop and J Lee and ME Levi and P Lewis and TS Li and I Mandrichenko and JL Marshall and G Martinez and KW Merritt and R Miquel and F Muñoz and EH Neilsen and RC Nichol and B Nord and R Ogando and J Olsen and N Palaio and K Patton and J Peoples and AA Plazas and J Rauch and K Reil and J-P Rheault and NA Roe and H Rogers and A Roodman and E Sanchez and V Scarpine and RH Schindler and R Schmidt and R Schmitt and M Schubnell and K Schultz and P Schurter and L Scott and S Serrano and TM Shaw and RC Smith and M Soares-Santos and A Stefanik and W Stuermer and E Suchyta and A Sypniewski and G Tarle and J Thaler and R Tighe and C Tran and D Tucker and AR Walker and G Wang and M Watson and C Weaverdyck and W Wester and R Woods and B Yanny and DES Collaboration,150,The Astronomical Journal,5,150,IOP Publishing,The Dark Energy Camera is a new imager with a 2 fdg 2 diameter field of view mounted at the prime focus of the Victor M. Blanco 4 m telescope on Cerro Tololo near La Serena. Chile. The camera was designed and constructed by the Dark Energy Survey Collaboration and meets or exceeds the stringent requirements designed for the wide-field and supernova surveys for which the collaboration uses it. The camera consists of a five-element optical corrector. seven filters. a shutter with a 60 cm aperture. and a charge-coupled device (CCD) focal plane of 250 μm thick fully depleted CCDs cooled inside a vacuum Dewar. The 570 megapixel focal plane comprises 62 2k× 4k CCDs for imaging and 12 2k× 2k CCDs for guiding and focus. The CCDs have 15 μm× 15 μm pixels with a plate scale of 0 farcs 263 pixel− 1. A hexapod system provides state-of-the-art focus and alignment capability. The camera is read out in 20 s …,True,ieqpr_kAAAAJ:W7OEmFMy1HYC,657,https://iopscience.iop.org/article/10.1088/0004-6256/150/5/150/meta,14371989500709017209,/scholar?cites=14371989500709017209,,,https://iopscience.iop.org/article/10.1088/0004-6256/150/5/150/pdf,0,0,0
1276413,Eight new Milky Way companions discovered in first-year Dark Energy Survey data,2015,Keith Bechtol and Alex Drlica-Wagner and Eduardo Balbinot and Adriano Pieres and Josh D Simon and Brian Yanny and B Santiago and Risa H Wechsler and J Frieman and AR Walker and P Williams and Eduardo Rozo and ES Rykoff and A Queiroz and E Luque and Aurélien Benoit-Lévy and D Tucker and I Sevilla and Robert A Gruendl and LN Da Costa and A Fausti Neto and Marcio Antonio Geimba Maia and Timothy Abbott and S Allam and Robert Armstrong and Anne Hollister Bauer and Gary M Bernstein and Rebecca A Bernstein and Emmanuel Bertin and D Brooks and Elizabeth Buckley-Geer and David Lyle Burke and A Carnero Rosell and FJ Castander and R Covarrubias and Christopher B D’Andrea and Darren L DePoy and S Desai and H Thomas Diehl and TF Eifler and Juan Estrada and August E Evrard and Enrique Fernandez and David A Finley and Brenna Flaugher and Enrique Gaztanaga and D Gerdes and L Girardi and M Gladders and Daniel Gruen and G Gutierrez and Jiangang Hao and K Honscheid and Bhuvnesh Jain and D James and S Kent and R Kron and Kyler Kuehn and N Kuropatkin and Ofer Lahav and TS Li and H Lin and Martín Makler and M March and J Marshall and Paul Martini and K Wyatt Merritt and C Miller and Ramon Miquel and J Mohr and E Neilsen and R Nichol and B Nord and R Ogando and John Peoples and D Petravick and AA Plazas and Anita K Romer and Aaron Roodman and Masao Sako and E Sanchez and V Scarpine and Michael Schubnell and Robert Christopher Smith and Marcelle Soares-Santos and Flávia Sobreira and Eric Suchyta and Molly EC Swanson and Gregory Tarle and J Thaler and D Thomas and W Wester and J Zuntz and DES Collaboration,807,The Astrophysical Journal,1,50,IOP Publishing,We report the discovery of eight new Milky Way companions in  of optical imaging data collected during the first year of the Dark Energy Survey (DES). Each system is identified as a statistically significant over-density of individual stars consistent with the expected isochrone and luminosity function of an old and metal-poor stellar population. The objects span a wide range of absolute magnitudes (M V from  to ). physical sizes (). and heliocentric distances (). Based on the low surface brightnesses. large physical sizes. and/or large Galactocentric distances of these objects. several are likely to be new ultra-faint satellite galaxies of the Milky Way and/or Magellanic Clouds. We introduce a likelihood-based algorithm to search for and characterize stellar over-densities. as well as identify stars with high satellite membership probabilities. We also present completeness estimates …,True,ieqpr_kAAAAJ:qjMakFHDy7sC,506,https://iopscience.iop.org/article/10.1088/0004-637X/807/1/50/meta,1950541693604597410,/scholar?cites=1950541693604597410,,,https://iopscience.iop.org/article/10.1088/0004-637X/807/1/50/pdf,0,0,0
1276414,The redshift dependence of the structure of massive Λ cold dark matter haloes,2008,Liang Gao and Julio F Navarro and Shaun Cole and Carlos S Frenk and Simon DM White and Volker Springel and Adrian Jenkins and Angelo F Neto,387,Monthly Notices of the Royal Astronomical Society,2,536-544,Blackwell Publishing Ltd,We use two very large cosmological simulations to study how the density profiles of relaxed Λ cold dark matter dark haloes depend on redshift and on halo mass. We confirm that these profiles deviate slightly but systematically from the NFW form and are better approximated by the empirical formula. d log ρ/d log r∝rα. first used by Einasto to fit star counts in the Milky Way. The best-fitting value of the additional shape parameter. α. increases gradually with mass. from α∼ 0.16 for present-day galaxy haloes to α∼ 0.3 for the rarest and most massive clusters. Halo concentrations depend only weakly on mass at z= 0. and this dependence weakens further at earlier times. At z∼ 3 the average concentration of relaxed haloes does not vary appreciably over the mass range accessible to our simulations (M≳ 3 × 1011h−1M⊙). Furthermore. in our biggest simulation. the average concentration of the most massive …,True,ieqpr_kAAAAJ:2osOgNQ5qMEC,494,https://academic.oup.com/mnras/article-abstract/387/2/536/1022058,6918638976063219374,/scholar?cites=6918638976063219374,,,https://academic.oup.com/mnras/article/387/2/536/1022058,0,0,0
1276415,Eight ultra-faint galaxy candidates discovered in year two of the dark energy survey,2015,Alex Drlica-Wagner and Keith Bechtol and ES Rykoff and E Luque and A Queiroz and Y-Y Mao and Risa H Wechsler and Josh D Simon and B Santiago and Brian Yanny and Eduardo Balbinot and Scott Dodelson and A Fausti Neto and David J James and TS Li and Marcio Antonio Geimba Maia and Jennifer L Marshall and Adriano Pieres and K Stringer and AR Walker and TMC Abbott and Filipe B Abdalla and S Allam and Aurélien Benoit-Lévy and GM Bernstein and E Bertin and D Brooks and E Buckley-Geer and DL Burke and A Carnero Rosell and M Carrasco Kind and J Carretero and M Crocce and LN Da Costa and S Desai and HT Diehl and JP Dietrich and P Doel and TF Eifler and AE Evrard and DA Finley and Brenna Flaugher and P Fosalba and J Frieman and Enrique Gaztanaga and David W Gerdes and Daniel Gruen and Robert A Gruendl and G Gutierrez and K Honscheid and Kyler Kuehn and N Kuropatkin and Ofer Lahav and P Martini and R Miquel and B Nord and R Ogando and AA Plazas and K Reil and A Roodman and M Sako and E Sanchez and V Scarpine and M Schubnell and I Sevilla-Noarbe and RC Smith and M Soares-Santos and F Sobreira and E Suchyta and MEC Swanson and G Tarle and D Tucker and V Vikram and W Wester and Y Zhang and J Zuntz and DES Collaboration,813,The Astrophysical Journal,2,109,IOP Publishing,We report the discovery of eight new ultra-faint dwarf galaxy candidates in the second year of optical imaging data from the Dark Energy Survey (DES). Six of these candidates are detected at high confidence. while two lower-confidence candidates are identified in regions of non-uniform survey coverage. The new stellar systems are found by three independent automated search techniques and are identified as overdensities of stars. consistent with the isochrone and luminosity function of an old and metal-poor simple stellar population. The new systems are faint (M V>− 4.7) and span a range of physical sizes (17< r 1/2< 181) and heliocentric distances (25 kpc< D⊙< 214 kpc). All of the new systems have central surface brightnesses consistent with known ultra-faint dwarf galaxies (μ gsim 27.5− 2). Roughly half of the DES candidates are more distant. less luminous. and/or have lower surface …,True,ieqpr_kAAAAJ:Zph67rFs4hoC,407,https://iopscience.iop.org/article/10.1088/0004-637X/813/2/109/meta,10038881008837509377,/scholar?cites=10038881008837509377,,,https://iopscience.iop.org/article/10.1088/0004-637X/813/2/109/pdf,0,0,0
1276416,Searching for dark matter annihilation in recently discovered Milky Way satellites with Fermi-LAT,2017,Andrea Albert and Brandon Anderson and Keith Bechtol and Alex Drlica-Wagner and Manuel Meyer and Miguel Sánchez-Conde and L Strigari and M Wood and TMC Abbott and Filipe B Abdalla and Aurélien Benoit-Lévy and Gary M Bernstein and Rebecca A Bernstein and Emmanuel Bertin and David Brooks and David Lyle Burke and A Carnero Rosell and M Carrasco Kind and Jorge Carretero and Martin Crocce and Carlos Eduardo Cunha and Christopher Brian D’Andrea and LN Da Costa and Shantanu Desai and H Thomas Diehl and Jörg P Dietrich and Peter Doel and Tim F Eifler and August E Evrard and A Fausti Neto and David A Finley and Brenna Flaugher and Pablo Fosalba and Josh Frieman and David W Gerdes and Daniel Abraham Goldstein and Daniel Gruen and Robert A Gruendl and Klaus Honscheid and David J James and S Kent and Kyler Kuehn and Nikolay Kuropatkin and Ofer Lahav and TS Li and Marcio Antonio Geimba Maia and M March and Jennifer L Marshall and Paul Martini and Christopher J Miller and Ramon Miquel and E Neilsen and B Nord and R Ogando and AA Plazas and Kevin Reil and Anita K Romer and ES Rykoff and E Sanchez and B Santiago and Michael Schubnell and Ignacio Sevilla-Noarbe and Robert Christopher Smith and Marcelle Soares-Santos and Flávia Sobreira and Eric Suchyta and Molly EC Swanson and Gregory Tarle and Vinu Vikram and AR Walker and Risa H Wechsler,834,The Astrophysical Journal,2,110,IOP Publishing,We search for excess γ-ray emission coincident with the positions of confirmed and candidate Milky Way satellite galaxies using six years of data from the Fermi Large Area Telescope (LAT). Our sample of 45 stellar systems includes 28 kinematically confirmed dark-matter-dominated dwarf spheroidal galaxies (dSphs) and 17 recently discovered systems that have photometric characteristics consistent with the population of known dSphs. For each of these targets. the relative predicted γ-ray flux due to dark matter annihilation is taken from kinematic analysis if available. and estimated from a distance-based scaling relation otherwise. assuming that the stellar systems are DM-dominated dSphs. LAT data coincident with four of the newly discovered targets show a slight preference (each  2σ local) for γ-ray emission in excess of the background. However. the ensemble of derived γ-ray flux upper limits for individual targets is …,True,ieqpr_kAAAAJ:RYcK_YlVTxYC,379,https://iopscience.iop.org/article/10.3847/1538-4357/834/2/110/meta,9591307849094303963,/scholar?cites=9591307849094303963,,,https://iopscience.iop.org/article/10.3847/1538-4357/834/2/110/pdf,0,0,0
1276417,The ninth data release of the Sloan Digital Sky Survey: first spectroscopic data from the SDSS-III Baryon Oscillation Spectroscopic Survey,2012,Christopher P Ahn and Rachael Alexandroff and Carlos Allende Prieto and Scott F Anderson and Timothy Anderton and Brett H Andrews and Éric Aubourg and Stephen Bailey and Eduardo Balbinot and Rory Barnes and Julian Bautista and Timothy C Beers and Alessandra Beifiori and Andreas A Berlind and Vaishali Bhardwaj and Dmitry Bizyaev and Cullen H Blake and Michael R Blanton and Michael Blomqvist and John J Bochanski and Adam S Bolton and Arnaud Borde and Jo Bovy and William Nielsen Brandt and Jon Brinkmann and Peter J Brown and Joel R Brownstein and Kevin Bundy and William Carithers and Aurelio R Carnero and Michael A Carr and Dana I Casetti-Dinescu and Yanmei Chen and Cristina Chiappini and Johan Comparat and Natalia Connolly and Justin R Crepp and Stefano Cristiani and Rupert AC Croft and Antonio J Cuesta and Luiz N Da Costa and James RA Davenport and Kyle S Dawson and Roland De Putter and Nathan De Lee and Timothée Delubac and Saurav Dhital and Anne Ealet and Garrett L Ebelke and Edward M Edmondson and Daniel J Eisenstein and Stephanie Escoffier and Massimiliano Esposito and Michael L Evans and Xiaohui Fan and Bruno Femenía Castellá and Emma Fernández Alvar and Leticia D Ferreira and N Filiz Ak and Hayley Finley and Scott W Fleming and Andreu Font-Ribera and Peter M Frinchaboy and DA García-Hernández and AE García Pérez and Jian Ge and Ricardo Genova-Santos and Bruce A Gillespie and Léo Girardi and Jonay I González Hernández and Eva K Grebel and James E Gunn and Hong Guo and Daryl Haggard and Jean-Christophe Hamilton and David W Harris and Suzanne L Hawley and Frederick R Hearty and Shirley Ho and David W Hogg and Jon A Holtzman and Klaus Honscheid and Joseph Huehnerhoff and Inese I Ivans and Željko Ivezić and Heather R Jacobson and Linhua Jiang and Jonas Johansson and Jennifer A Johnson and Guinevere Kauffmann and David Kirkby and Jessica A Kirkpatrick and Mark A Klaene and Gillian R Knapp and Jean-Paul Kneib and Jean-Marc Le Goff and Alexie Leauthaud and Khee-Gan Lee and Young Sun Lee and Daniel C Long and Craig P Loomis and Sara Lucatello and Britt Lundgren and Robert H Lupton and Bo Ma and Zhibo Ma and Nicholas MacDonald and Claude E Mack and Suvrath Mahadevan and Marcio AG Maia and Steven R Majewski and Martin Makler and Elena Malanushenko and Viktor Malanushenko and A Manchado and Rachel Mandelbaum and Marc Manera and Claudia Maraston and Daniel Margala and Sarah L Martell and Cameron K McBride and Ian D McGreer and Richard G McMahon and Brice Ménard and Sz Meszaros and Jordi Miralda-Escudé and Antonio D Montero-Dorta and Francesco Montesano and Heather L Morrison and Demitri Muna and Jeffrey A Munn and Hitoshi Murayama and Adam D Myers and Angelo Fausti Neto and Duy Cuong Nguyen and Robert C Nichol and David L Nidever and Pasquier Noterdaeme and Sebastián E Nuza and Ricardo LC Ogando and Matthew D Olmstead and Daniel J Oravetz and Russell Owen and Nikhil Padmanabhan and Nathalie Palanque-Delabrouille and Kaike Pan and John K Parejko and Prachi Parihar and Isabelle Pâris and Petchara Pattarakijwanich,203,The Astrophysical Journal Supplement Series,2,21,IOP Publishing,The Sloan Digital Sky Survey III (SDSS-III) presents the first spectroscopic data from the Baryon Oscillation Spectroscopic Survey (BOSS). This ninth data release (DR9) of the SDSS project includes 535.995 new galaxy spectra (median z∼ 0. 52). 102.100 new quasar spectra (median z∼ 2. 32). and 90.897 new stellar spectra. along with the data presented in previous data releases. These spectra were obtained with the new BOSS spectrograph and were taken between 2009 December and 2011 July. In addition. the stellar parameters pipeline. which determines radial velocities. surface temperatures. surface gravities. and metallicities of stars. has been updated and refined with improvements in temperature estimates for stars with Teff< 5000 K and in metallicity estimates for stars with [Fe/H]>− 0. 5. DR9 includes new stellar parameters for all stars presented in DR8. including stars from SDSS-I and II. as well as …,True,ieqpr_kAAAAJ:d1gkVwhDpl0C,264,https://iopscience.iop.org/article/10.1088/0067-0049/203/2/21/meta,6339357324860936826,/scholar?cites=6339357324860936826,,,https://iopscience.iop.org/article/10.1088/0067-0049/203/2/21/pdf,0,0,0
1276418,Dark energy survey year 1 results: The photometric data set for cosmology,2018,Alex Drlica-Wagner and Ignacio Sevilla-Noarbe and Eli S Rykoff and RA Gruendl and B Yanny and DL Tucker and B Hoyle and A Carnero Rosell and GM Bernstein and K Bechtol and MR Becker and A Benoit-Lévy and E Bertin and M Carrasco Kind and C Davis and J De Vicente and HT Diehl and D Gruen and WG Hartley and B Leistedt and TS Li and JL Marshall and E Neilsen and MM Rau and E Sheldon and J Smith and MA Troxel and S Wyatt and Y Zhang and TMC Abbott and FB Abdalla and S Allam and Manda Banerji and D Brooks and E Buckley-Geer and DL Burke and D Capozzi and J Carretero and CE Cunha and CB D’Andrea and LN Da Costa and DL DePoy and S Desai and JP Dietrich and P Doel and AE Evrard and A Fausti Neto and B Flaugher and P Fosalba and J Frieman and J García-Bellido and DW Gerdes and Tommaso Giannantonio and J Gschwend and G Gutierrez and K Honscheid and DJ James and T Jeltema and K Kuehn and S Kuhlmann and N Kuropatkin and O Lahav and M Lima and H Lin and MAG Maia and P Martini and RG McMahon and P Melchior and F Menanteau and R Miquel and RC Nichol and RLC Ogando and AA Plazas and AK Romer and A Roodman and E Sanchez and V Scarpine and R Schindler and M Schubnell and M Smith and RC Smith and M Soares-Santos and F Sobreira and E Suchyta and G Tarle and V Vikram and AR Walker and RH Wechsler and J Zuntz and DES Collaboration,235,The Astrophysical Journal Supplement Series,2,33,IOP Publishing,We describe the creation. content. and validation of the Dark Energy Survey (DES) internal year-one cosmology data set. Y1A1 GOLD. in support of upcoming cosmological analyses. The Y1A1 GOLD data set is assembled from multiple epochs of DES imaging and consists of calibrated photometric zero-points. object catalogs. and ancillary data products—eg. maps of survey depth and observing conditions. star–galaxy classification. and photometric redshift estimates—that are necessary for accurate cosmological analyses. The Y1A1 GOLD wide-area object catalog consists of  million objects detected in co-added images covering  in the DES grizY filters. The 10σ limiting magnitude for galaxies is . . . . and . Photometric calibration of Y1A1 GOLD was performed by combining nightly zero-point solutions with stellar locus regression. and the absolute calibration …,True,ieqpr_kAAAAJ:fPk4N6BV_jEC,190,https://iopscience.iop.org/article/10.3847/1538-4365/aab4f5/meta,11710371726367693246,/scholar?cites=11710371726367693246,,,https://iopscience.iop.org/article/10.3847/1538-4365/aab4f5/pdf,0,0,0
1276419,VIS: A system for verification and synthesis,1996,Robert K Brayton and Gary D Hachtel and Alberto Sangiovanni-Vincentelli and Fabio Somenzi and Adnan Aziz and Szu-Tsung Cheng and Stephen Edwards and Sunil Khatri and Yuji Kukimoto and Abelardo Pardo and Shaz Qadeer and Rajeev K Ranjan and Shaker Sarwary and Thomas R Staple and Gitanjali Swamy and Tiziano Villa,,,,428-432,Springer. Berlin. Heidelberg,VIS (Verification Interacting with Synthesis) is a tool that integrates the verification. simulation. and synthesis of finite-state hardware systems. It uses a Verilog front end and supports fair CTL model checking. language emptiness checking. combinational and sequential equivalence checking. cycle-based simulation. and hierarchical synthesis. We designed VIS to maximize performance by using state-of-the-art algorithms. and to provide a solid platform for future research in formal verification. VIS improves upon existing verification tools by:1. providing a better programming environment. 2. providing new capabilities. mad 3.~ mproving performance.,True,EqIVfYcAAAAJ:u5HHmVD_uO8C,925,https://link.springer.com/content/pdf/10.1007/3-540-61474-5_95.pdf,18143852545493005782,/scholar?cites=18143852545493005782,,,https://link.springer.com/content/pdf/10.1007/3-540-61474-5_95.pdf,0,0,0
1276420,Piranha: A scalable architecture based on single-chip multiprocessing,2000,Luiz André Barroso and Kourosh Gharachorloo and Robert McNamara and Andreas Nowatzyk and Shaz Qadeer and Barton Sano and Scott Smith and Robert Stets and Ben Verghese,28,ACM SIGARCH Computer Architecture News,2,282-293,ACM,The microprocessor industry is currently struggling with higher development costs and longer design times that arise from exceedingly complex processors that are pushing the limits of instruction-level parallelism. Meanwhile. such designs are especially ill suited for important commercial applications. such as on-line transaction processing (OLTP). which suffer from large memory stall times and exhibit little instruction-level parallelism. Given that commercial applications constitute by far the most important market for high-performance servers. the above trends emphasize the need to consider alternative processor designs that specifically target such workloads. The abundance of explicit thread-level parallelism in commercial workloads. along with advances in semiconductor integration density. identify chip multiprocessing (CMP) as potentially the most promising approach for designing processors targeted at …,True,EqIVfYcAAAAJ:u-x6o8ySG0sC,756,https://dl.acm.org/doi/abs/10.1145/342001.339696,4534853946306609474,/scholar?cites=4534853946306609474,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.4002&rep=rep1&type=pdf,0,0,0
1276421,Finding and Reproducing Heisenbugs in Concurrent Programs.,2008,Madanlal Musuvathi and Shaz Qadeer and Thomas Ball and Gerard Basler and Piramanayagam Arumuga Nainar and Iulian Neamtiu,8,OSDI,,267-280,,Concurrency is pervasive in large systems. Unexpected interference among threads often results in “Heisenbugs” that are extremely difficult to reproduce and eliminate. We have implemented a tool called CHESS for finding and reproducing such bugs. When attached to a program. CHESS takes control of thread scheduling and uses efficient search techniques to drive the program through possible thread interleavings. This systematic exploration of program behavior enables CHESS to quickly uncover bugs that might otherwise have remained hidden for a long time. For each bug. CHESS consistently reproduces an erroneous execution manifesting the bug. thereby making it significantly easier to debug the problem. CHESS scales to large concurrent programs and has found numerous bugs in existing systems that had been tested extensively prior to being tested by CHESS. CHESS has been integrated into the test frameworks of many code bases inside Microsoft and is used by testers on a daily basis.,True,EqIVfYcAAAAJ:qjMakFHDy7sC,647,https://www.usenix.org/legacy/event/osdi08/tech/full_papers/musuvathi/musuvathi.pdf,17266936435279180433,/scholar?cites=17266936435279180433,,,https://www.usenix.org/legacy/event/osdi08/tech/full_papers/musuvathi/musuvathi.pdf,0,0,0
1276422,Iterative context bounding for systematic testing of multithreaded programs,2007,Madanlal Musuvathi and Shaz Qadeer,42,ACM Sigplan Notices,6,446-455,ACM,Multithreaded programs are difficult to get right because of unexpected interaction between concurrently executing threads. Traditional testing methods are inadequate for catching subtle concurrency errors which manifest themselves late in the development cycle and post-deployment. Model checking or systematic exploration of program behavior is a promising alternative to traditional testing methods. However. it is difficult to perform systematic search on large programs as the number of possible program behaviors grows exponentially with the program size. Confronted with this state-explosion problem. traditional model checkers perform iterative depth-bounded search. Although effective for message-passing software. iterative depth-bounding is inadequate for multithreaded software.This paper proposes iterative context-bounding. a new search algorithm that systematically explores the executions of a …,True,EqIVfYcAAAAJ:2osOgNQ5qMEC,526,https://dl.acm.org/doi/abs/10.1145/1273442.1250785,406956721013661054,/scholar?cites=406956721013661054,,,http://fa11.pbworks.com/w/file/fetch/45563933/chess.pdf,0,0,0
1276423,MOCHA: Modularity in model checking,1998,Rajeev Alur and Thomas A Henzinger and Freddy YC Mang and Shaz Qadeer and Sriram K Rajamani and Serdar Tasiran,,,,521-525,Springer. Berlin. Heidelberg,We describe a new interactive verification environment called MOCHA for the modular verilication of heterogeneous systems. MOCItA differs from many existing model checkers in three significant ways:,True,EqIVfYcAAAAJ:d1gkVwhDpl0C,502,https://link.springer.com/content/pdf/10.1007/BFb0028774.pdf,12421285912036126406,/scholar?cites=12421285912036126406,,,https://link.springer.com/content/pdf/10.1007/BFb0028774.pdf,0,0,0
1276424,A type and effect system for atomicity,2003,Cormac Flanagan and Shaz Qadeer,38,ACM SIGPLAN Notices,5,338-349,ACM,Ensuring the correctness of multithreaded programs is difficult. due to the potential for unexpected and nondeterministic interactions between threads. Previous work addressed this problem by devising tools for detecting race conditions. a situation where two threads simultaneously access the same data variable. and at least one of the accesses is a write. However. verifying the absence of such simultaneous-access race conditions is neither necessary nor sufficient to ensure the absence of errors due to unexpected thread interactions.We propose that a stronger non-interference property is required. namely atomicity. Atomic methods can be assumed to execute serially. without interleaved steps of other threads. Thus. atomic methods are amenable to sequential reasoning techniques. which significantly simplifies both formal and informal reasoning about program correctness.This paper presents a type system for …,True,EqIVfYcAAAAJ:9yKSN-GCB0IC,471,https://dl.acm.org/doi/abs/10.1145/780822.781169,9244724306068912950,/scholar?cites=9244724306068912950,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.9708&rep=rep1&type=pdf,0,0,0
1276425,Context-bounded model checking of concurrent software,2005,Shaz Qadeer and Jakob Rehof,,,,93-107,Springer. Berlin. Heidelberg,The interaction among concurrently executing threads of a program results in insidious programming errors that are difficult to reproduce and fix. Unfortunately. the problem of verifying a concurrent boolean program is undecidable [24]. In this paper. we prove that the problem is decidable. even in the presence of unbounded parallelism. if the analysis is restricted to executions in which the number of context switches is bounded by an arbitrary constant. Restricting the analysis to executions with a bounded number of context switches is unsound. However. the analysis can still discover intricate bugs and is sound up to the bound since within each context. a thread is fully explored for unbounded stack depth. We present an analysis of a real concurrent system by the ZING model checker which demonstrates that the ability to model check with arbitrary but fixed context bound in the presence of unbounded …,True,EqIVfYcAAAAJ:UeHWp8X0CEIC,450,https://link.springer.com/chapter/10.1007/978-3-540-31980-1_7,7048035839845318982,/scholar?cites=7048035839845318982,,,https://link.springer.com/content/pdf/10.1007/978-3-540-31980-1_7.pdf,0,0,0
1276426,Predicate abstraction for software verification,2002,Cormac Flanagan and Shaz Qadeer,,,,191-202,,Software verification is an important and difficult problem. Many static checking techniques for software require annotations from the programmer in the form of method specifications and loop invariants. This annotation overhead. particularly of loop invariants. is a significant hurdle in the acceptance of static checking. We reduce the annotation burden by inferring loop invariants automatically. Our method is based on predicate abstraction. an abstract interpretation technique in which the abstract domain is constructed from a given set of predicates over program variables. A novel feature of our approach is that it infers universally-quantified loop invariants. which are crucial for verifying programs that manipulate unbounded data such as arrays. We present heuristics for generating appropriate predicates for each loop automatically; the programmer can specify additional predicates as well. We also present an efficient …,True,EqIVfYcAAAAJ:zYLM7Y9cAGgC,362,https://dl.acm.org/doi/abs/10.1145/503272.503291,15219658017991477770,/scholar?cites=15219658017991477770,,,https://www.researchgate.net/profile/Shaz_Qadeer/publication/220997569_Predicate_abstraction_for_software_verification/links/00b49524c1b8ebceaf000000.pdf,0,0,0
1276427,You assume. we guarantee: Methodology and case studies,1998,Thomas A Henzinger and Shaz Qadeer and Sriram K Rajamani,,,,440-451,Springer. Berlin. Heidelberg,Assume-guarantee reasoning has long been advertised as an important method for decomposing proof obligations in system verification. Refinement mappings (homomorphisms) have long been advertised as an important method for solving the language-inclusion problem in practice. When confronted with large verification problems. we therefore attempted to make use of both techniques. We soon found that rather than offering instant solutions. the success of assume-guarantee reasoning depends critically on the construction of suitable abstraction modules. and the success of refinement checking depends critically on the construction of suitable witness modules. Moreover. as abstractions need to be witnessed. and witnesses abstracted. the process must be iterated. We present here the main lessons we learned from our experiments. in limn of a systematic and structured discipline for the compositional …,True,EqIVfYcAAAAJ:IjCSPb-OGe4C,301,https://link.springer.com/chapter/10.1007/BFb0028765,11941043180373593253,/scholar?cites=11941043180373593253,,,https://link.springer.com/content/pdf/10.1007/BFb0028765.pdf,0,0,0
1276428,Goldilocks: a race and transaction-aware java runtime,2007,Tayfun Elmas and Shaz Qadeer and Serdar Tasiran,42,ACM SIGPLAN Notices,6,245-255,ACM,Data races often result in unexpected and erroneous behavior. In addition to causing data corruption and leading programs to crash. the presence of data races complicates the semantics of an execution which might no longer be sequentially consistent. Motivated by these observations. we have designed and implemented a Java runtime system that monitors program executions and throws a DataRaceException when a data race is about to occur. Analogous to other runtime exceptions. the DataRaceException provides two key benefits. First. accesses causing race conditions are interruptedand handled before they cause errors that may be difficult to diagnose later. Second. if no DataRaceException is thrown in an execution. it is guaranteed to be sequentially consistent. This strong guarantee helps to rule out many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException …,True,EqIVfYcAAAAJ:WF5omc3nYNoC,277,https://dl.acm.org/doi/abs/10.1145/1273442.1250762,1413059359217586461,/scholar?cites=1413059359217586461,,,http://www.cs.purdue.edu/homes/xyzhang/fall07/Papers/goldilock.pdf,0,0,0
1276429,KISS: keep it simple and sequential,2004,Shaz Qadeer and Dinghao Wu,39,ACM sigplan notices,6,14-24,ACM,The design of concurrent programs is error-prone due to the interaction between concurrently executing threads. Traditional automated techniques for finding errors in concurrent programs. such as model checking. explore all possible thread interleavings. Since the number of thread interleavings increases exponentially with the number of threads. such analyses have high computational complexity. In this paper. we present a novel analysis technique for concurrent programs that avoids this exponential complexity. Our analysis transforms a concurrent program into a sequential program that simulates the execution of a large subset of the behaviors of the concurrent program. The sequential program is then analyzed by a tool that only needs to understand the semantics of sequential execution. Our technique never reports false errors but may miss errors. We have implemented the technique in KISS. an automated …,True,EqIVfYcAAAAJ:Y0pCki6q_DkC,267,https://dl.acm.org/doi/abs/10.1145/996893.996845,4232488371842694106,/scholar?cites=4232488371842694106,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.244&rep=rep1&type=pdf,0,0,0
1276430,Patterns in property specifications for finite-state verification,1999,Matthew B Dwyer and George S Avrunin and James C Corbett,,,,411-420,,Despite the automation. users of finite-state verification tools still must be able to specify the system requirements in the specification language of the tool. This is more challenging than it might at first appear. For example. consider the following requirement for an elevator: Between the time an elevator is called at a floor and the time it opens its doors at that floor. the elevator can arrive at that floor’at most twice. To verify this property with a linear temporal logic (LTL) model checker. a developer would have to translate this informal requirement into the following LTL formula: q ((cal1 A Oopen)+,True,-ZRKCcEAAAAJ:u-x6o8ySG0sC,1844,https://dl.acm.org/doi/pdf/10.1145/302405.302672,16407565335377436475,/scholar?cites=16407565335377436475,,,https://www.academia.edu/download/8100230/p411-dwyer.pdf,0,0,0
1276431,Bandera: Extracting finite-state models from Java source code,2000,James C Corbett and Matthew B Dwyer and John Hatcliff and Shawn Laubach and Corina S Pasareanu and Hongjun Zheng,,,,439-448,IEEE,Finite-state verification techniques. such as model checking. have shown promise as a cost-effective means for finding defects in hardware designs. To date. the application of these techniques to software has been hindered by several obstacles. Chief among these is the problem of constructing a finite-state model that approximates the executable behavior of the software system of interest. Current best-practice involves hand construction of models which is expensive (prohibitive for all but the smallest systems). prone to errors (which can result in misleading verification results). and difficult to optimize (which is necessary to combat the exponential complexity of verification algorithms). The authors describe an integrated collection of program analysis and transformation components. called Bandera. that enables the automatic extraction of safe. compact finite-state models from program source code. Bandera takes …,True,-ZRKCcEAAAAJ:u5HHmVD_uO8C,1513,https://ieeexplore.ieee.org/abstract/document/870434/,6086026751177749156,/scholar?cites=6086026751177749156,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.47.1233&rep=rep1&type=pdf,0,0,0
1276432,Property specification patterns for finite-state verification,1998,Matthew B Dwyer and George S Avrunin and James C Corbett,,,,7-15,,Finite-state verification(eg. model checking) provides a powerful means to detect errors that are often subtle and difficult to reproduce. Nevertheless. the transition of this technology from research to practice has been slow. While there are a number of potential causes for reluctance in adopting such formal methods in practice. we believe that a primary cause rests with the fact that practitioners are unfamiliar with specification processes. notations. and strategies. Recent years have seen growing success in leveraging experience with design and coding patterns. We propose a pattern-based approach to the presentation. codification and reuse of property specifications for finite-state verification.,True,-ZRKCcEAAAAJ:d1gkVwhDpl0C,644,https://dl.acm.org/doi/pdf/10.1145/298595.298598,4168552404370141175,/scholar?cites=4168552404370141175,,,https://www.researchgate.net/profile/George_Avrunin/publication/2593589_Property_Specification_Patterns_for_Finite-State_Verification/links/0c96052c811687d4a8000000.pdf,0,0,0
1276433,Constructing interaction test suites for highly-configurable systems in the presence of constraints: A greedy approach,2008,Myra B Cohen and Matthew B Dwyer and Jiangfan Shi,34,IEEE Transactions on Software Engineering,5,633-650,IEEE,Researchers have explored the application of combinatorial interaction testing (CIT) methods to construct samples to drive systematic testing of software system configurations. Applying CIT to highly-configurable software systems is complicated by the fact that. in many such systems. there are constraints between specific configuration parameters that render certain combinations invalid. Many CIT algorithms lack a mechanism to avoid these. In recent work. automated constraint solving methods have been combined with search-based CIT construction methods to address the constraint problem with promising results. However. these techniques can incur a non-trivial overhead. In this paper. we build upon our previous work to develop a family of greedy CIT sample generation algorithms that exploit calculations made by modern Boolean satisfiability (SAT) solvers to prune the search space of the CIT problem. We …,True,-ZRKCcEAAAAJ:M3ejUd6NZC8C,342,https://ieeexplore.ieee.org/abstract/document/4564473/,3338963277806950958,/scholar?cites=3338963277806950958,,,,0,0,0
1276434,Bogor: an extensible and highly-modular software model checking framework,2003,Matthew B Dwyer and John Hatcliff,28,ACM SIGSOFT Software Engineering Notes,5,267-276,ACM,Model checking is emerging as a popular technology for reasoning about behavioral properties of a wide variety of software artifacts including: requirements models. architectural descriptions. designs. implementations. and process models. The complexity of model checking is well-known. yet cost-effective analyses have been achieved by exploiting. for example. naturally occurring abstractions and semantic properties of a target software artifact. semantic properties of target software artifacts. Adapting a model checking tool to exploit this kind of domain knowledge often requires in-depth knowledge of the tool's implementation.We believe that with appropriate tool support. domain experts will be able to develop efficient model checking-based analyses for a variety of software-related models. To explore this hypothesis. we have developed Bogor. a model checking framework with an extensible input language for …,True,-ZRKCcEAAAAJ:9yKSN-GCB0IC,332,https://dl.acm.org/doi/abs/10.1145/949952.940107,2471707337771431322,/scholar?cites=2471707337771431322,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.5816&rep=rep1&type=pdf,0,0,0
1276435,Differential symbolic execution,2008,Suzette Person and Matthew B Dwyer and Sebastian Elbaum and Corina S Pǎsǎreanu,,,,226-237,,Detecting and characterizing the effects of software changes is a fundamental component of software maintenance. Version differencing information can be used to perform version merging. infer change characteristics. produce program documentation. and guide program re-validation. Existing techniques for characterizing code changes. however. are imprecise leading to unnecessary maintenance efforts.,True,-ZRKCcEAAAAJ:hqOjcs7Dif8C,295,https://dl.acm.org/doi/abs/10.1145/1453101.1453131,452046246888046618,/scholar?cites=452046246888046618,,,https://pdfs.semanticscholar.org/b548/d84703792f2ec6a030b978a3719cc5ea57b5.pdf,0,0,0
1276436,Interaction testing of highly-configurable systems in the presence of constraints,2007,Myra B Cohen and Matthew B Dwyer and Jiangfan Shi,,,,129-139,,Combinatorial interaction testing (CIT) is a method to sample configurations of a software system systematically for testing. Many algorithms have been developed that create CIT samples. however few have considered the practical concerns that arise when adding constraints between combinations of options. In this paper. we survey constraint handling techniques in existing algorithms and discuss the challenges that they present. We examine two highly-configurable software systems to quantify the nature of constraints in real systems. We then present a general constraint representation and solving technique that can be integrated with existing CIT algorithms and compare two constraint-enhanced algorithm implementations with existing CIT tools to demonstrate feasibility.,True,-ZRKCcEAAAAJ:8k81kl-MbHgC,286,https://dl.acm.org/doi/abs/10.1145/1273463.1273482,2846837229658351040,/scholar?cites=2846837229658351040,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.4822&rep=rep1&type=pdf,0,0,0
1276437,Slicing software for model construction,2000,John Hatcliff and Matthew B Dwyer and Hongjun Zheng,13,Higher-order and symbolic computation,4,315-353,Kluwer Academic Publishers,Applying finite-state verification techniques (e.g.. model checking) to software requires that program source code be translated to a finite-state transition system that safely models program behavior. Automatically checking such a transition system for a correctness property is typically very costly. thus it is necessary to reduce the size of the transition system as much as possible. In fact. it is often the case that much of a program's source code is irrelevant for verifying a given correctness property.In this paper. we apply program slicing techniques to remove automatically such irrelevant code and thus reduce the size of the corresponding transition system models. We give a simple extension of the classical slicing definition. and prove its safety with respect to model checking of linear temporal logic (LTL) formulae. We discuss how this slicing strategy fits into a general methodology for deriving effective …,True,-ZRKCcEAAAAJ:IjCSPb-OGe4C,271,https://link.springer.com/article/10.1023/A:1026599015809,9490639040137149476,/scholar?cites=9490639040137149476,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43.3170&rep=rep1&type=pdf,0,0,0
1276438,Cadena: An integrated development. analysis. and verification environment for component-based systems,2003,John Hatcliff and Xinghua Deng and Matthew B Dwyer and Georg Jung and Venkatesh Prasad Ranganath,,,,160-172,IEEE,The use of component models such as Enterprise Java Beans and the CORBA Component Model (CCM) in application development is expanding rapidly. Even in real-time safety/mission-critical domains. component-based development is beginning to take hold as a mechanism for incorporating non-functional aspects such as real-time. quality-of-service. and distribution. To form an effective basis for development of such systems. we believe that support for reasoning about correctness properties of component-based designs is essential. In this paper. we present Cadena - an integrated environment for building and modeling CCM systems. Cadena provides facilities for defining component types using CCM IDL. specifying dependency information and transition System semantics for these types. assembling systems from CCM components. visualizing various dependence relationships between components …,True,-ZRKCcEAAAAJ:2osOgNQ5qMEC,258,https://ieeexplore.ieee.org/abstract/document/1201197/,16889452498791717545,/scholar?cites=16889452498791717545,,,http://people.cis.ksu.edu/~hatcliff/Papers/cadena.pdf,0,0,0
1276439,Data flow analysis for verifying properties of concurrent programs,1994,Matthew B Dwyer and Lori A Clarke,19,ACM SIGSOFT Software Engineering Notes,5,62-75,ACM,In this paper we present an approach. based on data flow analysis. that can provide cost-effective analysis of concurrent programs with respect to explicitly stated correctness properties. Using this approach. a developer specifies a property of a concurrent program as a pattern of selected program events and asks the analysis to verify that all or no program executions satisfy the given property. We have developed a family of polynomial-time. conservative data flow anlysis algorithms that support reasoning about these questions. To overcome the traditional inaccuracies of static analysis. we have also developed a range of techniques for improving the accuracy of the analysis results. One strength of our approach is the flexibility allowed in choosing and combining these techniques so as to increase accuracy without making analysis time impractical.We have implemented a prototype toolset that automates the …,True,-ZRKCcEAAAAJ:qjMakFHDy7sC,239,https://dl.acm.org/doi/abs/10.1145/195274.195295,7932496702137348754,/scholar?cites=7932496702137348754,,,https://web.cs.umass.edu/publication/docs/1994/UM-CS-1994-045.pdf,0,0,0
1276440,Evaluating improvements to a meta-heuristic search for constrained interaction testing,2011,Brady J Garvin and Myra B Cohen and Matthew B Dwyer,16,Empirical Software Engineering,1,61-102,Springer US,Combinatorial interaction testing (CIT) is a cost-effective sampling technique for discovering interaction faults in highly-configurable systems. Constrained CIT extends the technique to situations where some features cannot coexist in a configuration. and is therefore more applicable to real-world software. Recent work on greedy algorithms to build CIT samples now efficiently supports these feature constraints. But when testing a single system configuration is expensive. greedy techniques perform worse than meta-heuristic algorithms. because greedy algorithms generally need larger samples to exercise the same set of interactions. On the other hand. current meta-heuristic algorithms have long run times when feature constraints are present. Neither class of algorithm is suitable when both constraints and the cost of testing configurations are important factors. Therefore. we reformulate one meta-heuristic …,True,-ZRKCcEAAAAJ:70eg2SAEIzsC,224,https://link.springer.com/article/10.1007/s10664-010-9135-7,18273434525456844393,/scholar?cites=18273434525456844393,,,,0,0,0
1276441,Minimizing multimodal functions of continuous variables with the “simulated annealing” algorithm—Corrigenda for this article is available here,1987,Angelo Corana and Michele Marchesi and Claudio Martini and Sandro Ridella,13,ACM Transactions on Mathematical Software (TOMS),3,262-280,ACM,A new global optimization algorithm for functions of continuous variables is presented. derived from the “Simulated Annealing” algorithm recently introduced in combinatorial optimization.The algorithm is essentially an iterative random search procedure with adaptive moves along the coordinate directions. It permits uphill moves under the control of a probabilistic criterion. thus tending to avoid the first local minima encountered.The algorithm has been tested against the Nelder and Mead simplex method and against a version of Adaptive Random Search. The test functions were Rosenbrock valleys and multiminima functions in 2.4. and 10 dimensions.The new method proved to be more reliable than the others. being always able to find the optimum. or at least a point very close to it. It is quite costly in term of function evaluations. but its cost can be predicted in advance. depending only slightly on the starting point.,True,TROFGlO4ftgC:u5HHmVD_uO8C,2024,https://dl.acm.org/doi/abs/10.1145/29380.29864,3146423216024810472,/scholar?cites=3146423216024810472,,,https://www.researchgate.net/profile/Angelo_Corana/publication/220492522_Minimizing_Multimodal_Functions_Of_Continuous-Variables_with_Simulated_Annealing_Algorithm/links/00b7d5163cb37c30f9000000/Minimizing-Multimodal-Functions-Of-Continuous-Variables-with-Simulated-Annealing-Algorithm.pdf,0,0,0
1276442,Scaling and criticality in a stochastic multi-agent model of a financial market,1999,Thomas Lux and Michele Marchesi,397,Nature,6719,498-500,Nature Publishing Group,Financial prices have been found to exhibit some universal characteristics 1. 2. 3. 4. 5. 6 that resemble the scaling laws characterizing physical systems in which large numbers of units interact. This raises the question of whether scaling in finance emerges in a similar way—from the interactions of a large ensemble of market participants. However. such an explanation is in contradiction to the prevalent ‘efficient market hypothesis’7 in economics. which assumes that the movements of financial prices are an immediate and unbiased reflection of incoming news about future earning prospects. Within this hypothesis. scaling in price changes would simply reflect similar scaling in the ‘input’signals that influence them. Here we describe a multi-agent model of financial markets which supports the idea that scaling arises from mutual interactions of participants. Although the ‘news arrival process’ in our model lacks both …,True,TROFGlO4ftgC:u-x6o8ySG0sC,1811,https://www.nature.com/articles/17290,5434554980191657320,/scholar?cites=5434554980191657320,,,https://www.researchgate.net/profile/Michele_Marchesi/publication/4923736_Scaling_and_Criticality_in_a_Stochastic_Multi-Agent_Model_of_a_Financial_Market/links/02e7e517fc645a675b000000.pdf,0,0,0
1276443,Volatility clustering in financial markets: a microsimulation of interacting agents,2000,Thomas Lux and Michele Marchesi,3,International journal of theoretical and applied finance,04,675-702,World Scientific Publishing Company,The finding of clustered volatility and ARCH effects is ubiquitous in financial data. This paper presents a possible explanation for this phenomenon within a multi-agent framework of speculative activity. In the model. both chartist and fundamentalist strategies are considered with agents switching between both behavioural variants according to observed differences in pay-offs. Price changes are brought about by a market maker reacting to imbalances between demand and supply. Most of the time. a stable and efficient market results. However. its usual tranquil performance is interspersed by sudden transient phases of destabilisation. An outbreak of volatility occurs if the fraction of agents using chartist techniques surpasses a certain threshold value. but such phases are quickly brought to an end by stabilising tendencies. Formally. this pattern can be understood as an example of a new type of dynamic behaviour …,True,TROFGlO4ftgC:d1gkVwhDpl0C,916,https://www.worldscientific.com/doi/abs/10.1142/S0219024900000826,727976558947981946,/scholar?cites=727976558947981946,,,https://www.researchgate.net/profile/Michele_Marchesi/publication/45122249_Volatility_Clustering_in_Financial_Markets_A_MicroSimulation_of_Interacting_Agents/links/02e7e517fc645dc94c000000.pdf,0,0,0
1276444,A hybrid genetic-neural architecture for stock indexes forecasting,2005,Giuliano Armano and Michele Marchesi and Andrea Murru,170,Information sciences,1,3-33,Elsevier,In this paper. a new approach for time series forecasting is presented. The forecasting activity results from the interaction of a population of experts. each integrating genetic and neural technologies. An expert of this kind embodies a genetic classifier designed to control the activation of a feedforward artificial neural network for performing a locally scoped forecasting activity. Genetic and neural components are supplied with different information: The former deal with inputs encoding information retrieved from technical analysis. whereas the latter process other relevant inputs. in particular past stock prices. To investigate the performance of the proposed approach in response to real data. a stock market forecasting system has been implemented and tested on two stock market indexes. allowing for account realistic trading commissions. The results pointed to the good forecasting capability of the approach. which …,True,TROFGlO4ftgC:IjCSPb-OGe4C,361,https://www.sciencedirect.com/science/article/pii/S002002550300433X,7380597970675328627,/scholar?cites=7380597970675328627,,,,0,0,0
1276445,Agent-based simulation of a financial market,2001,Marco Raberto and Silvano Cincotti and Sergio M Focardi and Michele Marchesi,299,Physica A: Statistical Mechanics and its Applications,1-2,319-327,North-Holland,This paper introduces an agent-based artificial financial market in which heterogeneous agents trade one single asset through a realistic trading mechanism for price formation. Agents are initially endowed with a finite amount of cash and a given finite portfolio of assets. There is no money-creation process; the total available cash is conserved in time. In each period. agents make random buy and sell decisions that are constrained by available resources. subject to clustering. and dependent on the volatility of previous periods. The model proposed herein is able to reproduce the leptokurtic shape of the probability density of log price returns and the clustering of volatility. Implemented using extreme programming and object-oriented technology. the simulator is a flexible computational experimental facility that can find applications in both academic and industrial research projects.,True,TROFGlO4ftgC:9yKSN-GCB0IC,330,https://www.sciencedirect.com/science/article/pii/S0378437101003120,318863259876365095,/scholar?cites=318863259876365095,,,https://arxiv.org/pdf/cond-mat/0103600,0,0,0
1276446,Power-laws in a large object-oriented software system,2007,Giulio Concas and Michele Marchesi and Sandro Pinna and Nicola Serra,33,IEEE Transactions on Software Engineering,10,687-708,IEEE,We present a comprehensive study of an implementation of the Smalltalk object oriented system. one of the first and purest object-oriented programming environment. searching for scaling laws in its properties. We study ten system properties. including the distributions of variable and method names. inheritance hierarchies. class and method sizes. system architecture graph. We systematically found Pareto - or sometimes log-normal - distributions in these properties. This denotes that the programming activity. even when modeled from a statistical perspective. can in no way be simply modeled as a random addition of independent increments with finite variance. but exhibits strong organic dependencies on what has been already developed. We compare our results with similar ones obtained for large Java systems. reported in the literature or computed by ourselves for those properties never studied before. showing …,True,TROFGlO4ftgC:zYLM7Y9cAGgC,297,https://ieeexplore.ieee.org/abstract/document/4302780/,9630095114325371984,/scholar?cites=9630095114325371984,,,,0,0,0
1276447,Blockchain-oriented software engineering: challenges and new directions,2017,Simone Porru and Andrea Pinna and Michele Marchesi and Roberto Tonelli,,,,169-171,IEEE,In this work. we acknowledge the need for software engineers to devise specialized tools and techniques for blockchain-oriented software development. Ensuring effective testing activities. enhancing collaboration in large teams. and facilitating the development of smart contracts all appear as key factors in the future of blockchain-oriented software development.,True,TROFGlO4ftgC:nVrZBo8bIpAC,233,https://ieeexplore.ieee.org/abstract/document/7965292/,17127497357936760395,/scholar?cites=17127497357936760395,,,https://arxiv.org/pdf/1702.05146,0,0,0
1276448,OOA metrics for the Unified Modeling Language,1998,Michele Marchesi,,,,67-73,IEEE,UML is the emerging standard for expressing OOA/OOD models. New metrics for object oriented analysis models are introduced. and existing ones are adapted to the entities and concepts of UML. In particular. these metrics concern UML use case diagrams and class diagrams used during the OOA phase. The proposed metrics are intended to allow an early estimate of development efforts. implementation time and cost of the system under development. and to measure its object orientedness and quality since the beginning of the analysis phase. The proposed metric suite is described in detail. and its relations with proposed metrics found in the literature are highlighted. Some measurements on three software projects are given.,True,TROFGlO4ftgC:qjMakFHDy7sC,217,https://ieeexplore.ieee.org/abstract/document/665739/,9277546238715782638,/scholar?cites=9277546238715782638,,,https://www.researchgate.net/profile/Michele_Marchesi/publication/3740735_OOA_metrics_for_the_Unified_Modeling_Language/links/53ff4e090cf24c81027d6251.pdf,0,0,0
1276449,Applications of simulated annealing for the design of special digital filters,1992,Nevio Benvenuto and Michele Marchesi and Aurelio Uncini,40,IEEE Transactions on Signal Processing,2,323-332,,This paper describes the salient features of using a simulated annealing (SA) algorithm in the context of designing digital filters with coefficient values expressed as the sum of power of two. A procedure for linear phase digital filter design. using this algorithm. is first presented and tested. yielding results as good as known optimal methods. The algorithm is then applied to the design of Nyquist filters. optimizing at the same time both frequency response and intersymbol interference. and to the design of cascade form FIR filters. Although SA is not a solution to all design problems. and is computationally very expensive. it may be an important method for designing special digital filters where numerous or conflicting constraints are present.,True,TROFGlO4ftgC:2osOgNQ5qMEC,203,https://www.researchgate.net/profile/Michele_Marchesi/publication/3314304_Applications_of_simulated_annealing_for_the_design_of_special_digital_filters/links/02e7e517fc64663587000000/Applications-of-simulated-annealing-for-the-design-of-special-digital-filters.pdf,1245368221941908743,/scholar?cites=1245368221941908743,,,https://www.researchgate.net/profile/Michele_Marchesi/publication/3314304_Applications_of_simulated_annealing_for_the_design_of_special_digital_filters/links/02e7e517fc64663587000000/Applications-of-simulated-annealing-for-the-design-of-special-digital-filters.pdf,0,0,0
1276450,Fast neural networks without multipliers,1993,Michele Marchesi and Gianni Orlandi and Francesco Piazza and Aurelio Uncini,4,IEEE transactions on Neural Networks,1,53-62,IEEE,Multilayer perceptrons (MLPs) with weight values restricted to powers of two or sums of powers of two are introduced. In a digital implementation. these neural networks do not need multipliers but only shift registers when computing in forward mode. thus saving chip area and computation time. A learning procedure. based on backpropagation. is presented for such neural networks. This learning procedure requires full real arithmetic and therefore must be performed offline. Some test cases are presented. concerning MLPs with hidden layers of different sizes. on pattern recognition problems. Such tests demonstrate the validity and the generalization capability of the method and give some insight into the behavior of the learning algorithm.< >,True,TROFGlO4ftgC:Y0pCki6q_DkC,165,https://ieeexplore.ieee.org/abstract/document/182695/,12467742684075184048,/scholar?cites=12467742684075184048,,,http://www.uncini.com/research_activity/pdf/034_ieee_tr_nn4_93.pdf,0,0,0
1276451,Banking on blockchain: Costs savings thanks to the blockchain technology,2017,Luisanna Cocco and Andrea Pinna and Michele Marchesi,9,Future internet,3,25,Multidisciplinary Digital Publishing Institute,This paper looks at the challenges and opportunities of implementing blockchain technology across banking. providing food for thought about the potentialities of this disruptive technology. The blockchain technology can optimize the global financial infrastructure. achieving sustainable development. using more efficient systems than at present. In fact. many banks are currently focusing on blockchain technology to promote economic growth and accelerate the development of green technologies. In order to understand the potential of blockchain technology to support the financial system. we studied the actual performance of the Bitcoin system. also highlighting its major limitations. such as the significant energy consumption due to the high computing power required. and the high cost of hardware. We estimated the electrical power and the hash rate of the Bitcoin network. over time. and. in order to evaluate the efficiency of the Bitcoin system in its actual operation. we defined three quantities:“economic efficiency”.“operational efficiency”. and “efficient service”. The obtained results show that by overcoming the disadvantages of the Bitcoin system. and therefore of blockchain technology. we could be able to handle financial processes in a more efficient way than under the current system. View Full-Text,True,TROFGlO4ftgC:Ak0FvsSvgGUC,161,https://www.mdpi.com/1999-5903/9/3/25,14488817869913448397,/scholar?cites=14488817869913448397,,,https://www.mdpi.com/1999-5903/9/3/25/pdf,0,0,0
1276452,The Spec# programming system: An overview,2004,Mike Barnett and K Rustan M Leino and Wolfram Schulte,,,,49-69,Springer. Berlin. Heidelberg,The Spec# programming system is a new attempt at a more cost effective way to develop and maintain high-quality software. This paper describes the goals and architecture of the Spec# programming system. consisting of the object-oriented Spec# programming language. the Spec# compiler. and the Boogie static program verifier. The language includes constructs for writing specifications that capture programmer intentions about how methods and data are to be used. the compiler emits run-time checks to enforce these specifications. and the verifier can check the consistency between a program and its specifications.,True,hQOpWucAAAAJ:u5HHmVD_uO8C,1359,https://link.springer.com/chapter/10.1007/978-3-540-30569-9_3,17183232857152634936,/scholar?cites=17183232857152634936,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.933.8240&rep=rep1&type=pdf,0,0,0
1276453,VCC: A practical system for verifying concurrent C,2009,Ernie Cohen and Markus Dahlweid and Mark Hillebrand and Dirk Leinenbach and Michał Moskal and Thomas Santen and Wolfram Schulte and Stephan Tobies,,,,23-42,Springer. Berlin. Heidelberg,VCC is an industrial-strength verification environment for low-level concurrent system code written in C. VCC takes a program (annotated with function contracts. state assertions. and type invariants) and attempts to prove the correctness of these annotations. It includes tools for monitoring proof attempts and constructing partial counterexample executions for failed proofs. This paper motivates VCC. describes our verification methodology. describes the architecture of VCC. and reports on our experience using VCC to verify the Microsoft Hyper-V hypervisor.,True,hQOpWucAAAAJ:d1gkVwhDpl0C,731,https://link.springer.com/chapter/10.1007/978-3-642-03359-9_2,6802795235990559087,/scholar?cites=6802795235990559087,,,https://pdfs.semanticscholar.org/0387/5a7ec6e6f29622c8a383fe579af9e8bd35bb.pdf,0,0,0
1276454,Verification of Object-Oriented Programs with Invariants.,2004,Michael Barnett and Robert DeLine and Manuel Fähndrich and K Rustan M Leino and Wolfram Schulte,3,J. Object Technol.,6,27-56,,An object invariant defines what it means for an object’s data to be in a consistent state. Object invariants are central to the design and correctness of objectoriented programs. This paper defines a programming methodology for using object invariants. The methodology. which enriches a program’s state space to express when each object invariant holds. deals with owned object components. ownership transfer. and subclassing. and is expressive enough to allow many interesting object-oriented programs to be specified and verified. Lending itself to sound modular verification. the methodology also provides a solution to the problem of determining what state a method is allowed to modify.,True,hQOpWucAAAAJ:u-x6o8ySG0sC,431,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.9510&rep=rep1&type=pdf,1435794559544655192,/scholar?cites=1435794559544655192,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.108.9510&rep=rep1&type=pdf,0,0,0
1276455,Symstra: A framework for generating object-oriented unit tests using symbolic execution,2005,Tao Xie and Darko Marinov and Wolfram Schulte and David Notkin,,,,365-381,Springer. Berlin. Heidelberg,Object-oriented unit tests consist of sequences of method invocations. Behavior of an invocation depends on the method’s arguments and the state of the receiver at the beginning of the invocation. Correspondingly. generating unit tests involves two tasks: generating method sequences that build relevant receiver-object states and generating relevant method arguments. This paper proposes Symstra. a framework that achieves both test generation tasks using symbolic execution of method sequences with symbolic arguments. The paper defines symbolic states of object-oriented programs and novel comparisons of states. Given a set of methods from the class under test and a bound on the length of sequences. Symstra systematically explores the object-state space of the class and prunes this exploration based on the state comparisons. Experimental results show that Symstra generates unit tests that …,True,hQOpWucAAAAJ:9yKSN-GCB0IC,353,https://link.springer.com/chapter/10.1007/978-3-540-31980-1_24,18300782633464611726,/scholar?cites=18300782633464611726,,,https://link.springer.com/content/pdf/10.1007/978-3-540-31980-1_24.pdf,0,0,0
1276456,The design of a task parallel library,2009,Daan Leijen and Wolfram Schulte and Sebastian Burckhardt,44,Acm Sigplan Notices,10,227-242,ACM,The Task Parallel Library (TPL) is a library for .NET that makes it easy to take advantage of potential parallelism in a program. The library relies heavily on generics and delegate expressions to provide custom control structures expressing structured parallelism such as map-reduce in user programs. The library implementation is built around the notion of a task as a finite CPU-bound computation. To capture the ubiquitous apply-to-all pattern the library also introduces the novel concept of a replicable task. Tasks and replicable tasks are assigned to threads using work stealing techniques. but unlike traditional implementations based on the THE protocol. the library uses a novel data structure called a 'duplicating queue'. A surprising feature of duplicating queues is that they have sequentially inconsistent behavior on architectures with weak memory models. but capture this non-determinism in a benign way by …,True,hQOpWucAAAAJ:zYLM7Y9cAGgC,341,https://dl.acm.org/doi/abs/10.1145/1639949.1640106,9440454940660307037,/scholar?cites=9440454940660307037,,,https://www.microsoft.com/en-us/research/wp-content/uploads/2009/09/TheDesignOfATaskParallelLibraryoopsla2009.pdf,0,0,0
1276457,Model-based testing of object-oriented reactive systems with Spec Explorer,2008,Margus Veanes and Colin Campbell and Wolfgang Grieskamp and Wolfram Schulte and Nikolai Tillmann and Lev Nachmanson,,,,39-76,Springer. Berlin. Heidelberg,Testing is one of the costliest aspects of commercial software development. Model-based testing is a promising approach addressing these deficits. At Microsoft. model-based testing technology developed by the Foundations of Software Engineering group in Microsoft Research has been used since 2003. The second generation of this tool set. Spec Explorer. deployed in 2004. is now used on a daily basis by Microsoft product groups for testing operating system components. .NET framework components and other areas. This chapter provides a comprehensive survey of the concepts of the tool and their foundations.,True,hQOpWucAAAAJ:Tyk-4Ss8FVUC,335,https://link.springer.com/chapter/10.1007/978-3-540-78917-8_2,2523472452790634568,/scholar?cites=2523472452790634568,,,https://www.microsoft.com/en-us/research/wp-content/uploads/2008/01/bookChapterOnSE.pdf,0,0,0
1276458,Parameterized unit tests,2005,Nikolai Tillmann and Wolfram Schulte,30,ACM SIGSOFT Software Engineering Notes,5,253-262,ACM,Parameterized unit tests extend the current industry practice of using closed unit tests defined as parameterless methods. Parameterized unit tests separate two concerns: 1) They specify the external behavior of the involved methods for all test arguments. 2) Test cases can be re-obtained as traditional closed unit tests by instantiating the parameterized unit tests. Symbolic execution and constraint solving can be used to automatically choose a minimal set of inputs that exercise a parameterized unit test with respect to possible code paths of the implementation. In addition. parameterized unit tests can be used as symbolic summaries which allows symbolic execution to scale for arbitrary abstraction levels. We have developed a prototype tool which computes test cases from parameterized unit tests. We report on its first use testing parts of the .NET base class library.,True,hQOpWucAAAAJ:qjMakFHDy7sC,286,https://dl.acm.org/doi/abs/10.1145/1095430.1081749,9680204519198299025,/scholar?cites=9680204519198299025,,,https://www.researchgate.net/profile/Wolfram-Schulte/publication/221560789_Parameterized_unit_tests/links/0fcfd51083621a0508000000/Parameterized-unit-tests.pdf,0,0,0
1276459,Fitness-guided path exploration in dynamic symbolic execution,2009,Tao Xie and Nikolai Tillmann and Jonathan De Halleux and Wolfram Schulte,,,,359-368,IEEE,Dynamic symbolic execution is a structural testing technique that systematically explores feasible paths of the program under test by running the program with different test inputs to improve code coverage. To address the space-explosion issue in path exploration. we propose a novel approach called Fitnex. a search strategy that uses state-dependent fitness values (computed through a fitness function) to guide path exploration. The fitness function measures how close an already discovered feasible path is to a particular test target (e.g.. covering a not-yet-covered branch). Our new fitness-guided search strategy is integrated with other strategies that are effective for exploration problems where the fitness heuristic fails. We implemented the new approach in Pex. an automated structural testing tool developed at Microsoft Research. We evaluated our new approach by comparing it with existing search strategies. The …,True,hQOpWucAAAAJ:YsMSGLbcyi4C,279,https://ieeexplore.ieee.org/abstract/document/5270315/,17784016397009527169,/scholar?cites=17784016397009527169,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.215.4338&rep=rep1&type=pdf,0,0,0
1276460,Generating finite state machines from abstract state machines,2002,Wolfgang Grieskamp and Yuri Gurevich and Wolfram Schulte and Margus Veanes,,,,112-122,,We give an algorithm that derives a finite state machine (FSM) from a given abstract state machine (ASM) specification. This allows us to integrate ASM specs with the existing tools for test case generation from FSMs. ASM specs are executable but have typically too many. often infinitely many states. We group ASM states into finitely many hyperstates which are the nodes of the FSM. The links of the FSM are induced by the ASM state transitions.,True,hQOpWucAAAAJ:2osOgNQ5qMEC,270,https://dl.acm.org/doi/abs/10.1145/566172.566190,17642953147993667154,/scholar?cites=17642953147993667154,,,https://www.researchgate.net/profile/Yuri_Gurevich2/publication/220854477_Generating_finite_state_machines_from_abstract_state_machines/links/0fcfd5100a3f447d7f000000.pdf,0,0,0
1276461,Approximating finite domains in symbolic state exploration,2013,Nikolai Tillmann and Wolfgang Grieskamp and Wolfram Schulte,,,,,,A finite domain approximation for symbolic terms of a symbolic state is derived. given some finite domains for basic terms of the symbolic state. A method is executed recursively for symbolic sub-terms of a symbolic term. providing a domain over-approximation that can then be provided to a solver for determining a more accurate domain. The method can be applied to a wide array of system terms. including. for example. object states. arrays. and runtime types.,True,hQOpWucAAAAJ:KxtntwgDAa4C,216,https://patents.google.com/patent/US8533680B2/en,5939091356865265032,/scholar?cites=5939091356865265032,,,https://patentimages.storage.googleapis.com/ea/ec/ac/5b93ffecbb882e/US8533680.pdf,0,0,0
1276462,Specification and verification: the Spec# experience,2011,Mike Barnett and Manuel Fähndrich and K Rustan M Leino and Peter Müller and Wolfram Schulte and Herman Venter,54,Communications of the ACM,6,81-91,ACM,Can a programming language really help programmers write better programs?,True,hQOpWucAAAAJ:3fE2CSJIrl8C,192,https://dl.acm.org/doi/fullHtml/10.1145/1953122.1953145,5825508934667317049,/scholar?cites=5825508934667317049,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.228.9761&rep=rep1&type=pdf,0,0,0
1276463,Recovering documentation-to-source-code traceability links using latent semantic indexing,2003,Andrian Marcus and Jonathan I Maletic,,,,125-135,IEEE,An information retrieval technique. latent semantic indexing. is used to automatically identify traceability links from system documentation to program source code. The results of two experiments to identify links in existing software systems (i.e.. the LEDA library. and Albergate) are presented. These results are compared with other similar type experimental results of traceability link identification using different types of information retrieval techniques. The method presented proves to give good results by comparison and additionally it is a low cost. highly flexible method to apply with regards to preprocessing and/or parsing of the source code and documentation.,True,ZZiaPdYAAAAJ:d1gkVwhDpl0C,944,https://ieeexplore.ieee.org/abstract/document/1201194/,429141891997294480,/scholar?cites=429141891997294480,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.6049&rep=rep1&type=pdf,0,0,0
1276464,An information retrieval approach to concept location in source code,2004,Andrian Marcus and Andrey Sergeyev and Vaclav Rajlich and Jonathan I Maletic,,,,214-223,IEEE,Concept location identifies parts of a software system that implement a specific concept that originates from the problem or the solution domain. Concept location is a very common software engineering activity that directly supports software maintenance and evolution tasks such as incremental change and reverse engineering. This work addresses the problem of concept location using an advanced information retrieval method. Latent Semantic Indexing (LSI). LSI is used to map concepts expressed in natural language by the programmer to the relevant parts of the source code. Results of a case study on NCSA Mosaic are presented and compared with previously published results of other static methods for concept location.,True,ZZiaPdYAAAAJ:9yKSN-GCB0IC,598,https://ieeexplore.ieee.org/abstract/document/1374321/,16630744921584354567,/scholar?cites=16630744921584354567,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.8078&rep=rep1&type=pdf,0,0,0
1276465,Feature location using probabilistic ranking of methods based on execution scenarios and information retrieval,2007,Denys Poshyvanyk and Yann-Gaël Guéhéneuc and Andrian Marcus and Giuliano Antoniol and Vaclav Rajlich,33,IEEE Transactions on Software Engineering,6,420-432,IEEE,This paper recasts the problem of feature location in source code as a decision-making problem in the presence of uncertainty. The solution to the problem is formulated as a combination of the opinions of different experts. The experts in this work are two existing techniques for feature location: a scenario-based probabilistic ranking of events and an information-retrieval-based technique that uses latent semantic indexing. The combination of these two experts is empirically evaluated through several case studies. which use the source code of the Mozilla Web browser and the Eclipse integrated development environment. The results show that the combination of experts significantly improves the effectiveness of feature location as compared to each of the experts used independently,True,ZZiaPdYAAAAJ:zYLM7Y9cAGgC,544,https://ieeexplore.ieee.org/abstract/document/4181710/,6206715569362072129,/scholar?cites=6206715569362072129,,,https://www.researchgate.net/profile/Yann-Gael_Gueheneuc/publication/3189749_Feature_Location_Using_Probabilistic_Ranking_of_Methods_Based_on_Execution_Scenarios_and_Information_Retrieval/links/54d3f8730cf246475804e035/Feature-Location-Using-Probabilistic-Ranking-of-Methods-Based-on-Execution-Scenarios-and-Information-Retrieval.pdf,0,0,0
1276466,Identification of high-level concept clones in source code,2001,Andrian Marcus and Jonathan I Maletic,,,,107-114,IEEE,"Source code duplication occurs frequently within large software systems. Pieces of source code. functions. and data types are often duplicated in part or in whole. for a variety of reasons. Programmers may simply be reusing a piece of code via copy and paste or they may be ""re-inventing the wheel"". Previous research on the detection of clones is mainly focused on identifying pieces of code with similar (or nearly similar) structure. Our approach is to examine the source code text (comments and identifiers) and identify implementations of similar high-level concepts (e.g.. abstract data types). The approach uses an information retrieval technique (i.e.. latent semantic indexing) to statically analyze the software system and determine semantic similarities between source code documents (i.e.. functions. files. or code segments). These similarity measures are used to drive the clone detection process. The intention of our …",True,ZZiaPdYAAAAJ:UeHWp8X0CEIC,372,https://ieeexplore.ieee.org/abstract/document/989796/,3219881847819613190,/scholar?cites=3219881847819613190,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.3051&rep=rep1&type=pdf,0,0,0
1276467,Data Cleansing: Beyond Integrity Analysis.,2000,Jonathan I Maletic and Andrian Marcus,,,,200-209,,The paper analyzes the problem of data cleansing and automatically identifying potential errors in data sets. An overview of the diminutive amount of existing literature concerning data cleansing is given. Methods for error detection that go beyond integrity analysis are reviewed and presented. The applicable methods include: statistical outlier detection. pattern matching. clustering. and data mining techniques. Some brief results supporting the use of such methods are given. The future research directions necessary to address the data cleansing problem are discussed.,True,ZZiaPdYAAAAJ:IjCSPb-OGe4C,353,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.5212&rep=rep1&type=pdf,4656916888140321375,/scholar?cites=4656916888140321375,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.5212&rep=rep1&type=pdf,0,0,0
1276468,Using the conceptual cohesion of classes for fault prediction in object-oriented systems,2008,Andrian Marcus and Denys Poshyvanyk and Rudolf Ferenc,34,IEEE Transactions on Software Engineering,2,287-300,IEEE,High cohesion is a desirable property of software as it positively impacts understanding. reuse. and maintenance. Currently proposed measures for cohesion in Object-Oriented (OO) software reflect particular interpretations of cohesion and capture different aspects of it. Existing approaches are largely based on using the structural information from the source code. such as attribute references. in methods to measure cohesion. This paper proposes a new measure for the cohesion of classes in OO software systems based on the analysis of the unstructured information embedded in the source code. such as comments and identifiers. The measure. named the Conceptual Cohesion of Classes (C3). is inspired by the mechanisms used to measure textual coherence in cognitive psychology and computational linguistics. This paper presents the principles and the technology that stand behind the C3 measure. A large …,True,ZZiaPdYAAAAJ:YsMSGLbcyi4C,335,https://ieeexplore.ieee.org/abstract/document/4384505/,15011496947739658751,/scholar?cites=15011496947739658751,,,,0,0,0
1276469,Automated severity assessment of software defect reports,2008,Tim Menzies and Andrian Marcus,,,,346-355,IEEE,In mission critical systems. such as those developed by NASA. it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment). which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for …,True,ZZiaPdYAAAAJ:mVmsd5A6BfQC,333,https://ieeexplore.ieee.org/abstract/document/4658083/,5958433752823617661,/scholar?cites=5958433752823617661,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.344.1688&rep=rep1&type=pdf,0,0,0
1276470,Supporting program comprehension using semantic and structural information,2001,Jonathan I Maletic and Andrian Marcus,,,,103-112,IEEE,"Focuses on investigating the combined use of semantic and structural information of programs to support the comprehension tasks involved in the maintenance and reengineering of software systems. ""Semantic information"" refers to the domain-specific issues (both the problem and the development domains) of a software system. The other dimension. structural information. refers to issues such as the actual syntactic structure of the program. along with the control and data flow that it represents. An advanced information retrieval method. latent semantic indexing. is used to define a semantic similarity measure between software components. Components within a software system are then clustered together using this similarity measure. Simple structural information (i.e. the file organization) of the software system is then used to assess the semantic cohesion of the clusters and files with respect to each other. The …",True,ZZiaPdYAAAAJ:qjMakFHDy7sC,308,https://ieeexplore.ieee.org/abstract/document/919085/,16135038524159231424,/scholar?cites=16135038524159231424,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.4811&rep=rep1&type=pdf,0,0,0
1276471,Combining formal concept analysis with information retrieval for concept location in source code,2007,Denys Poshyvanyk and Andrian Marcus,,,,37-48,IEEE,The paper addresses the problem of concept location in source code by presenting an approach which combines formal concept analysis (FCA) and latent semantic indexing (LSI). In the proposed approach. LSI is used to map the concepts expressed in queries written by the programmer to relevant parts of the source code. presented as a ranked list of search results. Given the ranked list of source code elements. our approach selects most relevant attributes from these documents and organizes the results in a concept lattice. generated via FCA. The approach is evaluated in a case study on concept location in the source code of eclipse. an industrial size integrated development environment. The results of the case study show that the proposed approach is effective in organizing different concepts and their relationships present in the subset of the search results. The proposed concept location method outperforms …,True,ZZiaPdYAAAAJ:Y0pCki6q_DkC,306,https://ieeexplore.ieee.org/abstract/document/4268239/,11296430822897053145,/scholar?cites=11296430822897053145,,,https://core.ac.uk/download/pdf/194016477.pdf,0,0,0
1276472,3D representations for software visualization,2003,Andrian Marcus and Louis Feng and Jonathan I Maletic,,,,27-ff,,The paper presents a new 3D representation for visualizing large software systems. The origins of this representation can be directly traced to the SeeSoft metaphor. This work extends these visualization mechanisms by utilizing the third dimension. texture. abstraction mechanism. and by supporting new manipulation techniques and user interfaces. By utilizing a 3D representation we can better represent higher dimensional data than previous 2D views. An overview of our prototype tool and its basic functionality is given. Applications of this method to particular software engineering tasks are also discussed.,True,ZZiaPdYAAAAJ:2osOgNQ5qMEC,272,https://dl.acm.org/doi/abs/10.1145/774833.774837,12963906638435738163,/scholar?cites=12963906638435738163,,,http://www.cs.kent.edu/~jmaletic/papers/softvis03.pdf,0,0,0
1276473,Feature location via information retrieval based filtering of a single scenario execution trace,2007,Dapeng Liu and Andrian Marcus and Denys Poshyvanyk and Vaclav Rajlich,,,,234-243,,The paper presents a semi-automated technique for feature location in source code. The technique is based on combining information from two different sources: an execution trace. on one hand and the comments and identifiers from the source code. on the other hand.,True,ZZiaPdYAAAAJ:_FxGoFyzp5QC,269,https://dl.acm.org/doi/abs/10.1145/1321631.1321667,7096156943731834511,/scholar?cites=7096156943731834511,,,https://www.academia.edu/download/42459034/LiuMarPosRaj.SITIR.ASE07.pdf,0,0,0
1276474,Analysis and testing of web applications,2001,Filippo Ricca and Paolo Tonella,,,,25-34,IEEE,The economic relevance of Web applications increases the importance of controlling and improving their quality. Moreover. the newly available technologies for their development allow the insertion of sophisticated functions. but often leave the developers responsible for their organization and evolution. As a consequence. a high demand is emerging for methodologies and tools for the quality assurance of Web-based systems. In this paper. a UML model of Web applications is proposed for their high-level representation. Such a model is the starting point for several analyses. which can help in the assessment of the static site structure. Moreover. it drives Web application testing. in that it can be exploited to define white-box testing criteria and to semi-automatically generate the associated test cases. The proposed techniques were applied to several real-world Web applications. The results suggest that automatic …,True,6n3gAUMAAAAJ:u5HHmVD_uO8C,725,https://ieeexplore.ieee.org/abstract/document/919078/,11230760255293645442,/scholar?cites=11230760255293645442,,,http://www.cs.albany.edu/~mhc/csi668/05S/paper5.pdf,0,0,0
1276475,Evolutionary testing of classes,2004,Paolo Tonella,29,ACM SIGSOFT Software Engineering Notes,4,119-128,ACM,Object oriented programming promotes reuse of classes in multiple contexts. Thus. a class is designed and implemented with several usage scenarios in mind. some of which possibly open and generic. Correspondingly. the unit testing of classes cannot make too strict assumptions on the actual method invocation sequences. since these vary from application to application.In this paper. a genetic algorithm is exploited to automatically produce test cases for the unit testing of classes in a generic usage scenario. Test cases are described by chromosomes. which include information on which objects to create. which methods to invoke and which values to use as inputs. The proposed algorithm mutates them with the aim of maximizing a given coverage measure. The implementation of the algorithm and its application to classes from the Java standard library are described.,True,6n3gAUMAAAAJ:u-x6o8ySG0sC,524,https://dl.acm.org/doi/abs/10.1145/1013886.1007528,13497114337802952079,/scholar?cites=13497114337802952079,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.627.1278&rep=rep1&type=pdf,0,0,0
1276476,State-based testing of Ajax web applications,2008,Alessandro Marchetto and Paolo Tonella and Filippo Ricca,,,,121-130,IEEE,Ajax supports the development of rich-client Web applications. by providing primitives for the execution of asynchronous requests and for the dynamic update of the page structure and content. Often. Ajax Web applications consist of a single page whose elements are updated in response to callbacks activated asynchronously by the user or by a server message. These features give rise to new kinds of faults that are hardly revealed by existing Web testing approaches. In this paper. we propose a novel state-based testing approach. specifically designed to exercise Ajax Web applications. The document object model (DOM) of the page manipulated by the Ajax code is abstracted into a state model. Callback executions triggered by asynchronous messages received from the Web server are associated with state transitions. Test cases are derived from the state model based on the notion of semantically interacting …,True,6n3gAUMAAAAJ:MXK_kJrjxJIC,271,https://ieeexplore.ieee.org/abstract/document/4539539/,15727859275163270712,/scholar?cites=15727859275163270712,,,https://www.researchgate.net/profile/Filippo_Ricca/publication/4342767_State-Based_Testing_of_Ajax_Web_Applications/links/0912f51054ed0ce93b000000.pdf,0,0,0
1276477,Aspect mining through the formal concept analysis of execution traces,2004,Paolo Tonella and Mariano Ceccato,,,,112-121,IEEE,The presence of crosscutting concerns. i.e.. functionalities that are not assigned to a single modular unit in the implementation. is one of the major problems in software understanding and evolution. In fact. they are hard to locate (scattering) and may give rise to multiple ripple effects (tangling). Aspect oriented programming offers mechanisms to factor them out into a modular unit. called an aspect. Aspect identification in existing code is supported by means of dynamic code analysis. Execution traces are generated for the use cases that exercise the main functionalities of the given application. The relationship between execution traces and executed computational units (class methods) is subjected to concept analysis. In the resulting lattice. potential aspects are detected by determining the use-case specific concepts and examining their specific computational units. When these come from multiple modules (classes …,True,6n3gAUMAAAAJ:d1gkVwhDpl0C,258,https://ieeexplore.ieee.org/abstract/document/1374311/,6936369521939137033,/scholar?cites=6936369521939137033,,,https://www.academia.edu/download/41543444/Aspect_Mining_through_the_Formal_Concept20160125-12285-101tjj0.pdf,0,0,0
1276478,EEG data compression techniques,1997,Giuliano Antoniol and Paolo Tonella,44,IEEE Transactions on Biomedical engineering,2,105-114,IEEE,Electroencephalograph (EEG) and Holter EEG data compression techniques which allow perfect reconstruction of the recorded waveform from the compressed one are presented and discussed. Data compression permits one to achieve significant reduction in the space required to store signals and in transmission time. The Huffman coding technique in conjunction with derivative computation reaches high compression ratios (on average 49% on Holter and 58% on EEG signals) with low computational complexity. By exploiting this result a simple and fast encoder/decoder scheme capable of real-time performance on a PC was implemented. This simple technique is compared with other predictive transformations. vector quantization. discrete cosine transform (DCT). and repetition count compression methods. Finally. it is shown that the adoption of a collapsed Huffman tree for the encoding/decoding operations …,True,6n3gAUMAAAAJ:Tyk-4Ss8FVUC,221,https://ieeexplore.ieee.org/abstract/document/552239/,6514949685693901945,/scholar?cites=6514949685693901945,,,,0,0,0
1276479,Using a concept lattice of decomposition slices for program understanding and impact analysis,2003,Paolo Tonella,29,IEEE transactions on software engineering,6,495-509,IEEE,The decomposition slice graph and concept lattice are two program representations used to abstract the details of code into a higher-level view of the program. The decomposition slice graph partitions the program into computations performed on different variables and shows the dependence relation between computations. holding when a computation needs another computation as a building block. The concept lattice groups program entities which share common attributes and organizes such groupings into a hierarchy of concepts. which are related through generalizations/specializations. This paper investigates the relationship existing between these two program representations. The main result of this paper is a novel program representation. called concept lattice of decomposition slices. which is shown to be an extension of the decomposition slice graph. and is obtained by means of concept analysis. with …,True,6n3gAUMAAAAJ:2osOgNQ5qMEC,212,https://ieeexplore.ieee.org/abstract/document/1205178/,11190300797120191977,/scholar?cites=11190300797120191977,,,,0,0,0
1276480,Clustering test cases to achieve effective and scalable prioritisation incorporating expert knowledge,2009,Shin Yoo and Mark Harman and Paolo Tonella and Angelo Susi,,,,201-212,,Pair-wise comparison has been successfully utilised in order to prioritise test cases by exploiting the rich. valuable and unique knowledge of the tester. However. the prohibitively large cost of the pair-wise comparison method prevents it from being applied to large test suites. In this paper. we introduce a cluster-based test case prioritisation technique. By clustering test cases. based on their dynamic runtime behaviour. we can reduce the required number of pair-wise comparisons significantly. The approach is evaluated on seven test suites ranging in size from 154 to 1.061 test cases. We present an empirical study that shows that the resulting prioritisation is more effective than existing coverage-based prioritisation techniques in terms of rate of fault detection. Perhaps surprisingly. the paper also demonstrates that clustering (even without human input) can outperform unclustered coverage-based technologies. and …,True,6n3gAUMAAAAJ:-f6ydRqryjwC,209,https://dl.acm.org/doi/abs/10.1145/1572272.1572296,3760918441100640124,/scholar?cites=3760918441100640124,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.211.9479&rep=rep1&type=pdf,0,0,0
1276481,Reverse engineering of object oriented code,2005,Paolo Tonella,,,,724-725,IEEE,During software evolution. programmers devote most of their effort to the understanding of the structure and behavior of the system. For object oriented code. this might be particularly hard. when multiple. scattered objects contribute to the same function. Design views offer an invaluable help. but they are often not aligned with the code. when they are not missing at all. This tutorial describes some of the most advanced techniques that can be employed to reverse engineer several design views from the source code. The recovered diagrams. represented in UML (Unified Modeling Language). include class. object. interaction (collaboration and sequence). state and package diagrams. A unifying static code analysis framework used by most of the involved algorithms is presented at the beginning of the tutorial. A single running example is referred all over the presentation. Trade-offs (e.g.. static vs. dynamic analysis …,True,6n3gAUMAAAAJ:hqOjcs7Dif8C,190,https://ieeexplore.ieee.org/abstract/document/1553682/,405891585474113646,/scholar?cites=405891585474113646,,,,0,0,0
1276482,Concept analysis for module restructuring,2001,Paolo Tonella,27,IEEE Transactions on software engineering,4,351-363,IEEE,Low coupling between modules and high cohesion inside each module are the key features of good software design. This paper proposes a new approach to using concept analysis for module restructuring. based on the computation of extended concept subpartitions. Alternative modularizations. characterized by high cohesion around the internal structures that are being manipulated. can be determined by such a method. To assess the quality of the restructured modules. the trade-off between encapsulation violations and decomposition is considered. and proper measures for both factors are defined. Furthermore. the cost of restructuring is evaluated through a measure of distance between the original and the new modularizations. Concept subpartitions were determined for a test suite of 20 programs of variable size: 10 public-domain and 10 industrial applications. The trade-off between encapsulation and …,True,6n3gAUMAAAAJ:9yKSN-GCB0IC,187,https://ieeexplore.ieee.org/abstract/document/917524/,385211963948823294,/scholar?cites=385211963948823294,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.512.9809&rep=rep1&type=pdf,0,0,0
1276483,Measuring the effects of software aspectization,2004,Mariano Ceccato and Paolo Tonella,12,1st Workshop on Aspect Reverse Engineering,,,,The aim of Aspect Oriented Programming (AOP) is the production of code that is easier to understand and evolve. thanks to the separation of the crosscutting concerns from the principal decomposition. However. AOP languages introduce an implicit coupling between the aspects and the modules in the principal decomposition. in that the latter may be unaware of the presence of aspects that intercept their execution and/or modify their structure. These invisible connections represent the main drawback of AOP. A measuring method is proposed to investigate the trade-off between advantages and disadvantages obtained by using the AOP approach. The method that we are currently studying is based on a metrics suite that extends the metrics traditionally used with the OO paradigm.,True,6n3gAUMAAAAJ:zYLM7Y9cAGgC,181,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.4197&rep=rep1&type=pdf,12311257708884991097,/scholar?cites=12311257708884991097,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.105.4197&rep=rep1&type=pdf,0,0,0
1276484,Restructuring Program Identifier Names.,2000,Bruno Caprile and Paolo Tonella,,,,97-107,,The identifiers chosen by programmers as entity names contain valuable information. They are often the starting point for the program understanding activities. especially when high level views. like the call graph. are available. An approach for the restructuring of program identifier names is proposed. aimed at improving their meaningfulness. It considers two forms of standardization. associated respectively to the lexicon of the composing terms and to the syntax of their arrangement. Automatic and semiautomatic techniques are described which can help the restructuring intervention. Their application to a real world case study is also presented.,True,6n3gAUMAAAAJ:0EnyYjriUFMC,166,https://ieeexplore.ieee.org/abstract/document/883022/,7091256043370190686,/scholar?cites=7091256043370190686,,,,0,0,0
1276485,Antioxidant capacity. vitamin C. phenolics. and anthocyanins after fresh storage of small fruits,1999,Wilhelmina Kalt and Charles F Forney and Antonio Martin and Ronald L Prior,47,Journal of agricultural and food chemistry,11,4638-4644,American Chemical Society,Fresh strawberries (Fragaria × ananassa Duch.). raspberries (Rubus idaeus Michx.). highbush blueberries (Vaccinium corymbosum L.). and lowbush blueberries (Vaccinium angustifolium Aiton) were stored at 0. 10. 20. and 30 °C for up to 8 days to determine the effects of storage temperature on whole fruit antioxidant capacity (as measured by the oxygen radical absorbing capacity assay. Cao et al.. Clin. Chem. 1995. 41. 1738−1744) and total phenolic. anthocyanin. and ascorbate content. The four fruit varied markedly in their total antioxidant capacity. and antioxidant capacity was strongly correlated with the content of total phenolics (0.83) and anthocyanins (0.90). The antioxidant capacity of the two blueberry species was about 3-fold higher than either strawberries or raspberries. However. there was an increase in the antioxidant capacity of strawberries and raspberries during storage at temperatures >0 °C …,True,LXHt3PkAAAAJ:_5tno0g5mFcC,1335,https://pubs.acs.org/doi/abs/10.1021/jf990266t,11881296097950402920,/scholar?cites=11881296097950402920,,,https://www.academia.edu/download/49897427/Antioxidant_capacity_vitamin_C_phenolics20161026-18394-31l1sd.pdf,0,0,0
1276486,Failure of pentavalent antimony in visceral leishmaniasis in India: report from the center of the Indian epidemic,2000,Shyam Sundar and Deepak K More and Manoj K Singh and Vijay P Singh and Sashi Sharma and Anand Makharia and Prasanna CK Kumar and Henry W Murray,31,Clinical infectious diseases,4,1104-1107,The University of Chicago Press,In India. 320 patients with visceral leishmaniasis (209 in the state of Bihar and 11 in the neighboring state of Uttar Pradesh) received identical pentavalent antimony (Sb) treatment. Sb induced long-term cure in 35% (95% confidence interval [CI]. 28%–42%) of those in Bihar versus 86% (95% CI. 79%–93%) of those in Uttar Pradesh. In Bihar. the center of the Indian epidemic. traditional Sb treatment should be abandoned.,True,LXHt3PkAAAAJ:TiLqlu47W2oC,713,https://academic.oup.com/cid/article-abstract/31/4/1104/374192,2211120454666358371,/scholar?cites=2211120454666358371,,,https://academic.oup.com/cid/article-pdf/31/4/1104/1063793/31-4-1104.pdf,0,0,0
1276487,A hybrid approach using ISM and fuzzy TOPSIS for the selection of reverse logistics provider,2009,Govindan Kannan and Shaligram Pokharel and P Sasi Kumar,54,"Resources, conservation and recycling",1,28-36,Elsevier,Return of used products is becoming an important logistics activity due to government legislation and increasing awareness among the people to protect the environment and reduce waste. For industries. the management of return flow usually requires a specialized infrastructure with special information systems for tracking and dedicated equipment for the processing of returns. Therefore. industries are turning to third-party reverse logistics providers (3PRLPs). In this study. a multi-criteria group decision-making (MCGDM) model in fuzzy environment is developed to guide the selection process of best 3PRLP. The interactions among the criteria are also analyzed before arriving at a decision for the selection of 3PRLP from among 15 alternatives. The analysis is done through Interpretive Structural Modeling (ISM) and fuzzy technique for order preference by similarity to ideal solution (TOPSIS). Finally the effectiveness …,True,LXHt3PkAAAAJ:T5V60G5X4B8C,616,https://www.sciencedirect.com/science/article/pii/S0921344909001281,16784383796978690615,/scholar?cites=16784383796978690615,,,,0,0,0
1276488,Rapid accurate field diagnosis of Indian visceral leishmaniasis,1998,Shyam Sundar and Steven G Reed and Vijay P Singh and Prasanna CK Kumar and Henry W Murray,351,The Lancet,9102,563-565,Elsevier,A firm diagnosis of visceral leishmaniasis (kala-azar) requires demonstration of the parasite in organ aspirates or tissue biopsy samples. The aim of this prospective study was to assess the diagnostic usefulness of non-invasive testing for antibody to the leishmanial antigen K39 by means of antigen-impregnated nitrocellulose paper strips adapted for use under field conditions.One drop of peripheral blood is applied to the nitrocellulose strip. Three drops of test buffer (phosphate-buffered saline plus bovine serum albumin) are added to the dried blood. The development of two visible bands indicates presence of IgG anti-K39. 323 consecutive patients with suspected kala-azar referred to two specialist units in India. and 25 healthy controls. provided fingerstick blood samples for the test. Spleen aspirates were taken from 250 patients.Kala-azar was confirmed by microscopy of spleen …,True,LXHt3PkAAAAJ:wZJMF1LD7PcC,333,https://www.sciencedirect.com/science/article/pii/S014067369704350X,10864553902282333835,/scholar?cites=10864553902282333835,,,https://www.academia.edu/download/46154190/s0140-6736_2897_2904350-x20160601-9056-yphpku.pdf,0,0,0
1276489,Targeted chemoradiation for advanced head and neck cancer: analysis of 213 patients,2000,K Thomas Robbins and Parves Kumar and Frank SH Wong and William F Hartsell and Pamela Flick and Robert Palmer and Alva B Weir III and H Barry Neill and Thomas Murry and Robert Ferguson and Catherine Hanchett and Francisco Vieira and Andrew Bush and Stephen B Howell,22,Head & Neck: Journal for the Sciences and Specialties of the Head and Neck,7,687-693,John Wiley & Sons. Inc.,To determine the survival results. patterns of relapse. and organ preservation effects of a targeted chemoradiation protocol for patients with advanced (stage III–IV) carcinoma of the head and neck.Analysis of 213 patients with stage III–IV squamous cell carcinoma treated at UT Memphis between June 1993 and March 1998. Treatment included weekly intra‐arterial infusions of cisplatin (150 mg/m2/ week × 4) rapidly delivered to the tumor bulk. simultaneous intravenous thiosulfate for systemic drug neutralization. and conventional external‐beam irradiation (180–200 cGy/fraction) to a total dose of 68–72 Gy.Tumor response. toxicity. disease control above the clavicle. pattern of relapse. and survival. There were 89 events of grade III–IV toxicity and 6 treatment‐related deaths (grade V). Complete response in the primary and regional sites was obtained in 171 of 213 (80%) and 92 of …,True,LXHt3PkAAAAJ:sA9dB-pw3HoC,241,https://onlinelibrary.wiley.com/doi/abs/10.1002/1097-0347(200010)22:7%3C687::AID-HED8%3E3.0.CO;2-W,3347947896466422807,/scholar?cites=3347947896466422807,,,https://www.researchgate.net/profile/Kevin_Robbins/publication/341386389_Targeted_chemoradiation_for_advanced_head_and_neck_cancer_Analysis_of_213_patients/links/5ed2682892851c9c5e667af5/Targeted-chemoradiation-for-advanced-head-and-neck-cancer-Analysis-of-213-patients.pdf,0,0,0
1276490,DNA variation of the mammalian major histocompatibility complex reflects genomic diversity and population history,1990,Naoya Yuhki and STEPHEN J O'Brien,87,Proceedings of the National Academy of Sciences,2,836-840,National Academy of Sciences,The major histocompatibility complex (MHC) is a multigene complex of tightly linked homologous genes that encode cell surface antigens that play a key role in immune regulation and response to foreign antigens. In most species. MHC gene products display extreme antigenic polymorphism. and their variability has been interpreted to reflect an adaptive strategy for accommodating rapidly evolving infectious agents that periodically afflict natural populations. Determination of the extent of MHC variation has been limited to populations in which skin grafting is feasible or for which serological reagents have been developed. We present here a quantitative analysis of restriction fragment length polymorphism of MHC class I genes in several mammalian species (cats. rodents. humans) known to have very different levels of genetic diversity based on functional MHC assays and on allozyme surveys. When homologous …,True,LXHt3PkAAAAJ:wE8AsS3ykUMC,235,https://www.pnas.org/content/87/2/836.short,16221069722127479842,/scholar?cites=16221069722127479842,,,https://www.pnas.org/content/pnas/87/2/836.full.pdf,0,0,0
1276491,Influence of ferulic acid on γ-radiation induced DNA damage. lipid peroxidation and antioxidant status in primary culture of isolated rat hepatocytes,2006,M Srinivasan and A Ram Sudheer and K Raveendran Pillai and P Raghu Kumar and PR Sudhakaran and VP Menon,228,Toxicology,2-3,249-258,Elsevier,Ionizing radiation is known to induce oxidative stress through generation of reactive oxygen species (ROS) resulting in imbalance of the pro-oxidant and antioxidant activities ultimately resulting in cell death. Ferulic acid (FA) is a phytochemical commonly found in fruits and vegetables such as tomatoes. sweet corn. and ricebran. FA exhibit a wide range of pharmacological effects including antiageing. anti-inflammatory. anticancer. antidiabetic. antiapoptotic. and neuroprotective. The present work is aimed at evaluating the radioprotective effect of FA. on γ-radiation induced toxicity in primary cultures of isolated rat hepatocytes. Hepatocytes were isolated from the liver of rats by collagenase perfusion. The cellular changes were estimated using lipid peroxidative indices like thiobarbituric acid reactive substances (TBARS). the antioxidants superoxide dismutase (SOD). catalase (CAT). glutathione peroxidase (GPx) and …,True,LXHt3PkAAAAJ:VETmZaymeusC,159,https://www.sciencedirect.com/science/article/pii/S0300483X06005555,6110862259877237425,/scholar?cites=6110862259877237425,,,https://www.academia.edu/download/50902372/j.tox.2006.09.00420161215-3868-1x4l2ke.pdf,0,0,0
1276492,Extraction and pharmacological evaluation of some extracts of Tridax procumbens and Capparis deciduas,2009,B Sharma and P Kumar,1,Int J Appl Res Nat Prod,4,5-12,,,True,LXHt3PkAAAAJ:SAZ1SQo2q1kC,117,http://scholar.google.com/scholar?cluster=11156193313197814041&hl=en&oi=scholarr,11156193313197814041,/scholar?cites=11156193313197814041,,,,0,0,0
1276493,Lycopene as a natural protector against γ-radiation induced DNA damage. lipid peroxidation and antioxidant status in primary culture of isolated rat hepatocytes in vitro,2007,M Srinivasan and A Ram Sudheer and K Raveendran Pillai and P Raghu Kumar and PR Sudhakaran and VP Menon,1770,Biochimica et Biophysica Acta (BBA)-General Subjects,4,659-665,Elsevier,The present study was designed to evaluate the radioprotective effect of lycopene. a naturally occurring dietary carotenoid. on γ-radiation induced toxicity in cultured rat hepatocytes. The cellular changes were estimated using lipid peroxidative indices like thiobarbituric acid reactive substances (TBARS). superoxide dismutase (SOD). catalase (CAT). glutathione peroxidase (GPx). reduced glutathione (GSH). ceruloplasmin. vitamins A. E. C and uric acid. The DNA damage was analysed by single cell gel electrophoresis (comet assay). The increase in the severity of DNA damage was observed with the increase in γ-radiation dose (1. 2 and 4 Gy) in cultured rat hepatocytes. TBARS were increased significantly whereas the levels of GSH. vitamins C. E and A. ceruloplasmin. uric acid and antioxidant enzymes were significantly decreased in γ-irradiated groups. The maximum damage to hepatocytes was observed at 4 Gy …,True,LXHt3PkAAAAJ:jEJjQKk8aPQC,113,https://www.sciencedirect.com/science/article/pii/S0304416506003552,14824081157789348647,/scholar?cites=14824081157789348647,,,https://www.academia.edu/download/51728382/j.bbagen.2006.11.00820170210-16348-1ir8p4u.pdf,0,0,0
1276494,Development of novel α-chitin/nanobioactive glass ceramic composite scaffolds for tissue engineering applications,2009,Mathew Peter and Pandian Thodi Sudheesh Kumar and Nelson Sathy Binulal and Shanti V Nair and Hiroshi Tamura and Rangasamy Jayakumar,78,Carbohydrate Polymers,4,926-931,Elsevier,Bioactive glass ceramic nanoparticles (nBGC) were prepared by sol–gel technique. The novel chitin/nBGC composite scaffolds were prepared using chitin gel with nBGC by lyophilization technique. The prepared nBGC and composite scaffolds were characterized using Transmission Electron Microscopy (TEM). Scanning Electron Microscopy (SEM). Fourier Transformed Infrared Spectroscopy (FT-IR) and X-ray diffraction (XRD). The composite scaffolds showed adequate porosity where the nBGC nanoparticles were homogenously distributed on the pore walls. The swelling. density. degradation and in vitro biomineralization capability of the composite scaffolds were also evaluated. The developed composite scaffolds showed adequate swelling and degradation properties along with its ability to become bioactive. Cytocompatability of the scaffolds was assessed using MTT assay. direct contact test and cell …,True,LXHt3PkAAAAJ:QxlgOPrhsAcC,109,https://www.sciencedirect.com/science/article/pii/S0144861709003713,1666642357576150902,/scholar?cites=1666642357576150902,,,,0,0,0
1276495,Identification and Fine-Mapping of Xa33. a Novel Gene for Resistance to Xanthomonas oryzae pv. oryzae,2012,P Natraj Kumar and K Sujatha and GS Laha and K Srinivasa Rao and B Mishra and BC Viraktamath and Y Hari and CS Reddy and SM Balachandran and T Ram and M Sheshu Madhav and N Shobha Rani and CN Neeraja and G Ashok Reddy and H Shaik and RM Sundaram,102,Phytopathology,2,222-228,The American Phytopathological Society,Broadening of the genetic base for identification and transfer of genes for resistance to insect pests and diseases from wild relatives of rice is an important strategy in resistance breeding programs across the world. An accession of Oryza nivara. International Rice Germplasm Collection (IRGC) accession number 105710. was identified to exhibit high level and broad-spectrum resistance to Xanthomonas oryzae pv. oryzae. In order to study the genetics of resistance and to tag and map the resistance gene or genes present in IRGC 105710. it was crossed with the bacterial blight (BB)-susceptible varieties ‘TN1’ and ‘Samba Mahsuri’ (SM) and then backcrossed to generate backcross mapping populations. Analysis of these populations and their progeny testing revealed that a single dominant gene controls resistance in IRGC 105710. The BC1F2 population derived from the cross IRGC 105710/TN1//TN1 was screened …,True,LXHt3PkAAAAJ:XDrR66g3YHsC,94,https://apsjournals.apsnet.org/doi/abs/10.1094/PHYTO-03-11-0075,10781698276204426656,/scholar?cites=10781698276204426656,,,https://apsjournals.apsnet.org/doi/pdf/10.1094/PHYTO-03-11-0075,0,0,0
1276496,Image-directed robotic system for precise robotic surgery including redundant consistency checking,1995,Edward Glassman and William A Hanson and Peter Kazanzides and Brent D Mittelstadt and Bela L Musits and Howard A Paul and Russell H Taylor,,,,,,A robotic surgical system (10) includes a multiple degree of freedom manipulator arm (14) having a surgical tool (22). The arm is coupled to a controller (24) for controllably positioning the surgical tool within a three dimensional coordinate system. The system further includes a safety monitoring processor (38) for determining the position of the surgical tool in the three dimensional coordinate system relative to a volumetric model. The volumetric model may be represented as a constructive solid geometry (CSG) tree data structure. The system further includes an optical tracking camera system (28. 32) disposed for imaging a region of space that includes at least a portion of the manipulator arm. An output of the camera system is coupled to the processor (38) that processes the volumetric model for determining if the surgical tool is positioned outside of the volumetric model. The system further includes a strain gage (40 …,True,nNU3STcAAAAJ:u-x6o8ySG0sC,1283,https://patents.google.com/patent/US5408409A/en,7847017923296568399,/scholar?cites=7847017923296568399,,,https://patentimages.storage.googleapis.com/e3/41/29/3292ccbe6b7efa/US5408409.pdf,0,0,0
1276497,Image-directed robotic system for precise robotic surgery including redundant consistency checking,1992,Edward Glassman and William A Hanson and Peter Kazanzides and Brent D Mittelstadt and Bela L Musits and Howard A Paul and Russell H Taylor,,,,,,A robotic surgical system (10) includes a multiple degree of freedom manipulator arm (14) having a surgical tool (22). The arm is coupled to a controller (24) for controllably positioning the surgical tool within a three dimensional coordinate system. The system further includes a safety monitoring processor (38) for determining the position of the surgical tool in the three dimensional coordinate system relative to a volumetric model. The volumetric model may be represented as a constructive solid geometry (CSG) tree data structure. The system further includes an optical tracking camera system (28. 32) disposed for imaging a region of space that includes at least a portion of the manipulator arm. An output of the camera system is coupled to the processor (38) that processes the volumetric model for determining if the surgical tool is positioned outside of the volumetric model. The system further includes a strain gage (40 …,True,nNU3STcAAAAJ:u5HHmVD_uO8C,1033,https://patents.google.com/patent/US5086401A/en,12655033281797072071,/scholar?cites=12655033281797072071,,,https://patentimages.storage.googleapis.com/2f/86/b9/ffa26e7869ceaa/US5086401.pdf,0,0,0
1276498,An image-directed robotic system for precise orthopaedic surgery,1994,Russell H Taylor and Brent D Mittelstadt and Howard A Paul and William Hanson and Peter Kazanzides and Joel F Zuhars and Bill Williamson and Bela L Musits and Edward Glassman and William L Bargar,10,IEEE Transactions on Robotics and Automation,3,261-275,IEEE,The authors have developed an image-directed robotic system to augment the performance of human surgeons in precise bone machining procedures in orthopaedic surgery. initially targeted at cementless total hip replacement surgery. The total system consists of an interactive CT-based presurgical planning component and a surgical system consisting of a robot. redundant motion monitoring. and man-machine interface components. In vitro experiments conducted with this system have demonstrated an order-of-magnitude improvement in implant fit and placement accuracy. compared to standard manual preparation techniques. The first generation system described in this paper was used in a successful veterinary clinical trial on 26 dogs needing hip replacement surgery. It was the basis for subsequent development of a second-generation system that is now in human clinical trials.< >,True,nNU3STcAAAAJ:d1gkVwhDpl0C,546,https://ieeexplore.ieee.org/abstract/document/294202/,751775609974666578,/scholar?cites=751775609974666578,,,https://www.researchgate.net/profile/Brent_Mittelstadt2/publication/3298469_An_Image-Directed_Robotic_System_for_Precise_Orthopaedic_Surgery/links/5758426808ae9a9c954a7251.pdf,0,0,0
1276499,Development of a surgical robot for cementless total hip arthroplasty.,1992,Howard A Paul and William L Bargar and Brent Mittlestadt and Bela Musits and Russell H Taylor and Peter Kazanzides and Joel Zuhars and Bill Williamson and William Hanson,,Clinical Orthopaedics and related research,285,57-66,,The long-term success of cementless total hip arthroplasty (THA) may depend on bone ingrowth into the porous-fixation surfaces of the implant. The ingrowth process is facilitated when the surgeon achieves a satisfactory fit for the prosthesis. Clinically or roentgenographically visible failure and persistent thigh pain after cementless THA remain significant problems. both of which may be alleviated by more precise preparation of the femoral canal and selection of an appropriately sized prosthesis. The objective of this study was to obtain an exact fit for the prosthesis through the use of an image-directed surgical robot for femoral canal preparation.,True,nNU3STcAAAAJ:9yKSN-GCB0IC,466,https://europepmc.org/article/med/1446455,11816239689288320463,/scholar?cites=11816239689288320463,,,,0,0,0
1276500,Methods and apparatus for registering CT-scan data to multiple fluoroscopic images,1999,Andre Pierre Gueziec and Peter Kazanzides and Russell H Taylor,,,,,,A method and system is disclosed for registering two dimensional fluoroscopic images with a three dimensional model of a surgical tissue of interest. The method includes steps of:(a) generating. from CT or MRI data. a three dimensional model of a surgical tissue of interest;(b) obtaining at least two. two dimensional. preferably fluoroscopic. x-ray images representing at least two views of the surgical tissue of interest. the images containing radio-opaque markers for associating an image coordinate system with a surgical (robot) coordinate system;(c) detecting the presence of contours of the surgical tissue of interest in each of the at least two views;(d) deriving bundles of three dimensional lines that pass through the detected contours; and (e) interactively matching three dimensional points on three dimensional silhouette curves obtained from the three dimensional model with the bundles of three dimensional lines …,True,nNU3STcAAAAJ:2osOgNQ5qMEC,437,https://patents.google.com/patent/US5951475A/en,7242980695838169608,/scholar?cites=7242980695838169608,,,https://patentimages.storage.googleapis.com/7e/b0/c3/2623767fd584f6/US5951475.pdf,0,0,0
1276501,Safe and dependable physical human-robot interaction in anthropic domains: State of the art and challenges,2006,Rachid Alami and Alin Albu-Schäffer and Antonio Bicchi and Rainer Bischoff and Raja Chatila and Alessandro De Luca and Agostino De Santis and Georges Giralt and Jérémie Guiochet and Gerd Hirzinger and Félix Ingrand and Vincenzo Lippiello and Raffaela Mattone and David Powell and Soumen Sen and Bruno Siciliano and Giovanni Tonietti and Luigi Villani,,,,1-16,IEEE,"In the immediate future. metrics related to safety and dependability have to be found in order to successfully introduce robots in everyday environments. The crucial issues needed to tackle the problem of a safe and dependable physical human-robot interaction (pHRI) were addressed in the EURON Perspective Research Project PHRIDOM (Physical Human- Robot Interaction in Anthropic Domains). aimed at charting the new ""territory"" of pHRI. While there are certainly also ""cognitive"" issues involved. due to the human perception of the robot (and vice versa). and other objective metrics related to fault detection and isolation. the discussion in this paper will focus on the peculiar aspects of ""physical"" interaction with robots. In particular. safety and dependability will be the underlying evaluation criteria for mechanical design. actuation. and control architectures. Mechanical and control issues will be discussed with …",True,nNU3STcAAAAJ:hMsQuOkrut0C,411,https://ieeexplore.ieee.org/abstract/document/6936985/,11360342391089441396,/scholar?cites=11360342391089441396,,,https://hal.archives-ouvertes.fr/hal-01295366/document,0,0,0
1276502,System and method for cavity generation for surgical planning and initial placement of a bone prosthesis,1998,Alind Sahay and Brent Mittelstadt and Willie Williamson Jr and Joel Zuhars and Peter Kazanzides,,,,,,Methods. systems and apparatus for planning the position of a prosthesis in a long bone in orthopaedic surgical procedures. such as hip replacement surgery. knee replacement surgery. long bone osteotomies. and the like. A bone model is generated from a scanned image of a bone. a prosthesis model is selected from a library of prosthesis models and then a cavity model is formed based on the prosthesis model and/or the bone model. The cavity model may then be positioned over the bone model. either interactively by the surgeon or automatically through an algorithm based on clinical parameters. to determine a reasonable location for implantation of a prosthesis within the bone. The cavity model allows the surgeon to optimize placement of the implant within the bone. and it provides important clinical information to the surgeon. such as areas in which press fits are provided. extension areas for possible …,True,nNU3STcAAAAJ:UeHWp8X0CEIC,356,https://patents.google.com/patent/US5824085A/en,1227697154914197589,/scholar?cites=1227697154914197589,,,https://patentimages.storage.googleapis.com/ec/c8/6f/ae82c51c91473d/US5824085.pdf,0,0,0
1276503,Design and integration of a telerobotic system for minimally invasive surgery of the throat,2009,Nabil Simaan and Kai Xu and Wei Wei and Ankur Kapoor and Peter Kazanzides and Russell Taylor and Paul Flint,28,The International journal of robotics research,9,1134-1153,Sage Publications,In this paper we present the clinical motivation. design specifications.                     kinematics. statics. and actuation compensation for a newly constructed                     telerobotic system for Minimally Invasive Surgery (MIS) of the throat. A hybrid                     dual-arm telesurgical slave. with 20 joint-space Degrees-of-Freedom (DoFs). is                     used in this telerobotic system to provide the necessary dexterity in deep                     surgical fields such as the throat. The telerobotic slave uses novel continuum                     robots that use multiple super-elastic backbones for actuation and structural                     integrity. We present the kinematics of the telesurgical slave and methods for                     actuation compensation to cancel the effects of backlash. friction. and                     flexibility of the actuation lines. A method for actuation compensation is                     presented in order to overcome uncertainties of modeling. friction …,True,nNU3STcAAAAJ:IjCSPb-OGe4C,325,https://journals.sagepub.com/doi/abs/10.1177/0278364908104278,6800676731662699355,/scholar?cites=6800676731662699355,,,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2772168/,0,0,0
1276504,Interactive user interfaces for robotic minimally invasive surgical systems,2013,Simon P Dimaio and Christopher J Hasser and Russell H Taylor and David Q Larkin and Peter Kazanzides and Anton Deguet and Bálazs Peter Vágvölgyi and Joshua Leven,,,,,,In one embodiment of the invention. a method for a minimally invasive surgical system is disclosed. The method includes capturing and displaying camera images of a surgical site on at least one display device at a surgeon console; switching out of a following mode and into a masters-as-mice (MaM) mode; overlaying a graphical user interface (GUI) including an interactive graphical object onto the camera images; and rendering a pointer within the camera images for user interactive control. In the following mode. the input devices of the surgeon console may couple motion into surgical instruments. In the MaM mode. the input devices interact with the GUI and interactive graphical objects. The pointer is manipulated in three dimensions by input devices having at least three degrees of freedom. Interactive graphical objects are related to physical objects in the surgical site or a function thereof and are manipulatable …,True,nNU3STcAAAAJ:NMxIlDl6LWMC,315,https://patents.google.com/patent/US8398541B2/en,8769055428579974033,/scholar?cites=8769055428579974033,,,https://patentimages.storage.googleapis.com/0d/1c/11/df9526f1c7ec3e/US8398541.pdf,0,0,0
1276505,An open-source research kit for the da Vinci® Surgical System,2014,Peter Kazanzides and Zihan Chen and Anton Deguet and Gregory S Fischer and Russell H Taylor and Simon P DiMaio,,,,6434-6439,IEEE,We present a telerobotics research platform that provides complete access to all levels of control via open-source electronics and software. The electronics employs an FPGA to enable a centralized computation and distributed I/O architecture in which all control computations are implemented in a familiar development environment (Linux PC) and low-latency I/O is performed over an IEEE-1394a (FireWire) bus at speeds up to 400 Mbits/sec. The mechanical components are obtained from retired first-generation da Vinci ® Surgical Systems. This system is currently installed at 11 research institutions. with additional installations underway. thereby creating a research community around a common open-source hardware and software platform.,True,nNU3STcAAAAJ:kuK5TVdYjLIC,302,https://ieeexplore.ieee.org/abstract/document/6907809/,13876467541944559416,/scholar?cites=13876467541944559416,,,https://pdfs.semanticscholar.org/cc50/8b51931151d4e4f26b2e43195186c6c176fa.pdf,0,0,0
1276506,High-resolution. small animal radiation research platform with x-ray tomographic guidance capabilities,2008,John Wong and Elwood Armour and Peter Kazanzides and Iulian Iordachita and Erik Tryggestad and Hua Deng and Mohammad Matinfar and Christopher Kennedy and Zejian Liu and Timothy Chan and Owen Gray and Frank Verhaegen and Todd McNutt and Eric Ford and Theodore L DeWeese,71,International Journal of Radiation Oncology* Biology* Physics,5,1591-1599,Elsevier,To demonstrate the computed tomography. conformal irradiation. and treatment planning capabilities of a small animal radiation research platform (SARRP).The SARRP uses a dual-focal spot. constant voltage X-ray source mounted on a gantry with a source-to-isocenter distance of 35 cm. Gantry rotation is limited to 120° from vertical. X-rays of 80–100 kVp from the smaller 0.4-mm focal spot are used for imaging. Both 0.4-mm and 3.0-mm focal spots operate at 225 kVp for irradiation. Robotic translate/rotate stages are used to position the animal. Cone-beam computed tomography is achieved by rotating the horizontal animal between the stationary X-ray source and a flat-panel detector. The radiation beams range from 0.5 mm in diameter to 60 × 60 mm2. Dosimetry is measured with radiochromic films. Monte Carlo dose calculations are used for treatment planning. The combination of …,True,nNU3STcAAAAJ:zYLM7Y9cAGgC,301,https://www.sciencedirect.com/science/article/pii/S0360301608007578,12588893021377740332,/scholar?cites=12588893021377740332,,,https://www.ncbi.nlm.nih.gov/pmc/articles/pmc2605655/,0,0,0
1276507,Funology 2,2018,Mark Blythe and Andrew Monk,,,,,Springer International Publishing. DOI: http://dx. doi. org/10.1007/978-3-319-68213-6,The Human-Computer Interaction Series. launched in 2004. publishes books that advance the science and technology of developing systems which are effective and satisfying for people in a wide variety of contexts. Titles focus on theoretical perspectives (such as formal approaches drawn from a variety of behavioural sciences). practical approaches (such as techniques for effectively integrating user needs in system development). and social issues (such as the determinants of utility. usability and acceptability).HCI is a multidisciplinary field and focuses on the human aspects in the development of computer technology. As technology becomes increasingly more pervasive the need to take a human-centred approach in the design and development of computer-based systems becomes ever more important. Titles published within the Human–Computer Interaction Series are included in Thomson Reuters’ Book …,True,JSQuVBYAAAAJ:ZqE1mSdD_DYC,773,https://link.springer.com/content/pdf/10.1007/978-3-319-68213-6.pdf,16757551119467404528,/scholar?cites=16757551119467404528,,,,0,0,0
1276508,Model-driven architecture in practice: a software production environment based on conceptual modeling,2007,Oscar Pastor and Juan Carlos Molina,,,,,Springer Science & Business Media,"Formal specification languages. object-oriented methods. CASE tools. component-based software production. agent-oriented. aspect-oriented... During the last two decades many techniques have been proposed from both research and industry in order to generate a correct software product from a higher-level system specification. Nevertheless. the many failures in achieving this goal have resulted in scepticism when facing any new proposal that offers a"" press the button. get all the code"" strategy. And now the hype around OMG’s MDA has given a new push to these strategies. Oscar Pastor and Juan Carlos Molina combine a sound theoretical approach based on more than 10 years’ research with industrial strength and practical software development experience. They present a software process based on model transformation technology. thus making the statement"" the model is the code""–instead of the common"" the code is the model""–finally come true. They clearly explain which conceptual primitives should be present in a system specification. how to use UML to properly represent this subset of basic conceptual constructs. how to identify just those diagrams and modeling constructs that are actually required to create a meaningful conceptual schema. and. finally. how to accomplish the transformation process between the problem space and the solution space. Their approach is fully supported by commercially available tools. and the subsequent software production process is dramatically more efficient than today’s conventional software development processes. saving many man-days of work. For software developers and architects …",True,JSQuVBYAAAAJ:d1gkVwhDpl0C,407,http://books.google.com/books?hl=en&lr=&id=eKfKNEQs6XMC&oi=fnd&pg=PR13&dq=info:tpI7-rO-pI8J:scholar.google.com&ots=8L-u8bpdyn&sig=j5tBDO15S2R3l6rpEm2S9EXQr1w,10350607523810874038,/scholar?cites=10350607523810874038,,,,0,0,0
1276509,Conceptual modeling of device-independent web applications,2001,Jaime Gómez and Cristina Cachero and Oscar Pastor,8,Ieee multimedia,2,26-39,IEEE,Existing tools for building and deploying complex Web sites are inadequate for dealing with the software production process that involves connecting with underlying logic in a unified and systematic way. As a solution. we propose the OO-H method. an object-oriented software approach that captures relevant properties involved in modeling and implementing Web application interfaces.,True,JSQuVBYAAAAJ:u5HHmVD_uO8C,343,https://ieeexplore.ieee.org/abstract/document/917969/,1672007330184540324,/scholar?cites=1672007330184540324,,,https://www.researchgate.net/profile/Cristina_Cachero/publication/3338617_Conceptual_modeling_of_device-independent_Web_applications/links/5630b0a108ae68f782f93f0b.pdf,0,0,0
1276510,Automatic software production system,2006,Jose Iborra and Oscar Pastor,,,,,,An automated software production system is provided. in which system requirements are captured. converted into a formal specification. and validated for correctness and completeness. In addition. a translator is provided to automatically generate a complete. robust software application based on the validated formal specification. including user-interface code and error handling code.,True,JSQuVBYAAAAJ:Tyk-4Ss8FVUC,326,https://patents.google.com/patent/US7137100B2/en,2660580988552955646,/scholar?cites=2660580988552955646,,,,0,0,0
1276511,The OO-Method approach for information systems modeling: from object-oriented conceptual modeling to automated programming,2001,Oscar Pastor and Jaime Gómez and Emilio Insfrán and Vicente Pelechano,26,Information Systems,7,507-534,Pergamon,Current and future (conventional) notations used in Conceptual Modeling Techniques should have a precise (formal) semantics to provide a well-defined software development process. in order to go from specification to implementation in an automated way. To achieve this objective. the OO-method approach to Information Systems Modeling presented in this paper attempts to overcome the conventional (informal)/formal dichotomy by selecting the best ideas from both approaches. The OO-method makes a clear distinction between the problem space (centered on what the system is) and the solution space (centered on how it is implemented as a software product). It provides a precise. conventional graphical notation to obtain a system description at the problem space level. however this notation is strictly based on a formal OO specification language that determines the conceptual modeling constructs needed to …,True,JSQuVBYAAAAJ:u-x6o8ySG0sC,318,https://www.sciencedirect.com/science/article/pii/S0306437901000357,5553501773735628571,/scholar?cites=5553501773735628571,,,https://www.academia.edu/download/51126730/The_OO-method_approach_for_information_s20161230-20091-w19khi.pdf,0,0,0
1276512,Business process management: Models. techniques. and empirical studies,2003,van der Aalst Wil and Jörg Desel and Andreas Oberweis,,,,,Springer,Business processes are among today's hottest topics in the science and practice of information systems. Business processes and workflow management systems attract a lot of attention from R&D professionals in software engineering. information systems. business-oriented computer science. and management sciences. The carefully reviewed chapters contributed to this state-of-the-art survey by internationally leading scientists consolidate work presented at various workshops on the topic organized by the editors of the book in the past few years. The book spans the whole spectrum of business process management ranging from theoretical aspects. conceptual models. and application scenarios to implementation issues. It will become a valuable source of reference and information for R&D professionals active in the fascinating interdisciplinary area of business process management and for ambitious practitioners.,True,JSQuVBYAAAAJ:Q3-QASNKTMEC,277,http://books.google.com/books?hl=en&lr=&id=aMapCAAAQBAJ&oi=fnd&pg=PR1&dq=info:nUQZH3sj8h8J:scholar.google.com&ots=sLa1fsS_G9&sig=-_ozFKwgkzsbhwGeW4g_ma2LL44,2301941371249443997,/scholar?cites=2301941371249443997,,,,0,0,0
1276513,Web engineering: modelling and implementing web applications,2007,Gustavo Rossi and Oscar Pastor and Daniel Schwabe and Luis Olsina,,,,,Springer Science & Business Media,“Web Engineering: Modelling and Implementing Web Applications” presents the state of the art approaches for obtaining a correct and complete Web software product from conceptual schemas. represented via well-known design notations. Describing mature and consolidated approaches to developing complex applications. this edited volume is divided into three parts and covers the challenges web application developers face; design issues for web applications; and how to measure and evaluate web applications in a consistent way. With contributions from leading researchers in the field this book will appeal to researchers and students as well as to software engineers. software architects and business analysts.,True,JSQuVBYAAAAJ:UeHWp8X0CEIC,254,http://books.google.com/books?hl=en&lr=&id=-l1jW9O2bCEC&oi=fnd&pg=PA4&dq=info:vTILNE8xxbIJ:scholar.google.com&ots=8KDk9bNMkx&sig=Sd3v9cRZwgjfHLTaLumbJg_jweI,12881756525408498365,/scholar?cites=12881756525408498365,,,,0,0,0
1276514,Doing design ethnography,2012,Andrew Crabtree and Mark Rouncefield and Peter Tolmie,,,,,Springer Science & Business Media,Human-Computer Interaction is a multidisciplinary field focused on human aspects of the development of computer technology. As computer-based technology becomes increasingly pervasive-not just in developed countries. but worldwide-the need to take a humancentered approach in the design and development of this technology becomes ever more important. For roughly 30 years now. researchers and practitioners in computational and behavioral sciences have worked to identify theory and practice that influences the direction of these technologies. and this diverse work makes up the field of human–computer interaction. Broadly speaking it includes the study of what technology might be able to do for people and how people might interact with the technology. In this series we present work which advances the science and technology of developing systems which are both effective and satisfying for people in a …,True,JSQuVBYAAAAJ:5nxA0vEk-isC,235,https://link.springer.com/content/pdf/10.1007/978-1-4471-2726-0.pdf,4668731079484878110,/scholar?cites=4668731079484878110,,,https://mycourses.aalto.fi/pluginfile.php/453788/mod_resource/content/2/Crabtree_Doing_design_ethnography.pdf,0,0,0
1276515,Method and apparatus for automatic generation of information system user interfaces,2008,Pedro Juan Molina-Moreno and Oscar Pastor-Lopez and Juan Carlos Molina-Udaeta and Jose Miguel Barbera-Alonso,,,,,,A method and apparatus for the specification and automatic generation of user interfaces of information system (computer programs) is provided. The method is based in pattern language to specify requirements in an un-ambiguous mode and with precise semantics. The pattern language allows a user interface model to be composed using elements of the pattern language (computer objects in the object oriented programming style) which fully specify the desired user interface. The semantics of the objects in the user interface model have one and only one definition such that user interface model can be validated in a validation process. The validation process eliminates bugs in the final computer program code which is automatically produced from the user interface model. A model (metamodel). an editor tool (computer program) implementing the model for creating specifications of the user interface model. DTD …,True,JSQuVBYAAAAJ:rOcdG6UcVlcC,225,https://patents.google.com/patent/US7334216B2/en,17897022177817484568,/scholar?cites=17897022177817484568,,,https://patentimages.storage.googleapis.com/1b/a8/9e/1aec6d298c1c7c/US7334216.pdf,0,0,0
1276516,Automatic software production system,2004,Oscar Pastor and José Iborra,,,,,,An automated software production system is provided. in which system requirements are captured. converted into a formal specification. and validated for correctness and completeness. In addition. a translator is provided to automatically generate a complete. robust software application based on the validated formal specification. including user-interface code and error handling code.,True,JSQuVBYAAAAJ:zYLM7Y9cAGgC,204,https://patents.google.com/patent/US6681383B1/en,2505375885566326881,/scholar?cites=2505375885566326881,,,https://patentimages.storage.googleapis.com/5a/25/9d/ffc1eed584843a/US6681383.pdf,0,0,0
1276517,Requirements engineering-based conceptual modelling,2002,Emilio Insfrán and Oscar Pastor and ROEL Wieringa,7,Requirements Engineering,2,61-72,Springer-Verlag,The software production process involves a set of phases where a clear relationship and smooth transitions between them should be introduced. In this paper. a requirements engineering-based conceptual modelling approach is introduced as a way to improve the quality of the software production process. The aim of this approach is to provide a set of techniques and methods to capture software requirements and to provide a way to move from requirements to a conceptual schema in a traceable way. The approach combines a framework for requirements engineering (TRADE) and a graphical object-oriented method for conceptual modelling and code generation (OO-Method). The intended improvement of the software production process is accomplished by providing a precise methodological guidance to go from the user requirements (represented through the use of the appropriate TRADE techniques …,True,JSQuVBYAAAAJ:2osOgNQ5qMEC,194,https://link.springer.com/content/pdf/10.1007/s007660200005.pdf,16026008712630782487,/scholar?cites=16026008712630782487,,,https://www.researchgate.net/profile/Oscar_Pastor2/publication/220428142_Requirements_Engineering-Based_Conceptual_Modelling/links/0deec5200b84eb695d000000/Requirements-Engineering-Based-Conceptual-Modelling.pdf,0,0,0
1276518,Lazy abstraction,2002,Thomas A Henzinger and Ranjit Jhala and Rupak Majumdar and Gregoire Sutre,,,,58-70,,One approach to model checking software is based on the abstract-check-refine paradigm: build an abstract model. then check the desired property. and if the check fails. refine the model and start over. We introduce the concept of lazy abstraction to integrate and optimize the three phases of the abstract-check-refine loop. Lazy abstraction continuously builds and refines a single abstract model on demand. driven by the model checker. so that different parts of the model may exhibit different degrees of precision. namely just enough to verify the desired property. We present an algorithm for model checking safety properties using lazy abstraction and describe an implementation of the algorithm applied to C programs. We also provide sufficient conditions for the termination of the method.,True,H3wb878AAAAJ:u5HHmVD_uO8C,1463,https://dl.acm.org/doi/abs/10.1145/503272.503279,7397121109977970683,/scholar?cites=7397121109977970683,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.5090&rep=rep1&type=pdf,0,0,0
1276519,NV-Heaps: Making persistent objects fast and safe with next-generation. non-volatile memories,2011,Joel Coburn and Adrian M Caulfield and Ameen Akel and Laura M Grupp and Rajesh K Gupta and Ranjit Jhala and Steven Swanson,39,ACM SIGARCH Computer Architecture News,1,105-118,ACM,Persistent. user-defined objects present an attractive abstraction for working with non-volatile program state. However. the slow speed of persistent storage (i.e.. disk) has restricted their design and limited their performance. Fast. byte-addressable. non-volatile technologies. such as phase change memory. will remove this constraint and allow programmers to build high-performance. persistent data structures in non-volatile storage that is almost as fast as DRAM. Creating these data structures requires a system that is lightweight enough to expose the performance of the underlying memories but also ensures safety in the presence of application and system failures by avoiding familiar bugs such as dangling pointers. multiple free()s. and locking errors. In addition. the system must prevent new types of hard-to-find pointer safety bugs that only arise with persistent objects. These bugs are especially dangerous since …,True,H3wb878AAAAJ:ULOm3_A8WrAC,785,https://dl.acm.org/doi/abs/10.1145/1961295.1950380,4355297240541486347,/scholar?cites=4355297240541486347,,,https://www.cse.iitb.ac.in/~puru/courses/autumn15/cs695/downloads/nvheap.pdf,0,0,0
1276520,The software model checker b last,2007,Dirk Beyer and Thomas A Henzinger and Ranjit Jhala and Rupak Majumdar,9,International Journal on Software Tools for Technology Transfer,5,505-525,Springer-Verlag,Blast is an automatic verification tool for checking temporal safety properties of C programs. Given a C program and a temporal safety property. Blast either statically proves that the program satisfies the safety property. or provides an execution path that exhibits a violation of the property (or. since the problem is undecidable. does not terminate). Blast constructs. explores. and refines abstractions of the program state space based on lazy predicate abstraction and interpolation-based predicate discovery. This paper gives an introduction to Blast and demonstrates. through two case studies. how it can be applied to program verification and test-case generation. In the first case study. we use Blast to statically prove memory safety for C programs. We use CCured. a type-based memory-safety analyzer. to annotate a program with run-time assertions that check for safe memory operations. Then. we use Blast to …,True,H3wb878AAAAJ:9yKSN-GCB0IC,738,https://link.springer.com/article/10.1007/s10009-007-0044-z,840937417391242191,/scholar?cites=840937417391242191,,,http://www.inf.ed.ac.uk/teaching/courses/coc/BLAST.pdf,0,0,0
1276521,Software verification with BLAST,2003,Thomas A Henzinger and Ranjit Jhala and Rupak Majumdar and Gregoire Sutre,,,,235-239,Springer. Berlin. Heidelberg,Blast (the Berkeley Lazy Abstraction Software verification Tool) is a verification system for checking safety properties of C programs using automatic property-driven construction and model checking of software abstractions. Blast implements an abstract-model check-refine loop to check for reachability of a specified label in the program. The abstract model is built on the fly using predicate abstraction. This model is then checked for reachability. If there is no (abstract) path to the specified error label. Blast reports that the system is safe and produces a succinct proof. Otherwise. it checks if the path is feasible using symbolic execution of the program. If the path is feasible. Blast outputs the path as an error trace. otherwise. it uses the infeasibility of the path to refine the abstract model. Blast short-circuits the loop from abstraction to verification to refinement. integrating the three steps tightly through “lazy abstraction …,True,H3wb878AAAAJ:u-x6o8ySG0sC,651,https://link.springer.com/chapter/10.1007/3-540-44829-2_17,15775422451712803402,/scholar?cites=15775422451712803402,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.137.5102&rep=rep1&type=pdf,0,0,0
1276522,Abstractions from proofs,2004,Thomas A Henzinger and Ranjit Jhala and Rupak Majumdar and Kenneth L McMillan,39,ACM SIGPLAN Notices,1,232-244,ACM,The success of model checking for large programs depends crucially on the ability to efficiently construct parsimonious abstractions. A predicate abstraction is parsimonious if at each control location. it specifies only relationships between current values of variables. and only those which are required for proving correctness. Previous methods for automatically refining predicate abstractions until sufficient precision is obtained do not systematically construct parsimonious abstractions: predicates usually contain symbolic variables. and are added heuristically and often uniformly to many or all control locations at once. We use Craig interpolation to efficiently construct. from a given abstract error trace which cannot be concretized. a parsominous abstraction that removes the trace. At each location of the trace. we infer the relevant predicates as an interpolant between the two formulas that define the past and the future …,True,H3wb878AAAAJ:d1gkVwhDpl0C,640,https://dl.acm.org/doi/abs/10.1145/982962.964021,5911823128739926820,/scholar?cites=5911823128739926820,,,https://lara.epfl.ch/w/_media/sav12/abstractions_from_proofs.pdf,0,0,0
1276523,Software model checking,2009,Ranjit Jhala and Rupak Majumdar,41,,4,1-54,ACM,We survey recent progress in software model checking.,True,H3wb878AAAAJ:ufrVoPGSRksC,472,https://dl.acm.org/doi/abs/10.1145/1592434.1592438,3692251765652223781,/scholar?cites=3692251765652223781,,,http://faculty.sist.shanghaitech.edu.cn/faculty/songfu/cav/smc.pdf,0,0,0
1276524,Liquid types,2008,Patrick M Rondon and Ming Kawaguci and Ranjit Jhala,,,,159-169,,We present Logically Qualified Data Types. abbreviated to Liquid Types. a system that combines Hindley-Milner type inference with Predicate Abstraction to automatically infer dependent types precise enough to prove a variety of safety properties. Liquid types allow programmers to reap many of the benefits of dependent types. namely static verification of critical properties and the elimination of expensive run-time checks. without the heavy price of manual annotation. We have implemented liquid type inference in DSOLVE. which takes as input an OCAML program and a set of logical qualifiers and infers dependent types for the expressions in the OCAML program. To demonstrate the utility of our approach. we describe experiments using DSOLVE to statically verify the safety of array accesses on a set of OCAML benchmarks that were previously annotated with dependent types as part of the DML project. We show …,True,H3wb878AAAAJ:WF5omc3nYNoC,413,https://dl.acm.org/doi/abs/10.1145/1375581.1375602,2233039244122614125,/scholar?cites=2233039244122614125,,,http://goto.ucsd.edu/~rjhala/liquid/liquid_types_techrep.pdf,0,0,0
1276525,RELAY: static race detection on millions of lines of code,2007,Jan Wen Voung and Ranjit Jhala and Sorin Lerner,,,,205-214,,Data races occur when multiple threads are about to access the same piece of memory. and at least one of those accesses is a write. Such races can lead to hard-to-reproduce bugs that are time consuming to debug and fix. We present RELAY. a static and scalable race detection analysis in which unsoundness is modularized to a few sources. We describe the analysis and results from our experiments using RELAY to find data races in the Linux kernel. which includes about 4.5 million lines of code.,True,H3wb878AAAAJ:eQOLeE2rZwMC,357,https://dl.acm.org/doi/abs/10.1145/1287624.1287654,6774598797219936085,/scholar?cites=6774598797219936085,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.7064&rep=rep1&type=pdf,0,0,0
1276526,Staged information flow for JavaScript,2009,Ravi Chugh and Jeffrey A Meister and Ranjit Jhala and Sorin Lerner,,,,50-62,,Modern websites are powered by JavaScript. a flexible dynamic scripting language that executes in client browsers. A common paradigm in such websites is to include third-party JavaScript code in the form of libraries or advertisements. If this code were malicious. it could read sensitive information from the page or write to the location bar. thus redirecting the user to a malicious page. from which the entire machine could be compromised. We present an information-flow based approach for inferring the effects that a piece of JavaScript has on the website in order to ensure that key security properties are not violated. To handle dynamically loaded and generated JavaScript. we propose a framework for staging information flow properties. Our framework propagates information flow through the currently known code in order to compute a minimal set of syntactic residual checks that are performed on the remaining code …,True,H3wb878AAAAJ:Tyk-4Ss8FVUC,315,https://dl.acm.org/doi/abs/10.1145/1542476.1542483,8857174812049545566,/scholar?cites=8857174812049545566,,,http://cseweb.ucsd.edu/~lerner/papers/pldi09-sif.pdf,0,0,0
1276527,Generating Tests from Counterexamples,2004,Rupak Majumdar Dirk Beyer and Adam Chlipala and Thomas Henzinger and Ranjit,,,,326-335,IEEE Computer Society Press,,True,H3wb878AAAAJ:vV6vV6tmYwMC,296,,13611811947143294266,/scholar?cites=13611811947143294266,,,,0,0,0
1276528,Mace: language support for building distributed systems,2007,Charles Edwin Killian and James W Anderson and Ryan Braud and Ranjit Jhala and Amin M Vahdat,42,ACM SIGPLAN Notices,6,179-188,ACM,Building distributed systems is particularly difficult because of the asynchronous. heterogeneous. and failure-prone environment where these systemsmust run. Tools for building distributed systems must strike a compromise between reducing programmer effort and increasing system efficiency. We present Mace. a C++ language extension and source-to-source compiler that translates a concise but expressive distributed system specification into a C++ implementation. Mace overcomes the limitations of low-level languages by providing a unified framework for networking and event handling. and the limitations of high-level languages by allowing programmers to write program components in a controlled and structured manner in C++. By imposing structure and restrictions on how applications can be written. Mace supports debugging at a higher level. including support for efficient model checking and causal-path …,True,H3wb878AAAAJ:UeHWp8X0CEIC,277,https://dl.acm.org/doi/abs/10.1145/1273442.1250755,4199845572399102385,/scholar?cites=4199845572399102385,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.120.7239&rep=rep1&type=pdf,0,0,0
1276529,Method and system for remote diagnostic. control and information collection based on various communication modes for sending messages to users,2003,Tetsuro Motoyama and Masaichi Niro,,,,,,A method. system. and program product for communicating with machines and end users connected to a network. Information sent to or from the machines is transmitted using electronic mail or a via a direct connection. The electronic mail may be transmitted over the Internet to a service center or from a service center to a resource administrator. but also may remain within a local or wide area network for transmission between a machine and an end user or a resource administrator. E-mail messages may be transmitted from a computer which is attached to a device which is being monitored or controlled and include information regarding the status. usage or capabilities of the attached device. The device may send status messages and usage information of the device by an end user to either a resource administrator or to a service center on the Internet through a firewall. The message may be sent directly to the …,True,G_5oBOkAAAAJ:u9iWguZQMMsC,345,https://patents.google.com/patent/US6581092B1/en,7372189489221355673,/scholar?cites=7372189489221355673,,,https://patentimages.storage.googleapis.com/68/12/96/3c03e5c6028df9/US6581092.pdf,0,0,0
1276530,Method and system for translating documents using different translation resources for different portions of the documents,2001,Tetsuro Motoyama,,,,,,A system and method for translating a document from one language to another language using different translation resources depending on the document or portion of the document being translated. The original document which is to be translated contains information indicating the dictionary or translation rules which are to be utilized for the translation. The information contained within the document used to indicate different sections is encoded using Standard Generalized Markup Language (SGML) tags. Documents which have been previously translated can be used to train the translation system. Also. a side-by-side display of the original document and the translated document is presented to allow the user to compare both the original and translated document.,True,G_5oBOkAAAAJ:j3f4tGmQtD8C,272,https://patents.google.com/patent/US6208956B1/en,3580111967582812692,/scholar?cites=3580111967582812692,,,https://patentimages.storage.googleapis.com/60/27/16/e80d1de432b009/US6208956.pdf,0,0,0
1276531,Method and system for controlling and communicating with machines using multiple communication formats,1998,Tetsuro Motoyama,,,,,,A method and system which allows a remote monitoring and diagnostic computer or system to communicate using different communication protocols which are stored within a data base. After a communication is received. it is analyzed to determine if there is a protocol identifier. If the protocol identifier exists. a data base is searched to determine the format of the header of the communication. Once the format of the header is determined. the header of the received communication is read to determine the information contained therein. This information is utilized to determine the actual format of the data which follows. If the protocol identifier does not exist. the received communication is examined to determine if it is in a format which matches one of a plurality of previously defined format. Critical fields are defined which must have certain values and if the received communication matches these critical values. the record …,True,G_5oBOkAAAAJ:9Nmd_mFXekcC,247,https://patents.google.com/patent/US5818603A/en,11750854129149624413,/scholar?cites=11750854129149624413,,,https://patentimages.storage.googleapis.com/49/60/a0/1e281eaafe6b6b/US5818603.pdf,0,0,0
1276532,System for determining whether connection or connectionless modes of communication should be used to transmit information between devices in accordance with priorities of events,1998,Tetsuro Motoyama,,,,,,A method and system for monitoring. controlling and diagnosing operation of a machine such as a business office machine including a facsimile machine. a copier. and a printer. When the speed of communication between the remote device and machine is not urgent. a connectionless mode of communication may be used. The form of connectionless communication is an electronic mail message transmitted over the Internet. However. when a condition needs urgent action. a direct connection is used for communication such as communication via a telephone or ISDN line. The information obtained from the machine is stored in one or more data bases within a company and information of the machine is shared between a service department. engineering and design department. manufacturing department. and marketing department. As communication over the Internet via electronic mail is not secure. the …,True,G_5oBOkAAAAJ:a0OBvERweLwC,204,https://patents.google.com/patent/US5819110A/en,6269693702271345833,/scholar?cites=6269693702271345833,,,https://patentimages.storage.googleapis.com/d0/64/4c/59b33150561a26/US5819110.pdf,0,0,0
1276533,Method and system to diagnos a business office device based on operating parameters set by a user,1999,Tetsuro Motoyama,,,,,,A method and system for determining that problems exist in a business office device such as a copier. printer. facsimile machine. or scanner by analyzing the user settings of the business office device. If the user settings deviate from the default settings by a predetermined amount. there is a probability that the default settings are improper. parameters need to be changed within the business office device. or defective components within the business office device need to be changed. The analysis of the user settings is triggered after a predetermined time period expires. after a predetermined number of jobs are performed. or alternatively after a predetermined combination of jobs and elapsed time occurs. After a problem is found to exist with the default settings. the business office device communicates with a diagnostic service center via a connectionless-mode of communication such as by an Internet electronic mail …,True,G_5oBOkAAAAJ:g5m5HwL7SMYC,195,https://patents.google.com/patent/US5887216A/en,5529318149891942000,/scholar?cites=5529318149891942000,,,https://patentimages.storage.googleapis.com/82/6a/2e/180a191005227e/US5887216.pdf,0,0,0
1276534,Method and system for translating documents using different translation resources for different portions of the documents,1998,Tetsuro Motoyama,,,,,,A system and method for translating a document from one language to another language using different translation resources depending on the document or portion of the document being translated. The original document which is to be translated contains information indicating the dictionary or translation rules which are to be utilized for the translation. The information contained within the document used to indicate different sections is encoded using Standard Generalized Markup Language (SGML) tags. Documents which have been previously translated can be used to train the translation system. Also. a side-by-side display of the original document and the translated document is presented to allow the user to compare both the original and translated document.,True,G_5oBOkAAAAJ:CHSYGLWDkRkC,182,https://patents.google.com/patent/US5848386A/en,6861182380766133137,/scholar?cites=6861182380766133137,,,https://patentimages.storage.googleapis.com/19/63/1d/04e06f39fbf76c/US5848386.pdf,0,0,0
1276535,Method and apparatus for controlling and communicating with business office devices,1995,Tetsuro Motoyama,,,,,,A method and apparatus for controlling and communicating with business office devices. such as copiers. facsimiles and/or printers. The present invention communicates and controls various modules of business devices which allow an external device such as an operation panel to access the state of a target device. such as a copier. printer or facsimile. The operation panel can communicate with the target device and control the same target device. Also. a remote diagnostics station can provide remote diagnostics of the target device.,True,G_5oBOkAAAAJ:WqliGbK-hY8C,172,https://patents.google.com/patent/US5412779A/en,10004167968037752302,/scholar?cites=10004167968037752302,,,https://patentimages.storage.googleapis.com/91/28/16/bddfbe5fc85671/US5412779.pdf,0,0,0
1276536,System and method for document processing,1994,Tetsuro Motoyama,,,,,,A document processing system controls the printing of documents represented in page description language form. Documents are represented by a page description language which is structured so that definition and declaratory commands are positioned only at the beginning of each distinct document segment. Each document has prologue sections. which contain definition and declaratory commands. and content portions which contain the specific tokens or commands for defining specific images. The definition and declaratory commands in the prologue sections of the document are arranged in a hierarchical tree so that each definition and declaratory command has a scope corresponding to the portion of the hierarchical tree subtended by that command. A structure processor handles resource declaration and definitions. dictionary generation. context declarations and references to data external to the …,True,G_5oBOkAAAAJ:aqlVkmm33-oC,169,https://patents.google.com/patent/US5353388A/en,1954495660653127908,/scholar?cites=1954495660653127908,,,https://patentimages.storage.googleapis.com/pdfs/US5353388.pdf,0,0,0
1276537,Method and apparatus for controlling and communicating with business office devices,1998,Tetsuro Motoyama,,,,,,A method and apparatus for controlling and communicating with business office devices. such as copiers. facsimiles and/or printers. The present invention communicates and controls various modules of business devices which allow an external device such as an operation panel to access the state of a target device. such as a copier. printer or facsimile. The operation panel can communicate with the target device and control the same target device. Also. a remote diagnostics station can provide remote diagnostics of the target device.,True,G_5oBOkAAAAJ:g3aElNc5_aQC,161,https://patents.google.com/patent/US5774678A/en,13134247874971493639,/scholar?cites=13134247874971493639,,,https://patentimages.storage.googleapis.com/38/c4/6a/5ee66eefe59751/US5774678.pdf,0,0,0
1276538,Method and system for diagnosis and control of machines using connectionless modes of communication,1999,Tetsuro Motoyama,,,,,,A method and system of remotely monitoring and controlling machines and business office devices such as copiers. printers. and facsimile machines. Outgoing messages. such as Internet e-mail messages containing information describing the business office device are monitored by a security center. The security center either receives an unencrypted form of the message. or alternatively receives an encrypted form of the message. If the message is encrypted. it will be necessary for the security center to first decrypt the message. The contents of the message are monitored by the security center to assure that only authorized information is transmitted from an authorized business office device. over the Internet. to a data center which monitors the status of and/or controls the business office device. A log of messages passing through a firewall to the Internet is maintained and compared with messages received by the …,True,G_5oBOkAAAAJ:u-x6o8ySG0sC,158,https://patents.google.com/patent/US5909493A/en,51819510310492936,/scholar?cites=51819510310492936,,,https://patentimages.storage.googleapis.com/11/da/12/a345c2f061ab2b/US5909493.pdf,0,0,0
1276539,Object-oriented system and computer program product for mapping structured information to different structured information,2000,Tetsuro Motoyama and Avery Fong and Anurag Bhatnagar,,,,,,An object-oriented system and computer program product for mapping structured information to different structured information. which allows a user to interactively define the mapping. The present invention operates as an object-oriented user tool by accepting interactive input from a user of a source input. by processing the input to display the source input in a format for accepting and processing user commands to create or edit a transformation map of source components to target components. Interactive user input is then accepted and processed for selection of an input file to be transformed and selection of a transformation map to be used for the requested transformation. Interactive user input is accepted and processed for selection of individual components of the first structured information format for mapping. and for selection of options for the target components. Exemplary options for the target components are …,True,G_5oBOkAAAAJ:r0BpntZqJG4C,132,https://patents.google.com/patent/US6085196A/en,3858769546162305693,/scholar?cites=3858769546162305693,,,https://patentimages.storage.googleapis.com/07/f1/67/a8383d0649782f/US6085196.pdf,0,0,0
1276540,A systematic review of software development cost estimation studies,2006,Magne Jorgensen and Martin Shepperd,33,,1,33-53,IEEE,This paper aims to provide a basis for the improvement of software-estimation research through a systematic review of previous work. The review identifies 304 software cost estimation papers in 76 journals and classifies the papers according to research topic. estimation approach. research approach. study context and data set. A Web-based library of these cost estimation papers is provided to ease the identification of relevant estimation research results. The review results combined with other knowledge provide support for recommendations for future software cost estimation research. including: 1) increase the breadth of the search for relevant studies. 2) search manually for relevant papers within a carefully selected set of journals when completeness is essential. 3) conduct more studies on estimation methods commonly used by the software industry. and 4) increase the awareness of how properties of the data …,True,gxqbS9AAAAAJ:RYcK_YlVTxYC,1110,https://ieeexplore.ieee.org/abstract/document/4027147/,10645674402785210672,/scholar?cites=10645674402785210672,,,https://bura.brunel.ac.uk/bitstream/2438/1076/3/04027147.pdf,0,0,0
1276541,Evidence-based software engineering,2004,Barbara A Kitchenham and Tore Dyba and Magne Jorgensen,,,,273-281,IEEE Computer Society,Our objective is to describe how software engineering might benefit from an evidence-based approach and to identify the potential difficulties associated with the approach. We compared the organisation and technical infrastructure supporting evidence-based medicine (EBM) with the situation in software engineering. We considered the impact that factors peculiar to software engineering (i.e. the skill factor and the lifecycle factor) would have on our ability to practice evidence-based software engineering (EBSE). EBSE promises a number of benefits by encouraging integration of research results with a view to supporting the needs of many different stakeholder groups. However. we do not currently have the infrastructure needed for widespread adoption of EBSE. The skill factor means software engineering experiments are vulnerable to subject and experimenter bias. The lifecycle factor means it is difficult to …,True,gxqbS9AAAAAJ:35N4QoGY0k4C,1078,https://ieeexplore.ieee.org/abstract/document/1317449/,2737448898721281275,/scholar?cites=2737448898721281275,,,https://www.academia.edu/download/44069328/Evidence-based_software_engineering20160324-30468-1jr6b6j.pdf,0,0,0
1276542,A review of studies on expert estimation of software development effort,2004,Magne Jørgensen,70,,1-2,37-60,Elsevier,This paper provides an extensive review of studies related to expert estimation of software development effort. The main goal and contribution of the review is to support the research on expert estimation. e.g.. to ease other researcher’s search for relevant expert estimation studies. In addition. we provide software practitioners with useful estimation guidelines. based on the research-based knowledge of expert estimation processes. The review results suggest that expert estimation is the most frequently applied estimation strategy for software projects. that there is no substantial evidence in favour of use of estimation models. and that there are situations where we can expect expert estimates to be more accurate than formal estimation models. The following 12 expert estimation “best practice” guidelines are evaluated through the review: (1) evaluate estimation accuracy. but avoid high evaluation pressure; (2) avoid …,True,gxqbS9AAAAAJ:u5HHmVD_uO8C,740,https://www.sciencedirect.com/science/article/pii/S0164121202001565,17517821470341591785,/scholar?cites=17517821470341591785,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.387.5976&rep=rep1&type=pdf,0,0,0
1276543,Evidence-based software engineering for practitioners,2005,Tore Dyba and Barbara A Kitchenham and Magne Jorgensen,22,IEEE software,1,58-65,IEEE,Software managers and practitioners often must make decisions about what technologies to employ on their projects. They might be aware of problems with their current development practices (for example. production bottlenecks or numerous defect reports from customers) and want to resolve them. Or. they might have read about a new technology and want to take advantage of its promised benefits. However. practitioners can have difficulty making informed decisions about whether to adopt a new technology because there's little objective evidence to confirm its suitability. limits. qualities. costs. and inherent risks. This can lead to poor decisions about technology adoption. Software engineers might make incorrect decisions about adopting new techniques it they don't consider scientific evidence about the techniques' efficacy. They should consider using procedures similar to ones developed for evidence-based …,True,gxqbS9AAAAAJ:CaZNVDsoPx4C,573,https://ieeexplore.ieee.org/abstract/document/1377125/,15579109622584213762,/scholar?cites=15579109622584213762,,,https://ieeexplore.ieee.org/iel5/52/30054/01377125.pdf,0,0,0
1276544,The future of empirical methods in software engineering research,2007,Dag IK Sjoberg and Tore Dyba and Magne Jorgensen,,,,358-378,IEEE,We present the vision that for all fields of software engineering (SE). empirical research methods should enable the development of scientific knowledge about how useful different SE technologies are for different kinds of actors. performing different kinds of activities. on different kinds of systems. It is part of the vision that such scientific knowledge will guide the development of new SE technology and is a major input to important SE decisions in industry. Major challenges to the pursuit of this vision are: more SE research should be based on the use of empirical methods; the quality. including relevance. of the studies using such methods should be increased; there should be more and better synthesis of empirical evidence; and more theories should be built and tested. Means to meet these challenges include (1) increased competence regarding how to apply and combine alternative empirical methods. (2) tighter …,True,gxqbS9AAAAAJ:2P1L_qKh6hAC,554,https://ieeexplore.ieee.org/abstract/document/4221632/,16645473109522102835,/scholar?cites=16645473109522102835,,,https://www.academia.edu/download/41977611/The_Future_of_Empirical_Methods_in_Softw20160203-30232-xhq42q.pdf,0,0,0
1276545,A review of software surveys on software effort estimation,2003,Kjetil Molokken and Magne Jorgensen,,,,223-230,IEEE,"This paper summarizes estimation knowledge through a review of surveys on software effort estimation. Main findings were that: (1) most projects (60-80%) encounter effort and/or schedule overruns. The overruns. however. seem to be lower than the overruns reported by some consultancy companies. For example. Standish Group's ""Chaos Report"" describes an average cost overrun of 89%. which is much higher than the average overruns found in other surveys. i.e. 3040%. (2) The estimation methods in most frequent use of expert judgment is that there is no evidence that formal estimation models lead to more accurate estimates. (3) There is a lack of surveys including extensive analyses of the reasons for effort and schedule overruns.",True,gxqbS9AAAAAJ:70eg2SAEIzsC,526,https://ieeexplore.ieee.org/abstract/document/1237981/,5888195984569070709,/scholar?cites=5888195984569070709,,,https://www.academia.edu/download/34420273/A_Review_of_Surveys_on_Software_Effort_Estimation.pdf,0,0,0
1276546,Experience with the accuracy of software maintenance task effort prediction models,1995,Magne Jorgensen,21,IEEE Transactions on software engineering,8,674-681,IEEE,The paper reports experience from the development and use of eleven different software maintenance effort prediction models. The models were developed applying regression analysis. neural networks and pattern recognition and the prediction accuracy was measured and compared for each model type. The most accurate predictions were achieved applying models based on multiple regression and on pattern recognition. We suggest the use of prediction models as instruments to support the expert estimates and to analyse the impact of the maintenance variables on the maintenance process and product. We believe that the pattern recognition based models evaluated. i.e.. the prediction models based on the Optimized Set Reduction method. show potential for such use.< >,True,gxqbS9AAAAAJ:vV6vV6tmYwMC,360,https://ieeexplore.ieee.org/abstract/document/403791/,17132174830587978636,/scholar?cites=17132174830587978636,,,,0,0,0
1276547,How large are software cost overruns? A review of the 1994 CHAOS report,2006,Magne Jørgensen and Kjetil Moløkken-Østvold,48,,4,297-301,Elsevier,The Standish Group reported in their 1994 CHAOS report that the average cost overrun of software projects was as high as 189%. This figure for cost overrun is referred to frequently by scientific researchers. software process improvement consultants. and government advisors. In this paper. we review the validity of the Standish Group's 1994 cost overrun results. Our review is based on a comparison of the 189% cost overrun figure with the cost overrun figures reported in other cost estimation surveys. and an examination of the Standish Group's survey design and analysis methods. We find that the figure reported by the Standish Group is much higher than those reported in similar estimation surveys and that there may be severe problems with the survey design and methods of analysis. e.g. the population sampling method may be strongly biased towards ‘failure projects’. We conclude that the figure of 189% for …,True,gxqbS9AAAAAJ:dhFuZR0502QC,321,https://www.sciencedirect.com/science/article/pii/S0950584905001023,1477297518678353041,/scholar?cites=1477297518678353041,,,https://www.simula.no/sites/default/files/publications/SE.3.Moloekken-Oestvold.2004.pdf#page=195,0,0,0
1276548,Conducting realistic experiments in software engineering,2002,Dag IK Sjoberg and Bente Anda and Erik Arisholm and Tore Dyba and Magne Jorgensen and Amela Karahasanovic and Espen Frimann Koren and Marek Vokác,,,,17-26,IEEE,An important goal of most empirical software engineering research is the transfer of research results to industrial applications. Two important obstacles for this transfer are the lack of control of variables of case studies. i.e.. the lack of explanatory power. and the lack of realism of controlled experiments. While it may be difficult to increase the explanatory power of case studies. there is a large potential for increasing the realism of controlled software engineering experiments. To convince industry about the validity and applicability of the experimental results. the tasks. subjects and the environments of the experiments should be as realistic as practically possible. Such experiments are. however. more expensive than experiments involving students. small tasks and pen-and-paper environments. Consequently. a change towards more realistic experiments requires a change in the amount of resources spent on software …,True,gxqbS9AAAAAJ:M05iB0D1s5AC,234,https://ieeexplore.ieee.org/abstract/document/1166921/,2016490258705347342,/scholar?cites=2016490258705347342,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.5990&rep=rep1&type=pdf,0,0,0
1276549,Forecasting of software development work effort: Evidence on expert judgement and formal models,2007,Magne Jørgensen,23,International Journal of Forecasting,3,449-462,Elsevier,The review presented in this paper examines the evidence on the use of expert judgement. formal models. and a combination of these two approaches when estimating (forecasting) software development work effort. Sixteen relevant studies were identified and reviewed. The review found that the average accuracy of expert judgement-based effort estimates was higher than the average accuracy of the models in ten of the sixteen studies. Two indicators of higher accuracy of judgement-based effort estimates were estimation models not calibrated to the organization using the model. and important contextual information possessed by the experts not included in the formal estimation models. Four of the reviewed studies evaluated effort estimates based on a combination of expert judgement and models. The mean estimation accuracy of the combination-based methods was similar to the best of that of the other …,True,gxqbS9AAAAAJ:UeHWp8X0CEIC,232,https://www.sciencedirect.com/science/article/pii/S016920700700074X,17214955649146008453,/scholar?cites=17214955649146008453,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.387.5379&rep=rep1&type=pdf,0,0,0
1276550,Estimating software development effort based on use cases—experiences from industry,2001,Bente Anda and Hege Dreiem and Dag IK Sjøberg and Magne Jørgensen,,,,487-502,Springer. Berlin. Heidelberg,Use case models are used in object-oriented analysis for capturing and describing the functional requirements of a system. Several methods for estimating software development effort are based on attributes of a use case model. This paper reports the results of three industrial case studies on the application of a method for effort estimation based on use case points. The aim of this paper is to provide guidance for other organizations that want to improve their estimation process applying use cases. Our results support existing claims that use cases can be used successfully in estimating software development effort. The results indicate that the guidance provided by the use case points method can support expert knowledge in the estimation process. Our experience is also that the design of the use case models has a strong impact on the estimates.,True,gxqbS9AAAAAJ:u-x6o8ySG0sC,223,https://link.springer.com/chapter/10.1007/3-540-45441-1_35,18191729150619916424,/scholar?cites=18191729150619916424,,,https://www.simula.no/sites/default/files/publications/SE.3.Anda.2003.pdf#page=95,0,0,0
1276551,Formal Methods: State of the Art and Future Directions,1996,Edmund Clarke and Jeannette Wing and Rajeev Alur and Rance Cleaveland and David Dill and Allen Emerson and Stephen Garland and Steven German and John Guttag and Anthony Hall and Thomas Henzinger and Gerard Holzmann and Cliff Jones and Robert Kurshan and Nancy Leveson and Kenneth McMillan and J Moore and Doron Peled and Amir Pnueli and John Rushby and Natarajan Shankar and Joseph Sifakis and Prasad Sistla and Bernhard Steffen and Pierre Wolper and Jim Woodcock and Pamela Zave,28,ACM Computing Surveys,4,626-643,ACM,Hardware and software systems will inevitably grow in scale and functionality. Because of this increase in complexity. the likelihood of subtle errors is much greater. Moreover. some of these errors may cause catastrophic loss of money. time. or even human life. A major goal of software engineering is to enable developers to construct systems that operate reliably despite this complexity. One way of achieving this goal is by using formal methods. which are mathematically based languages. techniques. and tools for specifying and verifying such systems. Use of formal methods does not a priori guarantee correctness. However. they can greatly increase our understanding of a system by revealing inconsistencies. ambiguities. and incompleteness that might otherwise go undetected.The first part of this report assesses the state of the art in specification and verification. For verification. we highlight advances in model …,True,bO-FeTIAAAAJ:a0OBvERweLwC,2016,https://dl.acm.org/doi/abs/10.1145/242223.242257,1773010878819243963,/scholar?cites=1773010878819243963,,,http://www.site.uottawa.ca/~bochmann/ELG7187C/CourseNotes/Literature/Clarke%20-%20FM%20State%20of%20the%20art%20-%2096.pdf,0,0,0
1276552,Using Z: Specification ‚Refinement ‚and Proof,1996,Jim Woodcock and Jim Davies,,,,,Prentice Hall International,,True,bO-FeTIAAAAJ:u5HHmVD_uO8C,1880,https://ora.ox.ac.uk/objects/uuid:be6e51aa-037a-4a15-8095-ca9cb5f7b488,13735787760064723125,/scholar?cites=13735787760064723125,,,,0,0,0
1276553,Formal methods: Practice and experience,2009,Jim Woodcock and Peter Gorm Larsen and Juan Bicarregui and John Fitzgerald,41,,4,1-36,ACM,Formal methods use mathematical models for analysis and verification at any part of the program life-cycle. We describe the state of the art in the industrial use of formal methods. concentrating on their increasing use at the earlier stages of specification and design. We do this by reporting on a new survey of industrial use. comparing the situation in 2009 with the most significant surveys carried out over the last 20 years. We describe some of the highlights of our survey by presenting a series of industrial projects. and we draw some observations from these surveys and records of experience. Based on this. we discuss the issues surrounding the industrial adoption of formal methods. Finally. we look to the future and describe the development of a Verified Software Repository. part of the worldwide Verified Software Initiative. We introduce the initial projects being used to populate the repository. and describe the …,True,bO-FeTIAAAAJ:UeHWp8X0CEIC,810,https://dl.acm.org/doi/abs/10.1145/1592434.1592436,3473176833619199206,/scholar?cites=3473176833619199206,,,http://deploy-eprints.ecs.soton.ac.uk/161/2/fmsurvey%5B1%5D.pdf,0,0,0
1276554,The semantics of Circus,2002,Jim Woodcock and Ana Cavalcanti,,,,184-203,Springer. Berlin. Heidelberg,Circus is a concurrent language for refinement; it is a unification of imperative CSP. Z. and the refinement calculus. We describe the language of Circus and the formalisation of its model in Hoare & He’s unifying theories of programming.,True,bO-FeTIAAAAJ:u-x6o8ySG0sC,285,https://link.springer.com/chapter/10.1007/3-540-45648-1_10,13770486866281378331,/scholar?cites=13770486866281378331,,,,0,0,0
1276555,Systems of systems engineering: basic concepts. model-based techniques. and research directions,2015,Claus Ballegaard Nielsen and Peter Gorm Larsen and John Fitzgerald and Jim Woodcock and Jan Peleska,48,,2,1-41,ACM,The term “System of Systems” (SoS) has been used since the 1950s to describe systems that are composed of independent constituent systems. which act jointly towards a common goal through the synergism between them. Examples of SoS arise in areas such as power grid technology. transport. production. and military enterprises. SoS engineering is challenged by the independence. heterogeneity. evolution. and emergence properties found in SoS. This article focuses on the role of model-based techniques within the SoS engineering field. A review of existing attempts to define and classify SoS is used to identify several dimensions that characterise SoS applications. The SoS field is exemplified by a series of representative systems selected from the literature on SoS applications. Within the area of model-based techniques the survey specifically reviews the state of the art for SoS modelling. architectural …,True,bO-FeTIAAAAJ:ubry08Y2EpUC,276,https://dl.acm.org/doi/abs/10.1145/2794381,11506596496807064618,/scholar?cites=11506596496807064618,,,https://www.researchgate.net/profile/Peter_Larsen9/publication/282350448_Systems_of_Systems_Engineering/links/56b1f73a08ae56d7b06c9470/Systems-of-Systems-Engineering.pdf,0,0,0
1276556,Software engineering mathematics,1990,Jim Woodcock and Martin Loomes,,,,,Addison-Wesley Longman Publishing Co.. Inc.,"ACM Digital Library Logo. ACM Logo. Google. Inc. (search). Advanced Search; Browse; About;
Sign in; Register. Advanced Search; Journals; Magazines; Proceedings; Books; SIGs; Conferences;
People; More: Search ACM Digital Library. Search. Advanced Search. 10.5555/78160guidebooks
Article/Chapter ViewAbstractPublication PagesBook Browse. Browse Digital Library; Collections;
More: HomeBrowse by TitleBooksSoftware engineering mathematics. Export Citation. Select
Citation format BibTeX. Download citation; Copy citation. Categories. Journals; Magazines; Books;
Proceedings; SIGs; Conferences; Collections; People. About. About ACM Digital Library;
Subscription Information; Author Guidelines; Using ACM Digital Library; All Holdings within the
ACM Digital Library; ACM Computing Classification System. Join. Join ACM; Join SIGs; Subscribe
to Publications; Institutions and Libraries. Connect … 
",True,bO-FeTIAAAAJ:yxmsSjX2EkcC,212,https://dl.acm.org/doi/abs/10.5555/78160,16843321244978620595,/scholar?cites=16843321244978620595,,,,0,0,0
1276557,An electronic purse: Specification. refinement and proof,2000,Susan Stepney and David Cooper and Jim Woodcock,,,,,Oxford University,This case study is a reduced version of a real development by the NatWest Development Team (now platform seven) of a Smartcard product for electronic commerce. This development was deeply security critical: it was vital to ensure that these cards would not contain any bugs in implementation or design that would allow them to be subverted once in the field. The system consists of a number of electronic purses that carry financial value. each hosted on a Smartcard. The purses interact with each other via a communications device to exchange value. Once released into the field. each purse is on its own: it has to ensure the security of all its transactions without recourse to a central controller. All security measures have to be implemented on the card. with no real-time external audit logging or monitoring.,True,bO-FeTIAAAAJ:HGTzPopzzJcC,184,"https://kar.kent.ac.uk/22009/1/An_Electronic_Purse_Specification,_Refinement_and_Proof.pdf",946186292161499667,/scholar?cites=946186292161499667,,,"https://kar.kent.ac.uk/22009/1/An_Electronic_Purse_Specification,_Refinement_and_Proof.pdf",0,0,0
1276558,A refinement strategy for Circus,2003,Ana Cavalcanti and Augusto Sampaio and Jim Woodcock,15,Formal Aspects of Computing,2,146-181,Springer-Verlag,We present a refinement strategy for Circus. which is the combination of Z. CSP. and the refinement calculus in the setting of Hoare and He’s unifying theories of programming. The strategy unifies the theories of refinement for processes and their constituent actions. and provides a coherent technique for the stepwise refinement of concurrent and distributed programs involving rich data structures. This kind of development is carried out using Circus’s refinement calculus. and we describe some of its laws for the simultaneous refinement of state and control behaviour. including the splitting of a process into parallel subcomponents. We illustrate the strategy and the laws using a case study that shows the complete development of a small distributed program.,True,bO-FeTIAAAAJ:qjMakFHDy7sC,174,https://link.springer.com/article/10.1007/s00165-003-0006-5,14298312809814768230,/scholar?cites=14298312809814768230,,,https://projetos.dimap.ufrn.br/madiel_ppgsc_ufrn_br/circusrefine/raw/8d0dc533fd5d45593e7631a3f8891ecfc1e5906d/circus/documents/papers/Material/refinementstrategy.PDF,0,0,0
1276559,A UTP semantics for Circus,2009,Marcel Oliveira and Ana Cavalcanti and Jim Woodcock,21,Formal Aspects of Computing,1,3-32,Springer-Verlag, Circus specifications define both data and behavioural aspects of systems using a combination of Z and CSP constructs. Previously. a denotational semantics has been given to Circus; however. a shallow embedding of Circus in Z. in which the mapping from Circus constructs to their semantic representation as a Z specification. with yet another language being used as a meta-language. was not useful for proving properties like the refinement laws that justify the distinguishing development technique associated with Circus. This work presents a final reference for the Circus denotational semantics based on Hoare and He’s Unifying Theories of Programming (UTP); as such. it allows the proof of meta-theorems about Circus including the refinement laws in which we are interested. Its correspondence with the CSP semantics is illustrated with some examples. We also discuss the library of lemmas …,True,bO-FeTIAAAAJ:ufrVoPGSRksC,154,https://link.springer.com/article/10.1007/s00165-007-0052-5,8999536145686495654,/scholar?cites=8999536145686495654,,,https://www-users.cs.york.ac.uk/~alcc/publications/papers/OCW09.pdf,0,0,0
1276560,Non-interference through determinism,1994,AW Roscoe and JCP Woodcock and Lars Wulf,,,,31-53,Springer. Berlin. Heidelberg,The standard approach to the specification of a secure system is to present a (usually state-based) abstract security model separately from the specification of the system's functional requirements. and establishing a correspondence between the two specifications. This complex treatment has resulted in development methods distinct from those usually advocated for general applications.We provide a novel and intellectually satisfying formulation of security properties in a process algebraic framework. and show that these are preserved under refinement. We relate the results to a more familiar state-based (Z) specification methodology. There are efficient algorithms for verifying our security properties using model checking.,True,bO-FeTIAAAAJ:9yKSN-GCB0IC,152,https://link.springer.com/chapter/10.1007/3-540-58618-0_55,17125024982320130054,/scholar?cites=17125024982320130054,,,https://link.springer.com/content/pdf/10.1007/3-540-58618-0_55.pdf,0,0,0
1276561,A concurrent language for refinement,2001,Jim Woodcock and Ana Cavalcanti,,5th Irish Workshop on Formal Methods 5,,1-16,,We present a combination of the well-established formal specification languages Z and CSP; our objective is to provide support for the specification of both data and behaviour aspects of concurrent systems. and a development technique. The resulting language.  Circus . distinguishes itself in that it is aimed at the calculational refinement of specifications to programs written in a language similar to occam and  Handel-C . In this paper. we present  Circus . the rationale for its design. and a case study in its use.,True,bO-FeTIAAAAJ:FAceZFleit8C,149,https://www.scienceopen.com/hosted-document?doi=10.14236/ewic/IWFM2001.7,16392211284597049518,/scholar?cites=16392211284597049518,,,https://www.scienceopen.com/document_file/83957186-0ddc-4397-b7db-75c8cfe6070f/ScienceOpen/001_Woodcock.pdf,0,0,0
1276562,Combined measurements of Higgs boson production and decay using up to  of proton-proton collision data at  collected with the ATLAS experiment,2020,Georges Aad and Brad Abbott and Dale Charles Abbott and A Abed Abud and K Abeling and DK Abhayasinghe and SH Abidi and OS AbouZeid and NL Abraham and H Abramowicz and H Abreu and Y Abulaiti and BS Acharya and B Achkar and S Adachi and L Adam and C Adam Bourdarios and L Adamczyk and L Adamek and J Adelman and M Adersberger and A Adiguzel and S Adorni and T Adye and AA Affolder and Y Afik and C Agapopoulou and MN Agaras and A Aggarwal and C Agheorghiesei and JA Aguilar-Saavedra and F Ahmadov and WS Ahmed and X Ai and G Aielli and S Akatsuka and TPA Åkesson and E Akilli and AV Akimov and K Al Khoury and GL Alberghi and J Albert and MJ Alconada Verzini and S Alderweireldt and M Aleksa and IN Aleksandrov and C Alexa and D Alexandre and T Alexopoulos and A Alfonsi and M Alhroob and B Ali and G Alimonti and J Alison and SP Alkire and C Allaire and BMM Allbrooke and BW Allen and PP Allport and A Aloisio and A Alonso and F Alonso and C Alpigiani and AA Alshehri and M Alvarez Estevez and D Álvarez Piqueras and MG Alviggi and Y Amaral Coutinho and A Ambler and L Ambroz and C Amelung and D Amidei and SP Amor Dos Santos and S Amoroso and CS Amrouche and F An and C Anastopoulos and N Andari and T Andeen and CF Anders and JK Anders and A Andreazza and V Andrei and CR Anelli and S Angelidakis and A Angerami and AV Anisenkov and A Annovi and C Antel and MT Anthony and M Antonelli and DJA Antrim and F Anulli and M Aoki and JA Aparisi Pozo and L Aperio Bella and G Arabidze and JP Araque and V Araujo Ferraz and R Araujo Pereira and C Arcangeletti and ATH Arce and FA Arduh and JF Arguin and S Argyropoulos and J-H Arling and AJ Armbruster and LJ Armitage and A Armstrong and O Arnaez and H Arnold and A Artamonov and G Artoni and S Artz and S Asai and N Asbah and EM Asimakopoulou and L Asquith and K Assamagan and R Astalos and RJ Atkin and M Atkinson and NB Atlay and H Atmani and K Augsten and G Avolio and R Avramidou and MK Ayoub and AM Azoulay and G Azuelos and MJ Baca and H Bachacou and K Bachas and M Backes and F Backman and P Bagnaia and M Bahmani and H Bahrasemani and AJ Bailey and VR Bailey and JT Baines and M Bajic and C Bakalis and OK Baker and PJ Bakker and D Bakshi Gupta and S Balaji and EM Baldin and P Balek and F Balli,101,Physical Review D,1,012002,American Physical Society,Combined measurements of Higgs boson production cross sections and branching fractions are presented. The combination is based on the analyses of the Higgs boson decay modes H→ γ γ. Z Z*. W W*. τ τ. b b. μ μ. searches for decays into invisible final states. and on measurements of off-shell Higgs boson production. Up to 79.8 fb− 1 of proton–proton collision data collected at s= 13 TeV with the ATLAS detector are used. Results are presented for the gluon–gluon fusion and vector-boson fusion processes. and for associated production with vector bosons or top-quarks. The global signal strength is determined to be μ= 1.1 1− 0.08+ 0.09. The combined measurement yields an observed (expected) significance for the vector-boson fusion production process of 6.5 σ (5.3 σ). Measurements in kinematic regions defined within the simplified template cross section framework are also shown. The results are interpreted …,True,U2tkWyEAAAAJ:2v_ZtQDX9iAC,438,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.101.012002,278015124616932849,/scholar?cites=278015124616932849,,,https://link.aps.org/pdf/10.1103/PhysRevD.101.012002,0,0,0
1276563,Comparison of PCR and microscopy for detection of Cryptosporidium parvum in human fecal specimens: clinical trial,1998,f UM Morgan and L Pallant and BW Dwyer and DA Forbes and G Rich and RCA Thompson,36,Journal of Clinical Microbiology,4,995-998,American Society for Microbiology Journals,PCR technology offers alternatives to conventional diagnosis ofCryptosporidium for both clinical and environmental samples. We compared microscopic examination by a conventional acid-fast staining procedure with a recently developed PCR test that can not only detect Cryptosporidium but is also able to differentiate between what appear to be host-adapted genotypes of the parasite. Examinations were performed on 511 stool specimens referred for screening on the basis of diarrhea. PCR detected a total of 36 positives out of the 511 samples. while routine microscopy detected 29 positives. Additional positives detected by PCR were eventually confirmed to be positive by microscopy. A total of five samples that were positive by routine microscopy at Western Diagnostic Pathology but negative by PCR and by microscopy in our laboratory were treated as false positives. Microscopy therefore exhibited 83.7 …,True,U2tkWyEAAAAJ:F2UWTTQJPOcC,309,https://jcm.asm.org/content/36/4/995.short,4883413381241361088,/scholar?cites=4883413381241361088,,,https://jcm.asm.org/content/jcm/36/4/995.full.pdf,0,0,0
1276564,Meaurement of the production cro ection for a Z boon and one or more b jet in pp colliion at $$\qrt {} $$= 7 TeV,2014,Serguei Chatrchyan and V Khachatryan and AM Sirunyan and A Tumasyan and W Adam and T Bergauer and M Dragicevic and J Erö and C Fabjan and M Friedl and R Fruehwirth and VM Ghete and N Hoermann and J Hrubec and M Jeitler and W Kiesenhofer and V Knuenz and M Krammer and I Kraetschmer and D Liko and I Mikulec and D Rabady and B Rahbaran and C Rohringer and H Rohringer and R Schoefbeck and J Strauss and A Taurok and W Treberer-Treberspurg and W Waltenberger and C-E Wulz and V Mossolov and N Shumeiko and J Suarez Gonzalez and S Alderweireldt and M Bansal and S Bansal and T Cornelis and EA De Wolf and X Janssen and A Knutsson and S Luyckx and L Mucibello and S Ochesanu and B Roland and R Rougny and Z Staykova and H Van Haevermaet and P Van Mechelen and N Van Remortel and A Van Spilbeeck and F Blekman and S Blyweert and J D’Hondt and A Kalogeropoulos and J Keaveney and M Maes and A Olbrechts and S Tavernier and W Van Doninck and P Van Mulders and GP Van Onsem and I Villella and C Caillol and B Clerbaux and G De Lentdecker and L Favart and APR Gay and T Hreus and A Leonard and PE Marage and A Mohammadi and L Pernie and T Reis and T Seva and L Thomas and C Vander Velde and P Vanlaer and J Wang and Volker Adler and Kelly Beernaert and Leonardo Benucci and Anna Cimmino and Silvia Costantini and Sven Dildick and Guillaume Garcia and Benjamin Klein and Jeremie Lellouch and Andrey Marinov and Joseph McCartin and AA Ocampo Rios and Dirk Ryckbosch and Michael Sigamani and Nadja Strobbe and Filip Thyssen and Michael Tytgat and S Walsh and Efe Yazgan and Nikolaos Zaganidis and S Basegmez and C Beluffi and G Bruno and R Castello and A Caudron and L Ceard and GG Da Silveira and C Delaere and T Du Pree and D Favart and L Forthomme and A Giammanco and J Hollar and P Jez and V Lemaitre and J Liao and O Militaru and C Nuttens and D Pagano and A Pin and K Piotrzkowski and A Popov and M Selvaggi and JM Vizan Garcia and N Beliy and T Caebergs and E Daubie and GH Hammad and GA Alves and M Correa Martins and T Martins and ME Pol and MHG Souza and WL Aldá and W Carvalho and J Chinellato and A Custodio and EM Da Costa and D De Jesus Damiao and C De Oliveira Martins and S Fonseca De Souza and H Malbouisson and M Malek and D Matos Figueiredo and L Mundim and H Nogima and WL Prado Da Silva and A Santoro and A Sznajder and EJ Tonelli Manganote and A Vilela Pereira,2014,Journal of High Energy Physics,6,120,Springer Berlin Heidelberg,The production of a Z boson. decaying into two leptons and produced in association with one or more b jets. is studied using proton-proton collisions delivered by the LHC at a centre-of-mass energy of 7 TeV. The data were recorded in 2011 with the CMS detector and correspond to an integrated luminosity of 5 fb− 1. The Z (ℓℓ)+ b-jets cross sections (where ℓℓ= μμ or ee) are measured separately for a Z boson produced with exactly one b jet and with at least two b jets. In addition. a cross section ratio is extracted for a Z boson produced with at least one b jet. relative to a Z boson produced with at least one jet. The measured cross sections are compared to various theoretical predictions. and the data favour the predictions in the five-flavour scheme. where b quarks are assumed massless. The kinematic properties of the reconstructed particles are compared with the predictions from the M ad G raph event generator …,True,U2tkWyEAAAAJ:OU6Ihb5iCvQC,223,https://link.springer.com/content/pdf/10.1007/JHEP06(2014)120.pdf,12289628905119957135,/scholar?cites=12289628905119957135,,,https://link.springer.com/content/pdf/10.1007/JHEP06(2014)120.pdf,0,0,0
1276565,Production and optimization of cellulase-free. alkali-stable xylanase by Bacillus pumilus SV-85S in submerged fermentation,2010,Sushil Nagar and Vijay Kumar Gupta and Davender Kumar and Lalit Kumar and Ramesh Chander Kuhad,37,Journal of Industrial Microbiology and Biotechnology,1,71-83,Oxford University Press,This paper reports the production of a cellulase-free and alkali-stable xylanase in high titre from a newly isolated Bacillus pumilus SV-85S using cheap and easily available agro-residue wheat bran. Optimization of fermentation conditions enhanced the enzyme production to 2995.20 ± 200.00 IU/ml. which was 9.91-fold higher than the activity under unoptimized basal medium (302.2 IU/ml). Statistical optimization using response-surface methodology was employed to obtain a cumulative effect of peptone. yeast extract. and potassium nitrate (KNO3) on enzyme production. A 23 central composite design best optimized the nitrogen source at the 0 level for peptone and yeast extract and at the −α level for KNO3. along with 5.38-fold increase in xylanase activity. Addition of 0.1% tween 80 to the medium increased production by 1.5-fold. Optimum pH for xylanase was 6.0. The enzyme was 100% stable over the pH …,True,U2tkWyEAAAAJ:qE4H1tSSYIIC,146,https://academic.oup.com/jimb/article-abstract/37/1/71/5993908,15636452894323418659,/scholar?cites=15636452894323418659,,,https://academic.oup.com/jimb/article/37/1/71/5993908,0,0,0
1276566,Combination of the Searches for Pair-Produced Vectorlike Partners of the Third-Generation Quarks at  with the ATLAS Detector,2018,Morad Aaboud and Georges Aad and Brad Abbott and B Abeloos and DK Abhayasinghe and SH Abidi and OS AbouZeid and NL Abraham and H Abramowicz and H Abreu and Y Abulaiti and BS Acharya and S Adachi and L Adam and L Adamczyk and J Adelman and M Adersberger and A Adiguzel and T Adye and AA Affolder and Y Afik and C Agheorghiesei and JA Aguilar-Saavedra and F Ahmadov and G Aielli and S Akatsuka and TPA Åkesson and E Akilli and AV Akimov and GL Alberghi and J Albert and P Albicocco and MJ Alconada Verzini and S Alderweireldt and M Aleksa and IN Aleksandrov and C Alexa and T Alexopoulos and M Alhroob and B Ali and G Alimonti and J Alison and SP Alkire and C Allaire and BMM Allbrooke and BW Allen and PP Allport and A Aloisio and A Alonso and F Alonso and C Alpigiani and AA Alshehri and MI Alstaty and B Alvarez Gonzalez and D Álvarez Piqueras and MG Alviggi and BT Amadio and Y Amaral Coutinho and A Ambler and L Ambroz and C Amelung and D Amidei and SP Amor Dos Santos and S Amoroso and CS Amrouche and C Anastopoulos and LS Ancu and N Andari and T Andeen and CF Anders and JK Anders and KJ Anderson and A Andreazza and V Andrei and CR Anelli and S Angelidakis and I Angelozzi and A Angerami and AV Anisenkov and A Annovi and C Antel and MT Anthony and M Antonelli and DJA Antrim and F Anulli and M Aoki and JA Aparisi Pozo and L Aperio Bella and G Arabidze and JP Araque and V Araujo Ferraz and R Araujo Pereira and ATH Arce and RE Ardell and FA Arduh and JF Arguin and S Argyropoulos and AJ Armbruster and LJ Armitage and A Armstrong and O Arnaez and H Arnold and M Arratia and O Arslan and A Artamonov and G Artoni and S Artz and S Asai and N Asbah and EM Asimakopoulou and L Asquith and K Assamagan and R Astalos and RJ Atkin and M Atkinson and NB Atlay and K Augsten and G Avolio and R Avramidou and MK Ayoub and AM Azoulay and G Azuelos and AE Baas and MJ Baca and H Bachacou and K Bachas and M Backes and P Bagnaia and M Bahmani and H Bahrasemani and AJ Bailey and JT Baines and M Bajic and C Bakalis and OK Baker and PJ Bakker and D Bakshi Gupta and S Balaji and EM Baldin and P Balek and F Balli and WK Balunas and J Balz and E Banas and A Bandyopadhyay and S Banerjee and AAE Bannoura and L Barak and WM Barbe and EL Barberio,121,Physical review letters,21,211801,American Physical Society,A combination of the searches for pair-produced vectorlike partners of the top and bottom quarks in various decay channels (T→ Z t/W b/H t. B→ Z b/W t/H b) is performed using 36.1 fb− 1 of p p collision data at s= 13 TeV with the ATLAS detector at the Large Hadron Collider. The observed data are found to be in good agreement with the standard model background prediction in all individual searches. Therefore. combined 95% confidence-level upper limits are set on the production cross section for a range of vectorlike quark scenarios. significantly improving upon the reach of the individual searches. Model-independent limits are set assuming the vectorlike quarks decay to standard model particles. A singlet T is excluded for masses below 1.31 TeV and a singlet B is excluded for masses below 1.22 TeV. Assuming a weak isospin (T. B) doublet and| V T b|≪| V t B|. T and B masses below 1.37 TeV are excluded.,True,U2tkWyEAAAAJ:OR75R8vi5nAC,143,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.211801,17249006458618084140,/scholar?cites=17249006458618084140,,,https://link.aps.org/pdf/10.1103/PhysRevLett.121.211801,0,0,0
1276567,Performance of electron and photon triggers in ATLAS during LHC Run 2,2020,Georges Aad and Brad Abbott and Dale Charles Abbott and A Abed Abud and Kira Abeling and Deshan Kavishka Abhayasinghe and Syed Haider Abidi and OS AbouZeid and NL Abraham and Halina Abramowicz and Henso Abreu and Yiming Abulaiti and Bobby Samir Acharya and Baida Achkar and Shunsuke Adachi and Lennart Adam and C Adam Bourdarios and Leszek Adamczyk and Lukas Adamek and Jahred Adelman and Michael Adersberger and Aytul Adiguzel and Sofia Adorni and Tim Adye and AA Affolder and Yoav Afik and Christina Agapopoulou and Merve Nazlim Agaras and Anamika Aggarwal and Catalin Agheorghiesei and JA Aguilar-Saavedra and Faig Ahmadov and Waleed Syed Ahmed and Xiaocong Ai and Giulio Aielli and Shunichi Akatsuka and TPA Åkesson and Ece Akilli and AV Akimov and Konie Al Khoury and Gian Luigi Alberghi and Justin Albert and MJ Alconada Verzini and S Alderweireldt and Martin Aleksa and IN Aleksandrov and Calin Alexa and Theodoros Alexopoulos and Alice Alfonsi and Fabrizio Alfonsi and Muhammad Alhroob and Babar Ali and Malik Aliev and Gianluca Alimonti and Steven Patrick Alkire and Corentin Allaire and BMM Allbrooke and Benjamin William Allen and PP Allport and Alberto Aloisio and Alejandro Alonso and Francisco Alonso and Cristiano Alpigiani and Azzah Aziz Alshehri and M Alvarez Estevez and D Álvarez Piqueras and MG Alviggi and Y Amaral Coutinho and Alessandro Ambler and Luca Ambroz and Christoph Amelung and D Amidei and SP Amor Dos Santos and Simone Amoroso and Cherifa Sabrina Amrouche and Fenfen An and Christos Anastopoulos and Nansi Andari and Timothy Andeen and Christoph Falk Anders and John Kenneth Anders and Attilio Andreazza and V Andrei and Christopher Ryan Anelli and Stylianos Angelidakis and Aaron Angerami and AV Anisenkov and Alberto Annovi and Claire Antel and Matthew Thomas Anthony and Egor Antipov and Mario Antonelli and DJA Antrim and Fabio Anulli and Masato Aoki and JA Aparisi Pozo and L Aperio Bella and JP Araque and V Araujo Ferraz and R Araujo Pereira and Chiara Arcangeletti and ATH Arce and Francisco Anuar Arduh and Jean-Francois Arguin and Spyridon Argyropoulos and J-H Arling and Aaron James Armbruster and Alexander Armstrong and Olivier Arnaez and Hannah Arnold and ZP Arrubarrena Tame and Giacomo Artoni and Sebastian Artz and Shoji Asai and Nedaa Asbah and Eleni Myrto Asimakopoulou and Lily Asquith and Jihad Assahsah and Ketevi Assamagan and Robert Astalos and Ryan Justin Atkin and Markus Atkinson and Naim Bora Atlay and Hicham Atmani and Kamil Augsten and Giuseppe Avolio and R Avramidou and Mohamad Kassem Ayoub and Adam Maxwell Azoulay and Georges Azuelos and Henri Bachacou and Konstantinos Bachas and Moritz Backes and Filip Backman and Paolo Bagnaia and Marzieh Bahmani and H Bahrasemani and AJ Bailey and Virginia Ruth Bailey and JT Baines and Milena Bajic and Christos Bakalis and OK Baker and Pepijn Johannes Bakker and D Bakshi Gupta and Shyam Balaji and EM Baldin and Petr Balek and Fabrice Balli and William Keaton Balunas,80,The European Physical Journal C,1,47,Springer Berlin Heidelberg,Electron and photon triggers covering transverse energies from 5  to several  are essential for the ATLAS experiment to record signals for a wide variety of physics: from Standard Model processes to searches for new phenomena in both proton–proton and heavy-ion collisions. To cope with a fourfold increase of peak LHC luminosity from 2015 to 2018 (Run 2). to . and a similar increase in the number of interactions per beam-crossing to about 60. trigger algorithms and selections were optimised to control the rates while retaining a high efficiency for physics analyses. For proton–proton collisions. the single-electron trigger efficiency relative to a single-electron offline selection is at least 75% for an offline electron of 31 . and rises to 96% at 60 ; the trigger efficiency of a 25  leg of the primary diphoton trigger relative to a tight offline photon selection is more than 96% for an offline photon of …,True,U2tkWyEAAAAJ:oqD4_j7ulsYC,135,https://link.springer.com/article/10.1140/epjc/s10052-019-7500-2,1725420954053426904,/scholar?cites=1725420954053426904,,,https://link.springer.com/article/10.1140/epjc/s10052-019-7500-2,0,0,0
1276568,Combination of searches for Higgs boson pairs in pp collisions at s= 13TeV with the ATLAS detector,2020,Georges Aad and Brad Abbott and Dale Charles Abbott and A Abed Abud and Kira Abeling and Deshan Kavishka Abhayasinghe and Syed Haider Abidi and OS AbouZeid and Nadine L Abraham and Halina Abramowicz and Henso Abreu and Yiming Abulaiti and Bobby Samir Acharya and Baida Achkar and Shunsuke Adachi and Lennart Adam and C Adam Bourdarios and Leszek Adamczyk and Lukas Adamek and Jahred Adelman and Michael Adersberger and Aytul Adiguzel and Sofia Adorni and Tim Adye and AA Affolder and Yoav Afik and Christina Agapopoulou and Merve Nazlim Agaras and Anamika Aggarwal and Catalin Agheorghiesei and JA Aguilar-Saavedra and Faig Ahmadov and Waleed Syed Ahmed and Xiaocong Ai and Giulio Aielli and Shunichi Akatsuka and TPA Åkesson and Ece Akilli and AV Akimov and Konie Al Khoury and Gian Luigi Alberghi and Justin Albert and MJ Alconada Verzini and S Alderweireldt and Martin Aleksa and IN Aleksandrov and Calin Alexa and Didier Alexandre and Theodoros Alexopoulos and Alice Alfonsi and Muhammad Alhroob and Babar Ali and Gianluca Alimonti and John Alison and Steven Patrick Alkire and Corentin Allaire and BMM Allbrooke and Benjamin William Allen and PP Allport and Alberto Aloisio and Alejandro Alonso and Francisco Alonso and Cristiano Alpigiani and Azzah Aziz Alshehri and M Alvarez Estevez and D Álvarez Piqueras and MG Alviggi and Y Amaral Coutinho and Alessandro Ambler and Luca Ambroz and Christoph Amelung and D Amidei and SP Amor Dos Santos and Simone Amoroso and Cherifa Sabrina Amrouche and Fenfen An and Christos Anastopoulos and Nansi Andari and Timothy Andeen and Christoph Falk Anders and John Kenneth Anders and Attilio Andreazza and V Andrei and Christopher Ryan Anelli and Stylianos Angelidakis and Aaron Angerami and AV Anisenkov and Alberto Annovi and Claire Antel and Matthew Thomas Anthony and Mario Antonelli and DJA Antrim and Fabio Anulli and Masato Aoki and JA Aparisi Pozo and L Aperio Bella and Giorgi Arabidze and JP Araque and V Araujo Ferraz and R Araujo Pereira and Chiara Arcangeletti and ATH Arce and Francisco Anuar Arduh and Jean-Francois Arguin and Spyridon Argyropoulos and J-H Arling and Aaron James Armbruster and Alexander Armstrong and Olivier Arnaez and Hannah Arnold and Andrei Artamonov and Giacomo Artoni and Sebastian Artz and Shoji Asai and Nedaa Asbah and Eleni Myrto Asimakopoulou and Lily Asquith and Ketevi Assamagan and Robert Astalos and Ryan Justin Atkin and Markus Atkinson and Naim Bora Atlay and Hicham Atmani and Kamil Augsten and Giuseppe Avolio and R Avramidou and Mohamad Kassem Ayoub and Adam Maxwell Azoulay and Georges Azuelos and Henri Bachacou and Konstantinos Bachas and Moritz Backes and Filip Backman and Paolo Bagnaia and Marzieh Bahmani and H Bahrasemani and AJ Bailey and Virginia Ruth Bailey and JT Baines and Milena Bajic and Christos Bakalis and OK Baker and Pepijn Johannes Bakker and D Bakshi Gupta and Shyam Balaji and EM Baldin and Petr Balek and Fabrice Balli and William Keaton Balunas and Johannes Balz,800,Physics Letters B,,135103,North-Holland,This letter presents a combination of searches for Higgs boson pair production using up to 36.1 fb− 1 of proton–proton collision data at a centre-of-mass energy s= 13 TeV recorded with the ATLAS detector at the LHC. The combination is performed using six analyses searching for Higgs boson pairs decaying into the b b¯ b b¯. b b¯ W+ W−. b b¯ τ+ τ−. W+ W− W+ W−. b b¯ γ γ and W+ W− γ γ final states. Results are presented for non-resonant and resonant Higgs boson pair production modes. No statistically significant excess in data above the Standard Model predictions is found. The combined observed (expected) limit at 95% confidence level on the non-resonant Higgs boson pair production cross-section is 6.9 (10) times the predicted Standard Model cross-section. Limits are also set on the ratio (κ λ) of the Higgs boson self-coupling to its Standard Model value. This ratio is constrained at 95% confidence level in …,True,U2tkWyEAAAAJ:MAUkC_7iAq8C,130,https://www.sciencedirect.com/science/article/pii/S0370269319308251,5054892259278647097,/scholar?cites=5054892259278647097,,,https://www.sciencedirect.com/science/article/pii/S0370269319308251,0,0,0
1276569,Measurement of the  and  cross sections in proton-proton collisions at  with the ATLAS detector,2019,Morad Aaboud and Georges Aad and Brad Abbott and Dale Charles Abbott and B Abeloos and DK Abhayasinghe and SH Abidi and OS AbouZeid and NL Abraham and H Abramowicz and H Abreu and Y Abulaiti and BS Acharya and S Adachi and L Adam and L Adamczyk and L Adamek and J Adelman and M Adersberger and A Adiguzel and T Adye and AA Affolder and Y Afik and C Agheorghiesei and JA Aguilar-Saavedra and F Ahmadov and G Aielli and S Akatsuka and TPA Åkesson and E Akilli and AV Akimov and GL Alberghi and J Albert and P Albicocco and MJ Alconada Verzini and S Alderweireldt and M Aleksa and IN Aleksandrov and C Alexa and D Alexandre and T Alexopoulos and M Alhroob and B Ali and G Alimonti and J Alison and SP Alkire and C Allaire and BMM Allbrooke and BW Allen and PP Allport and A Aloisio and A Alonso and F Alonso and C Alpigiani and AA Alshehri and MI Alstaty and B Alvarez Gonzalez and D Álvarez Piqueras and MG Alviggi and BT Amadio and Y Amaral Coutinho and A Ambler and L Ambroz and C Amelung and D Amidei and SP Amor Dos Santos and S Amoroso and CS Amrouche and F An and C Anastopoulos and LS Ancu and N Andari and T Andeen and CF Anders and JK Anders and KJ Anderson and A Andreazza and V Andrei and CR Anelli and S Angelidakis and I Angelozzi and A Angerami and AV Anisenkov and A Annovi and C Antel and MT Anthony and M Antonelli and DJA Antrim and F Anulli and M Aoki and JA Aparisi Pozo and L Aperio Bella and G Arabidze and JP Araque and V Araujo Ferraz and R Araujo Pereira and ATH Arce and RE Ardell and FA Arduh and JF Arguin and S Argyropoulos and J-H Arling and AJ Armbruster and LJ Armitage and A Armstrong and O Arnaez and H Arnold and M Arratia and O Arslan and A Artamonov and G Artoni and S Artz and S Asai and N Asbah and EM Asimakopoulou and L Asquith and K Assamagan and R Astalos and RJ Atkin and M Atkinson and NB Atlay and K Augsten and G Avolio and R Avramidou and MK Ayoub and AM Azoulay and G Azuelos and AE Baas and MJ Baca and H Bachacou and K Bachas and M Backes and P Bagnaia and M Bahmani and H Bahrasemani and AJ Bailey and VR Bailey and JT Baines and M Bajic and C Bakalis and OK Baker and PJ Bakker and D Bakshi Gupta and S Balaji and EM Baldin and P Balek and F Balli and WK Balunas and J Balz and E Banas,99,Physical Review D,7,072009,American Physical Society,A measurement of the associated production of a top-quark pair (t t) with a vector boson (W. Z) in proton-proton collisions at a center-of-mass energy of 13 TeV is presented. using 36.1 fb− 1 of integrated luminosity collected by the ATLAS detector at the Large Hadron Collider. Events are selected in channels with two same-or opposite-sign leptons (electrons or muons). three leptons or four leptons. and each channel is further divided into multiple regions to maximize the sensitivity of the measurement. The t t Z and t t W production cross sections are simultaneously measured using a combined fit to all regions. The best-fit values of the production cross sections are σ t t Z= 0.95±0.0 8 stat±0.1 0 syst pb and σ t t W= 0.87±0.1 3 stat±0.1 4 syst pb in agreement with the Standard Model predictions. The measurement of the t t Z cross section is used to set constraints on effective field theory operators which modify the t t Z …,True,U2tkWyEAAAAJ:PR6Y55bgFSsC,119,https://journals.aps.org/prd/abstract/10.1103/PhysRevD.99.072009,17818998372995198204,/scholar?cites=17818998372995198204,,,https://link.aps.org/pdf/10.1103/PhysRevD.99.072009,0,0,0
1276570,Increasing the astrophysical reach of the advanced virgo detector via the application of squeezed vacuum states of light,2019,Fausto Acernese and M Agathos and L Aiello and A Allocca and A Amato and S Ansoldi and S Antier and M Arène and N Arnaud and S Ascenzi and P Astone and F Aubin and S Babak and P Bacon and F Badaracco and MKM Bader and J Baird and F Baldaccini and G Ballardin and G Baltus and C Barbieri and P Barneo and F Barone and M Barsuglia and D Barta and A Basti and M Bawaj and M Bazzan and M Bejger and I Belahcene and S Bernuzzi and D Bersanetti and A Bertolini and M Bischi and M Bitossi and MA Bizouard and F Bobba and M Boer and G Bogaert and François Bondu and R Bonnand and BA Boom and V Boschi and Y Bouffanais and A Bozzi and C Bradaschia and M Branchesi and M Breschi and T Briant and F Brighenti and A Brillet and J Brooks and G Bruno and T Bulik and HJ Bulten and D Buskulic and G Cagnoli and E Calloni and M Canepa and G Carapella and F Carbognani and G Carullo and J Casanueva Diaz and C Casentini and J Castañeda and S Caudill and F Cavalier and R Cavalieri and G Cella and P Cerdá-Durán and E Cesarini and O Chaibi and E Chassande-Mottin and F Chiadini and R Chierici and A Chincarini and A Chiummo and N Christensen and S Chua and G Ciani and P Ciecielag and M Cieślar and R Ciolfi and F Cipriano and A Cirone and S Clesse and F Cleva and E Coccia and P-F Cohadon and D Cohen and M Colpi and L Conti and I Cordero-Carrión and S Corezzi and D Corre and S Cortese and J-P Coulon and M Croquette and J-R Cudell and E Cuoco and M Curylo and B D’Angelo and S D’Antonio and V Dattilo and M Davier and J Degallaix and M De Laurentis and S Deléglise and W Del Pozzo and R De Pietri and R De Rosa and C De Rossi and T Dietrich and L Di Fiore and C Di Giorgio and F Di Giovanni and M Di Giovanni and T Di Girolamo and A Di Lieto and S Di Pace and I Di Palma and F Di Renzo and M Drago and J-G Ducoin and O Durante and D D’Urso and M Eisenmann and L Errico and D Estevez and V Fafone and S Farinon and F Feng and E Fenyvesi and I Ferrante and F Fidecaro and I Fiori and D Fiorucci and R Fittipaldi and V Fiumara and R Flaminio and JA Font and J-D Fournier and S Frasca and F Frasconi and V Frey and G Fronzè and F Garufi and G Gemme and E Genin and A Gennai,123,Physical review letters,23,231108,American Physical Society,Current interferometric gravitational-wave detectors are limited by quantum noise over a wide range of their measurement bandwidth. One method to overcome the quantum limit is the injection of squeezed vacuum states of light into the interferometer’s dark port. Here. we report on the successful application of this quantum technology to improve the shot noise limited sensitivity of the Advanced Virgo gravitational-wave detector. A sensitivity enhancement of up to 3.2±0.1 dB beyond the shot noise limit is achieved. This nonclassical improvement corresponds to a 5%–8% increase of the binary neutron star horizon. The squeezing injection was fully automated and over the first 5 months of the third joint LIGO-Virgo observation run O3 squeezing was applied for more than 99% of the science time. During this period several gravitational-wave candidates have been recorded.,True,U2tkWyEAAAAJ:TaaCk18tZOkC,115,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.231108,1500157906147748151,/scholar?cites=1500157906147748151,,,https://link.aps.org/pdf/10.1103/PhysRevLett.123.231108,0,0,0
1276571,Search for electroweak production of charginos and sleptons decaying into final states with two leptons and missing transverse momentum in s=13   TeV …,2020,Georges Aad and Brad Abbott and Dale Charles Abbott and A Abed Abud and K Abeling and DK Abhayasinghe and SH Abidi and OS AbouZeid and NL Abraham and H Abramowicz and H Abreu and Y Abulaiti and BS Acharya and B Achkar and S Adachi and L Adam and L Adamczyk and L Adamek and J Adelman and M Adersberger and A Adiguzel and S Adorni and T Adye and AA Affolder and Y Afik and C Agapopoulou and MN Agaras and A Aggarwal and C Agheorghiesei and JA Aguilar-Saavedra and F Ahmadov and WS Ahmed and X Ai and G Aielli and S Akatsuka and TPA Åkesson and E Akilli and AV Akimov and K Al Khoury and GL Alberghi and J Albert and MJ Alconada Verzini and S Alderweireldt and M Aleksa and IN Aleksandrov and C Alexa and D Alexandre and T Alexopoulos and A Alfonsi and M Alhroob and B Ali and G Alimonti and J Alison and SP Alkire and C Allaire and BMM Allbrooke and BW Allen and PP Allport and A Aloisio and A Alonso and F Alonso and C Alpigiani and AA Alshehri and M Alvarez Estevez and D Álvarez Piqueras and MG Alviggi and Y Amaral Coutinho and A Ambler and L Ambroz and C Amelung and D Amidei and SP Amor Dos Santos and S Amoroso and CS Amrouche and F An and C Anastopoulos and N Andari and T Andeen and CF Anders and JK Anders and A Andreazza and V Andrei and CR Anelli and S Angelidakis and A Angerami and AV Anisenkov and A Annovi and C Antel and MT Anthony and M Antonelli and DJA Antrim and F Anulli and M Aoki and JA Aparisi Pozo and L Aperio Bella and G Arabidze and JP Araque and V Araujo Ferraz and R Araujo Pereira and C Arcangeletti and ATH Arce and FA Arduh and JF Arguin and S Argyropoulos and J-H Arling and AJ Armbruster and A Armstrong and O Arnaez and H Arnold and A Artamonov and G Artoni and S Artz and S Asai and N Asbah and EM Asimakopoulou and L Asquith and K Assamagan and R Astalos and RJ Atkin and M Atkinson and NB Atlay and H Atmani and K Augsten and G Avolio and R Avramidou and MK Ayoub and AM Azoulay and G Azuelos and MJ Baca and H Bachacou and K Bachas and M Backes and F Backman and P Bagnaia and M Bahmani and H Bahrasemani and AJ Bailey and VR Bailey and JT Baines and M Bajic and C Bakalis and OK Baker and PJ Bakker and D Bakshi Gupta and S Balaji and EM Baldin and P Balek and F Balli and WK Balunas and J Balz,80,The European Physical Journal C,2,1-33,Springer Berlin Heidelberg,A search for the electroweak production of charginos and sleptons decaying into final states with two electrons or muons is presented. The analysis is based on 139 fb of proton–proton collisions recorded by the ATLAS detector at the Large Hadron Collider at. Three R-parity-conserving scenarios where the lightest neutralino is the lightest supersymmetric particle are considered: the production of chargino pairs with decays via either W bosons or sleptons. and the direct production of slepton pairs. The analysis is optimised for the first of these scenarios. but the results are also interpreted in the others. No significant deviations from the Standard Model expectations are observed and limits at 95% confidence level are set on the masses of relevant supersymmetric particles in each of the scenarios. For a massless lightest neutralino. masses up to 420 are excluded for the production of the lightest-chargino …,True,U2tkWyEAAAAJ:I2jIoRS3jIgC,113,https://link.springer.com/article/10.1140/epjc/s10052-019-7594-6,14275609720457446070,/scholar?cites=14275609720457446070,,,https://link.springer.com/article/10.1140/epjc/s10052-019-7594-6,0,0,0
1276572,Observation of electroweak production of a same-sign W boson pair in association with two jets in pp collisions at s= 13TeV with the ATLAS detector,2019,ATLAS Collaboration and Paul Newman,123,Rev. Lett,,161801,,Unless a licence is specified above. all rights (including copyright and moral rights) in this document are retained by the authors and/or the copyright holders. The express permission of the copyright holder must be obtained for any use of this material other than for purposes permitted by law.,True,U2tkWyEAAAAJ:hHIA4WEVY-EC,104,https://core.ac.uk/download/pdf/267320085.pdf,12299460116224739484,/scholar?cites=12299460116224739484,,,https://core.ac.uk/download/pdf/267320085.pdf,0,0,0
1276573,A taxonomy of scheduling in general-purpose distributed computing systems,1988,Thomas L.  Casavant and Jon G.  Kuhl,14,IEEE Transactions on software engineering,2,141-154,IEEE,One measure of the usefulness of a general-purpose distributed computing system is the system's ability to provide a level of performance commensurate to the degree of multiplicity of resources present in the system. A taxonomy of approaches to the resource management problem is presented in an attempt to provide a common terminology and classification mechanism necessary in addressing this problem. The taxonomy. while presented and discussed in terms of distributed scheduling. is also applicable to most types of resource management.< >,True,4uiMIaEAAAAJ:u5HHmVD_uO8C,1597,https://ieeexplore.ieee.org/abstract/document/4634/,5923345849705757531,/scholar?cites=5923345849705757531,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.2600&rep=rep1&type=pdf,0,0,0
1276574,Functional annotation of a full-length mouse cDNA collection,2001,J Kawai and A Shinagawa and K Shibata and M Yoshino and M Itoh and Y Ishii and T Arakawa and A Hara and Y Fukunishi and H Konno and J Adachi and S Fukuda and K Aizawa and M Izawa and K Nishi and H Kiyosawa and S Kondo and I Yamanaka and T Saito and Y Okazaki and T Gojobori and H Bono and T Kasukawa and R Saito and K Kadota and H Matsuda and M Ashburner and S Batalov and T Casavant and W Fleischmann and T Gaasterland and C Gissi and B King and H Kochiwa and P Kuehl and S Lewis and Y Matsuo and I Nikaido and G Pesole and J Quackenbush and LM Schriml and F Staubli and R Suzuki and Masaru Tomita and L Wagner and T Washio and K Sakai and T Okido and M Furuno and H Aono and R Baldarelli and G Barsh and J Blake and D Boffelli and N Bojunga and P Carninci and MF De Bonaldo and MJ Brownstein and C Bult and C Fletcher and M Fujita and M Gariboldi and Stefano Gustincich and D Hill and M Hofmann and DA Hume and M Kamiya and NH Lee and P Lyons and Luigi Marchionni and J Mashima and J Mazzarelli and P Mombaerts and P Nordone and B Ring and M Ringwald and I Rodriguez and N Sakamoto and H Sasaki and K Sato and C Schönbach and T Seya and Y Shibata and KF Storch and H Suzuki and K Toyo-Oka and KH Wang and C Weitz and C Whittaker and L Wilming and A Wynshaw-Boris and K Yoshida and Y Hasegawa and H Kawaji and S Kohtsuki and Y Hayashizaki,409,Nature,6821,685-689,Nature Publishing Group,The RIKEN Mouse Gene Encyclopaedia Project. a systematic approach to determining the full coding potential of the mouse genome. involves collection and sequencing of full-length complementary DNAs and physical mapping of the corresponding genes to the mouse genome. We organized an international functional annotation meeting (FANTOM) to annotate the first 21.076 cDNAs to be analysed in this project. Here we describe the first RIKEN clone collection. which is one of the largest described for any organism. Analysis of these cDNAs extends known gene families and identifies new ones.,True,4uiMIaEAAAAJ:S16KYo8Pm5AC,825,https://research.kaust.edu.sa/en/publications/functional-annotation-of-a-full-length-mouse-cdna-collection,18067464592734012304,/scholar?cites=18067464592734012304,,,https://research.kaust.edu.sa/en/publications/functional-annotation-of-a-full-length-mouse-cdna-collection,0,0,0
1276575,Discovery of five conserved β-defensin gene clusters using a computational search strategy,2002,Brian C Schutte and Joseph P Mitros and Jennifer A Bartlett and Jesse D Walters and Hong Peng Jia and Michael J Welsh and Thomas L Casavant and Paul B McCray,99,Proceedings of the National Academy of Sciences,4,2129-2133,National Academy of Sciences,The innate immune system includes antimicrobial peptides that protect multicellular organisms from a diverse spectrum of microorganisms. β-Defensins comprise one important family of mammalian antimicrobial peptides. The annotation of the human genome fails to reveal the expected diversity. and a recent query of the draft sequence with the blast search engine found only one new β-defensin gene (DEFB3). To define better the β-defensin gene family. we adopted a genomics approach that uses hmmer. a computational search tool based on hidden Markov models. in combination with blast. This strategy identified 28 new human and 43 new mouse β-defensin genes in five syntenic chromosomal regions. Within each syntenic cluster. the gene sequences and organization were similar. suggesting each cluster pair arose from a common ancestor and was retained because of conserved functions. Preliminary …,True,4uiMIaEAAAAJ:u-x6o8ySG0sC,612,https://www.pnas.org/content/99/4/2129.short,15991090510752536753,/scholar?cites=15991090510752536753,,,https://www.pnas.org/content/pnas/99/4/2129.full.pdf,0,0,0
1276576,The status. quality. and expansion of the NIH full-length cDNA project: the Mammalian Gene Collection (MGC),2004,Daniela S Gerhard and Lukas Wagner and Elise A Feingold and Carolyn M Shenmen and Lynette H Grouse and Greg Schuler and Steven L Klein and Susan Old and Rebekah Rasooly and Peter Good and Mark Guyer and Allison M Peck and Jeffery G Derge and David Lipman and Francis S Collins and Wonhee Jang and Steven Sherry and Mike Feolo and Leonie Misquitta and Eduardo Lee and Kirill Rotmistrovsky and Susan F Greenhut and Carl F Schaefer and Kenneth H Buetow and Tom I Bonner and David Haussler and Jim Kent and Mark Diekhans and Terry Furey and Michael Brent and Christa Prange and Kirsten Schreiber and Nicole Shapiro and Narayan K Bhat and Ralph F Hopkins and Florence Hsie and Tom Driscoll and M Bento Soares and Maria F Bonaldo and Tom L Casavant and Todd E Scheetz and Michael J Brownstein and Ted B Usdin and Shiraki Toshiyuki and Piero Carninci and Yulan Piao and Dawood B Dudekula and Minoru SH Ko and Koichi Kawakami and Yutaka Suzuki and Sumio Sugano and CE Gruber and MR Smith and Blake Simmons and Troy Moore and Richard Waterman and Stephen L Johnson and Yijun Ruan and Chia Lin Wei and S Mathavan and Preethi H Gunaratne and Jiaqian Wu and Angela M Garcia and Stephen W Hulyk and Edwin Fuh and Ye Yuan and Anna Sneed and Carla Kowis and Anne Hodgson and Donna M Muzny and John McPherson and Richard A Gibbs and Jessica Fahey and Erin Helton and Mark Ketteman and Anuradha Madan and Stephanie Rodrigues and Amy Sanchez and Michelle Whiting and Anup Madan and Alice C Young and Keith D Wetherby and Steven J Granite and Peggy N Kwong and Charles P Brinkley and Russell L Pearson and Gerard G Bouffard and Robert W Blakesly and Eric D Green and Mark C Dickson and Alex C Rodriguez and Jane Grimwood and Jeremy Schmutz and Richard M Myers and Yaron SN Butterfield and Malachi Griffith and Obi L Griffith and Martin I Krzywinski and Nancy Liao and Ryan Morrin and Diana Palmquist and Anca S Petrescu and Ursula Skalska and Duane E Smailus and Jeff M Stott and Angelique Schnerch and Jacqueline E Schein and Steven JM Jones and Robert A Holt and Agnes Baross and Marco A Marra and Sandra Clifton and Kathryn A Makowski and Stephanie Bosak and Joel Malek,14,Genome research,10 B,2121-2127,,The National Institutes of Health's Mammalian Gene Collection (MGC) project was designed to generate and sequence a publicly accessible cDNA resource containing a complete open reading frame (ORF) for every human and mouse gene. The project initially used a random strategy to select clones from a large number of cDNA libraries from diverse tissues. Candidate clones were chosen based on 5′-EST sequences. and then fully sequenced to high accuracy and analyzed by algorithms developed for this project. Currently. more than 11.000 human and 10.000 mouse genes are represented in MGC by at least one clone with a full ORF. The random selection approach is now reaching a saturation point. and a transition to protocols targeted at the missing transcripts is now required to complete the mouse and human collections. Comparison of the sequence of the MGC clones to reference genome sequences reveals that most cDNA clones are of very high sequence quality. although it is likely that some cDNAs may carry missense variants as a consequence of experimental artifact. such as PCR. cloning. or reverse transcriptase errors. Recently. a rat cDNA component was added to the project. and ongoing frog (Xenopus) and zebrafish (Danio) cDNA projects were expanded to take advantage of the high-throughput MGC pipeline.,True,4uiMIaEAAAAJ:Z5m8FVwuT1cC,584,https://profiles.wustl.edu/en/publications/the-status-quality-and-expansion-of-the-nih-full-length-cdna-proj,1687503982197358075,/scholar?cites=1687503982197358075,,,https://profiles.wustl.edu/en/publications/the-status-quality-and-expansion-of-the-nih-full-length-cdna-proj,0,0,0
1276577,Homozygosity mapping with SNP arrays identifies TRIM32. an E3 ubiquitin ligase. as a Bardet–Biedl syndrome gene (BBS11),2006,Annie P Chiang and John S Beck and Hsan-Jan Yen and Marwan K Tayeh and Todd E Scheetz and Ruth E Swiderski and Darryl Y Nishimura and Terry A Braun and Kwang-Youn A Kim and Jian Huang and Khalil Elbedour and Rivka Carmi and Diane C Slusarski and Thomas L Casavant and Edwin M Stone and Val C Sheffield,103,Proceedings of the National Academy of Sciences,16,6287-6292,National Academy of Sciences,The identification of mutations in genes that cause human diseases has largely been accomplished through the use of positional cloning. which relies on linkage mapping. In studies of rare diseases. the resolution of linkage mapping is limited by the number of available meioses and informative marker density. One recent advance is the development of high-density SNP microarrays for genotyping. The SNP arrays overcome low marker informativity by using a large number of markers to achieve greater coverage at finer resolution. We used SNP microarray genotyping for homozygosity mapping in a small consanguineous Israeli Bedouin family with autosomal recessive Bardet–Biedl syndrome (BBS; obesity. pigmentary retinopathy. polydactyly. hypogonadism. renal and cardiac abnormalities. and cognitive impairment) in which previous linkage studies using short tandem repeat polymorphisms failed to identify a …,True,4uiMIaEAAAAJ:2osOgNQ5qMEC,455,https://www.pnas.org/content/103/16/6287.short,14341592883669664251,/scholar?cites=14341592883669664251,,,https://www.pnas.org/content/pnas/103/16/6287.full.pdf,0,0,0
1276578,An autosomal genomic screen for autism. Collaborative linkage study of autism.,1999,Stacey Barrett and John C Beck and Raphael Bernier and Erica Bisson and Terry A Braun and Thomas L Casavant and Deb Childress and Susan E Folstein and Melissa Garcia and Mary Beth Gardiner and Stephen Gilman and Jonathan L Haines and Kelly Hopkins and Rebecca Landa and Nicole H Meyer and Julie Ann Mullane and Daryl Y Nishimura and Pat Palmer and Joseph Piven and Joy Purdy and Susan L Santangelo and Charles Searby and Val Sheffield and Jennifer Singleton and Susan Slager,88,American journal of medical genetics,6,609-615,,Autism is a severe neurodevelopmental disorder defined by social and communication deficits and ritualistic-repetitive behaviors that are detectable in early childhood. The etiology of idiopathic autism is strongly genetic. and oligogenic transmission is likely. The first stage of a two-stage genomic screen for autism was carried out by the Collaborative Linkage Study of Autism on individuals affected with autism from 75 families ascertained through an affected sib-pair. The strongest multipoint results were for regions on chromosomes 13 and 7. The highest maximum multipoint heterogeneity LOD (MMLS/het) score is 3.0 at D13S800 (approximately 55 cM from the telomere) under the recessive model. with an estimated 35% of families linked to this locus. The next highest peak is an MMLS/het score of 2.3 at 19 cM. between D13S217 and D13S1229. Our third highest MMLS/het score of 2.2 is on chromosome 7 and is consistent with the International Molecular Genetic Study of Autism Consortium report of a possible susceptibility locus somewhere within 7q31-33. These regions and others will be followed up in the second stage of our study by typing additional markers in both the original and a second set of identically ascertained autism families. which are currently being collected. By comparing results across a number of studies. we expect to be able to narrow our search for autism susceptibility genes to a small number of genomic regions. Am. J. Med. Genet.(Neuropsychiatr. Genet.) 88: 609-615. 1999.,True,4uiMIaEAAAAJ:d1gkVwhDpl0C,351,https://europepmc.org/article/med/10581478,5655288001651415465,/scholar?cites=5655288001651415465,,,,0,0,0
1276579,Missense variations in the fibulin 5 gene and age-related macular degeneration,2004,Edwin M Stone and Terry A Braun and Stephen R Russell and Markus H Kuehn and Andrew J Lotery and Paula A Moore and Christopher G Eastman and Thomas L Casavant and Val C Sheffield,351,New England Journal of Medicine,4,346-353,Massachusetts Medical Society,Age-related macular degeneration (AMD) is the most common cause of irreversible vision loss in the developed world. The study of a rare mendelian form of macular degeneration implicated fibulin genes in the pathogenesis of more common forms of this disease. We evaluated five fibulin genes in a large series of patients with AMD.We studied 402 patients with AMD and 429 control subjects from the same clinic population. Patients were examined by means of indirect ophthalmoscopy. slit-lamp microscopy. and fundus photography to establish the presence and phenotypic pattern of AMD. DNA samples were screened for sequence variations in five members of the fibulin gene family.Amino acid–altering sequence variations were found in all five fibulin genes. many of which were observed only in patients with AMD. Several of the altered residues have been conserved during …,True,4uiMIaEAAAAJ:9yKSN-GCB0IC,346,https://www.nejm.org/doi/full/10.1056/nejmoa040833,6910618785958866396,/scholar?cites=6910618785958866396,,,https://www.nejm.org/doi/full/10.1056/nejmoa040833,0,0,0
1276580,Bardet–Biedl syndrome type 4 (BBS4)-null mice implicate Bbs4 in flagella formation but not global cilia assembly,2004,Kirk Mykytyn and Robert F Mullins and Michael Andrews and Annie P Chiang and Ruth E Swiderski and Baoli Yang and Terry Braun and Thomas Casavant and Edwin M Stone and Val C Sheffield,101,Proceedings of the National Academy of Sciences,23,8664-8669,National Academy of Sciences,The functions of the proteins encoded by the Bardet–Biedl syndrome (BBS) genes are unknown. Mutations in these genes lead to the pleiotropic human disorder BBS. which is characterized by obesity. retinopathy. polydactyly. renal and cardiac malformations. learning disabilities. and hypogenitalism. Secondary features include diabetes mellitus and hypertension. Recently. it has been suggested that the BBS phenotypes are the result of a lack of cilia formation or function. In this study. we show that mice lacking the Bbs4 protein have major components of the human phenotype. including obesity and retinal degeneration. We show that Bbs4-null mice develop both motile and primary cilia. demonstrating that Bbs4 is not required for global cilia formation. Interestingly. male Bbs4-null mice do not form spermatozoa flagella. and BBS4 retinopathy involves apoptotic death of photoreceptors. the primary ciliated cells of …,True,4uiMIaEAAAAJ:UeHWp8X0CEIC,318,https://www.pnas.org/content/101/23/8664.short,15246648800536727514,/scholar?cites=15246648800536727514,,,https://www.pnas.org/content/pnas/101/23/8664.full.pdf,0,0,0
1276581,Identification of the gene that. when mutated. causes the human obesity syndrome BBS4,2001,Kirk Mykytyn and Terry Braun and Rivka Carmi and Neena B Haider and Charles C Searby and Mythreyi Shastri and Gretel Beck and Alan F Wright and Alessandro Iannaccone and Khalil Elbedour and Ruth Riise and Alfonso Baldi and Annick Raas-Rothschild and Susan W Gorman and David M Duhl and Samuel G Jacobson and Thomas Casavant and Edwin M Stone and Val C Sheffield,28,Nature genetics,2,188-191,Nature Publishing Group,Bardet–Biedl syndrome (BBS. MIM 209900) is a heterogeneous autosomal recessive disorder characterized by obesity. pigmentary retinopathy. polydactyly. renal malformations. mental retardation. and hypogenitalism 1. 2. 3. 4. The disorder is also associated with diabetes mellitus. hypertension. and congenital heart disease 4. 5. 6. Six distinct BBS loci map to 11q13 (BBS1). 16q21 (BBS2). 3p13–p12 (BBS3). 15q22. 3–q23 (BBS4). 2q31 (BBS5). and 20p12 (BBS6) 7. 8. 9. 10. 11. 12. 13. Although BBS is rare in the general population (< 1/100.000). there is considerable interest in identifying the genes causing BBS because components of the phenotype. such as obesity and diabetes. are common. We and others have demonstrated that BBS6 is caused by mutations in the gene MKKS (refs. 12. 13). mutation of which also causes McKusick–Kaufman syndrome (hydrometrocolpos. post-axial polydactyly. and …,True,4uiMIaEAAAAJ:qjMakFHDy7sC,290,https://www.nature.com/articles/ng0601_188,2218081812025849967,/scholar?cites=2218081812025849967,,,https://www.researchgate.net/profile/Thomas_Casavant/publication/11958166_Identification_of_the_gene_that_when_mutated_causes_the_human_obesity_syndrome_BBS4/links/00b7d516f06b0b2fb7000000.pdf,0,0,0
1276582,Regulation of gene expression in the mammalian eye and its relevance to eye disease,2006,Todd E Scheetz and Kwang-Youn A Kim and Ruth E Swiderski and Alisdair R Philp and Terry A Braun and Kevin L Knudtson and Anne M Dorrance and Gerald F DiBona and Jian Huang and Thomas L Casavant and Val C Sheffield and Edwin M Stone,103,Proceedings of the National Academy of Sciences,39,14429-14434,National Academy of Sciences,We used expression quantitative trait locus mapping in the laboratory rat (Rattus norvegicus) to gain a broad perspective of gene regulation in the mammalian eye and to identify genetic variation relevant to human eye disease. Of >31.000 gene probes represented on an Affymetrix expression microarray. 18.976 exhibited sufficient signal for reliable analysis and at least 2-fold variation in expression among 120 F2 rats generated from an SR/JrHsd × SHRSP intercross. Genome-wide linkage analysis with 399 genetic markers revealed significant linkage with at least one marker for 1.300 probes (α = 0.001; estimated empirical false discovery rate = 2%). Both contiguous and noncontiguous loci were found to be important in regulating mammalian eye gene expression. We investigated one locus of each type in greater detail and identified putative transcription-altering variations in both cases. We found an inserted …,True,4uiMIaEAAAAJ:MXK_kJrjxJIC,231,https://www.pnas.org/content/103/39/14429.short,14029334617022522332,/scholar?cites=14029334617022522332,,,https://www.pnas.org/content/pnas/103/39/14429.full.pdf,0,0,0
1276583,Comparative genomic analysis identifies an ADP-ribosylation factor–like gene as the cause of Bardet-Biedl syndrome (BBS3),2004,Annie P Chiang and Darryl Nishimura and Charles Searby and Khalil Elbedour and Rivka Carmi and Amanda L Ferguson and Jenifer Secrist and Terry Braun and Thomas Casavant and Edwin M Stone and Val C Sheffield,75,The American Journal of Human Genetics,3,475-484,Cell Press,Bardet-Biedl syndrome (BBS) is a genetically heterogeneous. pleiotropic human disorder characterized by obesity. retinopathy. polydactyly. renal and cardiac malformations. learning disabilities. and hypogenitalism. Eight BBS loci have been mapped. and seven genes have been identified. BBS3 was previously mapped to chromosome 3 by linkage analysis in a large Israeli Bedouin kindred. The rarity of other families mapping to the BBS3 locus has made it difficult to narrow the disease interval sufficiently to identify the gene by positional cloning. We hypothesized that the genomes of model organisms that contained the orthologues to known BBS genes would also likely contain a BBS3 orthologue. Therefore. comparative genomic analysis was performed to prioritize BBS candidate genes for mutation screening. Known BBS proteins were compared with the translated genomes of model organisms to identify a …,True,4uiMIaEAAAAJ:zYLM7Y9cAGgC,231,https://www.sciencedirect.com/science/article/pii/S0002929707633187,13209518878065742790,/scholar?cites=13209518878065742790,,,https://www.sciencedirect.com/science/article/pii/S0002929707633187,0,0,0
1276584,Software engineering for self-adaptive systems: A research roadmap,2009,Betty H. C. Cheng and Rogério de Lemos and Holger Giese and Paola Inverardi and Jeff Magee and Jesper Andersson and Basil Becker and Nelly Bencomo and Yuriy Brun and Bojan Cukic and Giovanna Di Marzo Serugendo and Schahram Dustdar and Anthony Finkelstein and Cristina Gacek and Kurt Geihs and Vincenzo Grassi and Gabor Karsai and Holger M. Kienle and Jeff Kramer and Marin Litoiu and Sam Malek and Raffaela Mirandola and Hausi A. Müller and Sooyong Park and Mary Shaw and Matthias Tichy and Massimo Tivoli and Danny Weyns and Jon Whittle,5525,,,1-26,Springer Berlin/Heidelberg,,True,8hyNFkYAAAAJ:-DxkuPiZhfEC,2010,,6326161709606373965,/scholar?cites=6326161709606373965,,,,0,0,0
1276585,Engineering self-adaptive systems through feedback loops,2009,Yuriy Brun and Giovanna Di Marzo Serugendo and Cristina Gacek and Holger Giese and Holger Kienle and Marin Litoiu and Hausi Müller and Mauro Pezzè and Mary Shaw,,,,48-70,Springer. Berlin. Heidelberg,To deal with the increasing complexity of software systems and uncertainty of their environments. software engineers have turned to self-adaptivity. Self-adaptive systems are capable of dealing with a continuously changing environment and emerging requirements that may be unknown at design-time. However. building such systems cost-effectively and in a predictable manner is a major engineering challenge. In this paper. we explore the state-of-the-art in engineering self-adaptive systems and identify potential improvements in the design process.Our most important finding is that in designing self-adaptive systems. the feedback loops that control self-adaptation must become first-class entities. We explore feedback loops from the perspective of control engineering and within existing self-adaptive systems in nature and biology. Finally. we identify the critical challenges our community must …,True,8hyNFkYAAAAJ:W7OEmFMy1HYC,646,https://link.springer.com/chapter/10.1007/978-3-642-02161-9_3,13692108246371196459,/scholar?cites=13692108246371196459,,,https://www.academia.edu/download/30703907/ebooksclub.org__Software_Engineering_for_Self_Adaptive_Systems__Lecture_Notes_in_Computer_Science___Programming_and_Software_Engineering.pdf#page=57,0,0,0
1276586,A reverse‐engineering approach to subsystem structure identification,1993,Hausi A Müller and Mehmet A Orgun and Scott R Tilley and James S Uhl,5,Journal of Software Maintenance: Research and Practice,4,181-204,John Wiley & Sons. Ltd,Reverse‐engineering is the process of extracting system abstractions and design information out of existing software systems. This process involves the identification of software artefacts in a particular subject system. the exploration of how these artefacts interact with one another. and their aggregation to form more abstract system representations that facilitate program understanding.This paper describes our approach to creating higher‐level abstract representations of a subject system. which involves the identification of related components and dependencies. the construction of layered subsystem structures. and the computation of exact interfaces among subsystems. We show how top‐down decompositions of a subject system can be (re)constructed via bottom‐up subsystem composition. This process involves identifying groups of building blocks (e.g.. variables. procedures. modules. and subsystems) using …,True,8hyNFkYAAAAJ:u5HHmVD_uO8C,486,https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.4360050402,15041616265653901951,/scholar?cites=15041616265653901951,,,https://www.academia.edu/download/40222228/A_reverseengineering_approach_to_subsyst20151120-25803-6mprk0.pdf,0,0,0
1276587,Cognitive design elements to support the construction of a mental model during software exploration,1999,M-AD Storey and F David Fracchia and Hausi A Müller,44,Journal of Systems and Software,3,171-185,Elsevier,The scope of software visualization tools which exist for the navigation. analysis and presentation of software information varies widely. One class of tools. which we refer to as Software exploration tools. provides graphical representations of static software structures linked to textual views of the program source code and documentation. This paper describes a hierarchy of cognitive issues which should be considered during the design of a software exploration tool. The hierarchy of cognitive design elements is derived through the examination of program comprehension cognitive models. Examples of how existing tools address each of these issues are provided. In addition. this paper demonstrates how these cognitive design elements may be applied to the design of an effective interface for software exploration.,True,8hyNFkYAAAAJ:u-x6o8ySG0sC,428,https://www.sciencedirect.com/science/article/pii/S0164121298100559,5951169391697950957,/scholar?cites=5951169391697950957,,,http://rigi.cs.uvic.ca/downloads/papers/pdf/wpc97.pdf,0,0,0
1276588,Reverse engineering: A roadmap,2000,Hausi A Müller and Jens H Jahnke and Dennis B Smith and Margaret-Anne Storey and Scott R Tilley and Kenny Wong,,,,47-60,,Teach reverse engineering. program understanding. and software analysis in computer science. computer engineering. and software engineering curricula. Investigate infrastructure. methods. and tools for continuous program understanding to support the entire evolution of a software system from the early design stages to the long-term legacy stages.,True,8hyNFkYAAAAJ:9yKSN-GCB0IC,373,https://dl.acm.org/doi/abs/10.1145/336512.336526,11010446025159591099,/scholar?cites=11010446025159591099,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.576.7289&rep=rep1&type=pdf,0,0,0
1276589,Rigi: A system for programming-in-the-large,1988,Hausi A Muller and Karl Klashinsky,,,,"80, 81, 82, 83, 84, 85, 86-80, 81, 82, 83, 84, 85, 86",IEEE Computer Society,The authors describe Rigi. a model and tool that uses a graph model and abstraction mechanisms to structure and represent the information accumulated during the development process. The objects and relationships of the graph model represent system components and their dependencies. The objects can be arranged in aggregation and generalization hierarchies. Rigi was designed to address three of the most difficult problems in the area of programming-in-the-large: the mastery of the structural complexity of large software systems. the effective presentation of development information. and the definition of procedures for checking and maintaining the completeness. consistency. and traceability of system descriptions. Thus. the major objective of Rigi is to effectively represent and manipulate the building blocks of a software system and their myriad dependencies. thereby aiding the development phases of the …,True,8hyNFkYAAAAJ:d1gkVwhDpl0C,340,https://www.computer.org/csdl/proceedings-article/fie/2003/796101/12OmNqI04Pw,2194034413943937705,/scholar?cites=2194034413943937705,,,,0,0,0
1276590,The software bookshelf,1997,Patrick J.  Finnigan and Richard C.  Holt and Ivan Kalas and Scott Kerr and Kostas Kontogiannis and Hausi A Muller and John Mylopoulos and Stephen G.  Perelgut and Martin Stanley and Kenny Wong,36,IBM systems Journal,4,564-593,IBM,Legacy software systems are typically complex. geriatric. and difficult to change. having evolved over decades and having passed through many developers. Nevertheless. these systems are mature. heavily used. and constitute massive corporate assets. Migrating such systems to modern platforms is a significant challenge due to the loss of information over time. As a result. we embarked on a research project to design and implement an environment to support software migration. In particular. we focused on migrating legacy PL/I source code to C++. with an initial phase of looking at redocumentation strategies. Recent technologies such as reverse engineering tools and World Wide Web standards now make it possible to build tools that greatly simplify the process of redocumenting a legacy software system. In this paper we introduce the concept of a software bookshelf as a means to capture. organize. and …,True,8hyNFkYAAAAJ:CHSYGLWDkRkC,320,https://ieeexplore.ieee.org/abstract/document/5387168/,9023098355753265395,/scholar?cites=9023098355753265395,,,https://www.academia.edu/download/40076359/The_Software_Bookshelf20151116-25862-1umzyqf.pdf,0,0,0
1276591,How do program understanding tools affect how programmers understand programs?,2000,M-AD Storey and Kenny Wong and Hausi A Müller,36,Science of Computer Programming,2-3,183-207,Elsevier,In this paper. we explore the question of whether program understanding tools enhance or change the way that programmers understand programs. The strategies that programmers use to comprehend programs vary widely. Program understanding tools should enhance or ease the programmer's preferred strategies. rather than impose a fixed strategy that may not always be suitable. We present observations from a user study that compares three tools for browsing program source code and exploring software structures. In this study. 30 participants used these tools to solve several high-level program understanding tasks. These tasks required a broad range of comprehension strategies. We describe how these tools supported or hindered the diverse comprehension strategies used.,True,8hyNFkYAAAAJ:P5F9QuxV20EC,294,https://www.sciencedirect.com/science/article/pii/S0167642399000362,6476461269626570025,/scholar?cites=6476461269626570025,,,https://www.sciencedirect.com/science/article/pii/S0167642399000362/pdf?md5=07809eca13ce1771b0c18b2712e22eeb&pid=1-s2.0-S0167642399000362-main.pdf&_valck=1,0,0,0
1276592,Structural Redocumentation: A Case Study,1995,Kenny Wong and Scott R. Tilley and Hausi A. Müller and Margaret-Anne Storey,12,IEEE Software,1,46-54,IEEE Computer Society,Most software documentation typically describes the program at the algorithm and data-structure level. For large legacy systems. understanding the system's architecture is more important. The authors propose a method of reverse engineering through redocumentation that promises to extend the useful life of large systems.< >,True,8hyNFkYAAAAJ:1sJd4Hv_s6UC,242,https://ieeexplore.ieee.org/abstract/document/363166/,3174010852182006368,/scholar?cites=3174010852182006368,,,https://www.researchgate.net/profile/Hausi_Mueller/publication/220092827_Structural_Redocumentation_A_Case_Study/links/00b7d515b635eb945c000000.pdf,0,0,0
1276593,Understanding Software Systems Using Reverse Engineering Technologyy,1994,Hausi A Muller and K. Wong and Scott R Tilley,,,,240-252,World Scientific Publishers,Software engineering research has focused primarily on software construction. neglecting software maintenance and evolution. Observed is a shift in research from synthesis to analysis. The process of reverse engineering is introduced as an aid in program understanding. This process is concerned with the analysis of existing software systems to make them more understandable for maintenance. re-engineering. and evolution purposes. Presented is reverse engineering technology developed as part of the Rigi project. The Rigi approach involves the identification of software artifacts in the subject system and the aggregation of these artifacts to form more abstract system representations. Early industrial experience has shown that software engineers using Rigi can quickly build mental models from the discovered abstractions that are compatible with the mental models formed by the maintainers of the underlying …,True,8hyNFkYAAAAJ:XD-gHx7UXLsC,238,https://www.worldscientific.com/doi/abs/10.1142/9789812831163_0016,6513680196901071105,/scholar?cites=6513680196901071105,,,https://www.researchgate.net/profile/Hausi_Mueller/publication/221500970_Understanding_Software_Systems_Using_Reverse_Engineering_Technology_Perspectives_from_the_Rigi_Project/links/00b7d515b635c45966000000.pdf,0,0,0
1276594,Manipulating and documenting software structures using SHriMP views,1995,M-AD Storey and Hausi A Muller,,,,275-284,IEEE,An effective approach to program understanding involves browsing. exploring. and creating views that document software structures at different levels of abstraction. While exploring the myriad of relationships in a multi-million line legacy system. one can easily loose context. One approach to alleviate this problem is to visualize these structures using fisheye techniques. This paper introduces Simple Hierarchical Multi-Perspective views (SHriMPs). The SHriMP visualization technique has been incorporated into the Rigi reverse engineering system. This greatly enhances Rigi's capabilities for documenting design patterns and architectural diagrams that span multiple levels of abstraction. The applicability and usefulness of SHriMPs is illustrated with selected program understanding tasks.,True,8hyNFkYAAAAJ:nb7KW1ujOQ8C,237,https://ieeexplore.ieee.org/abstract/document/526549/,3379367897766396296,/scholar?cites=3379367897766396296,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.114.5325&rep=rep1&type=pdf,0,0,0
1276595,Ownership types for flexible alias protection,1998,David G Clarke and John M Potter and James Noble,,,,48-64,,Object-oriented programming languages allow inter-object aliasing. Although necessary to construct linked data structures and networks of interacting objects. aliasing is problematic in that an aggregate object's state can change via an alias to one of its components. without the aggregate being aware of any aliasing. Ownership types form a static type system that indicates object ownership. This provides a flexible mechanism to limit the visibility of object references and restrict access paths to objects. thus controlling a system's dynamic topology. The type system is shown to be sound. and the specific aliasing properties that a system's object graph satisfies are formulated and proven invariant for well-typed programs.,True,SSUL-D8AAAAJ:u5HHmVD_uO8C,738,https://dl.acm.org/doi/abs/10.1145/286936.286947,4652737424010234122,/scholar?cites=4652737424010234122,,,https://lirias.kuleuven.be/retrieve/35867,0,0,0
1276596,Flexible alias protection,1998,James Noble and Jan Vitek and John Potter,,,,158-185,Springer. Berlin. Heidelberg,Aliasing is endemic in object oriented programming. Because an object can be modified via any alias. object oriented programs are hard to understand. maintain. and analyse. Flexible alias protection is a conceptual model of inter-object relationships which limits the visibility of changes via aliases. allowing objects to be aliased but mitigating the undesirable effects of aliasing. Flexible alias protection can be checked statically using programmer supplied aliasing modes and imposes no runtime overhead. Using flexible alias protection. programs can incorporate mutable objects. immutable values. and updatable collections of shared objects. in a natural object oriented programming style. while avoiding the problems caused by aliasing.,True,SSUL-D8AAAAJ:u-x6o8ySG0sC,415,https://link.springer.com/chapter/10.1007/BFb0054091,57097065111936648,/scholar?cites=57097065111936648,,,http://www.lirmm.fr/~ducour/Doc-objets/ECOOP/papers/1445/14450158.pdf,0,0,0
1276597,The Qualitas Corpus: A curated collection of Java code for empirical studies,2010,Ewan Tempero and Craig Anslow and Jens Dietrich and Ted Han and Jing Li and Markus Lumpe and Hayden Melton and James Noble,,,,336-345,IEEE,In order to increase our ability to use measurement to support software development practise we need to do more analysis of code. However. empirical studies of code are expensive and their results are difficult to compare. We describe the Qualitas Corpus. a large curated collection of open source Java systems. The corpus reduces the cost of performing large empirical studies of code and supports comparison of measurements of the same artifacts. We discuss its design. organisation. and issues associated with its development.,True,SSUL-D8AAAAJ:M3NEmzRMIkIC,402,https://ieeexplore.ieee.org/abstract/document/5693210/,18133341230014304980,/scholar?cites=18133341230014304980,,,https://cs.uwaterloo.ca/~m2nagapp/courses/CS846/1171/papers/tempero_apsec10.pdf,0,0,0
1276598,A framework for implementing pluggable type systems,2006,Chris Andreae and James Noble and Shane Markstrum and Todd Millstein,,,,57-74,,Pluggable types have been proposed to support multiple type systems in the same programming language. We have designed and implemented JavaCOP. a program constraint system for implementing practical pluggable type systems for Java. JavaCOP enforces user-defined typing constraints written in a declarative and expressive rule language. We have validated our design by (re) implementing a range of type systems and program checkers. By using a program constraint system to implement pluggable types. programmers are able to check that their programs will operate correctly in restricted environments. adhere to strict programming rules. avoid null pointer errors or scoped memory exceptions. and meet style guidelines. while programming language researchers can easily experiment with novel type systems.,True,SSUL-D8AAAAJ:IjCSPb-OGe4C,318,https://dl.acm.org/doi/abs/10.1145/1167473.1167479,10431273917169642587,/scholar?cites=10431273917169642587,,,https://www.researchgate.net/profile/Chris_Andreae/publication/221321983_A_framework_for_implementing_pluggable_type_systems/links/0deec5374b9f80df3d000000/A-framework-for-implementing-pluggable-type-systems.pdf,0,0,0
1276599,Video game values: Human–computer interaction and games,2007,Pippin Barr and James Noble and Robert Biddle,19,Interacting with Computers,2,180-195,OUP,Current human–computer interaction (HCI) research into video games rarely considers how they are different from other forms of software. This leads to research that. while useful concerning standard issues of interface design. does not address the nature of video games as games specifically. Unlike most software. video games are not made to support external. user-defined tasks. but instead define their own activities for players to engage in. We argue that video games contain systems of values which players perceive and adopt. and which shape the play of the game. A focus on video game values promotes a holistic view of video games as software. media. and as games specifically. which leads to a genuine video game HCI.,True,SSUL-D8AAAAJ:LkGwnXOMwfcC,295,https://ieeexplore.ieee.org/abstract/document/8149510/,10063344640599288788,/scholar?cites=10063344640599288788,,,,0,0,0
1276600,Scale-free geometry in OO programs,2005,Alex Potanin and James Noble and Marcus Frean and Robert Biddle,48,Communications of the ACM,5,99-103,ACM,Though conventional OO design suggests programs should be built from many small objects. like Lego bricks. they are instead built from objects that are scale-free. like fractals. and unlike Lego bricks.,True,SSUL-D8AAAAJ:2osOgNQ5qMEC,281,https://dl.acm.org/doi/abs/10.1145/1060710.1060716,4651301404168069606,/scholar?cites=4651301404168069606,,,https://homepages.ecs.vuw.ac.nz/foswiki/pub/Users/Marcus/MarcusFreanPublications/CACM.pdf,0,0,0
1276601,Self-organizing roles on agile software development teams,2012,Rashina Hoda and James Noble and Stuart Marshall,39,IEEE Transactions on Software Engineering,3,422-444,IEEE,Self-organizing teams have been recognized and studied in various forms-as autonomous groups in socio-technical systems. enablers of organizational theories. agents of knowledge management. and as examples of complex-adaptive systems. Over the last decade. self-organizing teams have taken center stage in software engineering when they were incorporated as a hallmark of Agile methods. Despite the long and rich history of self-organizing teams and their recent popularity with Agile methods. there has been little research on the topic within software wngineering. Particularly. there is a dearth of research on how Agile teams organize themselves in practice. Through a Grounded Theory research involving 58 Agile practitioners from 23 software organizations in New Zealand and India over a period of four years. we identified informal. implicit. transient. and spontaneous roles that make Agile teams self …,True,SSUL-D8AAAAJ:1lhNe0rCu4AC,272,https://ieeexplore.ieee.org/abstract/document/6197202/,1997176471712690110,/scholar?cites=1997176471712690110,,,,0,0,0
1276602,Understanding the shape of Java software,2006,Gareth Baxter and Marcus Frean and James Noble and Mark Rickerby and Hayden Smith and Matt Visser and Hayden Melton and Ewan Tempero,,,,397-412,,Large amounts of Java software have been written since the language's escape into unsuspecting software ecology more than ten years ago. Surprisingly little is known about the structure of Java programs in the wild: about the way methods are grouped into classes and then into packages. the way packages relate to each other. or the way inheritance and composition are used to put these programs together. We present the results of the first in-depth study of the structure of Java programs. We have collected a number of Java programs and measured their key structural attributes. We have found evidence that some relationships follow power-laws. while others do not. We have also observed variations that seem related to some characteristic of the application itself. This study provides important information for researchers who can investigate how and why the structural relationships we find may have originated …,True,SSUL-D8AAAAJ:UeHWp8X0CEIC,247,https://dl.acm.org/doi/abs/10.1145/1167473.1167507,7464556603607187783,/scholar?cites=7464556603607187783,,,https://researchspace.auckland.ac.nz/bitstream/handle/2292/16834/Understanding%20the%20shape%20of%20Java%20software.pdf?sequence=2&sa=U&ved=0CCQQFjADahUKEwjz9J-H_tnHAhXOnIgKHeDdAEY&usg=AFQjCNEN7Wh8LdIuvQQZzFjZDf0F1moZhw,0,0,0
1276603,The impact of inadequate customer collaboration on self-organizing Agile teams,2011,Rashina Hoda and James Noble and Stuart Marshall,53,Information and Software Technology,5,521-534,Elsevier,Customer collaboration is a vital feature of Agile software development.This article addresses the importance of adequate customer involvement on Agile projects. and the impact of different levels of customer involvement on real-life Agile projects.We conducted a Grounded Theory study involving 30 Agile practitioners from 16 software development organizations in New Zealand and India. over a period of 3 years.We discovered that Lack of Customer Involvement was one of the biggest challenges faced by Agile teams. Customers were not as involved on these Agile projects as Agile methods demand. We describe the causes of inadequate customer collaboration. its adverse consequences on self-organizing Agile teams. and Agile Undercover — a set of strategies used by the teams to practice Agile despite insufficient or ineffective customer involvement.Customer …,True,SSUL-D8AAAAJ:4fKUyHm3Qg0C,243,https://www.sciencedirect.com/science/article/pii/S0950584910001941,11770531423504568887,/scholar?cites=11770531423504568887,,,https://www.researchgate.net/profile/James_Noble2/publication/222999049_The_impact_of_inadequate_customer_collaboration_on_self-organizing_Agile_teams/links/59e8429ea6fdccfe7f8b30ba/The-impact-of-inadequate-customer-collaboration-on-self-organizing-Agile-teams.pdf,0,0,0
1276604,Developing a grounded theory to explain the practices of self-organizing Agile teams,2012,Rashina Hoda and James Noble and Stuart Marshall,17,Empirical Software Engineering,6,609-639,Springer US,Software Engineering researchers are constantly looking to improve the quantity and quality of their research findings through the use of an appropriate research methodology. Over the last decade. there has been a sustained increase in the number of researchers exploring the human and social aspects of Software Engineering. many of whom have used Grounded Theory. We have used Grounded Theory as a qualitative research method to study 40 Agile practitioners across 16 software organizations in New Zealand and India and explore how these Agile teams self-organize. We use our study to demonstrate the application of Grounded Theory to Software Engineering. In doing so. we present (a) a detailed description of the Grounded Theory methodology in general and its application in our research in particular; (b) discuss the major challenges we encountered while performing Grounded Theory’s …,True,SSUL-D8AAAAJ:uLbwQdceFCQC,222,https://link.springer.com/article/10.1007/s10664-011-9161-0,15369604615732022110,/scholar?cites=15369604615732022110,,,https://www.researchgate.net/profile/Rashina_Hoda/publication/226854769_Developing_a_grounded_theory_to_explain_the_practices_of_self-organizing_Agile_teams/links/0a85e535c370eafa2a000000/Developing-a-grounded-theory-to-explain-the-practices-of-self-organizing-Agile-teams.pdf,0,0,0
1276605,Capabilities for sharing,2001,John Boyland and James Noble and William Retert,,,,2-27,Springer. Berlin. Heidelberg,Many languages and language extensions include annotations on pointer variables suchas “read-only.” “unique.” and “borrowed”; many more annotations have been proposed but not implemented. Unfortunately. all these annotations are described individually and formalised independently — assuming they are formalised at all. In this paper. we show how these annotations can be subsumed into a general capability system for pointers. This system separates mechanism (defining the semantics of sharing and exclusion) from policy (defining the invariants that are intended to be preserved). The capability system has a welldefined semantics which can be used as a reference for the correctness of various extended type systems using annotations. Furthermore. it supports researchin new less-restrictive type systems that permit a wider range of idioms to be statically checked.,True,SSUL-D8AAAAJ:d1gkVwhDpl0C,213,https://link.springer.com/chapter/10.1007/3-540-45337-7_2,7894757543267856095,/scholar?cites=7894757543267856095,,,https://www.researchgate.net/profile/John_Boyland/publication/225821296_Capabilities_for_Sharing/links/0deec52891235e5059000000/Capabilities-for-Sharing.pdf,0,0,0
1276606,An analysis of the cloud computing security problem,2010,Mohamed Almorsy and John Grundy and Ingo Müller,,,,,,,True,bbEQGY8AAAAJ:P5F9QuxV20EC,523,,17308538882960228233,/scholar?cites=17308538882960228233,,,,0,0,0
1276607,Empirical studies of pair programming for CS/SE teaching in higher education: A systematic literature review,2011,Norsaremah Salleh and Emilia Mendes and John Grundy,37,IEEE Transactions on Software Engineering,4,509-525,IEEE,The objective of this paper is to present the current evidence relative to the effectiveness of pair programming (PP) as a pedagogical tool in higher education CS/SE courses. We performed a systematic literature review (SLR) of empirical studies that investigated factors affecting the effectiveness of PP for CS/SE students and studies that measured the effectiveness of PP for CS/SE students. Seventy-four papers were used in our synthesis of evidence. and 14 compatibility factors that can potentially affect PP's effectiveness as a pedagogical tool were identified. Results showed that students' skill level was the factor that affected PP's effectiveness the most. The most common measure used to gauge PP's effectiveness was time spent on programming. In addition. students' satisfaction when using PP was overall higher than when working solo. Our meta-analyses showed that PP was effective in improving students' …,True,bbEQGY8AAAAJ:iH-uZ7U-co4C,333,https://ieeexplore.ieee.org/abstract/document/5482588/,1821782422215623934,/scholar?cites=1821782422215623934,,,,0,0,0
1276608,Collaboration-Based Cloud Computing Security Management Framework,2011,Mohemed Almorsy and John Grundy and Amani S Ibrahim,,,,364-371,IEEE,Although the cloud computing model is considered to be a very promising internet-based computing platform. it results in a loss of security control over the cloud-hosted assets. This is due to the outsourcing of enterprise IT assets hosted on third-party cloud computing platforms. Moreover. the lack of security constraints in the Service Level Agreements between the cloud providers and consumers results in a loss of trust as well. Obtaining a security certificate such as ISO 27000 or NIST-FISMA would help cloud providers improve consumers trust in their cloud platforms' security. However. such standards are still far from covering the full complexity of the cloud computing model. We introduce a new cloud security management framework based on aligning the FISMA standard to fit with the cloud computing model. enabling cloud providers and consumers to be security certified. Our framework is based on improving …,True,bbEQGY8AAAAJ:ZfRJV9d4-WMC,244,https://ieeexplore.ieee.org/abstract/document/6008731/,2713319441350077465,/scholar?cites=2713319441350077465,,,https://researchbank.swinburne.edu.au/file/5078031e-1ae9-46fd-8a45-220cb4e4b657/1/PDF%20(Accepted%20manuscript).pdf,0,0,0
1276609,Inconsistency management for multiple-view software development environments,1998,John Grundy and John Hosking and Warwick B Mugridge,24,IEEE Transactions on Software Engineering,11,960-981,IEEE,Developers need tool support to help manage the wide range of inconsistencies that occur during software development. Such tools need to provide developers with ways to define. detect. record. present. interact with. monitor and resolve complex inconsistencies between different views of software artifacts. different developers and different phases of software development. This paper describes our experience with building complex multiple-view software development tools that support diverse inconsistency management facilities. We describe software architectures that we have developed and user interface techniques that are used in our multiple-view development tools. and we discuss the effectiveness of our approaches compared to other architectural and HCI techniques.,True,bbEQGY8AAAAJ:u5HHmVD_uO8C,242,https://ieeexplore.ieee.org/abstract/document/730545/,2761613501903331533,/scholar?cites=2761613501903331533,,,http://www.cs.auckland.ac.nz/~john-g/papers/tose98.pdf,0,0,0
1276610,Aspect-oriented requirements engineering for component-based software systems,1999,John Grundy,,,,84-91,IEEE,Developing requirements for software components. and ensuring these requirements are met by component designs. is very challenging. as very often application domain and stakeholders are not fully known during component development. The author introduces a new methodology. aspect-oriented component engineering. that addresses some difficult issues of component requirements engineering by analysing and characterising components based on different aspects of the overall application a component addresses. He gives an overview of the aspect-oriented component requirements engineering process. focus on component requirements analysis specification and reasoning. and briefly discuss tool support.,True,bbEQGY8AAAAJ:u-x6o8ySG0sC,218,https://ieeexplore.ieee.org/abstract/document/777988/,13491811219035527155,/scholar?cites=13491811219035527155,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.6224&rep=rep1&type=pdf,0,0,0
1276611,A visual language for design pattern modeling and instantiation,2007,David Maplesden and John Hosking and John Grundy,,,,20-43,IGI Global,In this chapter we describe the Design pattern modeling language. a notation supporting the specification of Design pattern solutions and their instantiation into UML design models. DPML uses a simple set of visual abstractions and readily lends itself to tool support. DPML Design pattern solution specifications are used to construct visual. formal specifications of Design patterns. DPML instantiation diagrams are used to link a Design pattern solution specification to instances of a UML model. indicating the roles played by different UML elements in the generic Design pattern solution. A prototype tool is described. together with an evaluation of the language and tool.,True,bbEQGY8AAAAJ:5pGZGXnFQ_sC,210,https://www.igi-global.com/chapter/visual-language-design-pattern-modeling/8150,14983833209663816145,/scholar?cites=14983833209663816145,,,http://dro.deakin.edu.au/eserv/DU:30094646/grundy-visuallanguage-2007.pdf,0,0,0
1276612,A generic approach to supporting diagram differencing and merging for collaborative design,2005,Akhil Mehra and John Grundy and John Hosking,,,,204-213,ACM,Differentiation tools enable team members to compare two or more text files. eg code or documentation. after change. Although a number of general-purpose differentiation tools exist for comparing text documents very few tools exist for comparing diagrams. We describe a new approach for realising visual differentiation in CASE tools via a set of plug-in components. We have added diagram version control. visual differentiation and merging support as component-based plug-ins to the Pounamu meta-CASE tool. The approach is generic across a wide variety of diagram types and has also been deployed with an Eclipse diagramming plug-in. We describe our approach's architecture. key design and implementation issues. illustrate feasibility of our approach via implementation of it as plug-in components and evaluate its effectiveness.,True,bbEQGY8AAAAJ:2osOgNQ5qMEC,173,https://dl.acm.org/doi/abs/10.1145/1101908.1101940,5590051415755597887,/scholar?cites=5590051415755597887,,,http://btn1x4.inf.uni-bayreuth.de/publications/dotor_buchmann/SCM/ChefRepo/DiffUndMerge/p204-mehra.pdf,0,0,0
1276613,AUIT: Adaptable user interface technology with extended Java Server pages,2004,John Grundy and Wenjing Zou,,,,149-167,John Wiley & Sons. Ltd,Many web-based information systems require degrees of adaptation of the system’s user interfaces to different client devices. users and user tasks [Vanderdonckt et al. 2001; Petrovski and Grundy 2001]. This includes providing interfaces that will run on conventional web browsers. using Hyper-Text Mark-up Language (HTML). as well as wireless PDAs. mobile phones and pagers using Wireless Mark-up Language (WML)[Marsic 2001a; Han et al. 2000; Zarikas et al. 2001]. In addition. adapting to different users and user tasks is required [Eisenstein and Puerta 2000; Grunst et al. 1996; Wing and Colomb 1996]. For example. hiding ‘Update’and ‘Delete’buttons if the user is a customer or if the user is,True,bbEQGY8AAAAJ:O3NaXMp0MMsC,163,https://onlinelibrary.wiley.com/doi/pdf/10.1002/0470091703#page=163,3350603193066904903,/scholar?cites=3350603193066904903,,,,0,0,0
1276614,A 3D metaphor for software production visualization,2003,Thomas Panas and Rebecca Berrigan and John Grundy,,,,314-319,IEEE,Software development is difficult because software is complex. the software production process is complex and understanding of software systems is a challenge. We propose a 3D visual approach to depict software production cost related program information to support software maintenance. The information helps us to reduce software maintenance costs. to plan the use of personnel wisely. to appoint experts efficiently and to detect system problems early.,True,bbEQGY8AAAAJ:eQOLeE2rZwMC,145,https://ieeexplore.ieee.org/abstract/document/1217996/,17282738153222192894,/scholar?cites=17282738153222192894,,,https://www.researchgate.net/profile/Thomas_Panas/publication/4026411_A_3D_metaphor_for_software_production_visualization/links/0c9605387f44b86fe6000000/A-3D-metaphor-for-software-production-visualization.pdf,0,0,0
1276615,CloudSec: A security monitoring appliance for Virtual Machines in the IaaS cloud model,2011,Amani S Ibrahim and James Hamlyn-Harris and John Grundy and Mohamed Almorsy,,,,113-120,IEEE,The Infrastructure-as-a-Service (IaaS) cloud computing model has become a compelling computing solution with a proven ability to reduce costs and improve resource efficiency. Virtualization has a key role in supporting the IaaS model. However. virtualization also makes it a target for potent rootkits because of the loss of control problem over the hosted Virtual Machines (VMs). This makes traditional in-guest security solutions. relying on operating system kernel trustworthiness. no longer an effective solution to secure the virtual infrastructure of the IaaS model. In this paper. we explore briefly the security problem of the IaaS cloud computing model. and present CloudSec. a new virtualization-aware monitoring appliance that provides active. transparent and real-time security monitoring for hosted VMs in the IaaS model. CloudSec utilizes virtual machine introspection techniques to provide fine-grained inspection of …,True,bbEQGY8AAAAJ:vbGhcppDl1QC,135,https://ieeexplore.ieee.org/abstract/document/6059967/,8045186216772693124,/scholar?cites=8045186216772693124,,,https://researchbank.swinburne.edu.au/file/85e8efbc-7d31-45f6-814d-2e481a9c9029/1/PDF%20(Accepted%20manuscript).pdf,0,0,0
1276616,A Systematic Mapping Study of Mobile Application Testing Techniques,2016,Samer Zain and Norsaremah Salleh and John C. Grundy,117,Journal of Systems and Software,,334-356,Elsevier,The importance of mobile application specific testing techniques and methods has been attracting much attention of software engineers over the past few years. This is due to the fact that mobile applications are different than traditional web and desktop applications. and more and more they are moving to being used in critical domains. Mobile applications require a different approach to application quality and dependability and require an effective testing approach to build high quality and more reliable software. We performed a systematic mapping study to categorize and to structure the research evidence that has been published in the area of mobile application testing techniques and challenges that they have reported. Seventy nine (79) empirical studies are mapped to a classification schema. Several research gaps are identified and specific key testing issues for practitioners are identified: there is a need for …,True,bbEQGY8AAAAJ:mYPvCrJ_kzAC,127,https://www.sciencedirect.com/science/article/pii/S0164121216300140,11306135464421067251,/scholar?cites=11306135464421067251,,,https://fada.birzeit.edu/bitstream/20.500.11889/2748/1/12946.pdf,0,0,0
1276617,Comparison and evaluation of code clone detection techniques and tools: A qualitative approach,2009,Chanchal K Roy and James R Cordy and Rainer Koschke,74,Science of computer programming,7,470-495,Elsevier,Over the last decade many techniques and tools for software clone detection have been proposed. In this paper. we provide a qualitative comparison and evaluation of the current state-of-the-art in clone detection techniques and tools. and organize the large amount of information into a coherent conceptual framework. We begin with background concepts. a generic clone detection process and an overall taxonomy of current techniques and tools. We then classify. compare and evaluate the techniques and tools in two different dimensions. First. we classify and compare approaches based on a number of facets. each of which has a set of (possibly overlapping) attributes. Second. we qualitatively evaluate the classified techniques and tools with respect to a taxonomy of editing scenarios designed to model the creation of Type-1. Type-2. Type-3 and Type-4 clones. Finally. we provide examples of how one might use …,True,t7IssBgAAAAJ:W7OEmFMy1HYC,1082,https://www.sciencedirect.com/science/article/pii/S0167642309000367,11664249256432668921,/scholar?cites=11664249256432668921,,,https://www.sciencedirect.com/science/article/pii/S0167642309000367,0,0,0
1276618,A survey on software clone detection research,2007,Chanchal Kumar Roy and James R Cordy,541,Queen’s School of Computing TR,115,64-68,,Code duplication or copying a code fragment and then reuse by pasting with or without any modifications is a well known code smell in software maintenance. Several studies show that about 5% to 20% of a software systems can contain duplicated code. which is basically the results of copying existing code fragments and using then by pasting with or without minor modifications. One of the major shortcomings of such duplicated fragments is that if a bug is detected in a code fragment. all the other fragments similar to it should be investigated to check the possible existence of the same bug in the similar fragments. Refactoring of the duplicated code is another prime issue in software maintenance although several studies claim that refactoring of certain clones are not desirable and there is a risk of removing them. However. it is also widely agreed that clones should at least be detected. In this paper. we survey the state of the art in clone detection research. First. we describe the clone terms commonly used in the literature along with their corresponding mappings to the commonly used clone types. Second. we provide a review of the existing clone taxonomies. detection approaches and experimental evaluations of clone detection tools. Applications of clone detection research to other domains of software engineering and in the same time how other domain can assist clone detection research have also been pointed out. Finally. this paper concludes by pointing out several open problems related to clone detection research.,True,t7IssBgAAAAJ:UeHWp8X0CEIC,829,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.9931&rep=rep1&type=pdf,2547250293089211696,/scholar?cites=2547250293089211696,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.9931&rep=rep1&type=pdf,0,0,0
1276619,NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization,2008,Chanchal K Roy and James R Cordy,,,,172-181,IEEE,This paper examines the effectiveness of a new language- specific parser-based but lightweight clone detection approach. Exploiting a novel application of a source transformation system. the method accurately finds near-miss clones using an efficient text line comparison technique. The transformation system assists the method in three ways. First. using agile parsing it provides user-specified flexible pretty- printing to remove noise. standardize formatting and break program statements into parts such that potential changes can be detected as simple linewise text differences. Second. it provides efficient flexible extraction of potential clones to be compared using island grammars and agile parsing to select granularities and enumerate potential clones. Third. using transformation rules it provides flexible code normalization to allow for local editing differences between similar code segments and filtering out of …,True,t7IssBgAAAAJ:WF5omc3nYNoC,507,https://ieeexplore.ieee.org/abstract/document/4556129/,7884695128810969838,/scholar?cites=7884695128810969838,,,https://www.academia.edu/download/30774446/RC_ICPC08_NICAD.pdf,0,0,0
1276620,The TXL source transformation language,2006,James R Cordy,61,Science of Computer Programming,3,190-210,Elsevier,TXL is a special-purpose programming language designed for creating. manipulating and rapidly prototyping language descriptions. tools and applications. TXL is designed to allow explicit programmer control over the interpretation. application. order and backtracking of both parsing and rewriting rules. Using first order functional programming at the higher level and term rewriting at the lower level. TXL provides for flexible programming of traversals. guards. scope of application and parameterized context. This flexibility has allowed TXL users to express and experiment with both new ideas in parsing. such as robust. island and agile parsing. and new paradigms in rewriting. such as XML mark-up. rewriting strategies and contextualized rules. without any change to TXL itself. This paper outlines the history. evolution and concepts of TXL with emphasis on its distinctive style and philosophy. and gives examples of its …,True,t7IssBgAAAAJ:2osOgNQ5qMEC,470,https://www.sciencedirect.com/science/article/pii/S0167642306000669,6643797382831408164,/scholar?cites=6643797382831408164,,,https://www.sciencedirect.com/science/article/pii/S0167642306000669/pdf?md5=1c6377e25c29d9d9f7b249f3d00ce172&pid=1-s2.0-S0167642306000669-main.pdf,0,0,0
1276621,A survey of self-management in dynamic software architecture specifications,2004,Jeremy S Bradbury and James R Cordy and Juergen Dingel and Michel Wermelinger,,,,28-33,,As dynamic software architecture use becomes more widespread. a variety of formal specification languages have been developed to gain a better understanding of the foundations of this type of software evolutionary change. In this paper we survey 14 formal specification approaches based on graphs. process algebras. logic. and other formalisms. Our survey will evaluate the ability of each approach to specify self-managing systems as well as the ability to address issues regarding expressiveness and scalability. Based on the results of our survey we will provide recommendations on future directions for improving the specification of dynamic software architectures. specifically self-managed architectures.,True,t7IssBgAAAAJ:u-x6o8ySG0sC,376,https://dl.acm.org/doi/abs/10.1145/1075405.1075411,6966679436391900367,/scholar?cites=6966679436391900367,,,https://oro.open.ac.uk/23229/1/bradbury04woss.pdf,0,0,0
1276622,A survey of table recognition,2004,Richard Zanibbi and Dorothea Blostein and James R Cordy,7,Document Analysis and Recognition,1,1-16,Springer-Verlag,Table characteristics vary widely. Consequently. a great variety of computational approaches have been applied to table recognition. In this survey. the table recognition literature is presented as an interaction of table models. observations. transformations. and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup. transformations alter or restructure data. and inferences generate and test hypotheses. This presentation clarifies both the decisions made by a table recognizer and the assumptions and inferencing techniques that underlie these decisions.,True,t7IssBgAAAAJ:d1gkVwhDpl0C,372,https://link.springer.com/article/10.1007/s10032-004-0120-9,1953602357623371896,/scholar?cites=1953602357623371896,,,https://www.researchgate.net/profile/Dorothea_Blostein/publication/220163566_A_survey_of_table_recognition/links/0912f50d091a46bad2000000/A-survey-of-table-recognition.pdf,0,0,0
1276623,Recognizing mathematical expressions using tree transformation,2002,Richard Zanibbi and Dorothea Blostein and James R.  Cordy,24,IEEE Transactions on pattern analysis and machine intelligence,11,1455-1467,IEEE,"We describe a robust and efficient system for recognizing typeset and handwritten mathematical notation. From a list of symbols with bounding boxes the system analyzes an expression in three successive passes. The Layout Pass constructs a Baseline Structure Tree (BST) describing the two-dimensional arrangement of input symbols. Reading order and operator dominance are used to allow efficient recognition of symbol layout even when symbols deviate greatly from their ideal positions. Next. the Lexical Pass produces a Lexed BST from the initial BST by grouping tokens comprised of multiple input symbols; these include decimal numbers. function names. and symbols comprised of nonoverlapping primitives such as ""="". The Lexical Pass also labels vertical structures such as fractions and accents. The Lexed BST is translated into L/sup A/T/sub E/X. Additional processing. necessary for producing output for …",True,t7IssBgAAAAJ:qjMakFHDy7sC,279,https://ieeexplore.ieee.org/abstract/document/1046157/,7140811174553157176,/scholar?cites=7140811174553157176,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.836.5169&rep=rep1&type=pdf,0,0,0
1276624,TXL: A rapid prototyping system for programming language dialects,1991,James R Cordy and Charles D Halpern-Hamu and Eric Promislow,16,Computer Languages,1,97-107,Pergamon,This paper describes a rapid prototyping system for extensions to an existing programming language. Such extensions might include new language features or might introduce notation specific to a particular problem domain. The system consists of a dialect description language used to specify the syntax and semantics of extensions. and a context sensitive syntactic transducer that automatically implements the extensions by transforming source programs written using them to equivalent programs in the original unextended language. Because the transformer is context sensitive. it is more powerful than traditional context free preprocessors and extensible languages can be used to prototype language extensions involving significantly new programming paradigms such as object oriented programming.,True,t7IssBgAAAAJ:u5HHmVD_uO8C,271,https://www.sciencedirect.com/science/article/pii/0096055191900196,9257420865835812545,/scholar?cites=9257420865835812545,,,https://research.cs.queensu.ca/home/cordy/Papers/Cordy_TXL_91.pdf,0,0,0
1276625,The NiCad clone detector,2011,James R Cordy and Chanchal K Roy,,,,219-220,IEEE,The NiCad Clone Detector is a scalable. flexible clone detection tool designed to implement the NiCad (Automated Detection of Near-Miss Intentional Clones) hybrid clone detection method in a convenient. easy-to-use command-line tool that can easily be embedded in IDEs and other environments. It takes as input a source directory or directories to be checked for clones and a configuration file specifying the normalization and filtering to be done. and provides output results in both XML form for easy analysis and HTML form for convenient browsing. NiCad handles a range of languages and normalizations. and is designed to be easily extensible using a component-based plugin architecture. It is scalable to very large systems and has been used to analyze. for example. all 47 releases of FreeBSD (60 million lines) as a single system.,True,t7IssBgAAAAJ:fPk4N6BV_jEC,231,https://ieeexplore.ieee.org/abstract/document/5970189/,14481373172632869689,/scholar?cites=14481373172632869689,,,https://www.researchgate.net/profile/Chanchal_Roy2/publication/221219568_The_NiCad_clone_detector/links/56b384ab08ae61c48058075e.pdf,0,0,0
1276626,A mutation/injection-based automatic framework for evaluating code clone detection tools,2009,Chanchal K Roy and James R Cordy,,,,157-166,IEEE,In recent years many methods and tools for software clone detection have been proposed. While some work has been done on assessing and comparing performance of these tools. very little empirical evaluation has been done. In particular. accuracy measures such as precision and recall have only been roughly estimated. due both to problems in creating a validated clone benchmark against which tools can be compared. and to the manual effort required to hand check large numbers of candidate clones. In this paper we propose an automated method for empirically evaluating clone detection tools that leverages mutation-based techniques to overcome these limitations by automatically synthesizing large numbers of known clones based on an editing theory of clone creation. Our framework is effective in measuring recall and precision of clone detection tools for various types of fine-grained clones in real …,True,t7IssBgAAAAJ:IWHjjKOFINEC,207,https://ieeexplore.ieee.org/abstract/document/4976382/,16789236647961829130,/scholar?cites=16789236647961829130,,,https://www.academia.edu/download/30774450/roy.pdf,0,0,0
1276627,Comprehending reality-practical barriers to industrial adoption of software maintenance automation,2003,James R Cordy,,,,196-205,IEEE,Recent years have seen many significant advances in program comprehension and software maintenance automation technology. In spite of the enormous potential savings in software maintenance costs. for the most part adoption of these ideas in industry remains at the experimental prototype stage. In this paper the author explores some of the practical reasons for industrial resistance to adoption of software maintenance automation. Based on the experience of six years of software maintenance automation services to the financial industry involving more than 4.5 Gloc of code at Legasys Corporation. the author discusses some of the social. technical and business realities that lie at the root of this resistance. outlines various Legasys attempts overcome these barriers. and suggests some approaches to software maintenance automation that may lead to higher levels of industrial acceptance in the future.,True,t7IssBgAAAAJ:Y0pCki6q_DkC,206,https://ieeexplore.ieee.org/abstract/document/1199203/,2982924365324144319,/scholar?cites=2982924365324144319,,,https://www.comp.nus.edu.sg/~cs6201/REFERENCES/Cordy%20tools.pdf,0,0,0
1276628,The reservoir model and architecture for open federated cloud computing,2009,Benny Rochwerger and David Breitgand and Eliezer Levy and Alex Galis and Kenneth Nagin and Ignacio Martín Llorente and Rubén Montero and Yaron Wolfsthal and Erik Elmroth and Juan Caceres and Muli Ben-Yehuda and Wolfgang Emmerich and Fermín Galán,53,IBM Journal of Research and Development,4,4: 1-4: 11,IBM,The emerging cloud-computing paradigm is rapidly gaining momentum as an alternative to traditional IT (information technology). However. contemporary cloud-computing offerings are primarily targeted for Web 2.0-style applications. Only recently have they begun to address the requirements of enterprise solutions. such as support for infrastructure service-level agreements. To address the challenges and deficiencies in the current state of the art. we propose a modular. extensible cloud architecture with intrinsic support for business service management and the federation of clouds. The goal is to facilitate an open. service-based online economy in which resources and services are transparently provisioned and managed across clouds on an on-demand basis at competitive costs with high-quality service. The Reservoir project is motivated by the vision of implementing an architecture that would enable providers …,True,ZgDFblUAAAAJ:Z5m8FVwuT1cC,1097,https://ieeexplore.ieee.org/abstract/document/5429058/,335058728656343736,/scholar?cites=335058728656343736,,,http://ants.iis.sinica.edu.tw/3bkmj9ltewxtsrrvnoknfdxrm3zfwrr/69/reservoir_ibmsj08.pdf,0,0,0
1276629,The reservoir model and architecture for open federated cloud computing,2009,Benny Rochwerger and David Breitgand and Eliezer Levy and Alex Galis and Kenneth Nagin and Ignacio Martín Llorente and Rubén Montero and Yaron Wolfsthal and Erik Elmroth and Juan Caceres and Muli Ben-Yehuda and Wolfgang Emmerich and Fermín Galán,53,IBM Journal of Research and Development,4,4: 1-4: 11,IBM,The emerging cloud-computing paradigm is rapidly gaining momentum as an alternative to traditional IT (information technology). However. contemporary cloud-computing offerings are primarily targeted for Web 2.0-style applications. Only recently have they begun to address the requirements of enterprise solutions. such as support for infrastructure service-level agreements. To address the challenges and deficiencies in the current state of the art. we propose a modular. extensible cloud architecture with intrinsic support for business service management and the federation of clouds. The goal is to facilitate an open. service-based online economy in which resources and services are transparently provisioned and managed across clouds on an on-demand basis at competitive costs with high-quality service. The Reservoir project is motivated by the vision of implementing an architecture that would enable providers …,True,ZgDFblUAAAAJ:u-x6o8ySG0sC,1097,https://ieeexplore.ieee.org/abstract/document/5429058/,335058728656343736,/scholar?cites=335058728656343736,,,http://ants.iis.sinica.edu.tw/3bkmj9ltewxtsrrvnoknfdxrm3zfwrr/69/reservoir_ibmsj08.pdf,0,0,0
1276630,Object-Oriented analysis & design,1992,Tom Horton,,,,,Englewood Cliffs (New Jersey): Prentice-Hall,,True,ZgDFblUAAAAJ:HtS1dXgVpQUC,1005,http://scholar.google.com/scholar?cluster=16781022404412854101&hl=en&oi=scholarr,16781022404412854101,/scholar?cites=16781022404412854101,,,http://www.cs.virginia.edu/~horton/cs494/slides/a-intro-6.pdf,0,0,0
1276631,Carisma: Context-aware reflective middleware system for mobile applications,2003,Licia Capra and Wolfgang Emmerich and Cecilia Mascolo,29,IEEE Transactions on software engineering,10,929-945,IEEE,Mobile devices. such as mobile phones and personal digital assistants. have gained wide-spread popularity. These devices will increasingly be networked. thus enabling the construction of distributed applications that have to adapt to changes in context. such as variations in network bandwidth. battery power. connectivity. reachability of services and hosts. etc. In this paper. we describe CARISMA. a mobile computing middleware which exploits the principle of reflection to enhance the construction of adaptive and context-aware mobile applications. The middleware provides software engineers with primitives to describe how context changes should be handled using policies. These policies may conflict. We classify the different types of conflicts that may arise in mobile computing and argue that conflicts cannot be resolved statically at the time applications are designed. but. rather. need to be resolved at execution …,True,ZgDFblUAAAAJ:u5HHmVD_uO8C,725,https://ieeexplore.ieee.org/abstract/document/1237173/,5023667342798872524,/scholar?cites=5023667342798872524,,,https://discovery.ucl.ac.uk/id/eprint/818/1/5.4_tse03.pdf,0,0,0
1276632,Slang: A language for defining service level agreements,2003,D Davide Lamanna and James Skene and Wolfgang Emmerich,,,,100-106,IEEE COMPUTER SOC,Application or web services are increasingly being used across organisational boundaries. Moreover. new services are being introduced at the network and storage level. Languages to specify interfaces for such services have been researched and transferred into industrial practice. We investigate end-to-end quality of service (QoS) and highlight that QoS provision has multiple facets and requires complex agreements between network services. storage services and middleware services. We introduce SLAng. a language for defining Service Level Agreements (SLAs) that accommodates these needs. We illustrate how SLAng is used to specify QoS in a case study that uses a web services specification to support the processing of images across multiple domains and we evaluate our language based on it.,True,ZgDFblUAAAAJ:qjMakFHDy7sC,428,https://discovery.ucl.ac.uk/id/eprint/721/1/9.9.6slang.pdf,10879110416995644691,/scholar?cites=10879110416995644691,,,https://discovery.ucl.ac.uk/id/eprint/721/1/9.9.6slang.pdf,0,0,0
1276633,Software engineering and middleware: a roadmap,2000,Wolfgang Emmerich,,,,117-129,,The construction of a large class of distributed systems can be simplified by leveraging middleware. which is layered between network operating systems and application components. Middleware resolves heterogeneity. and facilitates communication and coordination of distributed components. Existing middleware products enable software engineers to build systems that are distributed across a local-area network. State-of-the-art middleware research aims to push this boundary towards Internet-scale distribution. adaptive and reconfigurable middleware and middleware for dependable and wireless systems. The challenge for software engineering research is to devise notations. techniques. methods and tools for distributed system construction that systematically build and exploit the capabilities that middleware deliver.,True,ZgDFblUAAAAJ:d1gkVwhDpl0C,387,https://dl.acm.org/doi/pdf/10.1145/336512.336542,2000587732626048094,/scholar?cites=2000587732626048094,,,https://discovery.ucl.ac.uk/id/eprint/787/1/7.6_middleware.pdf,0,0,0
1276634,Engineering distributed objects,2000,Wolfgang Emmerich,,,,,John Wiley & Sons Software,The pay-offs for creating distributed applications are in achieving portability. scalability and fault-tolerance. In order to simplify building software that performs robustly regardless of platform or network infrastructure. a new strata of middleware has been created. This book provides a conceptual framework within which to describe object-oriented middleware for the integration of distributed objects. UML is used to explain distributed systems concepts. Presenting both an extended case study and smaller illustrative examples. there are plenty of coded examples in Java. C++. CORBA IDL and Microsoft IDL. which reflect the reality of todays multi-language heterogeneous systems. This is a book for developers who are new to programming in distributed environments. It also supports a variety of courses where the central theme is object-oriented development with middleware technologies. The book shows the …,True,ZgDFblUAAAAJ:GtLg2Ama23sC,361,https://dl.acm.org/doi/abs/10.5555/1717167,6347072700348195756,/scholar?cites=6347072700348195756,,,,0,0,0
1276635,xlinkit: A consistency checking and smart link generation service,2002,Christian Nentwich and Licia Capra and Wolfgang Emmerich and Anthony Finkelsteiin,2,ACM Transactions on Internet Technology (TOIT),2,151-185,ACM,xlinkit is a lightweight application service that provides rule-based link generation and checks the consistency of distributed Web content. It leverages standard Internet technologies. notably XML. XPath. and XLink. xlinkit can be used as part of a consistency management scheme or in applications that require smart link generation. including portal construction and management of large document repositories. In this article we show how consistency constraints can be expressed and checked. We describe a novel semantics for first-order logic that produces links instead of truth values and give an account of our content management strategy. We present the architecture of our service and the results of two substantial case studies that use xlinkit for checking course syllabus information and for validating UML models supplied by industrial partners.,True,ZgDFblUAAAAJ:IjCSPb-OGe4C,288,https://dl.acm.org/doi/abs/10.1145/514183.514186,14438888967894675063,/scholar?cites=14438888967894675063,,,http://www0.cs.ucl.ac.uk/staff/w.emmerich/publications/TOIT/xlinkit.pdf,0,0,0
1276636,XMIDDLE: A data-sharing middleware for mobile computing,2002,Cecilia Mascolo and Licia Capra and Stefanos Zachariadis and Wolfgang Emmerich,21,Wireless Personal Communications,1,77-103,Kluwer Academic Publishers,An increasing number of distributed applications will be written for mobilehosts. such as laptop computers. third generation mobile phones. personaldigital assistants. watches and the like. Application engineers have to dealwith a new set of problems caused by mobility. such as low bandwidth. contextchanges or loss of connectivity. During disconnection. users will typicallyupdate local replicas of shared data independently from each other. Theresulting inconsistent replicas need to be reconciled upon re-connection. Tosupport building mobile applications that use both replication andreconciliation over ad-hoc networks. we have designed xmiddle. a mobilecomputing middleware. In this paper we describe xmiddle and show how it usesreflection capabilities to allow application engineers to influencereplication and reconciliation techniques. xmiddle enables the transparentsharing of XML documents across …,True,ZgDFblUAAAAJ:UeHWp8X0CEIC,285,https://link.springer.com/article/10.1023/A:1015584805733,18158324675900741745,/scholar?cites=18158324675900741745,,,http://www0.cs.ucl.ac.uk/staff/w.emmerich/publications/WPC/xmiddle.pdf,0,0,0
1276637,Precise service level agreements,2004,James Skene and D Davide Lamanna and Wolfgang Emmerich,,,,179-188,IEEE,SLAng is an XML language for defining service level agreements. the part of a contract between the client and provider of an Internet service that describes the quality attributes that the service is required to possess. We define the semantics of SLAng precisely by modelling the syntax of the language in UML. then relating the language model to a model that describes the structure and behaviour of services. The presence of SLAng elements imposes behavioural constraints on service elements. and the precise definition of these constraints using OCL constitutes the semantic description of the language. We use the semantics to define a notion of SLA compatibility. and an extension to UML that enables the modelling of service situations as a precursor to analysis. implementation and provisioning activities.,True,ZgDFblUAAAAJ:zYLM7Y9cAGgC,266,https://ieeexplore.ieee.org/abstract/document/1317440/,11219650538455468658,/scholar?cites=11219650538455468658,,,https://discovery.ucl.ac.uk/id/eprint/717/1/9.9.4icse04.pdf,0,0,0
1276638,Consistency management with repair actions,2003,Christian Nentwich and Wolfgang Emmerich and Anthony Finkelstein,,,,455-464,IEEE,Comprehensive consistency management requires a strong mechanism for repair once inconsistencies have been detected In this paper we present a repair framework for inconsistent distributed documents. The core piece of the framework is a new method for generating interactive repairs from full first order logic formulae that constrain these documents. We present a full implementation of the components in our repair framework. as well as their application to the UML and related heterogeneous documents such as EJB deployment descriptors. We describe how our approach can be used as an infrastructure for building higher-level. domain specific frameworks and provide an overview of related work in the database and software development environment community.,True,ZgDFblUAAAAJ:Y0pCki6q_DkC,258,https://ieeexplore.ieee.org/abstract/document/1201223/,8720951599880022402,/scholar?cites=8720951599880022402,,,https://discovery.ucl.ac.uk/id/eprint/877/1/2.8_repair.pdf,0,0,0
1276639,A survey of peer-to-peer content distribution technologies,2004,Stephanos Androutsellis-Theotokis and Diomidis Spinellis,36,,4,335-371,ACM,"Distributed computer architectures labeled ""peer-to-peer"" are designed for the sharing of computer resources (content. storage. CPU cycles) by direct exchange. rather than requiring the intermediation or support of a centralized server or authority. Peer-to-peer architectures are characterized by their ability to adapt to failures and accommodate transient populations of nodes while maintaining acceptable connectivity and performance.Content distribution is an important peer-to-peer application on the Internet that has received considerable research attention. Content distribution applications typically allow personal computers to function in a coordinated manner as a distributed storage medium by contributing. searching. and obtaining digital content.In this survey. we propose a framework for analyzing peer-to-peer content distribution technologies. Our approach focuses on nonfunctional characteristics such as …",True,RjXNgA8AAAAJ:u5HHmVD_uO8C,2171,https://dl.acm.org/doi/abs/10.1145/1041680.1041681,1476671354074190151,/scholar?cites=1476671354074190151,,,http://csis.pace.edu/~marchese/CS865/Papers/p335-androutsellis-theotokis.pdf,0,0,0
1276640,Notable design patterns for domain-specific languages,2001,Diomidis Spinellis,56,Journal of systems and software,1,91-99,Elsevier,The realisation of domain-specific languages (dsls) differs in fundamental ways from that of traditional programming languages. We describe eight recurring patterns that we have identified as being used for dsl design and implementation. Existing languages can be extended. restricted. partially used. or become hosts for dsls. Simple dsls can be implemented by lexical processing. In addition. dsls can be used to create front-ends to existing systems or to express complicated data structures. Finally. dsls can be combined using process pipelines. The patterns described form a pattern language that can be used as a building block for a systematic view of the software development process involving dsls.,True,RjXNgA8AAAAJ:u-x6o8ySG0sC,412,https://www.sciencedirect.com/science/article/pii/S0164121200000893,3019755501097755333,/scholar?cites=3019755501097755333,,,https://www2.dmst.aueb.gr/dds/pubs/jrnl/2000-JSS-DSLPatterns/html/dslpat.pdf,0,0,0
1276641,Power laws in software,2008,Panagiotis Louridas and Diomidis Spinellis and Vasileios Vlachos,18,ACM Transactions on Software Engineering and Methodology (TOSEM),1,1-26,ACM,A single statistical framework. comprising power law distributions and scale-free networks. seems to fit a wide variety of phenomena. There is evidence that power laws appear in software at the class and function level. We show that distributions with long. fat tails in software are much more pervasive than previously established. appearing at various levels of abstraction. in diverse systems and languages. The implications of this phenomenon cover various aspects of software engineering research and practice.,True,RjXNgA8AAAAJ:WF5omc3nYNoC,246,https://dl.acm.org/doi/abs/10.1145/1391984.1391986,8680349501300224849,/scholar?cites=8680349501300224849,,,https://www2.dmst.aueb.gr/dds/pubs/jrnl/2008-TOSEM-PowerLaws/html/LSV08.pdf,0,0,0
1276642,GHTorrent: GitHub's data from a firehose,2012,Georgios Gousios and Diomidis Spinellis,,,,12-21,IEEE,A common requirement of many empirical software engineering studies is the acquisition and curation of data from software repositories. During the last few years. GitHub has emerged as a popular project hosting. mirroring and collaboration platform. GitHub provides an extensive REST API. which enables researchers to retrieve both the commits to the projects' repositories and events generated through user actions on project resources. GHTorrent aims to create a scalable off line mirror of GitHub's event streams and persistent data. and offer it to the research community as a service. In this paper. we present the project's design and initial implementation and demonstrate how the provided datasets can be queried and processed.,True,RjXNgA8AAAAJ:foquWX3nUaYC,242,https://ieeexplore.ieee.org/abstract/document/6224294/,9159843476657694384,/scholar?cites=9159843476657694384,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.641.6104&rep=rep1&type=pdf,0,0,0
1276643,The decay and failures of web references,2003,Diomidis Spinellis,46,Communications of the ACM,1,71-77,ACM,Attempting to determine how quickly archival information becomes outdated.,True,RjXNgA8AAAAJ:d1gkVwhDpl0C,224,https://dl.acm.org/doi/fullHtml/10.1145/602421.602422,17321391550959730819,/scholar?cites=17321391550959730819,,,https://www.spinellis.gr/pubs/jrnl/2003-CACM-URLcite/html/urlcite.pdf,0,0,0
1276644,Refactoring--does it improve software quality?,2007,Konstantinos Stroggylos and Diomidis Spinellis,,,,10-10,IEEE,Software systems undergo modifications. improvements and enhancements to cope with evolving requirements. This maintenance can cause their quality to decrease. Various metrics can be used to evaluate the way the quality is affected. Refactoring is one of the most important and commonly used techniques of transforming a piece of software in order to improve its quality. However. although it would be expected that the increase in quality achieved via refactoring is reflected in the various metrics. measurements on real life systems indicate the opposite. We analyzed source code version control system logs of popular open source software systems to detect changes marked as refactorings and examine how the software metrics are affected by this process. in order to evaluate whether refactoring is effectively used as a means to improve software quality within the open source community.,True,RjXNgA8AAAAJ:M3ejUd6NZC8C,186,https://ieeexplore.ieee.org/abstract/document/4273477/,5835552492203685175,/scholar?cites=5835552492203685175,,,https://www2.dmst.aueb.gr/dds/pubs/conf/2007-WoSQ-Refactor/html/SS07.pdf,0,0,0
1276645,How is open source affecting software development?,2004,Diomidis Spinellis and Clemens Szyperski,21,IEEE software,1,28,IEEE Computer Society,Clemens Szyperski. Microsoft Research tributed with the FreeBSD operating system.(Many projects appear on more than one of the locations just listed.) Following the reused open source code’s evolution and deploying the corresponding components are also becoming less haphazard operations. with mechanisms such as installable packages and anonymous Concurrent Versions System (CVS) access enabling the automation of many operations. This special issue examines how the proliferation and availability of open source are affecting software development practices. From a developer’s perspective. open source is a combination of two important properties: visible source code and a right to make (relatively) unencumbered derivatives. The motivations behind the two properties are different. and each can occur in isolation—examples include Microsoft’s shared source and library vendors’ code licenses for developing derivative products from nonvisible source. Both properties affect—in positive and negative ways—the software artifacts (products) we develop and how we develop them (process).,True,RjXNgA8AAAAJ:2osOgNQ5qMEC,186,https://www2.dmst.aueb.gr/dds/pubs/jrnl/2004-IEEESW-OSS/html/ge-intro.pdf,15281597216104915445,/scholar?cites=15281597216104915445,,,https://www2.dmst.aueb.gr/dds/pubs/jrnl/2004-IEEESW-OSS/html/ge-intro.pdf,0,0,0
1276646,Code quality: the open source perspective,2006,Diomidis Spinellis,,,,,Adobe Press,Page 26: How can I avoid off-by-one errors? Page 143: Are Trojan Horse attacks for real? Page 158: Where should I look when my application can't handle its workload? Page 256: How can I detect memory leaks? Page 309: How do I target my application to international markets? Page 394: How should I name my code's identifiers? Page 441: How can I find and improve the code coverage of my tests? Diomidis Spinellis' first book. Code Reading. showed programmers how to understand and modify key functional properties of software. Code Quality focuses on non-functional properties. demonstrating how to meet such critical requirements as reliability. security. portability. and maintainability. as well as efficiency in time and space. Spinellis draws on hundreds of examples from open source projects--such as the Apache web and application servers. the BSD Unix systems. and the HSQLDB Java database--to illustrate concepts and techniques that every professional software developer will be able to appreciate and apply immediately. Complete files for the open source code illustrated in this book are available online at: http://www. spinellis. gr/codequality/,True,RjXNgA8AAAAJ:zYLM7Y9cAGgC,183,http://books.google.com/books?hl=en&lr=&id=vEN-ckcdtCwC&oi=fnd&pg=PA1&dq=info:OgiZz8lwvnoJ:scholar.google.com&ots=sJ0sf83OtK&sig=OKswVvWI8Cqgj9Y8yYC1dTKquyo,8844630730275883066,/scholar?cites=8844630730275883066,,,http://www.e-reading-lib.com/bookreader.php/141539/Spinellis_-_Code_quality_-_the_OpenSource_perspective.pdf,0,0,0
1276647,The SQO-OSS quality model: measurement based open source software evaluation,2008,Ioannis Samoladas and Georgios Gousios and Diomidis Spinellis and Ioannis Stamelos,,,,237-248,Springer. Boston. MA,Software quality evaluation has always been an important part of software business. The quality evaluation process is usually based on hierarchical quality models that measure various aspects of software quality and deduce a characterization of the product quality being evaluated. The particular nature of open source software has rendered existing models inappropriate for detailed quality evaluations. In this paper. we present a hierarchical quality model that evaluates source code and community processes. based on automatic calculation of metric values and their correlation to a set of predefined quality profiles.1 ,True,RjXNgA8AAAAJ:hqOjcs7Dif8C,179,https://link.springer.com/chapter/10.1007/978-0-387-09684-1_19,16000596267449162779,/scholar?cites=16000596267449162779,,,https://link.springer.com/content/pdf/10.1007/978-0-387-09684-1_19.pdf,0,0,0
1276648,Using object-oriented design metrics to predict software defects,2010,Marian Jureczko and Diomidis Spinellis,,Models and Methods of System Dependability. Oficyna Wydawnicza Politechniki Wrocławskiej,,69-81,,Many object-oriented design metrics have been developed [1. 3. 8. 17. 24] to help in predict software defects or evaluate design quality. Since a defect prediction model may give crucial clues about the distribution and location of defects and. thereby. test prioritization. accurate prediction can save costs in the testing process. Considerable research has been performed on defect prediction methods; see the surveys by Purao and Vaishnavi [22] and by Wahyudin et al.[25]. unfortunately few results appear at statistically significant level. Therefore. further empirical validation is necessary to prove the usefulness of the metrics and software prediction models in industrial practice. Our study was made possible through the creation of a new metric calculation tool 4. There are many tools that calculate object-oriented metrics. What is the reason to create another one? In fact the situation is not so perfect. The available programs are either extremely inefficient (sometimes they do not work with big software projects at all). not available as open source and therefore difficult to reason about their results. or incomplete—the set of calculated metrics is not wide enough. It is extremely hard to find a tool that calculates all metrics from the Chidamber and Kemerer (C&K) metrics suite [3]. Having both. C&K and QMOOD metrics suites [1] in one tool is even rarer. and according to the authors' knowledge there is no other tool. that calculates metrics suggested by Tang et al.[24]. Ckjm calculates metrics that have been recommended as good quality indicators. There are several works that investigate the C&K metric suite and that have empirically proven their usability in …,True,RjXNgA8AAAAJ:70eg2SAEIzsC,170,https://www2.dmst.aueb.gr/dds/pubs/conf/2010-DepCoS-RELCOMEX-ckjm-defects/html/JS10.pdf,17283038738442281240,/scholar?cites=17283038738442281240,,,https://www2.dmst.aueb.gr/dds/pubs/conf/2010-DepCoS-RELCOMEX-ckjm-defects/html/JS10.pdf,0,0,0
1276649,Security protocols over open networks and distributed systems: Formal methods for their analysis. design. and verification,1999,Stefanos Gritzalis and Diomidis Spinellis and Panagiotis Georgiadis,22,,8,697-709,Elsevier,Formal methods. theory. and supporting tools can aid the design. analysis. and verification of the security-related and cryptographic protocols used over open networks and distributed systems. The most commonly followed techniques for the application of formal methods for the ex-post analysis and verification of cryptographic protocols. as the analysis approach. are reviewed. followed by the examination of robustness principles and application limitations. Modern high-level specification languages and tools can be used for automatically analysing cryptographic protocols. Recent research work focuses on the ex-ante use of formal methods in the design state of new security protocols. as the synthesis approach. Finally. an outline is presented on current trends for the utilisation of formal methods for the analysis and verification of modern complicated protocols and protocol suites for the real commercial world.,True,RjXNgA8AAAAJ:9yKSN-GCB0IC,152,https://www.sciencedirect.com/science/article/pii/S0140366499000304,8808432262052070854,/scholar?cites=8808432262052070854,,,https://www.spinellis.gr/pubs/jrnl/1997-CompComm-Formal/html/journal.pdf,0,0,0
1276650,Empirical studies of agile software development: A systematic review,2008,Tore Dybå and Torgeir Dingsøyr,50,,9-10,833-859,Elsevier,Agile software development represents a major departure from traditional. plan-based approaches to software engineering. A systematic review of empirical studies of agile software development up to and including 2005 was conducted. The search strategy identified 1996 studies. of which 36 were identified as empirical studies. The studies were grouped into four themes: introduction and adoption. human and social factors. perceptions on agile methods. and comparative studies. The review investigates what is currently known about the benefits and limitations of. and the strength of evidence for. agile methods. Implications for research and practice are presented. The main implication for research is a need for more and better empirical studies of agile software development within a common research agenda. For the industrial readership. the review provides a map of findings. according to topic. that can be …,True,jU4kmMwAAAAJ:M3NEmzRMIkIC,2971,https://www.sciencedirect.com/science/article/pii/S0950584908000256,17112214621088319822,/scholar?cites=17112214621088319822,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.493.910&rep=rep1&type=pdf,0,0,0
1276651,A decade of agile methodologies: Towards explaining agile software development,2012,Torgeir Dingsøyr and Sridhar Nerur and VenuGopal Balijepally and Nils Brede Moe,85,,6,1213-1221,Elsevier,Ever since the agile manifesto was created in 2001. the research community has devoted a great deal of attention to agile software development. This article examines publications and citations to illustrate how the research on agile has progressed in the 10 years following the articulation of the manifesto. Specifically. we delineate the conceptual structure underlying agile scholarship by performing an analysis of authors who have made notable contributions to the field. Further. we summarize prior research and introduce contributions in this special issue on agile software development. We conclude by discussing directions for future research and urging agile researchers to embrace a theory-based approach in their scholarship.,True,jU4kmMwAAAAJ:ZHo1McVdvXMC,1128,https://www.sciencedirect.com/science/article/pii/S0164121212000532,4506590499988105806,/scholar?cites=4506590499988105806,,,https://www.sciencedirect.com/science/article/pii/S0164121212000532,0,0,0
1276652,A teamwork model for understanding an agile team: A case study of a Scrum project,2010,Nils Brede Moe and Torgeir Dingsøyr and Tore Dybå,52,Information and Software Technology,5,480-491,Elsevier,Software development depends significantly on team performance. as does any process that involves human interaction.Most current development methods argue that teams should self-manage. Our objective is thus to provide a better understanding of the nature of self-managing agile teams. and the teamwork challenges that arise when introducing such teams.We conducted extensive fieldwork for 9 months in a software development company that introduced Scrum. We focused on the human sensemaking. on how mechanisms of teamwork were understood by the people involved.We describe a project through Dickinson and McIntyre’s teamwork model. focusing on the interrelations between essential teamwork components. Problems with team orientation. team leadership and coordination in addition to highly specialized skills and corresponding division of work were important …,True,jU4kmMwAAAAJ:ns9cj8rnVeAC,546,https://www.sciencedirect.com/science/article/pii/S0950584909002043,333661691435106684,/scholar?cites=333661691435106684,,,https://sintef.brage.unit.no/sintef-xmlui/bitstream/handle/11250/2430479/SINTEF+S15971.pdf?sequence=2,0,0,0
1276653,Knowledge management in software engineering: A systematic review of studied concepts. findings and research methods used,2008,Finn Olav Bjørnson and Torgeir Dingsøyr,50,,11,1055-1068,Elsevier,Software engineering is knowledge-intensive work. and how to manage software engineering knowledge has received much attention. This systematic review identifies empirical studies of knowledge management initiatives in software engineering. and discusses the concepts studied. the major findings. and the research methods used. Seven hundred and sixty-two articles were identified. of which 68 were studies in an industry context. Of these. 29 were empirical studies and 39 reports of lessons learned. More than half of the empirical studies were case studies.The majority of empirical studies relate to technocratic and behavioural aspects of knowledge management. while there are few studies relating to economic. spatial and cartographic approaches. A finding reported across multiple papers was the need to not focus exclusively on explicit knowledge. but also consider tacit knowledge. We also describe …,True,jU4kmMwAAAAJ:NMxIlDl6LWMC,506,https://www.sciencedirect.com/science/article/pii/S0950584908000487,4148390883606379601,/scholar?cites=4148390883606379601,,,https://arxiv.org/pdf/1811.12278,0,0,0
1276654,Applying systematic reviews to diverse study types: An experience report,2007,Tore Dyba and Torgeir Dingsoyr and Geir K Hanssen,,,,225-234,IEEE,Systematic reviews are one of the key building blocks of evidence-based software engineering. Current guidelines for such reviews are. for a large part. based on standard meta-analytic techniques. However. such quantitative techniques have only limited applicability to software engineering research. In this paper. therefore. we describe our experience with an approach to combine diverse study types in a systematic review of empirical research of agile software development.,True,jU4kmMwAAAAJ:hMod-77fHWUC,484,https://ieeexplore.ieee.org/abstract/document/4343750/,17845405424442061439,/scholar?cites=17845405424442061439,,,https://www.researchgate.net/profile/Torgeir_Dingsoyr/publication/4279060_Applying_Systematic_Reviews_to_Diverse_Study_Types_An_Experience_Report/links/0c9605183b3e5a39d4000000/Applying-Systematic-Reviews-to-Diverse-Study-Types-An-Experience-Report.pdf,0,0,0
1276655,What do we know about agile software development?,2009,Tore Dyba and Torgeir Dingsoyr,26,IEEE software,5,6-9,IEEE,"Agile software development has had a huge impact on how software is developed worldwide. We can view agile methods such as Extreme Programming (XP) and Scrum as a reaction to plan-based or traditional methods. which emphasize a ""rationalized. engineering-based approach. incorporating extensive planning. codified processes. and rigorous reuse. In contrast. agile methods address the challenge of an unpredictable world. emphasizing the value competent people and their relationships bring to software development. To clarify the effectiveness of agile methods. we reviewed the agile development literature and conducted a systematic study of what we know empirically about its benefits and limitations.",True,jU4kmMwAAAAJ:O3NaXMp0MMsC,351,https://ieeexplore.ieee.org/abstract/document/5222784/,7539029676865807416,/scholar?cites=7539029676865807416,,,https://www.tamps.cinvestav.mx/~ertello/svam/s06-SWE-AgileSW.pdf,0,0,0
1276656,Software Architecture Knowledge Management: Theory and Practice,2009,H van Vliet MA Babar and T Dingsøyr and P Lago,,,,,Springer,,True,jU4kmMwAAAAJ:u5HHmVD_uO8C,265,,14559257942427453591,/scholar?cites=14559257942427453591,,,,0,0,0
1276657,Strength of evidence in systematic reviews in software engineering,2008,Tore Dybå and Torgeir Dingsøyr,,,,178-187,,Systematic reviews are only as good as the evidence they are based on. It is important. therefore. that users of systematic reviews know how much confidence they can place in the conclusions and recommendations arising from such reviews. In this paper we present an overview of some of the most influential systems for assessing the quality of individual primary studies and for grading the overall strength of a body of evidence. We also present an example of the use of such systems based on a systematic review of empirical studies of agile software development. Our findings suggest that the systems used in other disciplines for grading the strength of evidence for and reporting of systematic reviews. especially those that take account of qualitative and observational studies are of particular relevance for software engineering.,True,jU4kmMwAAAAJ:2osOgNQ5qMEC,238,https://dl.acm.org/doi/abs/10.1145/1414004.1414034,18127018662438739602,/scholar?cites=18127018662438739602,,,https://www.researchgate.net/profile/Torgeir_Dingsoyr/publication/221494984_Strength_of_Evidence_in_Systematic_Reviews_in_Software_Engineering/links/0fcfd506ec26a57371000000.pdf,0,0,0
1276658,Postmortem: Never leave a project without it,2002,Andreas Birk and Torgeir Dingsoyr and Tor Stalhane,19,IEEE software,3,43-45,IEEE,Postmortem analysis (PMA) is a practical method for initiating knowledge management by capturing experience and improvement suggestions from completed projects. It requires little effort and quickly provides initial results. making it suitable even for small- and medium-size projects and companies. The authors describe their experiences with applying PMA techniques for collecting and analyzing experience in software organizations.,True,jU4kmMwAAAAJ:JV2RwH3_ST0C,226,https://ieeexplore.ieee.org/abstract/document/1003452/,13702715340470333093,/scholar?cites=13702715340470333093,,,https://www.academia.edu/download/40452856/Postmortem_Never_leave_a_project_without20151128-22733-1cey87e.pdf,0,0,0
1276659,Teamwork quality and project success in software development: A survey of agile development teams,2016,Yngve Lindsjørn and Dag IK Sjøberg and Torgeir Dingsøyr and Gunnar R Bergersen and Tore Dybå,122,Journal of Systems and Software,,274-286,Elsevier,Small. self-directed teams are central in agile development. This article investigates the effect of teamwork quality on team performance. learning and work satisfaction in agile software teams. and whether this effect differs from that of traditional software teams. A survey was administered to 477 respondents from 71 agile software teams in 26 companies and analyzed using structural equation modeling. A positive effect of teamwork quality on team performance was found when team members and team leaders rated team performance. In contrast. a negligible effect was found when product owners rated team performance. The effect of teamwork quality on team members´ learning and work satisfaction was strongly positive. but was only rated by the team members. Despite claims of the importance of teamwork in agile teams. this study did not find teamwork quality to be higher than in a similar survey on traditional …,True,jU4kmMwAAAAJ:ddB7do2jUx8C,205,https://www.sciencedirect.com/science/article/pii/S016412121630187X,4068922465370228232,/scholar?cites=4068922465370228232,,,https://www.sciencedirect.com/science/article/pii/S016412121630187X,0,0,0
1276660,Understanding self-organizing teams in agile software development,2008,Nils Brede Moe and Torgeir Dingsøyr and Tore Dybå,,,,76-85,IEEE,Traditional software teams consist of independently focused self-managing professionals with high individual but low team autonomy. A challenge with introducing agile software development is that it requires a high level of both individual and team autonomy. This paper studies the barriers with introducing self-organizing teams in agile software development and presents data from a seven month ethnographic study of professional developers in a Scrum team. We found the most important barrier to be the highly specialized skills of the developers and the corresponding division of work. In addition we found a lack of system for team support. and reduced external autonomy to be important barriers for introducing self- organizing teams. These findings have implications for software development managers and practitioners.,True,jU4kmMwAAAAJ:J_g5lzvAfSwC,205,https://ieeexplore.ieee.org/abstract/document/4483195/,6713170315133722117,/scholar?cites=6713170315133722117,,,https://www.researchgate.net/profile/Tore_Dyba/publication/4328234_Understanding_Self-Organizing_Teams_in_Agile_Software_Development/links/00b4953a5c2590d60c000000/Understanding-Self-Organizing-Teams-in-Agile-Software-Development.pdf,0,0,0
1276661,Enterprise architecture at work: Modelling. communication and analysis,2009,Marc Lankhorst,,,,,Springer-Verlag New York Inc,,True,GTW3mJ4AAAAJ:a3BOlSfXSfwC,2350,,8787632811592118523,/scholar?cites=8787632811592118523,,,,0,0,0
1276662,Reo: a channel-based coordination model for component composition,2004,Farhad Arbab,14,Mathematical structures in computer science,3,329-366,Cambridge University Press,In this paper. we present Reo. which forms a paradigm for composition of software components based on the notion of mobile channels. Reo is a channel-based exogenous coordination model in which complex coordinators. called connectors. are compositionally built out of simpler ones. The simplest connectors in Reo are a set of channels with well-defined behaviour supplied by users. Reo can be used as a language for coordination of concurrent processes. or as a ‘glue language’ for compositional construction of connectors that orchestrate component instances in a component-based system. The emphasis in Reo is just on connectors and their composition. and not on the entities that connect to. communicate and cooperate through these connectors. Each connector in Reo imposes a specific coordination pattern on the entities (for example. components) that perform I/O operations through that connector …,True,GTW3mJ4AAAAJ:u-x6o8ySG0sC,851,https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/reo-a-channelbased-coordination-model-for-component-composition/7EDB5FDF8CB5D3C2E5D11011B3391722,11738088633729680929,/scholar?cites=11738088633729680929,,,http://homepages.cwi.nl/~farhad/MSCS03Reo.pdf,0,0,0
1276663,Coordination models and languages,1998,George A Papadopoulos and Farhad Arbab,46,,,329-400,Elsevier,A new class of models. formalisms. and mechanisms has recently evolved for describing concurrent and distributed computations based on the concept of “CO-ordination.” The purpose of a coordination model and associated language is to provide a means of integrating a number of possibly heterogeneous components by interfacing with each component in such a way that the collective set forms a single application that can execute on and take advantage of parallel and distributed systems. In this chapter we initially define and present in sufficient detail the fundamental concepts of what constitutes a coordination model or language. We then go on to classify these models and languages as either “data-driven” or “control-driven” (also called “process-” or “task-oriented”). In the process. the main existing coordination models and languages are described in sufficient detail to let the reader appreciate their …,True,GTW3mJ4AAAAJ:u5HHmVD_uO8C,725,https://www.sciencedirect.com/science/article/pii/S0065245808602089,4553187139352185129,/scholar?cites=4553187139352185129,,,https://www.researchgate.net/profile/Farhad_Arbab/publication/2349828_Coordination_Models_and_Languages/links/59f1f2e8458515bfd081c6c5/Coordination-Models-and-Languages.pdf,0,0,0
1276664,Modeling component connectors in Reo by constraint automata,2006,Christel Baier and Marjan Sirjani and Farhad Arbab and Jan Rutten,61,Science of computer programming,2,75-113,Elsevier,In this paper we introduce constraint automata and propose them as an operational model for Reo. an exogenous coordination language for compositional construction of component connectors based on a calculus of channels. By providing composition operators for constraint automata and defining notions of equivalence and refinement relations for them. this paper covers the foundations for building tools to address concerns such as the automated construction of the automaton for a given component connector. equivalence checking or containment checking of the behavior of two given connectors. and verification of coordination mechanisms.,True,GTW3mJ4AAAAJ:2osOgNQ5qMEC,434,https://www.sciencedirect.com/science/article/pii/S0167642306000219,17945549003690870160,/scholar?cites=17945549003690870160,,,https://www.sciencedirect.com/science/article/pii/S0167642306000219/pdf?md5=f2b1eab770c9677aa471267e22b692a4&pid=1-s2.0-S0167642306000219-main.pdf&_valck=1,0,0,0
1276665,Enterprise architecture: Management tool and blueprint for the organisation,2006,Henk Jonkers and Marc M Lankhorst and Hugo WL ter Doest and Farhad Arbab and Hans Bosma and Roel J Wieringa,8,Information systems frontiers,2,63-66,Kluwer Academic Publishers,In current business practice. an integrated approach to business and IT is indispensable. Take for example a company that needs to assess the impact of introducing a new product in its portfolio. This may require defining additional business processes. hiring extra personnel. changing the supporting applications. and augmenting the technological infrastructure to support the additional load of these applications. Perhaps this may even require a change of the organisational structure.However. in many companies such an integrated view of the entire enterprise is still far off. This is an important problem. because changes in a company’s strategy and business goals have significant consequences within all domains of the enterprise. such as the organisation structure. business processes. software systems. data management and technical infrastructure. Companies have to adjust processes to their environment. open …,True,GTW3mJ4AAAAJ:_FxGoFyzp5QC,326,https://link.springer.com/content/pdf/10.1007/s10796-006-7970-2.pdf,4555240667675830997,/scholar?cites=4555240667675830997,,,https://www.academia.edu/download/46624884/Enterprise_architecture_Management_tool_20160619-13693-rp46t8.pdf,0,0,0
1276666,The IWIM model for coordination of concurrent activities,1996,Farhad Arbab,,,,34-56,Springer. Berlin. Heidelberg,Exploiting the full potential of massively parallel systems requires programming models that explicitly deal with the concurrency of cooperation among very large numbers of active entities that comprise a single application. In practice. the concurrent applications of today essentially use a set of ad hoc templates to coordinate the cooperation of their active components. This shows the lack of proper coordination languages that can be used to explicitly describe complex cooperation protocols in terms of simple primitives and structuring constructs.In this paper we present a generic model of communication and describe a specific control-oriented coordination language based on this model. The important characteristics of this model include compositionality. which it inherits from the data-flow model. anonymous communication. and separation of computation concerns from communication concerns …,True,GTW3mJ4AAAAJ:d1gkVwhDpl0C,293,https://link.springer.com/chapter/10.1007/3-540-61052-9_38,3514858419980988486,/scholar?cites=3514858419980988486,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.3007&rep=rep1&type=pdf,0,0,0
1276667,Abstract behavior types: a foundation model for components and their composition,2005,Farhad Arbab,55,Science of Computer Programming,1-3,3-52,Elsevier,The notion of Abstract Data Type (ADT) has served as a foundation model for structured and object oriented programming for some thirty years. The current trend in software engineering toward component based systems requires a foundation model as well. The most basic inherent property of an ADT. i.e.. that it provides a set of operations. subverts some highly desirable properties in emerging formal models for components that are based on the object oriented paradigm.We introduce the notion of Abstract Behavior Type (ABT) as a higher-level alternative to ADT and propose it as a proper foundation model for both components and their composition. An ABT defines an abstract behavior as a relation among a set of timed-data-streams. without specifying any detail about the operations that may be used to implement such behavior or the data types it may manipulate for its realization. The ABT model supports a …,True,GTW3mJ4AAAAJ:IjCSPb-OGe4C,248,https://www.sciencedirect.com/science/article/pii/S0167642304001455,11536171989195086968,/scholar?cites=11536171989195086968,,,https://www.sciencedirect.com/science/article/pii/S0167642304001455/pdf?md5=7ee77673a158aa2192618520ebcea05a&pid=1-s2.0-S0167642304001455-main.pdf,0,0,0
1276668,An overview of Manifold and its implementation,1993,Farhad Arbab and Ivan Herman and Pål Spilling,5,,1,23-70,John Wiley & Sons. Ltd,Management of the communications among a set of concurrent processes arises in many applications and is a central concern in parallel computing. In this paper we introduce MANIFOLD: a co‐ordination language whose sole purpose is to describe and manage complex interconnections among independent. concurrent processes. In the underlying paradigm of this language the primary concern is not with what functionality the individual processes in a parallel system provide. Instead. the emphasis is on how these processes are interconnected and how their interaction patterns change during the execution life of the system. This paper also includes an overview of our implementation of MANIFOLD.As an example of the application of MANIFOLD. we present a series of small manifold programs which describe the skeletons of some adaptive recursive algorithms that are of particular interest in computer graphics …,True,GTW3mJ4AAAAJ:9yKSN-GCB0IC,246,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4330050103,3691108283267421830,/scholar?cites=3691108283267421830,,,https://www.researchgate.net/profile/Farhad_Arbab/publication/227706136_Overview_of_Manifold_and_its_implementation/links/59f1f2ebaca272cdc7d00a9b/Overview-of-Manifold-and-its-implementation.pdf,0,0,0
1276669,A coinductive calculus of component connectors,2002,Farhad Arbab and Jan JMM Rutten,,,,34-55,Springer. Berlin. Heidelberg,Reo is a recently introduced channel-based model for coordination. wherein complex coordinators. called connectors. are compositionally built out of simpler ones. Using a more liberal notion of a channel. Reo generalises existing dataflow networks. In this paper. we present a simple and transparent semantical model for Reo. in which connectors are relations on timed data streams. Timed data streams constitute a characteristic of our model and consist of twin pairs of separate data and time streams. Furthermore. coinduction is our main reasoning principle and we use it to prove properties such as connector equivalence.,True,GTW3mJ4AAAAJ:qjMakFHDy7sC,210,https://link.springer.com/chapter/10.1007/978-3-540-40020-2_2,9772999602468364795,/scholar?cites=9772999602468364795,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/Recent%20Trends%20in%20Algebraic%20Development%20Techniques,%2016%20conf.,%20WADT%202002(LNCS2755,%20Springer,%202003)(ISBN%203540205373)(465s).pdf#page=42",0,0,0
1276670,An algorithm for generating NC tool paths for arbitrarily shaped pockets with islands,1992,Allan Hansen and Farhad Arbab,11,ACM Transactions on Graphics (TOG),2,152-182,ACM,In this paper we describe algorithms for generating NC tool paths for machining of arbitrarily shaped 2 l/2 dimensional pockets with arbitrary islands. These pocketing algorithms are based on a new offsetting algorithm presented in this paper. Our offsetting algorithm avoids costly two-dimensional Boolean set operations. relatively expensive distance calculations. and the overhead of extraneous geometry. such as the Voronoi diagrams. used in other pocketing algorithms.,True,GTW3mJ4AAAAJ:OTTXONDVkokC,198,https://dl.acm.org/doi/abs/10.1145/130826.130832,9256059211583029039,/scholar?cites=9256059211583029039,,,,0,0,0
1276671,What do you mean. coordination,1998,Farhad Arbab,19,Bulletin of the Dutch Association for Theoretical Computer Science (NVTI),,,,"Coordination models and languages represent a new approach to design and development of concurrent systems. The interest in coordination has intensi ed in the last few years. as evidenced by the increasing number of conferences. tracks. and papers devoted to this topic. and by the recent upsurge of research activity in the theoretical computer science community in this eld. The eld is relatively new. and while many coordination models and languages form a tight cluster of very similar variants. some others are drastically di erent and they appear to have nothing in common with each other. All this makes it di cult for the uninitiated to discern the underlying similarities of various approaches to coordination. This paper is an\easy reader"" introduction to coordination models and languages. their common aims and purpose. their relevance. and their place in the computing arena. The work on coordination at CWI is presented here as a speci c example.",True,GTW3mJ4AAAAJ:UeHWp8X0CEIC,146,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.9702&rep=rep1&type=pdf,1864629394384002166,/scholar?cites=1864629394384002166,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.26.9702&rep=rep1&type=pdf,0,0,0
1276672,Developing multi-agent systems with JADE,2007,Fabio Luigi Bellifemine and Giovanni Caire and Dominic Greenwood,7,,,,John Wiley & Sons,Learn how to employ JADE to build multi-agent systems! JADE (Java Agent DEvelopment framework) is a middleware for the development of applications. both in the mobile and fixed environment. based on the Peer-to-Peer intelligent autonomous agent approach. JADE enables developers to implement and deploy multi-agent systems. including agents running on wireless networks and limited-resource devices. Developing Multi-Agent Systems with JADE is a practical guide to using JADE. The text will give an introduction to agent technologies and the JADE Platform. before proceeding to give a comprehensive guide to programming with JADE. Basic features such as creating agents. agent tasks. agent communication. agent discovery and GUIs are covered. as well as more advanced features including ontologies and content languages. complex behaviours. interaction protocols. agent mobility. and the in-process interface. Issues such as JADE internals. running JADE agents on mobile devices. deploying a fault tolerant JADE platform. and main add-ons are also covered in depth. Developing Multi-Agent Systems with JADE: Comprehensive guide to using JADE to build multi-agent systems and agent orientated programming. Describes and explains ontologies and content language. interaction protocols and complex behaviour. Includes material on persistence. security and a semantics framework. Contains numerous examples. problems. and illustrations to enhance learning. Presents a case study demonstrating the use of JADE in practice. Offers an accompanying website with additional learning resources such as sample code. exercises …,True,OPeK2-cAAAAJ:2osOgNQ5qMEC,3906,http://books.google.com/books?hl=en&lr=&id=scComY9Kq40C&oi=fnd&pg=PR5&dq=info:U3gjvZmzlhIJ:scholar.google.com&ots=3x9aK4CUJ7&sig=IUGTCMmPsLluA3IbGOYW-s0B1Mk,1339455412073887827,/scholar?cites=1339455412073887827,,,,0,0,0
1276673,JADE–A FIPA-compliant agent framework,1999,Fabio Bellifemine and Agostino Poggi and Giovanni Rimassa,99,Proceedings of PAAM,97-108,33,,JADE is a software framework to develop agent applications in compliance with the FIPA specifications for interoperable intelligent multi-agent systems. The goal is to simplify development while ensuring standard compliance through a comprehensive set of system services and agents. JADE can then be considered an agent middle-ware that implements an Agent Platform and a development framework. It deals with all those aspects that are not peculiar of the agent internals and that are independent of the applications. such as message transport. encoding and parsing. or agent life-cycle. This paper presents the JADE software describing its intended uses. as well as being a walkthrough of JADE internal architecture. The main architectural issues are discussed. and the major design decisions are outlined.,True,OPeK2-cAAAAJ:u5HHmVD_uO8C,2347,https://www.cs.unicam.it/merelli/Calcolo/PAAM.pdf,15662656915000137949,/scholar?cites=15662656915000137949,,,https://www.cs.unicam.it/merelli/Calcolo/PAAM.pdf,0,0,0
1276674,Developing multi‐agent systems with a FIPA‐compliant agent framework,2001,Fabio Bellifemine and Agostino Poggi and Giovanni Rimassa,31,Software: Practice and Experience,2,103-128,John Wiley & Sons. Ltd.,To ease large‐scale realization of agent applications there is an urgent need for frameworks. methodologies and toolkits that support the effective development of agent systems. Moreover. since one of the main tasks for which agent systems were invented is the integration between heterogeneous software. independently developed agents should be able to interact successfully.In this paper. we present JADE (Java Agent Development Environment). a software framework to build agent systems for the management of networked information resources in compliance with the FIPA specifications for inter‐operable intelligent multi‐agent systems. The goal of JADE is to simplify development while ensuring standard compliance through a comprehensive set of system services and agents. JADE can then be considered to be an agent middle‐ware that implements an efficient agent platform and supports the …,True,OPeK2-cAAAAJ:u-x6o8ySG0sC,775,https://onlinelibrary.wiley.com/doi/abs/10.1002/1097-024X(200102)31:2%3C103::AID-SPE358%3E3.0.CO;2-O,8868380431477859319,/scholar?cites=8868380431477859319,,,https://www.emse.fr/~boissier/enseignement/maop19-winter/pdf/FIPA-JADE.pdf,0,0,0
1276675,JADE: A software framework for developing multi-agent applications. Lessons learned,2008,Fabio Bellifemine and Giovanni Caire and Agostino Poggi and Giovanni Rimassa,50,Information and Software Technology,1-2,10-21,Elsevier,Since a number of years agent technology is considered one of the most innovative technologies for the development of distributed software systems. While not yet a mainstream approach in software engineering at large. a lot of work on agent technology has been done. many research results and applications have been presented. and some software products exists which have moved from the research community to the industrial community. One of these is JADE. a software framework that facilitates development of interoperable intelligent multi-agent systems and that is distributed under an Open Source License. JADE is a very mature product. used by a heterogeneous community of users both in research activities and in industrial applications. This paper presents JADE and its technological components together with a discussion of the possible reasons for its success and lessons learned from the somewhat …,True,OPeK2-cAAAAJ:zYLM7Y9cAGgC,418,https://www.sciencedirect.com/science/article/pii/S0950584907001218,7248386854866335618,/scholar?cites=7248386854866335618,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.408.9517&rep=rep1&type=pdf,0,0,0
1276676,JADE—a java agent development framework,2005,Fabio Bellifemine and Federico Bergenti and Giovanni Caire and Agostino Poggi,,,,125-147,Springer. Boston. MA,JADE (Java Agent Development Framework) is a software environment to build agent systems for the management of networked information resources in compliance with the FIPA specifications for interoperable multi-agent systems. JADE provides a middleware for the development and execution of agent-based applications which can seamless work and interoperate both in wired and wireless environment. Moreover. JADE supports the development of multi-agent systems through the predefined programmable and extensible agent model and a set of management and testing tools. Currently. JADE is one of the most used and promising agent development framework; in fact. it has a large user group. involving more than two thousands active members. it has been used to realize real systems in different application sectors. and its future development is guided by a governing board involving some …,True,OPeK2-cAAAAJ:IjCSPb-OGe4C,388,https://link.springer.com/chapter/10.1007/0-387-26350-0_5,10635122861501012073,/scholar?cites=10635122861501012073,,,,0,0,0
1276677,Leap: A fipa platform for handheld and mobile devices,2001,Federico Bergenti and Agostino Poggi,,,,436-446,Springer. Berlin. Heidelberg,The ever-increasing importance of the market of portable devices is promoting the migration of technologies originally developed for the fixed network to the mobile network. This paper describes the general aim and the current results of a European-scale project intended to provide the enabling technology for deploying multi-agent systems across fixed and mobile networks. The LEAP project achieves its goal realising a FIPA platform that can be deployed seamlessly on any Java-enabled device with sufficient resources and with a wired or wireless connection. Such a platform is implemented as a new kernel for JADE to ease the migration of legacy agents to the mobile network and it exploits a modular design to scale its functionality with the capabilities of the device.,True,OPeK2-cAAAAJ:qjMakFHDy7sC,172,https://link.springer.com/chapter/10.1007/3-540-45448-9_33,3212645858296088113,/scholar?cites=3212645858296088113,,,https://www.academia.edu/download/30755390/JohnJules_C_Meyer_Intelligent_Agents_8_conf_ATA.pdf#page=448,0,0,0
1276678,Exploiting UML in the design of multi-agent systems,2000,Federico Bergenti and Agostino Poggi,,,,106-113,Springer. Berlin. Heidelberg,A basic concept of software engineering is that a system can be described at different levels of abstraction. Agent-oriented software engineering introduces a new level of abstraction. called the agent level. to allow software architects modelling a system in terms of interacting agents. This level of abstraction is not yet supported by an accepted diagrammatic notation even if a number of proposals are available. This work shows how UML can be exploited to model a multi-agent system at the agent level. In particular. it presents a set of agent-oriented diagrams intended to provide an UML-based notation to model: the architecture of the multi-agent system. the ontology followed by agents and the interaction protocols used to co-ordinate agents. The presented notation exploits stereotypes to associate an agent-oriented semantic with class and collaboration diagrams. The benefit of using stereotypes rather than …,True,OPeK2-cAAAAJ:UeHWp8X0CEIC,144,https://link.springer.com/chapter/10.1007/3-540-44539-0_8,9524036094179563039,/scholar?cites=9524036094179563039,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/E/Engineering%20Societies%20in%20the%20Agent%20World,%201%20conf.,%20ESAW%202000(LNCS1972,%20Springer,%202000)(ISBN%203540414770)(153s)_CsLn_.pdf#page=116",0,0,0
1276679,Improving UML designs using automatic design pattern detection,2002,Federico Bergenti and Agostino Poggi,,,,771-784,,Design patterns are considered one of the most valuable tools to produce quality designs and a general-purpose technique to improve a design is to identify all pattern realizations and to apply well-known rules to improve them. This technique requires finding all pattern realizations used in a design and it is a rather tedious task. This paper shows the work in the literature on assistants for programmers and software architects and presents a system called IDEA (Interactive DEsign Assistant). IDEA is an interactive design assistant for software architects meant for automating the task of finding and improving the realizations of design patterns. Basically. IDEA is capable of automatically (i) finding the patterns employed in a UML diagram and (ii) producing critiques about these patterns. The core of IDEA is the module that automatically detects the pattern realizations found in the model that the architect is producing …,True,OPeK2-cAAAAJ:W7OEmFMy1HYC,108,https://www.worldscientific.com/doi/abs/10.1142/9789812389701_0033,5959781362965438550,/scholar?cites=5959781362965438550,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.3764&rep=rep1&type=pdf,0,0,0
1276680,Multi-user and security support for multi-agent systems,2001,Agostino Poggi and Giovanni Rimassa and Michele Tomaiuolo,,,,,,This paper discusses the requirements an agent system needs to be secure. In particular. the paper introduces a classification of modern distributed systems. and examines the delegation concept from a security point of view. After discussing the peculiar security and delegation issues present in distributed object systems. mobile agent systems and in multi agent systems. a case study is presented. describing the multi-user and security support that is being built into the JADE platform. 1,True,OPeK2-cAAAAJ:Y0pCki6q_DkC,76,http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.93.9730,5734407194874326138,/scholar?cites=5734407194874326138,,,,0,0,0
1276681,An object-oriented framework to realize agent systems,2000,Fabio Bellifemine and Agostino Poggi and Giovanni Rimassa and Paola Turci,,,,52-57,,In this paper. we present an agent model and platform we defined and implemented to realize efficient and reusable agent software through an agent development environment called JADE. JADE (Java Agent Development Environment) is a software framework to make easy the development of agent applications in compliance with the FIPA specifications for interoperable intelligent multifagent systems. JADE uses an agent model and a Java implementation that offer a good runtime efficiency and software reuse. Such an agent model is more ³primitive than the agent models offered by other systems. but such models can be implemented on the top of our ³ primitive agent model. JADE agent platform tries to optimize the performance of a distributed agent system implemented with the Java language. In particular. its communication architecture tries to offer flexible and efficient messaging. transparently choosing the best transport available and leveraging statefoffthef art distributed object technology embedded within Java runtime environment.,True,OPeK2-cAAAAJ:Tyk-4Ss8FVUC,68,http://lia.deis.unibo.it/confs/woa2000/pdf/11.pdf,15420672192603846647,/scholar?cites=15420672192603846647,,,http://lia.deis.unibo.it/confs/woa2000/pdf/11.pdf,0,0,0
1276682,Deploying FIPA-compliant systems on handheld devices,2001,Federico Bergenti and Agostino Poggi and Bernard Burg and Giovanni Caire,5,IEEE Internet Computing,4,20-25,IEEE,LEAP is a runtime environment for deploying agents on a network of Java-enabled devices. It complies with FIPA international standards for multiagent systems. The Lightweight Extensive Agent Platform project is the first attempt to implement a FIPA agent platform that runs seamlessly on both mobile and fixed devices over both wireless and wired networks.,True,OPeK2-cAAAAJ:WF5omc3nYNoC,67,https://ieeexplore.ieee.org/abstract/document/939446/,2670182286826498061,/scholar?cites=2670182286826498061,,,https://www.researchgate.net/profile/Federico_Bergenti/publication/3419414_Deploying_FIPA_-_Compliant_systems_on_handheld_devices/links/5559d9b208ae6fd2d8278916/Deploying-FIPA-Compliant-systems-on-handheld-devices.pdf,0,0,0
1276683,Software engineering for self-adaptive systems: A second research roadmap,2013,Rogério De Lemos and Holger Giese and Hausi A Müller and Mary Shaw and Jesper Andersson and Marin Litoiu and Bradley Schmerl and Gabriel Tamura and Norha M Villegas and Thomas Vogel and Danny Weyns and Luciano Baresi and Basil Becker and Nelly Bencomo and Yuriy Brun and Bojan Cukic and Ron Desmarais and Schahram Dustdar and Gregor Engels and Kurt Geihs and Karl M Göschka and Alessandra Gorla and Vincenzo Grassi and Paola Inverardi and Gabor Karsai and Jeff Kramer and Antónia Lopes and Jeff Magee and Sam Malek and Serge Mankovskii and Raffaela Mirandola and John Mylopoulos and Oscar Nierstrasz and Mauro Pezzè and Christian Prehofer and Wilhelm Schäfer and Rick Schlichting and Dennis B Smith and João Pedro Sousa and Ladan Tahvildari and Kenny Wong and Jochen Wuttke,,,,1-32,Springer. Berlin. Heidelberg,The goal of this roadmap paper is to summarize the state-of-the-art and identify research challenges when developing. deploying and managing self-adaptive software systems. Instead of dealing with a wide range of topics associated with the field. we focus on four essential topics of self-adaptation: design space for self-adaptive solutions. software engineering processes for self-adaptive systems. from centralized to decentralized control. and practical run-time verification & validation for self-adaptive systems. For each topic. we present an overview. suggest future directions. and focus on selected challenges. This paper complements and extends a previous roadmap on software engineering for self-adaptive systems published in 2009 covering a different set of topics. and reflecting in part on the previous paper. This roadmap is one of the many results of the Dagstuhl Seminar 10431 on Software …,True,xvzzSFgAAAAJ:L_l9e5I586QC,2010,https://link.springer.com/chapter/10.1007/978-3-642-35813-5_1,6326161709606373965,/scholar?cites=6326161709606373965,,,https://drops.dagstuhl.de/opus/volltexte/2011/3156/pdf/report10431_3156.pdf,0,0,0
1276684,Towards dynamic monitoring of WS-BPEL processes,2005,Luciano Baresi and Sam Guinea,,,,269-282,Springer. Berlin. Heidelberg,The intrinsic flexibility and dynamism of service-centric applications preclude their pre-release validation and demand for suitable probes to monitor their behavior at run-time. Probes must be suitably activated and deactivated according to the context in which the application is executed. but also according to the confidence we get on its quality. The paper supports the idea that significant data may come from very different sources and probes must be able to accommodate all of them.The paper presents: (1) an approach to specify monitoring directives. called monitoring rules. and weave them dynamically into the process they belong to; (2) a proxy-based solution to support the dynamic selection and execution of monitoring rules at run-time; (3) a user-oriented language to integrate data acquisition and analysis into monitoring rules.,True,xvzzSFgAAAAJ:u5HHmVD_uO8C,413,https://link.springer.com/chapter/10.1007/11596141_21,13649207488202801714,/scholar?cites=13649207488202801714,,,https://link.springer.com/content/pdf/10.1007/11596141_21.pdf,0,0,0
1276685,Smart monitors for composed services,2004,Luciano Baresi and Carlo Ghezzi and Sam Guinea,,,,193-202,,Service-based approaches are widely used to integrate heterogenous systems. Web services allow for the definition of highly dynamic systems where components (services) can be discovered and QoS parameters negotiated at run-time. This justifies the need for monitoring service compositions at run-time. Research on this issue. however. is still in its infancy.,True,xvzzSFgAAAAJ:u-x6o8ySG0sC,312,https://dl.acm.org/doi/abs/10.1145/1035167.1035195,4952999253653045325,/scholar?cites=4952999253653045325,,,https://www.academia.edu/download/35474682/ICSOC04-1.pdf,0,0,0
1276686,Toward open-world software: Issues and challenges,2006,Luciano Baresi and Elisabetta Di Nitto and Carlo Ghezzi,39,,10,36-43,IEEE,Traditional software development is based on the closed-world assumption that the boundary between system and environment is known and unchanging. However. this assumption no longer works within today's unpredictable open-world settings. especially in ubiquitous and pervasive computing settings. which demand techniques that let software react to changes by self-organizing its structure and self-adapting its behavior. The more we move toward dynamic and heterogeneous systems. and the more we stress their self-healing and self-adapting capabilities. the more we need new approaches to develop these applications and new ways to structure and program them. Programming open systems requires new programming language features. Two features that bear investigation are introspection mechanisms to get runtime information about newly encountered services and reflective mechanisms to adapt …,True,xvzzSFgAAAAJ:UeHWp8X0CEIC,308,https://ieeexplore.ieee.org/abstract/document/1707632/,2716249322464970946,/scholar?cites=2716249322464970946,,,http://cs.furman.edu/~chealy/cs75/important%20papers/open%20world%20software.pdf,0,0,0
1276687,Fuzzy goals for requirements-driven adaptation,2010,Luciano Baresi and Liliana Pasquale and Paola Spoletini,,,,125-134,IEEE,Self-adaptation is imposing as a key characteristic of many modern software systems to tackle their complexity and cope with the many environments in which they can operate. Self-adaptation is a requirement per-se. but it also impacts the other (conventional) requirements of the system; all these new and old requirements must be elicited and represented in a coherent and homogenous way. This paper presents FLAGS. an innovative goal model that generalizes the KAOS model. adds adaptive goals to embed adaptation countermeasures. and fosters self-adaptation by considering requirements as live. runtime entities. FLAGS also distinguishes between crisp goals. whose satisfaction is boolean. and fuzzy goals. whose satisfaction is represented through fuzzy constraints. Adaptation countermeasures are triggered by violated goals and the goal model is modified accordingly to maintain a coherent view of the …,True,xvzzSFgAAAAJ:IWHjjKOFINEC,291,https://ieeexplore.ieee.org/abstract/document/5636887/,17715705277876442778,/scholar?cites=17715705277876442778,,,https://lili-pasquale.lero.ie/papers/RE2010.pdf,0,0,0
1276688,Tutorial introduction to graph transformation: A software engineering perspective,2002,Luciano Baresi and Reiko Heckel,,,,402-429,Springer. Berlin. Heidelberg,We give an introduction to graph transformation. not only for researchers in software engineering. but based on applications of graph transformation in this domain. In particular. we demonstrate the use of graph transformation to model object- and component-based systems and to specify syntax and semantics of diagram languages. Along the way we introduce the basic concepts. discuss different approaches. and mention relevant theory and tools.,True,xvzzSFgAAAAJ:qjMakFHDy7sC,258,https://link.springer.com/chapter/10.1007/3-540-45832-8_30,8332259365699881202,/scholar?cites=8332259365699881202,,,https://www.researchgate.net/profile/Reiko_Heckel/publication/220713239_Lecture_Notes_in_Computer_Science/links/0912f50f6948aaaeb1000000/Lecture-Notes-in-Computer-Science.pdf,0,0,0
1276689,Extending UML for modeling web applications,2001,Luciano Baresi and Franca Garzotto and Paolo Paolini,,,,10 pp.,IEEE,"Web sites are progressively evolving from browsable. read-only information repositories to Web-based distributed applications. Compared to traditional Web sites. these Web applications do not only support navigation and browsing. but also operations that affect their contents and navigation states. Compared to traditional applications Web applications integrate operations with the built-in browsing capabilities of hypermedia. These novelties make Web application design a complex task that requires the integration of methods and techniques developed in different ""worlds"". This integration is achieved in this paper by extending and customizing the Unified Modeling Language (UML) with Web design concepts borrowed from the Hypermedia Design Model (HDM). Hypermedia elements are described through appropriate UML stereotypes. UML diagrams are also tailored to model operations and relate them with …",True,xvzzSFgAAAAJ:9yKSN-GCB0IC,238,https://ieeexplore.ieee.org/abstract/document/926350/,15840807167474062159,/scholar?cites=15840807167474062159,,,https://www.researchgate.net/profile/Franca_Garzotto/publication/232628922_Extending_UML_for_Modeling_Web_Applications_PDF/links/5475e4270cf2778985af1b1c/Extending-UML-for-Modeling-Web-Applications-PDF.pdf,0,0,0
1276690,Modeling and validation of service-oriented architectures: Application vs. style,2003,Luciano Baresi and Reiko Heckel and Sebastian Thöne and Dániel Varró,28,ACM SIGSOFT Software Engineering Notes,5,68-77,ACM,Most applications developed today rely on a given middleware platform which governs the interaction between components. the access to resources. etc. To decide. which platform is suitable for a given application (or more generally. to understand the interaction between application and platform). we propose UML models of both the architectural style of the platform and the application scenario. Based on a formal interpretation of these as graphs and graph transformation systems. we are able to validate the consistency between platform and application.,True,xvzzSFgAAAAJ:2osOgNQ5qMEC,225,https://dl.acm.org/doi/abs/10.1145/949952.940082,4529001496461507109,/scholar?cites=4529001496461507109,,,https://www.researchgate.net/profile/Reiko_Heckel/publication/221560337_Modeling_and_validation_of_service-oriented_architectures_Application_vs_style/links/09e415107eac8c7fff000000.pdf,0,0,0
1276691,Test oracles,2001,Luciano Baresi and Michal Young,,,,,Technical Report CIS-TR-01-02. University of Oregon. Dept. of Computer and Information Science. Eugene. Oregon. USA,All software testing methods depend on the availability of an oracle. that is. some method for checking whether the system under test has behaved correctly on a particular execution. An ideal oracle would provide an unerring pass/fail judgment for any possible program execution. judged against a natural specification of intended behavior. Practical approaches must make compromises to balance trade-offs and provide useful capabilities. This report surveys proposed approaches to the oracle problem that are general in the sense that they require neither pre-computed input/output pairs nor a previous version of the system under test. The survey is not encyclopedic. but discusses representative examples of the main approaches and tactics for solving common problems.Partially supported by the Italian National Research Council (CNR). This work has also been supported by the Defense Advanced Research Projects Agency and Rome Laboratory. Air Force Materiel Command. USAF. under agreement number F30602-97-2-0034. The US Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements. either expressed or implied. of the Defense Advanced Research Projects Agency. Rome Laboratory. or the US Government.,True,xvzzSFgAAAAJ:zYLM7Y9cAGgC,225,https://www.academia.edu/download/38771810/oracles.pdf,14002609534452017894,/scholar?cites=14002609534452017894,,,https://www.academia.edu/download/38771810/oracles.pdf,0,0,0
1276692,From web sites to web applications: New issues for conceptual modeling,2000,Luciano Baresi and Franca Garzotto and Paolo Paolini,,,,89-100,Springer. Berlin. Heidelberg,E-commerce. web-based booking systems. and on-line auction systems are only a few examples that demonstrate how web sites are evolving from essentially read-only information repositories to distributed applications. These new web applications blend navigation and browsing capabilities. common to hypermedia. with “classical” operations (or transactions). common to traditional information systems. The coupling between hypermedia and operational features raises a number of novel modeling issues. Conceptual modeling for web applications is not just the union of two activities performed in isolation - designing the operations and designing the hypermedia aspects. Rather. modeling the integration (and interference) of the two facets of design (hypermedia and operations) is the issue. The co-existence of operational and navigational aspects poses several new problems to designers: For example …,True,xvzzSFgAAAAJ:d1gkVwhDpl0C,197,https://link.springer.com/chapter/10.1007/3-540-45394-6_9,15568558327231742509,/scholar?cites=15568558327231742509,,,"ftp://nozdr.ru/biblio/kolxoz/Cs/CsLn/C/Conceptual%20Modeling%20for%20E-Business%20and%20the%20Web,%20ER%202000(LNCS1921,%20Springer,%202000)(ISBN%203540410732)(188s)_CsLn_.pdf#page=99",0,0,0
1276693,Self-supervising bpel processes,2010,Luciano Baresi and Sam Guinea,37,IEEE Transactions on Software Engineering,2,247-263,IEEE,Service compositions suffer changes in their partner services. Even if the composition does not change. its behavior may evolve over time and become incorrect. Such changes cannot be fully foreseen through prerelease validation. but impose a shift in the quality assessment activities. Provided functionality and quality of service must be continuously probed while the application executes. and the application itself must be able to take corrective actions to preserve its dependability and robustness. We propose the idea of self-supervising BPEL processes. that is. special-purpose compositions that assess their behavior and react through user-defined rules. Supervision consists of monitoring and recovery. The former checks the system's execution to see whether everything is proceeding as planned. while the latter attempts to fix any anomalies. The paper introduces two languages for defining monitoring and …,True,xvzzSFgAAAAJ:e5wmG9Sq2KIC,160,https://ieeexplore.ieee.org/abstract/document/5432226/,6157249933476161689,/scholar?cites=6157249933476161689,,,https://re.public.polimi.it/bitstream/11311/573236/1/tse.pdf,0,0,0
1276694,A safe approximate algorithm for interprocedural aliasing,1992,William Landi and Barbara G Ryder,27,ACM SIGPLAN Notices,7,235-248,ACM,During execution. when two or more names exist for the same location at some program point. we call them aliases. In a language which allows arbitrary pointers. the problem of determining aliases at a program point is ρ-space-hard [Lan92]. We present an algorithm for the Conditional May Alias problem. which can be used to safely approximate Interprocedural May Alias in the presence of pointers. This algorithm is as precise as possible in the worst case and has been implemented in a prototype analysis tool for C programs. Preliminary speed and precision results are presented.,True,OdWimfcAAAAJ:u5HHmVD_uO8C,676,https://dl.acm.org/doi/abs/10.1145/143103.143137,1602474973710633428,/scholar?cites=1602474973710633428,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.38&rep=rep1&type=pdf,0,0,0
1276695,Chianti: a tool for change impact analysis of java programs,2004,Xiaoxia Ren and Fenil Shah and Frank Tip and Barbara G Ryder and Ophelia Chesley,,,,432-448,,This paper reports on the design and implementation of Chianti. a change impact analysis tool for Java that is implemented in the context of the Eclipse environment. Chianti analyzes two versions of an application and decomposes their difference into a set of atomic changes. Change impact is then reported in terms of affected (regression or unit) tests whose execution behavior may have been modified by the applied changes. For each affected test. Chianti also determines a set of affecting changes that were responsible for the test's modified behavior. This latter step of isolating the changes that induce the failure of one specific test from those changes that only affect other tests can be used as a debugging technique in situations where a test fails unexpectedly after a long editing session. We evaluated Chianti on a year (2002) of CVS data from M. Ernst's Daikon system. and found that. on average. 52% of Daikon's …,True,OdWimfcAAAAJ:qjMakFHDy7sC,519,https://dl.acm.org/doi/abs/10.1145/1028976.1029012,1215642415758664262,/scholar?cites=1215642415758664262,,,https://www.franktip.org/pubs/oopsla2004.pdf,0,0,0
1276696,Parameterized object sensitivity for points-to analysis for Java,2005,Ana Milanova and Atanas Rountev and Barbara G Ryder,14,ACM Transactions on Software Engineering and Methodology (TOSEM),1,1-41,ACM,The goal of points-to analysis for Java is to determine the set of objects pointed to by a reference variable or a reference object field. We present object sensitivity. a new form of context sensitivity for flow-insensitive points-to analysis for Java. The key idea of our approach is to analyze a method separately for each of the object names that represent run-time objects on which this method may be invoked. To ensure flexibility and practicality. we propose a parameterization framework that allows analysis designers to control the tradeoffs between cost and precision in the object-sensitive analysis.Side-effect analysis determines the memory locations that may be modified by the execution of a program statement. Def-use analysis identifies pairs of statements that set the value of a memory location and subsequently use that value. The information computed by such analyses has a wide variety of uses in compilers and …,True,OdWimfcAAAAJ:Tyk-4Ss8FVUC,448,https://dl.acm.org/doi/abs/10.1145/1044834.1044835,12850898927362076820,/scholar?cites=12850898927362076820,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.759&rep=rep1&type=pdf,0,0,0
1276697,A framework for reducing the cost of instrumented code,2001,Matthew Arnold and Barbara G Ryder,,,,168-179,,Instrumenting code to collect profiling information can cause substantial execution overhead. This overhead makes instrumentation difficult to perform at runtime. often preventing many known offline feedback-directed optimizations from being used in online systems. This paper presents a general framework for performing instrumentation sampling to reduce the overhead of previously expensive instrumentation. The framework is simple and effective. using code-duplication and counter-based sampling to allow switching between instrumented and non-instrumented code.,True,OdWimfcAAAAJ:u-x6o8ySG0sC,444,https://dl.acm.org/doi/abs/10.1145/378795.378832,527626358947644239,/scholar?cites=527626358947644239,,,https://rucore.libraries.rutgers.edu/rutgers-lib/59453/PDF/1/,0,0,0
1276698,Constructing the call graph of a program,1979,Barbara G Ryder,,IEEE Transactions on Software Engineering,3,216-226,IEEE,The proliferation of large software systems written in high level programming languages insures the utility of analysis programs which examine interprocedural communications. Often these analysis programs need to reduce the dynamic relations between procedures to a static data representation. This paper presents one such representation. a directed. acyclic graph named the call graph of a program. We delineate the programs representable by an acyclic call graph and present an algorithm for constructing it using the property that its nodes may be linearly ordered. We prove the correctness of the algorithm and discuss the results obtained from an implementation of the algorithm in the PFORT Verifier [1].,True,OdWimfcAAAAJ:YsMSGLbcyi4C,342,https://ieeexplore.ieee.org/abstract/document/1702621/,1642828596417494329,/scholar?cites=1642828596417494329,,,,0,0,0
1276699,Pointer-induced aliasing: A problem classification,1991,William Landi and Barbara G Ryder,,,,93-103,,A? iasing occurs at some program point during execution when two or more names exist for the same location. We have isolated various programming language mechanisms which create aliases. We have classified the complexity of the fllas problem induced by each mechanism alone and in combination. as AfP-hard. complement tip-hard. or polynomial(’P). We present our problem classification. give an overview of our proof that finding interprocedural aliases in the presence of single level pointers is in 7. and present a represent tive proof for the NP-hard problems.,True,OdWimfcAAAAJ:d1gkVwhDpl0C,320,https://dl.acm.org/doi/pdf/10.1145/99583.99599,15973185594544664966,/scholar?cites=15973185594544664966,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.466.4302&rep=rep1&type=pdf,0,0,0
1276700,Change impact analysis for object-oriented programs,2001,Barbara G Ryder and Frank Tip,,,,46-53,,Small changes can have major and nonlocal effects in object-oriented languages. due to the use of subtyping and dynamic dispatch. This complicates life for maintenance programmers. who need to fix bugs or add enhancements to systems originally written by others. Change impact analysis provides feedback on the semantic impact of a set of program changes. This analysis can be used to determine the regression test drivers that are affected by a set of changes. Moreover. if a test fails. a subset of changes responsible for the failure can be identified. as well as a subset of changes that can be incorporated safely without affecting any test driver.,True,OdWimfcAAAAJ:zYLM7Y9cAGgC,313,https://dl.acm.org/doi/abs/10.1145/379605.379661,9061468520848755225,/scholar?cites=9061468520848755225,,,https://prolangs.cs.vt.edu/refs/docs/paste01.pdf,0,0,0
1276701,The PFORT verifier,1974,Barbara G Ryder,4,Software: Practice and Experience,4,359-377,John Wiley & Sons. Ltd.,The PFORT Verifier is a program which checks a FORTRAN program (i.e. a main program and a set of subprograms) for adherence to a large. carefully defined. portable subset of American National Standard FORTRAN called PFORT. Unlike many FORTRAN implementations. the Verifier diagnoses errors in interprogram‐unit communication through argument lists and COMMON. The Verifier is itself written in PFORT and has been installed on a variety of computers. This paper describes the development of PFORT and the Verifier. A detailed definition of PFORT noting its differences from ANS FORTRAN is included.,True,OdWimfcAAAAJ:5awf1xo2G04C,257,https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.4380040405,14433807533030635428,/scholar?cites=14433807533030635428,,,,0,0,0
1276702,Relevant context inference,1999,Ramkrishna Chatterjee and Barbara G Ryder and William A Landi,,,,133-146,,Relevant context inference (RCI) is a modular technique for flow-and context-sensitive data-flow analysis of statically typed object-oriented programming languages such as C++ and Java. RCI can be used to analyze complete programs as well as incomplete programs such as libraries; this approach does not require that the entire program be memory-resident during the analysis. RCI is presented in the context of points-to analysis for a realistic subset of C++. The empirical evidence obtained from a prototype implementation argues the effectiveness of RCI.,True,OdWimfcAAAAJ:IjCSPb-OGe4C,255,https://dl.acm.org/doi/abs/10.1145/292540.292554,16608646168538319021,/scholar?cites=16608646168538319021,,,https://rucore.libraries.rutgers.edu/rutgers-lib/58528/PDF/1/,0,0,0
1276703,Properties of data flow frameworks,1990,Thomas J Marlowe and Barbara G Ryder,28,Acta Informatica,2,121-163,Springer-Verlag,A comprehensive overview of data flow frameworks and their characterizing properties is presented. to clarify property definitions and demonstrate their interrelation. Properties ensuring the existence of a solution are differentiated from those guaranteeing particular convergence behavior for specific solution procedures. Examples illustrate the orthogonality of these precision and convergence properties. In addition. several data flow problems are categorized with respect to these properties.,True,OdWimfcAAAAJ:2osOgNQ5qMEC,236,https://link.springer.com/article/10.1007%252FBF01237234,16137112680240177867,/scholar?cites=16137112680240177867,,,,0,0,0
1276704,Interprocedural modification side effect analysis with pointer aliasing,1993,William Landi and Barbara G Ryder and Sean Zhang,28,ACM SIGPLAN Notices,6,56-67,ACM,We present a new interprocedural modification side effects algorithm for C programs. that can discern side effects through general-purpose pointer usage. Ours is the first complete design and implementation of such an algorithm. Preliminary performance findings support the practicality of the technique. which is based on our previous approximation algorithm for pointer aliases [LR92]. Each indirect store through a pointer variable is found. on average. to correspond to a store into 1.2 locations. This indicates that our program-point-specific pointer aliasing information is quite precise when used to determine the effects of these stores.,True,OdWimfcAAAAJ:9yKSN-GCB0IC,231,https://dl.acm.org/doi/abs/10.1145/173262.155096,5019952056718806902,/scholar?cites=5019952056718806902,,,https://rucore.libraries.rutgers.edu/rutgers-lib/59307/PDF/1/play/,0,0,0
1276705,Supervised machine learning: A review of classification techniques,2007,Sotiris B Kotsiantis and I Zaharakis and P Pintelas,160,,1,3-24,,The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known. but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course. a single chapter cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms). yet we hope that the references cited will cover the major theoretical issues. guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.,True,6UFNG84AAAAJ:bnK-pcrLprsC,4950,http://books.google.com/books?hl=en&lr=&id=vLiTXDHr_sYC&oi=fnd&pg=PA3&dq=info:5OsGaQhQgMYJ:scholar.google.com&ots=CZlABz3Gjk&sig=YxlI5ThiwJBdVv7PUoNUCjJ08tk,14303520413580717028,/scholar?cites=14303520413580717028,,,http://www.informatica.si/index.php/informatica/article/viewFile/148/140,0,0,0
1276706,Machine learning: a review of classification and combining techniques,2006,Sotiris B Kotsiantis and Ioannis D Zaharakis and Panayiotis E Pintelas,26,,3,159-190,Springer Netherlands,Supervised classification is one of the tasks most frequently carried out by so-called Intelligent Systems. Thus. a large number of techniques have been developed based on Artificial Intelligence (Logic-based techniques. Perceptron-based techniques) and Statistics (Bayesian Networks. Instance-based techniques). The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known. but the value of the class label is unknown. This paper describes various classification algorithms and the recent attempt for improving classification accuracy—ensembles of classifiers.,True,6UFNG84AAAAJ:9yKSN-GCB0IC,874,https://link.springer.com/content/pdf/10.1007/s10462-007-9052-3.pdf,8266669733129795215,/scholar?cites=8266669733129795215,,,https://www.academia.edu/download/46222687/Machine_learning_A_review_of_classificat20160604-31979-s4tevt.pdf,0,0,0
1276707,Handling imbalanced datasets: A review,2006,Sotiris Kotsiantis and Dimitris Kanellopoulos and Panayiotis Pintelas,30,GESTS International Transactions on Computer Science and Engineering,1,25-36,,Learning classifiers from imbalanced or skewed datasets is an important topic. arising very often in practice in classification problems. In such problems. almost all the instances are labelled as one class. while far fewer instances are labelled as the other class. usually the more important class. It is obvious that traditional classifiers seeking an accurate performance over a full range of instances are not suitable to deal with imbalanced learning tasks. since they tend to classify all the data into the majority class. which is usually the less important class. This paper describes various techniques for handling imbalance dataset problems. Of course. a single article cannot be a complete review of all the methods and algorithms. yet we hope that the references cited will cover the major theoretical issues. guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.,True,6UFNG84AAAAJ:u-x6o8ySG0sC,813,https://www.researchgate.net/profile/P_Pintelas/publication/228084509_Handling_imbalanced_datasets_A_review/links/0c960517fefa59fa6b000000.pdf,5244076761059916111,/scholar?cites=5244076761059916111,,,https://www.researchgate.net/profile/P_Pintelas/publication/228084509_Handling_imbalanced_datasets_A_review/links/0c960517fefa59fa6b000000.pdf,0,0,0
1276708,Data preprocessing for supervised leaning,2006,Sotiris B Kotsiantis and Dimitris Kanellopoulos and Panagiotis E Pintelas,1,International Journal of Computer Science,2,111-117,,(ML) on a given task. The representation and quality of the instance data is first and foremost. If there is much irrelevant and redundant information present or noisy and unreliable data. then knowledge discovery during the training phase is more difficult. It is well known that data preparation and filtering steps take considerable amount of processing time in ML problems. Data pre-processing includes data cleaning. normalization. transformation. feature extraction and selection. etc. The product of data pre-processing is the final training set. It would be nice if a single sequence of data pre-processing algorithms had the best performance for each data set but this is not happened. Thus. we present the most well know algorithms for each step of data pre-processing so that one achieves the best performance for their data set.,True,6UFNG84AAAAJ:2osOgNQ5qMEC,806,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.8413&rep=rep1&type=pdf,12574157447843411505,/scholar?cites=12574157447843411505,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.8413&rep=rep1&type=pdf,0,0,0
1276709,A survey on student dropout rates and dropout causes concerning the students in the Course of Informatics of the Hellenic Open University,2002,Michalis Xenos and Christos Pierrakeas and Panagiotis Pintelas,39,Computers & Education,4,361-377,Pergamon,This paper focuses on university-level education offered by methods of distance learning in the field of computers and aims at the investigation of the main causes for student dropouts. The presented study is based on the students of the Course of “Informatics”. Faculty of Science and Technology of the Hellenic Open University and investigates the particularities of education provided through the use of computers and technology in general. This paper presents information about the students' profile. the use of computer technology. the percentage of dropouts. as well as a classification of the reasons for dropouts based on interviews with the students. The study shows that dropouts are correlated with the use of technological means and. based on this fact. the Hellenic Open University implemented interventions in the use of such means. It also proves that a correlation exists between dropouts and students' age. but …,True,6UFNG84AAAAJ:35N4QoGY0k4C,349,https://www.sciencedirect.com/science/article/pii/S0360131502000726,744129697722060135,/scholar?cites=744129697722060135,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.2275&rep=rep1&type=pdf,0,0,0
1276710,Preventing student dropout in distance learning using machine learning techniques,2003,Sotiris B Kotsiantis and CJ Pierrakeas and Panayiotis E Pintelas,,,,267-274,Springer. Berlin. Heidelberg,Student dropout occurs quite often in universities providing distance education. The scope of this research is to study whether the usage of machine learning techniques can be useful in dealing with this problem. Subsequently. an attempt was made to identifying the most appropriate learning algorithm for the prediction of students’ dropout. A number of experiments have taken place with data provided by the ‘informatics’ course of the Hellenic Open University and a quite interesting conclusion is that the Naive Bayes algorithm can be successfully used. A prototype web based support tool. which can automatically recognize students with high probability of dropout. has been constructed by implementing this algorithm.,True,6UFNG84AAAAJ:IjCSPb-OGe4C,267,https://link.springer.com/chapter/10.1007/978-3-540-45226-3_37,13929357911243670856,/scholar?cites=13929357911243670856,,,https://www.researchgate.net/profile/P_Pintelas/publication/221018112_Preventing_Student_Dropout_in_Distance_Learning_Using_Machine_Learning_Techniques/links/0046352b17a5271c1b000000/Preventing-Student-Dropout-in-Distance-Learning-Using-Machine-Learning-Techniques.pdf,0,0,0
1276711,PREDICTING STUDENTS'PERFORMANCE IN DISTANCE LEARNING USING MACHINE LEARNING TECHNIQUES,2004,Sotiris Kotsiantis and Christos Pierrakeas and Panagiotis Pintelas,18,Applied Artificial Intelligence,5,411-426,Taylor & Francis Group,The ability to predict a student's performance could be useful in a great number of different ways associated with university-level distance learning. Students' key demographic characteristics and their marks on a few written assignments can constitute the training set for a supervised machine learning algorithm. The learning algorithm could then be able to predict the performance of new students. thus becoming a useful tool for identifying predicted poor performers. The scope of this work is to compare some of the state of the art learning algorithms. Two experiments have been conducted with six algorithms. which were trained using data sets provided by the Hellenic Open University. Among other significant conclusions. it was found that the Naïve Bayes algorithm is the most appropriate to be used for the construction of a software support tool. has more than satisfactory accuracy. its overall sensitivity is extremely …,True,6UFNG84AAAAJ:zYLM7Y9cAGgC,260,https://www.tandfonline.com/doi/abs/10.1080/08839510490442058,6035580480667046388,/scholar?cites=6035580480667046388,,,https://www.researchgate.net/profile/Christos_Pierrakeas/publication/228084511_PREDICTING_STUDENTS%27PERFORMANCE_IN_DISTANCE_LEARNING_USING_MACHINE_LEARNING_TECHNIQUES/links/0c96051e7c713e77a0000000/PREDICTING-STUDENTSPERFORMANCE-IN-DISTANCE-LEARNING-USING-MACHINE-LEARNING-TECHNIQUES.pdf,0,0,0
1276712,Recent advances in clustering: A brief survey,2004,Sotiris Kotsiantis and Panayiotis Pintelas,1,WSEAS Transactions on Information Science and Applications,1,73-81,,Unsupervised learning (clustering) deals with instances. which have not been pre-classified in any way and so do not have a class attribute associated with them. The scope of applying clustering algorithms is to discover useful but unknown classes of items. Unsupervised learning is an approach of learning where instances are automatically placed into meaningful groups based on their similarity. This paper introduces the fundamental concepts of unsupervised learning while it surveys the recent clustering algorithms. Moreover. recent advances in unsupervised learning. such as ensembles of clustering algorithms and distributed clustering. are described.,True,6UFNG84AAAAJ:d1gkVwhDpl0C,241,https://tarjomefa.com/wp-content/uploads/2018/10/9329-English-TarjomeFa.pdf,1421823786511548837,/scholar?cites=1421823786511548837,,,https://tarjomefa.com/wp-content/uploads/2018/10/9329-English-TarjomeFa.pdf,0,0,0
1276713,Mixture of expert agents for handling imbalanced data sets,2003,SB Kotsiantis and PE Pintelas,1,"Annals of Mathematics, Computing & Teleinformatics",1,46-55,,Many real-world data sets exhibit skewed class distributions in which almost all cases are allotted to a class and far fewer cases to a smaller. usually more interesting class. A classifier induced from an imbalanced data set has. typically. a low error rate for the majority class and an unacceptable error rate for the minority class. This paper firstly provides a systematic study on the various methodologies that have tried to handle this problem. Finally. it presents an experimental study of these methodologies with a proposed mixture of expert agents and it concludes that such a framework can be a more effective solution to the problem. Our method seems to allow improved identification of difficult small classes in predictive analysis. while keeping the classification ability of the other classes in an acceptable level.,True,6UFNG84AAAAJ:qjMakFHDy7sC,159,https://www.researchgate.net/profile/P_Pintelas/publication/228084517_Mixture_of_expert_agents_for_handling_imbalanced_data_sets/links/0c960517fefa3be3f2000000/Mixture-of-expert-agents-for-handling-imbalanced-data-sets.pdf,11188994455009813559,/scholar?cites=11188994455009813559,,,https://www.researchgate.net/profile/P_Pintelas/publication/228084517_Mixture_of_expert_agents_for_handling_imbalanced_data_sets/links/0c960517fefa3be3f2000000/Mixture-of-expert-agents-for-handling-imbalanced-data-sets.pdf,0,0,0
1276714,Combining bagging and boosting,2004,S Kotsiantis and P Pintelas,1,International Journal of Computational Intelligence,4,324-333,,Bagging and boosting are among the most popular re-sampling ensemble methods that generate and combine a diversity of classifiers using the same learning algorithm for the base-classifiers. Boosting algorithms are considered stronger than bagging on noisefree data. However. there are strong empirical indications that bagging is much more robust than boosting in noisy settings. For this reason. in this work we built an ensemble using a voting methodology of bagging and boosting ensembles with 10 subclassifiers in each one. We performed a comparison with simple bagging and boosting ensembles with 25 sub-classifiers. as well as other well known combining methods. on standard benchmark datasets and the proposed technique was the most accurate.,True,6UFNG84AAAAJ:UeHWp8X0CEIC,150,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.3525&rep=rep1&type=pdf,12159230512816710051,/scholar?cites=12159230512816710051,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.3525&rep=rep1&type=pdf,0,0,0
1276715,Predicting students marks in hellenic open university,2005,Sotiris B Kotsiantis and Panayiotis E Pintelas,,,,664-668,IEEE,The ability to provide assistance for a student at the appropriate level is invaluable in the learning process. Not only does it aids the student's learning process but also prevents problems. such as student frustration and floundering. Students' key demographic characteristics and their marks in a small number of written assignments can constitute the training set for a regression method in order to predict the student's performance. The scope of this work compares some of the state of the art regression algorithms in the application domain of predicting students' marks. A number of experiments have been conducted with six algorithms. which were trained using datasets provided by the Hellenic Open University. Finally. a prototype version of software support tool for tutors has been constructed implementing the M5rules algorithm. which proved to be the most appropriate among the tested algorithms.,True,6UFNG84AAAAJ:W7OEmFMy1HYC,110,https://ieeexplore.ieee.org/abstract/document/1508784/,10892379896834947212,/scholar?cites=10892379896834947212,,,https://www.researchgate.net/profile/P_Pintelas/publication/221423304_Predicting_Students_Marks_in_Hellenic_Open_University/links/0deec525d1051f20df000000/Predicting-Students-Marks-in-Hellenic-Open-University.pdf,0,0,0
1276716,Experience factory,2002,Victor R Basili and Gianluigi Caldiera and H Dieter Rombach,,Encyclopedia of software engineering,,,John Wiley & Sons. Inc.,Reuse of products. processes. and experience originating from the system life cycle is seen today as a feasible solution to the problem of developing higher quality systems at a lower cost. In fact. quality improvement is very often achieved by repeatedly reusing and modifying the same elements. learning about them by direct experience.This article presents an infrastructure. called the experience factory. aimed at capitalization and reuse of life‐cycle experience and products. The experience factory is a logical and physical organization. and its activities are independent from those of the development organization. The activities of the development organization and of the experience factory can be summarized as follows:  The development organization develops and delivers systems with the aid of analyzed. synthesized. and packaged experiences from the experience factory. It provides the experience factory with …The development organization develops and delivers systems with the aid of analyzed. synthesized. and packaged experiences from the experience factory. It provides the experience factory with …,True,d9Y04UwAAAAJ:t6usbXjVLHcC,1365,https://onlinelibrary.wiley.com/doi/abs/10.1002/0471028959.sof110,18048848868552178414,/scholar?cites=18048848868552178414,,,http://www.cs.umd.edu/projects/SoftEng/ESEG/papers/fact.pdf,0,0,0
1276717,A study of effective regression testing in practice,1997,W Eric Wong and Joseph R Horgan and Saul London and Hiralal Agrawal,,,,264-274,IEEE,The purpose of regression testing is to ensure that changes made to software. such as adding new features or modifying existing features. have not adversely affected features of the software that should not change. Regression testing is usually performed by running some. or all. of the test cases created to test modifications in previous versions of the software. Many techniques have been reported on how to select regression tests so that the number of test cases does not grow too large as the software evolves. Our proposed hybrid technique combines modification. minimization and prioritization-based selection using a list of source code changes and the execution traces from test cases run on previous versions. This technique seeks to identify a representative subset of all test cases that may result in different output behavior on the new software version. We report our experience with a tool called ATAC …,True,d9Y04UwAAAAJ:u-x6o8ySG0sC,578,https://ieeexplore.ieee.org/abstract/document/630875/,15279188293322760013,/scholar?cites=15279188293322760013,,,https://www.researchgate.net/profile/Hira_Agrawal/publication/3719734_Study_of_effective_regression_testing_in_practice/links/0deec517066a5a3cb6000000/Study-of-effective-regression-testing-in-practice.pdf,0,0,0
1276718,A survey on software fault localization,2016,W Eric Wong and Ruizhi Gao and Yihao Li and Rui Abreu and Franz Wotawa,42,IEEE Transactions on Software Engineering,8,707-740,IEEE,Software fault localization. the act of identifying the locations of faults in a program. is widely recognized to be one of the most tedious. time consuming. and expensive - yet equally critical - activities in program debugging. Due to the increasing scale and complexity of software today. manually locating faults when failures occur is rapidly becoming infeasible. and consequently. there is a strong demand for techniques that can guide software developers to the locations of faults in a program with minimal human intervention. This demand in turn has fueled the proposal and development of a broad spectrum of fault localization techniques. each of which aims to streamline the fault localization process and make it more effective by attacking the problem in a unique way. In this article. we catalog and provide a comprehensive overview of such techniques and discuss key issues and concerns that are pertinent to software …,True,d9Y04UwAAAAJ:FAceZFleit8C,523,https://ieeexplore.ieee.org/abstract/document/7390282/,517074276150213009,/scholar?cites=517074276150213009,,,,0,0,0
1276719,Effect of test set minimization on fault detection effectiveness,1998,W Eric Wong and Joseph R Horgan and Saul London and Aditya P Mathur,28,Software: Practice and Experience,4,347-369,John Wiley & Sons. Ltd.,Given a test set T to test a program P. there are at least two attributes of T that determine its fault detection effectiveness. One attribute is the size of T measured as the number of test cases in T. Another attribute is the code coverage measured when P is executed on all elements of T. The fault detection effectiveness of T is the ratio of the number of faults guaranteed to result in program failure when P is executed on T to the total number of faults present in P. An empirical study was conducted to determine the relative importance of the size and coverage attributes in affecting the fault detection effectiveness of a randomly selected test set for some program P. Results from this study indicate that as the size of a test set is reduced. while the code coverage is kept constant. there is little or no reduction in the fault detection effectiveness of the new test set so generated. For the study reported. of the two attributes mentioned …,True,d9Y04UwAAAAJ:u5HHmVD_uO8C,506,https://onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1097-024X(19980410)28:4%3C347::AID-SPE145%3E3.0.CO;2-L,4524474736395820384,/scholar?cites=4524474736395820384,,,https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.243&rep=rep1&type=pdf,0,0,0
1276720,Fault localization using execution slices and dataflow tests,1995,Hiralal Agrawal and Joseph R Horgan and Saul London and W Eric Wong,,,,143-151,IEEE,Finding a fault in a program is a complex process which involves understanding the program's purpose. structure. semantics. and the relevant characteristics of failure producing tests. We describe a tool which supports execution slicing and dicing based on test cases. We report the results of an experiment that uses heuristic techniques in fault localization.,True,d9Y04UwAAAAJ:d1gkVwhDpl0C,406,https://ieeexplore.ieee.org/abstract/document/497652/,15560623558518872785,/scholar?cites=15560623558518872785,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.5879&rep=rep1&type=pdf,0,0,0
1276721,Testing and quality assurance for component-based software,2003,Jerry Gao and H-SJ Tsao and Ye Wu,,,,,Artech House,From the basics to the most advanced quality of service (QoS) concepts. this all encompassing. first-of-its-kind book offers an in-depth understanding of the latest technical issues raised by the emergence of new types. classes and qualities of Internet services. The book provides end-to-end QoS guidance for real time multimedia communications over the Internet. It offers you a multiplicity of hands-on examples and simulation script support. and shows you where and when it is preferable to use these techniques for QoS support in networks and Internet traffic with widely varying characteristics and demand profiles. This practical resource discusses key standards and protocols. including real-time transport. resource reservation. and integrated and differentiated service models. policy based management. and mobile/wireless QoS. The book features numerous examples. simulation results and graphs that illustrate important concepts. and pseudo codes are used to explain algorithms. Case studies. based on freely available Linux/FreeBSD systems. are presented to show you how to build networks supporting Quality of Service. Online support material including presentation foils. lab exercises and additional exercises are available to text adopters.,True,d9Y04UwAAAAJ:4OULZ7Gr8RgC,311,http://books.google.com/books?hl=en&lr=&id=VoCX09hOsCoC&oi=fnd&pg=PR17&dq=info:sBn1cuFCC94J:scholar.google.com&ots=vg_Uz9t4yL&sig=K80yinbIceUBRILzfdcLJPw15mI,15999955637227559344,/scholar?cites=15999955637227559344,,,,0,0,0
1276722,Reducing the cost of mutation testing: An empirical study,1995,W Eric Wong and Aditya P Mathur,31,Journal of Systems and Software,3,185-196,Elsevier,Of the various testing strategies. mutation testing has been empirically found to be effective in detecting faults. However. mutation often imposes unacceptable demands on computing and human resources because of the large number of mutants that need to be compiled and executed on one or more test cases. In addition. the tester needs to examine many mutants and analyze these for possible equivalence with the program under test. For these reasons. mutation is generally regarded as too expensive to use. Because one significant component of the cost of mutation is the execution of mutants against test cases. we believe that this cost can be reduced dramatically by reducing the number of mutants that need to be examined. We report results from a case study designed to investigate two alternatives for reducing the cost of mutation. The alternatives considered are randomly selected x% mutation and …,True,d9Y04UwAAAAJ:UeHWp8X0CEIC,271,https://www.sciencedirect.com/science/article/pii/0164121294000980,16558664699463504721,/scholar?cites=16558664699463504721,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.8308&rep=rep1&type=pdf,0,0,0
1276723,Using mutation to automatically suggest fixes for faulty programs,2010,Vidroha Debroy and W Eric Wong,,,,65-74,IEEE,This paper proposes a strategy for automatically fixing faults in a program by combining the processes of mutation and fault localization. Statements that are ranked in order of their suspiciousness of containing faults can then be mutated in the same order to produce possible fixes for the faulty program. The proposed strategy is evaluated against the seven benchmark programs of the Siemens suite and the Ant program. Results indicate that the strategy is effective at automatically suggesting fixes for faults without any human intervention.,True,d9Y04UwAAAAJ:MXK_kJrjxJIC,241,https://ieeexplore.ieee.org/abstract/document/5477098/,11099669392750317486,/scholar?cites=11099669392750317486,,,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1060.2767&rep=rep1&type=pdf,0,0,0
1276724,A family of code coverage-based heuristics for effective fault localization,2010,W Eric Wong and Vidroha Debroy and Byoungju Choi,83,Journal of Systems and Software,2,188-208,Elsevier,Locating faults in a program can be very time-consuming and arduous. and therefore. there is an increased demand for automated techniques that can assist in the fault localization process. In this paper a code coverage-based method with a family of heuristics is proposed in order to prioritize suspicious code according to its likelihood of containing program bugs. Highly suspicious code (i.e.. code that is more likely to contain a bug) should be examined before code that is relatively less suspicious; and in this manner programmers can identify and repair faulty code more efficiently and effectively. We also address two important issues: first. how can each additional failed test case aid in locating program faults; and second. how can each additional successful test case help in locating program faults. We propose that with respect to a piece of code. the contribution of the first failed test case that executes it in …,True,d9Y04UwAAAAJ:PR6Y55bgFSsC,237,https://www.sciencedirect.com/science/article/pii/S0164121209002465,5349930914170276462,/scholar?cites=5349930914170276462,,,,0,0,0
1276725,The DStar method for effective software fault localization,2013,W Eric Wong and Vidroha Debroy and Ruizhi Gao and Yihao Li,63,IEEE Transactions on Reliability,1,290-308,IEEE,Effective debugging is crucial to producing reliable software. Manual debugging is becoming prohibitively expensive. especially due to the growing size and complexity of programs. Given that fault localization is one of the most expensive activities in program debugging. there has been a great demand for fault localization techniques that can help guide programmers to the locations of faults. In this paper. a technique named DStar (D*) is proposed which can suggest suspicious locations for fault localization automatically without requiring any prior information on program structure or semantics. D* is evaluated across 24 programs. and is compared to 38 different fault localization techniques. Both single-fault and multi-fault programs are used. Results indicate that D* is more effective at locating faults than all the other techniques it is compared to. An empirical evaluation is also conducted to illustrate how the …,True,d9Y04UwAAAAJ:EkHepimYqZsC,228,https://ieeexplore.ieee.org/abstract/document/6651713/,10041379269606886594,/scholar?cites=10041379269606886594,,,,0,0,0
1276726,Effective fault localization using code coverage,2007,W Eric Wong and Yu Qi and Lei Zhao and Kai-Yuan Cai,1,,,449-456,IEEE,Localizing a bug in a program can be a complex and time- consuming process. In this paper we propose a code coverage-based fault localization method to prioritize suspicious code in terms of its likelihood of containing program bugs. Code with a higher risk should be examined before that with a lower risk. as the former is more suspicious (i.e.. more likely to contain program bugs) than the latter. We also answer a very important question: how can each additional test case that executes the program successfully help locate program bugs? We propose that with respect to a piece of code. the aid introduced by the first successful test that executes it in computing its likelihood of containing a bug is larger than or equal to that of the second successful test that executes it. which is larger than or equal to that of the third successful test that executes it. etc. A tool. chiDebug. was implemented to automate the computation of …,True,d9Y04UwAAAAJ:ufrVoPGSRksC,209,https://ieeexplore.ieee.org/abstract/document/4291037/,6576894374182462340,/scholar?cites=6576894374182462340,,,,0,0,0
1276727,An introduction to conditional random fields for relational learning,2006,Charles Sutton and Andrew McCallum,2,Introduction to statistical relational learning,,93-128,MIT press,Conditional random ﬁelds (CRFs) combine the modeling ﬂexibility of graphical models with the ability to use rich. nonindependent features of the input. In this tutorial. we review modeling. inference. and parameter estimation in CRFs. both on linear chains and on general graphical structures. We discuss diﬀerences between generative and discriminative modeling. latent-variable conditional models. and practical aspects of CRF implementations. Finally. we present a case study applying a loopy CRF to a relational problem in natural language processing.,True,hYtGXD0AAAAJ:M3ejUd6NZC8C,2284,http://books.google.com/books?hl=en&lr=&id=lSkIewOw2WoC&oi=fnd&pg=PA93&dq=info:Gofdi6tx9Q4J:scholar.google.com&ots=T2yNU4fkl0&sig=-G2ye7CTSEdnGp7ti1kxuVs0Vxs,1077892667424999194,/scholar?cites=1077892667424999194,,,https://arxiv.org/pdf/1011.4088,0,0,0
1276728,Introduction to statistical relational learning,2007,Daphne Koller and Nir Friedman and Sašo Džeroski and Charles Sutton and Andrew McCallum and Avi Pfeffer and Pieter Abbeel and Ming-Fai Wong and Chris Meek and Jennifer Neville and David Jensen and James Cussens and Kristian Kersting and Luc De Raedt and Niels Pahlavi and Matthew Richardson and Brian Milch and Marthi Bhaskara and Stuart Russell and Daniel L Ong and Andrey Kolobov and Rodrigo de Salvo Braz and Alexandrin Popescul and Lyle H Ungar and Elizabeth Burnside and Inês Dutra and David Page and Raghu Ramakrishnan and Dan Roth and Jude Shavlik and Alan Fern and Vítor Santos Costa and SungWook Yoon and Razvan Bunescu and Robert Givan and Raymond J Mooney and Wen-tau Yih,,,,,MIT press,Advanced statistical modeling and knowledge representation techniques for a newly emerging area of machine learning and probabilistic reasoning; includes introductory material. tutorials for different proposed approaches. and applications. Handling inherent uncertainty and exploiting compositional structure are fundamental to understanding and designing large-scale systems. Statistical relational learning builds on ideas from probability theory and statistics to address uncertainty while incorporating tools from logic. databases and programming languages to represent structure. In Introduction to Statistical Relational Learning. leading researchers in this emerging area of machine learning describe current formalisms. models. and algorithms that enable effective and robust reasoning about richly structured systems and data. The early chapters provide tutorials for material used in later chapters. offering introductions to representation. inference and learning in graphical models. and logic. The book then describes object-oriented approaches. including probabilistic relational models. relational Markov networks. and probabilistic entity-relationship models as well as logic-based formalisms including Bayesian logic programs. Markov logic. and stochastic logic programs. Later chapters discuss such topics as probabilistic models with unknown objects. relational dependency networks. reinforcement learning in relational domains. and information extraction. By presenting a variety of approaches. the book highlights commonalities and clarifies important differences among proposed approaches and. along the way. identifies important …,True,hYtGXD0AAAAJ:5awf1xo2G04C,1760,http://books.google.com/books?hl=en&lr=&id=lSkIewOw2WoC&oi=fnd&pg=PR5&dq=info:sIP1p7yAYBYJ:scholar.google.com&ots=T2yNU4fkl2&sig=tas5s7uWKcnL4DQYtHJJ6DwvY3k,1612430214358729648,/scholar?cites=1612430214358729648,,,https://www.academia.edu/download/30742662/z2009_1489.pdf,0,0,0
1276729,Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data.,2007,Charles Sutton and Andrew McCallum and Khashayar Rohanimanesh,8,Journal of Machine Learning Research,3,,,In sequence modeling. we often wish to represent complex interaction between labels. such as when performing multiple. cascaded labeling tasks on the same sequence. or when long-range dependencies exist. We present dynamic conditional random fields (DCRFs). a generalization of linear-chain conditional random fields (CRFs) in which each time slice contains a set of state variables and edges—a distributed state representation as in dynamic Bayesian networks (DBNs)—and parameters are tied across slices. Since exact inference can be intractable in such models. we perform approximate inference using several schedules for belief propagation. including tree-based reparameterization (TRP). On a natural-language chunking task. we show that a DCRF performs better than a series of linear-chain CRFs. achieving comparable performance using only half the training data. In addition to maximum conditional likelihood. we present two alternative approaches for training DCRFs: marginal likelihood training. for when we are primarily interested in predicting only a subset of the variables. and cascaded training. for when we have a distinct data set for each state variable. as in transfer learning. We evaluate marginal training and cascaded training on both synthetic data and real-world text data. finding that marginal training can improve accuracy when uncertainty exists over the latent variables. and that for transfer learning. a DCRF trained in a cascaded fashion performs better than a linear-chain CRF that predicts the final task directly.,True,hYtGXD0AAAAJ:u-x6o8ySG0sC,595,https://www.jmlr.org/papers/volume8/sutton07a/sutton07a.pdf,870546838079268566,/scholar?cites=870546838079268566,,,https://www.jmlr.org/papers/volume8/sutton07a/sutton07a.pdf,0,0,0
1276730,A survey of machine learning for big code and naturalness,2018,Miltiadis Allamanis and Earl T Barr and Premkumar Devanbu and Charles Sutton,51,,4,1-37,ACM,Research at the intersection of machine learning. programming languages. and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article. we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then. we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.,True,hYtGXD0AAAAJ:5ugPr518TE4C,363,https://dl.acm.org/doi/abs/10.1145/3212695,1672997375350314594,/scholar?cites=1672997375350314594,,,https://dl.acm.org/doi/pdf/10.1145/3212695,0,0,0
1276731,A convolutional attention network for extreme summarization of source code,2016,Miltiadis Allamanis and Hao Peng and Charles Sutton,,,,2091-2100,PMLR,Attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension. Often there exist features that are locally translation invariant and would be valuable for directing the model’s attention. but previous attentional architectures are not constructed to learn such features specifically. We introduce an attentional neural network that employs convolution on the input tokens to detect local time-invariant and long-range topical attention features in a context-dependent way. We apply this architecture to the problem of extreme summarization of source code snippets into short. descriptive function name-like summaries. Using those features. the model sequentially generates a summary by marginalizing over two attention mechanisms: one that predicts the next summary token based on the attention weights of the input tokens and another that is able to copy a code token as-is directly into the summary. We demonstrate our convolutional attention neural network’s performance on 10 popular Java projects showing that it achieves better performance compared to previous attentional mechanisms.,True,hYtGXD0AAAAJ:pyW8ca7W8N0C,314,http://proceedings.mlr.press/v48/allamanis16.html,4589077170845352419,/scholar?cites=4589077170845352419,,,http://proceedings.mlr.press/v48/allamanis16.pdf,0,0,0
1276732,Veegan: Reducing mode collapse in gans using implicit variational learning,2017,Akash Srivastava and Lazar Valkov and Chris Russell and Michael U Gutmann and Charles Sutton,,arXiv preprint arXiv:1705.07761,,,,Deep generative models provide powerful tools for distributions over complicated manifolds. such as those of natural images. But many of these methods. including generative adversarial networks (GANs). can be difficult to train. in part because they are prone to mode collapse. which means that they characterize only a few modes of the true distribution. To address this. we introduce VEEGAN. which features a reconstructor network. reversing the action of the generator by mapping from data to noise. Our training objective retains the original asymptotic consistency guarantee of GANs. and can be interpreted as a novel autoencoder loss over the noise. In sharp contrast to a traditional autoencoder over data points. VEEGAN does not require specifying a loss function over the data. but rather only over the representations. which are standard normal by assumption. On an extensive set of synthetic and real world image datasets. VEEGAN indeed resists mode collapsing to a far greater extent than other recent GAN variants. and produces more realistic samples.,True,hYtGXD0AAAAJ:kRWSkSYxWN8C,296,https://arxiv.org/abs/1705.07761,4824955249203309779,/scholar?cites=4824955249203309779,,,https://arxiv.org/pdf/1705.07761,0,0,0
1276733,Learning natural coding conventions,2014,Miltiadis Allamanis and Earl T Barr and Christian Bird and Charles Sutton,,,,281-293,,Every programmer has a characteristic style. ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style. fostering readability and hence maintainability. When collaborating. programmers strive to obey a project’s coding conventions. However. one third of reviews of changes contain feedback about coding conventions. indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately. programmers are often unaware of coding conventions because inferring them requires a global view. one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE. a framework that learns the style of a codebase. and suggests revisions to improve stylistic consistency. NATURALIZE builds on …,True,hYtGXD0AAAAJ:lSLTfruPkqcC,295,https://dl.acm.org/doi/abs/10.1145/2635868.2635883,9348437320402747516,/scholar?cites=9348437320402747516,,,https://arxiv.org/pdf/1402.4182,0,0,0
1276734,Suggesting accurate method and class names,2015,Miltiadis Allamanis and Earl T Barr and Christian Bird and Charles Sutton,,,,38-49,,Descriptive names are a vital part of readable. and hence maintainable. code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However. suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive. but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations. called embeddings. in a high-dimensional continuous space. in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens. even …,True,hYtGXD0AAAAJ:3s1wT3WcHBgC,290,https://dl.acm.org/doi/abs/10.1145/2786805.2786849,7265187719308145074,/scholar?cites=7265187719308145074,,,http://www.research.ed.ac.uk/portal/files/23088913/accurate_method_and_class.pdf,0,0,0
1276735,Statistical Machine Learning Makes Automatic Control Practical for Internet Datacenters.,2009,Peter Bodík and Rean Griffith and Charles A Sutton and Armando Fox and Michael I Jordan and David A Patterson,9,HotCloud,,12-12,,Horizontally-scalable Internet services on clusters of commodity computers appear to be a great fit for automatic control: there is a target output (service-level agreement). observed output (actual latency). and gain controller (adjusting the number of servers). Yet few datacenters are automated this way in practice. due in part to well-founded skepticism about whether the simple models often used in the research literature can capture complex real-life workload/performance relationships and keep up with changing conditions that might invalidate the models. We argue that these shortcomings can be fixed by importing modeling. control. and analysis techniques from statistics and machine learning. In particular. we apply rich statistical models of the application’s performance. simulation-based methods for finding an optimal control policy. and change-point methods to find abrupt changes in performance. Preliminary results running a Web 2.0 benchmark application driven by real workload traces on Amazon’s EC2 cloud show that our method can effectively control the number of servers. even in the face of performance anomalies.,True,hYtGXD0AAAAJ:W7OEmFMy1HYC,273,https://static.usenix.org/events/hotcloud09/tech/full_papers/bodik.pdf,12847924518318054367,/scholar?cites=12847924518318054367,,,https://static.usenix.org/events/hotcloud09/tech/full_papers/bodik.pdf,0,0,0
1276736,Exploiting Machine Learning to Subvert Your Spam Filter.,2008,Blaine Nelson and Marco Barreno and Fuching Jack Chi and Anthony D Joseph and Benjamin IP Rubinstein and Udam Saini and Charles A Sutton and J Doug Tygar and Kai Xia,8,LEET,,1-9,,Using statistical machine learning for making security decisions introduces new vulnerabilities in large scale systems. This paper shows how an adversary can exploit statistical machine learning. as used in the SpamBayes spam filter. to render it useless—even if the adversary’s access is limited to only 1% of the training messages. We further demonstrate a new class of focused attacks that successfully prevent victims from receiving specific email messages. Finally. we introduce two new types of defenses against these attacks.,True,hYtGXD0AAAAJ:eQOLeE2rZwMC,263,https://static.usenix.org/event/leet08/tech/full_papers/nelson/nelson.pdf,14180393297832044380,/scholar?cites=14180393297832044380,,,https://static.usenix.org/event/leet08/tech/full_papers/nelson/nelson.pdf,0,0,0
1276737,Mining source code repositories at massive scale using language modeling,2013,Miltiadis Allamanis and Charles Sutton,,,,207-216,IEEE,The tens of thousands of high-quality open source software projects on the Internet raise the exciting possibility of studying software development by finding patterns across truly large source code repositories. This could enable new tools for developing code. encouraging reuse. and navigating large projects. In this paper. we build the first giga-token probabilistic language model of source code. based on 352 million lines of Java. This is 100 times the scale of the pioneering work by Hindle et al. The giga-token model is significantly better at the code suggestion task than previous models. More broadly. our approach provides a new “lens” for analyzing software projects. enabling new complexity metrics based on statistical analysis of large corpora. We call these metrics data-driven complexity metrics. We propose new metrics that measure the complexity of a code module and the topical centrality of a module to a …,True,hYtGXD0AAAAJ:GnPB-g6toBAC,260,https://ieeexplore.ieee.org/abstract/document/6624029/,5675845069319283655,/scholar?cites=5675845069319283655,,,https://core.ac.uk/download/pdf/28974624.pdf,0,0,0
